2025-01-06 12:23:26,663: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/WN_CKGE/', dataset='WN_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106122318/WN_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/WN_CKGE', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 10000.0, 10000.0, 10000.0], token_num=3, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 12:23:34,488: Snapshot:0	Epoch:0	Loss:15.314	translation_Loss:15.314	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:1.68	Hits@10:4.8	Best:1.68
2025-01-06 12:23:41,345: Snapshot:0	Epoch:1	Loss:8.263	translation_Loss:8.263	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.17	Hits@10:16.62	Best:6.17
2025-01-06 12:23:47,904: Snapshot:0	Epoch:2	Loss:3.796	translation_Loss:3.796	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:10.92	Hits@10:27.93	Best:10.92
2025-01-06 12:23:54,852: Snapshot:0	Epoch:3	Loss:1.587	translation_Loss:1.587	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:13.18	Hits@10:33.2	Best:13.18
2025-01-06 12:24:01,437: Snapshot:0	Epoch:4	Loss:0.854	translation_Loss:0.854	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.03	Hits@10:35.47	Best:14.03
2025-01-06 12:24:08,291: Snapshot:0	Epoch:5	Loss:0.534	translation_Loss:0.534	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.62	Hits@10:36.61	Best:14.62
2025-01-06 12:24:14,941: Snapshot:0	Epoch:6	Loss:0.348	translation_Loss:0.348	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.97	Hits@10:37.38	Best:14.97
2025-01-06 12:24:21,910: Snapshot:0	Epoch:7	Loss:0.243	translation_Loss:0.243	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.21	Hits@10:37.97	Best:15.21
2025-01-06 12:24:28,832: Snapshot:0	Epoch:8	Loss:0.178	translation_Loss:0.178	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.35	Hits@10:38.16	Best:15.35
2025-01-06 12:24:35,450: Snapshot:0	Epoch:9	Loss:0.14	translation_Loss:0.14	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.51	Hits@10:38.46	Best:15.51
2025-01-06 12:24:42,247: Snapshot:0	Epoch:10	Loss:0.112	translation_Loss:0.112	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.61	Hits@10:38.74	Best:15.61
2025-01-06 12:24:48,921: Snapshot:0	Epoch:11	Loss:0.093	translation_Loss:0.093	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.7	Hits@10:38.95	Best:15.7
2025-01-06 12:24:55,708: Snapshot:0	Epoch:12	Loss:0.077	translation_Loss:0.077	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.73	Hits@10:39.13	Best:15.73
2025-01-06 12:25:02,601: Snapshot:0	Epoch:13	Loss:0.069	translation_Loss:0.069	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.78	Hits@10:39.24	Best:15.78
2025-01-06 12:25:09,269: Snapshot:0	Epoch:14	Loss:0.059	translation_Loss:0.059	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.84	Hits@10:39.44	Best:15.84
2025-01-06 12:25:16,131: Snapshot:0	Epoch:15	Loss:0.052	translation_Loss:0.052	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.88	Hits@10:39.58	Best:15.88
2025-01-06 12:25:22,800: Snapshot:0	Epoch:16	Loss:0.048	translation_Loss:0.048	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.91	Hits@10:39.66	Best:15.91
2025-01-06 12:25:29,679: Snapshot:0	Epoch:17	Loss:0.045	translation_Loss:0.045	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.95	Hits@10:39.77	Best:15.95
2025-01-06 12:25:36,257: Snapshot:0	Epoch:18	Loss:0.042	translation_Loss:0.042	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.97	Hits@10:39.91	Best:15.97
2025-01-06 12:25:43,104: Snapshot:0	Epoch:19	Loss:0.038	translation_Loss:0.038	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.0	Hits@10:39.99	Best:16.0
2025-01-06 12:25:49,934: Snapshot:0	Epoch:20	Loss:0.037	translation_Loss:0.037	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.0	Hits@10:40.04	Best:16.0
2025-01-06 12:25:56,587: Snapshot:0	Epoch:21	Loss:0.033	translation_Loss:0.033	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.04	Hits@10:40.03	Best:16.04
2025-01-06 12:26:03,376: Snapshot:0	Epoch:22	Loss:0.032	translation_Loss:0.032	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.08	Hits@10:40.13	Best:16.08
2025-01-06 12:26:09,853: Snapshot:0	Epoch:23	Loss:0.032	translation_Loss:0.032	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.05	Hits@10:40.3	Best:16.08
2025-01-06 12:26:16,740: Snapshot:0	Epoch:24	Loss:0.031	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.09	Hits@10:40.38	Best:16.09
2025-01-06 12:26:23,375: Snapshot:0	Epoch:25	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.08	Hits@10:40.38	Best:16.09
2025-01-06 12:26:30,166: Snapshot:0	Epoch:26	Loss:0.03	translation_Loss:0.03	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.09	Hits@10:40.33	Best:16.09
2025-01-06 12:26:37,031: Snapshot:0	Epoch:27	Loss:0.03	translation_Loss:0.03	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.13	Hits@10:40.46	Best:16.13
2025-01-06 12:26:43,649: Snapshot:0	Epoch:28	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.11	Hits@10:40.5	Best:16.13
2025-01-06 12:26:50,504: Snapshot:0	Epoch:29	Loss:0.027	translation_Loss:0.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.15	Hits@10:40.52	Best:16.15
2025-01-06 12:26:57,144: Snapshot:0	Epoch:30	Loss:0.027	translation_Loss:0.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.18	Hits@10:40.6	Best:16.18
2025-01-06 12:27:04,004: Snapshot:0	Epoch:31	Loss:0.027	translation_Loss:0.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.23	Hits@10:40.65	Best:16.23
2025-01-06 12:27:10,859: Snapshot:0	Epoch:32	Loss:0.026	translation_Loss:0.026	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.2	Hits@10:40.66	Best:16.23
2025-01-06 12:27:17,494: Snapshot:0	Epoch:33	Loss:0.025	translation_Loss:0.025	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.22	Hits@10:40.66	Best:16.23
2025-01-06 12:27:24,317: Early Stopping! Snapshot: 0 Epoch: 34 Best Results: 16.23
2025-01-06 12:27:24,317: Start to training tokens! Snapshot: 0 Epoch: 34 Loss:0.026 MRR:16.2 Best Results: 16.23
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:27:24,317: Snapshot:0	Epoch:34	Loss:0.026	translation_Loss:0.026	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.2	Hits@10:40.7	Best:16.23
2025-01-06 12:27:31,397: Snapshot:0	Epoch:35	Loss:17.282	translation_Loss:5.471	token_training_loss:11.811	distillation_Loss:0.0                                                   	MRR:16.2	Hits@10:40.7	Best:16.23
2025-01-06 12:27:38,256: End of token training: 0 Epoch: 36 Loss:5.853 MRR:16.2 Best Results: 16.23
2025-01-06 12:27:38,256: Snapshot:0	Epoch:36	Loss:5.853	translation_Loss:5.473	token_training_loss:0.38	distillation_Loss:0.0                                                           	MRR:16.2	Hits@10:40.7	Best:16.23
2025-01-06 12:27:38,347: => loading checkpoint './checkpoint/WN_CKGE/0model_best.tar'
2025-01-06 12:27:41,783: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1638 | 0.0064 | 0.294  | 0.3554 |  0.4084 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:27:45,064: Snapshot:1	Epoch:0	Loss:2.693	translation_Loss:2.65	token_training_loss:0.0	distillation_Loss:0.044                                                   	MRR:2.54	Hits@10:6.8	Best:2.54
2025-01-06 12:27:46,522: Snapshot:1	Epoch:1	Loss:1.722	translation_Loss:1.61	token_training_loss:0.0	distillation_Loss:0.113                                                   	MRR:7.55	Hits@10:19.68	Best:7.55
2025-01-06 12:27:47,886: Snapshot:1	Epoch:2	Loss:0.932	translation_Loss:0.792	token_training_loss:0.0	distillation_Loss:0.139                                                   	MRR:10.7	Hits@10:26.59	Best:10.7
2025-01-06 12:27:49,360: Snapshot:1	Epoch:3	Loss:0.453	translation_Loss:0.293	token_training_loss:0.0	distillation_Loss:0.16                                                   	MRR:12.51	Hits@10:30.32	Best:12.51
2025-01-06 12:27:50,778: Snapshot:1	Epoch:4	Loss:0.284	translation_Loss:0.103	token_training_loss:0.0	distillation_Loss:0.181                                                   	MRR:13.4	Hits@10:31.77	Best:13.4
2025-01-06 12:27:52,167: Snapshot:1	Epoch:5	Loss:0.232	translation_Loss:0.042	token_training_loss:0.0	distillation_Loss:0.19                                                   	MRR:13.78	Hits@10:32.74	Best:13.78
2025-01-06 12:27:53,784: Snapshot:1	Epoch:6	Loss:0.203	translation_Loss:0.019	token_training_loss:0.0	distillation_Loss:0.184                                                   	MRR:13.91	Hits@10:33.28	Best:13.91
2025-01-06 12:27:55,184: Snapshot:1	Epoch:7	Loss:0.18	translation_Loss:0.011	token_training_loss:0.0	distillation_Loss:0.169                                                   	MRR:13.95	Hits@10:33.49	Best:13.95
2025-01-06 12:27:56,541: Snapshot:1	Epoch:8	Loss:0.157	translation_Loss:0.008	token_training_loss:0.0	distillation_Loss:0.148                                                   	MRR:14.04	Hits@10:33.58	Best:14.04
2025-01-06 12:27:57,994: Snapshot:1	Epoch:9	Loss:0.133	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.126                                                   	MRR:14.09	Hits@10:33.74	Best:14.09
2025-01-06 12:27:59,287: Snapshot:1	Epoch:10	Loss:0.112	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.105                                                   	MRR:14.06	Hits@10:33.79	Best:14.09
2025-01-06 12:28:00,637: Snapshot:1	Epoch:11	Loss:0.094	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.087                                                   	MRR:14.06	Hits@10:33.87	Best:14.09
2025-01-06 12:28:01,901: Early Stopping! Snapshot: 1 Epoch: 12 Best Results: 14.09
2025-01-06 12:28:01,901: Start to training tokens! Snapshot: 1 Epoch: 12 Loss:0.079 MRR:13.97 Best Results: 14.09
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:28:01,902: Snapshot:1	Epoch:12	Loss:0.079	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.072                                                   	MRR:13.97	Hits@10:33.9	Best:14.09
2025-01-06 12:28:03,219: Snapshot:1	Epoch:13	Loss:8.012	translation_Loss:1.145	token_training_loss:6.867	distillation_Loss:0.0                                                   	MRR:13.97	Hits@10:33.9	Best:14.09
2025-01-06 12:28:04,515: End of token training: 1 Epoch: 14 Loss:4.663 MRR:13.97 Best Results: 14.09
2025-01-06 12:28:04,516: Snapshot:1	Epoch:14	Loss:4.663	translation_Loss:1.146	token_training_loss:3.517	distillation_Loss:0.0                                                           	MRR:13.97	Hits@10:33.9	Best:14.09
2025-01-06 12:28:04,612: => loading checkpoint './checkpoint/WN_CKGE/1model_best.tar'
2025-01-06 12:28:08,679: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1637 | 0.0076 | 0.2888 | 0.3563 |  0.4129 |
|     1      | 0.1416 | 0.0059 | 0.2567 | 0.2925 |  0.3336 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:28:12,183: Snapshot:2	Epoch:0	Loss:2.638	translation_Loss:2.595	token_training_loss:0.0	distillation_Loss:0.043                                                   	MRR:2.94	Hits@10:7.77	Best:2.94
2025-01-06 12:28:13,671: Snapshot:2	Epoch:1	Loss:1.638	translation_Loss:1.518	token_training_loss:0.0	distillation_Loss:0.12                                                   	MRR:7.67	Hits@10:19.46	Best:7.67
2025-01-06 12:28:15,150: Snapshot:2	Epoch:2	Loss:0.837	translation_Loss:0.686	token_training_loss:0.0	distillation_Loss:0.151                                                   	MRR:10.74	Hits@10:25.86	Best:10.74
2025-01-06 12:28:16,634: Snapshot:2	Epoch:3	Loss:0.391	translation_Loss:0.225	token_training_loss:0.0	distillation_Loss:0.165                                                   	MRR:12.32	Hits@10:28.28	Best:12.32
2025-01-06 12:28:18,124: Snapshot:2	Epoch:4	Loss:0.255	translation_Loss:0.078	token_training_loss:0.0	distillation_Loss:0.176                                                   	MRR:13.08	Hits@10:29.54	Best:13.08
2025-01-06 12:28:19,708: Snapshot:2	Epoch:5	Loss:0.212	translation_Loss:0.034	token_training_loss:0.0	distillation_Loss:0.178                                                   	MRR:13.42	Hits@10:30.3	Best:13.42
2025-01-06 12:28:21,383: Snapshot:2	Epoch:6	Loss:0.187	translation_Loss:0.018	token_training_loss:0.0	distillation_Loss:0.169                                                   	MRR:13.57	Hits@10:30.81	Best:13.57
2025-01-06 12:28:22,883: Snapshot:2	Epoch:7	Loss:0.166	translation_Loss:0.012	token_training_loss:0.0	distillation_Loss:0.154                                                   	MRR:13.65	Hits@10:31.05	Best:13.65
2025-01-06 12:28:24,292: Snapshot:2	Epoch:8	Loss:0.145	translation_Loss:0.008	token_training_loss:0.0	distillation_Loss:0.136                                                   	MRR:13.64	Hits@10:31.16	Best:13.65
2025-01-06 12:28:25,662: Snapshot:2	Epoch:9	Loss:0.124	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.117                                                   	MRR:13.63	Hits@10:31.13	Best:13.65
2025-01-06 12:28:27,046: Early Stopping! Snapshot: 2 Epoch: 10 Best Results: 13.65
2025-01-06 12:28:27,046: Start to training tokens! Snapshot: 2 Epoch: 10 Loss:0.104 MRR:13.56 Best Results: 13.65
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:28:27,047: Snapshot:2	Epoch:10	Loss:0.104	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.099                                                   	MRR:13.56	Hits@10:31.24	Best:13.65
2025-01-06 12:28:28,491: Snapshot:2	Epoch:11	Loss:7.8	translation_Loss:1.174	token_training_loss:6.625	distillation_Loss:0.0                                                   	MRR:13.56	Hits@10:31.24	Best:13.65
2025-01-06 12:28:29,922: End of token training: 2 Epoch: 12 Loss:4.498 MRR:13.56 Best Results: 13.65
2025-01-06 12:28:29,922: Snapshot:2	Epoch:12	Loss:4.498	translation_Loss:1.173	token_training_loss:3.325	distillation_Loss:0.0                                                           	MRR:13.56	Hits@10:31.24	Best:13.65
2025-01-06 12:28:30,015: => loading checkpoint './checkpoint/WN_CKGE/2model_best.tar'
2025-01-06 12:28:34,808: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1599 | 0.0075 | 0.2791 | 0.3497 |  0.4101 |
|     1      | 0.1381 | 0.0067 | 0.2462 | 0.2868 |  0.3333 |
|     2      | 0.1406 | 0.0086 | 0.2527 | 0.2833 |  0.3228 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:28:38,447: Snapshot:3	Epoch:0	Loss:2.595	translation_Loss:2.553	token_training_loss:0.0	distillation_Loss:0.042                                                   	MRR:2.97	Hits@10:7.53	Best:2.97
2025-01-06 12:28:40,012: Snapshot:3	Epoch:1	Loss:1.57	translation_Loss:1.445	token_training_loss:0.0	distillation_Loss:0.125                                                   	MRR:7.57	Hits@10:19.06	Best:7.57
2025-01-06 12:28:41,638: Snapshot:3	Epoch:2	Loss:0.774	translation_Loss:0.612	token_training_loss:0.0	distillation_Loss:0.162                                                   	MRR:10.65	Hits@10:25.22	Best:10.65
2025-01-06 12:28:43,393: Snapshot:3	Epoch:3	Loss:0.361	translation_Loss:0.187	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:12.12	Hits@10:27.31	Best:12.12
2025-01-06 12:28:44,978: Snapshot:3	Epoch:4	Loss:0.247	translation_Loss:0.07	token_training_loss:0.0	distillation_Loss:0.176                                                   	MRR:12.84	Hits@10:28.44	Best:12.84
2025-01-06 12:28:46,601: Snapshot:3	Epoch:5	Loss:0.203	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.172                                                   	MRR:13.17	Hits@10:29.17	Best:13.17
2025-01-06 12:28:48,214: Snapshot:3	Epoch:6	Loss:0.181	translation_Loss:0.021	token_training_loss:0.0	distillation_Loss:0.16                                                   	MRR:13.26	Hits@10:29.49	Best:13.26
2025-01-06 12:28:49,836: Snapshot:3	Epoch:7	Loss:0.16	translation_Loss:0.014	token_training_loss:0.0	distillation_Loss:0.146                                                   	MRR:13.27	Hits@10:29.65	Best:13.27
2025-01-06 12:28:51,536: Snapshot:3	Epoch:8	Loss:0.14	translation_Loss:0.01	token_training_loss:0.0	distillation_Loss:0.13                                                   	MRR:13.33	Hits@10:30.0	Best:13.33
2025-01-06 12:28:53,103: Snapshot:3	Epoch:9	Loss:0.121	translation_Loss:0.007	token_training_loss:0.0	distillation_Loss:0.114                                                   	MRR:13.35	Hits@10:30.03	Best:13.35
2025-01-06 12:28:54,549: Snapshot:3	Epoch:10	Loss:0.104	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.097                                                   	MRR:13.33	Hits@10:30.08	Best:13.35
2025-01-06 12:28:56,143: Snapshot:3	Epoch:11	Loss:0.088	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.083                                                   	MRR:13.36	Hits@10:30.19	Best:13.36
2025-01-06 12:28:57,647: Snapshot:3	Epoch:12	Loss:0.075	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.07                                                   	MRR:13.3	Hits@10:30.22	Best:13.36
2025-01-06 12:28:59,085: Snapshot:3	Epoch:13	Loss:0.065	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.059                                                   	MRR:13.3	Hits@10:30.43	Best:13.36
2025-01-06 12:29:00,817: Early Stopping! Snapshot: 3 Epoch: 14 Best Results: 13.36
2025-01-06 12:29:00,817: Start to training tokens! Snapshot: 3 Epoch: 14 Loss:0.057 MRR:13.31 Best Results: 13.36
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:29:00,817: Snapshot:3	Epoch:14	Loss:0.057	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.051                                                   	MRR:13.31	Hits@10:30.38	Best:13.36
2025-01-06 12:29:02,334: Snapshot:3	Epoch:15	Loss:7.688	translation_Loss:1.131	token_training_loss:6.557	distillation_Loss:0.0                                                   	MRR:13.31	Hits@10:30.38	Best:13.36
2025-01-06 12:29:03,781: End of token training: 3 Epoch: 16 Loss:4.314 MRR:13.31 Best Results: 13.36
2025-01-06 12:29:03,781: Snapshot:3	Epoch:16	Loss:4.314	translation_Loss:1.128	token_training_loss:3.186	distillation_Loss:0.0                                                           	MRR:13.31	Hits@10:30.38	Best:13.36
2025-01-06 12:29:03,879: => loading checkpoint './checkpoint/WN_CKGE/3model_best.tar'
2025-01-06 12:29:09,508: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1581 | 0.0074 | 0.2729 | 0.3469 |  0.4074 |
|     1      | 0.1355 | 0.007  | 0.2392 | 0.2831 |  0.3255 |
|     2      | 0.137  | 0.0081 | 0.2441 | 0.2801 |  0.3191 |
|     3      | 0.1382 | 0.0097 | 0.2462 | 0.2839 |  0.3239 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:29:13,432: Snapshot:4	Epoch:0	Loss:2.53	translation_Loss:2.49	token_training_loss:0.0	distillation_Loss:0.041                                                   	MRR:10.23	Hits@10:24.46	Best:10.23
2025-01-06 12:29:15,183: Snapshot:4	Epoch:1	Loss:1.495	translation_Loss:1.368	token_training_loss:0.0	distillation_Loss:0.127                                                   	MRR:11.87	Hits@10:28.44	Best:11.87
2025-01-06 12:29:17,090: Snapshot:4	Epoch:2	Loss:0.715	translation_Loss:0.546	token_training_loss:0.0	distillation_Loss:0.169                                                   	MRR:12.89	Hits@10:30.46	Best:12.89
2025-01-06 12:29:18,800: Snapshot:4	Epoch:3	Loss:0.33	translation_Loss:0.153	token_training_loss:0.0	distillation_Loss:0.177                                                   	MRR:13.41	Hits@10:31.18	Best:13.41
2025-01-06 12:29:20,498: Snapshot:4	Epoch:4	Loss:0.23	translation_Loss:0.058	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:13.71	Hits@10:31.45	Best:13.71
2025-01-06 12:29:22,228: Snapshot:4	Epoch:5	Loss:0.192	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.161                                                   	MRR:13.94	Hits@10:31.96	Best:13.94
2025-01-06 12:29:24,052: Snapshot:4	Epoch:6	Loss:0.167	translation_Loss:0.02	token_training_loss:0.0	distillation_Loss:0.146                                                   	MRR:14.05	Hits@10:32.15	Best:14.05
2025-01-06 12:29:25,708: Snapshot:4	Epoch:7	Loss:0.146	translation_Loss:0.014	token_training_loss:0.0	distillation_Loss:0.132                                                   	MRR:14.09	Hits@10:32.45	Best:14.09
2025-01-06 12:29:27,391: Snapshot:4	Epoch:8	Loss:0.129	translation_Loss:0.011	token_training_loss:0.0	distillation_Loss:0.118                                                   	MRR:14.15	Hits@10:32.74	Best:14.15
2025-01-06 12:29:29,112: Snapshot:4	Epoch:9	Loss:0.112	translation_Loss:0.008	token_training_loss:0.0	distillation_Loss:0.104                                                   	MRR:14.23	Hits@10:32.88	Best:14.23
2025-01-06 12:29:30,809: Snapshot:4	Epoch:10	Loss:0.097	translation_Loss:0.007	token_training_loss:0.0	distillation_Loss:0.09                                                   	MRR:14.25	Hits@10:32.77	Best:14.25
2025-01-06 12:29:32,489: Snapshot:4	Epoch:11	Loss:0.083	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.078                                                   	MRR:14.33	Hits@10:32.82	Best:14.33
2025-01-06 12:29:34,053: Snapshot:4	Epoch:12	Loss:0.071	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.066                                                   	MRR:14.32	Hits@10:32.8	Best:14.33
2025-01-06 12:29:35,615: Snapshot:4	Epoch:13	Loss:0.062	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.057                                                   	MRR:14.3	Hits@10:32.77	Best:14.33
2025-01-06 12:29:37,462: Early Stopping! Snapshot: 4 Epoch: 14 Best Results: 14.33
2025-01-06 12:29:37,462: Start to training tokens! Snapshot: 4 Epoch: 14 Loss:0.055 MRR:14.29 Best Results: 14.33
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:29:37,462: Snapshot:4	Epoch:14	Loss:0.055	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.05                                                   	MRR:14.29	Hits@10:32.8	Best:14.33
2025-01-06 12:29:39,096: Snapshot:4	Epoch:15	Loss:7.692	translation_Loss:1.112	token_training_loss:6.58	distillation_Loss:0.0                                                   	MRR:14.29	Hits@10:32.8	Best:14.33
2025-01-06 12:29:40,630: End of token training: 4 Epoch: 16 Loss:4.395 MRR:14.29 Best Results: 14.33
2025-01-06 12:29:40,630: Snapshot:4	Epoch:16	Loss:4.395	translation_Loss:1.111	token_training_loss:3.284	distillation_Loss:0.0                                                           	MRR:14.29	Hits@10:32.8	Best:14.33
2025-01-06 12:29:40,704: => loading checkpoint './checkpoint/WN_CKGE/4model_best.tar'
2025-01-06 12:29:47,378: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1562 | 0.0072 | 0.2688 | 0.3424 |  0.406  |
|     1      | 0.1323 | 0.0051 | 0.2315 | 0.2804 |  0.3245 |
|     2      | 0.1351 | 0.0073 | 0.2417 | 0.2793 |  0.314  |
|     3      | 0.1364 | 0.0073 | 0.2465 | 0.2833 |  0.3204 |
|     4      | 0.1336 | 0.0073 | 0.2354 | 0.2864 |  0.3297 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 12:29:47,379: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1638 | 0.0064 | 0.294  | 0.3554 |  0.4084 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1637 | 0.0076 | 0.2888 | 0.3563 |  0.4129 |
|     1      | 0.1416 | 0.0059 | 0.2567 | 0.2925 |  0.3336 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1599 | 0.0075 | 0.2791 | 0.3497 |  0.4101 |
|     1      | 0.1381 | 0.0067 | 0.2462 | 0.2868 |  0.3333 |
|     2      | 0.1406 | 0.0086 | 0.2527 | 0.2833 |  0.3228 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1581 | 0.0074 | 0.2729 | 0.3469 |  0.4074 |
|     1      | 0.1355 | 0.007  | 0.2392 | 0.2831 |  0.3255 |
|     2      | 0.137  | 0.0081 | 0.2441 | 0.2801 |  0.3191 |
|     3      | 0.1382 | 0.0097 | 0.2462 | 0.2839 |  0.3239 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1562 | 0.0072 | 0.2688 | 0.3424 |  0.406  |
|     1      | 0.1323 | 0.0051 | 0.2315 | 0.2804 |  0.3245 |
|     2      | 0.1351 | 0.0073 | 0.2417 | 0.2793 |  0.314  |
|     3      | 0.1364 | 0.0073 | 0.2465 | 0.2833 |  0.3204 |
|     4      | 0.1336 | 0.0073 | 0.2354 | 0.2864 |  0.3297 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 12:29:47,380: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 251.5927255153656  |   0.164   |    0.006     |    0.294     |     0.408     |
|    1     | 21.847092390060425 |   0.161   |    0.007     |    0.284     |     0.402     |
|    2     | 20.45842456817627  |   0.155   |    0.008     |    0.272     |      0.39     |
|    3     | 27.959421396255493 |   0.151   |    0.008     |    0.263     |     0.379     |
|    4     | 30.01355290412903  |   0.147   |    0.007     |    0.257     |     0.372     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 12:29:47,380: Sum_Training_Time:351.8712167739868
2025-01-06 12:29:47,380: Every_Training_Time:[251.5927255153656, 21.847092390060425, 20.45842456817627, 27.959421396255493, 30.01355290412903]
2025-01-06 12:29:47,380: Forward transfer: 0.059475 Backward transfer: -0.00605
2025-01-06 12:29:59,508: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/WN_CKGE/', dataset='WN_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106122951/WN_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/WN_CKGE', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[5000.0, 5000.0, 10000.0, 20000.0], token_num=3, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 12:30:07,613: Snapshot:0	Epoch:0	Loss:15.314	translation_Loss:15.314	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:1.68	Hits@10:4.8	Best:1.68
2025-01-06 12:30:14,608: Snapshot:0	Epoch:1	Loss:8.263	translation_Loss:8.263	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.17	Hits@10:16.63	Best:6.17
2025-01-06 12:30:21,279: Snapshot:0	Epoch:2	Loss:3.796	translation_Loss:3.796	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:10.92	Hits@10:27.93	Best:10.92
2025-01-06 12:30:28,216: Snapshot:0	Epoch:3	Loss:1.587	translation_Loss:1.587	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:13.19	Hits@10:33.2	Best:13.19
2025-01-06 12:30:34,964: Snapshot:0	Epoch:4	Loss:0.854	translation_Loss:0.854	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.04	Hits@10:35.45	Best:14.04
2025-01-06 12:30:41,984: Snapshot:0	Epoch:5	Loss:0.535	translation_Loss:0.535	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.63	Hits@10:36.54	Best:14.63
2025-01-06 12:30:48,978: Snapshot:0	Epoch:6	Loss:0.35	translation_Loss:0.35	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.98	Hits@10:37.39	Best:14.98
2025-01-06 12:30:55,954: Snapshot:0	Epoch:7	Loss:0.243	translation_Loss:0.243	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.2	Hits@10:37.97	Best:15.2
2025-01-06 12:31:02,956: Snapshot:0	Epoch:8	Loss:0.178	translation_Loss:0.178	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.37	Hits@10:38.24	Best:15.37
2025-01-06 12:31:09,653: Snapshot:0	Epoch:9	Loss:0.138	translation_Loss:0.138	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.53	Hits@10:38.53	Best:15.53
2025-01-06 12:31:16,677: Snapshot:0	Epoch:10	Loss:0.114	translation_Loss:0.114	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.64	Hits@10:38.86	Best:15.64
2025-01-06 12:31:23,440: Snapshot:0	Epoch:11	Loss:0.092	translation_Loss:0.092	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.7	Hits@10:39.08	Best:15.7
2025-01-06 12:31:30,515: Snapshot:0	Epoch:12	Loss:0.079	translation_Loss:0.079	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.75	Hits@10:39.09	Best:15.75
2025-01-06 12:31:37,601: Snapshot:0	Epoch:13	Loss:0.07	translation_Loss:0.07	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.79	Hits@10:39.22	Best:15.79
2025-01-06 12:31:44,398: Snapshot:0	Epoch:14	Loss:0.061	translation_Loss:0.061	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.83	Hits@10:39.48	Best:15.83
2025-01-06 12:31:51,320: Snapshot:0	Epoch:15	Loss:0.052	translation_Loss:0.052	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.89	Hits@10:39.62	Best:15.89
2025-01-06 12:31:58,119: Snapshot:0	Epoch:16	Loss:0.049	translation_Loss:0.049	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.92	Hits@10:39.65	Best:15.92
2025-01-06 12:32:05,039: Snapshot:0	Epoch:17	Loss:0.045	translation_Loss:0.045	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.94	Hits@10:39.72	Best:15.94
2025-01-06 12:32:11,796: Snapshot:0	Epoch:18	Loss:0.04	translation_Loss:0.04	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.94	Hits@10:39.73	Best:15.94
2025-01-06 12:32:18,820: Snapshot:0	Epoch:19	Loss:0.038	translation_Loss:0.038	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.0	Hits@10:39.91	Best:16.0
2025-01-06 12:32:25,901: Snapshot:0	Epoch:20	Loss:0.037	translation_Loss:0.037	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.07	Hits@10:40.04	Best:16.07
2025-01-06 12:32:32,567: Snapshot:0	Epoch:21	Loss:0.033	translation_Loss:0.033	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.03	Hits@10:40.08	Best:16.07
2025-01-06 12:32:39,486: Snapshot:0	Epoch:22	Loss:0.03	translation_Loss:0.03	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.06	Hits@10:40.21	Best:16.07
2025-01-06 12:32:46,195: Early Stopping! Snapshot: 0 Epoch: 23 Best Results: 16.07
2025-01-06 12:32:46,195: Start to training tokens! Snapshot: 0 Epoch: 23 Loss:0.031 MRR:16.03 Best Results: 16.07
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:32:46,196: Snapshot:0	Epoch:23	Loss:0.031	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.03	Hits@10:40.2	Best:16.07
2025-01-06 12:32:53,760: Snapshot:0	Epoch:24	Loss:17.492	translation_Loss:5.68	token_training_loss:11.811	distillation_Loss:0.0                                                   	MRR:16.03	Hits@10:40.2	Best:16.07
2025-01-06 12:33:00,585: End of token training: 0 Epoch: 25 Loss:6.066 MRR:16.03 Best Results: 16.07
2025-01-06 12:33:00,585: Snapshot:0	Epoch:25	Loss:6.066	translation_Loss:5.686	token_training_loss:0.38	distillation_Loss:0.0                                                           	MRR:16.03	Hits@10:40.2	Best:16.07
2025-01-06 12:33:00,679: => loading checkpoint './checkpoint/WN_CKGE/0model_best.tar'
2025-01-06 12:33:04,071: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1624 | 0.0067 | 0.2933 | 0.3526 |  0.4022 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:33:07,380: Snapshot:1	Epoch:0	Loss:2.66	translation_Loss:2.635	token_training_loss:0.0	distillation_Loss:0.024                                                   	MRR:2.33	Hits@10:6.37	Best:2.33
2025-01-06 12:33:08,824: Snapshot:1	Epoch:1	Loss:1.663	translation_Loss:1.582	token_training_loss:0.0	distillation_Loss:0.081                                                   	MRR:7.43	Hits@10:19.57	Best:7.43
2025-01-06 12:33:10,289: Snapshot:1	Epoch:2	Loss:0.873	translation_Loss:0.756	token_training_loss:0.0	distillation_Loss:0.117                                                   	MRR:10.82	Hits@10:26.8	Best:10.82
2025-01-06 12:33:11,725: Snapshot:1	Epoch:3	Loss:0.399	translation_Loss:0.266	token_training_loss:0.0	distillation_Loss:0.133                                                   	MRR:12.67	Hits@10:29.81	Best:12.67
2025-01-06 12:33:13,125: Snapshot:1	Epoch:4	Loss:0.233	translation_Loss:0.093	token_training_loss:0.0	distillation_Loss:0.14                                                   	MRR:13.37	Hits@10:31.29	Best:13.37
2025-01-06 12:33:14,640: Snapshot:1	Epoch:5	Loss:0.178	translation_Loss:0.037	token_training_loss:0.0	distillation_Loss:0.141                                                   	MRR:13.76	Hits@10:32.07	Best:13.76
2025-01-06 12:33:16,070: Snapshot:1	Epoch:6	Loss:0.153	translation_Loss:0.017	token_training_loss:0.0	distillation_Loss:0.135                                                   	MRR:13.89	Hits@10:32.47	Best:13.89
2025-01-06 12:33:17,478: Snapshot:1	Epoch:7	Loss:0.138	translation_Loss:0.012	token_training_loss:0.0	distillation_Loss:0.127                                                   	MRR:13.98	Hits@10:32.8	Best:13.98
2025-01-06 12:33:18,963: Snapshot:1	Epoch:8	Loss:0.125	translation_Loss:0.008	token_training_loss:0.0	distillation_Loss:0.117                                                   	MRR:14.06	Hits@10:32.9	Best:14.06
2025-01-06 12:33:20,526: Snapshot:1	Epoch:9	Loss:0.111	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.106                                                   	MRR:14.05	Hits@10:33.04	Best:14.06
2025-01-06 12:33:22,014: Snapshot:1	Epoch:10	Loss:0.1	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.095                                                   	MRR:14.09	Hits@10:33.12	Best:14.09
2025-01-06 12:33:23,452: Snapshot:1	Epoch:11	Loss:0.089	translation_Loss:0.004	token_training_loss:0.0	distillation_Loss:0.085                                                   	MRR:14.03	Hits@10:33.25	Best:14.09
2025-01-06 12:33:24,771: Snapshot:1	Epoch:12	Loss:0.078	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.075                                                   	MRR:14.01	Hits@10:33.31	Best:14.09
2025-01-06 12:33:26,081: Early Stopping! Snapshot: 1 Epoch: 13 Best Results: 14.09
2025-01-06 12:33:26,081: Start to training tokens! Snapshot: 1 Epoch: 13 Loss:0.069 MRR:14.01 Best Results: 14.09
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:33:26,082: Snapshot:1	Epoch:13	Loss:0.069	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.066                                                   	MRR:14.01	Hits@10:33.23	Best:14.09
2025-01-06 12:33:27,464: Snapshot:1	Epoch:14	Loss:8.044	translation_Loss:1.177	token_training_loss:6.867	distillation_Loss:0.0                                                   	MRR:14.01	Hits@10:33.23	Best:14.09
2025-01-06 12:33:28,765: End of token training: 1 Epoch: 15 Loss:4.693 MRR:14.01 Best Results: 14.09
2025-01-06 12:33:28,765: Snapshot:1	Epoch:15	Loss:4.693	translation_Loss:1.176	token_training_loss:3.517	distillation_Loss:0.0                                                           	MRR:14.01	Hits@10:33.23	Best:14.09
2025-01-06 12:33:28,863: => loading checkpoint './checkpoint/WN_CKGE/1model_best.tar'
2025-01-06 12:33:32,961: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1583 | 0.0075 | 0.2799 | 0.348  |  0.4035 |
|     1      | 0.1435 | 0.007  | 0.2605 | 0.2917 |  0.3333 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:33:36,495: Snapshot:2	Epoch:0	Loss:2.595	translation_Loss:2.571	token_training_loss:0.0	distillation_Loss:0.024                                                   	MRR:2.76	Hits@10:7.69	Best:2.76
2025-01-06 12:33:38,008: Snapshot:2	Epoch:1	Loss:1.571	translation_Loss:1.488	token_training_loss:0.0	distillation_Loss:0.083                                                   	MRR:7.82	Hits@10:19.78	Best:7.82
2025-01-06 12:33:39,622: Snapshot:2	Epoch:2	Loss:0.783	translation_Loss:0.66	token_training_loss:0.0	distillation_Loss:0.124                                                   	MRR:10.86	Hits@10:25.48	Best:10.86
2025-01-06 12:33:41,155: Snapshot:2	Epoch:3	Loss:0.349	translation_Loss:0.207	token_training_loss:0.0	distillation_Loss:0.141                                                   	MRR:12.38	Hits@10:28.12	Best:12.38
2025-01-06 12:33:42,726: Snapshot:2	Epoch:4	Loss:0.216	translation_Loss:0.071	token_training_loss:0.0	distillation_Loss:0.145                                                   	MRR:13.18	Hits@10:29.03	Best:13.18
2025-01-06 12:33:44,255: Snapshot:2	Epoch:5	Loss:0.171	translation_Loss:0.032	token_training_loss:0.0	distillation_Loss:0.139                                                   	MRR:13.41	Hits@10:29.62	Best:13.41
2025-01-06 12:33:45,751: Snapshot:2	Epoch:6	Loss:0.148	translation_Loss:0.02	token_training_loss:0.0	distillation_Loss:0.128                                                   	MRR:13.57	Hits@10:30.05	Best:13.57
2025-01-06 12:33:47,358: Snapshot:2	Epoch:7	Loss:0.129	translation_Loss:0.013	token_training_loss:0.0	distillation_Loss:0.116                                                   	MRR:13.62	Hits@10:30.48	Best:13.62
2025-01-06 12:33:48,874: Snapshot:2	Epoch:8	Loss:0.114	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.106                                                   	MRR:13.66	Hits@10:30.7	Best:13.66
2025-01-06 12:33:50,592: Snapshot:2	Epoch:9	Loss:0.104	translation_Loss:0.008	token_training_loss:0.0	distillation_Loss:0.096                                                   	MRR:13.69	Hits@10:30.97	Best:13.69
2025-01-06 12:33:52,174: Snapshot:2	Epoch:10	Loss:0.092	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.087                                                   	MRR:13.73	Hits@10:31.1	Best:13.73
2025-01-06 12:33:53,680: Snapshot:2	Epoch:11	Loss:0.083	translation_Loss:0.004	token_training_loss:0.0	distillation_Loss:0.078                                                   	MRR:13.78	Hits@10:31.21	Best:13.78
2025-01-06 12:33:55,055: Snapshot:2	Epoch:12	Loss:0.073	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.07                                                   	MRR:13.77	Hits@10:31.16	Best:13.78
2025-01-06 12:33:56,443: Snapshot:2	Epoch:13	Loss:0.066	translation_Loss:0.004	token_training_loss:0.0	distillation_Loss:0.062                                                   	MRR:13.78	Hits@10:31.26	Best:13.78
2025-01-06 12:33:58,000: Snapshot:2	Epoch:14	Loss:0.059	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.055                                                   	MRR:13.79	Hits@10:31.26	Best:13.79
2025-01-06 12:33:59,407: Snapshot:2	Epoch:15	Loss:0.052	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.049                                                   	MRR:13.78	Hits@10:31.34	Best:13.79
2025-01-06 12:34:00,917: Snapshot:2	Epoch:16	Loss:0.047	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.044                                                   	MRR:13.78	Hits@10:31.37	Best:13.79
2025-01-06 12:34:02,336: Early Stopping! Snapshot: 2 Epoch: 17 Best Results: 13.79
2025-01-06 12:34:02,336: Start to training tokens! Snapshot: 2 Epoch: 17 Loss:0.043 MRR:13.77 Best Results: 13.79
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:34:02,336: Snapshot:2	Epoch:17	Loss:0.043	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.04                                                   	MRR:13.77	Hits@10:31.29	Best:13.79
2025-01-06 12:34:03,752: Snapshot:2	Epoch:18	Loss:7.805	translation_Loss:1.179	token_training_loss:6.625	distillation_Loss:0.0                                                   	MRR:13.77	Hits@10:31.29	Best:13.79
2025-01-06 12:34:05,144: End of token training: 2 Epoch: 19 Loss:4.503 MRR:13.77 Best Results: 13.79
2025-01-06 12:34:05,144: Snapshot:2	Epoch:19	Loss:4.503	translation_Loss:1.177	token_training_loss:3.325	distillation_Loss:0.0                                                           	MRR:13.77	Hits@10:31.29	Best:13.79
2025-01-06 12:34:05,218: => loading checkpoint './checkpoint/WN_CKGE/2model_best.tar'
2025-01-06 12:34:10,222: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1546 | 0.0064 | 0.2725 | 0.3419 |  0.3985 |
|     1      | 0.1409 | 0.0075 | 0.2546 | 0.2933 |  0.332  |
|     2      | 0.1404 | 0.0086 | 0.2554 | 0.2831 |  0.3153 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:34:13,899: Snapshot:3	Epoch:0	Loss:2.58	translation_Loss:2.538	token_training_loss:0.0	distillation_Loss:0.042                                                   	MRR:2.84	Hits@10:7.07	Best:2.84
2025-01-06 12:34:15,498: Snapshot:3	Epoch:1	Loss:1.553	translation_Loss:1.426	token_training_loss:0.0	distillation_Loss:0.127                                                   	MRR:7.39	Hits@10:18.44	Best:7.39
2025-01-06 12:34:17,118: Snapshot:3	Epoch:2	Loss:0.764	translation_Loss:0.597	token_training_loss:0.0	distillation_Loss:0.167                                                   	MRR:10.59	Hits@10:25.08	Best:10.59
2025-01-06 12:34:18,730: Snapshot:3	Epoch:3	Loss:0.36	translation_Loss:0.183	token_training_loss:0.0	distillation_Loss:0.177                                                   	MRR:12.2	Hits@10:27.37	Best:12.2
2025-01-06 12:34:20,342: Snapshot:3	Epoch:4	Loss:0.246	translation_Loss:0.067	token_training_loss:0.0	distillation_Loss:0.179                                                   	MRR:12.91	Hits@10:28.6	Best:12.91
2025-01-06 12:34:21,941: Snapshot:3	Epoch:5	Loss:0.205	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.174                                                   	MRR:13.17	Hits@10:29.03	Best:13.17
2025-01-06 12:34:23,534: Snapshot:3	Epoch:6	Loss:0.182	translation_Loss:0.02	token_training_loss:0.0	distillation_Loss:0.162                                                   	MRR:13.3	Hits@10:29.35	Best:13.3
2025-01-06 12:34:25,228: Snapshot:3	Epoch:7	Loss:0.162	translation_Loss:0.014	token_training_loss:0.0	distillation_Loss:0.148                                                   	MRR:13.38	Hits@10:29.57	Best:13.38
2025-01-06 12:34:26,857: Snapshot:3	Epoch:8	Loss:0.141	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.132                                                   	MRR:13.47	Hits@10:30.0	Best:13.47
2025-01-06 12:34:28,407: Snapshot:3	Epoch:9	Loss:0.123	translation_Loss:0.008	token_training_loss:0.0	distillation_Loss:0.115                                                   	MRR:13.45	Hits@10:30.13	Best:13.47
2025-01-06 12:34:29,982: Snapshot:3	Epoch:10	Loss:0.106	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.099                                                   	MRR:13.51	Hits@10:30.22	Best:13.51
2025-01-06 12:34:31,567: Snapshot:3	Epoch:11	Loss:0.091	translation_Loss:0.007	token_training_loss:0.0	distillation_Loss:0.085                                                   	MRR:13.54	Hits@10:30.46	Best:13.54
2025-01-06 12:34:33,233: Snapshot:3	Epoch:12	Loss:0.077	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.072                                                   	MRR:13.5	Hits@10:30.4	Best:13.54
2025-01-06 12:34:34,709: Snapshot:3	Epoch:13	Loss:0.066	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.061                                                   	MRR:13.51	Hits@10:30.22	Best:13.54
2025-01-06 12:34:36,351: Snapshot:3	Epoch:14	Loss:0.059	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.053                                                   	MRR:13.56	Hits@10:30.4	Best:13.56
2025-01-06 12:34:37,820: Snapshot:3	Epoch:15	Loss:0.053	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.046                                                   	MRR:13.54	Hits@10:30.4	Best:13.56
2025-01-06 12:34:39,298: Snapshot:3	Epoch:16	Loss:0.048	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.042                                                   	MRR:13.56	Hits@10:30.38	Best:13.56
2025-01-06 12:34:40,769: Early Stopping! Snapshot: 3 Epoch: 17 Best Results: 13.56
2025-01-06 12:34:40,769: Start to training tokens! Snapshot: 3 Epoch: 17 Loss:0.044 MRR:13.55 Best Results: 13.56
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:34:40,770: Snapshot:3	Epoch:17	Loss:0.044	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.038                                                   	MRR:13.55	Hits@10:30.3	Best:13.56
2025-01-06 12:34:42,359: Snapshot:3	Epoch:18	Loss:7.758	translation_Loss:1.201	token_training_loss:6.557	distillation_Loss:0.0                                                   	MRR:13.55	Hits@10:30.3	Best:13.56
2025-01-06 12:34:43,900: End of token training: 3 Epoch: 19 Loss:4.386 MRR:13.55 Best Results: 13.56
2025-01-06 12:34:43,900: Snapshot:3	Epoch:19	Loss:4.386	translation_Loss:1.2	token_training_loss:3.186	distillation_Loss:0.0                                                           	MRR:13.55	Hits@10:30.3	Best:13.56
2025-01-06 12:34:44,033: => loading checkpoint './checkpoint/WN_CKGE/3model_best.tar'
2025-01-06 12:34:49,875: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1537 | 0.0066 | 0.2697 | 0.3405 |  0.3974 |
|     1      | 0.1391 | 0.007  | 0.2495 | 0.2914 |  0.3298 |
|     2      | 0.138  | 0.0078 |  0.25  | 0.2841 |  0.3161 |
|     3      | 0.1376 | 0.0097 | 0.2444 | 0.2823 |  0.3207 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:34:53,844: Snapshot:4	Epoch:0	Loss:2.552	translation_Loss:2.479	token_training_loss:0.0	distillation_Loss:0.073                                                   	MRR:10.11	Hits@10:24.25	Best:10.11
2025-01-06 12:34:55,548: Snapshot:4	Epoch:1	Loss:1.535	translation_Loss:1.359	token_training_loss:0.0	distillation_Loss:0.176                                                   	MRR:11.83	Hits@10:28.12	Best:11.83
2025-01-06 12:34:57,302: Snapshot:4	Epoch:2	Loss:0.745	translation_Loss:0.543	token_training_loss:0.0	distillation_Loss:0.202                                                   	MRR:13.02	Hits@10:30.59	Best:13.02
2025-01-06 12:34:58,992: Snapshot:4	Epoch:3	Loss:0.37	translation_Loss:0.156	token_training_loss:0.0	distillation_Loss:0.214                                                   	MRR:13.59	Hits@10:31.21	Best:13.59
2025-01-06 12:35:00,711: Snapshot:4	Epoch:4	Loss:0.283	translation_Loss:0.06	token_training_loss:0.0	distillation_Loss:0.222                                                   	MRR:13.89	Hits@10:31.56	Best:13.89
2025-01-06 12:35:02,523: Snapshot:4	Epoch:5	Loss:0.249	translation_Loss:0.034	token_training_loss:0.0	distillation_Loss:0.215                                                   	MRR:14.03	Hits@10:31.83	Best:14.03
2025-01-06 12:35:04,248: Snapshot:4	Epoch:6	Loss:0.214	translation_Loss:0.021	token_training_loss:0.0	distillation_Loss:0.193                                                   	MRR:14.15	Hits@10:32.42	Best:14.15
2025-01-06 12:35:06,070: Snapshot:4	Epoch:7	Loss:0.182	translation_Loss:0.015	token_training_loss:0.0	distillation_Loss:0.167                                                   	MRR:14.29	Hits@10:32.72	Best:14.29
2025-01-06 12:35:07,850: Snapshot:4	Epoch:8	Loss:0.152	translation_Loss:0.012	token_training_loss:0.0	distillation_Loss:0.14                                                   	MRR:14.29	Hits@10:33.06	Best:14.29
2025-01-06 12:35:09,515: Snapshot:4	Epoch:9	Loss:0.124	translation_Loss:0.01	token_training_loss:0.0	distillation_Loss:0.114                                                   	MRR:14.29	Hits@10:33.28	Best:14.29
2025-01-06 12:35:11,170: Early Stopping! Snapshot: 4 Epoch: 10 Best Results: 14.29
2025-01-06 12:35:11,170: Start to training tokens! Snapshot: 4 Epoch: 10 Loss:0.102 MRR:14.29 Best Results: 14.29
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:35:11,171: Snapshot:4	Epoch:10	Loss:0.102	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.092                                                   	MRR:14.29	Hits@10:33.2	Best:14.29
2025-01-06 12:35:12,818: Snapshot:4	Epoch:11	Loss:7.804	translation_Loss:1.224	token_training_loss:6.58	distillation_Loss:0.0                                                   	MRR:14.29	Hits@10:33.2	Best:14.29
2025-01-06 12:35:14,390: End of token training: 4 Epoch: 12 Loss:4.508 MRR:14.29 Best Results: 14.29
2025-01-06 12:35:14,391: Snapshot:4	Epoch:12	Loss:4.508	translation_Loss:1.224	token_training_loss:3.284	distillation_Loss:0.0                                                           	MRR:14.29	Hits@10:33.2	Best:14.29
2025-01-06 12:35:14,483: => loading checkpoint './checkpoint/WN_CKGE/4model_best.tar'
2025-01-06 12:35:21,179: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1521 | 0.0072 | 0.2662 | 0.3359 |  0.3918 |
|     1      | 0.137  | 0.007  | 0.2425 | 0.2852 |  0.3282 |
|     2      | 0.137  | 0.0081 | 0.246  | 0.282  |  0.3169 |
|     3      | 0.1373 | 0.0102 | 0.243  | 0.2863 |  0.3199 |
|     4      | 0.1333 | 0.0102 | 0.2327 | 0.2834 |  0.3254 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 12:35:21,181: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1624 | 0.0067 | 0.2933 | 0.3526 |  0.4022 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1583 | 0.0075 | 0.2799 | 0.348  |  0.4035 |
|     1      | 0.1435 | 0.007  | 0.2605 | 0.2917 |  0.3333 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1546 | 0.0064 | 0.2725 | 0.3419 |  0.3985 |
|     1      | 0.1409 | 0.0075 | 0.2546 | 0.2933 |  0.332  |
|     2      | 0.1404 | 0.0086 | 0.2554 | 0.2831 |  0.3153 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1537 | 0.0066 | 0.2697 | 0.3405 |  0.3974 |
|     1      | 0.1391 | 0.007  | 0.2495 | 0.2914 |  0.3298 |
|     2      | 0.138  | 0.0078 |  0.25  | 0.2841 |  0.3161 |
|     3      | 0.1376 | 0.0097 | 0.2444 | 0.2823 |  0.3207 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1521 | 0.0072 | 0.2662 | 0.3359 |  0.3918 |
|     1      | 0.137  | 0.007  | 0.2425 | 0.2852 |  0.3282 |
|     2      | 0.137  | 0.0081 | 0.246  | 0.282  |  0.3169 |
|     3      | 0.1373 | 0.0102 | 0.243  | 0.2863 |  0.3199 |
|     4      | 0.1333 | 0.0102 | 0.2327 | 0.2834 |  0.3254 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 12:35:21,182: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 181.07614731788635 |   0.162   |    0.007     |    0.293     |     0.402     |
|    1     | 23.989830493927002 |   0.156   |    0.007     |    0.277     |     0.393     |
|    2     | 31.39065933227539  |   0.151   |    0.007     |    0.268     |      0.38     |
|    3     | 32.84565997123718  |   0.149   |    0.007     |    0.262     |     0.372     |
|    4     | 23.569947242736816 |   0.146   |    0.008     |    0.256     |     0.364     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 12:35:21,182: Sum_Training_Time:292.87224435806274
2025-01-06 12:35:21,182: Every_Training_Time:[181.07614731788635, 23.989830493927002, 31.39065933227539, 32.84565997123718, 23.569947242736816]
2025-01-06 12:35:21,182: Forward transfer: 0.059675000000000006 Backward transfer: -0.005124999999999984
2025-01-06 12:35:33,292: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/WN_CKGE/', dataset='WN_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106123525/WN_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/WN_CKGE', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[1000.0, 5000.0, 10000.0, 20000.0], token_num=3, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 12:35:41,259: Snapshot:0	Epoch:0	Loss:15.314	translation_Loss:15.314	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:1.68	Hits@10:4.8	Best:1.68
2025-01-06 12:35:48,262: Snapshot:0	Epoch:1	Loss:8.263	translation_Loss:8.263	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.17	Hits@10:16.63	Best:6.17
2025-01-06 12:35:55,036: Snapshot:0	Epoch:2	Loss:3.796	translation_Loss:3.796	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:10.92	Hits@10:27.93	Best:10.92
2025-01-06 12:36:01,959: Snapshot:0	Epoch:3	Loss:1.587	translation_Loss:1.587	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:13.18	Hits@10:33.17	Best:13.18
2025-01-06 12:36:08,651: Snapshot:0	Epoch:4	Loss:0.854	translation_Loss:0.854	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.04	Hits@10:35.48	Best:14.04
2025-01-06 12:36:15,461: Snapshot:0	Epoch:5	Loss:0.535	translation_Loss:0.535	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.62	Hits@10:36.69	Best:14.62
2025-01-06 12:36:22,212: Snapshot:0	Epoch:6	Loss:0.348	translation_Loss:0.348	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.0	Hits@10:37.44	Best:15.0
2025-01-06 12:36:29,079: Snapshot:0	Epoch:7	Loss:0.244	translation_Loss:0.244	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.22	Hits@10:37.93	Best:15.22
2025-01-06 12:36:35,901: Snapshot:0	Epoch:8	Loss:0.177	translation_Loss:0.177	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.37	Hits@10:38.26	Best:15.37
2025-01-06 12:36:42,758: Snapshot:0	Epoch:9	Loss:0.139	translation_Loss:0.139	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.55	Hits@10:38.56	Best:15.55
2025-01-06 12:36:49,746: Snapshot:0	Epoch:10	Loss:0.111	translation_Loss:0.111	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.61	Hits@10:38.76	Best:15.61
2025-01-06 12:36:56,444: Snapshot:0	Epoch:11	Loss:0.093	translation_Loss:0.093	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.68	Hits@10:38.89	Best:15.68
2025-01-06 12:37:03,236: Snapshot:0	Epoch:12	Loss:0.079	translation_Loss:0.079	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.73	Hits@10:39.05	Best:15.73
2025-01-06 12:37:10,104: Snapshot:0	Epoch:13	Loss:0.07	translation_Loss:0.07	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.73	Hits@10:39.22	Best:15.73
2025-01-06 12:37:16,767: Snapshot:0	Epoch:14	Loss:0.061	translation_Loss:0.061	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.79	Hits@10:39.36	Best:15.79
2025-01-06 12:37:23,747: Snapshot:0	Epoch:15	Loss:0.053	translation_Loss:0.053	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.8	Hits@10:39.5	Best:15.8
2025-01-06 12:37:30,566: Snapshot:0	Epoch:16	Loss:0.049	translation_Loss:0.049	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.89	Hits@10:39.58	Best:15.89
2025-01-06 12:37:37,410: Snapshot:0	Epoch:17	Loss:0.045	translation_Loss:0.045	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.9	Hits@10:39.75	Best:15.9
2025-01-06 12:37:44,091: Snapshot:0	Epoch:18	Loss:0.041	translation_Loss:0.041	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.93	Hits@10:39.88	Best:15.93
2025-01-06 12:37:50,965: Snapshot:0	Epoch:19	Loss:0.037	translation_Loss:0.037	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.94	Hits@10:39.93	Best:15.94
2025-01-06 12:37:57,824: Snapshot:0	Epoch:20	Loss:0.037	translation_Loss:0.037	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.97	Hits@10:39.94	Best:15.97
2025-01-06 12:38:04,384: Snapshot:0	Epoch:21	Loss:0.033	translation_Loss:0.033	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.96	Hits@10:40.09	Best:15.97
2025-01-06 12:38:11,316: Snapshot:0	Epoch:22	Loss:0.033	translation_Loss:0.033	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.01	Hits@10:40.18	Best:16.01
2025-01-06 12:38:18,034: Snapshot:0	Epoch:23	Loss:0.034	translation_Loss:0.034	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.04	Hits@10:40.33	Best:16.04
2025-01-06 12:38:25,019: Snapshot:0	Epoch:24	Loss:0.03	translation_Loss:0.03	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.08	Hits@10:40.35	Best:16.08
2025-01-06 12:38:31,629: Snapshot:0	Epoch:25	Loss:0.029	translation_Loss:0.029	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.07	Hits@10:40.45	Best:16.08
2025-01-06 12:38:38,414: Snapshot:0	Epoch:26	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.11	Hits@10:40.41	Best:16.11
2025-01-06 12:38:45,359: Snapshot:0	Epoch:27	Loss:0.03	translation_Loss:0.03	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.09	Hits@10:40.43	Best:16.11
2025-01-06 12:38:52,197: Snapshot:0	Epoch:28	Loss:0.029	translation_Loss:0.029	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.13	Hits@10:40.56	Best:16.13
2025-01-06 12:38:59,008: Snapshot:0	Epoch:29	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.1	Hits@10:40.54	Best:16.13
2025-01-06 12:39:05,553: Snapshot:0	Epoch:30	Loss:0.027	translation_Loss:0.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.13	Hits@10:40.65	Best:16.13
2025-01-06 12:39:12,488: Snapshot:0	Epoch:31	Loss:0.026	translation_Loss:0.026	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.14	Hits@10:40.72	Best:16.14
2025-01-06 12:39:19,340: Snapshot:0	Epoch:32	Loss:0.025	translation_Loss:0.025	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.13	Hits@10:40.7	Best:16.14
2025-01-06 12:39:25,962: Snapshot:0	Epoch:33	Loss:0.027	translation_Loss:0.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.13	Hits@10:40.65	Best:16.14
2025-01-06 12:39:32,920: Early Stopping! Snapshot: 0 Epoch: 34 Best Results: 16.14
2025-01-06 12:39:32,920: Start to training tokens! Snapshot: 0 Epoch: 34 Loss:0.025 MRR:16.14 Best Results: 16.14
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:39:32,921: Snapshot:0	Epoch:34	Loss:0.025	translation_Loss:0.025	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.14	Hits@10:40.74	Best:16.14
2025-01-06 12:39:40,074: Snapshot:0	Epoch:35	Loss:17.293	translation_Loss:5.482	token_training_loss:11.811	distillation_Loss:0.0                                                   	MRR:16.14	Hits@10:40.74	Best:16.14
2025-01-06 12:39:46,853: End of token training: 0 Epoch: 36 Loss:5.864 MRR:16.14 Best Results: 16.14
2025-01-06 12:39:46,853: Snapshot:0	Epoch:36	Loss:5.864	translation_Loss:5.484	token_training_loss:0.38	distillation_Loss:0.0                                                           	MRR:16.14	Hits@10:40.74	Best:16.14
2025-01-06 12:39:46,949: => loading checkpoint './checkpoint/WN_CKGE/0model_best.tar'
2025-01-06 12:39:50,113: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1641 | 0.0066 | 0.2937 | 0.3562 |  0.4097 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:39:53,489: Snapshot:1	Epoch:0	Loss:2.655	translation_Loss:2.649	token_training_loss:0.0	distillation_Loss:0.006                                                   	MRR:2.59	Hits@10:6.77	Best:2.59
2025-01-06 12:39:54,892: Snapshot:1	Epoch:1	Loss:1.627	translation_Loss:1.603	token_training_loss:0.0	distillation_Loss:0.024                                                   	MRR:7.58	Hits@10:20.35	Best:7.58
2025-01-06 12:39:56,322: Snapshot:1	Epoch:2	Loss:0.821	translation_Loss:0.778	token_training_loss:0.0	distillation_Loss:0.043                                                   	MRR:10.93	Hits@10:27.04	Best:10.93
2025-01-06 12:39:57,703: Snapshot:1	Epoch:3	Loss:0.334	translation_Loss:0.277	token_training_loss:0.0	distillation_Loss:0.057                                                   	MRR:12.77	Hits@10:30.3	Best:12.77
2025-01-06 12:39:59,074: Snapshot:1	Epoch:4	Loss:0.158	translation_Loss:0.091	token_training_loss:0.0	distillation_Loss:0.066                                                   	MRR:13.65	Hits@10:31.96	Best:13.65
2025-01-06 12:40:00,500: Snapshot:1	Epoch:5	Loss:0.105	translation_Loss:0.035	token_training_loss:0.0	distillation_Loss:0.07                                                   	MRR:14.03	Hits@10:32.66	Best:14.03
2025-01-06 12:40:02,124: Snapshot:1	Epoch:6	Loss:0.087	translation_Loss:0.016	token_training_loss:0.0	distillation_Loss:0.07                                                   	MRR:14.12	Hits@10:33.23	Best:14.12
2025-01-06 12:40:03,540: Snapshot:1	Epoch:7	Loss:0.077	translation_Loss:0.01	token_training_loss:0.0	distillation_Loss:0.067                                                   	MRR:14.22	Hits@10:33.39	Best:14.22
2025-01-06 12:40:04,995: Snapshot:1	Epoch:8	Loss:0.069	translation_Loss:0.007	token_training_loss:0.0	distillation_Loss:0.062                                                   	MRR:14.24	Hits@10:33.58	Best:14.24
2025-01-06 12:40:06,394: Snapshot:1	Epoch:9	Loss:0.061	translation_Loss:0.004	token_training_loss:0.0	distillation_Loss:0.057                                                   	MRR:14.17	Hits@10:33.71	Best:14.24
2025-01-06 12:40:07,804: Snapshot:1	Epoch:10	Loss:0.055	translation_Loss:0.004	token_training_loss:0.0	distillation_Loss:0.051                                                   	MRR:14.18	Hits@10:33.79	Best:14.24
2025-01-06 12:40:09,165: Early Stopping! Snapshot: 1 Epoch: 11 Best Results: 14.24
2025-01-06 12:40:09,165: Start to training tokens! Snapshot: 1 Epoch: 11 Loss:0.049 MRR:14.21 Best Results: 14.24
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:40:09,165: Snapshot:1	Epoch:11	Loss:0.049	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.046                                                   	MRR:14.21	Hits@10:33.71	Best:14.24
2025-01-06 12:40:10,537: Snapshot:1	Epoch:12	Loss:8.107	translation_Loss:1.241	token_training_loss:6.867	distillation_Loss:0.0                                                   	MRR:14.21	Hits@10:33.71	Best:14.24
2025-01-06 12:40:11,820: End of token training: 1 Epoch: 13 Loss:4.758 MRR:14.21 Best Results: 14.24
2025-01-06 12:40:11,821: Snapshot:1	Epoch:13	Loss:4.758	translation_Loss:1.241	token_training_loss:3.517	distillation_Loss:0.0                                                           	MRR:14.21	Hits@10:33.71	Best:14.24
2025-01-06 12:40:11,898: => loading checkpoint './checkpoint/WN_CKGE/1model_best.tar'
2025-01-06 12:40:15,949: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1533 | 0.0067 | 0.2648 | 0.3359 |  0.4011 |
|     1      | 0.1433 | 0.0056 | 0.2659 | 0.2944 |  0.3328 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:40:19,439: Snapshot:2	Epoch:0	Loss:2.596	translation_Loss:2.573	token_training_loss:0.0	distillation_Loss:0.024                                                   	MRR:2.83	Hits@10:7.72	Best:2.83
2025-01-06 12:40:21,009: Snapshot:2	Epoch:1	Loss:1.584	translation_Loss:1.504	token_training_loss:0.0	distillation_Loss:0.081                                                   	MRR:7.83	Hits@10:19.65	Best:7.83
2025-01-06 12:40:22,546: Snapshot:2	Epoch:2	Loss:0.792	translation_Loss:0.675	token_training_loss:0.0	distillation_Loss:0.117                                                   	MRR:10.85	Hits@10:25.35	Best:10.85
2025-01-06 12:40:24,130: Snapshot:2	Epoch:3	Loss:0.348	translation_Loss:0.216	token_training_loss:0.0	distillation_Loss:0.132                                                   	MRR:12.34	Hits@10:27.9	Best:12.34
2025-01-06 12:40:25,612: Snapshot:2	Epoch:4	Loss:0.213	translation_Loss:0.077	token_training_loss:0.0	distillation_Loss:0.135                                                   	MRR:13.05	Hits@10:28.95	Best:13.05
2025-01-06 12:40:27,216: Snapshot:2	Epoch:5	Loss:0.166	translation_Loss:0.033	token_training_loss:0.0	distillation_Loss:0.132                                                   	MRR:13.31	Hits@10:29.81	Best:13.31
2025-01-06 12:40:28,715: Snapshot:2	Epoch:6	Loss:0.144	translation_Loss:0.02	token_training_loss:0.0	distillation_Loss:0.124                                                   	MRR:13.57	Hits@10:30.24	Best:13.57
2025-01-06 12:40:30,428: Snapshot:2	Epoch:7	Loss:0.127	translation_Loss:0.012	token_training_loss:0.0	distillation_Loss:0.114                                                   	MRR:13.66	Hits@10:30.4	Best:13.66
2025-01-06 12:40:32,019: Snapshot:2	Epoch:8	Loss:0.114	translation_Loss:0.01	token_training_loss:0.0	distillation_Loss:0.104                                                   	MRR:13.68	Hits@10:30.59	Best:13.68
2025-01-06 12:40:33,526: Snapshot:2	Epoch:9	Loss:0.1	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.094                                                   	MRR:13.7	Hits@10:30.81	Best:13.7
2025-01-06 12:40:35,003: Snapshot:2	Epoch:10	Loss:0.09	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.085                                                   	MRR:13.7	Hits@10:30.99	Best:13.7
2025-01-06 12:40:36,496: Snapshot:2	Epoch:11	Loss:0.08	translation_Loss:0.004	token_training_loss:0.0	distillation_Loss:0.076                                                   	MRR:13.77	Hits@10:31.21	Best:13.77
2025-01-06 12:40:37,907: Snapshot:2	Epoch:12	Loss:0.071	translation_Loss:0.004	token_training_loss:0.0	distillation_Loss:0.068                                                   	MRR:13.76	Hits@10:31.13	Best:13.77
2025-01-06 12:40:39,384: Snapshot:2	Epoch:13	Loss:0.063	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:13.72	Hits@10:31.18	Best:13.77
2025-01-06 12:40:40,786: Early Stopping! Snapshot: 2 Epoch: 14 Best Results: 13.77
2025-01-06 12:40:40,786: Start to training tokens! Snapshot: 2 Epoch: 14 Loss:0.056 MRR:13.71 Best Results: 13.77
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:40:40,787: Snapshot:2	Epoch:14	Loss:0.056	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.053                                                   	MRR:13.71	Hits@10:31.21	Best:13.77
2025-01-06 12:40:42,156: Snapshot:2	Epoch:15	Loss:7.867	translation_Loss:1.242	token_training_loss:6.625	distillation_Loss:0.0                                                   	MRR:13.71	Hits@10:31.21	Best:13.77
2025-01-06 12:40:43,553: End of token training: 2 Epoch: 16 Loss:4.571 MRR:13.71 Best Results: 13.77
2025-01-06 12:40:43,554: Snapshot:2	Epoch:16	Loss:4.571	translation_Loss:1.245	token_training_loss:3.325	distillation_Loss:0.0                                                           	MRR:13.71	Hits@10:31.21	Best:13.77
2025-01-06 12:40:43,679: => loading checkpoint './checkpoint/WN_CKGE/2model_best.tar'
2025-01-06 12:40:48,735: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1498 | 0.0063 | 0.2565 | 0.3285 |  0.3936 |
|     1      | 0.1403 | 0.0065 | 0.253  | 0.2901 |  0.3317 |
|     2      | 0.1395 | 0.0067 | 0.253  | 0.2841 |  0.3148 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:40:52,175: Snapshot:3	Epoch:0	Loss:2.582	translation_Loss:2.54	token_training_loss:0.0	distillation_Loss:0.042                                                   	MRR:2.91	Hits@10:7.1	Best:2.91
2025-01-06 12:40:53,966: Snapshot:3	Epoch:1	Loss:1.558	translation_Loss:1.436	token_training_loss:0.0	distillation_Loss:0.122                                                   	MRR:7.5	Hits@10:18.98	Best:7.5
2025-01-06 12:40:55,544: Snapshot:3	Epoch:2	Loss:0.766	translation_Loss:0.609	token_training_loss:0.0	distillation_Loss:0.157                                                   	MRR:10.7	Hits@10:24.95	Best:10.7
2025-01-06 12:40:57,164: Snapshot:3	Epoch:3	Loss:0.358	translation_Loss:0.189	token_training_loss:0.0	distillation_Loss:0.169                                                   	MRR:12.19	Hits@10:27.02	Best:12.19
2025-01-06 12:40:58,737: Snapshot:3	Epoch:4	Loss:0.239	translation_Loss:0.066	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:12.79	Hits@10:28.23	Best:12.79
2025-01-06 12:41:00,315: Snapshot:3	Epoch:5	Loss:0.204	translation_Loss:0.034	token_training_loss:0.0	distillation_Loss:0.17                                                   	MRR:13.18	Hits@10:28.82	Best:13.18
2025-01-06 12:41:01,920: Snapshot:3	Epoch:6	Loss:0.179	translation_Loss:0.02	token_training_loss:0.0	distillation_Loss:0.159                                                   	MRR:13.31	Hits@10:29.06	Best:13.31
2025-01-06 12:41:03,505: Snapshot:3	Epoch:7	Loss:0.158	translation_Loss:0.013	token_training_loss:0.0	distillation_Loss:0.145                                                   	MRR:13.39	Hits@10:29.41	Best:13.39
2025-01-06 12:41:05,172: Snapshot:3	Epoch:8	Loss:0.138	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.129                                                   	MRR:13.44	Hits@10:29.49	Best:13.44
2025-01-06 12:41:06,739: Snapshot:3	Epoch:9	Loss:0.119	translation_Loss:0.007	token_training_loss:0.0	distillation_Loss:0.112                                                   	MRR:13.5	Hits@10:29.7	Best:13.5
2025-01-06 12:41:08,190: Snapshot:3	Epoch:10	Loss:0.102	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.096                                                   	MRR:13.49	Hits@10:29.92	Best:13.5
2025-01-06 12:41:09,820: Snapshot:3	Epoch:11	Loss:0.087	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.081                                                   	MRR:13.51	Hits@10:30.05	Best:13.51
2025-01-06 12:41:11,547: Snapshot:3	Epoch:12	Loss:0.074	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.069                                                   	MRR:13.45	Hits@10:30.13	Best:13.51
2025-01-06 12:41:13,111: Snapshot:3	Epoch:13	Loss:0.063	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.058                                                   	MRR:13.42	Hits@10:30.08	Best:13.51
2025-01-06 12:41:14,571: Early Stopping! Snapshot: 3 Epoch: 14 Best Results: 13.51
2025-01-06 12:41:14,571: Start to training tokens! Snapshot: 3 Epoch: 14 Loss:0.056 MRR:13.45 Best Results: 13.51
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:41:14,571: Snapshot:3	Epoch:14	Loss:0.056	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.05                                                   	MRR:13.45	Hits@10:30.11	Best:13.51
2025-01-06 12:41:16,105: Snapshot:3	Epoch:15	Loss:7.808	translation_Loss:1.251	token_training_loss:6.557	distillation_Loss:0.0                                                   	MRR:13.45	Hits@10:30.11	Best:13.51
2025-01-06 12:41:17,570: End of token training: 3 Epoch: 16 Loss:4.441 MRR:13.45 Best Results: 13.51
2025-01-06 12:41:17,571: Snapshot:3	Epoch:16	Loss:4.441	translation_Loss:1.255	token_training_loss:3.186	distillation_Loss:0.0                                                           	MRR:13.45	Hits@10:30.11	Best:13.51
2025-01-06 12:41:17,646: => loading checkpoint './checkpoint/WN_CKGE/3model_best.tar'
2025-01-06 12:41:23,463: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1479 | 0.0068 | 0.2537 | 0.3238 |  0.3894 |
|     1      | 0.138  | 0.0067 | 0.2478 | 0.286  |  0.3274 |
|     2      | 0.1381 | 0.0081 | 0.2503 | 0.2817 |  0.3134 |
|     3      | 0.138  | 0.0089 | 0.2454 | 0.282  |  0.3215 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:41:27,115: Snapshot:4	Epoch:0	Loss:2.546	translation_Loss:2.474	token_training_loss:0.0	distillation_Loss:0.072                                                   	MRR:10.05	Hits@10:24.17	Best:10.05
2025-01-06 12:41:29,010: Snapshot:4	Epoch:1	Loss:1.53	translation_Loss:1.362	token_training_loss:0.0	distillation_Loss:0.168                                                   	MRR:11.69	Hits@10:27.8	Best:11.69
2025-01-06 12:41:30,716: Snapshot:4	Epoch:2	Loss:0.746	translation_Loss:0.553	token_training_loss:0.0	distillation_Loss:0.193                                                   	MRR:12.78	Hits@10:30.4	Best:12.78
2025-01-06 12:41:32,419: Snapshot:4	Epoch:3	Loss:0.372	translation_Loss:0.163	token_training_loss:0.0	distillation_Loss:0.209                                                   	MRR:13.27	Hits@10:31.34	Best:13.27
2025-01-06 12:41:34,110: Snapshot:4	Epoch:4	Loss:0.281	translation_Loss:0.064	token_training_loss:0.0	distillation_Loss:0.217                                                   	MRR:13.57	Hits@10:31.53	Best:13.57
2025-01-06 12:41:35,920: Snapshot:4	Epoch:5	Loss:0.242	translation_Loss:0.033	token_training_loss:0.0	distillation_Loss:0.209                                                   	MRR:13.69	Hits@10:31.75	Best:13.69
2025-01-06 12:41:37,658: Snapshot:4	Epoch:6	Loss:0.209	translation_Loss:0.022	token_training_loss:0.0	distillation_Loss:0.187                                                   	MRR:13.79	Hits@10:32.02	Best:13.79
2025-01-06 12:41:39,445: Snapshot:4	Epoch:7	Loss:0.179	translation_Loss:0.017	token_training_loss:0.0	distillation_Loss:0.162                                                   	MRR:13.81	Hits@10:32.28	Best:13.81
2025-01-06 12:41:41,137: Snapshot:4	Epoch:8	Loss:0.148	translation_Loss:0.012	token_training_loss:0.0	distillation_Loss:0.136                                                   	MRR:13.89	Hits@10:32.53	Best:13.89
2025-01-06 12:41:42,958: Snapshot:4	Epoch:9	Loss:0.12	translation_Loss:0.01	token_training_loss:0.0	distillation_Loss:0.111                                                   	MRR:13.91	Hits@10:32.9	Best:13.91
2025-01-06 12:41:44,724: Snapshot:4	Epoch:10	Loss:0.099	translation_Loss:0.01	token_training_loss:0.0	distillation_Loss:0.089                                                   	MRR:14.0	Hits@10:32.82	Best:14.0
2025-01-06 12:41:46,499: Snapshot:4	Epoch:11	Loss:0.082	translation_Loss:0.01	token_training_loss:0.0	distillation_Loss:0.072                                                   	MRR:14.01	Hits@10:32.74	Best:14.01
2025-01-06 12:41:48,454: Snapshot:4	Epoch:12	Loss:0.069	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:14.03	Hits@10:32.8	Best:14.03
2025-01-06 12:41:50,088: Snapshot:4	Epoch:13	Loss:0.06	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.051                                                   	MRR:14.01	Hits@10:32.85	Best:14.03
2025-01-06 12:41:51,723: Snapshot:4	Epoch:14	Loss:0.054	translation_Loss:0.01	token_training_loss:0.0	distillation_Loss:0.045                                                   	MRR:14.02	Hits@10:32.82	Best:14.03
2025-01-06 12:41:53,498: Snapshot:4	Epoch:15	Loss:0.051	translation_Loss:0.01	token_training_loss:0.0	distillation_Loss:0.041                                                   	MRR:14.04	Hits@10:32.85	Best:14.04
2025-01-06 12:41:55,246: Snapshot:4	Epoch:16	Loss:0.046	translation_Loss:0.008	token_training_loss:0.0	distillation_Loss:0.038                                                   	MRR:14.12	Hits@10:32.96	Best:14.12
2025-01-06 12:41:57,254: Snapshot:4	Epoch:17	Loss:0.045	translation_Loss:0.008	token_training_loss:0.0	distillation_Loss:0.036                                                   	MRR:14.2	Hits@10:32.98	Best:14.2
2025-01-06 12:41:58,824: Snapshot:4	Epoch:18	Loss:0.042	translation_Loss:0.008	token_training_loss:0.0	distillation_Loss:0.035                                                   	MRR:14.16	Hits@10:33.01	Best:14.2
2025-01-06 12:42:00,377: Snapshot:4	Epoch:19	Loss:0.04	translation_Loss:0.007	token_training_loss:0.0	distillation_Loss:0.033                                                   	MRR:14.11	Hits@10:33.04	Best:14.2
2025-01-06 12:42:01,935: Early Stopping! Snapshot: 4 Epoch: 20 Best Results: 14.2
2025-01-06 12:42:01,935: Start to training tokens! Snapshot: 4 Epoch: 20 Loss:0.039 MRR:14.16 Best Results: 14.2
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:42:01,935: Snapshot:4	Epoch:20	Loss:0.039	translation_Loss:0.007	token_training_loss:0.0	distillation_Loss:0.032                                                   	MRR:14.16	Hits@10:33.12	Best:14.2
2025-01-06 12:42:03,499: Snapshot:4	Epoch:21	Loss:7.853	translation_Loss:1.274	token_training_loss:6.58	distillation_Loss:0.0                                                   	MRR:14.16	Hits@10:33.12	Best:14.2
2025-01-06 12:42:05,046: End of token training: 4 Epoch: 22 Loss:4.559 MRR:14.16 Best Results: 14.2
2025-01-06 12:42:05,047: Snapshot:4	Epoch:22	Loss:4.559	translation_Loss:1.274	token_training_loss:3.284	distillation_Loss:0.0                                                           	MRR:14.16	Hits@10:33.12	Best:14.2
2025-01-06 12:42:05,196: => loading checkpoint './checkpoint/WN_CKGE/4model_best.tar'
2025-01-06 12:42:12,044: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1481 | 0.0069 | 0.2532 | 0.3241 |  0.3909 |
|     1      | 0.1361 | 0.0048 | 0.2425 | 0.2836 |  0.3266 |
|     2      | 0.1373 | 0.0059 | 0.2522 | 0.2836 |  0.3156 |
|     3      | 0.1374 | 0.0081 | 0.2457 | 0.2833 |  0.3242 |
|     4      | 0.1305 | 0.0083 | 0.2265 | 0.2775 |  0.3208 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 12:42:12,047: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1641 | 0.0066 | 0.2937 | 0.3562 |  0.4097 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1533 | 0.0067 | 0.2648 | 0.3359 |  0.4011 |
|     1      | 0.1433 | 0.0056 | 0.2659 | 0.2944 |  0.3328 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1498 | 0.0063 | 0.2565 | 0.3285 |  0.3936 |
|     1      | 0.1403 | 0.0065 | 0.253  | 0.2901 |  0.3317 |
|     2      | 0.1395 | 0.0067 | 0.253  | 0.2841 |  0.3148 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1479 | 0.0068 | 0.2537 | 0.3238 |  0.3894 |
|     1      | 0.138  | 0.0067 | 0.2478 | 0.286  |  0.3274 |
|     2      | 0.1381 | 0.0081 | 0.2503 | 0.2817 |  0.3134 |
|     3      | 0.138  | 0.0089 | 0.2454 | 0.282  |  0.3215 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1481 | 0.0069 | 0.2532 | 0.3241 |  0.3909 |
|     1      | 0.1361 | 0.0048 | 0.2425 | 0.2836 |  0.3266 |
|     2      | 0.1373 | 0.0059 | 0.2522 | 0.2836 |  0.3156 |
|     3      | 0.1374 | 0.0081 | 0.2457 | 0.2833 |  0.3242 |
|     4      | 0.1305 | 0.0083 | 0.2265 | 0.2775 |  0.3208 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 12:42:12,047: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 253.56064629554749 |   0.164   |    0.007     |    0.294     |      0.41     |
|    1     | 20.817445039749146 |   0.152   |    0.007     |    0.265     |     0.391     |
|    2     | 26.817437410354614 |   0.147   |    0.006     |    0.256     |     0.376     |
|    3     | 27.994784116744995 |   0.145   |    0.007     |    0.252     |     0.367     |
|    4     | 40.64593172073364  |   0.143   |    0.007     |    0.249     |     0.363     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 12:42:12,047: Sum_Training_Time:369.8362445831299
2025-01-06 12:42:12,047: Every_Training_Time:[253.56064629554749, 20.817445039749146, 26.817437410354614, 27.994784116744995, 40.64593172073364]
2025-01-06 12:42:12,047: Forward transfer: 0.0584 Backward transfer: -0.006500000000000006
2025-01-06 12:42:24,451: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/WN_CKGE/', dataset='WN_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106124216/WN_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/WN_CKGE', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[20000.0, 5000.0, 10000.0, 20000.0], token_num=3, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 12:42:32,428: Snapshot:0	Epoch:0	Loss:15.314	translation_Loss:15.314	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:1.68	Hits@10:4.8	Best:1.68
2025-01-06 12:42:39,438: Snapshot:0	Epoch:1	Loss:8.263	translation_Loss:8.263	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.17	Hits@10:16.63	Best:6.17
2025-01-06 12:42:46,156: Snapshot:0	Epoch:2	Loss:3.796	translation_Loss:3.796	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:10.92	Hits@10:27.94	Best:10.92
2025-01-06 12:42:53,291: Snapshot:0	Epoch:3	Loss:1.587	translation_Loss:1.587	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:13.18	Hits@10:33.2	Best:13.18
2025-01-06 12:42:59,996: Snapshot:0	Epoch:4	Loss:0.854	translation_Loss:0.854	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.04	Hits@10:35.51	Best:14.04
2025-01-06 12:43:06,992: Snapshot:0	Epoch:5	Loss:0.533	translation_Loss:0.533	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.63	Hits@10:36.64	Best:14.63
2025-01-06 12:43:13,666: Snapshot:0	Epoch:6	Loss:0.349	translation_Loss:0.349	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.0	Hits@10:37.43	Best:15.0
2025-01-06 12:43:20,569: Snapshot:0	Epoch:7	Loss:0.245	translation_Loss:0.245	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.19	Hits@10:37.95	Best:15.19
2025-01-06 12:43:27,432: Snapshot:0	Epoch:8	Loss:0.179	translation_Loss:0.179	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.36	Hits@10:38.19	Best:15.36
2025-01-06 12:43:34,180: Snapshot:0	Epoch:9	Loss:0.138	translation_Loss:0.138	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.47	Hits@10:38.46	Best:15.47
2025-01-06 12:43:41,165: Snapshot:0	Epoch:10	Loss:0.113	translation_Loss:0.113	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.59	Hits@10:38.68	Best:15.59
2025-01-06 12:43:47,799: Snapshot:0	Epoch:11	Loss:0.094	translation_Loss:0.094	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.66	Hits@10:38.96	Best:15.66
2025-01-06 12:43:54,780: Snapshot:0	Epoch:12	Loss:0.078	translation_Loss:0.078	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.69	Hits@10:39.12	Best:15.69
2025-01-06 12:44:01,643: Snapshot:0	Epoch:13	Loss:0.071	translation_Loss:0.071	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.8	Hits@10:39.27	Best:15.8
2025-01-06 12:44:08,269: Snapshot:0	Epoch:14	Loss:0.06	translation_Loss:0.06	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.84	Hits@10:39.37	Best:15.84
2025-01-06 12:44:15,101: Snapshot:0	Epoch:15	Loss:0.052	translation_Loss:0.052	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.87	Hits@10:39.44	Best:15.87
2025-01-06 12:44:21,797: Snapshot:0	Epoch:16	Loss:0.047	translation_Loss:0.047	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.9	Hits@10:39.53	Best:15.9
2025-01-06 12:44:28,788: Snapshot:0	Epoch:17	Loss:0.045	translation_Loss:0.045	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.94	Hits@10:39.69	Best:15.94
2025-01-06 12:44:35,414: Snapshot:0	Epoch:18	Loss:0.042	translation_Loss:0.042	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.96	Hits@10:39.78	Best:15.96
2025-01-06 12:44:42,361: Snapshot:0	Epoch:19	Loss:0.04	translation_Loss:0.04	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.97	Hits@10:39.88	Best:15.97
2025-01-06 12:44:49,130: Snapshot:0	Epoch:20	Loss:0.037	translation_Loss:0.037	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.96	Hits@10:39.75	Best:15.97
2025-01-06 12:44:55,895: Snapshot:0	Epoch:21	Loss:0.035	translation_Loss:0.035	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.97	Hits@10:39.97	Best:15.97
2025-01-06 12:45:02,848: Snapshot:0	Epoch:22	Loss:0.031	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.01	Hits@10:40.06	Best:16.01
2025-01-06 12:45:09,620: Snapshot:0	Epoch:23	Loss:0.031	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.02	Hits@10:40.24	Best:16.02
2025-01-06 12:45:16,582: Snapshot:0	Epoch:24	Loss:0.031	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.09	Hits@10:40.36	Best:16.09
2025-01-06 12:45:23,432: Snapshot:0	Epoch:25	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.09	Hits@10:40.39	Best:16.09
2025-01-06 12:45:30,379: Snapshot:0	Epoch:26	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.08	Hits@10:40.38	Best:16.09
2025-01-06 12:45:37,184: Snapshot:0	Epoch:27	Loss:0.029	translation_Loss:0.029	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.11	Hits@10:40.51	Best:16.11
2025-01-06 12:45:43,812: Snapshot:0	Epoch:28	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.14	Hits@10:40.52	Best:16.14
2025-01-06 12:45:50,630: Snapshot:0	Epoch:29	Loss:0.027	translation_Loss:0.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.17	Hits@10:40.52	Best:16.17
2025-01-06 12:45:57,277: Snapshot:0	Epoch:30	Loss:0.027	translation_Loss:0.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.15	Hits@10:40.56	Best:16.17
2025-01-06 12:46:04,121: Snapshot:0	Epoch:31	Loss:0.027	translation_Loss:0.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.12	Hits@10:40.53	Best:16.17
2025-01-06 12:46:10,918: Early Stopping! Snapshot: 0 Epoch: 32 Best Results: 16.17
2025-01-06 12:46:10,918: Start to training tokens! Snapshot: 0 Epoch: 32 Loss:0.028 MRR:16.1 Best Results: 16.17
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:46:10,919: Snapshot:0	Epoch:32	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.1	Hits@10:40.55	Best:16.17
2025-01-06 12:46:18,155: Snapshot:0	Epoch:33	Loss:17.364	translation_Loss:5.553	token_training_loss:11.811	distillation_Loss:0.0                                                   	MRR:16.1	Hits@10:40.55	Best:16.17
2025-01-06 12:46:25,056: End of token training: 0 Epoch: 34 Loss:5.928 MRR:16.1 Best Results: 16.17
2025-01-06 12:46:25,056: Snapshot:0	Epoch:34	Loss:5.928	translation_Loss:5.549	token_training_loss:0.38	distillation_Loss:0.0                                                           	MRR:16.1	Hits@10:40.55	Best:16.17
2025-01-06 12:46:25,148: => loading checkpoint './checkpoint/WN_CKGE/0model_best.tar'
2025-01-06 12:46:28,522: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1639 | 0.0069 | 0.2929 | 0.3547 |  0.4083 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:46:31,820: Snapshot:1	Epoch:0	Loss:2.723	translation_Loss:2.648	token_training_loss:0.0	distillation_Loss:0.075                                                   	MRR:2.52	Hits@10:6.59	Best:2.52
2025-01-06 12:46:33,334: Snapshot:1	Epoch:1	Loss:1.755	translation_Loss:1.612	token_training_loss:0.0	distillation_Loss:0.142                                                   	MRR:7.51	Hits@10:19.7	Best:7.51
2025-01-06 12:46:34,743: Snapshot:1	Epoch:2	Loss:0.976	translation_Loss:0.8	token_training_loss:0.0	distillation_Loss:0.176                                                   	MRR:10.75	Hits@10:27.18	Best:10.75
2025-01-06 12:46:36,216: Snapshot:1	Epoch:3	Loss:0.527	translation_Loss:0.305	token_training_loss:0.0	distillation_Loss:0.222                                                   	MRR:12.55	Hits@10:30.11	Best:12.55
2025-01-06 12:46:37,680: Snapshot:1	Epoch:4	Loss:0.367	translation_Loss:0.115	token_training_loss:0.0	distillation_Loss:0.252                                                   	MRR:13.35	Hits@10:31.72	Best:13.35
2025-01-06 12:46:39,039: Snapshot:1	Epoch:5	Loss:0.3	translation_Loss:0.049	token_training_loss:0.0	distillation_Loss:0.252                                                   	MRR:13.75	Hits@10:32.63	Best:13.75
2025-01-06 12:46:40,429: Snapshot:1	Epoch:6	Loss:0.251	translation_Loss:0.024	token_training_loss:0.0	distillation_Loss:0.227                                                   	MRR:13.87	Hits@10:33.01	Best:13.87
2025-01-06 12:46:42,054: Snapshot:1	Epoch:7	Loss:0.208	translation_Loss:0.016	token_training_loss:0.0	distillation_Loss:0.192                                                   	MRR:13.89	Hits@10:33.15	Best:13.89
2025-01-06 12:46:43,394: Snapshot:1	Epoch:8	Loss:0.168	translation_Loss:0.013	token_training_loss:0.0	distillation_Loss:0.155                                                   	MRR:13.82	Hits@10:33.17	Best:13.89
2025-01-06 12:46:44,679: Snapshot:1	Epoch:9	Loss:0.134	translation_Loss:0.013	token_training_loss:0.0	distillation_Loss:0.121                                                   	MRR:13.73	Hits@10:33.12	Best:13.89
2025-01-06 12:46:45,937: Early Stopping! Snapshot: 1 Epoch: 10 Best Results: 13.89
2025-01-06 12:46:45,937: Start to training tokens! Snapshot: 1 Epoch: 10 Loss:0.108 MRR:13.73 Best Results: 13.89
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:46:45,938: Snapshot:1	Epoch:10	Loss:0.108	translation_Loss:0.013	token_training_loss:0.0	distillation_Loss:0.095                                                   	MRR:13.73	Hits@10:33.17	Best:13.89
2025-01-06 12:46:47,317: Snapshot:1	Epoch:11	Loss:8.055	translation_Loss:1.189	token_training_loss:6.867	distillation_Loss:0.0                                                   	MRR:13.73	Hits@10:33.17	Best:13.89
2025-01-06 12:46:48,685: End of token training: 1 Epoch: 12 Loss:4.707 MRR:13.73 Best Results: 13.89
2025-01-06 12:46:48,685: Snapshot:1	Epoch:12	Loss:4.707	translation_Loss:1.19	token_training_loss:3.517	distillation_Loss:0.0                                                           	MRR:13.73	Hits@10:33.17	Best:13.89
2025-01-06 12:46:48,761: => loading checkpoint './checkpoint/WN_CKGE/1model_best.tar'
2025-01-06 12:46:52,734: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1646 | 0.008  | 0.2916 | 0.3575 |  0.415  |
|     1      | 0.1398 | 0.0067 | 0.2532 | 0.2882 |  0.3331 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:46:56,257: Snapshot:2	Epoch:0	Loss:2.621	translation_Loss:2.598	token_training_loss:0.0	distillation_Loss:0.024                                                   	MRR:2.87	Hits@10:7.63	Best:2.87
2025-01-06 12:46:57,736: Snapshot:2	Epoch:1	Loss:1.599	translation_Loss:1.517	token_training_loss:0.0	distillation_Loss:0.082                                                   	MRR:7.93	Hits@10:20.13	Best:7.93
2025-01-06 12:46:59,250: Snapshot:2	Epoch:2	Loss:0.799	translation_Loss:0.678	token_training_loss:0.0	distillation_Loss:0.121                                                   	MRR:10.88	Hits@10:25.91	Best:10.88
2025-01-06 12:47:00,796: Snapshot:2	Epoch:3	Loss:0.354	translation_Loss:0.217	token_training_loss:0.0	distillation_Loss:0.137                                                   	MRR:12.39	Hits@10:28.25	Best:12.39
2025-01-06 12:47:02,313: Snapshot:2	Epoch:4	Loss:0.215	translation_Loss:0.074	token_training_loss:0.0	distillation_Loss:0.141                                                   	MRR:13.11	Hits@10:29.25	Best:13.11
2025-01-06 12:47:03,876: Snapshot:2	Epoch:5	Loss:0.166	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.136                                                   	MRR:13.48	Hits@10:30.24	Best:13.48
2025-01-06 12:47:05,379: Snapshot:2	Epoch:6	Loss:0.143	translation_Loss:0.017	token_training_loss:0.0	distillation_Loss:0.126                                                   	MRR:13.57	Hits@10:30.89	Best:13.57
2025-01-06 12:47:06,862: Snapshot:2	Epoch:7	Loss:0.127	translation_Loss:0.012	token_training_loss:0.0	distillation_Loss:0.115                                                   	MRR:13.7	Hits@10:31.16	Best:13.7
2025-01-06 12:47:08,370: Snapshot:2	Epoch:8	Loss:0.113	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.105                                                   	MRR:13.79	Hits@10:31.18	Best:13.79
2025-01-06 12:47:09,864: Snapshot:2	Epoch:9	Loss:0.101	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.095                                                   	MRR:13.84	Hits@10:31.32	Best:13.84
2025-01-06 12:47:11,584: Snapshot:2	Epoch:10	Loss:0.09	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.086                                                   	MRR:13.86	Hits@10:31.42	Best:13.86
2025-01-06 12:47:12,965: Snapshot:2	Epoch:11	Loss:0.081	translation_Loss:0.004	token_training_loss:0.0	distillation_Loss:0.077                                                   	MRR:13.8	Hits@10:31.51	Best:13.86
2025-01-06 12:47:14,399: Snapshot:2	Epoch:12	Loss:0.071	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.068                                                   	MRR:13.74	Hits@10:31.59	Best:13.86
2025-01-06 12:47:15,811: Early Stopping! Snapshot: 2 Epoch: 13 Best Results: 13.86
2025-01-06 12:47:15,811: Start to training tokens! Snapshot: 2 Epoch: 13 Loss:0.063 MRR:13.68 Best Results: 13.86
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:47:15,811: Snapshot:2	Epoch:13	Loss:0.063	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.061                                                   	MRR:13.68	Hits@10:31.56	Best:13.86
2025-01-06 12:47:17,298: Snapshot:2	Epoch:14	Loss:7.757	translation_Loss:1.132	token_training_loss:6.625	distillation_Loss:0.0                                                   	MRR:13.68	Hits@10:31.56	Best:13.86
2025-01-06 12:47:18,686: End of token training: 2 Epoch: 15 Loss:4.458 MRR:13.68 Best Results: 13.86
2025-01-06 12:47:18,686: Snapshot:2	Epoch:15	Loss:4.458	translation_Loss:1.133	token_training_loss:3.325	distillation_Loss:0.0                                                           	MRR:13.68	Hits@10:31.56	Best:13.86
2025-01-06 12:47:18,763: => loading checkpoint './checkpoint/WN_CKGE/2model_best.tar'
2025-01-06 12:47:23,548: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1599 | 0.0074 | 0.2791 | 0.3491 |  0.413  |
|     1      | 0.1356 | 0.0073 | 0.2398 | 0.2849 |  0.3306 |
|     2      | 0.1404 | 0.0078 | 0.2519 | 0.2849 |  0.3258 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:47:27,171: Snapshot:3	Epoch:0	Loss:2.601	translation_Loss:2.559	token_training_loss:0.0	distillation_Loss:0.042                                                   	MRR:3.03	Hits@10:7.34	Best:3.03
2025-01-06 12:47:28,726: Snapshot:3	Epoch:1	Loss:1.57	translation_Loss:1.445	token_training_loss:0.0	distillation_Loss:0.125                                                   	MRR:7.63	Hits@10:19.17	Best:7.63
2025-01-06 12:47:30,310: Snapshot:3	Epoch:2	Loss:0.779	translation_Loss:0.616	token_training_loss:0.0	distillation_Loss:0.163                                                   	MRR:10.73	Hits@10:25.05	Best:10.73
2025-01-06 12:47:31,978: Snapshot:3	Epoch:3	Loss:0.362	translation_Loss:0.187	token_training_loss:0.0	distillation_Loss:0.175                                                   	MRR:12.2	Hits@10:27.34	Best:12.2
2025-01-06 12:47:33,536: Snapshot:3	Epoch:4	Loss:0.245	translation_Loss:0.067	token_training_loss:0.0	distillation_Loss:0.177                                                   	MRR:12.91	Hits@10:28.68	Best:12.91
2025-01-06 12:47:35,171: Snapshot:3	Epoch:5	Loss:0.204	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:13.2	Hits@10:29.27	Best:13.2
2025-01-06 12:47:36,970: Snapshot:3	Epoch:6	Loss:0.182	translation_Loss:0.021	token_training_loss:0.0	distillation_Loss:0.161                                                   	MRR:13.31	Hits@10:29.57	Best:13.31
2025-01-06 12:47:38,581: Snapshot:3	Epoch:7	Loss:0.16	translation_Loss:0.013	token_training_loss:0.0	distillation_Loss:0.147                                                   	MRR:13.37	Hits@10:29.7	Best:13.37
2025-01-06 12:47:40,041: Snapshot:3	Epoch:8	Loss:0.14	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.131                                                   	MRR:13.37	Hits@10:29.95	Best:13.37
2025-01-06 12:47:41,716: Snapshot:3	Epoch:9	Loss:0.122	translation_Loss:0.007	token_training_loss:0.0	distillation_Loss:0.114                                                   	MRR:13.41	Hits@10:30.3	Best:13.41
2025-01-06 12:47:43,301: Snapshot:3	Epoch:10	Loss:0.104	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.098                                                   	MRR:13.48	Hits@10:30.38	Best:13.48
2025-01-06 12:47:44,875: Snapshot:3	Epoch:11	Loss:0.089	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.083                                                   	MRR:13.52	Hits@10:30.56	Best:13.52
2025-01-06 12:47:46,480: Snapshot:3	Epoch:12	Loss:0.076	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.07                                                   	MRR:13.54	Hits@10:30.62	Best:13.54
2025-01-06 12:47:48,003: Snapshot:3	Epoch:13	Loss:0.065	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:13.49	Hits@10:30.75	Best:13.54
2025-01-06 12:47:49,517: Snapshot:3	Epoch:14	Loss:0.057	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.052                                                   	MRR:13.48	Hits@10:30.91	Best:13.54
2025-01-06 12:47:50,971: Early Stopping! Snapshot: 3 Epoch: 15 Best Results: 13.54
2025-01-06 12:47:50,971: Start to training tokens! Snapshot: 3 Epoch: 15 Loss:0.05 MRR:13.52 Best Results: 13.54
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:47:50,972: Snapshot:3	Epoch:15	Loss:0.05	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.045                                                   	MRR:13.52	Hits@10:30.86	Best:13.54
2025-01-06 12:47:52,478: Snapshot:3	Epoch:16	Loss:7.694	translation_Loss:1.137	token_training_loss:6.557	distillation_Loss:0.0                                                   	MRR:13.52	Hits@10:30.86	Best:13.54
2025-01-06 12:47:53,880: End of token training: 3 Epoch: 17 Loss:4.324 MRR:13.52 Best Results: 13.54
2025-01-06 12:47:53,880: Snapshot:3	Epoch:17	Loss:4.324	translation_Loss:1.138	token_training_loss:3.186	distillation_Loss:0.0                                                           	MRR:13.52	Hits@10:30.86	Best:13.54
2025-01-06 12:47:54,005: => loading checkpoint './checkpoint/WN_CKGE/3model_best.tar'
2025-01-06 12:47:59,774: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1582 | 0.0073 | 0.2749 | 0.3481 |  0.4091 |
|     1      | 0.1331 | 0.0059 | 0.2355 | 0.2809 |  0.3261 |
|     2      | 0.1373 | 0.007  | 0.247  | 0.2849 |  0.3237 |
|     3      | 0.137  | 0.0078 | 0.2441 | 0.2849 |  0.3207 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:48:03,611: Snapshot:4	Epoch:0	Loss:2.567	translation_Loss:2.495	token_training_loss:0.0	distillation_Loss:0.072                                                   	MRR:10.11	Hits@10:24.41	Best:10.11
2025-01-06 12:48:05,328: Snapshot:4	Epoch:1	Loss:1.548	translation_Loss:1.375	token_training_loss:0.0	distillation_Loss:0.172                                                   	MRR:11.72	Hits@10:28.17	Best:11.72
2025-01-06 12:48:07,007: Snapshot:4	Epoch:2	Loss:0.755	translation_Loss:0.557	token_training_loss:0.0	distillation_Loss:0.198                                                   	MRR:12.93	Hits@10:30.51	Best:12.93
2025-01-06 12:48:08,816: Snapshot:4	Epoch:3	Loss:0.374	translation_Loss:0.161	token_training_loss:0.0	distillation_Loss:0.212                                                   	MRR:13.53	Hits@10:31.26	Best:13.53
2025-01-06 12:48:10,733: Snapshot:4	Epoch:4	Loss:0.282	translation_Loss:0.062	token_training_loss:0.0	distillation_Loss:0.221                                                   	MRR:13.82	Hits@10:31.61	Best:13.82
2025-01-06 12:48:12,441: Snapshot:4	Epoch:5	Loss:0.243	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.212                                                   	MRR:13.97	Hits@10:31.91	Best:13.97
2025-01-06 12:48:14,129: Snapshot:4	Epoch:6	Loss:0.211	translation_Loss:0.02	token_training_loss:0.0	distillation_Loss:0.19                                                   	MRR:14.06	Hits@10:32.07	Best:14.06
2025-01-06 12:48:15,772: Snapshot:4	Epoch:7	Loss:0.179	translation_Loss:0.014	token_training_loss:0.0	distillation_Loss:0.164                                                   	MRR:14.01	Hits@10:32.37	Best:14.06
2025-01-06 12:48:17,419: Snapshot:4	Epoch:8	Loss:0.15	translation_Loss:0.012	token_training_loss:0.0	distillation_Loss:0.138                                                   	MRR:13.89	Hits@10:32.45	Best:14.06
2025-01-06 12:48:19,036: Early Stopping! Snapshot: 4 Epoch: 9 Best Results: 14.06
2025-01-06 12:48:19,037: Start to training tokens! Snapshot: 4 Epoch: 9 Loss:0.121 MRR:13.87 Best Results: 14.06
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:48:19,037: Snapshot:4	Epoch:9	Loss:0.121	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.112                                                   	MRR:13.87	Hits@10:32.5	Best:14.06
2025-01-06 12:48:20,679: Snapshot:4	Epoch:10	Loss:7.736	translation_Loss:1.157	token_training_loss:6.58	distillation_Loss:0.0                                                   	MRR:13.87	Hits@10:32.5	Best:14.06
2025-01-06 12:48:22,218: End of token training: 4 Epoch: 11 Loss:4.437 MRR:13.87 Best Results: 14.06
2025-01-06 12:48:22,218: Snapshot:4	Epoch:11	Loss:4.437	translation_Loss:1.153	token_training_loss:3.284	distillation_Loss:0.0                                                           	MRR:13.87	Hits@10:32.5	Best:14.06
2025-01-06 12:48:22,309: => loading checkpoint './checkpoint/WN_CKGE/4model_best.tar'
2025-01-06 12:48:29,174: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1559 | 0.0074 | 0.2706 | 0.3412 |  0.4043 |
|     1      | 0.1295 | 0.0065 | 0.2261 | 0.2715 |  0.3164 |
|     2      | 0.1362 | 0.0078 | 0.2444 | 0.2804 |  0.3194 |
|     3      | 0.1373 | 0.0099 | 0.2414 | 0.2828 |  0.3218 |
|     4      | 0.133  | 0.0081 |  0.23  | 0.2875 |  0.3267 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 12:48:29,176: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1639 | 0.0069 | 0.2929 | 0.3547 |  0.4083 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1646 | 0.008  | 0.2916 | 0.3575 |  0.415  |
|     1      | 0.1398 | 0.0067 | 0.2532 | 0.2882 |  0.3331 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1599 | 0.0074 | 0.2791 | 0.3491 |  0.413  |
|     1      | 0.1356 | 0.0073 | 0.2398 | 0.2849 |  0.3306 |
|     2      | 0.1404 | 0.0078 | 0.2519 | 0.2849 |  0.3258 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1582 | 0.0073 | 0.2749 | 0.3481 |  0.4091 |
|     1      | 0.1331 | 0.0059 | 0.2355 | 0.2809 |  0.3261 |
|     2      | 0.1373 | 0.007  | 0.247  | 0.2849 |  0.3237 |
|     3      | 0.137  | 0.0078 | 0.2441 | 0.2849 |  0.3207 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1559 | 0.0074 | 0.2706 | 0.3412 |  0.4043 |
|     1      | 0.1295 | 0.0065 | 0.2261 | 0.2715 |  0.3164 |
|     2      | 0.1362 | 0.0078 | 0.2444 | 0.2804 |  0.3194 |
|     3      | 0.1373 | 0.0099 | 0.2414 | 0.2828 |  0.3218 |
|     4      | 0.133  | 0.0081 |  0.23  | 0.2875 |  0.3267 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 12:48:29,177: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 240.6048891544342  |   0.164   |    0.007     |    0.293     |     0.408     |
|    1     | 19.268535137176514 |   0.161   |    0.008     |    0.286     |     0.403     |
|    2     | 25.161583423614502 |   0.154   |    0.007     |    0.271     |     0.392     |
|    3     |  29.3131422996521  |   0.151   |    0.007     |    0.264     |     0.381     |
|    4     | 21.328745365142822 |   0.147   |    0.008     |    0.257     |     0.371     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 12:48:29,177: Sum_Training_Time:335.67689538002014
2025-01-06 12:48:29,177: Every_Training_Time:[240.6048891544342, 19.268535137176514, 25.161583423614502, 29.3131422996521, 21.328745365142822]
2025-01-06 12:48:29,177: Forward transfer: 0.059275 Backward transfer: -0.005549999999999999
