[lijing@p0316 IncDE]$ python main.py -dataset FB_CKGE -lifelong_name double_tokened -using_token_distillation_loss True -use_multi_layers False -without_multi_layers True -use_two_stage False -batch_size 3072 -learning_rate 0.001 -patience 3 -multi_layer_weight 1 -token_distillation_weight 10000 3000 1000 20000 -token_num 5
/users/PCS0256/lijing/.local/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
2025-01-05 20:56:21,022: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FB_CKGE/', dataset='FB_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250105205602/FB_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FB_CKGE', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 3000.0, 1000.0, 20000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-05 20:56:42,471: Snapshot:0	Epoch:0	Loss:43.8	translation_Loss:43.8	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.2	Hits@10:34.63	Best:15.2
2025-01-05 20:56:59,606: Snapshot:0	Epoch:1	Loss:18.582	translation_Loss:18.582	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.8	Hits@10:45.21	Best:23.8
2025-01-05 20:57:16,694: Snapshot:0	Epoch:2	Loss:7.139	translation_Loss:7.139	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.47	Hits@10:46.78	Best:25.47
2025-01-05 20:57:33,721: Snapshot:0	Epoch:3	Loss:3.625	translation_Loss:3.625	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:47.01	Best:25.79
2025-01-05 20:57:51,247: Snapshot:0	Epoch:4	Loss:2.337	translation_Loss:2.337	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.72	Hits@10:46.52	Best:25.79
2025-01-05 20:58:08,227: Snapshot:0	Epoch:5	Loss:1.744	translation_Loss:1.744	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.54	Hits@10:46.41	Best:25.79
2025-01-05 20:58:25,209: Early Stopping! Snapshot: 0 Epoch: 6 Best Results: 25.79
2025-01-05 20:58:25,209: Start to training tokens! Snapshot: 0 Epoch: 6 Loss:1.416 MRR:25.45 Best Results: 25.79
Token added to optimizer, embeddings excluded successfully.
2025-01-05 20:58:25,210: Snapshot:0	Epoch:6	Loss:1.416	translation_Loss:1.416	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.45	Hits@10:46.24	Best:25.79
2025-01-05 20:58:42,718: Snapshot:0	Epoch:7	Loss:51.537	translation_Loss:36.122	token_training_loss:15.415	distillation_Loss:0.0                                                   	MRR:25.45	Hits@10:46.24	Best:25.79
2025-01-05 20:58:59,887: End of token training: 0 Epoch: 8 Loss:36.133 MRR:25.45 Best Results: 25.79
2025-01-05 20:58:59,887: Snapshot:0	Epoch:8	Loss:36.133	translation_Loss:36.13	token_training_loss:0.003	distillation_Loss:0.0                                                           	MRR:25.45	Hits@10:46.24	Best:25.79
2025-01-05 20:59:00,211: => loading checkpoint './checkpoint/FB_CKGE/0model_best.tar'
2025-01-05 20:59:06,058: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2576 | 0.1501 | 0.3029 | 0.3755 |  0.4682 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 20:59:15,302: Snapshot:1	Epoch:0	Loss:6.524	translation_Loss:6.209	token_training_loss:0.0	distillation_Loss:0.315                                                   	MRR:10.22	Hits@10:19.67	Best:10.22
2025-01-05 20:59:18,380: Snapshot:1	Epoch:1	Loss:3.358	translation_Loss:2.987	token_training_loss:0.0	distillation_Loss:0.371                                                   	MRR:13.01	Hits@10:24.04	Best:13.01
2025-01-05 20:59:21,844: Snapshot:1	Epoch:2	Loss:1.758	translation_Loss:1.473	token_training_loss:0.0	distillation_Loss:0.285                                                   	MRR:14.74	Hits@10:27.16	Best:14.74
2025-01-05 20:59:25,004: Snapshot:1	Epoch:3	Loss:1.04	translation_Loss:0.843	token_training_loss:0.0	distillation_Loss:0.197                                                   	MRR:15.74	Hits@10:29.32	Best:15.74
2025-01-05 20:59:28,107: Snapshot:1	Epoch:4	Loss:0.719	translation_Loss:0.582	token_training_loss:0.0	distillation_Loss:0.137                                                   	MRR:16.48	Hits@10:30.84	Best:16.48
2025-01-05 20:59:31,208: Snapshot:1	Epoch:5	Loss:0.553	translation_Loss:0.446	token_training_loss:0.0	distillation_Loss:0.106                                                   	MRR:17.0	Hits@10:31.83	Best:17.0
2025-01-05 20:59:34,287: Snapshot:1	Epoch:6	Loss:0.461	translation_Loss:0.369	token_training_loss:0.0	distillation_Loss:0.092                                                   	MRR:17.23	Hits@10:32.43	Best:17.23
2025-01-05 20:59:37,775: Snapshot:1	Epoch:7	Loss:0.405	translation_Loss:0.322	token_training_loss:0.0	distillation_Loss:0.083                                                   	MRR:17.32	Hits@10:32.88	Best:17.32
2025-01-05 20:59:40,888: Snapshot:1	Epoch:8	Loss:0.378	translation_Loss:0.298	token_training_loss:0.0	distillation_Loss:0.08                                                   	MRR:17.64	Hits@10:33.19	Best:17.64
2025-01-05 20:59:43,964: Snapshot:1	Epoch:9	Loss:0.352	translation_Loss:0.275	token_training_loss:0.0	distillation_Loss:0.077                                                   	MRR:17.8	Hits@10:33.29	Best:17.8
2025-01-05 20:59:47,065: Snapshot:1	Epoch:10	Loss:0.326	translation_Loss:0.251	token_training_loss:0.0	distillation_Loss:0.075                                                   	MRR:17.77	Hits@10:33.59	Best:17.8
2025-01-05 20:59:50,162: Snapshot:1	Epoch:11	Loss:0.311	translation_Loss:0.239	token_training_loss:0.0	distillation_Loss:0.072                                                   	MRR:17.86	Hits@10:33.75	Best:17.86
2025-01-05 20:59:53,574: Snapshot:1	Epoch:12	Loss:0.292	translation_Loss:0.222	token_training_loss:0.0	distillation_Loss:0.07                                                   	MRR:17.72	Hits@10:33.59	Best:17.86
2025-01-05 20:59:56,626: Snapshot:1	Epoch:13	Loss:0.287	translation_Loss:0.218	token_training_loss:0.0	distillation_Loss:0.07                                                   	MRR:17.91	Hits@10:33.7	Best:17.91
2025-01-05 20:59:59,702: Snapshot:1	Epoch:14	Loss:0.281	translation_Loss:0.212	token_training_loss:0.0	distillation_Loss:0.069                                                   	MRR:17.83	Hits@10:33.8	Best:17.91
2025-01-05 21:00:02,829: Snapshot:1	Epoch:15	Loss:0.266	translation_Loss:0.197	token_training_loss:0.0	distillation_Loss:0.068                                                   	MRR:17.92	Hits@10:33.8	Best:17.92
2025-01-05 21:00:05,968: Snapshot:1	Epoch:16	Loss:0.261	translation_Loss:0.194	token_training_loss:0.0	distillation_Loss:0.067                                                   	MRR:17.92	Hits@10:33.94	Best:17.92
2025-01-05 21:00:09,641: Snapshot:1	Epoch:17	Loss:0.254	translation_Loss:0.186	token_training_loss:0.0	distillation_Loss:0.068                                                   	MRR:17.99	Hits@10:34.22	Best:17.99
2025-01-05 21:00:12,658: Snapshot:1	Epoch:18	Loss:0.247	translation_Loss:0.181	token_training_loss:0.0	distillation_Loss:0.066                                                   	MRR:17.99	Hits@10:34.15	Best:17.99
2025-01-05 21:00:15,714: Snapshot:1	Epoch:19	Loss:0.243	translation_Loss:0.179	token_training_loss:0.0	distillation_Loss:0.064                                                   	MRR:18.05	Hits@10:34.11	Best:18.05
2025-01-05 21:00:18,766: Snapshot:1	Epoch:20	Loss:0.237	translation_Loss:0.171	token_training_loss:0.0	distillation_Loss:0.065                                                   	MRR:18.05	Hits@10:34.29	Best:18.05
2025-01-05 21:00:21,808: Snapshot:1	Epoch:21	Loss:0.239	translation_Loss:0.173	token_training_loss:0.0	distillation_Loss:0.066                                                   	MRR:17.92	Hits@10:34.32	Best:18.05
2025-01-05 21:00:25,298: Early Stopping! Snapshot: 1 Epoch: 22 Best Results: 18.05
2025-01-05 21:00:25,298: Start to training tokens! Snapshot: 1 Epoch: 22 Loss:0.233 MRR:17.96 Best Results: 18.05
Token added to optimizer, embeddings excluded successfully.
2025-01-05 21:00:25,298: Snapshot:1	Epoch:22	Loss:0.233	translation_Loss:0.167	token_training_loss:0.0	distillation_Loss:0.066                                                   	MRR:17.96	Hits@10:34.14	Best:18.05
2025-01-05 21:00:28,327: Snapshot:1	Epoch:23	Loss:19.699	translation_Loss:6.172	token_training_loss:13.527	distillation_Loss:0.0                                                   	MRR:17.96	Hits@10:34.14	Best:18.05
2025-01-05 21:00:31,343: End of token training: 1 Epoch: 24 Loss:7.536 MRR:17.96 Best Results: 18.05
2025-01-05 21:00:31,343: Snapshot:1	Epoch:24	Loss:7.536	translation_Loss:6.173	token_training_loss:1.363	distillation_Loss:0.0                                                           	MRR:17.96	Hits@10:34.14	Best:18.05
2025-01-05 21:00:31,638: => loading checkpoint './checkpoint/FB_CKGE/1model_best.tar'
2025-01-05 21:00:38,939: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2555 | 0.1473 | 0.3015 | 0.3743 |  0.4658 |
|     1      | 0.1886 | 0.1101 | 0.2114 | 0.2655 |  0.3468 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 21:00:48,532: Snapshot:2	Epoch:0	Loss:4.308	translation_Loss:4.068	token_training_loss:0.0	distillation_Loss:0.24                                                   	MRR:18.23	Hits@10:33.17	Best:18.23
2025-01-05 21:00:51,743: Snapshot:2	Epoch:1	Loss:2.092	translation_Loss:1.679	token_training_loss:0.0	distillation_Loss:0.413                                                   	MRR:19.54	Hits@10:34.87	Best:19.54
2025-01-05 21:00:54,967: Snapshot:2	Epoch:2	Loss:1.22	translation_Loss:0.764	token_training_loss:0.0	distillation_Loss:0.456                                                   	MRR:20.06	Hits@10:35.75	Best:20.06
2025-01-05 21:00:58,211: Snapshot:2	Epoch:3	Loss:0.873	translation_Loss:0.481	token_training_loss:0.0	distillation_Loss:0.392                                                   	MRR:20.25	Hits@10:36.11	Best:20.25
2025-01-05 21:01:01,462: Snapshot:2	Epoch:4	Loss:0.724	translation_Loss:0.387	token_training_loss:0.0	distillation_Loss:0.336                                                   	MRR:20.34	Hits@10:36.43	Best:20.34
2025-01-05 21:01:05,205: Snapshot:2	Epoch:5	Loss:0.654	translation_Loss:0.347	token_training_loss:0.0	distillation_Loss:0.307                                                   	MRR:20.38	Hits@10:36.46	Best:20.38
2025-01-05 21:01:08,435: Snapshot:2	Epoch:6	Loss:0.613	translation_Loss:0.319	token_training_loss:0.0	distillation_Loss:0.294                                                   	MRR:20.43	Hits@10:36.6	Best:20.43
2025-01-05 21:01:11,604: Snapshot:2	Epoch:7	Loss:0.591	translation_Loss:0.305	token_training_loss:0.0	distillation_Loss:0.287                                                   	MRR:20.31	Hits@10:36.41	Best:20.43
2025-01-05 21:01:14,782: Snapshot:2	Epoch:8	Loss:0.575	translation_Loss:0.291	token_training_loss:0.0	distillation_Loss:0.284                                                   	MRR:20.15	Hits@10:36.18	Best:20.43
2025-01-05 21:01:18,064: Early Stopping! Snapshot: 2 Epoch: 9 Best Results: 20.43
2025-01-05 21:01:18,065: Start to training tokens! Snapshot: 2 Epoch: 9 Loss:0.565 MRR:20.18 Best Results: 20.43
Token added to optimizer, embeddings excluded successfully.
2025-01-05 21:01:18,065: Snapshot:2	Epoch:9	Loss:0.565	translation_Loss:0.283	token_training_loss:0.0	distillation_Loss:0.282                                                   	MRR:20.18	Hits@10:36.41	Best:20.43
2025-01-05 21:01:21,674: Snapshot:2	Epoch:10	Loss:20.327	translation_Loss:6.211	token_training_loss:14.116	distillation_Loss:0.0                                                   	MRR:20.18	Hits@10:36.41	Best:20.43
2025-01-05 21:01:24,815: End of token training: 2 Epoch: 11 Loss:7.687 MRR:20.18 Best Results: 20.43
2025-01-05 21:01:24,815: Snapshot:2	Epoch:11	Loss:7.687	translation_Loss:6.199	token_training_loss:1.488	distillation_Loss:0.0                                                           	MRR:20.18	Hits@10:36.41	Best:20.43
2025-01-05 21:01:25,108: => loading checkpoint './checkpoint/FB_CKGE/2model_best.tar'
2025-01-05 21:01:34,124: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2485 | 0.1424 | 0.2929 | 0.3639 |  0.455  |
|     1      | 0.1937 | 0.1112 | 0.2193 | 0.2745 |  0.3601 |
|     2      | 0.205  | 0.1225 | 0.2355 | 0.2918 |  0.3659 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 21:01:43,442: Snapshot:3	Epoch:0	Loss:2.653	translation_Loss:2.524	token_training_loss:0.0	distillation_Loss:0.13                                                   	MRR:21.05	Hits@10:37.31	Best:21.05
2025-01-05 21:01:47,148: Snapshot:3	Epoch:1	Loss:1.265	translation_Loss:1.009	token_training_loss:0.0	distillation_Loss:0.257                                                   	MRR:21.5	Hits@10:37.66	Best:21.5
2025-01-05 21:01:50,478: Snapshot:3	Epoch:2	Loss:0.725	translation_Loss:0.424	token_training_loss:0.0	distillation_Loss:0.302                                                   	MRR:21.6	Hits@10:37.96	Best:21.6
2025-01-05 21:01:53,790: Snapshot:3	Epoch:3	Loss:0.536	translation_Loss:0.239	token_training_loss:0.0	distillation_Loss:0.297                                                   	MRR:21.89	Hits@10:38.27	Best:21.89
2025-01-05 21:01:57,164: Snapshot:3	Epoch:4	Loss:0.452	translation_Loss:0.179	token_training_loss:0.0	distillation_Loss:0.272                                                   	MRR:21.94	Hits@10:38.31	Best:21.94
2025-01-05 21:02:00,418: Snapshot:3	Epoch:5	Loss:0.412	translation_Loss:0.16	token_training_loss:0.0	distillation_Loss:0.252                                                   	MRR:21.89	Hits@10:38.59	Best:21.94
2025-01-05 21:02:04,099: Snapshot:3	Epoch:6	Loss:0.399	translation_Loss:0.156	token_training_loss:0.0	distillation_Loss:0.243                                                   	MRR:22.13	Hits@10:38.51	Best:22.13
2025-01-05 21:02:07,396: Snapshot:3	Epoch:7	Loss:0.389	translation_Loss:0.146	token_training_loss:0.0	distillation_Loss:0.244                                                   	MRR:21.89	Hits@10:38.26	Best:22.13
2025-01-05 21:02:10,639: Snapshot:3	Epoch:8	Loss:0.386	translation_Loss:0.144	token_training_loss:0.0	distillation_Loss:0.243                                                   	MRR:21.59	Hits@10:38.32	Best:22.13
2025-01-05 21:02:13,872: Early Stopping! Snapshot: 3 Epoch: 9 Best Results: 22.13
2025-01-05 21:02:13,872: Start to training tokens! Snapshot: 3 Epoch: 9 Loss:0.383 MRR:21.85 Best Results: 22.13
Token added to optimizer, embeddings excluded successfully.
2025-01-05 21:02:13,873: Snapshot:3	Epoch:9	Loss:0.383	translation_Loss:0.14	token_training_loss:0.0	distillation_Loss:0.243                                                   	MRR:21.85	Hits@10:38.41	Best:22.13
2025-01-05 21:02:17,119: Snapshot:3	Epoch:10	Loss:18.912	translation_Loss:5.989	token_training_loss:12.922	distillation_Loss:0.0                                                   	MRR:21.85	Hits@10:38.41	Best:22.13
2025-01-05 21:02:20,818: End of token training: 3 Epoch: 11 Loss:7.189 MRR:21.85 Best Results: 22.13
2025-01-05 21:02:20,818: Snapshot:3	Epoch:11	Loss:7.189	translation_Loss:5.993	token_training_loss:1.196	distillation_Loss:0.0                                                           	MRR:21.85	Hits@10:38.41	Best:22.13
2025-01-05 21:02:21,055: => loading checkpoint './checkpoint/FB_CKGE/3model_best.tar'
2025-01-05 21:02:31,924: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2333 | 0.1313 | 0.2711 | 0.3415 |  0.4323 |
|     1      | 0.195  | 0.1079 | 0.2226 | 0.2826 |  0.3693 |
|     2      | 0.2023 | 0.117  | 0.2322 | 0.2911 |  0.369  |
|     3      | 0.2191 | 0.132  | 0.2539 | 0.3098 |  0.3855 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 21:02:41,360: Snapshot:4	Epoch:0	Loss:1.913	translation_Loss:1.46	token_training_loss:0.0	distillation_Loss:0.454                                                   	MRR:23.86	Hits@10:40.0	Best:23.86
2025-01-05 21:02:44,656: Snapshot:4	Epoch:1	Loss:1.384	translation_Loss:0.894	token_training_loss:0.0	distillation_Loss:0.49                                                   	MRR:23.56	Hits@10:39.68	Best:23.86
2025-01-05 21:02:47,985: Snapshot:4	Epoch:2	Loss:1.305	translation_Loss:0.93	token_training_loss:0.0	distillation_Loss:0.375                                                   	MRR:23.71	Hits@10:39.88	Best:23.86
2025-01-05 21:02:51,707: Early Stopping! Snapshot: 4 Epoch: 3 Best Results: 23.86
2025-01-05 21:02:51,707: Start to training tokens! Snapshot: 4 Epoch: 3 Loss:1.162 MRR:23.7 Best Results: 23.86
Token added to optimizer, embeddings excluded successfully.
2025-01-05 21:02:51,708: Snapshot:4	Epoch:3	Loss:1.162	translation_Loss:0.793	token_training_loss:0.0	distillation_Loss:0.369                                                   	MRR:23.7	Hits@10:39.83	Best:23.86
2025-01-05 21:02:54,954: Snapshot:4	Epoch:4	Loss:20.036	translation_Loss:6.555	token_training_loss:13.481	distillation_Loss:0.0                                                   	MRR:23.7	Hits@10:39.83	Best:23.86
2025-01-05 21:02:58,250: End of token training: 4 Epoch: 5 Loss:7.936 MRR:23.7 Best Results: 23.86
2025-01-05 21:02:58,250: Snapshot:4	Epoch:5	Loss:7.936	translation_Loss:6.56	token_training_loss:1.376	distillation_Loss:0.0                                                           	MRR:23.7	Hits@10:39.83	Best:23.86
2025-01-05 21:02:58,482: => loading checkpoint './checkpoint/FB_CKGE/4model_best.tar'
2025-01-05 21:03:11,370: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2347 | 0.1316 | 0.274  | 0.3449 |  0.4344 |
|     1      | 0.2011 | 0.1111 | 0.2287 | 0.2925 |  0.3805 |
|     2      | 0.2086 | 0.1231 | 0.2371 | 0.2969 |  0.3783 |
|     3      | 0.2229 | 0.133  | 0.2571 | 0.3173 |  0.3962 |
|     4      | 0.2234 | 0.1331 | 0.2577 | 0.3183 |  0.3987 |
+------------+--------+--------+--------+--------+---------+
2025-01-05 21:03:11,372: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2576 | 0.1501 | 0.3029 | 0.3755 |  0.4682 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2555 | 0.1473 | 0.3015 | 0.3743 |  0.4658 |
|     1      | 0.1886 | 0.1101 | 0.2114 | 0.2655 |  0.3468 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2485 | 0.1424 | 0.2929 | 0.3639 |  0.455  |
|     1      | 0.1937 | 0.1112 | 0.2193 | 0.2745 |  0.3601 |
|     2      | 0.205  | 0.1225 | 0.2355 | 0.2918 |  0.3659 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2333 | 0.1313 | 0.2711 | 0.3415 |  0.4323 |
|     1      | 0.195  | 0.1079 | 0.2226 | 0.2826 |  0.3693 |
|     2      | 0.2023 | 0.117  | 0.2322 | 0.2911 |  0.369  |
|     3      | 0.2191 | 0.132  | 0.2539 | 0.3098 |  0.3855 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2347 | 0.1316 | 0.274  | 0.3449 |  0.4344 |
|     1      | 0.2011 | 0.1111 | 0.2287 | 0.2925 |  0.3805 |
|     2      | 0.2086 | 0.1231 | 0.2371 | 0.2969 |  0.3783 |
|     3      | 0.2229 | 0.133  | 0.2571 | 0.3173 |  0.3962 |
|     4      | 0.2234 | 0.1331 | 0.2577 | 0.3183 |  0.3987 |
+------------+--------+--------+--------+--------+---------+]
2025-01-05 21:03:11,374: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 158.86502647399902 |   0.258   |     0.15     |    0.303     |     0.468     |
|    1     | 83.36604714393616  |   0.246   |    0.142     |    0.289     |     0.449     |
|    2     | 44.15554928779602  |   0.236   |    0.136     |    0.277     |     0.432     |
|    3     | 44.88583731651306  |   0.224   |    0.127     |    0.259     |     0.413     |
|    4     | 24.46010732650757  |   0.226   |    0.129     |    0.262     |     0.416     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-05 21:03:11,374: Sum_Training_Time:355.73256754875183
2025-01-05 21:03:11,374: Every_Training_Time:[158.86502647399902, 83.36604714393616, 44.15554928779602, 44.88583731651306, 24.46010732650757]
2025-01-05 21:03:11,374: Forward transfer: 0.161075 Backward transfer: -0.0007499999999999937
2025-01-06 12:02:18,991: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FB_CKGE/', dataset='FB_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106120156/FB_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FB_CKGE', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 10000.0, 10000.0, 20000.0], token_num=3, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 12:02:40,808: Snapshot:0 Epoch:0 Loss:43.8 translation_Loss:43.8 token_training_loss:0.0 distillation_Loss:0.0                                                     MRR:15.19 Hits@10:34.62 Best:15.19
2025-01-06 12:02:58,087: Snapshot:0 Epoch:1 Loss:18.581 translation_Loss:18.581 token_training_loss:0.0 distillation_Loss:0.0                                                     MRR:23.78 Hits@10:45.2  Best:23.78
2025-01-06 12:03:15,370: Snapshot:0 Epoch:2 Loss:7.139  translation_Loss:7.139  token_training_loss:0.0 distillation_Loss:0.0                                                     MRR:25.57 Hits@10:46.9  Best:25.57
2025-01-06 12:03:32,535: Snapshot:0 Epoch:3 Loss:3.626  translation_Loss:3.626  token_training_loss:0.0 distillation_Loss:0.0                                                     MRR:25.86 Hits@10:47.08 Best:25.86
2025-01-06 12:03:50,017: Snapshot:0 Epoch:4 Loss:2.338  translation_Loss:2.338  token_training_loss:0.0 distillation_Loss:0.0                                                     MRR:25.74 Hits@10:46.63 Best:25.86
2025-01-06 12:04:07,112: Snapshot:0 Epoch:5 Loss:1.746  translation_Loss:1.746  token_training_loss:0.0 distillation_Loss:0.0                                                     MRR:25.5  Hits@10:46.29 Best:25.86
2025-01-06 12:04:24,243: Early Stopping! Snapshot: 0 Epoch: 6 Best Results: 25.86
2025-01-06 12:04:24,243: Start to training tokens! Snapshot: 0 Epoch: 6 Loss:1.418 MRR:25.38 Best Results: 25.86
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:04:24,244: Snapshot:0 Epoch:6 Loss:1.418  translation_Loss:1.418  token_training_loss:0.0 distillation_Loss:0.0                                                     MRR:25.38 Hits@10:46.27 Best:25.86
2025-01-06 12:04:41,838: Snapshot:0 Epoch:7 Loss:48.399 translation_Loss:36.181 token_training_loss:12.218  distillation_Loss:0.0                                                     MRR:25.38 Hits@10:46.27 Best:25.86
2025-01-06 12:04:59,233: End of token training: 0 Epoch: 8 Loss:36.192 MRR:25.38 Best Results: 25.86
2025-01-06 12:04:59,233: Snapshot:0 Epoch:8 Loss:36.192 translation_Loss:36.19  token_training_loss:0.002 distillation_Loss:0.0                                                             MRR:25.38 Hits@10:46.27 Best:25.86
2025-01-06 12:04:59,513: => loading checkpoint './checkpoint/FB_CKGE/0model_best.tar'
2025-01-06 12:05:05,491: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2574 | 0.1496 | 0.3031 | 0.376  |  0.4679 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:05:14,801: Snapshot:1 Epoch:0 Loss:6.465  translation_Loss:6.194  token_training_loss:0.0 distillation_Loss:0.272                                                     MRR:10.24 Hits@10:19.99 Best:10.24
2025-01-06 12:05:17,918: Snapshot:1 Epoch:1 Loss:3.297  translation_Loss:2.895  token_training_loss:0.0 distillation_Loss:0.402                                                     MRR:13.02 Hits@10:24.35 Best:13.02
2025-01-06 12:05:21,483: Snapshot:1 Epoch:2 Loss:1.731  translation_Loss:1.393  token_training_loss:0.0 distillation_Loss:0.339                                                     MRR:14.62 Hits@10:27.23 Best:14.62
2025-01-06 12:05:24,587: Snapshot:1 Epoch:3 Loss:1.029  translation_Loss:0.792  token_training_loss:0.0 distillation_Loss:0.237                                                     MRR:15.76 Hits@10:29.34 Best:15.76
2025-01-06 12:05:27,790: Snapshot:1 Epoch:4 Loss:0.712  translation_Loss:0.544  token_training_loss:0.0 distillation_Loss:0.168                                                     MRR:16.41 Hits@10:30.8  Best:16.41
2025-01-06 12:05:31,004: Snapshot:1 Epoch:5 Loss:0.548  translation_Loss:0.42 token_training_loss:0.0 distillation_Loss:0.128                                                     MRR:16.82 Hits@10:31.46 Best:16.82
2025-01-06 12:05:34,068: Snapshot:1 Epoch:6 Loss:0.455  translation_Loss:0.347  token_training_loss:0.0 distillation_Loss:0.108                                                     MRR:17.08 Hits@10:32.14 Best:17.08
2025-01-06 12:05:37,764: Snapshot:1 Epoch:7 Loss:0.398  translation_Loss:0.302  token_training_loss:0.0 distillation_Loss:0.096                                                     MRR:17.28 Hits@10:32.67 Best:17.28
2025-01-06 12:05:41,024: Snapshot:1 Epoch:8 Loss:0.369  translation_Loss:0.279  token_training_loss:0.0 distillation_Loss:0.09                                                    MRR:17.64 Hits@10:33.01 Best:17.64
2025-01-06 12:05:44,166: Snapshot:1 Epoch:9 Loss:0.343  translation_Loss:0.258  token_training_loss:0.0 distillation_Loss:0.086                                                     MRR:17.74 Hits@10:33.01 Best:17.74
2025-01-06 12:05:47,352: Snapshot:1 Epoch:10  Loss:0.319  translation_Loss:0.236  token_training_loss:0.0 distillation_Loss:0.084                                                     MRR:17.61 Hits@10:33.33 Best:17.74
2025-01-06 12:05:50,497: Snapshot:1 Epoch:11  Loss:0.304  translation_Loss:0.223  token_training_loss:0.0 distillation_Loss:0.08                                                    MRR:17.7  Hits@10:33.43 Best:17.74
2025-01-06 12:05:54,109: Early Stopping! Snapshot: 1 Epoch: 12 Best Results: 17.74
2025-01-06 12:05:54,109: Start to training tokens! Snapshot: 1 Epoch: 12 Loss:0.286 MRR:17.74 Best Results: 17.74
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:05:54,110: Snapshot:1 Epoch:12  Loss:0.286  translation_Loss:0.209  token_training_loss:0.0 distillation_Loss:0.078                                                     MRR:17.74 Hits@10:33.51 Best:17.74
2025-01-06 12:05:57,260: Snapshot:1 Epoch:13  Loss:18.308 translation_Loss:6.249  token_training_loss:12.059  distillation_Loss:0.0                                                     MRR:17.74 Hits@10:33.51 Best:17.74
2025-01-06 12:06:00,301: End of token training: 1 Epoch: 14 Loss:7.039 MRR:17.74 Best Results: 17.74
2025-01-06 12:06:00,302: Snapshot:1 Epoch:14  Loss:7.039  translation_Loss:6.256  token_training_loss:0.783 distillation_Loss:0.0                                                             MRR:17.74 Hits@10:33.51 Best:17.74
2025-01-06 12:06:00,595: => loading checkpoint './checkpoint/FB_CKGE/1model_best.tar'
2025-01-06 12:06:07,864: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2565 | 0.1489 | 0.3021 | 0.3755 |  0.4655 |
|     1      | 0.183  | 0.1065 | 0.2061 | 0.258  |  0.3388 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:06:17,546: Snapshot:2 Epoch:0 Loss:4.409  translation_Loss:4.109  token_training_loss:0.0 distillation_Loss:0.3                                                     MRR:18.02 Hits@10:33.27 Best:18.02
2025-01-06 12:06:20,886: Snapshot:2 Epoch:1 Loss:2.272  translation_Loss:1.774  token_training_loss:0.0 distillation_Loss:0.498                                                     MRR:19.09 Hits@10:34.44 Best:19.09
2025-01-06 12:06:24,232: Snapshot:2 Epoch:2 Loss:1.389  translation_Loss:0.916  token_training_loss:0.0 distillation_Loss:0.473                                                     MRR:19.46 Hits@10:35.07 Best:19.46
2025-01-06 12:06:27,668: Snapshot:2 Epoch:3 Loss:1.035  translation_Loss:0.647  token_training_loss:0.0 distillation_Loss:0.388                                                     MRR:19.71 Hits@10:35.45 Best:19.71
2025-01-06 12:06:30,880: Snapshot:2 Epoch:4 Loss:0.879  translation_Loss:0.539  token_training_loss:0.0 distillation_Loss:0.34                                                    MRR:19.87 Hits@10:35.4  Best:19.87
2025-01-06 12:06:34,556: Snapshot:2 Epoch:5 Loss:0.808  translation_Loss:0.493  token_training_loss:0.0 distillation_Loss:0.315                                                     MRR:19.84 Hits@10:35.58 Best:19.87
2025-01-06 12:06:37,828: Snapshot:2 Epoch:6 Loss:0.775  translation_Loss:0.469  token_training_loss:0.0 distillation_Loss:0.306                                                     MRR:19.81 Hits@10:35.56 Best:19.87
2025-01-06 12:06:41,100: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 19.87
2025-01-06 12:06:41,101: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:0.744 MRR:19.79 Best Results: 19.87
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:06:41,101: Snapshot:2 Epoch:7 Loss:0.744  translation_Loss:0.443  token_training_loss:0.0 distillation_Loss:0.301                                                     MRR:19.79 Hits@10:35.49 Best:19.87
2025-01-06 12:06:44,288: Snapshot:2 Epoch:8 Loss:19.193 translation_Loss:6.361  token_training_loss:12.832  distillation_Loss:0.0                                                     MRR:19.79 Hits@10:35.49 Best:19.87
2025-01-06 12:06:47,579: End of token training: 2 Epoch: 9 Loss:7.288 MRR:19.79 Best Results: 19.87
2025-01-06 12:06:47,579: Snapshot:2 Epoch:9 Loss:7.288  translation_Loss:6.366  token_training_loss:0.922 distillation_Loss:0.0                                                             MRR:19.79 Hits@10:35.49 Best:19.87
2025-01-06 12:06:47,903: => loading checkpoint './checkpoint/FB_CKGE/2model_best.tar'
2025-01-06 12:06:57,393: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.253  | 0.1465 | 0.2978 | 0.3691 |  0.4599 |
|     1      | 0.1891 | 0.1089 | 0.2115 | 0.2691 |  0.3528 |
|     2      | 0.1995 | 0.1184 | 0.2304 | 0.284  |  0.3573 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:07:06,975: Snapshot:3 Epoch:0 Loss:2.868  translation_Loss:2.573  token_training_loss:0.0 distillation_Loss:0.295                                                     MRR:20.75 Hits@10:36.63 Best:20.75
2025-01-06 12:07:10,385: Snapshot:3 Epoch:1 Loss:1.677  translation_Loss:1.157  token_training_loss:0.0 distillation_Loss:0.52                                                    MRR:21.3  Hits@10:37.38 Best:21.3
2025-01-06 12:07:13,780: Snapshot:3 Epoch:2 Loss:1.193  translation_Loss:0.691  token_training_loss:0.0 distillation_Loss:0.502                                                     MRR:21.32 Hits@10:37.42 Best:21.32
2025-01-06 12:07:17,576: Snapshot:3 Epoch:3 Loss:1.007  translation_Loss:0.56 token_training_loss:0.0 distillation_Loss:0.447                                                     MRR:21.44 Hits@10:37.61 Best:21.44
2025-01-06 12:07:20,943: Snapshot:3 Epoch:4 Loss:0.911  translation_Loss:0.488  token_training_loss:0.0 distillation_Loss:0.423                                                     MRR:21.33 Hits@10:37.44 Best:21.44
2025-01-06 12:07:24,161: Snapshot:3 Epoch:5 Loss:0.874  translation_Loss:0.469  token_training_loss:0.0 distillation_Loss:0.405                                                     MRR:21.3  Hits@10:37.39 Best:21.44
2025-01-06 12:07:27,437: Early Stopping! Snapshot: 3 Epoch: 6 Best Results: 21.44
2025-01-06 12:07:27,438: Start to training tokens! Snapshot: 3 Epoch: 6 Loss:0.854 MRR:21.3 Best Results: 21.44
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:07:27,438: Snapshot:3 Epoch:6 Loss:0.854  translation_Loss:0.455  token_training_loss:0.0 distillation_Loss:0.399                                                     MRR:21.3  Hits@10:37.54 Best:21.44
2025-01-06 12:07:30,691: Snapshot:3 Epoch:7 Loss:17.415 translation_Loss:6.388  token_training_loss:11.027  distillation_Loss:0.0                                                     MRR:21.3  Hits@10:37.54 Best:21.44
2025-01-06 12:07:34,305: End of token training: 3 Epoch: 8 Loss:7.041 MRR:21.3 Best Results: 21.44
2025-01-06 12:07:34,305: Snapshot:3 Epoch:8 Loss:7.041  translation_Loss:6.395  token_training_loss:0.646 distillation_Loss:0.0                                                             MRR:21.3  Hits@10:37.54 Best:21.44
2025-01-06 12:07:34,532: => loading checkpoint './checkpoint/FB_CKGE/3model_best.tar'
2025-01-06 12:07:45,184: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2462 | 0.1402 | 0.2899 | 0.3624 |  0.4528 |
|     1      | 0.1938 | 0.1087 | 0.2217 | 0.2794 |  0.3642 |
|     2      | 0.2017 | 0.119  | 0.2279 | 0.2878 |  0.3656 |
|     3      | 0.2131 | 0.1261 | 0.2501 | 0.3053 |  0.3787 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:07:55,001: Snapshot:4 Epoch:0 Loss:1.924  translation_Loss:1.547  token_training_loss:0.0 distillation_Loss:0.377                                                     MRR:23.36 Hits@10:39.24 Best:23.36
2025-01-06 12:07:58,383: Snapshot:4 Epoch:1 Loss:1.348  translation_Loss:0.806  token_training_loss:0.0 distillation_Loss:0.542                                                     MRR:23.37 Hits@10:39.32 Best:23.37
2025-01-06 12:08:01,798: Snapshot:4 Epoch:2 Loss:1.237  translation_Loss:0.791  token_training_loss:0.0 distillation_Loss:0.447                                                     MRR:23.33 Hits@10:39.2  Best:23.37
2025-01-06 12:08:05,507: Snapshot:4 Epoch:3 Loss:1.113  translation_Loss:0.689  token_training_loss:0.0 distillation_Loss:0.424                                                     MRR:23.34 Hits@10:39.35 Best:23.37
2025-01-06 12:08:08,935: Snapshot:4 Epoch:4 Loss:1.08 translation_Loss:0.672  token_training_loss:0.0 distillation_Loss:0.409                                                     MRR:23.39 Hits@10:39.29 Best:23.39
2025-01-06 12:08:12,321: Snapshot:4 Epoch:5 Loss:1.084  translation_Loss:0.673  token_training_loss:0.0 distillation_Loss:0.411                                                     MRR:23.28 Hits@10:39.05 Best:23.39
2025-01-06 12:08:15,651: Snapshot:4 Epoch:6 Loss:1.064  translation_Loss:0.65 token_training_loss:0.0 distillation_Loss:0.414                                                     MRR:23.3  Hits@10:39.38 Best:23.39
2025-01-06 12:08:19,100: Snapshot:4 Epoch:7 Loss:1.06 translation_Loss:0.646  token_training_loss:0.0 distillation_Loss:0.414                                                     MRR:23.41 Hits@10:39.04 Best:23.41
2025-01-06 12:08:22,951: Snapshot:4 Epoch:8 Loss:1.066  translation_Loss:0.658  token_training_loss:0.0 distillation_Loss:0.408                                                     MRR:23.62 Hits@10:39.58 Best:23.62
2025-01-06 12:08:26,270: Snapshot:4 Epoch:9 Loss:1.062  translation_Loss:0.648  token_training_loss:0.0 distillation_Loss:0.414                                                     MRR:23.34 Hits@10:39.4  Best:23.62
2025-01-06 12:08:29,598: Snapshot:4 Epoch:10  Loss:1.061  translation_Loss:0.646  token_training_loss:0.0 distillation_Loss:0.415                                                     MRR:23.07 Hits@10:39.33 Best:23.62
2025-01-06 12:08:32,899: Early Stopping! Snapshot: 4 Epoch: 11 Best Results: 23.62
2025-01-06 12:08:32,900: Start to training tokens! Snapshot: 4 Epoch: 11 Loss:1.061 MRR:23.22 Best Results: 23.62
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:08:32,900: Snapshot:4 Epoch:11  Loss:1.061  translation_Loss:0.652  token_training_loss:0.0 distillation_Loss:0.409                                                     MRR:23.22 Hits@10:39.08 Best:23.62
2025-01-06 12:08:36,219: Snapshot:4 Epoch:12  Loss:16.862 translation_Loss:6.547  token_training_loss:10.315  distillation_Loss:0.0                                                     MRR:23.22 Hits@10:39.08 Best:23.62
2025-01-06 12:08:39,915: End of token training: 4 Epoch: 13 Loss:7.142 MRR:23.22 Best Results: 23.62
2025-01-06 12:08:39,915: Snapshot:4 Epoch:13  Loss:7.142  translation_Loss:6.542  token_training_loss:0.601 distillation_Loss:0.0                                                             MRR:23.22 Hits@10:39.08 Best:23.62
2025-01-06 12:08:40,145: => loading checkpoint './checkpoint/FB_CKGE/4model_best.tar'
2025-01-06 12:08:53,047: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2449 | 0.1393 | 0.2877 | 0.3589 |  0.4503 |
|     1      | 0.1969 | 0.1116 | 0.2227 | 0.2823 |  0.3712 |
|     2      | 0.2047 | 0.1196 | 0.232  | 0.2932 |  0.3739 |
|     3      | 0.215  | 0.1269 | 0.2492 | 0.3122 |  0.3865 |
|     4      | 0.2351 | 0.1422 | 0.2734 | 0.3363 |  0.413  |
+------------+--------+--------+--------+--------+---------+
2025-01-06 12:08:53,049: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2574 | 0.1496 | 0.3031 | 0.376  |  0.4679 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2565 | 0.1489 | 0.3021 | 0.3755 |  0.4655 |
|     1      | 0.183  | 0.1065 | 0.2061 | 0.258  |  0.3388 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.253  | 0.1465 | 0.2978 | 0.3691 |  0.4599 |
|     1      | 0.1891 | 0.1089 | 0.2115 | 0.2691 |  0.3528 |
|     2      | 0.1995 | 0.1184 | 0.2304 | 0.284  |  0.3573 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2462 | 0.1402 | 0.2899 | 0.3624 |  0.4528 |
|     1      | 0.1938 | 0.1087 | 0.2217 | 0.2794 |  0.3642 |
|     2      | 0.2017 | 0.119  | 0.2279 | 0.2878 |  0.3656 |
|     3      | 0.2131 | 0.1261 | 0.2501 | 0.3053 |  0.3787 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2449 | 0.1393 | 0.2877 | 0.3589 |  0.4503 |
|     1      | 0.1969 | 0.1116 | 0.2227 | 0.2823 |  0.3712 |
|     2      | 0.2047 | 0.1196 | 0.232  | 0.2932 |  0.3739 |
|     3      | 0.215  | 0.1269 | 0.2492 | 0.3122 |  0.3865 |
|     4      | 0.2351 | 0.1422 | 0.2734 | 0.3363 |  0.413  |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 12:08:53,050: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 160.2417185306549  |   0.257   |     0.15     |    0.303     |     0.468     |
|    1     | 52.85400629043579  |   0.246   |    0.143     |    0.288     |     0.447     |
|    2     | 37.995805501937866 |   0.238   |    0.138     |    0.279     |     0.434     |
|    3     | 35.102824211120605 |   0.232   |    0.133     |    0.271     |     0.425     |
|    4     | 52.558558225631714 |   0.232   |    0.134     |     0.27     |     0.425     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 12:08:53,050: Sum_Training_Time:338.7529127597809
2025-01-06 12:08:53,050: Every_Training_Time:[160.2417185306549, 52.85400629043579, 37.995805501937866, 35.102824211120605, 52.558558225631714]
2025-01-06 12:08:53,050: Forward transfer: 0.162225 Backward transfer: 0.002124999999999988