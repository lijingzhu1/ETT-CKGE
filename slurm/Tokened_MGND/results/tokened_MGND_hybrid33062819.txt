2025-01-04 19:03:49,287: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250104190320/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[5000.0, 5000.0, 1000.0, 10000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-04 19:03:59,295: Snapshot:0	Epoch:0	Loss:15.399	translation_Loss:15.399	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.3	Hits@10:18.01	Best:7.3
2025-01-04 19:04:05,374: Snapshot:0	Epoch:1	Loss:10.741	translation_Loss:10.741	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.4	Hits@10:31.06	Best:12.4
2025-01-04 19:04:11,751: Snapshot:0	Epoch:2	Loss:7.011	translation_Loss:7.011	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.94	Hits@10:39.68	Best:18.94
2025-01-04 19:04:17,285: Snapshot:0	Epoch:3	Loss:4.123	translation_Loss:4.123	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.69	Hits@10:43.56	Best:22.69
2025-01-04 19:04:24,000: Snapshot:0	Epoch:4	Loss:2.462	translation_Loss:2.462	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.2	Hits@10:45.22	Best:24.2
2025-01-04 19:04:29,681: Snapshot:0	Epoch:5	Loss:1.562	translation_Loss:1.562	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.95	Hits@10:45.95	Best:24.95
2025-01-04 19:04:36,402: Snapshot:0	Epoch:6	Loss:1.067	translation_Loss:1.067	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.31	Hits@10:46.24	Best:25.31
2025-01-04 19:04:42,036: Snapshot:0	Epoch:7	Loss:0.799	translation_Loss:0.799	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.58	Hits@10:46.57	Best:25.58
2025-01-04 19:04:48,769: Snapshot:0	Epoch:8	Loss:0.631	translation_Loss:0.631	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.6	Hits@10:46.61	Best:25.6
2025-01-04 19:04:54,373: Snapshot:0	Epoch:9	Loss:0.535	translation_Loss:0.535	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.74	Hits@10:46.61	Best:25.74
2025-01-04 19:05:01,169: Snapshot:0	Epoch:10	Loss:0.454	translation_Loss:0.454	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.75	Hits@10:46.36	Best:25.75
2025-01-04 19:05:07,172: Snapshot:0	Epoch:11	Loss:0.401	translation_Loss:0.401	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.76	Hits@10:46.28	Best:25.76
2025-01-04 19:05:13,528: Snapshot:0	Epoch:12	Loss:0.356	translation_Loss:0.356	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:46.21	Best:25.79
2025-01-04 19:05:19,513: Snapshot:0	Epoch:13	Loss:0.319	translation_Loss:0.319	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.85	Hits@10:46.14	Best:25.85
2025-01-04 19:05:25,811: Snapshot:0	Epoch:14	Loss:0.293	translation_Loss:0.293	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.81	Hits@10:46.11	Best:25.85
2025-01-04 19:05:32,001: Snapshot:0	Epoch:15	Loss:0.271	translation_Loss:0.271	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.85	Hits@10:46.01	Best:25.85
2025-01-04 19:05:38,379: Snapshot:0	Epoch:16	Loss:0.252	translation_Loss:0.252	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.88	Hits@10:46.01	Best:25.88
2025-01-04 19:05:44,248: Snapshot:0	Epoch:17	Loss:0.237	translation_Loss:0.237	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.67	Hits@10:45.93	Best:25.88
2025-01-04 19:05:50,567: Snapshot:0	Epoch:18	Loss:0.222	translation_Loss:0.222	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.78	Hits@10:45.9	Best:25.88
2025-01-04 19:05:56,591: Snapshot:0	Epoch:19	Loss:0.219	translation_Loss:0.219	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.69	Hits@10:45.87	Best:25.88
2025-01-04 19:06:02,834: Snapshot:0	Epoch:20	Loss:0.197	translation_Loss:0.197	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.46	Hits@10:45.67	Best:25.88
2025-01-04 19:06:08,351: Early Stopping! Snapshot: 0 Epoch: 21 Best Results: 25.88
2025-01-04 19:06:08,351: Start to training tokens! Snapshot: 0 Epoch: 21 Loss:0.196 MRR:25.28 Best Results: 25.88
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:06:08,352: Snapshot:0	Epoch:21	Loss:0.196	translation_Loss:0.196	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.28	Hits@10:45.69	Best:25.88
2025-01-04 19:06:15,556: Snapshot:0	Epoch:22	Loss:26.489	translation_Loss:11.49	token_training_loss:14.999	distillation_Loss:0.0                                                   	MRR:25.28	Hits@10:45.69	Best:25.88
2025-01-04 19:06:21,196: End of token training: 0 Epoch: 23 Loss:11.88 MRR:25.28 Best Results: 25.88
2025-01-04 19:06:21,196: Snapshot:0	Epoch:23	Loss:11.88	translation_Loss:11.508	token_training_loss:0.373	distillation_Loss:0.0                                                           	MRR:25.28	Hits@10:45.69	Best:25.88
2025-01-04 19:06:21,436: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2025-01-04 19:06:23,928: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2558 | 0.1487 | 0.3113 | 0.3767 |  0.4504 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:06:30,783: Snapshot:1	Epoch:0	Loss:4.885	translation_Loss:4.725	token_training_loss:0.0	distillation_Loss:0.16                                                   	MRR:9.67	Hits@10:17.01	Best:9.67
2025-01-04 19:06:32,861: Snapshot:1	Epoch:1	Loss:2.896	translation_Loss:2.554	token_training_loss:0.0	distillation_Loss:0.341                                                   	MRR:16.51	Hits@10:30.29	Best:16.51
2025-01-04 19:06:35,360: Snapshot:1	Epoch:2	Loss:1.797	translation_Loss:1.343	token_training_loss:0.0	distillation_Loss:0.454                                                   	MRR:20.8	Hits@10:36.6	Best:20.8
2025-01-04 19:06:37,818: Snapshot:1	Epoch:3	Loss:1.259	translation_Loss:0.811	token_training_loss:0.0	distillation_Loss:0.448                                                   	MRR:23.49	Hits@10:40.36	Best:23.49
2025-01-04 19:06:40,226: Snapshot:1	Epoch:4	Loss:0.955	translation_Loss:0.57	token_training_loss:0.0	distillation_Loss:0.385                                                   	MRR:24.58	Hits@10:42.8	Best:24.58
2025-01-04 19:06:42,940: Snapshot:1	Epoch:5	Loss:0.779	translation_Loss:0.457	token_training_loss:0.0	distillation_Loss:0.322                                                   	MRR:25.58	Hits@10:44.93	Best:25.58
2025-01-04 19:06:45,203: Snapshot:1	Epoch:6	Loss:0.674	translation_Loss:0.394	token_training_loss:0.0	distillation_Loss:0.28                                                   	MRR:26.46	Hits@10:46.3	Best:26.46
2025-01-04 19:06:47,301: Snapshot:1	Epoch:7	Loss:0.609	translation_Loss:0.352	token_training_loss:0.0	distillation_Loss:0.257                                                   	MRR:26.98	Hits@10:47.68	Best:26.98
2025-01-04 19:06:49,447: Snapshot:1	Epoch:8	Loss:0.558	translation_Loss:0.316	token_training_loss:0.0	distillation_Loss:0.241                                                   	MRR:27.56	Hits@10:48.43	Best:27.56
2025-01-04 19:06:51,524: Snapshot:1	Epoch:9	Loss:0.526	translation_Loss:0.299	token_training_loss:0.0	distillation_Loss:0.227                                                   	MRR:27.8	Hits@10:48.69	Best:27.8
2025-01-04 19:06:54,013: Snapshot:1	Epoch:10	Loss:0.497	translation_Loss:0.28	token_training_loss:0.0	distillation_Loss:0.218                                                   	MRR:28.26	Hits@10:49.35	Best:28.26
2025-01-04 19:06:56,551: Snapshot:1	Epoch:11	Loss:0.472	translation_Loss:0.261	token_training_loss:0.0	distillation_Loss:0.211                                                   	MRR:28.43	Hits@10:49.66	Best:28.43
2025-01-04 19:06:58,995: Snapshot:1	Epoch:12	Loss:0.455	translation_Loss:0.251	token_training_loss:0.0	distillation_Loss:0.204                                                   	MRR:28.79	Hits@10:49.72	Best:28.79
2025-01-04 19:07:01,336: Snapshot:1	Epoch:13	Loss:0.444	translation_Loss:0.245	token_training_loss:0.0	distillation_Loss:0.199                                                   	MRR:29.02	Hits@10:49.75	Best:29.02
2025-01-04 19:07:03,741: Snapshot:1	Epoch:14	Loss:0.431	translation_Loss:0.237	token_training_loss:0.0	distillation_Loss:0.194                                                   	MRR:29.21	Hits@10:50.13	Best:29.21
2025-01-04 19:07:06,077: Snapshot:1	Epoch:15	Loss:0.422	translation_Loss:0.231	token_training_loss:0.0	distillation_Loss:0.191                                                   	MRR:29.39	Hits@10:50.1	Best:29.39
2025-01-04 19:07:08,550: Snapshot:1	Epoch:16	Loss:0.405	translation_Loss:0.217	token_training_loss:0.0	distillation_Loss:0.188                                                   	MRR:29.49	Hits@10:50.59	Best:29.49
2025-01-04 19:07:10,835: Snapshot:1	Epoch:17	Loss:0.396	translation_Loss:0.212	token_training_loss:0.0	distillation_Loss:0.184                                                   	MRR:29.61	Hits@10:50.23	Best:29.61
2025-01-04 19:07:13,673: Snapshot:1	Epoch:18	Loss:0.39	translation_Loss:0.211	token_training_loss:0.0	distillation_Loss:0.18                                                   	MRR:29.74	Hits@10:50.44	Best:29.74
2025-01-04 19:07:16,037: Snapshot:1	Epoch:19	Loss:0.381	translation_Loss:0.204	token_training_loss:0.0	distillation_Loss:0.177                                                   	MRR:29.71	Hits@10:50.56	Best:29.74
2025-01-04 19:07:18,234: Snapshot:1	Epoch:20	Loss:0.375	translation_Loss:0.201	token_training_loss:0.0	distillation_Loss:0.175                                                   	MRR:29.8	Hits@10:50.68	Best:29.8
2025-01-04 19:07:20,370: Snapshot:1	Epoch:21	Loss:0.369	translation_Loss:0.197	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:29.96	Hits@10:50.59	Best:29.96
2025-01-04 19:07:22,831: Snapshot:1	Epoch:22	Loss:0.368	translation_Loss:0.197	token_training_loss:0.0	distillation_Loss:0.171                                                   	MRR:29.97	Hits@10:50.68	Best:29.97
2025-01-04 19:07:25,038: Snapshot:1	Epoch:23	Loss:0.358	translation_Loss:0.188	token_training_loss:0.0	distillation_Loss:0.171                                                   	MRR:29.67	Hits@10:50.74	Best:29.97
2025-01-04 19:07:27,766: Snapshot:1	Epoch:24	Loss:0.359	translation_Loss:0.192	token_training_loss:0.0	distillation_Loss:0.167                                                   	MRR:29.92	Hits@10:50.56	Best:29.97
2025-01-04 19:07:29,995: Snapshot:1	Epoch:25	Loss:0.349	translation_Loss:0.183	token_training_loss:0.0	distillation_Loss:0.166                                                   	MRR:30.11	Hits@10:50.71	Best:30.11
2025-01-04 19:07:32,484: Snapshot:1	Epoch:26	Loss:0.347	translation_Loss:0.183	token_training_loss:0.0	distillation_Loss:0.164                                                   	MRR:30.02	Hits@10:50.78	Best:30.11
2025-01-04 19:07:34,640: Snapshot:1	Epoch:27	Loss:0.348	translation_Loss:0.185	token_training_loss:0.0	distillation_Loss:0.163                                                   	MRR:29.94	Hits@10:50.9	Best:30.11
2025-01-04 19:07:37,018: Snapshot:1	Epoch:28	Loss:0.345	translation_Loss:0.181	token_training_loss:0.0	distillation_Loss:0.164                                                   	MRR:29.68	Hits@10:50.85	Best:30.11
2025-01-04 19:07:39,217: Snapshot:1	Epoch:29	Loss:0.343	translation_Loss:0.179	token_training_loss:0.0	distillation_Loss:0.163                                                   	MRR:29.77	Hits@10:50.8	Best:30.11
2025-01-04 19:07:41,875: Early Stopping! Snapshot: 1 Epoch: 30 Best Results: 30.11
2025-01-04 19:07:41,875: Start to training tokens! Snapshot: 1 Epoch: 30 Loss:0.341 MRR:29.79 Best Results: 30.11
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:07:41,875: Snapshot:1	Epoch:30	Loss:0.341	translation_Loss:0.18	token_training_loss:0.0	distillation_Loss:0.161                                                   	MRR:29.79	Hits@10:50.54	Best:30.11
2025-01-04 19:07:44,247: Snapshot:1	Epoch:31	Loss:16.176	translation_Loss:4.387	token_training_loss:11.789	distillation_Loss:0.0                                                   	MRR:29.79	Hits@10:50.54	Best:30.11
2025-01-04 19:07:46,460: End of token training: 1 Epoch: 32 Loss:7.02 MRR:29.79 Best Results: 30.11
2025-01-04 19:07:46,460: Snapshot:1	Epoch:32	Loss:7.02	translation_Loss:4.382	token_training_loss:2.638	distillation_Loss:0.0                                                           	MRR:29.79	Hits@10:50.54	Best:30.11
2025-01-04 19:07:46,710: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2025-01-04 19:07:50,355: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.257  | 0.1507 | 0.3116 | 0.3759 |  0.4527 |
|     1      | 0.2968 | 0.1937 | 0.3401 | 0.4129 |  0.5047 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:08:06,734: Snapshot:2	Epoch:0	Loss:15.82	translation_Loss:14.618	token_training_loss:0.0	distillation_Loss:1.202                                                   	MRR:14.12	Hits@10:28.08	Best:14.12
2025-01-04 19:08:17,111: Snapshot:2	Epoch:1	Loss:7.21	translation_Loss:5.786	token_training_loss:0.0	distillation_Loss:1.425                                                   	MRR:18.89	Hits@10:35.39	Best:18.89
2025-01-04 19:08:26,581: Snapshot:2	Epoch:2	Loss:4.719	translation_Loss:3.59	token_training_loss:0.0	distillation_Loss:1.129                                                   	MRR:20.26	Hits@10:37.17	Best:20.26
2025-01-04 19:08:37,268: Snapshot:2	Epoch:3	Loss:3.873	translation_Loss:2.895	token_training_loss:0.0	distillation_Loss:0.978                                                   	MRR:20.87	Hits@10:37.51	Best:20.87
2025-01-04 19:08:46,525: Snapshot:2	Epoch:4	Loss:3.521	translation_Loss:2.612	token_training_loss:0.0	distillation_Loss:0.91                                                   	MRR:21.12	Hits@10:37.53	Best:21.12
2025-01-04 19:08:57,194: Snapshot:2	Epoch:5	Loss:3.361	translation_Loss:2.478	token_training_loss:0.0	distillation_Loss:0.884                                                   	MRR:21.16	Hits@10:37.71	Best:21.16
2025-01-04 19:09:06,700: Snapshot:2	Epoch:6	Loss:3.266	translation_Loss:2.398	token_training_loss:0.0	distillation_Loss:0.868                                                   	MRR:21.21	Hits@10:37.7	Best:21.21
2025-01-04 19:09:17,315: Snapshot:2	Epoch:7	Loss:3.226	translation_Loss:2.36	token_training_loss:0.0	distillation_Loss:0.866                                                   	MRR:21.33	Hits@10:37.81	Best:21.33
2025-01-04 19:09:26,454: Snapshot:2	Epoch:8	Loss:3.18	translation_Loss:2.318	token_training_loss:0.0	distillation_Loss:0.862                                                   	MRR:21.21	Hits@10:37.88	Best:21.33
2025-01-04 19:09:35,678: Snapshot:2	Epoch:9	Loss:3.15	translation_Loss:2.294	token_training_loss:0.0	distillation_Loss:0.856                                                   	MRR:21.26	Hits@10:37.95	Best:21.33
2025-01-04 19:09:46,396: Snapshot:2	Epoch:10	Loss:3.124	translation_Loss:2.269	token_training_loss:0.0	distillation_Loss:0.855                                                   	MRR:21.14	Hits@10:37.94	Best:21.33
2025-01-04 19:09:56,652: Snapshot:2	Epoch:11	Loss:3.104	translation_Loss:2.249	token_training_loss:0.0	distillation_Loss:0.855                                                   	MRR:21.22	Hits@10:37.92	Best:21.33
2025-01-04 19:10:06,047: Early Stopping! Snapshot: 2 Epoch: 12 Best Results: 21.33
2025-01-04 19:10:06,047: Start to training tokens! Snapshot: 2 Epoch: 12 Loss:3.082 MRR:21.25 Best Results: 21.33
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:10:06,048: Snapshot:2	Epoch:12	Loss:3.082	translation_Loss:2.231	token_training_loss:0.0	distillation_Loss:0.852                                                   	MRR:21.25	Hits@10:37.69	Best:21.33
2025-01-04 19:10:16,678: Snapshot:2	Epoch:13	Loss:32.571	translation_Loss:18.133	token_training_loss:14.438	distillation_Loss:0.0                                                   	MRR:21.25	Hits@10:37.69	Best:21.33
2025-01-04 19:10:25,804: End of token training: 2 Epoch: 14 Loss:18.265 MRR:21.25 Best Results: 21.33
2025-01-04 19:10:25,804: Snapshot:2	Epoch:14	Loss:18.265	translation_Loss:18.137	token_training_loss:0.127	distillation_Loss:0.0                                                           	MRR:21.25	Hits@10:37.69	Best:21.33
2025-01-04 19:10:26,048: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2025-01-04 19:10:33,593: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2527 | 0.1423 | 0.3096 | 0.378  |  0.4574 |
|     1      | 0.2835 |  0.18  | 0.3254 | 0.391  |  0.4887 |
|     2      | 0.2124 | 0.1275 | 0.2425 | 0.2998 |  0.3791 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:10:54,590: Snapshot:3	Epoch:0	Loss:14.226	translation_Loss:13.346	token_training_loss:0.0	distillation_Loss:0.88                                                   	MRR:16.02	Hits@10:31.94	Best:16.02
2025-01-04 19:11:05,976: Snapshot:3	Epoch:1	Loss:5.235	translation_Loss:3.76	token_training_loss:0.0	distillation_Loss:1.474                                                   	MRR:20.23	Hits@10:37.65	Best:20.23
2025-01-04 19:11:18,731: Snapshot:3	Epoch:2	Loss:3.492	translation_Loss:2.087	token_training_loss:0.0	distillation_Loss:1.405                                                   	MRR:20.88	Hits@10:38.67	Best:20.88
2025-01-04 19:11:29,982: Snapshot:3	Epoch:3	Loss:2.957	translation_Loss:1.634	token_training_loss:0.0	distillation_Loss:1.323                                                   	MRR:21.24	Hits@10:38.96	Best:21.24
2025-01-04 19:11:42,483: Snapshot:3	Epoch:4	Loss:2.743	translation_Loss:1.464	token_training_loss:0.0	distillation_Loss:1.279                                                   	MRR:21.56	Hits@10:39.39	Best:21.56
2025-01-04 19:11:53,784: Snapshot:3	Epoch:5	Loss:2.63	translation_Loss:1.379	token_training_loss:0.0	distillation_Loss:1.251                                                   	MRR:21.59	Hits@10:39.57	Best:21.59
2025-01-04 19:12:06,696: Snapshot:3	Epoch:6	Loss:2.557	translation_Loss:1.327	token_training_loss:0.0	distillation_Loss:1.23                                                   	MRR:21.58	Hits@10:39.62	Best:21.59
2025-01-04 19:12:18,053: Snapshot:3	Epoch:7	Loss:2.518	translation_Loss:1.293	token_training_loss:0.0	distillation_Loss:1.225                                                   	MRR:21.65	Hits@10:39.76	Best:21.65
2025-01-04 19:12:30,812: Snapshot:3	Epoch:8	Loss:2.495	translation_Loss:1.276	token_training_loss:0.0	distillation_Loss:1.219                                                   	MRR:21.58	Hits@10:39.76	Best:21.65
2025-01-04 19:12:43,184: Snapshot:3	Epoch:9	Loss:2.47	translation_Loss:1.255	token_training_loss:0.0	distillation_Loss:1.215                                                   	MRR:21.65	Hits@10:39.61	Best:21.65
2025-01-04 19:12:54,439: Snapshot:3	Epoch:10	Loss:2.453	translation_Loss:1.24	token_training_loss:0.0	distillation_Loss:1.213                                                   	MRR:21.66	Hits@10:39.63	Best:21.66
2025-01-04 19:13:05,638: Snapshot:3	Epoch:11	Loss:2.436	translation_Loss:1.229	token_training_loss:0.0	distillation_Loss:1.207                                                   	MRR:21.66	Hits@10:39.63	Best:21.66
2025-01-04 19:13:16,815: Snapshot:3	Epoch:12	Loss:2.43	translation_Loss:1.217	token_training_loss:0.0	distillation_Loss:1.213                                                   	MRR:21.65	Hits@10:39.5	Best:21.66
2025-01-04 19:13:29,626: Snapshot:3	Epoch:13	Loss:2.43	translation_Loss:1.22	token_training_loss:0.0	distillation_Loss:1.21                                                   	MRR:21.63	Hits@10:39.45	Best:21.66
2025-01-04 19:13:42,079: Snapshot:3	Epoch:14	Loss:2.417	translation_Loss:1.207	token_training_loss:0.0	distillation_Loss:1.21                                                   	MRR:21.69	Hits@10:39.48	Best:21.69
2025-01-04 19:13:53,000: Snapshot:3	Epoch:15	Loss:2.431	translation_Loss:1.218	token_training_loss:0.0	distillation_Loss:1.213                                                   	MRR:21.76	Hits@10:39.7	Best:21.76
2025-01-04 19:14:05,791: Snapshot:3	Epoch:16	Loss:2.412	translation_Loss:1.199	token_training_loss:0.0	distillation_Loss:1.213                                                   	MRR:21.62	Hits@10:39.18	Best:21.76
2025-01-04 19:14:17,034: Snapshot:3	Epoch:17	Loss:2.408	translation_Loss:1.2	token_training_loss:0.0	distillation_Loss:1.208                                                   	MRR:21.74	Hits@10:39.42	Best:21.76
2025-01-04 19:14:28,155: Snapshot:3	Epoch:18	Loss:2.403	translation_Loss:1.194	token_training_loss:0.0	distillation_Loss:1.208                                                   	MRR:21.86	Hits@10:39.59	Best:21.86
2025-01-04 19:14:40,987: Snapshot:3	Epoch:19	Loss:2.406	translation_Loss:1.196	token_training_loss:0.0	distillation_Loss:1.21                                                   	MRR:21.66	Hits@10:39.67	Best:21.86
2025-01-04 19:14:51,952: Snapshot:3	Epoch:20	Loss:2.399	translation_Loss:1.185	token_training_loss:0.0	distillation_Loss:1.214                                                   	MRR:21.73	Hits@10:39.59	Best:21.86
2025-01-04 19:15:04,718: Snapshot:3	Epoch:21	Loss:2.403	translation_Loss:1.185	token_training_loss:0.0	distillation_Loss:1.217                                                   	MRR:21.71	Hits@10:39.64	Best:21.86
2025-01-04 19:15:16,149: Snapshot:3	Epoch:22	Loss:2.398	translation_Loss:1.186	token_training_loss:0.0	distillation_Loss:1.212                                                   	MRR:21.81	Hits@10:39.74	Best:21.86
2025-01-04 19:15:28,733: Early Stopping! Snapshot: 3 Epoch: 23 Best Results: 21.86
2025-01-04 19:15:28,733: Start to training tokens! Snapshot: 3 Epoch: 23 Loss:2.389 MRR:21.62 Best Results: 21.86
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:15:28,733: Snapshot:3	Epoch:23	Loss:2.389	translation_Loss:1.172	token_training_loss:0.0	distillation_Loss:1.217                                                   	MRR:21.62	Hits@10:39.68	Best:21.86
2025-01-04 19:15:40,100: Snapshot:3	Epoch:24	Loss:33.752	translation_Loss:18.404	token_training_loss:15.348	distillation_Loss:0.0                                                   	MRR:21.62	Hits@10:39.68	Best:21.86
2025-01-04 19:15:53,077: End of token training: 3 Epoch: 25 Loss:18.462 MRR:21.62 Best Results: 21.86
2025-01-04 19:15:53,077: Snapshot:3	Epoch:25	Loss:18.462	translation_Loss:18.391	token_training_loss:0.071	distillation_Loss:0.0                                                           	MRR:21.62	Hits@10:39.68	Best:21.86
2025-01-04 19:15:53,321: => loading checkpoint './checkpoint/HYBRID/3model_best.tar'
2025-01-04 19:16:06,271: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2594 | 0.1549 | 0.3094 | 0.3745 |  0.455  |
|     1      | 0.2769 | 0.1771 | 0.314  | 0.3788 |  0.478  |
|     2      | 0.2074 | 0.1231 | 0.2359 | 0.292  |  0.373  |
|     3      | 0.2179 | 0.1242 | 0.2548 | 0.3139 |  0.3961 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:16:17,127: Snapshot:4	Epoch:0	Loss:6.627	translation_Loss:6.101	token_training_loss:0.0	distillation_Loss:0.526                                                   	MRR:9.34	Hits@10:19.97	Best:9.34
2025-01-04 19:16:22,121: Snapshot:4	Epoch:1	Loss:4.379	translation_Loss:3.517	token_training_loss:0.0	distillation_Loss:0.861                                                   	MRR:15.11	Hits@10:32.88	Best:15.11
2025-01-04 19:16:26,715: Snapshot:4	Epoch:2	Loss:3.307	translation_Loss:2.429	token_training_loss:0.0	distillation_Loss:0.878                                                   	MRR:18.78	Hits@10:34.99	Best:18.78
2025-01-04 19:16:32,071: Snapshot:4	Epoch:3	Loss:2.708	translation_Loss:1.879	token_training_loss:0.0	distillation_Loss:0.829                                                   	MRR:21.24	Hits@10:36.37	Best:21.24
2025-01-04 19:16:36,692: Snapshot:4	Epoch:4	Loss:2.344	translation_Loss:1.57	token_training_loss:0.0	distillation_Loss:0.774                                                   	MRR:22.28	Hits@10:36.94	Best:22.28
2025-01-04 19:16:41,929: Snapshot:4	Epoch:5	Loss:2.103	translation_Loss:1.375	token_training_loss:0.0	distillation_Loss:0.729                                                   	MRR:22.73	Hits@10:37.23	Best:22.73
2025-01-04 19:16:46,963: Snapshot:4	Epoch:6	Loss:1.952	translation_Loss:1.261	token_training_loss:0.0	distillation_Loss:0.691                                                   	MRR:22.81	Hits@10:37.5	Best:22.81
2025-01-04 19:16:51,939: Snapshot:4	Epoch:7	Loss:1.856	translation_Loss:1.191	token_training_loss:0.0	distillation_Loss:0.665                                                   	MRR:22.71	Hits@10:37.36	Best:22.81
2025-01-04 19:16:56,940: Snapshot:4	Epoch:8	Loss:1.798	translation_Loss:1.154	token_training_loss:0.0	distillation_Loss:0.645                                                   	MRR:22.7	Hits@10:37.41	Best:22.81
2025-01-04 19:17:02,044: Snapshot:4	Epoch:9	Loss:1.748	translation_Loss:1.12	token_training_loss:0.0	distillation_Loss:0.629                                                   	MRR:22.49	Hits@10:37.31	Best:22.81
2025-01-04 19:17:06,999: Snapshot:4	Epoch:10	Loss:1.728	translation_Loss:1.108	token_training_loss:0.0	distillation_Loss:0.62                                                   	MRR:22.59	Hits@10:37.52	Best:22.81
2025-01-04 19:17:12,064: Early Stopping! Snapshot: 4 Epoch: 11 Best Results: 22.81
2025-01-04 19:17:12,064: Start to training tokens! Snapshot: 4 Epoch: 11 Loss:1.705 MRR:22.38 Best Results: 22.81
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:17:12,064: Snapshot:4	Epoch:11	Loss:1.705	translation_Loss:1.093	token_training_loss:0.0	distillation_Loss:0.612                                                   	MRR:22.38	Hits@10:37.41	Best:22.81
2025-01-04 19:17:16,930: Snapshot:4	Epoch:12	Loss:24.264	translation_Loss:9.201	token_training_loss:15.063	distillation_Loss:0.0                                                   	MRR:22.38	Hits@10:37.41	Best:22.81
2025-01-04 19:17:22,211: End of token training: 4 Epoch: 13 Loss:10.12 MRR:22.38 Best Results: 22.81
2025-01-04 19:17:22,212: Snapshot:4	Epoch:13	Loss:10.12	translation_Loss:9.204	token_training_loss:0.916	distillation_Loss:0.0                                                           	MRR:22.38	Hits@10:37.41	Best:22.81
2025-01-04 19:17:22,457: => loading checkpoint './checkpoint/HYBRID/4model_best.tar'
2025-01-04 19:17:37,826: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2269 | 0.1259 | 0.2739 | 0.3349 |  0.4127 |
|     1      | 0.265  | 0.1651 | 0.3004 | 0.3659 |  0.4628 |
|     2      | 0.1975 | 0.1153 | 0.2233 | 0.2781 |  0.3567 |
|     3      | 0.1999 | 0.1085 | 0.2328 | 0.2936 |  0.3763 |
|     4      | 0.2245 | 0.1469 | 0.2552 | 0.3045 |  0.3735 |
+------------+--------+--------+--------+--------+---------+
2025-01-04 19:17:37,829: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2558 | 0.1487 | 0.3113 | 0.3767 |  0.4504 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.257  | 0.1507 | 0.3116 | 0.3759 |  0.4527 |
|     1      | 0.2968 | 0.1937 | 0.3401 | 0.4129 |  0.5047 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2527 | 0.1423 | 0.3096 | 0.378  |  0.4574 |
|     1      | 0.2835 |  0.18  | 0.3254 | 0.391  |  0.4887 |
|     2      | 0.2124 | 0.1275 | 0.2425 | 0.2998 |  0.3791 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2594 | 0.1549 | 0.3094 | 0.3745 |  0.455  |
|     1      | 0.2769 | 0.1771 | 0.314  | 0.3788 |  0.478  |
|     2      | 0.2074 | 0.1231 | 0.2359 | 0.292  |  0.373  |
|     3      | 0.2179 | 0.1242 | 0.2548 | 0.3139 |  0.3961 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2269 | 0.1259 | 0.2739 | 0.3349 |  0.4127 |
|     1      | 0.265  | 0.1651 | 0.3004 | 0.3659 |  0.4628 |
|     2      | 0.1975 | 0.1153 | 0.2233 | 0.2781 |  0.3567 |
|     3      | 0.1999 | 0.1085 | 0.2328 | 0.2936 |  0.3763 |
|     4      | 0.2245 | 0.1469 | 0.2552 | 0.3045 |  0.3735 |
+------------+--------+--------+--------+--------+---------+]
2025-01-04 19:17:37,829: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 151.9081780910492  |   0.256   |    0.149     |    0.311     |      0.45     |
|    1     | 81.38676738739014  |   0.268   |    0.162     |    0.319     |     0.467     |
|    2     | 151.70990204811096 |   0.235   |    0.139     |    0.276     |      0.42     |
|    3     | 314.5849013328552  |   0.228   |    0.134     |    0.265     |     0.407     |
|    4     |  73.3216598033905  |   0.212   |    0.122     |    0.245     |     0.383     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-04 19:17:37,829: Sum_Training_Time:772.911408662796
2025-01-04 19:17:37,829: Every_Training_Time:[151.9081780910492, 81.38676738739014, 151.70990204811096, 314.5849013328552, 73.3216598033905]
2025-01-04 19:17:37,829: Forward transfer: 0.04295 Backward transfer: -0.02340000000000001
2025-01-04 19:18:10,042: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250104191742/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[5000.0, 3000.0, 3000.0, 10000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-04 19:18:19,114: Snapshot:0	Epoch:0	Loss:15.399	translation_Loss:15.399	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.3	Hits@10:18.01	Best:7.3
2025-01-04 19:18:25,839: Snapshot:0	Epoch:1	Loss:10.741	translation_Loss:10.741	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.4	Hits@10:31.06	Best:12.4
2025-01-04 19:18:31,455: Snapshot:0	Epoch:2	Loss:7.011	translation_Loss:7.011	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.94	Hits@10:39.69	Best:18.94
2025-01-04 19:18:37,795: Snapshot:0	Epoch:3	Loss:4.123	translation_Loss:4.123	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.71	Hits@10:43.56	Best:22.71
2025-01-04 19:18:44,315: Snapshot:0	Epoch:4	Loss:2.462	translation_Loss:2.462	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.24	Hits@10:45.28	Best:24.24
2025-01-04 19:18:50,681: Snapshot:0	Epoch:5	Loss:1.562	translation_Loss:1.562	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.98	Hits@10:45.9	Best:24.98
2025-01-04 19:18:56,569: Snapshot:0	Epoch:6	Loss:1.067	translation_Loss:1.067	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.27	Hits@10:46.2	Best:25.27
2025-01-04 19:19:03,040: Snapshot:0	Epoch:7	Loss:0.799	translation_Loss:0.799	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.55	Hits@10:46.53	Best:25.55
2025-01-04 19:19:09,408: Snapshot:0	Epoch:8	Loss:0.631	translation_Loss:0.631	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.67	Hits@10:46.53	Best:25.67
2025-01-04 19:19:15,922: Snapshot:0	Epoch:9	Loss:0.535	translation_Loss:0.535	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.64	Hits@10:46.56	Best:25.67
2025-01-04 19:19:21,915: Snapshot:0	Epoch:10	Loss:0.453	translation_Loss:0.453	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.67	Hits@10:46.54	Best:25.67
2025-01-04 19:19:28,018: Snapshot:0	Epoch:11	Loss:0.402	translation_Loss:0.402	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.77	Hits@10:46.36	Best:25.77
2025-01-04 19:19:33,845: Snapshot:0	Epoch:12	Loss:0.355	translation_Loss:0.355	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.9	Hits@10:46.31	Best:25.9
2025-01-04 19:19:40,446: Snapshot:0	Epoch:13	Loss:0.319	translation_Loss:0.319	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.78	Hits@10:46.34	Best:25.9
2025-01-04 19:19:46,103: Snapshot:0	Epoch:14	Loss:0.293	translation_Loss:0.293	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.76	Hits@10:46.06	Best:25.9
2025-01-04 19:19:52,719: Snapshot:0	Epoch:15	Loss:0.271	translation_Loss:0.271	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.72	Hits@10:45.94	Best:25.9
2025-01-04 19:19:58,294: Snapshot:0	Epoch:16	Loss:0.252	translation_Loss:0.252	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.72	Hits@10:45.96	Best:25.9
2025-01-04 19:20:04,918: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 25.9
2025-01-04 19:20:04,919: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.238 MRR:25.72 Best Results: 25.9
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:20:04,920: Snapshot:0	Epoch:17	Loss:0.238	translation_Loss:0.238	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.72	Hits@10:46.0	Best:25.9
2025-01-04 19:20:11,111: Snapshot:0	Epoch:18	Loss:26.544	translation_Loss:11.546	token_training_loss:14.999	distillation_Loss:0.0                                                   	MRR:25.72	Hits@10:46.0	Best:25.9
2025-01-04 19:20:17,964: End of token training: 0 Epoch: 19 Loss:11.926 MRR:25.72 Best Results: 25.9
2025-01-04 19:20:17,964: Snapshot:0	Epoch:19	Loss:11.926	translation_Loss:11.553	token_training_loss:0.373	distillation_Loss:0.0                                                           	MRR:25.72	Hits@10:46.0	Best:25.9
2025-01-04 19:20:18,202: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2025-01-04 19:20:20,560: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2578 |  0.15  | 0.3161 |  0.38  |  0.4548 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:20:27,387: Snapshot:1	Epoch:0	Loss:4.921	translation_Loss:4.759	token_training_loss:0.0	distillation_Loss:0.162                                                   	MRR:9.77	Hits@10:17.43	Best:9.77
2025-01-04 19:20:29,532: Snapshot:1	Epoch:1	Loss:2.943	translation_Loss:2.598	token_training_loss:0.0	distillation_Loss:0.344                                                   	MRR:16.76	Hits@10:30.98	Best:16.76
2025-01-04 19:20:31,990: Snapshot:1	Epoch:2	Loss:1.867	translation_Loss:1.406	token_training_loss:0.0	distillation_Loss:0.461                                                   	MRR:21.14	Hits@10:37.37	Best:21.14
2025-01-04 19:20:34,340: Snapshot:1	Epoch:3	Loss:1.311	translation_Loss:0.85	token_training_loss:0.0	distillation_Loss:0.46                                                   	MRR:23.82	Hits@10:41.23	Best:23.82
2025-01-04 19:20:36,460: Snapshot:1	Epoch:4	Loss:1.007	translation_Loss:0.605	token_training_loss:0.0	distillation_Loss:0.401                                                   	MRR:25.0	Hits@10:43.28	Best:25.0
2025-01-04 19:20:39,246: Snapshot:1	Epoch:5	Loss:0.832	translation_Loss:0.491	token_training_loss:0.0	distillation_Loss:0.341                                                   	MRR:25.67	Hits@10:45.16	Best:25.67
2025-01-04 19:20:41,702: Snapshot:1	Epoch:6	Loss:0.716	translation_Loss:0.416	token_training_loss:0.0	distillation_Loss:0.3                                                   	MRR:26.44	Hits@10:46.69	Best:26.44
2025-01-04 19:20:43,983: Snapshot:1	Epoch:7	Loss:0.643	translation_Loss:0.368	token_training_loss:0.0	distillation_Loss:0.274                                                   	MRR:27.21	Hits@10:48.36	Best:27.21
2025-01-04 19:20:46,413: Snapshot:1	Epoch:8	Loss:0.598	translation_Loss:0.341	token_training_loss:0.0	distillation_Loss:0.256                                                   	MRR:27.94	Hits@10:49.43	Best:27.94
2025-01-04 19:20:48,640: Snapshot:1	Epoch:9	Loss:0.565	translation_Loss:0.321	token_training_loss:0.0	distillation_Loss:0.243                                                   	MRR:28.34	Hits@10:49.81	Best:28.34
2025-01-04 19:20:50,744: Snapshot:1	Epoch:10	Loss:0.533	translation_Loss:0.298	token_training_loss:0.0	distillation_Loss:0.235                                                   	MRR:28.8	Hits@10:50.08	Best:28.8
2025-01-04 19:20:53,461: Snapshot:1	Epoch:11	Loss:0.508	translation_Loss:0.279	token_training_loss:0.0	distillation_Loss:0.228                                                   	MRR:29.2	Hits@10:50.23	Best:29.2
2025-01-04 19:20:55,619: Snapshot:1	Epoch:12	Loss:0.488	translation_Loss:0.267	token_training_loss:0.0	distillation_Loss:0.221                                                   	MRR:29.26	Hits@10:50.41	Best:29.26
2025-01-04 19:20:58,087: Snapshot:1	Epoch:13	Loss:0.477	translation_Loss:0.263	token_training_loss:0.0	distillation_Loss:0.214                                                   	MRR:29.3	Hits@10:50.84	Best:29.3
2025-01-04 19:21:00,420: Snapshot:1	Epoch:14	Loss:0.459	translation_Loss:0.25	token_training_loss:0.0	distillation_Loss:0.209                                                   	MRR:29.71	Hits@10:50.73	Best:29.71
2025-01-04 19:21:02,542: Snapshot:1	Epoch:15	Loss:0.451	translation_Loss:0.245	token_training_loss:0.0	distillation_Loss:0.206                                                   	MRR:29.92	Hits@10:50.8	Best:29.92
2025-01-04 19:21:04,977: Snapshot:1	Epoch:16	Loss:0.439	translation_Loss:0.237	token_training_loss:0.0	distillation_Loss:0.202                                                   	MRR:29.75	Hits@10:50.97	Best:29.92
2025-01-04 19:21:07,741: Snapshot:1	Epoch:17	Loss:0.428	translation_Loss:0.229	token_training_loss:0.0	distillation_Loss:0.199                                                   	MRR:29.85	Hits@10:51.1	Best:29.92
2025-01-04 19:21:09,858: Snapshot:1	Epoch:18	Loss:0.42	translation_Loss:0.225	token_training_loss:0.0	distillation_Loss:0.195                                                   	MRR:29.97	Hits@10:51.14	Best:29.97
2025-01-04 19:21:12,222: Snapshot:1	Epoch:19	Loss:0.411	translation_Loss:0.217	token_training_loss:0.0	distillation_Loss:0.194                                                   	MRR:29.8	Hits@10:51.14	Best:29.97
2025-01-04 19:21:14,315: Snapshot:1	Epoch:20	Loss:0.406	translation_Loss:0.215	token_training_loss:0.0	distillation_Loss:0.192                                                   	MRR:29.8	Hits@10:51.27	Best:29.97
2025-01-04 19:21:16,407: Snapshot:1	Epoch:21	Loss:0.404	translation_Loss:0.215	token_training_loss:0.0	distillation_Loss:0.189                                                   	MRR:29.93	Hits@10:51.27	Best:29.97
2025-01-04 19:21:18,770: Snapshot:1	Epoch:22	Loss:0.4	translation_Loss:0.212	token_training_loss:0.0	distillation_Loss:0.188                                                   	MRR:29.78	Hits@10:51.27	Best:29.97
2025-01-04 19:21:21,046: Early Stopping! Snapshot: 1 Epoch: 23 Best Results: 29.97
2025-01-04 19:21:21,046: Start to training tokens! Snapshot: 1 Epoch: 23 Loss:0.394 MRR:29.93 Best Results: 29.97
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:21:21,047: Snapshot:1	Epoch:23	Loss:0.394	translation_Loss:0.206	token_training_loss:0.0	distillation_Loss:0.187                                                   	MRR:29.93	Hits@10:51.41	Best:29.97
2025-01-04 19:21:23,395: Snapshot:1	Epoch:24	Loss:16.147	translation_Loss:4.358	token_training_loss:11.789	distillation_Loss:0.0                                                   	MRR:29.93	Hits@10:51.41	Best:29.97
2025-01-04 19:21:25,420: End of token training: 1 Epoch: 25 Loss:6.989 MRR:29.93 Best Results: 29.97
2025-01-04 19:21:25,420: Snapshot:1	Epoch:25	Loss:6.989	translation_Loss:4.351	token_training_loss:2.638	distillation_Loss:0.0                                                           	MRR:29.93	Hits@10:51.41	Best:29.97
2025-01-04 19:21:25,661: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2025-01-04 19:21:29,112: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2584 | 0.1518 | 0.3141 | 0.3801 |  0.4538 |
|     1      | 0.2952 | 0.1878 | 0.3443 | 0.4187 |  0.5067 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:21:45,593: Snapshot:2	Epoch:0	Loss:15.841	translation_Loss:14.795	token_training_loss:0.0	distillation_Loss:1.046                                                   	MRR:14.2	Hits@10:29.12	Best:14.2
2025-01-04 19:21:54,952: Snapshot:2	Epoch:1	Loss:7.043	translation_Loss:5.571	token_training_loss:0.0	distillation_Loss:1.471                                                   	MRR:19.02	Hits@10:36.2	Best:19.02
2025-01-04 19:22:05,487: Snapshot:2	Epoch:2	Loss:4.601	translation_Loss:3.33	token_training_loss:0.0	distillation_Loss:1.271                                                   	MRR:20.63	Hits@10:37.78	Best:20.63
2025-01-04 19:22:14,995: Snapshot:2	Epoch:3	Loss:3.763	translation_Loss:2.635	token_training_loss:0.0	distillation_Loss:1.127                                                   	MRR:21.19	Hits@10:38.14	Best:21.19
2025-01-04 19:22:24,300: Snapshot:2	Epoch:4	Loss:3.428	translation_Loss:2.368	token_training_loss:0.0	distillation_Loss:1.06                                                   	MRR:21.41	Hits@10:38.09	Best:21.41
2025-01-04 19:22:34,688: Snapshot:2	Epoch:5	Loss:3.261	translation_Loss:2.236	token_training_loss:0.0	distillation_Loss:1.025                                                   	MRR:21.52	Hits@10:38.24	Best:21.52
2025-01-04 19:22:44,255: Snapshot:2	Epoch:6	Loss:3.166	translation_Loss:2.155	token_training_loss:0.0	distillation_Loss:1.011                                                   	MRR:21.44	Hits@10:38.16	Best:21.52
2025-01-04 19:22:54,798: Snapshot:2	Epoch:7	Loss:3.119	translation_Loss:2.12	token_training_loss:0.0	distillation_Loss:0.999                                                   	MRR:21.66	Hits@10:38.55	Best:21.66
2025-01-04 19:23:03,756: Snapshot:2	Epoch:8	Loss:3.063	translation_Loss:2.067	token_training_loss:0.0	distillation_Loss:0.996                                                   	MRR:21.62	Hits@10:38.49	Best:21.66
2025-01-04 19:23:14,425: Snapshot:2	Epoch:9	Loss:3.037	translation_Loss:2.045	token_training_loss:0.0	distillation_Loss:0.992                                                   	MRR:21.52	Hits@10:38.41	Best:21.66
2025-01-04 19:23:23,946: Snapshot:2	Epoch:10	Loss:3.017	translation_Loss:2.028	token_training_loss:0.0	distillation_Loss:0.989                                                   	MRR:21.89	Hits@10:38.47	Best:21.89
2025-01-04 19:23:32,847: Snapshot:2	Epoch:11	Loss:2.992	translation_Loss:2.007	token_training_loss:0.0	distillation_Loss:0.985                                                   	MRR:21.76	Hits@10:38.56	Best:21.89
2025-01-04 19:23:41,934: Snapshot:2	Epoch:12	Loss:2.988	translation_Loss:2.0	token_training_loss:0.0	distillation_Loss:0.988                                                   	MRR:21.64	Hits@10:38.43	Best:21.89
2025-01-04 19:23:52,539: Snapshot:2	Epoch:13	Loss:2.974	translation_Loss:1.985	token_training_loss:0.0	distillation_Loss:0.988                                                   	MRR:21.68	Hits@10:38.33	Best:21.89
2025-01-04 19:24:02,211: Snapshot:2	Epoch:14	Loss:2.959	translation_Loss:1.974	token_training_loss:0.0	distillation_Loss:0.985                                                   	MRR:21.58	Hits@10:38.35	Best:21.89
2025-01-04 19:24:12,691: Early Stopping! Snapshot: 2 Epoch: 15 Best Results: 21.89
2025-01-04 19:24:12,692: Start to training tokens! Snapshot: 2 Epoch: 15 Loss:2.963 MRR:21.47 Best Results: 21.89
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:24:12,692: Snapshot:2	Epoch:15	Loss:2.963	translation_Loss:1.978	token_training_loss:0.0	distillation_Loss:0.985                                                   	MRR:21.47	Hits@10:38.46	Best:21.89
2025-01-04 19:24:23,282: Snapshot:2	Epoch:16	Loss:32.288	translation_Loss:17.85	token_training_loss:14.438	distillation_Loss:0.0                                                   	MRR:21.47	Hits@10:38.46	Best:21.89
2025-01-04 19:24:32,550: End of token training: 2 Epoch: 17 Loss:17.98 MRR:21.47 Best Results: 21.89
2025-01-04 19:24:32,551: Snapshot:2	Epoch:17	Loss:17.98	translation_Loss:17.853	token_training_loss:0.127	distillation_Loss:0.0                                                           	MRR:21.47	Hits@10:38.46	Best:21.89
2025-01-04 19:24:32,800: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2025-01-04 19:24:40,312: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2518 | 0.1391 | 0.3112 | 0.3788 |  0.4579 |
|     1      | 0.2816 | 0.1752 | 0.3309 | 0.3987 |  0.4824 |
|     2      | 0.218  | 0.1315 | 0.2491 | 0.308  |  0.3883 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:24:59,574: Snapshot:3	Epoch:0	Loss:15.002	translation_Loss:13.532	token_training_loss:0.0	distillation_Loss:1.471                                                   	MRR:15.71	Hits@10:31.76	Best:15.71
2025-01-04 19:25:10,766: Snapshot:3	Epoch:1	Loss:6.58	translation_Loss:4.656	token_training_loss:0.0	distillation_Loss:1.923                                                   	MRR:19.73	Hits@10:36.97	Best:19.73
2025-01-04 19:25:23,581: Snapshot:3	Epoch:2	Loss:4.758	translation_Loss:3.142	token_training_loss:0.0	distillation_Loss:1.616                                                   	MRR:20.73	Hits@10:38.17	Best:20.73
2025-01-04 19:25:36,615: Snapshot:3	Epoch:3	Loss:4.154	translation_Loss:2.681	token_training_loss:0.0	distillation_Loss:1.473                                                   	MRR:21.08	Hits@10:38.32	Best:21.08
2025-01-04 19:25:47,802: Snapshot:3	Epoch:4	Loss:3.899	translation_Loss:2.5	token_training_loss:0.0	distillation_Loss:1.4                                                   	MRR:21.14	Hits@10:38.58	Best:21.14
2025-01-04 19:25:59,180: Snapshot:3	Epoch:5	Loss:3.763	translation_Loss:2.396	token_training_loss:0.0	distillation_Loss:1.367                                                   	MRR:21.3	Hits@10:38.41	Best:21.3
2025-01-04 19:26:12,037: Snapshot:3	Epoch:6	Loss:3.699	translation_Loss:2.359	token_training_loss:0.0	distillation_Loss:1.341                                                   	MRR:21.31	Hits@10:38.59	Best:21.31
2025-01-04 19:26:23,257: Snapshot:3	Epoch:7	Loss:3.647	translation_Loss:2.315	token_training_loss:0.0	distillation_Loss:1.332                                                   	MRR:21.27	Hits@10:38.55	Best:21.31
2025-01-04 19:26:36,071: Snapshot:3	Epoch:8	Loss:3.62	translation_Loss:2.29	token_training_loss:0.0	distillation_Loss:1.33                                                   	MRR:21.2	Hits@10:38.67	Best:21.31
2025-01-04 19:26:48,774: Snapshot:3	Epoch:9	Loss:3.595	translation_Loss:2.267	token_training_loss:0.0	distillation_Loss:1.328                                                   	MRR:21.32	Hits@10:38.4	Best:21.32
2025-01-04 19:27:01,624: Snapshot:3	Epoch:10	Loss:3.568	translation_Loss:2.25	token_training_loss:0.0	distillation_Loss:1.319                                                   	MRR:21.19	Hits@10:38.39	Best:21.32
2025-01-04 19:27:13,005: Snapshot:3	Epoch:11	Loss:3.571	translation_Loss:2.248	token_training_loss:0.0	distillation_Loss:1.322                                                   	MRR:21.25	Hits@10:38.57	Best:21.32
2025-01-04 19:27:25,686: Snapshot:3	Epoch:12	Loss:3.573	translation_Loss:2.242	token_training_loss:0.0	distillation_Loss:1.331                                                   	MRR:21.06	Hits@10:38.49	Best:21.32
2025-01-04 19:27:36,822: Snapshot:3	Epoch:13	Loss:3.542	translation_Loss:2.218	token_training_loss:0.0	distillation_Loss:1.325                                                   	MRR:21.13	Hits@10:38.39	Best:21.32
2025-01-04 19:27:49,231: Early Stopping! Snapshot: 3 Epoch: 14 Best Results: 21.32
2025-01-04 19:27:49,231: Start to training tokens! Snapshot: 3 Epoch: 14 Loss:3.52 MRR:21.19 Best Results: 21.32
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:27:49,231: Snapshot:3	Epoch:14	Loss:3.52	translation_Loss:2.203	token_training_loss:0.0	distillation_Loss:1.317                                                   	MRR:21.19	Hits@10:38.52	Best:21.32
2025-01-04 19:28:00,495: Snapshot:3	Epoch:15	Loss:34.572	translation_Loss:19.224	token_training_loss:15.348	distillation_Loss:0.0                                                   	MRR:21.19	Hits@10:38.52	Best:21.32
2025-01-04 19:28:13,386: End of token training: 3 Epoch: 16 Loss:19.305 MRR:21.19 Best Results: 21.32
2025-01-04 19:28:13,386: Snapshot:3	Epoch:16	Loss:19.305	translation_Loss:19.234	token_training_loss:0.071	distillation_Loss:0.0                                                           	MRR:21.19	Hits@10:38.52	Best:21.32
2025-01-04 19:28:13,628: => loading checkpoint './checkpoint/HYBRID/3model_best.tar'
2025-01-04 19:28:26,735: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2635 | 0.1579 | 0.3173 |  0.38  |  0.4603 |
|     1      | 0.2786 | 0.1747 | 0.3214 | 0.3863 |  0.4804 |
|     2      | 0.2144 | 0.1265 | 0.245  | 0.3033 |  0.3869 |
|     3      | 0.2109 | 0.1207 | 0.2442 | 0.3048 |  0.3827 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:28:37,180: Snapshot:4	Epoch:0	Loss:6.694	translation_Loss:6.157	token_training_loss:0.0	distillation_Loss:0.537                                                   	MRR:9.23	Hits@10:20.25	Best:9.23
2025-01-04 19:28:42,690: Snapshot:4	Epoch:1	Loss:4.428	translation_Loss:3.548	token_training_loss:0.0	distillation_Loss:0.88                                                   	MRR:15.34	Hits@10:32.73	Best:15.34
2025-01-04 19:28:47,389: Snapshot:4	Epoch:2	Loss:3.414	translation_Loss:2.513	token_training_loss:0.0	distillation_Loss:0.901                                                   	MRR:18.31	Hits@10:35.1	Best:18.31
2025-01-04 19:28:52,595: Snapshot:4	Epoch:3	Loss:2.846	translation_Loss:1.987	token_training_loss:0.0	distillation_Loss:0.859                                                   	MRR:20.71	Hits@10:35.89	Best:20.71
2025-01-04 19:28:57,520: Snapshot:4	Epoch:4	Loss:2.502	translation_Loss:1.696	token_training_loss:0.0	distillation_Loss:0.806                                                   	MRR:21.68	Hits@10:36.26	Best:21.68
2025-01-04 19:29:02,016: Snapshot:4	Epoch:5	Loss:2.27	translation_Loss:1.505	token_training_loss:0.0	distillation_Loss:0.765                                                   	MRR:22.11	Hits@10:36.33	Best:22.11
2025-01-04 19:29:07,213: Snapshot:4	Epoch:6	Loss:2.11	translation_Loss:1.376	token_training_loss:0.0	distillation_Loss:0.734                                                   	MRR:22.5	Hits@10:36.71	Best:22.5
2025-01-04 19:29:12,818: Snapshot:4	Epoch:7	Loss:2.015	translation_Loss:1.31	token_training_loss:0.0	distillation_Loss:0.705                                                   	MRR:22.44	Hits@10:36.98	Best:22.5
2025-01-04 19:29:17,332: Snapshot:4	Epoch:8	Loss:1.945	translation_Loss:1.257	token_training_loss:0.0	distillation_Loss:0.688                                                   	MRR:22.18	Hits@10:36.7	Best:22.5
2025-01-04 19:29:21,749: Snapshot:4	Epoch:9	Loss:1.912	translation_Loss:1.239	token_training_loss:0.0	distillation_Loss:0.673                                                   	MRR:22.11	Hits@10:36.55	Best:22.5
2025-01-04 19:29:27,207: Snapshot:4	Epoch:10	Loss:1.887	translation_Loss:1.224	token_training_loss:0.0	distillation_Loss:0.663                                                   	MRR:22.4	Hits@10:36.75	Best:22.5
2025-01-04 19:29:31,735: Early Stopping! Snapshot: 4 Epoch: 11 Best Results: 22.5
2025-01-04 19:29:31,736: Start to training tokens! Snapshot: 4 Epoch: 11 Loss:1.864 MRR:22.37 Best Results: 22.5
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:29:31,736: Snapshot:4	Epoch:11	Loss:1.864	translation_Loss:1.21	token_training_loss:0.0	distillation_Loss:0.655                                                   	MRR:22.37	Hits@10:36.54	Best:22.5
2025-01-04 19:29:36,163: Snapshot:4	Epoch:12	Loss:24.329	translation_Loss:9.266	token_training_loss:15.063	distillation_Loss:0.0                                                   	MRR:22.37	Hits@10:36.54	Best:22.5
2025-01-04 19:29:41,530: End of token training: 4 Epoch: 13 Loss:10.171 MRR:22.37 Best Results: 22.5
2025-01-04 19:29:41,530: Snapshot:4	Epoch:13	Loss:10.171	translation_Loss:9.256	token_training_loss:0.916	distillation_Loss:0.0                                                           	MRR:22.37	Hits@10:36.54	Best:22.5
2025-01-04 19:29:41,776: => loading checkpoint './checkpoint/HYBRID/4model_best.tar'
2025-01-04 19:29:57,177: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2279 | 0.1261 | 0.2758 | 0.3379 |  0.4157 |
|     1      | 0.2652 | 0.1638 | 0.3053 | 0.3685 |  0.4611 |
|     2      | 0.2016 | 0.1164 | 0.2302 | 0.2871 |  0.3686 |
|     3      | 0.1908 | 0.1026 | 0.2211 | 0.2811 |   0.36  |
|     4      | 0.2221 | 0.1467 | 0.2533 | 0.3034 |  0.365  |
+------------+--------+--------+--------+--------+---------+
2025-01-04 19:29:57,179: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2578 |  0.15  | 0.3161 |  0.38  |  0.4548 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2584 | 0.1518 | 0.3141 | 0.3801 |  0.4538 |
|     1      | 0.2952 | 0.1878 | 0.3443 | 0.4187 |  0.5067 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2518 | 0.1391 | 0.3112 | 0.3788 |  0.4579 |
|     1      | 0.2816 | 0.1752 | 0.3309 | 0.3987 |  0.4824 |
|     2      | 0.218  | 0.1315 | 0.2491 | 0.308  |  0.3883 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2635 | 0.1579 | 0.3173 |  0.38  |  0.4603 |
|     1      | 0.2786 | 0.1747 | 0.3214 | 0.3863 |  0.4804 |
|     2      | 0.2144 | 0.1265 | 0.245  | 0.3033 |  0.3869 |
|     3      | 0.2109 | 0.1207 | 0.2442 | 0.3048 |  0.3827 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2279 | 0.1261 | 0.2758 | 0.3379 |  0.4157 |
|     1      | 0.2652 | 0.1638 | 0.3053 | 0.3685 |  0.4611 |
|     2      | 0.2016 | 0.1164 | 0.2302 | 0.2871 |  0.3686 |
|     3      | 0.1908 | 0.1026 | 0.2211 | 0.2811 |   0.36  |
|     4      | 0.2221 | 0.1467 | 0.2533 | 0.3034 |  0.365  |
+------------+--------+--------+--------+--------+---------+]
2025-01-04 19:29:57,180: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 127.92186522483826 |   0.258   |     0.15     |    0.316     |     0.455     |
|    1     | 63.69902276992798  |   0.268   |    0.161     |    0.322     |     0.468     |
|    2     | 179.43257856369019 |   0.238   |     0.14     |    0.281     |     0.424     |
|    3     | 208.20053029060364 |   0.229   |    0.135     |    0.266     |     0.408     |
|    4     | 72.41057443618774  |    0.21   |    0.121     |    0.244     |      0.38     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-04 19:29:57,180: Sum_Training_Time:651.6645712852478
2025-01-04 19:29:57,180: Every_Training_Time:[127.92186522483826, 63.69902276992798, 179.43257856369019, 208.20053029060364, 72.41057443618774]
2025-01-04 19:29:57,180: Forward transfer: 0.043425000000000005 Backward transfer: -0.024100000000000003
2025-01-04 19:30:30,124: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250104193002/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[8000.0, 5000.0, 3000.0, 12000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-04 19:30:39,861: Snapshot:0	Epoch:0	Loss:15.399	translation_Loss:15.399	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.3	Hits@10:18.0	Best:7.3
2025-01-04 19:30:46,486: Snapshot:0	Epoch:1	Loss:10.741	translation_Loss:10.741	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.4	Hits@10:31.06	Best:12.4
2025-01-04 19:30:52,166: Snapshot:0	Epoch:2	Loss:7.011	translation_Loss:7.011	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.94	Hits@10:39.7	Best:18.94
2025-01-04 19:30:58,237: Snapshot:0	Epoch:3	Loss:4.124	translation_Loss:4.124	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.66	Hits@10:43.48	Best:22.66
2025-01-04 19:31:04,045: Snapshot:0	Epoch:4	Loss:2.462	translation_Loss:2.462	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.25	Hits@10:45.37	Best:24.25
2025-01-04 19:31:10,052: Snapshot:0	Epoch:5	Loss:1.562	translation_Loss:1.562	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.92	Hits@10:45.97	Best:24.92
2025-01-04 19:31:16,873: Snapshot:0	Epoch:6	Loss:1.068	translation_Loss:1.068	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.26	Hits@10:46.21	Best:25.26
2025-01-04 19:31:22,609: Snapshot:0	Epoch:7	Loss:0.8	translation_Loss:0.8	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.63	Hits@10:46.52	Best:25.63
2025-01-04 19:31:29,290: Snapshot:0	Epoch:8	Loss:0.632	translation_Loss:0.632	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.61	Hits@10:46.53	Best:25.63
2025-01-04 19:31:35,299: Snapshot:0	Epoch:9	Loss:0.535	translation_Loss:0.535	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.72	Hits@10:46.52	Best:25.72
2025-01-04 19:31:41,908: Snapshot:0	Epoch:10	Loss:0.456	translation_Loss:0.456	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.66	Hits@10:46.28	Best:25.72
2025-01-04 19:31:47,251: Snapshot:0	Epoch:11	Loss:0.402	translation_Loss:0.402	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.68	Hits@10:46.33	Best:25.72
2025-01-04 19:31:53,570: Snapshot:0	Epoch:12	Loss:0.356	translation_Loss:0.356	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:46.33	Best:25.79
2025-01-04 19:31:59,688: Snapshot:0	Epoch:13	Loss:0.317	translation_Loss:0.317	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:46.12	Best:25.79
2025-01-04 19:32:06,003: Snapshot:0	Epoch:14	Loss:0.293	translation_Loss:0.293	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.77	Hits@10:46.07	Best:25.79
2025-01-04 19:32:12,063: Snapshot:0	Epoch:15	Loss:0.271	translation_Loss:0.271	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.68	Hits@10:45.84	Best:25.79
2025-01-04 19:32:18,200: Snapshot:0	Epoch:16	Loss:0.252	translation_Loss:0.252	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.65	Hits@10:46.04	Best:25.79
2025-01-04 19:32:23,993: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 25.79
2025-01-04 19:32:23,993: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.235 MRR:25.61 Best Results: 25.79
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:32:23,994: Snapshot:0	Epoch:17	Loss:0.235	translation_Loss:0.235	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.61	Hits@10:45.94	Best:25.79
2025-01-04 19:32:30,137: Snapshot:0	Epoch:18	Loss:26.519	translation_Loss:11.52	token_training_loss:14.999	distillation_Loss:0.0                                                   	MRR:25.61	Hits@10:45.94	Best:25.79
2025-01-04 19:32:35,882: End of token training: 0 Epoch: 19 Loss:11.9 MRR:25.61 Best Results: 25.79
2025-01-04 19:32:35,883: Snapshot:0	Epoch:19	Loss:11.9	translation_Loss:11.527	token_training_loss:0.373	distillation_Loss:0.0                                                           	MRR:25.61	Hits@10:45.94	Best:25.79
2025-01-04 19:32:36,123: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2025-01-04 19:32:38,395: 
+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.258 | 0.1509 | 0.3143 | 0.3781 |  0.4533 |
+------------+-------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:32:45,466: Snapshot:1	Epoch:0	Loss:4.965	translation_Loss:4.767	token_training_loss:0.0	distillation_Loss:0.199                                                   	MRR:9.7	Hits@10:17.07	Best:9.7
2025-01-04 19:32:47,743: Snapshot:1	Epoch:1	Loss:3.049	translation_Loss:2.66	token_training_loss:0.0	distillation_Loss:0.389                                                   	MRR:16.61	Hits@10:30.63	Best:16.61
2025-01-04 19:32:49,862: Snapshot:1	Epoch:2	Loss:1.973	translation_Loss:1.509	token_training_loss:0.0	distillation_Loss:0.464                                                   	MRR:20.86	Hits@10:36.48	Best:20.86
2025-01-04 19:32:52,319: Snapshot:1	Epoch:3	Loss:1.401	translation_Loss:0.966	token_training_loss:0.0	distillation_Loss:0.435                                                   	MRR:23.51	Hits@10:40.75	Best:23.51
2025-01-04 19:32:54,466: Snapshot:1	Epoch:4	Loss:1.09	translation_Loss:0.721	token_training_loss:0.0	distillation_Loss:0.369                                                   	MRR:24.7	Hits@10:43.33	Best:24.7
2025-01-04 19:32:57,171: Snapshot:1	Epoch:5	Loss:0.913	translation_Loss:0.598	token_training_loss:0.0	distillation_Loss:0.315                                                   	MRR:25.6	Hits@10:45.75	Best:25.6
2025-01-04 19:32:59,365: Snapshot:1	Epoch:6	Loss:0.795	translation_Loss:0.516	token_training_loss:0.0	distillation_Loss:0.279                                                   	MRR:26.61	Hits@10:47.11	Best:26.61
2025-01-04 19:33:01,714: Snapshot:1	Epoch:7	Loss:0.718	translation_Loss:0.461	token_training_loss:0.0	distillation_Loss:0.257                                                   	MRR:27.25	Hits@10:48.29	Best:27.25
2025-01-04 19:33:03,933: Snapshot:1	Epoch:8	Loss:0.669	translation_Loss:0.424	token_training_loss:0.0	distillation_Loss:0.245                                                   	MRR:28.0	Hits@10:49.15	Best:28.0
2025-01-04 19:33:06,010: Snapshot:1	Epoch:9	Loss:0.636	translation_Loss:0.402	token_training_loss:0.0	distillation_Loss:0.234                                                   	MRR:28.25	Hits@10:49.81	Best:28.25
2025-01-04 19:33:08,482: Snapshot:1	Epoch:10	Loss:0.6	translation_Loss:0.376	token_training_loss:0.0	distillation_Loss:0.225                                                   	MRR:28.85	Hits@10:49.83	Best:28.85
2025-01-04 19:33:11,172: Snapshot:1	Epoch:11	Loss:0.573	translation_Loss:0.357	token_training_loss:0.0	distillation_Loss:0.216                                                   	MRR:29.0	Hits@10:50.01	Best:29.0
2025-01-04 19:33:13,487: Snapshot:1	Epoch:12	Loss:0.553	translation_Loss:0.343	token_training_loss:0.0	distillation_Loss:0.21                                                   	MRR:29.27	Hits@10:50.32	Best:29.27
2025-01-04 19:33:15,690: Snapshot:1	Epoch:13	Loss:0.54	translation_Loss:0.333	token_training_loss:0.0	distillation_Loss:0.206                                                   	MRR:29.64	Hits@10:50.48	Best:29.64
2025-01-04 19:33:18,051: Snapshot:1	Epoch:14	Loss:0.521	translation_Loss:0.32	token_training_loss:0.0	distillation_Loss:0.201                                                   	MRR:29.71	Hits@10:50.35	Best:29.71
2025-01-04 19:33:20,470: Snapshot:1	Epoch:15	Loss:0.51	translation_Loss:0.313	token_training_loss:0.0	distillation_Loss:0.197                                                   	MRR:29.79	Hits@10:50.6	Best:29.79
2025-01-04 19:33:22,775: Snapshot:1	Epoch:16	Loss:0.496	translation_Loss:0.303	token_training_loss:0.0	distillation_Loss:0.193                                                   	MRR:29.67	Hits@10:50.42	Best:29.79
2025-01-04 19:33:25,303: Snapshot:1	Epoch:17	Loss:0.486	translation_Loss:0.296	token_training_loss:0.0	distillation_Loss:0.19                                                   	MRR:29.75	Hits@10:50.61	Best:29.79
2025-01-04 19:33:27,338: Snapshot:1	Epoch:18	Loss:0.477	translation_Loss:0.29	token_training_loss:0.0	distillation_Loss:0.187                                                   	MRR:29.76	Hits@10:50.93	Best:29.79
2025-01-04 19:33:29,769: Snapshot:1	Epoch:19	Loss:0.468	translation_Loss:0.282	token_training_loss:0.0	distillation_Loss:0.186                                                   	MRR:29.81	Hits@10:50.91	Best:29.81
2025-01-04 19:33:32,052: Snapshot:1	Epoch:20	Loss:0.462	translation_Loss:0.279	token_training_loss:0.0	distillation_Loss:0.184                                                   	MRR:30.14	Hits@10:51.17	Best:30.14
2025-01-04 19:33:34,163: Snapshot:1	Epoch:21	Loss:0.46	translation_Loss:0.28	token_training_loss:0.0	distillation_Loss:0.18                                                   	MRR:30.02	Hits@10:51.05	Best:30.14
2025-01-04 19:33:36,607: Snapshot:1	Epoch:22	Loss:0.456	translation_Loss:0.277	token_training_loss:0.0	distillation_Loss:0.179                                                   	MRR:29.82	Hits@10:51.11	Best:30.14
2025-01-04 19:33:38,778: Snapshot:1	Epoch:23	Loss:0.449	translation_Loss:0.271	token_training_loss:0.0	distillation_Loss:0.178                                                   	MRR:29.84	Hits@10:51.05	Best:30.14
2025-01-04 19:33:41,146: Snapshot:1	Epoch:24	Loss:0.439	translation_Loss:0.263	token_training_loss:0.0	distillation_Loss:0.177                                                   	MRR:30.03	Hits@10:51.15	Best:30.14
2025-01-04 19:33:43,224: Snapshot:1	Epoch:25	Loss:0.44	translation_Loss:0.265	token_training_loss:0.0	distillation_Loss:0.175                                                   	MRR:30.23	Hits@10:51.19	Best:30.23
2025-01-04 19:33:45,362: Snapshot:1	Epoch:26	Loss:0.435	translation_Loss:0.26	token_training_loss:0.0	distillation_Loss:0.174                                                   	MRR:30.36	Hits@10:51.44	Best:30.36
2025-01-04 19:33:47,782: Snapshot:1	Epoch:27	Loss:0.434	translation_Loss:0.262	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:30.27	Hits@10:50.95	Best:30.36
2025-01-04 19:33:49,974: Snapshot:1	Epoch:28	Loss:0.427	translation_Loss:0.255	token_training_loss:0.0	distillation_Loss:0.172                                                   	MRR:30.27	Hits@10:51.1	Best:30.36
2025-01-04 19:33:52,355: Snapshot:1	Epoch:29	Loss:0.425	translation_Loss:0.253	token_training_loss:0.0	distillation_Loss:0.172                                                   	MRR:30.08	Hits@10:51.01	Best:30.36
2025-01-04 19:33:54,945: Snapshot:1	Epoch:30	Loss:0.428	translation_Loss:0.257	token_training_loss:0.0	distillation_Loss:0.171                                                   	MRR:30.04	Hits@10:50.99	Best:30.36
2025-01-04 19:33:57,255: Early Stopping! Snapshot: 1 Epoch: 31 Best Results: 30.36
2025-01-04 19:33:57,255: Start to training tokens! Snapshot: 1 Epoch: 31 Loss:0.426 MRR:30.32 Best Results: 30.36
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:33:57,255: Snapshot:1	Epoch:31	Loss:0.426	translation_Loss:0.256	token_training_loss:0.0	distillation_Loss:0.17                                                   	MRR:30.32	Hits@10:51.38	Best:30.36
2025-01-04 19:33:59,534: Snapshot:1	Epoch:32	Loss:16.233	translation_Loss:4.444	token_training_loss:11.789	distillation_Loss:0.0                                                   	MRR:30.32	Hits@10:51.38	Best:30.36
2025-01-04 19:34:01,934: End of token training: 1 Epoch: 33 Loss:7.076 MRR:30.32 Best Results: 30.36
2025-01-04 19:34:01,934: Snapshot:1	Epoch:33	Loss:7.076	translation_Loss:4.438	token_training_loss:2.638	distillation_Loss:0.0                                                           	MRR:30.32	Hits@10:51.38	Best:30.36
2025-01-04 19:34:02,189: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2025-01-04 19:34:06,108: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2584 | 0.1514 | 0.3163 | 0.3811 |  0.453  |
|     1      | 0.2964 | 0.1899 | 0.3446 | 0.4176 |  0.5083 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:34:22,734: Snapshot:2	Epoch:0	Loss:16.083	translation_Loss:14.873	token_training_loss:0.0	distillation_Loss:1.21                                                   	MRR:13.83	Hits@10:28.55	Best:13.83
2025-01-04 19:34:33,349: Snapshot:2	Epoch:1	Loss:7.55	translation_Loss:6.092	token_training_loss:0.0	distillation_Loss:1.458                                                   	MRR:18.91	Hits@10:35.66	Best:18.91
2025-01-04 19:34:42,795: Snapshot:2	Epoch:2	Loss:5.027	translation_Loss:3.85	token_training_loss:0.0	distillation_Loss:1.178                                                   	MRR:20.29	Hits@10:37.21	Best:20.29
2025-01-04 19:34:52,560: Snapshot:2	Epoch:3	Loss:4.153	translation_Loss:3.118	token_training_loss:0.0	distillation_Loss:1.035                                                   	MRR:20.98	Hits@10:37.68	Best:20.98
2025-01-04 19:35:02,931: Snapshot:2	Epoch:4	Loss:3.791	translation_Loss:2.818	token_training_loss:0.0	distillation_Loss:0.974                                                   	MRR:21.04	Hits@10:37.86	Best:21.04
2025-01-04 19:35:13,633: Snapshot:2	Epoch:5	Loss:3.636	translation_Loss:2.692	token_training_loss:0.0	distillation_Loss:0.944                                                   	MRR:21.26	Hits@10:37.92	Best:21.26
2025-01-04 19:35:23,188: Snapshot:2	Epoch:6	Loss:3.536	translation_Loss:2.604	token_training_loss:0.0	distillation_Loss:0.932                                                   	MRR:21.26	Hits@10:37.92	Best:21.26
2025-01-04 19:35:33,458: Snapshot:2	Epoch:7	Loss:3.471	translation_Loss:2.551	token_training_loss:0.0	distillation_Loss:0.92                                                   	MRR:21.51	Hits@10:37.96	Best:21.51
2025-01-04 19:35:42,929: Snapshot:2	Epoch:8	Loss:3.433	translation_Loss:2.516	token_training_loss:0.0	distillation_Loss:0.918                                                   	MRR:21.45	Hits@10:37.97	Best:21.51
2025-01-04 19:35:52,180: Snapshot:2	Epoch:9	Loss:3.405	translation_Loss:2.489	token_training_loss:0.0	distillation_Loss:0.916                                                   	MRR:21.41	Hits@10:38.06	Best:21.51
2025-01-04 19:36:02,645: Snapshot:2	Epoch:10	Loss:3.379	translation_Loss:2.465	token_training_loss:0.0	distillation_Loss:0.914                                                   	MRR:21.32	Hits@10:37.92	Best:21.51
2025-01-04 19:36:11,455: Snapshot:2	Epoch:11	Loss:3.36	translation_Loss:2.45	token_training_loss:0.0	distillation_Loss:0.91                                                   	MRR:21.33	Hits@10:38.05	Best:21.51
2025-01-04 19:36:22,022: Early Stopping! Snapshot: 2 Epoch: 12 Best Results: 21.51
2025-01-04 19:36:22,023: Start to training tokens! Snapshot: 2 Epoch: 12 Loss:3.351 MRR:21.34 Best Results: 21.51
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:36:22,023: Snapshot:2	Epoch:12	Loss:3.351	translation_Loss:2.436	token_training_loss:0.0	distillation_Loss:0.914                                                   	MRR:21.34	Hits@10:38.18	Best:21.51
2025-01-04 19:36:31,347: Snapshot:2	Epoch:13	Loss:32.673	translation_Loss:18.235	token_training_loss:14.438	distillation_Loss:0.0                                                   	MRR:21.34	Hits@10:38.18	Best:21.51
2025-01-04 19:36:40,171: End of token training: 2 Epoch: 14 Loss:18.35 MRR:21.34 Best Results: 21.51
2025-01-04 19:36:40,171: Snapshot:2	Epoch:14	Loss:18.35	translation_Loss:18.223	token_training_loss:0.127	distillation_Loss:0.0                                                           	MRR:21.34	Hits@10:38.18	Best:21.51
2025-01-04 19:36:40,414: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2025-01-04 19:36:48,041: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2553 | 0.145  | 0.3125 | 0.3788 |  0.459  |
|     1      | 0.2803 | 0.1756 | 0.3225 | 0.3941 |  0.4867 |
|     2      | 0.2145 | 0.1288 | 0.2463 | 0.3033 |  0.3827 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:37:08,879: Snapshot:3	Epoch:0	Loss:15.171	translation_Loss:13.696	token_training_loss:0.0	distillation_Loss:1.474                                                   	MRR:15.7	Hits@10:31.72	Best:15.7
2025-01-04 19:37:20,186: Snapshot:3	Epoch:1	Loss:6.771	translation_Loss:4.808	token_training_loss:0.0	distillation_Loss:1.963                                                   	MRR:19.75	Hits@10:37.16	Best:19.75
2025-01-04 19:37:32,634: Snapshot:3	Epoch:2	Loss:4.947	translation_Loss:3.277	token_training_loss:0.0	distillation_Loss:1.67                                                   	MRR:20.84	Hits@10:38.22	Best:20.84
2025-01-04 19:37:44,102: Snapshot:3	Epoch:3	Loss:4.34	translation_Loss:2.804	token_training_loss:0.0	distillation_Loss:1.536                                                   	MRR:21.02	Hits@10:38.28	Best:21.02
2025-01-04 19:37:55,162: Snapshot:3	Epoch:4	Loss:4.081	translation_Loss:2.618	token_training_loss:0.0	distillation_Loss:1.463                                                   	MRR:21.25	Hits@10:38.65	Best:21.25
2025-01-04 19:38:08,091: Snapshot:3	Epoch:5	Loss:3.935	translation_Loss:2.511	token_training_loss:0.0	distillation_Loss:1.424                                                   	MRR:21.34	Hits@10:38.67	Best:21.34
2025-01-04 19:38:19,941: Snapshot:3	Epoch:6	Loss:3.86	translation_Loss:2.46	token_training_loss:0.0	distillation_Loss:1.401                                                   	MRR:21.39	Hits@10:38.59	Best:21.39
2025-01-04 19:38:31,221: Snapshot:3	Epoch:7	Loss:3.808	translation_Loss:2.418	token_training_loss:0.0	distillation_Loss:1.39                                                   	MRR:21.26	Hits@10:38.64	Best:21.39
2025-01-04 19:38:43,539: Snapshot:3	Epoch:8	Loss:3.787	translation_Loss:2.396	token_training_loss:0.0	distillation_Loss:1.391                                                   	MRR:21.3	Hits@10:38.53	Best:21.39
2025-01-04 19:38:54,887: Snapshot:3	Epoch:9	Loss:3.752	translation_Loss:2.371	token_training_loss:0.0	distillation_Loss:1.381                                                   	MRR:21.43	Hits@10:38.74	Best:21.43
2025-01-04 19:39:07,638: Snapshot:3	Epoch:10	Loss:3.741	translation_Loss:2.357	token_training_loss:0.0	distillation_Loss:1.384                                                   	MRR:21.26	Hits@10:38.43	Best:21.43
2025-01-04 19:39:18,937: Snapshot:3	Epoch:11	Loss:3.728	translation_Loss:2.346	token_training_loss:0.0	distillation_Loss:1.382                                                   	MRR:21.2	Hits@10:38.55	Best:21.43
2025-01-04 19:39:29,939: Snapshot:3	Epoch:12	Loss:3.717	translation_Loss:2.332	token_training_loss:0.0	distillation_Loss:1.384                                                   	MRR:21.15	Hits@10:38.49	Best:21.43
2025-01-04 19:39:40,917: Snapshot:3	Epoch:13	Loss:3.71	translation_Loss:2.326	token_training_loss:0.0	distillation_Loss:1.384                                                   	MRR:21.17	Hits@10:38.46	Best:21.43
2025-01-04 19:39:51,895: Early Stopping! Snapshot: 3 Epoch: 14 Best Results: 21.43
2025-01-04 19:39:51,895: Start to training tokens! Snapshot: 3 Epoch: 14 Loss:3.701 MRR:21.14 Best Results: 21.43
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:39:51,895: Snapshot:3	Epoch:14	Loss:3.701	translation_Loss:2.316	token_training_loss:0.0	distillation_Loss:1.385                                                   	MRR:21.14	Hits@10:38.51	Best:21.43
2025-01-04 19:40:03,274: Snapshot:3	Epoch:15	Loss:34.628	translation_Loss:19.28	token_training_loss:15.348	distillation_Loss:0.0                                                   	MRR:21.14	Hits@10:38.51	Best:21.43
2025-01-04 19:40:14,441: End of token training: 3 Epoch: 16 Loss:19.344 MRR:21.14 Best Results: 21.43
2025-01-04 19:40:14,441: Snapshot:3	Epoch:16	Loss:19.344	translation_Loss:19.274	token_training_loss:0.071	distillation_Loss:0.0                                                           	MRR:21.14	Hits@10:38.51	Best:21.43
2025-01-04 19:40:14,692: => loading checkpoint './checkpoint/HYBRID/3model_best.tar'
2025-01-04 19:40:26,667: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2634 | 0.1583 | 0.3144 | 0.3802 |  0.4603 |
|     1      | 0.285  |  0.18  | 0.3274 | 0.3946 |  0.4951 |
|     2      | 0.2125 | 0.1257 | 0.2428 | 0.3022 |  0.3836 |
|     3      | 0.2126 | 0.1218 | 0.247  | 0.3084 |  0.3858 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:40:37,644: Snapshot:4	Epoch:0	Loss:6.793	translation_Loss:6.215	token_training_loss:0.0	distillation_Loss:0.578                                                   	MRR:9.58	Hits@10:20.57	Best:9.58
2025-01-04 19:40:42,523: Snapshot:4	Epoch:1	Loss:4.597	translation_Loss:3.707	token_training_loss:0.0	distillation_Loss:0.89                                                   	MRR:15.44	Hits@10:32.75	Best:15.44
2025-01-04 19:40:48,069: Snapshot:4	Epoch:2	Loss:3.591	translation_Loss:2.703	token_training_loss:0.0	distillation_Loss:0.888                                                   	MRR:19.37	Hits@10:35.14	Best:19.37
2025-01-04 19:40:52,749: Snapshot:4	Epoch:3	Loss:3.011	translation_Loss:2.176	token_training_loss:0.0	distillation_Loss:0.835                                                   	MRR:21.03	Hits@10:36.0	Best:21.03
2025-01-04 19:40:57,712: Snapshot:4	Epoch:4	Loss:2.662	translation_Loss:1.876	token_training_loss:0.0	distillation_Loss:0.786                                                   	MRR:21.94	Hits@10:36.54	Best:21.94
2025-01-04 19:41:02,633: Snapshot:4	Epoch:5	Loss:2.411	translation_Loss:1.662	token_training_loss:0.0	distillation_Loss:0.749                                                   	MRR:22.43	Hits@10:36.83	Best:22.43
2025-01-04 19:41:07,812: Snapshot:4	Epoch:6	Loss:2.256	translation_Loss:1.54	token_training_loss:0.0	distillation_Loss:0.715                                                   	MRR:22.49	Hits@10:37.03	Best:22.49
2025-01-04 19:41:12,461: Snapshot:4	Epoch:7	Loss:2.156	translation_Loss:1.464	token_training_loss:0.0	distillation_Loss:0.692                                                   	MRR:22.36	Hits@10:36.67	Best:22.49
2025-01-04 19:41:17,182: Snapshot:4	Epoch:8	Loss:2.108	translation_Loss:1.433	token_training_loss:0.0	distillation_Loss:0.675                                                   	MRR:22.53	Hits@10:36.44	Best:22.53
2025-01-04 19:41:22,188: Snapshot:4	Epoch:9	Loss:2.056	translation_Loss:1.395	token_training_loss:0.0	distillation_Loss:0.662                                                   	MRR:22.31	Hits@10:36.54	Best:22.53
2025-01-04 19:41:26,870: Snapshot:4	Epoch:10	Loss:2.027	translation_Loss:1.377	token_training_loss:0.0	distillation_Loss:0.651                                                   	MRR:22.24	Hits@10:36.55	Best:22.53
2025-01-04 19:41:31,667: Snapshot:4	Epoch:11	Loss:2.013	translation_Loss:1.369	token_training_loss:0.0	distillation_Loss:0.644                                                   	MRR:22.41	Hits@10:36.54	Best:22.53
2025-01-04 19:41:36,726: Snapshot:4	Epoch:12	Loss:1.995	translation_Loss:1.357	token_training_loss:0.0	distillation_Loss:0.638                                                   	MRR:22.42	Hits@10:36.72	Best:22.53
2025-01-04 19:41:41,224: Early Stopping! Snapshot: 4 Epoch: 13 Best Results: 22.53
2025-01-04 19:41:41,224: Start to training tokens! Snapshot: 4 Epoch: 13 Loss:1.979 MRR:22.17 Best Results: 22.53
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:41:41,224: Snapshot:4	Epoch:13	Loss:1.979	translation_Loss:1.348	token_training_loss:0.0	distillation_Loss:0.631                                                   	MRR:22.17	Hits@10:36.36	Best:22.53
2025-01-04 19:41:45,971: Snapshot:4	Epoch:14	Loss:24.492	translation_Loss:9.429	token_training_loss:15.063	distillation_Loss:0.0                                                   	MRR:22.17	Hits@10:36.36	Best:22.53
2025-01-04 19:41:50,949: End of token training: 4 Epoch: 15 Loss:10.349 MRR:22.17 Best Results: 22.53
2025-01-04 19:41:50,950: Snapshot:4	Epoch:15	Loss:10.349	translation_Loss:9.433	token_training_loss:0.916	distillation_Loss:0.0                                                           	MRR:22.17	Hits@10:36.36	Best:22.53
2025-01-04 19:41:51,192: => loading checkpoint './checkpoint/HYBRID/4model_best.tar'
2025-01-04 19:42:06,846: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2319 | 0.1288 | 0.2814 | 0.3427 |  0.4201 |
|     1      | 0.2773 | 0.1764 | 0.3195 | 0.381  |  0.4745 |
|     2      | 0.2028 | 0.1182 | 0.2296 | 0.2895 |  0.3686 |
|     3      | 0.197  | 0.1087 | 0.228  | 0.2884 |  0.3674 |
|     4      | 0.2279 | 0.1532 |  0.26  | 0.3086 |  0.3689 |
+------------+--------+--------+--------+--------+---------+
2025-01-04 19:42:06,848: Final Result:
[+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.258 | 0.1509 | 0.3143 | 0.3781 |  0.4533 |
+------------+-------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2584 | 0.1514 | 0.3163 | 0.3811 |  0.453  |
|     1      | 0.2964 | 0.1899 | 0.3446 | 0.4176 |  0.5083 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2553 | 0.145  | 0.3125 | 0.3788 |  0.459  |
|     1      | 0.2803 | 0.1756 | 0.3225 | 0.3941 |  0.4867 |
|     2      | 0.2145 | 0.1288 | 0.2463 | 0.3033 |  0.3827 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2634 | 0.1583 | 0.3144 | 0.3802 |  0.4603 |
|     1      | 0.285  |  0.18  | 0.3274 | 0.3946 |  0.4951 |
|     2      | 0.2125 | 0.1257 | 0.2428 | 0.3022 |  0.3836 |
|     3      | 0.2126 | 0.1218 | 0.247  | 0.3084 |  0.3858 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2319 | 0.1288 | 0.2814 | 0.3427 |  0.4201 |
|     1      | 0.2773 | 0.1764 | 0.3195 | 0.381  |  0.4745 |
|     2      | 0.2028 | 0.1182 | 0.2296 | 0.2895 |  0.3686 |
|     3      | 0.197  | 0.1087 | 0.228  | 0.2884 |  0.3674 |
|     4      | 0.2279 | 0.1532 |  0.26  | 0.3086 |  0.3689 |
+------------+--------+--------+--------+--------+---------+]
2025-01-04 19:42:06,849: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 125.75746726989746 |   0.258   |    0.151     |    0.314     |     0.453     |
|    1     | 82.39230036735535  |   0.269   |    0.162     |    0.324     |     0.468     |
|    2     | 150.02056217193604 |   0.237   |     0.14     |    0.279     |     0.422     |
|    3     | 201.74389743804932 |   0.229   |    0.135     |    0.266     |     0.409     |
|    4     | 82.03883790969849  |   0.215   |    0.125     |    0.249     |     0.385     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-04 19:42:06,849: Sum_Training_Time:641.9530651569366
2025-01-04 19:42:06,849: Every_Training_Time:[125.75746726989746, 82.39230036735535, 150.02056217193604, 201.74389743804932, 82.03883790969849]
2025-01-04 19:42:06,849: Forward transfer: 0.044024999999999995 Backward transfer: -0.018125000000000002
