2025-01-07 18:01:14,761: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FB_CKGE/', dataset='FB_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250107180055/FB_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=1111, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FB_CKGE', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 10000.0, 10000.0, 20000.0], token_num=9, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-07 18:01:37,140: Snapshot:0	Epoch:0	Loss:44.077	translation_Loss:44.077	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.73	Hits@10:34.23	Best:14.73
2025-01-07 18:01:55,064: Snapshot:0	Epoch:1	Loss:18.848	translation_Loss:18.848	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.45	Hits@10:44.75	Best:23.45
2025-01-07 18:02:12,931: Snapshot:0	Epoch:2	Loss:7.308	translation_Loss:7.308	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.01	Hits@10:46.35	Best:25.01
2025-01-07 18:02:30,844: Snapshot:0	Epoch:3	Loss:3.706	translation_Loss:3.706	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.38	Hits@10:46.33	Best:25.38
2025-01-07 18:02:49,262: Snapshot:0	Epoch:4	Loss:2.369	translation_Loss:2.369	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.43	Hits@10:46.24	Best:25.43
2025-01-07 18:03:07,049: Snapshot:0	Epoch:5	Loss:1.731	translation_Loss:1.731	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.47	Hits@10:45.82	Best:25.47
2025-01-07 18:03:25,114: Snapshot:0	Epoch:6	Loss:1.407	translation_Loss:1.407	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.3	Hits@10:45.87	Best:25.47
2025-01-07 18:03:43,019: Snapshot:0	Epoch:7	Loss:1.204	translation_Loss:1.204	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.16	Hits@10:45.58	Best:25.47
2025-01-07 18:04:00,802: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 25.47
2025-01-07 18:04:00,802: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:1.059 MRR:24.95 Best Results: 25.47
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:04:00,803: Snapshot:0	Epoch:8	Loss:1.059	translation_Loss:1.059	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.95	Hits@10:45.45	Best:25.47
2025-01-07 18:04:19,220: Snapshot:0	Epoch:9	Loss:53.162	translation_Loss:35.685	token_training_loss:17.477	distillation_Loss:0.0                                                   	MRR:24.95	Hits@10:45.45	Best:25.47
2025-01-07 18:04:37,478: End of token training: 0 Epoch: 10 Loss:35.694 MRR:24.95 Best Results: 25.47
2025-01-07 18:04:37,478: Snapshot:0	Epoch:10	Loss:35.694	translation_Loss:35.691	token_training_loss:0.003	distillation_Loss:0.0                                                           	MRR:24.95	Hits@10:45.45	Best:25.47
2025-01-07 18:04:37,774: => loading checkpoint './checkpoint/FB_CKGE/0model_best.tar'
2025-01-07 18:04:43,696: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2536 | 0.1477 | 0.2971 | 0.3674 |  0.4593 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (1,501,000)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 1,599,400
Trainable params: 3,600
Non-trainable params: 1,595,800
=================================================================
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:04:53,423: Snapshot:1	Epoch:0	Loss:6.558	translation_Loss:6.192	token_training_loss:0.0	distillation_Loss:0.366                                                   	MRR:10.05	Hits@10:19.44	Best:10.05
2025-01-07 18:04:56,713: Snapshot:1	Epoch:1	Loss:3.274	translation_Loss:2.956	token_training_loss:0.0	distillation_Loss:0.318                                                   	MRR:12.97	Hits@10:23.49	Best:12.97
2025-01-07 18:05:00,292: Snapshot:1	Epoch:2	Loss:1.57	translation_Loss:1.348	token_training_loss:0.0	distillation_Loss:0.222                                                   	MRR:14.39	Hits@10:26.04	Best:14.39
2025-01-07 18:05:04,260: Snapshot:1	Epoch:3	Loss:0.851	translation_Loss:0.711	token_training_loss:0.0	distillation_Loss:0.141                                                   	MRR:15.27	Hits@10:28.03	Best:15.27
2025-01-07 18:05:07,675: Snapshot:1	Epoch:4	Loss:0.564	translation_Loss:0.472	token_training_loss:0.0	distillation_Loss:0.092                                                   	MRR:16.0	Hits@10:29.64	Best:16.0
2025-01-07 18:05:11,001: Snapshot:1	Epoch:5	Loss:0.42	translation_Loss:0.35	token_training_loss:0.0	distillation_Loss:0.07                                                   	MRR:16.48	Hits@10:30.71	Best:16.48
2025-01-07 18:05:14,358: Snapshot:1	Epoch:6	Loss:0.352	translation_Loss:0.29	token_training_loss:0.0	distillation_Loss:0.062                                                   	MRR:16.71	Hits@10:31.09	Best:16.71
2025-01-07 18:05:17,778: Snapshot:1	Epoch:7	Loss:0.307	translation_Loss:0.25	token_training_loss:0.0	distillation_Loss:0.057                                                   	MRR:16.93	Hits@10:31.41	Best:16.93
2025-01-07 18:05:21,517: Snapshot:1	Epoch:8	Loss:0.281	translation_Loss:0.228	token_training_loss:0.0	distillation_Loss:0.054                                                   	MRR:17.0	Hits@10:31.85	Best:17.0
2025-01-07 18:05:24,924: Snapshot:1	Epoch:9	Loss:0.255	translation_Loss:0.202	token_training_loss:0.0	distillation_Loss:0.053                                                   	MRR:17.26	Hits@10:32.18	Best:17.26
2025-01-07 18:05:28,231: Snapshot:1	Epoch:10	Loss:0.25	translation_Loss:0.198	token_training_loss:0.0	distillation_Loss:0.052                                                   	MRR:17.38	Hits@10:32.3	Best:17.38
2025-01-07 18:05:31,535: Snapshot:1	Epoch:11	Loss:0.229	translation_Loss:0.179	token_training_loss:0.0	distillation_Loss:0.05                                                   	MRR:17.51	Hits@10:32.17	Best:17.51
2025-01-07 18:05:34,839: Snapshot:1	Epoch:12	Loss:0.222	translation_Loss:0.173	token_training_loss:0.0	distillation_Loss:0.049                                                   	MRR:17.47	Hits@10:32.61	Best:17.51
2025-01-07 18:05:38,542: Snapshot:1	Epoch:13	Loss:0.209	translation_Loss:0.162	token_training_loss:0.0	distillation_Loss:0.047                                                   	MRR:17.54	Hits@10:32.8	Best:17.54
2025-01-07 18:05:41,918: Snapshot:1	Epoch:14	Loss:0.203	translation_Loss:0.156	token_training_loss:0.0	distillation_Loss:0.047                                                   	MRR:17.56	Hits@10:32.96	Best:17.56
2025-01-07 18:05:45,215: Snapshot:1	Epoch:15	Loss:0.197	translation_Loss:0.15	token_training_loss:0.0	distillation_Loss:0.047                                                   	MRR:17.8	Hits@10:33.2	Best:17.8
2025-01-07 18:05:48,522: Snapshot:1	Epoch:16	Loss:0.188	translation_Loss:0.14	token_training_loss:0.0	distillation_Loss:0.048                                                   	MRR:17.79	Hits@10:33.35	Best:17.8
2025-01-07 18:05:51,918: Snapshot:1	Epoch:17	Loss:0.19	translation_Loss:0.143	token_training_loss:0.0	distillation_Loss:0.047                                                   	MRR:17.82	Hits@10:33.0	Best:17.82
2025-01-07 18:05:55,651: Snapshot:1	Epoch:18	Loss:0.183	translation_Loss:0.138	token_training_loss:0.0	distillation_Loss:0.045                                                   	MRR:17.91	Hits@10:33.31	Best:17.91
2025-01-07 18:05:58,966: Snapshot:1	Epoch:19	Loss:0.181	translation_Loss:0.135	token_training_loss:0.0	distillation_Loss:0.046                                                   	MRR:17.93	Hits@10:33.42	Best:17.93
2025-01-07 18:06:02,385: Snapshot:1	Epoch:20	Loss:0.179	translation_Loss:0.134	token_training_loss:0.0	distillation_Loss:0.045                                                   	MRR:17.94	Hits@10:33.46	Best:17.94
2025-01-07 18:06:05,840: Snapshot:1	Epoch:21	Loss:0.173	translation_Loss:0.127	token_training_loss:0.0	distillation_Loss:0.046                                                   	MRR:17.99	Hits@10:33.52	Best:17.99
2025-01-07 18:06:09,141: Snapshot:1	Epoch:22	Loss:0.167	translation_Loss:0.122	token_training_loss:0.0	distillation_Loss:0.045                                                   	MRR:17.98	Hits@10:33.67	Best:17.99
2025-01-07 18:06:12,976: Snapshot:1	Epoch:23	Loss:0.172	translation_Loss:0.127	token_training_loss:0.0	distillation_Loss:0.045                                                   	MRR:18.01	Hits@10:33.76	Best:18.01
2025-01-07 18:06:16,321: Snapshot:1	Epoch:24	Loss:0.167	translation_Loss:0.122	token_training_loss:0.0	distillation_Loss:0.045                                                   	MRR:18.05	Hits@10:33.59	Best:18.05
2025-01-07 18:06:19,748: Snapshot:1	Epoch:25	Loss:0.163	translation_Loss:0.119	token_training_loss:0.0	distillation_Loss:0.044                                                   	MRR:18.06	Hits@10:33.8	Best:18.06
2025-01-07 18:06:23,024: Snapshot:1	Epoch:26	Loss:0.16	translation_Loss:0.115	token_training_loss:0.0	distillation_Loss:0.045                                                   	MRR:18.03	Hits@10:33.84	Best:18.06
2025-01-07 18:06:26,320: Snapshot:1	Epoch:27	Loss:0.165	translation_Loss:0.119	token_training_loss:0.0	distillation_Loss:0.045                                                   	MRR:18.14	Hits@10:34.01	Best:18.14
2025-01-07 18:06:30,113: Snapshot:1	Epoch:28	Loss:0.153	translation_Loss:0.11	token_training_loss:0.0	distillation_Loss:0.043                                                   	MRR:18.2	Hits@10:33.97	Best:18.2
2025-01-07 18:06:33,400: Snapshot:1	Epoch:29	Loss:0.159	translation_Loss:0.116	token_training_loss:0.0	distillation_Loss:0.044                                                   	MRR:18.25	Hits@10:34.06	Best:18.25
2025-01-07 18:06:36,680: Snapshot:1	Epoch:30	Loss:0.16	translation_Loss:0.115	token_training_loss:0.0	distillation_Loss:0.045                                                   	MRR:18.16	Hits@10:33.97	Best:18.25
2025-01-07 18:06:40,008: Snapshot:1	Epoch:31	Loss:0.163	translation_Loss:0.116	token_training_loss:0.0	distillation_Loss:0.047                                                   	MRR:18.15	Hits@10:33.97	Best:18.25
2025-01-07 18:06:43,312: Early Stopping! Snapshot: 1 Epoch: 32 Best Results: 18.25
2025-01-07 18:06:43,312: Start to training tokens! Snapshot: 1 Epoch: 32 Loss:0.155 MRR:18.21 Best Results: 18.25
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:06:43,313: Snapshot:1	Epoch:32	Loss:0.155	translation_Loss:0.109	token_training_loss:0.0	distillation_Loss:0.047                                                   	MRR:18.21	Hits@10:34.07	Best:18.25
2025-01-07 18:06:46,929: Snapshot:1	Epoch:33	Loss:21.27	translation_Loss:6.076	token_training_loss:15.194	distillation_Loss:0.0                                                   	MRR:18.21	Hits@10:34.07	Best:18.25
2025-01-07 18:06:50,148: End of token training: 1 Epoch: 34 Loss:8.226 MRR:18.21 Best Results: 18.25
2025-01-07 18:06:50,149: Snapshot:1	Epoch:34	Loss:8.226	translation_Loss:6.077	token_training_loss:2.149	distillation_Loss:0.0                                                           	MRR:18.21	Hits@10:34.07	Best:18.25
2025-01-07 18:06:50,461: => loading checkpoint './checkpoint/FB_CKGE/1model_best.tar'
2025-01-07 18:06:58,510: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2537 | 0.1483 | 0.2974 | 0.3667 |  0.4585 |
|     1      | 0.1892 | 0.1116 | 0.2132 | 0.2677 |  0.3427 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,251,600)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,350,000
Trainable params: 3,600
Non-trainable params: 2,346,400
=================================================================
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:07:08,254: Snapshot:2	Epoch:0	Loss:4.292	translation_Loss:3.891	token_training_loss:0.0	distillation_Loss:0.401                                                   	MRR:18.48	Hits@10:33.57	Best:18.48
2025-01-07 18:07:12,155: Snapshot:2	Epoch:1	Loss:2.207	translation_Loss:1.796	token_training_loss:0.0	distillation_Loss:0.411                                                   	MRR:19.21	Hits@10:34.37	Best:19.21
2025-01-07 18:07:15,666: Snapshot:2	Epoch:2	Loss:1.306	translation_Loss:1.016	token_training_loss:0.0	distillation_Loss:0.291                                                   	MRR:19.72	Hits@10:34.96	Best:19.72
2025-01-07 18:07:19,156: Snapshot:2	Epoch:3	Loss:0.94	translation_Loss:0.706	token_training_loss:0.0	distillation_Loss:0.234                                                   	MRR:19.81	Hits@10:35.11	Best:19.81
2025-01-07 18:07:22,750: Snapshot:2	Epoch:4	Loss:0.81	translation_Loss:0.604	token_training_loss:0.0	distillation_Loss:0.206                                                   	MRR:19.97	Hits@10:35.29	Best:19.97
2025-01-07 18:07:26,233: Snapshot:2	Epoch:5	Loss:0.751	translation_Loss:0.55	token_training_loss:0.0	distillation_Loss:0.202                                                   	MRR:19.93	Hits@10:35.25	Best:19.97
2025-01-07 18:07:30,234: Snapshot:2	Epoch:6	Loss:0.712	translation_Loss:0.521	token_training_loss:0.0	distillation_Loss:0.191                                                   	MRR:19.89	Hits@10:35.54	Best:19.97
2025-01-07 18:07:33,687: Snapshot:2	Epoch:7	Loss:0.684	translation_Loss:0.496	token_training_loss:0.0	distillation_Loss:0.188                                                   	MRR:19.98	Hits@10:35.55	Best:19.98
2025-01-07 18:07:37,141: Snapshot:2	Epoch:8	Loss:0.683	translation_Loss:0.492	token_training_loss:0.0	distillation_Loss:0.191                                                   	MRR:19.96	Hits@10:35.47	Best:19.98
2025-01-07 18:07:40,598: Snapshot:2	Epoch:9	Loss:0.674	translation_Loss:0.48	token_training_loss:0.0	distillation_Loss:0.194                                                   	MRR:20.07	Hits@10:35.59	Best:20.07
2025-01-07 18:07:44,019: Snapshot:2	Epoch:10	Loss:0.659	translation_Loss:0.471	token_training_loss:0.0	distillation_Loss:0.188                                                   	MRR:20.07	Hits@10:35.53	Best:20.07
2025-01-07 18:07:47,861: Snapshot:2	Epoch:11	Loss:0.656	translation_Loss:0.465	token_training_loss:0.0	distillation_Loss:0.19                                                   	MRR:19.98	Hits@10:35.53	Best:20.07
2025-01-07 18:07:51,294: Early Stopping! Snapshot: 2 Epoch: 12 Best Results: 20.07
2025-01-07 18:07:51,295: Start to training tokens! Snapshot: 2 Epoch: 12 Loss:0.663 MRR:19.89 Best Results: 20.07
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:07:51,295: Snapshot:2	Epoch:12	Loss:0.663	translation_Loss:0.471	token_training_loss:0.0	distillation_Loss:0.192                                                   	MRR:19.89	Hits@10:35.39	Best:20.07
2025-01-07 18:07:54,717: Snapshot:2	Epoch:13	Loss:21.162	translation_Loss:6.334	token_training_loss:14.828	distillation_Loss:0.0                                                   	MRR:19.89	Hits@10:35.39	Best:20.07
2025-01-07 18:07:58,054: End of token training: 2 Epoch: 14 Loss:8.278 MRR:19.89 Best Results: 20.07
2025-01-07 18:07:58,054: Snapshot:2	Epoch:14	Loss:8.278	translation_Loss:6.334	token_training_loss:1.944	distillation_Loss:0.0                                                           	MRR:19.89	Hits@10:35.39	Best:20.07
2025-01-07 18:07:58,359: => loading checkpoint './checkpoint/FB_CKGE/2model_best.tar'
2025-01-07 18:08:08,485: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2525 | 0.147  | 0.2953 | 0.3658 |  0.4578 |
|     1      | 0.1916 | 0.1131 | 0.2138 | 0.272  |  0.3502 |
|     2      | 0.2008 | 0.1209 | 0.2287 | 0.2824 |  0.355  |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,626,800)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,725,200
Trainable params: 3,600
Non-trainable params: 2,721,600
=================================================================
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:08:18,423: Snapshot:3	Epoch:0	Loss:2.703	translation_Loss:2.293	token_training_loss:0.0	distillation_Loss:0.41                                                   	MRR:20.84	Hits@10:36.53	Best:20.84
2025-01-07 18:08:22,069: Snapshot:3	Epoch:1	Loss:1.651	translation_Loss:1.205	token_training_loss:0.0	distillation_Loss:0.447                                                   	MRR:21.06	Hits@10:36.64	Best:21.06
2025-01-07 18:08:25,737: Snapshot:3	Epoch:2	Loss:1.226	translation_Loss:0.89	token_training_loss:0.0	distillation_Loss:0.336                                                   	MRR:21.32	Hits@10:36.89	Best:21.32
2025-01-07 18:08:29,707: Snapshot:3	Epoch:3	Loss:0.995	translation_Loss:0.692	token_training_loss:0.0	distillation_Loss:0.303                                                   	MRR:21.3	Hits@10:36.88	Best:21.32
2025-01-07 18:08:33,192: Snapshot:3	Epoch:4	Loss:0.929	translation_Loss:0.645	token_training_loss:0.0	distillation_Loss:0.284                                                   	MRR:21.14	Hits@10:36.94	Best:21.32
2025-01-07 18:08:36,710: Early Stopping! Snapshot: 3 Epoch: 5 Best Results: 21.32
2025-01-07 18:08:36,710: Start to training tokens! Snapshot: 3 Epoch: 5 Loss:0.897 MRR:21.32 Best Results: 21.32
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:08:36,711: Snapshot:3	Epoch:5	Loss:0.897	translation_Loss:0.612	token_training_loss:0.0	distillation_Loss:0.285                                                   	MRR:21.32	Hits@10:37.0	Best:21.32
2025-01-07 18:08:40,231: Snapshot:3	Epoch:6	Loss:21.482	translation_Loss:6.463	token_training_loss:15.02	distillation_Loss:0.0                                                   	MRR:21.32	Hits@10:37.0	Best:21.32
2025-01-07 18:08:43,750: End of token training: 3 Epoch: 7 Loss:8.56 MRR:21.32 Best Results: 21.32
2025-01-07 18:08:43,750: Snapshot:3	Epoch:7	Loss:8.56	translation_Loss:6.46	token_training_loss:2.099	distillation_Loss:0.0                                                           	MRR:21.32	Hits@10:37.0	Best:21.32
2025-01-07 18:08:44,103: => loading checkpoint './checkpoint/FB_CKGE/3model_best.tar'
2025-01-07 18:08:56,213: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2509 | 0.145  | 0.2943 | 0.3645 |  0.4561 |
|     1      | 0.1939 | 0.1127 | 0.2181 | 0.277  |  0.3568 |
|     2      | 0.2034 | 0.121  | 0.2331 | 0.2889 |  0.3631 |
|     3      | 0.2109 | 0.1293 | 0.2431 | 0.2964 |  0.3643 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,814,400)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,912,800
Trainable params: 3,600
Non-trainable params: 2,909,200
=================================================================
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:09:06,522: Snapshot:4	Epoch:0	Loss:1.855	translation_Loss:1.33	token_training_loss:0.0	distillation_Loss:0.525                                                   	MRR:22.83	Hits@10:38.29	Best:22.83
2025-01-07 18:09:10,201: Snapshot:4	Epoch:1	Loss:1.412	translation_Loss:1.029	token_training_loss:0.0	distillation_Loss:0.383                                                   	MRR:22.91	Hits@10:38.03	Best:22.91
2025-01-07 18:09:14,229: Snapshot:4	Epoch:2	Loss:1.22	translation_Loss:0.929	token_training_loss:0.0	distillation_Loss:0.291                                                   	MRR:22.9	Hits@10:38.35	Best:22.91
2025-01-07 18:09:17,830: Snapshot:4	Epoch:3	Loss:1.125	translation_Loss:0.842	token_training_loss:0.0	distillation_Loss:0.283                                                   	MRR:22.96	Hits@10:38.28	Best:22.96
2025-01-07 18:09:21,385: Snapshot:4	Epoch:4	Loss:1.093	translation_Loss:0.816	token_training_loss:0.0	distillation_Loss:0.278                                                   	MRR:22.83	Hits@10:38.25	Best:22.96
2025-01-07 18:09:25,046: Snapshot:4	Epoch:5	Loss:1.081	translation_Loss:0.804	token_training_loss:0.0	distillation_Loss:0.277                                                   	MRR:22.96	Hits@10:38.42	Best:22.96
2025-01-07 18:09:28,585: Early Stopping! Snapshot: 4 Epoch: 6 Best Results: 22.96
2025-01-07 18:09:28,586: Start to training tokens! Snapshot: 4 Epoch: 6 Loss:1.073 MRR:22.87 Best Results: 22.96
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:09:28,586: Snapshot:4	Epoch:6	Loss:1.073	translation_Loss:0.8	token_training_loss:0.0	distillation_Loss:0.273                                                   	MRR:22.87	Hits@10:38.46	Best:22.96
2025-01-07 18:09:32,493: Snapshot:4	Epoch:7	Loss:21.862	translation_Loss:6.631	token_training_loss:15.231	distillation_Loss:0.0                                                   	MRR:22.87	Hits@10:38.46	Best:22.96
2025-01-07 18:09:36,008: End of token training: 4 Epoch: 8 Loss:8.692 MRR:22.87 Best Results: 22.96
2025-01-07 18:09:36,009: Snapshot:4	Epoch:8	Loss:8.692	translation_Loss:6.631	token_training_loss:2.061	distillation_Loss:0.0                                                           	MRR:22.87	Hits@10:38.46	Best:22.96
2025-01-07 18:09:36,252: => loading checkpoint './checkpoint/FB_CKGE/4model_best.tar'
2025-01-07 18:09:50,168: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2507 | 0.1454 | 0.2936 | 0.3637 |  0.455  |
|     1      | 0.1958 | 0.1132 | 0.2199 | 0.2792 |  0.3595 |
|     2      | 0.2057 | 0.124  | 0.2346 | 0.2906 |  0.3658 |
|     3      | 0.2125 | 0.1307 | 0.2447 | 0.2975 |  0.3693 |
|     4      | 0.2343 | 0.1419 | 0.2742 | 0.3324 |  0.4114 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,908,200)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 3,006,600
Trainable params: 3,600
Non-trainable params: 3,003,000
=================================================================
2025-01-07 18:09:50,171: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2536 | 0.1477 | 0.2971 | 0.3674 |  0.4593 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2537 | 0.1483 | 0.2974 | 0.3667 |  0.4585 |
|     1      | 0.1892 | 0.1116 | 0.2132 | 0.2677 |  0.3427 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2525 | 0.147  | 0.2953 | 0.3658 |  0.4578 |
|     1      | 0.1916 | 0.1131 | 0.2138 | 0.272  |  0.3502 |
|     2      | 0.2008 | 0.1209 | 0.2287 | 0.2824 |  0.355  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2509 | 0.145  | 0.2943 | 0.3645 |  0.4561 |
|     1      | 0.1939 | 0.1127 | 0.2181 | 0.277  |  0.3568 |
|     2      | 0.2034 | 0.121  | 0.2331 | 0.2889 |  0.3631 |
|     3      | 0.2109 | 0.1293 | 0.2431 | 0.2964 |  0.3643 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2507 | 0.1454 | 0.2936 | 0.3637 |  0.455  |
|     1      | 0.1958 | 0.1132 | 0.2199 | 0.2792 |  0.3595 |
|     2      | 0.2057 | 0.124  | 0.2346 | 0.2906 |  0.3658 |
|     3      | 0.2125 | 0.1307 | 0.2447 | 0.2975 |  0.3693 |
|     4      | 0.2343 | 0.1419 | 0.2742 | 0.3324 |  0.4114 |
+------------+--------+--------+--------+--------+---------+]
2025-01-07 18:09:50,172: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 202.71648240089417 |   0.254   |    0.148     |    0.297     |     0.459     |
|    1     | 124.39982032775879 |   0.244   |    0.143     |    0.285     |     0.442     |
|    2     | 57.65815258026123  |   0.238   |    0.139     |    0.277     |     0.431     |
|    3     | 33.28335428237915  |   0.235   |    0.137     |    0.273     |     0.425     |
|    4     | 37.478482246398926 |   0.235   |    0.138     |    0.273     |     0.424     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-07 18:09:50,172: Sum_Training_Time:455.53629183769226
2025-01-07 18:09:50,172: Every_Training_Time:[202.71648240089417, 124.39982032775879, 57.65815258026123, 33.28335428237915, 37.478482246398926]
2025-01-07 18:09:50,172: Forward transfer: 0.16135 Backward transfer: 0.0025499999999999898
2025-01-07 18:10:13,380: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FB_CKGE/', dataset='FB_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250107180954/FB_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=2222, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FB_CKGE', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 10000.0, 10000.0, 20000.0], token_num=9, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-07 18:10:35,699: Snapshot:0	Epoch:0	Loss:43.779	translation_Loss:43.779	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.0	Hits@10:34.65	Best:15.0
2025-01-07 18:10:53,818: Snapshot:0	Epoch:1	Loss:18.633	translation_Loss:18.633	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.39	Hits@10:44.78	Best:23.39
2025-01-07 18:11:11,765: Snapshot:0	Epoch:2	Loss:7.226	translation_Loss:7.226	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.16	Hits@10:46.55	Best:25.16
2025-01-07 18:11:29,664: Snapshot:0	Epoch:3	Loss:3.667	translation_Loss:3.667	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.61	Hits@10:46.8	Best:25.61
2025-01-07 18:11:48,370: Snapshot:0	Epoch:4	Loss:2.363	translation_Loss:2.363	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.56	Hits@10:46.46	Best:25.61
2025-01-07 18:12:06,282: Snapshot:0	Epoch:5	Loss:1.752	translation_Loss:1.752	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.36	Hits@10:46.25	Best:25.61
2025-01-07 18:12:24,275: Early Stopping! Snapshot: 0 Epoch: 6 Best Results: 25.61
2025-01-07 18:12:24,276: Start to training tokens! Snapshot: 0 Epoch: 6 Loss:1.425 MRR:25.2 Best Results: 25.61
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:12:24,276: Snapshot:0	Epoch:6	Loss:1.425	translation_Loss:1.425	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.2	Hits@10:45.9	Best:25.61
2025-01-07 18:12:43,003: Snapshot:0	Epoch:7	Loss:53.806	translation_Loss:36.092	token_training_loss:17.714	distillation_Loss:0.0                                                   	MRR:25.2	Hits@10:45.9	Best:25.61
2025-01-07 18:13:01,050: End of token training: 0 Epoch: 8 Loss:36.079 MRR:25.2 Best Results: 25.61
2025-01-07 18:13:01,050: Snapshot:0	Epoch:8	Loss:36.079	translation_Loss:36.076	token_training_loss:0.003	distillation_Loss:0.0                                                           	MRR:25.2	Hits@10:45.9	Best:25.61
2025-01-07 18:13:01,348: => loading checkpoint './checkpoint/FB_CKGE/0model_best.tar'
2025-01-07 18:13:07,516: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2542 | 0.146  | 0.2991 | 0.3727 |  0.4675 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (1,501,000)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 1,599,400
Trainable params: 3,600
Non-trainable params: 1,595,800
=================================================================
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:13:17,342: Snapshot:1	Epoch:0	Loss:6.61	translation_Loss:6.237	token_training_loss:0.0	distillation_Loss:0.373                                                   	MRR:10.12	Hits@10:19.97	Best:10.12
2025-01-07 18:13:20,779: Snapshot:1	Epoch:1	Loss:3.449	translation_Loss:3.122	token_training_loss:0.0	distillation_Loss:0.327                                                   	MRR:12.86	Hits@10:24.02	Best:12.86
2025-01-07 18:13:24,134: Snapshot:1	Epoch:2	Loss:1.774	translation_Loss:1.536	token_training_loss:0.0	distillation_Loss:0.238                                                   	MRR:14.53	Hits@10:27.02	Best:14.53
2025-01-07 18:13:27,965: Snapshot:1	Epoch:3	Loss:1.035	translation_Loss:0.875	token_training_loss:0.0	distillation_Loss:0.16                                                   	MRR:15.64	Hits@10:29.45	Best:15.64
2025-01-07 18:13:31,573: Snapshot:1	Epoch:4	Loss:0.705	translation_Loss:0.595	token_training_loss:0.0	distillation_Loss:0.11                                                   	MRR:16.28	Hits@10:30.7	Best:16.28
2025-01-07 18:13:35,014: Snapshot:1	Epoch:5	Loss:0.551	translation_Loss:0.464	token_training_loss:0.0	distillation_Loss:0.087                                                   	MRR:16.91	Hits@10:31.54	Best:16.91
2025-01-07 18:13:38,341: Snapshot:1	Epoch:6	Loss:0.466	translation_Loss:0.388	token_training_loss:0.0	distillation_Loss:0.078                                                   	MRR:17.27	Hits@10:32.27	Best:17.27
2025-01-07 18:13:41,792: Snapshot:1	Epoch:7	Loss:0.404	translation_Loss:0.332	token_training_loss:0.0	distillation_Loss:0.072                                                   	MRR:17.38	Hits@10:32.59	Best:17.38
2025-01-07 18:13:45,489: Snapshot:1	Epoch:8	Loss:0.37	translation_Loss:0.301	token_training_loss:0.0	distillation_Loss:0.069                                                   	MRR:17.56	Hits@10:33.05	Best:17.56
2025-01-07 18:13:48,812: Snapshot:1	Epoch:9	Loss:0.348	translation_Loss:0.282	token_training_loss:0.0	distillation_Loss:0.066                                                   	MRR:17.7	Hits@10:33.26	Best:17.7
2025-01-07 18:13:52,208: Snapshot:1	Epoch:10	Loss:0.325	translation_Loss:0.258	token_training_loss:0.0	distillation_Loss:0.067                                                   	MRR:17.68	Hits@10:33.44	Best:17.7
2025-01-07 18:13:55,506: Snapshot:1	Epoch:11	Loss:0.307	translation_Loss:0.243	token_training_loss:0.0	distillation_Loss:0.064                                                   	MRR:17.9	Hits@10:33.57	Best:17.9
2025-01-07 18:13:58,978: Snapshot:1	Epoch:12	Loss:0.289	translation_Loss:0.228	token_training_loss:0.0	distillation_Loss:0.062                                                   	MRR:18.0	Hits@10:33.69	Best:18.0
2025-01-07 18:14:02,772: Snapshot:1	Epoch:13	Loss:0.281	translation_Loss:0.221	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:17.84	Hits@10:33.8	Best:18.0
2025-01-07 18:14:06,097: Snapshot:1	Epoch:14	Loss:0.279	translation_Loss:0.216	token_training_loss:0.0	distillation_Loss:0.063                                                   	MRR:18.07	Hits@10:33.88	Best:18.07
2025-01-07 18:14:09,430: Snapshot:1	Epoch:15	Loss:0.271	translation_Loss:0.209	token_training_loss:0.0	distillation_Loss:0.062                                                   	MRR:18.09	Hits@10:34.01	Best:18.09
2025-01-07 18:14:12,813: Snapshot:1	Epoch:16	Loss:0.258	translation_Loss:0.195	token_training_loss:0.0	distillation_Loss:0.063                                                   	MRR:18.14	Hits@10:33.58	Best:18.14
2025-01-07 18:14:16,139: Snapshot:1	Epoch:17	Loss:0.255	translation_Loss:0.194	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:18.15	Hits@10:33.95	Best:18.15
2025-01-07 18:14:19,891: Snapshot:1	Epoch:18	Loss:0.248	translation_Loss:0.186	token_training_loss:0.0	distillation_Loss:0.061                                                   	MRR:18.1	Hits@10:33.95	Best:18.15
2025-01-07 18:14:23,135: Snapshot:1	Epoch:19	Loss:0.249	translation_Loss:0.189	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:18.1	Hits@10:34.0	Best:18.15
2025-01-07 18:14:26,453: Snapshot:1	Epoch:20	Loss:0.24	translation_Loss:0.18	token_training_loss:0.0	distillation_Loss:0.061                                                   	MRR:18.29	Hits@10:34.0	Best:18.29
2025-01-07 18:14:29,786: Snapshot:1	Epoch:21	Loss:0.239	translation_Loss:0.178	token_training_loss:0.0	distillation_Loss:0.061                                                   	MRR:18.17	Hits@10:33.97	Best:18.29
2025-01-07 18:14:33,065: Snapshot:1	Epoch:22	Loss:0.234	translation_Loss:0.176	token_training_loss:0.0	distillation_Loss:0.058                                                   	MRR:18.19	Hits@10:34.26	Best:18.29
2025-01-07 18:14:36,850: Snapshot:1	Epoch:23	Loss:0.233	translation_Loss:0.173	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:18.41	Hits@10:34.21	Best:18.41
2025-01-07 18:14:40,210: Snapshot:1	Epoch:24	Loss:0.228	translation_Loss:0.168	token_training_loss:0.0	distillation_Loss:0.061                                                   	MRR:18.19	Hits@10:34.09	Best:18.41
2025-01-07 18:14:43,551: Snapshot:1	Epoch:25	Loss:0.231	translation_Loss:0.171	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:18.31	Hits@10:33.97	Best:18.41
2025-01-07 18:14:46,826: Early Stopping! Snapshot: 1 Epoch: 26 Best Results: 18.41
2025-01-07 18:14:46,826: Start to training tokens! Snapshot: 1 Epoch: 26 Loss:0.222 MRR:18.38 Best Results: 18.41
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:14:46,827: Snapshot:1	Epoch:26	Loss:0.222	translation_Loss:0.163	token_training_loss:0.0	distillation_Loss:0.059                                                   	MRR:18.38	Hits@10:33.96	Best:18.41
2025-01-07 18:14:50,136: Snapshot:1	Epoch:27	Loss:21.338	translation_Loss:6.168	token_training_loss:15.17	distillation_Loss:0.0                                                   	MRR:18.38	Hits@10:33.96	Best:18.41
2025-01-07 18:14:53,777: End of token training: 1 Epoch: 28 Loss:8.179 MRR:18.38 Best Results: 18.41
2025-01-07 18:14:53,778: Snapshot:1	Epoch:28	Loss:8.179	translation_Loss:6.172	token_training_loss:2.006	distillation_Loss:0.0                                                           	MRR:18.38	Hits@10:33.96	Best:18.41
2025-01-07 18:14:54,086: => loading checkpoint './checkpoint/FB_CKGE/1model_best.tar'
2025-01-07 18:15:02,046: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2536 | 0.1456 | 0.2987 | 0.3716 |  0.4655 |
|     1      | 0.1911 | 0.1118 | 0.215  | 0.2683 |  0.3491 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,251,600)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,350,000
Trainable params: 3,600
Non-trainable params: 2,346,400
=================================================================
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:15:12,044: Snapshot:2	Epoch:0	Loss:4.484	translation_Loss:4.069	token_training_loss:0.0	distillation_Loss:0.414                                                   	MRR:18.67	Hits@10:34.09	Best:18.67
2025-01-07 18:15:15,509: Snapshot:2	Epoch:1	Loss:2.449	translation_Loss:1.999	token_training_loss:0.0	distillation_Loss:0.45                                                   	MRR:19.49	Hits@10:34.92	Best:19.49
2025-01-07 18:15:19,018: Snapshot:2	Epoch:2	Loss:1.56	translation_Loss:1.23	token_training_loss:0.0	distillation_Loss:0.329                                                   	MRR:19.84	Hits@10:35.43	Best:19.84
2025-01-07 18:15:22,664: Snapshot:2	Epoch:3	Loss:1.176	translation_Loss:0.898	token_training_loss:0.0	distillation_Loss:0.278                                                   	MRR:19.92	Hits@10:35.88	Best:19.92
2025-01-07 18:15:26,732: Snapshot:2	Epoch:4	Loss:1.033	translation_Loss:0.786	token_training_loss:0.0	distillation_Loss:0.247                                                   	MRR:20.04	Hits@10:35.95	Best:20.04
2025-01-07 18:15:30,228: Snapshot:2	Epoch:5	Loss:0.962	translation_Loss:0.718	token_training_loss:0.0	distillation_Loss:0.243                                                   	MRR:20.08	Hits@10:36.09	Best:20.08
2025-01-07 18:15:33,768: Snapshot:2	Epoch:6	Loss:0.915	translation_Loss:0.683	token_training_loss:0.0	distillation_Loss:0.233                                                   	MRR:20.2	Hits@10:36.14	Best:20.2
2025-01-07 18:15:37,179: Snapshot:2	Epoch:7	Loss:0.884	translation_Loss:0.654	token_training_loss:0.0	distillation_Loss:0.231                                                   	MRR:20.16	Hits@10:36.07	Best:20.2
2025-01-07 18:15:40,719: Snapshot:2	Epoch:8	Loss:0.864	translation_Loss:0.637	token_training_loss:0.0	distillation_Loss:0.228                                                   	MRR:20.24	Hits@10:36.11	Best:20.24
2025-01-07 18:15:44,536: Snapshot:2	Epoch:9	Loss:0.855	translation_Loss:0.625	token_training_loss:0.0	distillation_Loss:0.23                                                   	MRR:20.16	Hits@10:36.13	Best:20.24
2025-01-07 18:15:47,946: Snapshot:2	Epoch:10	Loss:0.848	translation_Loss:0.619	token_training_loss:0.0	distillation_Loss:0.229                                                   	MRR:20.18	Hits@10:36.21	Best:20.24
2025-01-07 18:15:51,355: Early Stopping! Snapshot: 2 Epoch: 11 Best Results: 20.24
2025-01-07 18:15:51,355: Start to training tokens! Snapshot: 2 Epoch: 11 Loss:0.842 MRR:20.07 Best Results: 20.24
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:15:51,355: Snapshot:2	Epoch:11	Loss:0.842	translation_Loss:0.611	token_training_loss:0.0	distillation_Loss:0.232                                                   	MRR:20.07	Hits@10:36.25	Best:20.24
2025-01-07 18:15:54,702: Snapshot:2	Epoch:12	Loss:21.601	translation_Loss:6.437	token_training_loss:15.164	distillation_Loss:0.0                                                   	MRR:20.07	Hits@10:36.25	Best:20.24
2025-01-07 18:15:58,047: End of token training: 2 Epoch: 13 Loss:8.572 MRR:20.07 Best Results: 20.24
2025-01-07 18:15:58,047: Snapshot:2	Epoch:13	Loss:8.572	translation_Loss:6.439	token_training_loss:2.132	distillation_Loss:0.0                                                           	MRR:20.07	Hits@10:36.25	Best:20.24
2025-01-07 18:15:58,359: => loading checkpoint './checkpoint/FB_CKGE/2model_best.tar'
2025-01-07 18:16:08,459: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2523 | 0.1444 | 0.2966 | 0.371  |  0.465  |
|     1      | 0.1937 | 0.1127 | 0.2183 | 0.2739 |  0.355  |
|     2      | 0.2008 | 0.118  | 0.2299 | 0.2892 |  0.3642 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,626,800)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,725,200
Trainable params: 3,600
Non-trainable params: 2,721,600
=================================================================
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:16:18,507: Snapshot:3	Epoch:0	Loss:2.946	translation_Loss:2.511	token_training_loss:0.0	distillation_Loss:0.435                                                   	MRR:21.13	Hits@10:37.06	Best:21.13
2025-01-07 18:16:22,186: Snapshot:3	Epoch:1	Loss:1.876	translation_Loss:1.37	token_training_loss:0.0	distillation_Loss:0.506                                                   	MRR:21.27	Hits@10:37.05	Best:21.27
2025-01-07 18:16:25,834: Snapshot:3	Epoch:2	Loss:1.482	translation_Loss:1.097	token_training_loss:0.0	distillation_Loss:0.385                                                   	MRR:21.5	Hits@10:37.62	Best:21.5
2025-01-07 18:16:29,963: Snapshot:3	Epoch:3	Loss:1.23	translation_Loss:0.876	token_training_loss:0.0	distillation_Loss:0.354                                                   	MRR:21.52	Hits@10:37.6	Best:21.52
2025-01-07 18:16:33,540: Snapshot:3	Epoch:4	Loss:1.166	translation_Loss:0.833	token_training_loss:0.0	distillation_Loss:0.333                                                   	MRR:21.63	Hits@10:37.56	Best:21.63
2025-01-07 18:16:37,054: Snapshot:3	Epoch:5	Loss:1.114	translation_Loss:0.781	token_training_loss:0.0	distillation_Loss:0.333                                                   	MRR:21.42	Hits@10:37.43	Best:21.63
2025-01-07 18:16:40,623: Snapshot:3	Epoch:6	Loss:1.11	translation_Loss:0.781	token_training_loss:0.0	distillation_Loss:0.329                                                   	MRR:21.62	Hits@10:37.51	Best:21.63
2025-01-07 18:16:44,259: Early Stopping! Snapshot: 3 Epoch: 7 Best Results: 21.63
2025-01-07 18:16:44,259: Start to training tokens! Snapshot: 3 Epoch: 7 Loss:1.085 MRR:21.41 Best Results: 21.63
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:16:44,259: Snapshot:3	Epoch:7	Loss:1.085	translation_Loss:0.753	token_training_loss:0.0	distillation_Loss:0.332                                                   	MRR:21.41	Hits@10:37.56	Best:21.63
2025-01-07 18:16:48,250: Snapshot:3	Epoch:8	Loss:21.806	translation_Loss:6.541	token_training_loss:15.265	distillation_Loss:0.0                                                   	MRR:21.41	Hits@10:37.56	Best:21.63
2025-01-07 18:16:51,683: End of token training: 3 Epoch: 9 Loss:8.595 MRR:21.41 Best Results: 21.63
2025-01-07 18:16:51,683: Snapshot:3	Epoch:9	Loss:8.595	translation_Loss:6.534	token_training_loss:2.062	distillation_Loss:0.0                                                           	MRR:21.41	Hits@10:37.56	Best:21.63
2025-01-07 18:16:52,026: => loading checkpoint './checkpoint/FB_CKGE/3model_best.tar'
2025-01-07 18:17:03,854: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2503 | 0.1422 | 0.2951 | 0.3688 |  0.4615 |
|     1      | 0.197  | 0.1132 | 0.2234 | 0.2803 |  0.366  |
|     2      | 0.2057 | 0.1221 | 0.2338 | 0.2932 |  0.3703 |
|     3      | 0.2139 | 0.1289 | 0.2475 | 0.3048 |  0.3752 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,814,400)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,912,800
Trainable params: 3,600
Non-trainable params: 2,909,200
=================================================================
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:17:13,901: Snapshot:4	Epoch:0	Loss:2.111	translation_Loss:1.544	token_training_loss:0.0	distillation_Loss:0.567                                                   	MRR:23.39	Hits@10:39.47	Best:23.39
2025-01-07 18:17:17,535: Snapshot:4	Epoch:1	Loss:1.624	translation_Loss:1.2	token_training_loss:0.0	distillation_Loss:0.424                                                   	MRR:23.46	Hits@10:39.08	Best:23.46
2025-01-07 18:17:21,660: Snapshot:4	Epoch:2	Loss:1.443	translation_Loss:1.122	token_training_loss:0.0	distillation_Loss:0.321                                                   	MRR:23.53	Hits@10:39.34	Best:23.53
2025-01-07 18:17:25,377: Snapshot:4	Epoch:3	Loss:1.334	translation_Loss:1.02	token_training_loss:0.0	distillation_Loss:0.314                                                   	MRR:23.57	Hits@10:39.22	Best:23.57
2025-01-07 18:17:29,047: Snapshot:4	Epoch:4	Loss:1.304	translation_Loss:1.0	token_training_loss:0.0	distillation_Loss:0.304                                                   	MRR:23.48	Hits@10:39.21	Best:23.57
2025-01-07 18:17:32,705: Snapshot:4	Epoch:5	Loss:1.292	translation_Loss:0.986	token_training_loss:0.0	distillation_Loss:0.307                                                   	MRR:23.67	Hits@10:39.39	Best:23.67
2025-01-07 18:17:36,309: Snapshot:4	Epoch:6	Loss:1.283	translation_Loss:0.979	token_training_loss:0.0	distillation_Loss:0.305                                                   	MRR:23.5	Hits@10:39.21	Best:23.67
2025-01-07 18:17:40,303: Snapshot:4	Epoch:7	Loss:1.297	translation_Loss:0.988	token_training_loss:0.0	distillation_Loss:0.308                                                   	MRR:23.43	Hits@10:39.21	Best:23.67
2025-01-07 18:17:43,857: Early Stopping! Snapshot: 4 Epoch: 8 Best Results: 23.67
2025-01-07 18:17:43,857: Start to training tokens! Snapshot: 4 Epoch: 8 Loss:1.284 MRR:23.49 Best Results: 23.67
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:17:43,858: Snapshot:4	Epoch:8	Loss:1.284	translation_Loss:0.97	token_training_loss:0.0	distillation_Loss:0.314                                                   	MRR:23.49	Hits@10:39.41	Best:23.67
2025-01-07 18:17:47,335: Snapshot:4	Epoch:9	Loss:21.573	translation_Loss:6.705	token_training_loss:14.868	distillation_Loss:0.0                                                   	MRR:23.49	Hits@10:39.41	Best:23.67
2025-01-07 18:17:50,907: End of token training: 4 Epoch: 10 Loss:8.749 MRR:23.49 Best Results: 23.67
2025-01-07 18:17:50,907: Snapshot:4	Epoch:10	Loss:8.749	translation_Loss:6.712	token_training_loss:2.037	distillation_Loss:0.0                                                           	MRR:23.49	Hits@10:39.41	Best:23.67
2025-01-07 18:17:51,202: => loading checkpoint './checkpoint/FB_CKGE/4model_best.tar'
2025-01-07 18:18:05,206: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2492 | 0.1409 | 0.2939 | 0.3686 |  0.4608 |
|     1      | 0.1973 | 0.1112 | 0.2242 | 0.2835 |  0.3682 |
|     2      | 0.2062 | 0.1212 | 0.2364 | 0.2964 |  0.3733 |
|     3      | 0.2152 | 0.1297 | 0.2494 | 0.3068 |  0.381  |
|     4      | 0.2358 | 0.1449 | 0.2737 | 0.3359 |  0.4102 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,908,200)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 3,006,600
Trainable params: 3,600
Non-trainable params: 3,003,000
=================================================================
2025-01-07 18:18:05,209: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2542 | 0.146  | 0.2991 | 0.3727 |  0.4675 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2536 | 0.1456 | 0.2987 | 0.3716 |  0.4655 |
|     1      | 0.1911 | 0.1118 | 0.215  | 0.2683 |  0.3491 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2523 | 0.1444 | 0.2966 | 0.371  |  0.465  |
|     1      | 0.1937 | 0.1127 | 0.2183 | 0.2739 |  0.355  |
|     2      | 0.2008 | 0.118  | 0.2299 | 0.2892 |  0.3642 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2503 | 0.1422 | 0.2951 | 0.3688 |  0.4615 |
|     1      | 0.197  | 0.1132 | 0.2234 | 0.2803 |  0.366  |
|     2      | 0.2057 | 0.1221 | 0.2338 | 0.2932 |  0.3703 |
|     3      | 0.2139 | 0.1289 | 0.2475 | 0.3048 |  0.3752 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2492 | 0.1409 | 0.2939 | 0.3686 |  0.4608 |
|     1      | 0.1973 | 0.1112 | 0.2242 | 0.2835 |  0.3682 |
|     2      | 0.2062 | 0.1212 | 0.2364 | 0.2964 |  0.3733 |
|     3      | 0.2152 | 0.1297 | 0.2494 | 0.3068 |  0.381  |
|     4      | 0.2358 | 0.1449 | 0.2737 | 0.3359 |  0.4102 |
+------------+--------+--------+--------+--------+---------+]
2025-01-07 18:18:05,209: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 167.66969633102417 |   0.254   |    0.146     |    0.299     |     0.468     |
|    1     | 104.19439101219177 |   0.245   |    0.141     |    0.287     |     0.449     |
|    2     | 54.053985834121704 |   0.239   |    0.137     |    0.278     |     0.439     |
|    3     | 41.22392010688782  |   0.235   |    0.135     |    0.275     |     0.431     |
|    4     | 45.36083436012268  |   0.235   |    0.135     |    0.275     |      0.43     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-07 18:18:05,209: Sum_Training_Time:412.50282764434814
2025-01-07 18:18:05,209: Every_Training_Time:[167.66969633102417, 104.19439101219177, 54.053985834121704, 41.22392010688782, 45.36083436012268]
2025-01-07 18:18:05,209: Forward transfer: 0.16260000000000002 Backward transfer: 0.0019750000000000045
2025-01-07 18:18:28,392: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FB_CKGE/', dataset='FB_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250107181810/FB_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3333, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FB_CKGE', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 10000.0, 10000.0, 20000.0], token_num=9, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-07 18:18:50,853: Snapshot:0	Epoch:0	Loss:43.893	translation_Loss:43.893	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.97	Hits@10:34.5	Best:14.97
2025-01-07 18:19:08,784: Snapshot:0	Epoch:1	Loss:18.97	translation_Loss:18.97	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.44	Hits@10:45.02	Best:23.44
2025-01-07 18:19:26,709: Snapshot:0	Epoch:2	Loss:7.539	translation_Loss:7.539	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.29	Hits@10:46.67	Best:25.29
2025-01-07 18:19:44,626: Snapshot:0	Epoch:3	Loss:3.834	translation_Loss:3.834	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.35	Hits@10:46.63	Best:25.35
2025-01-07 18:20:03,134: Snapshot:0	Epoch:4	Loss:2.467	translation_Loss:2.467	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.4	Hits@10:46.43	Best:25.4
2025-01-07 18:20:21,358: Snapshot:0	Epoch:5	Loss:1.815	translation_Loss:1.815	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.37	Hits@10:46.31	Best:25.4
2025-01-07 18:20:39,296: Snapshot:0	Epoch:6	Loss:1.464	translation_Loss:1.464	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.24	Hits@10:45.9	Best:25.4
2025-01-07 18:20:57,150: Early Stopping! Snapshot: 0 Epoch: 7 Best Results: 25.4
2025-01-07 18:20:57,150: Start to training tokens! Snapshot: 0 Epoch: 7 Loss:1.245 MRR:25.21 Best Results: 25.4
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:20:57,151: Snapshot:0	Epoch:7	Loss:1.245	translation_Loss:1.245	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.21	Hits@10:45.85	Best:25.4
2025-01-07 18:21:15,548: Snapshot:0	Epoch:8	Loss:53.795	translation_Loss:35.918	token_training_loss:17.878	distillation_Loss:0.0                                                   	MRR:25.21	Hits@10:45.85	Best:25.4
2025-01-07 18:21:33,396: End of token training: 0 Epoch: 9 Loss:35.938 MRR:25.21 Best Results: 25.4
2025-01-07 18:21:33,397: Snapshot:0	Epoch:9	Loss:35.938	translation_Loss:35.935	token_training_loss:0.003	distillation_Loss:0.0                                                           	MRR:25.21	Hits@10:45.85	Best:25.4
2025-01-07 18:21:33,701: => loading checkpoint './checkpoint/FB_CKGE/0model_best.tar'
2025-01-07 18:21:40,207: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2547 | 0.1476 | 0.2995 | 0.3723 |  0.4638 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (1,501,000)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 1,599,400
Trainable params: 3,600
Non-trainable params: 1,595,800
=================================================================
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:21:49,701: Snapshot:1	Epoch:0	Loss:6.576	translation_Loss:6.209	token_training_loss:0.0	distillation_Loss:0.367                                                   	MRR:10.13	Hits@10:19.59	Best:10.13
2025-01-07 18:21:53,050: Snapshot:1	Epoch:1	Loss:3.353	translation_Loss:3.034	token_training_loss:0.0	distillation_Loss:0.319                                                   	MRR:12.79	Hits@10:23.89	Best:12.79
2025-01-07 18:21:56,417: Snapshot:1	Epoch:2	Loss:1.668	translation_Loss:1.441	token_training_loss:0.0	distillation_Loss:0.227                                                   	MRR:14.48	Hits@10:26.71	Best:14.48
2025-01-07 18:22:00,121: Snapshot:1	Epoch:3	Loss:0.939	translation_Loss:0.79	token_training_loss:0.0	distillation_Loss:0.149                                                   	MRR:15.63	Hits@10:29.06	Best:15.63
2025-01-07 18:22:03,483: Snapshot:1	Epoch:4	Loss:0.634	translation_Loss:0.533	token_training_loss:0.0	distillation_Loss:0.101                                                   	MRR:16.2	Hits@10:30.41	Best:16.2
2025-01-07 18:22:06,817: Snapshot:1	Epoch:5	Loss:0.481	translation_Loss:0.402	token_training_loss:0.0	distillation_Loss:0.079                                                   	MRR:16.72	Hits@10:31.14	Best:16.72
2025-01-07 18:22:10,258: Snapshot:1	Epoch:6	Loss:0.41	translation_Loss:0.341	token_training_loss:0.0	distillation_Loss:0.069                                                   	MRR:16.89	Hits@10:31.75	Best:16.89
2025-01-07 18:22:13,638: Snapshot:1	Epoch:7	Loss:0.364	translation_Loss:0.301	token_training_loss:0.0	distillation_Loss:0.063                                                   	MRR:17.16	Hits@10:31.88	Best:17.16
2025-01-07 18:22:17,632: Snapshot:1	Epoch:8	Loss:0.324	translation_Loss:0.263	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:17.3	Hits@10:32.29	Best:17.3
2025-01-07 18:22:20,980: Snapshot:1	Epoch:9	Loss:0.295	translation_Loss:0.235	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:17.37	Hits@10:32.59	Best:17.37
2025-01-07 18:22:24,437: Snapshot:1	Epoch:10	Loss:0.285	translation_Loss:0.228	token_training_loss:0.0	distillation_Loss:0.058                                                   	MRR:17.51	Hits@10:32.83	Best:17.51
2025-01-07 18:22:27,767: Snapshot:1	Epoch:11	Loss:0.265	translation_Loss:0.208	token_training_loss:0.0	distillation_Loss:0.057                                                   	MRR:17.52	Hits@10:32.92	Best:17.52
2025-01-07 18:22:31,205: Snapshot:1	Epoch:12	Loss:0.252	translation_Loss:0.198	token_training_loss:0.0	distillation_Loss:0.054                                                   	MRR:17.61	Hits@10:33.1	Best:17.61
2025-01-07 18:22:35,027: Snapshot:1	Epoch:13	Loss:0.243	translation_Loss:0.189	token_training_loss:0.0	distillation_Loss:0.054                                                   	MRR:17.72	Hits@10:33.3	Best:17.72
2025-01-07 18:22:38,487: Snapshot:1	Epoch:14	Loss:0.236	translation_Loss:0.183	token_training_loss:0.0	distillation_Loss:0.053                                                   	MRR:17.84	Hits@10:33.27	Best:17.84
2025-01-07 18:22:41,836: Snapshot:1	Epoch:15	Loss:0.229	translation_Loss:0.176	token_training_loss:0.0	distillation_Loss:0.053                                                   	MRR:17.9	Hits@10:33.63	Best:17.9
2025-01-07 18:22:45,076: Snapshot:1	Epoch:16	Loss:0.223	translation_Loss:0.169	token_training_loss:0.0	distillation_Loss:0.053                                                   	MRR:17.86	Hits@10:33.67	Best:17.9
2025-01-07 18:22:48,378: Snapshot:1	Epoch:17	Loss:0.221	translation_Loss:0.168	token_training_loss:0.0	distillation_Loss:0.053                                                   	MRR:17.87	Hits@10:33.61	Best:17.9
2025-01-07 18:22:52,116: Snapshot:1	Epoch:18	Loss:0.215	translation_Loss:0.162	token_training_loss:0.0	distillation_Loss:0.053                                                   	MRR:18.0	Hits@10:33.9	Best:18.0
2025-01-07 18:22:55,601: Snapshot:1	Epoch:19	Loss:0.206	translation_Loss:0.155	token_training_loss:0.0	distillation_Loss:0.052                                                   	MRR:18.1	Hits@10:33.84	Best:18.1
2025-01-07 18:22:59,054: Snapshot:1	Epoch:20	Loss:0.209	translation_Loss:0.156	token_training_loss:0.0	distillation_Loss:0.053                                                   	MRR:18.11	Hits@10:33.85	Best:18.11
2025-01-07 18:23:02,316: Snapshot:1	Epoch:21	Loss:0.203	translation_Loss:0.152	token_training_loss:0.0	distillation_Loss:0.051                                                   	MRR:18.05	Hits@10:33.98	Best:18.11
2025-01-07 18:23:05,605: Snapshot:1	Epoch:22	Loss:0.203	translation_Loss:0.151	token_training_loss:0.0	distillation_Loss:0.052                                                   	MRR:18.13	Hits@10:33.73	Best:18.13
2025-01-07 18:23:09,453: Snapshot:1	Epoch:23	Loss:0.198	translation_Loss:0.147	token_training_loss:0.0	distillation_Loss:0.052                                                   	MRR:18.17	Hits@10:33.88	Best:18.17
2025-01-07 18:23:12,826: Snapshot:1	Epoch:24	Loss:0.191	translation_Loss:0.14	token_training_loss:0.0	distillation_Loss:0.051                                                   	MRR:18.29	Hits@10:33.96	Best:18.29
2025-01-07 18:23:16,075: Snapshot:1	Epoch:25	Loss:0.19	translation_Loss:0.14	token_training_loss:0.0	distillation_Loss:0.05                                                   	MRR:18.22	Hits@10:33.99	Best:18.29
2025-01-07 18:23:19,330: Snapshot:1	Epoch:26	Loss:0.184	translation_Loss:0.134	token_training_loss:0.0	distillation_Loss:0.05                                                   	MRR:18.14	Hits@10:34.05	Best:18.29
2025-01-07 18:23:22,677: Early Stopping! Snapshot: 1 Epoch: 27 Best Results: 18.29
2025-01-07 18:23:22,677: Start to training tokens! Snapshot: 1 Epoch: 27 Loss:0.188 MRR:18.2 Best Results: 18.29
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:23:22,677: Snapshot:1	Epoch:27	Loss:0.188	translation_Loss:0.138	token_training_loss:0.0	distillation_Loss:0.05                                                   	MRR:18.2	Hits@10:34.01	Best:18.29
2025-01-07 18:23:26,419: Snapshot:1	Epoch:28	Loss:21.187	translation_Loss:6.177	token_training_loss:15.01	distillation_Loss:0.0                                                   	MRR:18.2	Hits@10:34.01	Best:18.29
2025-01-07 18:23:29,672: End of token training: 1 Epoch: 29 Loss:8.288 MRR:18.2 Best Results: 18.29
2025-01-07 18:23:29,672: Snapshot:1	Epoch:29	Loss:8.288	translation_Loss:6.169	token_training_loss:2.119	distillation_Loss:0.0                                                           	MRR:18.2	Hits@10:34.01	Best:18.29
2025-01-07 18:23:30,008: => loading checkpoint './checkpoint/FB_CKGE/1model_best.tar'
2025-01-07 18:23:38,002: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2536 | 0.146  | 0.2985 | 0.3721 |  0.4629 |
|     1      | 0.187  | 0.1107 | 0.2083 | 0.261  |  0.341  |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,251,600)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,350,000
Trainable params: 3,600
Non-trainable params: 2,346,400
=================================================================
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:23:47,801: Snapshot:2	Epoch:0	Loss:4.397	translation_Loss:3.988	token_training_loss:0.0	distillation_Loss:0.409                                                   	MRR:18.27	Hits@10:33.66	Best:18.27
2025-01-07 18:23:51,256: Snapshot:2	Epoch:1	Loss:2.335	translation_Loss:1.903	token_training_loss:0.0	distillation_Loss:0.432                                                   	MRR:19.18	Hits@10:34.28	Best:19.18
2025-01-07 18:23:55,169: Snapshot:2	Epoch:2	Loss:1.426	translation_Loss:1.113	token_training_loss:0.0	distillation_Loss:0.312                                                   	MRR:19.53	Hits@10:34.84	Best:19.53
2025-01-07 18:23:58,673: Snapshot:2	Epoch:3	Loss:1.051	translation_Loss:0.796	token_training_loss:0.0	distillation_Loss:0.255                                                   	MRR:19.64	Hits@10:35.09	Best:19.64
2025-01-07 18:24:02,146: Snapshot:2	Epoch:4	Loss:0.921	translation_Loss:0.696	token_training_loss:0.0	distillation_Loss:0.225                                                   	MRR:19.73	Hits@10:35.3	Best:19.73
2025-01-07 18:24:05,758: Snapshot:2	Epoch:5	Loss:0.844	translation_Loss:0.624	token_training_loss:0.0	distillation_Loss:0.22                                                   	MRR:19.78	Hits@10:35.16	Best:19.78
2025-01-07 18:24:09,180: Snapshot:2	Epoch:6	Loss:0.817	translation_Loss:0.607	token_training_loss:0.0	distillation_Loss:0.21                                                   	MRR:19.63	Hits@10:35.18	Best:19.78
2025-01-07 18:24:13,088: Snapshot:2	Epoch:7	Loss:0.783	translation_Loss:0.57	token_training_loss:0.0	distillation_Loss:0.214                                                   	MRR:19.69	Hits@10:35.23	Best:19.78
2025-01-07 18:24:16,471: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 19.78
2025-01-07 18:24:16,472: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:0.777 MRR:19.67 Best Results: 19.78
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:24:16,472: Snapshot:2	Epoch:8	Loss:0.777	translation_Loss:0.565	token_training_loss:0.0	distillation_Loss:0.212                                                   	MRR:19.67	Hits@10:35.46	Best:19.78
2025-01-07 18:24:19,817: Snapshot:2	Epoch:9	Loss:21.347	translation_Loss:6.457	token_training_loss:14.89	distillation_Loss:0.0                                                   	MRR:19.67	Hits@10:35.46	Best:19.78
2025-01-07 18:24:23,198: End of token training: 2 Epoch: 10 Loss:8.476 MRR:19.67 Best Results: 19.78
2025-01-07 18:24:23,199: Snapshot:2	Epoch:10	Loss:8.476	translation_Loss:6.451	token_training_loss:2.025	distillation_Loss:0.0                                                           	MRR:19.67	Hits@10:35.46	Best:19.78
2025-01-07 18:24:23,460: => loading checkpoint './checkpoint/FB_CKGE/2model_best.tar'
2025-01-07 18:24:33,741: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2537 | 0.1464 | 0.2996 | 0.3713 |  0.4619 |
|     1      | 0.1898 | 0.1109 | 0.2122 | 0.2665 |  0.3485 |
|     2      | 0.1993 | 0.1191 | 0.228  | 0.2803 |  0.354  |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,626,800)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,725,200
Trainable params: 3,600
Non-trainable params: 2,721,600
=================================================================
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:24:43,693: Snapshot:3	Epoch:0	Loss:2.849	translation_Loss:2.42	token_training_loss:0.0	distillation_Loss:0.428                                                   	MRR:20.74	Hits@10:36.34	Best:20.74
2025-01-07 18:24:47,270: Snapshot:3	Epoch:1	Loss:1.78	translation_Loss:1.294	token_training_loss:0.0	distillation_Loss:0.486                                                   	MRR:20.93	Hits@10:36.85	Best:20.93
2025-01-07 18:24:51,366: Snapshot:3	Epoch:2	Loss:1.369	translation_Loss:1.0	token_training_loss:0.0	distillation_Loss:0.369                                                   	MRR:21.02	Hits@10:37.01	Best:21.02
2025-01-07 18:24:55,058: Snapshot:3	Epoch:3	Loss:1.121	translation_Loss:0.785	token_training_loss:0.0	distillation_Loss:0.336                                                   	MRR:21.32	Hits@10:36.99	Best:21.32
2025-01-07 18:24:58,550: Snapshot:3	Epoch:4	Loss:1.052	translation_Loss:0.737	token_training_loss:0.0	distillation_Loss:0.315                                                   	MRR:21.08	Hits@10:37.04	Best:21.32
2025-01-07 18:25:02,123: Snapshot:3	Epoch:5	Loss:1.017	translation_Loss:0.701	token_training_loss:0.0	distillation_Loss:0.316                                                   	MRR:21.19	Hits@10:37.13	Best:21.32
2025-01-07 18:25:05,779: Early Stopping! Snapshot: 3 Epoch: 6 Best Results: 21.32
2025-01-07 18:25:05,779: Start to training tokens! Snapshot: 3 Epoch: 6 Loss:1.006 MRR:21.08 Best Results: 21.32
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:25:05,779: Snapshot:3	Epoch:6	Loss:1.006	translation_Loss:0.694	token_training_loss:0.0	distillation_Loss:0.312                                                   	MRR:21.08	Hits@10:37.09	Best:21.32
2025-01-07 18:25:09,703: Snapshot:3	Epoch:7	Loss:22.231	translation_Loss:6.525	token_training_loss:15.706	distillation_Loss:0.0                                                   	MRR:21.08	Hits@10:37.09	Best:21.32
2025-01-07 18:25:13,192: End of token training: 3 Epoch: 8 Loss:8.856 MRR:21.08 Best Results: 21.32
2025-01-07 18:25:13,192: Snapshot:3	Epoch:8	Loss:8.856	translation_Loss:6.55	token_training_loss:2.305	distillation_Loss:0.0                                                           	MRR:21.08	Hits@10:37.09	Best:21.32
2025-01-07 18:25:13,432: => loading checkpoint './checkpoint/FB_CKGE/3model_best.tar'
2025-01-07 18:25:25,540: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2521 | 0.1446 | 0.297  | 0.3698 |  0.4601 |
|     1      | 0.1936 | 0.112  | 0.2191 | 0.2744 |  0.3586 |
|     2      | 0.2016 | 0.1204 | 0.2305 | 0.2862 |  0.3593 |
|     3      | 0.2122 | 0.1307 | 0.2431 | 0.2981 |  0.3704 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,814,400)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,912,800
Trainable params: 3,600
Non-trainable params: 2,909,200
=================================================================
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:25:35,648: Snapshot:4	Epoch:0	Loss:2.012	translation_Loss:1.461	token_training_loss:0.0	distillation_Loss:0.55                                                   	MRR:22.9	Hits@10:38.5	Best:22.9
2025-01-07 18:25:39,261: Snapshot:4	Epoch:1	Loss:1.547	translation_Loss:1.136	token_training_loss:0.0	distillation_Loss:0.411                                                   	MRR:22.89	Hits@10:38.33	Best:22.9
2025-01-07 18:25:43,306: Snapshot:4	Epoch:2	Loss:1.347	translation_Loss:1.033	token_training_loss:0.0	distillation_Loss:0.314                                                   	MRR:23.07	Hits@10:38.45	Best:23.07
2025-01-07 18:25:46,944: Snapshot:4	Epoch:3	Loss:1.251	translation_Loss:0.947	token_training_loss:0.0	distillation_Loss:0.304                                                   	MRR:23.14	Hits@10:38.68	Best:23.14
2025-01-07 18:25:50,651: Snapshot:4	Epoch:4	Loss:1.21	translation_Loss:0.914	token_training_loss:0.0	distillation_Loss:0.296                                                   	MRR:23.0	Hits@10:38.54	Best:23.14
2025-01-07 18:25:54,264: Snapshot:4	Epoch:5	Loss:1.195	translation_Loss:0.903	token_training_loss:0.0	distillation_Loss:0.292                                                   	MRR:22.96	Hits@10:38.45	Best:23.14
2025-01-07 18:25:57,796: Early Stopping! Snapshot: 4 Epoch: 6 Best Results: 23.14
2025-01-07 18:25:57,796: Start to training tokens! Snapshot: 4 Epoch: 6 Loss:1.201 MRR:23.08 Best Results: 23.14
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:25:57,796: Snapshot:4	Epoch:6	Loss:1.201	translation_Loss:0.902	token_training_loss:0.0	distillation_Loss:0.299                                                   	MRR:23.08	Hits@10:38.59	Best:23.14
2025-01-07 18:26:01,799: Snapshot:4	Epoch:7	Loss:22.095	translation_Loss:6.701	token_training_loss:15.394	distillation_Loss:0.0                                                   	MRR:23.08	Hits@10:38.59	Best:23.14
2025-01-07 18:26:05,365: End of token training: 4 Epoch: 8 Loss:8.965 MRR:23.08 Best Results: 23.14
2025-01-07 18:26:05,365: Snapshot:4	Epoch:8	Loss:8.965	translation_Loss:6.712	token_training_loss:2.253	distillation_Loss:0.0                                                           	MRR:23.08	Hits@10:38.59	Best:23.14
2025-01-07 18:26:05,666: => loading checkpoint './checkpoint/FB_CKGE/4model_best.tar'
2025-01-07 18:26:19,705: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2512 | 0.1437 | 0.2961 | 0.3679 |  0.4601 |
|     1      | 0.1957 | 0.1128 | 0.2217 | 0.2772 |  0.3635 |
|     2      | 0.2035 | 0.1219 | 0.2321 | 0.2878 |  0.3655 |
|     3      | 0.2134 | 0.1307 | 0.2455 | 0.2998 |  0.3727 |
|     4      | 0.2362 | 0.1464 | 0.2709 | 0.3322 |  0.411  |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,908,200)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 3,006,600
Trainable params: 3,600
Non-trainable params: 3,003,000
=================================================================
2025-01-07 18:26:19,709: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2547 | 0.1476 | 0.2995 | 0.3723 |  0.4638 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2536 | 0.146  | 0.2985 | 0.3721 |  0.4629 |
|     1      | 0.187  | 0.1107 | 0.2083 | 0.261  |  0.341  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2537 | 0.1464 | 0.2996 | 0.3713 |  0.4619 |
|     1      | 0.1898 | 0.1109 | 0.2122 | 0.2665 |  0.3485 |
|     2      | 0.1993 | 0.1191 | 0.228  | 0.2803 |  0.354  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2521 | 0.1446 | 0.297  | 0.3698 |  0.4601 |
|     1      | 0.1936 | 0.112  | 0.2191 | 0.2744 |  0.3586 |
|     2      | 0.2016 | 0.1204 | 0.2305 | 0.2862 |  0.3593 |
|     3      | 0.2122 | 0.1307 | 0.2431 | 0.2981 |  0.3704 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2512 | 0.1437 | 0.2961 | 0.3679 |  0.4601 |
|     1      | 0.1957 | 0.1128 | 0.2217 | 0.2772 |  0.3635 |
|     2      | 0.2035 | 0.1219 | 0.2321 | 0.2878 |  0.3655 |
|     3      | 0.2134 | 0.1307 | 0.2455 | 0.2998 |  0.3727 |
|     4      | 0.2362 | 0.1464 | 0.2709 | 0.3322 |  0.411  |
+------------+--------+--------+--------+--------+---------+]
2025-01-07 18:26:19,710: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 185.00428652763367 |   0.255   |    0.148     |    0.299     |     0.464     |
|    1     | 107.6760048866272  |   0.244   |    0.141     |    0.286     |     0.445     |
|    2     | 43.28989911079407  |   0.239   |    0.139     |     0.28     |     0.434     |
|    3     | 37.80019402503967  |   0.236   |    0.137     |    0.275     |     0.428     |
|    4     | 38.08343243598938  |   0.236   |    0.137     |    0.275     |     0.427     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-07 18:26:19,710: Sum_Training_Time:411.853816986084
2025-01-07 18:26:19,710: Every_Training_Time:[185.00428652763367, 107.6760048866272, 43.28989911079407, 37.80019402503967, 38.08343243598938]
2025-01-07 18:26:19,710: Forward transfer: 0.161975 Backward transfer: 0.0026499999999999996
2025-01-07 18:26:43,110: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FB_CKGE/', dataset='FB_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250107182624/FB_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=4444, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FB_CKGE', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 10000.0, 10000.0, 20000.0], token_num=9, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-07 18:27:05,531: Snapshot:0	Epoch:0	Loss:43.629	translation_Loss:43.629	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.21	Hits@10:34.74	Best:15.21
2025-01-07 18:27:23,674: Snapshot:0	Epoch:1	Loss:18.564	translation_Loss:18.564	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.84	Hits@10:45.25	Best:23.84
2025-01-07 18:27:41,775: Snapshot:0	Epoch:2	Loss:7.184	translation_Loss:7.184	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.5	Hits@10:46.98	Best:25.5
2025-01-07 18:28:00,031: Snapshot:0	Epoch:3	Loss:3.649	translation_Loss:3.649	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.88	Hits@10:47.16	Best:25.88
2025-01-07 18:28:18,437: Snapshot:0	Epoch:4	Loss:2.337	translation_Loss:2.337	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.71	Hits@10:46.62	Best:25.88
2025-01-07 18:28:36,263: Snapshot:0	Epoch:5	Loss:1.723	translation_Loss:1.723	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.49	Hits@10:46.26	Best:25.88
2025-01-07 18:28:54,206: Early Stopping! Snapshot: 0 Epoch: 6 Best Results: 25.88
2025-01-07 18:28:54,207: Start to training tokens! Snapshot: 0 Epoch: 6 Loss:1.39 MRR:25.3 Best Results: 25.88
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:28:54,207: Snapshot:0	Epoch:6	Loss:1.39	translation_Loss:1.39	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.3	Hits@10:46.1	Best:25.88
2025-01-07 18:29:12,704: Snapshot:0	Epoch:7	Loss:54.093	translation_Loss:36.194	token_training_loss:17.899	distillation_Loss:0.0                                                   	MRR:25.3	Hits@10:46.1	Best:25.88
2025-01-07 18:29:30,651: End of token training: 0 Epoch: 8 Loss:36.177 MRR:25.3 Best Results: 25.88
2025-01-07 18:29:30,652: Snapshot:0	Epoch:8	Loss:36.177	translation_Loss:36.174	token_training_loss:0.003	distillation_Loss:0.0                                                           	MRR:25.3	Hits@10:46.1	Best:25.88
2025-01-07 18:29:30,951: => loading checkpoint './checkpoint/FB_CKGE/0model_best.tar'
2025-01-07 18:29:37,110: 
+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.257 | 0.1478 | 0.3034 | 0.3777 |  0.4705 |
+------------+-------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (1,501,000)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 1,599,400
Trainable params: 3,600
Non-trainable params: 1,595,800
=================================================================
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:29:46,901: Snapshot:1	Epoch:0	Loss:6.62	translation_Loss:6.247	token_training_loss:0.0	distillation_Loss:0.374                                                   	MRR:10.3	Hits@10:20.03	Best:10.3
2025-01-07 18:29:50,265: Snapshot:1	Epoch:1	Loss:3.452	translation_Loss:3.124	token_training_loss:0.0	distillation_Loss:0.328                                                   	MRR:13.12	Hits@10:24.19	Best:13.12
2025-01-07 18:29:53,600: Snapshot:1	Epoch:2	Loss:1.78	translation_Loss:1.543	token_training_loss:0.0	distillation_Loss:0.237                                                   	MRR:14.66	Hits@10:27.25	Best:14.66
2025-01-07 18:29:57,414: Snapshot:1	Epoch:3	Loss:1.05	translation_Loss:0.889	token_training_loss:0.0	distillation_Loss:0.161                                                   	MRR:15.64	Hits@10:29.21	Best:15.64
2025-01-07 18:30:00,761: Snapshot:1	Epoch:4	Loss:0.719	translation_Loss:0.606	token_training_loss:0.0	distillation_Loss:0.112                                                   	MRR:16.26	Hits@10:30.63	Best:16.26
2025-01-07 18:30:04,203: Snapshot:1	Epoch:5	Loss:0.561	translation_Loss:0.473	token_training_loss:0.0	distillation_Loss:0.088                                                   	MRR:16.79	Hits@10:31.59	Best:16.79
2025-01-07 18:30:07,651: Snapshot:1	Epoch:6	Loss:0.465	translation_Loss:0.388	token_training_loss:0.0	distillation_Loss:0.077                                                   	MRR:17.01	Hits@10:32.09	Best:17.01
2025-01-07 18:30:11,057: Snapshot:1	Epoch:7	Loss:0.417	translation_Loss:0.345	token_training_loss:0.0	distillation_Loss:0.071                                                   	MRR:17.17	Hits@10:32.43	Best:17.17
2025-01-07 18:30:14,928: Snapshot:1	Epoch:8	Loss:0.384	translation_Loss:0.314	token_training_loss:0.0	distillation_Loss:0.07                                                   	MRR:17.37	Hits@10:32.78	Best:17.37
2025-01-07 18:30:18,397: Snapshot:1	Epoch:9	Loss:0.354	translation_Loss:0.286	token_training_loss:0.0	distillation_Loss:0.068                                                   	MRR:17.49	Hits@10:33.04	Best:17.49
2025-01-07 18:30:21,763: Snapshot:1	Epoch:10	Loss:0.33	translation_Loss:0.264	token_training_loss:0.0	distillation_Loss:0.066                                                   	MRR:17.6	Hits@10:33.34	Best:17.6
2025-01-07 18:30:25,067: Snapshot:1	Epoch:11	Loss:0.316	translation_Loss:0.252	token_training_loss:0.0	distillation_Loss:0.064                                                   	MRR:17.62	Hits@10:33.38	Best:17.62
2025-01-07 18:30:28,417: Snapshot:1	Epoch:12	Loss:0.3	translation_Loss:0.235	token_training_loss:0.0	distillation_Loss:0.065                                                   	MRR:17.75	Hits@10:33.58	Best:17.75
2025-01-07 18:30:32,322: Snapshot:1	Epoch:13	Loss:0.29	translation_Loss:0.226	token_training_loss:0.0	distillation_Loss:0.064                                                   	MRR:17.95	Hits@10:33.3	Best:17.95
2025-01-07 18:30:35,755: Snapshot:1	Epoch:14	Loss:0.282	translation_Loss:0.217	token_training_loss:0.0	distillation_Loss:0.065                                                   	MRR:18.0	Hits@10:33.37	Best:18.0
2025-01-07 18:30:39,228: Snapshot:1	Epoch:15	Loss:0.275	translation_Loss:0.212	token_training_loss:0.0	distillation_Loss:0.063                                                   	MRR:18.05	Hits@10:33.33	Best:18.05
2025-01-07 18:30:42,639: Snapshot:1	Epoch:16	Loss:0.267	translation_Loss:0.206	token_training_loss:0.0	distillation_Loss:0.061                                                   	MRR:18.02	Hits@10:33.55	Best:18.05
2025-01-07 18:30:45,875: Snapshot:1	Epoch:17	Loss:0.26	translation_Loss:0.2	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:17.97	Hits@10:33.71	Best:18.05
2025-01-07 18:30:49,601: Snapshot:1	Epoch:18	Loss:0.253	translation_Loss:0.192	token_training_loss:0.0	distillation_Loss:0.062                                                   	MRR:18.07	Hits@10:33.92	Best:18.07
2025-01-07 18:30:53,100: Snapshot:1	Epoch:19	Loss:0.252	translation_Loss:0.191	token_training_loss:0.0	distillation_Loss:0.061                                                   	MRR:18.1	Hits@10:34.01	Best:18.1
2025-01-07 18:30:56,472: Snapshot:1	Epoch:20	Loss:0.246	translation_Loss:0.186	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:18.01	Hits@10:33.79	Best:18.1
2025-01-07 18:30:59,730: Snapshot:1	Epoch:21	Loss:0.239	translation_Loss:0.18	token_training_loss:0.0	distillation_Loss:0.059                                                   	MRR:18.06	Hits@10:34.12	Best:18.1
2025-01-07 18:31:03,037: Snapshot:1	Epoch:22	Loss:0.238	translation_Loss:0.178	token_training_loss:0.0	distillation_Loss:0.061                                                   	MRR:18.18	Hits@10:33.92	Best:18.18
2025-01-07 18:31:06,861: Snapshot:1	Epoch:23	Loss:0.236	translation_Loss:0.177	token_training_loss:0.0	distillation_Loss:0.059                                                   	MRR:18.1	Hits@10:34.17	Best:18.18
2025-01-07 18:31:10,177: Snapshot:1	Epoch:24	Loss:0.229	translation_Loss:0.17	token_training_loss:0.0	distillation_Loss:0.058                                                   	MRR:18.31	Hits@10:34.33	Best:18.31
2025-01-07 18:31:13,528: Snapshot:1	Epoch:25	Loss:0.227	translation_Loss:0.168	token_training_loss:0.0	distillation_Loss:0.059                                                   	MRR:18.36	Hits@10:34.52	Best:18.36
2025-01-07 18:31:16,943: Snapshot:1	Epoch:26	Loss:0.226	translation_Loss:0.169	token_training_loss:0.0	distillation_Loss:0.057                                                   	MRR:18.36	Hits@10:34.42	Best:18.36
2025-01-07 18:31:20,291: Snapshot:1	Epoch:27	Loss:0.224	translation_Loss:0.164	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:18.31	Hits@10:34.19	Best:18.36
2025-01-07 18:31:24,076: Early Stopping! Snapshot: 1 Epoch: 28 Best Results: 18.36
2025-01-07 18:31:24,077: Start to training tokens! Snapshot: 1 Epoch: 28 Loss:0.222 MRR:18.18 Best Results: 18.36
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:31:24,077: Snapshot:1	Epoch:28	Loss:0.222	translation_Loss:0.163	token_training_loss:0.0	distillation_Loss:0.059                                                   	MRR:18.18	Hits@10:34.14	Best:18.36
2025-01-07 18:31:27,277: Snapshot:1	Epoch:29	Loss:20.879	translation_Loss:6.122	token_training_loss:14.756	distillation_Loss:0.0                                                   	MRR:18.18	Hits@10:34.14	Best:18.36
2025-01-07 18:31:30,503: End of token training: 1 Epoch: 30 Loss:8.029 MRR:18.18 Best Results: 18.36
2025-01-07 18:31:30,503: Snapshot:1	Epoch:30	Loss:8.029	translation_Loss:6.125	token_training_loss:1.904	distillation_Loss:0.0                                                           	MRR:18.18	Hits@10:34.14	Best:18.36
2025-01-07 18:31:30,811: => loading checkpoint './checkpoint/FB_CKGE/1model_best.tar'
2025-01-07 18:31:38,794: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2555 | 0.1463 | 0.3012 | 0.376  |  0.469  |
|     1      | 0.1907 | 0.1118 | 0.2129 | 0.2685 |  0.3493 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,251,600)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,350,000
Trainable params: 3,600
Non-trainable params: 2,346,400
=================================================================
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:31:48,869: Snapshot:2	Epoch:0	Loss:4.47	translation_Loss:4.057	token_training_loss:0.0	distillation_Loss:0.413                                                   	MRR:18.56	Hits@10:34.12	Best:18.56
2025-01-07 18:31:52,354: Snapshot:2	Epoch:1	Loss:2.45	translation_Loss:2.004	token_training_loss:0.0	distillation_Loss:0.446                                                   	MRR:19.37	Hits@10:35.01	Best:19.37
2025-01-07 18:31:55,912: Snapshot:2	Epoch:2	Loss:1.564	translation_Loss:1.239	token_training_loss:0.0	distillation_Loss:0.325                                                   	MRR:19.75	Hits@10:35.52	Best:19.75
2025-01-07 18:31:59,399: Snapshot:2	Epoch:3	Loss:1.18	translation_Loss:0.906	token_training_loss:0.0	distillation_Loss:0.274                                                   	MRR:19.65	Hits@10:35.54	Best:19.75
2025-01-07 18:32:03,363: Snapshot:2	Epoch:4	Loss:1.03	translation_Loss:0.789	token_training_loss:0.0	distillation_Loss:0.24                                                   	MRR:19.93	Hits@10:36.29	Best:19.93
2025-01-07 18:32:06,804: Snapshot:2	Epoch:5	Loss:0.953	translation_Loss:0.717	token_training_loss:0.0	distillation_Loss:0.236                                                   	MRR:19.91	Hits@10:35.99	Best:19.93
2025-01-07 18:32:10,331: Snapshot:2	Epoch:6	Loss:0.914	translation_Loss:0.684	token_training_loss:0.0	distillation_Loss:0.23                                                   	MRR:19.87	Hits@10:36.08	Best:19.93
2025-01-07 18:32:13,878: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 19.93
2025-01-07 18:32:13,878: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:0.888 MRR:19.89 Best Results: 19.93
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:32:13,878: Snapshot:2	Epoch:7	Loss:0.888	translation_Loss:0.657	token_training_loss:0.0	distillation_Loss:0.231                                                   	MRR:19.89	Hits@10:36.21	Best:19.93
2025-01-07 18:32:17,237: Snapshot:2	Epoch:8	Loss:21.401	translation_Loss:6.417	token_training_loss:14.984	distillation_Loss:0.0                                                   	MRR:19.89	Hits@10:36.21	Best:19.93
2025-01-07 18:32:21,072: End of token training: 2 Epoch: 9 Loss:8.443 MRR:19.89 Best Results: 19.93
2025-01-07 18:32:21,072: Snapshot:2	Epoch:9	Loss:8.443	translation_Loss:6.434	token_training_loss:2.009	distillation_Loss:0.0                                                           	MRR:19.89	Hits@10:36.21	Best:19.93
2025-01-07 18:32:21,308: => loading checkpoint './checkpoint/FB_CKGE/2model_best.tar'
2025-01-07 18:32:31,181: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2549 | 0.1457 | 0.301  | 0.3751 |  0.4662 |
|     1      | 0.1926 | 0.1103 | 0.2179 | 0.2745 |  0.3582 |
|     2      | 0.1973 | 0.1164 | 0.2242 | 0.2816 |  0.3584 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,626,800)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,725,200
Trainable params: 3,600
Non-trainable params: 2,721,600
=================================================================
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:32:41,115: Snapshot:3	Epoch:0	Loss:2.972	translation_Loss:2.535	token_training_loss:0.0	distillation_Loss:0.437                                                   	MRR:20.97	Hits@10:37.18	Best:20.97
2025-01-07 18:32:44,727: Snapshot:3	Epoch:1	Loss:1.908	translation_Loss:1.396	token_training_loss:0.0	distillation_Loss:0.512                                                   	MRR:21.14	Hits@10:37.23	Best:21.14
2025-01-07 18:32:48,837: Snapshot:3	Epoch:2	Loss:1.508	translation_Loss:1.114	token_training_loss:0.0	distillation_Loss:0.394                                                   	MRR:21.25	Hits@10:37.75	Best:21.25
2025-01-07 18:32:52,555: Snapshot:3	Epoch:3	Loss:1.265	translation_Loss:0.902	token_training_loss:0.0	distillation_Loss:0.363                                                   	MRR:21.29	Hits@10:37.68	Best:21.29
2025-01-07 18:32:56,278: Snapshot:3	Epoch:4	Loss:1.188	translation_Loss:0.851	token_training_loss:0.0	distillation_Loss:0.337                                                   	MRR:21.34	Hits@10:37.64	Best:21.34
2025-01-07 18:32:59,952: Snapshot:3	Epoch:5	Loss:1.152	translation_Loss:0.815	token_training_loss:0.0	distillation_Loss:0.337                                                   	MRR:21.18	Hits@10:37.45	Best:21.34
2025-01-07 18:33:03,457: Snapshot:3	Epoch:6	Loss:1.123	translation_Loss:0.789	token_training_loss:0.0	distillation_Loss:0.334                                                   	MRR:21.22	Hits@10:37.72	Best:21.34
2025-01-07 18:33:07,417: Early Stopping! Snapshot: 3 Epoch: 7 Best Results: 21.34
2025-01-07 18:33:07,417: Start to training tokens! Snapshot: 3 Epoch: 7 Loss:1.108 MRR:21.26 Best Results: 21.34
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:33:07,417: Snapshot:3	Epoch:7	Loss:1.108	translation_Loss:0.772	token_training_loss:0.0	distillation_Loss:0.336                                                   	MRR:21.26	Hits@10:37.67	Best:21.34
2025-01-07 18:33:10,899: Snapshot:3	Epoch:8	Loss:21.911	translation_Loss:6.528	token_training_loss:15.383	distillation_Loss:0.0                                                   	MRR:21.26	Hits@10:37.67	Best:21.34
2025-01-07 18:33:14,366: End of token training: 3 Epoch: 9 Loss:8.651 MRR:21.26 Best Results: 21.34
2025-01-07 18:33:14,366: Snapshot:3	Epoch:9	Loss:8.651	translation_Loss:6.524	token_training_loss:2.127	distillation_Loss:0.0                                                           	MRR:21.26	Hits@10:37.67	Best:21.34
2025-01-07 18:33:14,670: => loading checkpoint './checkpoint/FB_CKGE/3model_best.tar'
2025-01-07 18:33:26,502: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2532 | 0.1444 | 0.299  | 0.3734 |  0.4641 |
|     1      | 0.1947 | 0.1099 | 0.2209 | 0.2799 |  0.3668 |
|     2      | 0.2006 | 0.1179 | 0.2276 | 0.2867 |  0.3644 |
|     3      | 0.2133 | 0.1287 | 0.2475 | 0.304  |  0.3752 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,814,400)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,912,800
Trainable params: 3,600
Non-trainable params: 2,909,200
=================================================================
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:33:37,019: Snapshot:4	Epoch:0	Loss:2.134	translation_Loss:1.567	token_training_loss:0.0	distillation_Loss:0.566                                                   	MRR:23.41	Hits@10:38.88	Best:23.41
2025-01-07 18:33:40,596: Snapshot:4	Epoch:1	Loss:1.665	translation_Loss:1.235	token_training_loss:0.0	distillation_Loss:0.431                                                   	MRR:23.39	Hits@10:38.57	Best:23.41
2025-01-07 18:33:44,238: Snapshot:4	Epoch:2	Loss:1.478	translation_Loss:1.15	token_training_loss:0.0	distillation_Loss:0.328                                                   	MRR:23.51	Hits@10:38.94	Best:23.51
2025-01-07 18:33:47,833: Snapshot:4	Epoch:3	Loss:1.374	translation_Loss:1.057	token_training_loss:0.0	distillation_Loss:0.318                                                   	MRR:23.49	Hits@10:39.0	Best:23.51
2025-01-07 18:33:51,391: Snapshot:4	Epoch:4	Loss:1.346	translation_Loss:1.035	token_training_loss:0.0	distillation_Loss:0.311                                                   	MRR:23.47	Hits@10:38.91	Best:23.51
2025-01-07 18:33:55,435: Snapshot:4	Epoch:5	Loss:1.326	translation_Loss:1.013	token_training_loss:0.0	distillation_Loss:0.313                                                   	MRR:23.55	Hits@10:38.84	Best:23.55
2025-01-07 18:33:59,045: Snapshot:4	Epoch:6	Loss:1.324	translation_Loss:1.012	token_training_loss:0.0	distillation_Loss:0.312                                                   	MRR:23.59	Hits@10:38.96	Best:23.59
2025-01-07 18:34:02,685: Snapshot:4	Epoch:7	Loss:1.323	translation_Loss:1.012	token_training_loss:0.0	distillation_Loss:0.31                                                   	MRR:23.35	Hits@10:38.88	Best:23.59
2025-01-07 18:34:06,439: Snapshot:4	Epoch:8	Loss:1.317	translation_Loss:1.001	token_training_loss:0.0	distillation_Loss:0.316                                                   	MRR:23.71	Hits@10:38.85	Best:23.71
2025-01-07 18:34:10,000: Snapshot:4	Epoch:9	Loss:1.321	translation_Loss:1.003	token_training_loss:0.0	distillation_Loss:0.318                                                   	MRR:23.37	Hits@10:38.86	Best:23.71
2025-01-07 18:34:14,151: Snapshot:4	Epoch:10	Loss:1.318	translation_Loss:1.001	token_training_loss:0.0	distillation_Loss:0.317                                                   	MRR:23.56	Hits@10:38.97	Best:23.71
2025-01-07 18:34:17,745: Early Stopping! Snapshot: 4 Epoch: 11 Best Results: 23.71
2025-01-07 18:34:17,745: Start to training tokens! Snapshot: 4 Epoch: 11 Loss:1.324 MRR:23.44 Best Results: 23.71
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:34:17,746: Snapshot:4	Epoch:11	Loss:1.324	translation_Loss:1.003	token_training_loss:0.0	distillation_Loss:0.321                                                   	MRR:23.44	Hits@10:38.93	Best:23.71
2025-01-07 18:34:21,339: Snapshot:4	Epoch:12	Loss:21.835	translation_Loss:6.661	token_training_loss:15.174	distillation_Loss:0.0                                                   	MRR:23.44	Hits@10:38.93	Best:23.71
2025-01-07 18:34:24,833: End of token training: 4 Epoch: 13 Loss:8.89 MRR:23.44 Best Results: 23.71
2025-01-07 18:34:24,833: Snapshot:4	Epoch:13	Loss:8.89	translation_Loss:6.67	token_training_loss:2.22	distillation_Loss:0.0                                                           	MRR:23.44	Hits@10:38.93	Best:23.71
2025-01-07 18:34:25,166: => loading checkpoint './checkpoint/FB_CKGE/4model_best.tar'
2025-01-07 18:34:39,202: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2528 | 0.1445 | 0.2976 | 0.3723 |  0.4628 |
|     1      | 0.197  | 0.1115 | 0.2241 | 0.2842 |  0.3708 |
|     2      | 0.2034 | 0.1206 | 0.2296 | 0.2909 |  0.3688 |
|     3      | 0.2163 | 0.1308 | 0.2504 | 0.3078 |  0.3768 |
|     4      | 0.237  | 0.1441 | 0.2773 | 0.3376 |  0.4154 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,908,200)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 3,006,600
Trainable params: 3,600
Non-trainable params: 3,003,000
=================================================================
2025-01-07 18:34:39,205: Final Result:
[+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.257 | 0.1478 | 0.3034 | 0.3777 |  0.4705 |
+------------+-------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2555 | 0.1463 | 0.3012 | 0.376  |  0.469  |
|     1      | 0.1907 | 0.1118 | 0.2129 | 0.2685 |  0.3493 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2549 | 0.1457 | 0.301  | 0.3751 |  0.4662 |
|     1      | 0.1926 | 0.1103 | 0.2179 | 0.2745 |  0.3582 |
|     2      | 0.1973 | 0.1164 | 0.2242 | 0.2816 |  0.3584 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2532 | 0.1444 | 0.299  | 0.3734 |  0.4641 |
|     1      | 0.1947 | 0.1099 | 0.2209 | 0.2799 |  0.3668 |
|     2      | 0.2006 | 0.1179 | 0.2276 | 0.2867 |  0.3644 |
|     3      | 0.2133 | 0.1287 | 0.2475 | 0.304  |  0.3752 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2528 | 0.1445 | 0.2976 | 0.3723 |  0.4628 |
|     1      | 0.197  | 0.1115 | 0.2241 | 0.2842 |  0.3708 |
|     2      | 0.2034 | 0.1206 | 0.2296 | 0.2909 |  0.3688 |
|     3      | 0.2163 | 0.1308 | 0.2504 | 0.3078 |  0.3768 |
|     4      | 0.237  | 0.1441 | 0.2773 | 0.3376 |  0.4154 |
+------------+--------+--------+--------+--------+---------+]
2025-01-07 18:34:39,205: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 167.5408856868744  |   0.257   |    0.148     |    0.303     |      0.47     |
|    1     | 111.33956360816956 |   0.246   |    0.141     |    0.289     |     0.452     |
|    2     |  40.4118926525116  |    0.24   |    0.138     |    0.281     |     0.439     |
|    3     | 41.53444576263428  |   0.236   |    0.136     |    0.277     |     0.432     |
|    4     | 56.317038774490356 |   0.237   |    0.137     |    0.277     |     0.431     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-07 18:34:39,205: Sum_Training_Time:417.1438264846802
2025-01-07 18:34:39,205: Every_Training_Time:[167.5408856868744, 111.33956360816956, 40.4118926525116, 41.53444576263428, 56.317038774490356]
2025-01-07 18:34:39,205: Forward transfer: 0.163775 Backward transfer: 0.002800000000000004
2025-01-07 18:35:02,093: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FB_CKGE/', dataset='FB_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250107183443/FB_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=5555, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FB_CKGE', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 10000.0, 10000.0, 20000.0], token_num=9, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-07 18:35:25,065: Snapshot:0	Epoch:0	Loss:43.768	translation_Loss:43.768	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.92	Hits@10:34.66	Best:14.92
2025-01-07 18:35:43,122: Snapshot:0	Epoch:1	Loss:18.58	translation_Loss:18.58	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.63	Hits@10:45.06	Best:23.63
2025-01-07 18:36:01,179: Snapshot:0	Epoch:2	Loss:7.255	translation_Loss:7.255	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.1	Hits@10:46.61	Best:25.1
2025-01-07 18:36:19,235: Snapshot:0	Epoch:3	Loss:3.709	translation_Loss:3.709	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.56	Hits@10:46.69	Best:25.56
2025-01-07 18:36:37,893: Snapshot:0	Epoch:4	Loss:2.39	translation_Loss:2.39	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.45	Hits@10:46.58	Best:25.56
2025-01-07 18:36:55,977: Snapshot:0	Epoch:5	Loss:1.766	translation_Loss:1.766	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.33	Hits@10:46.53	Best:25.56
2025-01-07 18:37:14,105: Early Stopping! Snapshot: 0 Epoch: 6 Best Results: 25.56
2025-01-07 18:37:14,105: Start to training tokens! Snapshot: 0 Epoch: 6 Loss:1.414 MRR:25.34 Best Results: 25.56
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:37:14,106: Snapshot:0	Epoch:6	Loss:1.414	translation_Loss:1.414	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.34	Hits@10:46.16	Best:25.56
2025-01-07 18:37:32,871: Snapshot:0	Epoch:7	Loss:53.228	translation_Loss:36.135	token_training_loss:17.093	distillation_Loss:0.0                                                   	MRR:25.34	Hits@10:46.16	Best:25.56
2025-01-07 18:37:51,133: End of token training: 0 Epoch: 8 Loss:36.142 MRR:25.34 Best Results: 25.56
2025-01-07 18:37:51,133: Snapshot:0	Epoch:8	Loss:36.142	translation_Loss:36.139	token_training_loss:0.003	distillation_Loss:0.0                                                           	MRR:25.34	Hits@10:46.16	Best:25.56
2025-01-07 18:37:51,435: => loading checkpoint './checkpoint/FB_CKGE/0model_best.tar'
2025-01-07 18:37:57,615: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2556 | 0.1475 | 0.3005 | 0.3744 |  0.466  |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (1,501,000)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 1,599,400
Trainable params: 3,600
Non-trainable params: 1,595,800
=================================================================
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:38:07,435: Snapshot:1	Epoch:0	Loss:6.625	translation_Loss:6.253	token_training_loss:0.0	distillation_Loss:0.371                                                   	MRR:10.15	Hits@10:19.9	Best:10.15
2025-01-07 18:38:10,766: Snapshot:1	Epoch:1	Loss:3.465	translation_Loss:3.139	token_training_loss:0.0	distillation_Loss:0.326                                                   	MRR:13.11	Hits@10:23.86	Best:13.11
2025-01-07 18:38:14,184: Snapshot:1	Epoch:2	Loss:1.796	translation_Loss:1.558	token_training_loss:0.0	distillation_Loss:0.238                                                   	MRR:14.67	Hits@10:27.04	Best:14.67
2025-01-07 18:38:17,983: Snapshot:1	Epoch:3	Loss:1.059	translation_Loss:0.898	token_training_loss:0.0	distillation_Loss:0.161                                                   	MRR:15.73	Hits@10:29.41	Best:15.73
2025-01-07 18:38:21,292: Snapshot:1	Epoch:4	Loss:0.723	translation_Loss:0.614	token_training_loss:0.0	distillation_Loss:0.11                                                   	MRR:16.45	Hits@10:30.73	Best:16.45
2025-01-07 18:38:24,692: Snapshot:1	Epoch:5	Loss:0.56	translation_Loss:0.474	token_training_loss:0.0	distillation_Loss:0.086                                                   	MRR:16.78	Hits@10:31.55	Best:16.78
2025-01-07 18:38:28,021: Snapshot:1	Epoch:6	Loss:0.475	translation_Loss:0.397	token_training_loss:0.0	distillation_Loss:0.078                                                   	MRR:17.19	Hits@10:32.26	Best:17.19
2025-01-07 18:38:31,375: Snapshot:1	Epoch:7	Loss:0.419	translation_Loss:0.346	token_training_loss:0.0	distillation_Loss:0.073                                                   	MRR:17.4	Hits@10:32.51	Best:17.4
2025-01-07 18:38:35,188: Snapshot:1	Epoch:8	Loss:0.383	translation_Loss:0.313	token_training_loss:0.0	distillation_Loss:0.07                                                   	MRR:17.56	Hits@10:32.76	Best:17.56
2025-01-07 18:38:38,547: Snapshot:1	Epoch:9	Loss:0.349	translation_Loss:0.281	token_training_loss:0.0	distillation_Loss:0.068                                                   	MRR:17.63	Hits@10:33.1	Best:17.63
2025-01-07 18:38:41,952: Snapshot:1	Epoch:10	Loss:0.333	translation_Loss:0.268	token_training_loss:0.0	distillation_Loss:0.066                                                   	MRR:17.73	Hits@10:33.19	Best:17.73
2025-01-07 18:38:45,401: Snapshot:1	Epoch:11	Loss:0.31	translation_Loss:0.246	token_training_loss:0.0	distillation_Loss:0.064                                                   	MRR:17.69	Hits@10:33.56	Best:17.73
2025-01-07 18:38:48,845: Snapshot:1	Epoch:12	Loss:0.296	translation_Loss:0.234	token_training_loss:0.0	distillation_Loss:0.061                                                   	MRR:17.88	Hits@10:33.5	Best:17.88
2025-01-07 18:38:52,774: Snapshot:1	Epoch:13	Loss:0.289	translation_Loss:0.226	token_training_loss:0.0	distillation_Loss:0.063                                                   	MRR:18.01	Hits@10:33.39	Best:18.01
2025-01-07 18:38:56,056: Snapshot:1	Epoch:14	Loss:0.284	translation_Loss:0.221	token_training_loss:0.0	distillation_Loss:0.064                                                   	MRR:17.98	Hits@10:33.63	Best:18.01
2025-01-07 18:38:59,462: Snapshot:1	Epoch:15	Loss:0.275	translation_Loss:0.212	token_training_loss:0.0	distillation_Loss:0.063                                                   	MRR:17.93	Hits@10:33.71	Best:18.01
2025-01-07 18:39:02,741: Early Stopping! Snapshot: 1 Epoch: 16 Best Results: 18.01
2025-01-07 18:39:02,741: Start to training tokens! Snapshot: 1 Epoch: 16 Loss:0.265 MRR:17.89 Best Results: 18.01
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:39:02,741: Snapshot:1	Epoch:16	Loss:0.265	translation_Loss:0.202	token_training_loss:0.0	distillation_Loss:0.063                                                   	MRR:17.89	Hits@10:33.9	Best:18.01
2025-01-07 18:39:06,004: Snapshot:1	Epoch:17	Loss:20.844	translation_Loss:6.203	token_training_loss:14.642	distillation_Loss:0.0                                                   	MRR:17.89	Hits@10:33.9	Best:18.01
2025-01-07 18:39:09,649: End of token training: 1 Epoch: 18 Loss:8.142 MRR:17.89 Best Results: 18.01
2025-01-07 18:39:09,650: Snapshot:1	Epoch:18	Loss:8.142	translation_Loss:6.199	token_training_loss:1.943	distillation_Loss:0.0                                                           	MRR:17.89	Hits@10:33.9	Best:18.01
2025-01-07 18:39:09,949: => loading checkpoint './checkpoint/FB_CKGE/1model_best.tar'
2025-01-07 18:39:17,568: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2552 | 0.1475 | 0.2997 | 0.3729 |  0.4653 |
|     1      | 0.1893 | 0.1111 | 0.2103 | 0.2673 |  0.3478 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,251,600)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,350,000
Trainable params: 3,600
Non-trainable params: 2,346,400
=================================================================
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:39:27,737: Snapshot:2	Epoch:0	Loss:4.508	translation_Loss:4.088	token_training_loss:0.0	distillation_Loss:0.42                                                   	MRR:18.61	Hits@10:33.82	Best:18.61
2025-01-07 18:39:31,413: Snapshot:2	Epoch:1	Loss:2.462	translation_Loss:1.992	token_training_loss:0.0	distillation_Loss:0.47                                                   	MRR:19.39	Hits@10:34.58	Best:19.39
2025-01-07 18:39:35,025: Snapshot:2	Epoch:2	Loss:1.593	translation_Loss:1.246	token_training_loss:0.0	distillation_Loss:0.347                                                   	MRR:19.72	Hits@10:35.33	Best:19.72
2025-01-07 18:39:39,020: Snapshot:2	Epoch:3	Loss:1.2	translation_Loss:0.913	token_training_loss:0.0	distillation_Loss:0.287                                                   	MRR:19.87	Hits@10:35.58	Best:19.87
2025-01-07 18:39:42,606: Snapshot:2	Epoch:4	Loss:1.062	translation_Loss:0.801	token_training_loss:0.0	distillation_Loss:0.261                                                   	MRR:19.85	Hits@10:35.74	Best:19.87
2025-01-07 18:39:46,094: Snapshot:2	Epoch:5	Loss:0.978	translation_Loss:0.724	token_training_loss:0.0	distillation_Loss:0.254                                                   	MRR:19.93	Hits@10:35.78	Best:19.93
2025-01-07 18:39:49,652: Snapshot:2	Epoch:6	Loss:0.942	translation_Loss:0.698	token_training_loss:0.0	distillation_Loss:0.244                                                   	MRR:19.87	Hits@10:35.96	Best:19.93
2025-01-07 18:39:53,110: Snapshot:2	Epoch:7	Loss:0.912	translation_Loss:0.668	token_training_loss:0.0	distillation_Loss:0.244                                                   	MRR:19.89	Hits@10:35.67	Best:19.93
2025-01-07 18:39:57,029: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 19.93
2025-01-07 18:39:57,030: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:0.902 MRR:19.81 Best Results: 19.93
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:39:57,030: Snapshot:2	Epoch:8	Loss:0.902	translation_Loss:0.657	token_training_loss:0.0	distillation_Loss:0.245                                                   	MRR:19.81	Hits@10:35.89	Best:19.93
2025-01-07 18:40:00,413: Snapshot:2	Epoch:9	Loss:21.544	translation_Loss:6.428	token_training_loss:15.116	distillation_Loss:0.0                                                   	MRR:19.81	Hits@10:35.89	Best:19.93
2025-01-07 18:40:03,884: End of token training: 2 Epoch: 10 Loss:8.564 MRR:19.81 Best Results: 19.93
2025-01-07 18:40:03,884: Snapshot:2	Epoch:10	Loss:8.564	translation_Loss:6.432	token_training_loss:2.132	distillation_Loss:0.0                                                           	MRR:19.81	Hits@10:35.89	Best:19.93
2025-01-07 18:40:04,221: => loading checkpoint './checkpoint/FB_CKGE/2model_best.tar'
2025-01-07 18:40:14,200: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2536 | 0.1453 | 0.2995 | 0.372  |  0.4633 |
|     1      | 0.1908 | 0.1088 | 0.216  | 0.2708 |  0.3558 |
|     2      | 0.1973 | 0.115  | 0.2259 | 0.2841 |  0.3617 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,626,800)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,725,200
Trainable params: 3,600
Non-trainable params: 2,721,600
=================================================================
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:40:24,510: Snapshot:3	Epoch:0	Loss:3.012	translation_Loss:2.566	token_training_loss:0.0	distillation_Loss:0.446                                                   	MRR:21.02	Hits@10:36.98	Best:21.02
2025-01-07 18:40:28,112: Snapshot:3	Epoch:1	Loss:1.945	translation_Loss:1.408	token_training_loss:0.0	distillation_Loss:0.538                                                   	MRR:20.99	Hits@10:37.13	Best:21.02
2025-01-07 18:40:31,701: Snapshot:3	Epoch:2	Loss:1.542	translation_Loss:1.13	token_training_loss:0.0	distillation_Loss:0.413                                                   	MRR:21.19	Hits@10:37.16	Best:21.19
2025-01-07 18:40:35,322: Snapshot:3	Epoch:3	Loss:1.295	translation_Loss:0.914	token_training_loss:0.0	distillation_Loss:0.381                                                   	MRR:21.18	Hits@10:37.59	Best:21.19
2025-01-07 18:40:39,404: Snapshot:3	Epoch:4	Loss:1.209	translation_Loss:0.854	token_training_loss:0.0	distillation_Loss:0.355                                                   	MRR:21.4	Hits@10:37.49	Best:21.4
2025-01-07 18:40:43,066: Snapshot:3	Epoch:5	Loss:1.168	translation_Loss:0.815	token_training_loss:0.0	distillation_Loss:0.353                                                   	MRR:21.17	Hits@10:37.65	Best:21.4
2025-01-07 18:40:46,566: Snapshot:3	Epoch:6	Loss:1.153	translation_Loss:0.803	token_training_loss:0.0	distillation_Loss:0.35                                                   	MRR:21.39	Hits@10:37.58	Best:21.4
2025-01-07 18:40:50,153: Early Stopping! Snapshot: 3 Epoch: 7 Best Results: 21.4
2025-01-07 18:40:50,153: Start to training tokens! Snapshot: 3 Epoch: 7 Loss:1.131 MRR:21.21 Best Results: 21.4
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:40:50,154: Snapshot:3	Epoch:7	Loss:1.131	translation_Loss:0.779	token_training_loss:0.0	distillation_Loss:0.353                                                   	MRR:21.21	Hits@10:37.73	Best:21.4
2025-01-07 18:40:53,646: Snapshot:3	Epoch:8	Loss:21.732	translation_Loss:6.523	token_training_loss:15.209	distillation_Loss:0.0                                                   	MRR:21.21	Hits@10:37.73	Best:21.4
2025-01-07 18:40:57,546: End of token training: 3 Epoch: 9 Loss:8.594 MRR:21.21 Best Results: 21.4
2025-01-07 18:40:57,546: Snapshot:3	Epoch:9	Loss:8.594	translation_Loss:6.528	token_training_loss:2.066	distillation_Loss:0.0                                                           	MRR:21.21	Hits@10:37.73	Best:21.4
2025-01-07 18:40:57,802: => loading checkpoint './checkpoint/FB_CKGE/3model_best.tar'
2025-01-07 18:41:09,751: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      |  0.25  | 0.1421 | 0.2941 | 0.3673 |  0.4601 |
|     1      | 0.1939 | 0.1096 | 0.2188 | 0.2788 |  0.365  |
|     2      | 0.2001 | 0.1164 | 0.2301 | 0.2891 |   0.37  |
|     3      | 0.2115 | 0.1282 | 0.2435 | 0.2982 |  0.3707 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,814,400)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 2,912,800
Trainable params: 3,600
Non-trainable params: 2,909,200
=================================================================
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-07 18:41:19,904: Snapshot:4	Epoch:0	Loss:2.189	translation_Loss:1.605	token_training_loss:0.0	distillation_Loss:0.584                                                   	MRR:23.4	Hits@10:39.04	Best:23.4
2025-01-07 18:41:23,520: Snapshot:4	Epoch:1	Loss:1.699	translation_Loss:1.244	token_training_loss:0.0	distillation_Loss:0.455                                                   	MRR:23.32	Hits@10:38.76	Best:23.4
2025-01-07 18:41:27,100: Snapshot:4	Epoch:2	Loss:1.513	translation_Loss:1.167	token_training_loss:0.0	distillation_Loss:0.346                                                   	MRR:23.37	Hits@10:39.08	Best:23.4
2025-01-07 18:41:31,172: Snapshot:4	Epoch:3	Loss:1.402	translation_Loss:1.068	token_training_loss:0.0	distillation_Loss:0.334                                                   	MRR:23.42	Hits@10:38.99	Best:23.42
2025-01-07 18:41:34,832: Snapshot:4	Epoch:4	Loss:1.371	translation_Loss:1.044	token_training_loss:0.0	distillation_Loss:0.327                                                   	MRR:23.46	Hits@10:39.08	Best:23.46
2025-01-07 18:41:38,606: Snapshot:4	Epoch:5	Loss:1.354	translation_Loss:1.026	token_training_loss:0.0	distillation_Loss:0.328                                                   	MRR:23.45	Hits@10:39.01	Best:23.46
2025-01-07 18:41:42,257: Snapshot:4	Epoch:6	Loss:1.345	translation_Loss:1.019	token_training_loss:0.0	distillation_Loss:0.326                                                   	MRR:23.55	Hits@10:39.21	Best:23.55
2025-01-07 18:41:45,953: Snapshot:4	Epoch:7	Loss:1.353	translation_Loss:1.025	token_training_loss:0.0	distillation_Loss:0.328                                                   	MRR:23.32	Hits@10:38.96	Best:23.55
2025-01-07 18:41:50,015: Snapshot:4	Epoch:8	Loss:1.345	translation_Loss:1.014	token_training_loss:0.0	distillation_Loss:0.332                                                   	MRR:23.5	Hits@10:38.92	Best:23.55
2025-01-07 18:41:53,576: Early Stopping! Snapshot: 4 Epoch: 9 Best Results: 23.55
2025-01-07 18:41:53,576: Start to training tokens! Snapshot: 4 Epoch: 9 Loss:1.345 MRR:23.39 Best Results: 23.55
Token added to optimizer, embeddings excluded successfully.
2025-01-07 18:41:53,577: Snapshot:4	Epoch:9	Loss:1.345	translation_Loss:1.016	token_training_loss:0.0	distillation_Loss:0.329                                                   	MRR:23.39	Hits@10:39.09	Best:23.55
2025-01-07 18:41:57,092: Snapshot:4	Epoch:10	Loss:22.613	translation_Loss:6.7	token_training_loss:15.913	distillation_Loss:0.0                                                   	MRR:23.39	Hits@10:39.09	Best:23.55
2025-01-07 18:42:00,699: End of token training: 4 Epoch: 11 Loss:9.115 MRR:23.39 Best Results: 23.55
2025-01-07 18:42:00,699: Snapshot:4	Epoch:11	Loss:9.115	translation_Loss:6.697	token_training_loss:2.418	distillation_Loss:0.0                                                           	MRR:23.39	Hits@10:39.09	Best:23.55
2025-01-07 18:42:00,960: => loading checkpoint './checkpoint/FB_CKGE/4model_best.tar'
2025-01-07 18:42:15,168: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2499 | 0.1423 | 0.2941 | 0.3668 |  0.4587 |
|     1      | 0.1953 | 0.1103 | 0.2199 | 0.2784 |  0.3672 |
|     2      | 0.2035 | 0.1185 | 0.2327 | 0.2918 |  0.3734 |
|     3      | 0.2132 | 0.1291 | 0.246  | 0.3017 |  0.3755 |
|     4      | 0.2365 | 0.1454 | 0.2709 | 0.3336 |  0.4143 |
+------------+--------+--------+--------+--------+---------+
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
TransE                                   3,600
├─Embedding: 1-1                         (2,908,200)
├─Embedding: 1-2                         (94,800)
├─MarginRankingLoss: 1-3                 --
├─MSELoss: 1-4                           --
├─HuberLoss: 1-5                         --
=================================================================
Total params: 3,006,600
Trainable params: 3,600
Non-trainable params: 3,003,000
=================================================================
2025-01-07 18:42:15,171: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2556 | 0.1475 | 0.3005 | 0.3744 |  0.466  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2552 | 0.1475 | 0.2997 | 0.3729 |  0.4653 |
|     1      | 0.1893 | 0.1111 | 0.2103 | 0.2673 |  0.3478 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2536 | 0.1453 | 0.2995 | 0.372  |  0.4633 |
|     1      | 0.1908 | 0.1088 | 0.216  | 0.2708 |  0.3558 |
|     2      | 0.1973 | 0.115  | 0.2259 | 0.2841 |  0.3617 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      |  0.25  | 0.1421 | 0.2941 | 0.3673 |  0.4601 |
|     1      | 0.1939 | 0.1096 | 0.2188 | 0.2788 |  0.365  |
|     2      | 0.2001 | 0.1164 | 0.2301 | 0.2891 |   0.37  |
|     3      | 0.2115 | 0.1282 | 0.2435 | 0.2982 |  0.3707 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2499 | 0.1423 | 0.2941 | 0.3668 |  0.4587 |
|     1      | 0.1953 | 0.1103 | 0.2199 | 0.2784 |  0.3672 |
|     2      | 0.2035 | 0.1185 | 0.2327 | 0.2918 |  0.3734 |
|     3      | 0.2132 | 0.1291 | 0.246  | 0.3017 |  0.3755 |
|     4      | 0.2365 | 0.1454 | 0.2709 | 0.3336 |  0.4143 |
+------------+--------+--------+--------+--------+---------+]
2025-01-07 18:42:15,172: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 169.04004192352295 |   0.256   |    0.147     |     0.3      |     0.466     |
|    1     | 69.96528387069702  |   0.246   |    0.142     |    0.287     |     0.449     |
|    2     | 44.116947174072266 |   0.239   |    0.137     |     0.28     |     0.437     |
|    3     | 41.39145588874817  |   0.234   |    0.134     |    0.273     |      0.43     |
|    4     | 48.90641713142395  |   0.235   |    0.136     |    0.273     |     0.428     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-07 18:42:15,172: Sum_Training_Time:373.42014598846436
2025-01-07 18:42:15,172: Every_Training_Time:[169.04004192352295, 69.96528387069702, 44.116947174072266, 41.39145588874817, 48.90641713142395]
2025-01-07 18:42:15,172: Forward transfer: 0.16235 Backward transfer: 0.002050000000000003
