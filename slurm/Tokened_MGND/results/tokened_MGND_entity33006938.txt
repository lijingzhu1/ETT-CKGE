2024-12-27 14:26:43,907: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227142609/ENTITYentity_0.01_512_2', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_512_2', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_512_2', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=2, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 14:26:51,918: Snapshot:0	Epoch:0	Loss:52.474	translation_Loss:52.474	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.98	Hits@10:48.63	Best:25.98
2024-12-27 14:26:55,942: Snapshot:0	Epoch:1	Loss:15.809	translation_Loss:15.809	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.64	Hits@10:53.33	Best:30.64
2024-12-27 14:26:59,996: Snapshot:0	Epoch:2	Loss:6.245	translation_Loss:6.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.85	Hits@10:53.42	Best:30.85
2024-12-27 14:27:03,966: Snapshot:0	Epoch:3	Loss:3.612	translation_Loss:3.612	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.12	Hits@10:53.14	Best:31.12
2024-12-27 14:27:07,934: Snapshot:0	Epoch:4	Loss:2.603	translation_Loss:2.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.82	Hits@10:53.35	Best:31.12
2024-12-27 14:27:11,861: Snapshot:0	Epoch:5	Loss:2.111	translation_Loss:2.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.9	Hits@10:53.04	Best:31.12
2024-12-27 14:27:15,767: Snapshot:0	Epoch:6	Loss:1.881	translation_Loss:1.881	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.78	Hits@10:52.89	Best:31.12
2024-12-27 14:27:19,708: Snapshot:0	Epoch:7	Loss:1.669	translation_Loss:1.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.97	Hits@10:52.6	Best:31.12
2024-12-27 14:27:23,626: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 31.12
2024-12-27 14:27:23,626: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:1.508 MRR:30.8 Best Results: 31.12
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 14:27:23,627: Snapshot:0	Epoch:8	Loss:1.508	translation_Loss:1.508	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.8	Hits@10:52.18	Best:31.12
2024-12-27 14:27:28,343: Snapshot:0	Epoch:9	Loss:55.233	translation_Loss:55.198	multi_layer_Loss:0.035	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.8	Hits@10:52.18	Best:31.12
2024-12-27 14:27:32,570: End of token training: 0 Epoch: 10 Loss:55.231 MRR:30.8 Best Results: 31.12
2024-12-27 14:27:32,570: Snapshot:0	Epoch:10	Loss:55.231	translation_Loss:55.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.8	Hits@10:52.18	Best:31.12
2024-12-27 14:27:32,864: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_2/0model_best.tar'
2024-12-27 14:27:34,159: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3153 | 0.199  | 0.3645 | 0.4372 |  0.5359 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 14:27:58,922: Snapshot:1	Epoch:0	Loss:68.457	translation_Loss:31.945	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:36.512                                                   	MRR:21.09	Hits@10:38.03	Best:21.09
2024-12-27 14:28:06,143: Snapshot:1	Epoch:1	Loss:10.373	translation_Loss:9.49	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.883                                                   	MRR:22.23	Hits@10:39.68	Best:22.23
2024-12-27 14:28:13,428: Snapshot:1	Epoch:2	Loss:8.194	translation_Loss:7.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.027                                                   	MRR:22.37	Hits@10:40.17	Best:22.37
2024-12-27 14:28:20,683: Snapshot:1	Epoch:3	Loss:8.477	translation_Loss:7.103	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.374                                                   	MRR:22.46	Hits@10:40.48	Best:22.46
2024-12-27 14:28:27,847: Snapshot:1	Epoch:4	Loss:7.338	translation_Loss:5.696	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.642                                                   	MRR:22.65	Hits@10:40.87	Best:22.65
2024-12-27 14:28:35,053: Snapshot:1	Epoch:5	Loss:6.807	translation_Loss:5.348	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.459                                                   	MRR:22.99	Hits@10:41.19	Best:22.99
2024-12-27 14:28:42,219: Snapshot:1	Epoch:6	Loss:6.619	translation_Loss:5.042	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.578                                                   	MRR:23.0	Hits@10:41.2	Best:23.0
2024-12-27 14:28:49,501: Snapshot:1	Epoch:7	Loss:6.62	translation_Loss:4.91	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.71                                                   	MRR:23.05	Hits@10:41.2	Best:23.05
2024-12-27 14:28:56,714: Snapshot:1	Epoch:8	Loss:6.495	translation_Loss:4.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.815                                                   	MRR:23.01	Hits@10:41.4	Best:23.05
2024-12-27 14:29:03,884: Snapshot:1	Epoch:9	Loss:6.626	translation_Loss:4.566	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.06                                                   	MRR:23.0	Hits@10:41.35	Best:23.05
2024-12-27 14:29:11,037: Snapshot:1	Epoch:10	Loss:6.675	translation_Loss:4.401	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.274                                                   	MRR:22.89	Hits@10:41.35	Best:23.05
2024-12-27 14:29:18,733: Snapshot:1	Epoch:11	Loss:6.706	translation_Loss:4.313	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.393                                                   	MRR:23.11	Hits@10:41.58	Best:23.11
2024-12-27 14:29:25,982: Snapshot:1	Epoch:12	Loss:6.796	translation_Loss:4.284	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.511                                                   	MRR:23.08	Hits@10:41.49	Best:23.11
2024-12-27 14:29:33,154: Snapshot:1	Epoch:13	Loss:6.748	translation_Loss:4.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.549                                                   	MRR:23.22	Hits@10:41.54	Best:23.22
2024-12-27 14:29:40,526: Snapshot:1	Epoch:14	Loss:6.656	translation_Loss:4.102	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.553                                                   	MRR:23.1	Hits@10:41.53	Best:23.22
2024-12-27 14:29:47,671: Snapshot:1	Epoch:15	Loss:6.609	translation_Loss:4.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.539                                                   	MRR:23.29	Hits@10:41.58	Best:23.29
2024-12-27 14:29:54,826: Snapshot:1	Epoch:16	Loss:6.559	translation_Loss:3.988	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.571                                                   	MRR:23.31	Hits@10:41.9	Best:23.31
2024-12-27 14:30:02,105: Snapshot:1	Epoch:17	Loss:6.587	translation_Loss:3.996	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.591                                                   	MRR:23.35	Hits@10:41.9	Best:23.35
2024-12-27 14:30:09,530: Snapshot:1	Epoch:18	Loss:6.542	translation_Loss:3.975	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.567                                                   	MRR:23.18	Hits@10:41.55	Best:23.35
2024-12-27 14:30:16,658: Snapshot:1	Epoch:19	Loss:6.471	translation_Loss:3.9	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.571                                                   	MRR:23.35	Hits@10:42.04	Best:23.35
2024-12-27 14:30:23,769: Snapshot:1	Epoch:20	Loss:6.4	translation_Loss:3.858	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.543                                                   	MRR:23.25	Hits@10:41.86	Best:23.35
2024-12-27 14:30:31,049: Snapshot:1	Epoch:21	Loss:6.417	translation_Loss:3.883	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.533                                                   	MRR:23.4	Hits@10:42.06	Best:23.4
2024-12-27 14:30:38,206: Snapshot:1	Epoch:22	Loss:6.381	translation_Loss:3.82	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.561                                                   	MRR:23.35	Hits@10:41.91	Best:23.4
2024-12-27 14:30:45,363: Snapshot:1	Epoch:23	Loss:6.311	translation_Loss:3.776	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.534                                                   	MRR:23.5	Hits@10:42.29	Best:23.5
2024-12-27 14:30:52,578: Snapshot:1	Epoch:24	Loss:6.282	translation_Loss:3.738	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.544                                                   	MRR:23.38	Hits@10:41.92	Best:23.5
2024-12-27 14:30:59,758: Snapshot:1	Epoch:25	Loss:6.266	translation_Loss:3.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.532                                                   	MRR:23.33	Hits@10:41.94	Best:23.5
2024-12-27 14:31:07,050: Snapshot:1	Epoch:26	Loss:6.161	translation_Loss:3.648	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.513                                                   	MRR:23.5	Hits@10:42.51	Best:23.5
2024-12-27 14:31:14,655: Snapshot:1	Epoch:27	Loss:6.133	translation_Loss:3.635	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.499                                                   	MRR:23.6	Hits@10:42.16	Best:23.6
2024-12-27 14:31:21,881: Snapshot:1	Epoch:28	Loss:6.19	translation_Loss:3.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.539                                                   	MRR:23.56	Hits@10:42.18	Best:23.6
2024-12-27 14:31:28,960: Snapshot:1	Epoch:29	Loss:6.159	translation_Loss:3.618	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.542                                                   	MRR:23.45	Hits@10:42.46	Best:23.6
2024-12-27 14:31:36,234: Snapshot:1	Epoch:30	Loss:6.077	translation_Loss:3.561	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.516                                                   	MRR:23.42	Hits@10:42.32	Best:23.6
2024-12-27 14:31:43,418: Snapshot:1	Epoch:31	Loss:6.116	translation_Loss:3.596	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.52                                                   	MRR:23.7	Hits@10:42.24	Best:23.7
2024-12-27 14:31:50,559: Snapshot:1	Epoch:32	Loss:6.102	translation_Loss:3.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.531                                                   	MRR:23.65	Hits@10:42.35	Best:23.7
2024-12-27 14:31:57,717: Snapshot:1	Epoch:33	Loss:6.069	translation_Loss:3.561	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.508                                                   	MRR:23.63	Hits@10:42.3	Best:23.7
2024-12-27 14:32:04,959: Snapshot:1	Epoch:34	Loss:6.074	translation_Loss:3.554	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.52                                                   	MRR:23.59	Hits@10:42.47	Best:23.7
2024-12-27 14:32:12,082: Snapshot:1	Epoch:35	Loss:5.994	translation_Loss:3.503	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.491                                                   	MRR:23.51	Hits@10:42.08	Best:23.7
2024-12-27 14:32:19,328: Early Stopping! Snapshot: 1 Epoch: 36 Best Results: 23.7
2024-12-27 14:32:19,329: Start to training tokens! Snapshot: 1 Epoch: 36 Loss:6.031 MRR:23.52 Best Results: 23.7
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 14:32:19,329: Snapshot:1	Epoch:36	Loss:6.031	translation_Loss:3.511	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.521                                                   	MRR:23.52	Hits@10:42.2	Best:23.7
2024-12-27 14:32:26,537: Snapshot:1	Epoch:37	Loss:92.244	translation_Loss:92.208	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.52	Hits@10:42.2	Best:23.7
2024-12-27 14:32:33,819: End of token training: 1 Epoch: 38 Loss:92.18 MRR:23.52 Best Results: 23.7
2024-12-27 14:32:33,819: Snapshot:1	Epoch:38	Loss:92.18	translation_Loss:92.18	multi_layer_Loss:-0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.52	Hits@10:42.2	Best:23.7
2024-12-27 14:32:34,116: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_2/1model_best.tar'
2024-12-27 14:32:37,949: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3154 | 0.1992 | 0.3647 | 0.4372 |  0.5358 |
|     1      | 0.2386 | 0.1453 | 0.2657 | 0.3294 |  0.4238 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 14:33:04,091: Snapshot:2	Epoch:0	Loss:63.98	translation_Loss:30.523	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:33.457                                                   	MRR:19.01	Hits@10:34.14	Best:19.01
2024-12-27 14:33:11,941: Snapshot:2	Epoch:1	Loss:10.652	translation_Loss:9.476	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.176                                                   	MRR:20.14	Hits@10:36.33	Best:20.14
2024-12-27 14:33:19,764: Snapshot:2	Epoch:2	Loss:8.625	translation_Loss:7.309	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.316                                                   	MRR:20.5	Hits@10:36.73	Best:20.5
2024-12-27 14:33:27,613: Snapshot:2	Epoch:3	Loss:7.889	translation_Loss:6.443	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.445                                                   	MRR:20.76	Hits@10:36.91	Best:20.76
2024-12-27 14:33:35,463: Snapshot:2	Epoch:4	Loss:7.606	translation_Loss:6.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.567                                                   	MRR:20.97	Hits@10:37.47	Best:20.97
2024-12-27 14:33:43,302: Snapshot:2	Epoch:5	Loss:7.29	translation_Loss:5.615	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.675                                                   	MRR:21.16	Hits@10:37.55	Best:21.16
2024-12-27 14:33:51,100: Snapshot:2	Epoch:6	Loss:7.259	translation_Loss:5.457	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.802                                                   	MRR:21.13	Hits@10:37.65	Best:21.16
2024-12-27 14:33:58,962: Snapshot:2	Epoch:7	Loss:7.087	translation_Loss:5.193	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.895                                                   	MRR:21.25	Hits@10:37.69	Best:21.25
2024-12-27 14:34:06,808: Snapshot:2	Epoch:8	Loss:7.146	translation_Loss:5.072	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.073                                                   	MRR:21.41	Hits@10:38.1	Best:21.41
2024-12-27 14:34:14,615: Snapshot:2	Epoch:9	Loss:7.278	translation_Loss:4.897	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.381                                                   	MRR:21.3	Hits@10:38.14	Best:21.41
2024-12-27 14:34:22,930: Snapshot:2	Epoch:10	Loss:7.3	translation_Loss:4.807	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.493                                                   	MRR:21.43	Hits@10:37.95	Best:21.43
2024-12-27 14:34:30,754: Snapshot:2	Epoch:11	Loss:7.398	translation_Loss:4.767	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.631                                                   	MRR:21.42	Hits@10:38.27	Best:21.43
2024-12-27 14:34:38,563: Snapshot:2	Epoch:12	Loss:7.372	translation_Loss:4.666	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.706                                                   	MRR:21.52	Hits@10:38.33	Best:21.52
2024-12-27 14:34:46,337: Snapshot:2	Epoch:13	Loss:7.263	translation_Loss:4.565	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.698                                                   	MRR:21.31	Hits@10:38.1	Best:21.52
2024-12-27 14:34:54,133: Snapshot:2	Epoch:14	Loss:7.187	translation_Loss:4.493	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.694                                                   	MRR:21.49	Hits@10:38.49	Best:21.52
2024-12-27 14:35:02,077: Snapshot:2	Epoch:15	Loss:7.231	translation_Loss:4.499	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.732                                                   	MRR:21.52	Hits@10:38.69	Best:21.52
2024-12-27 14:35:09,976: Snapshot:2	Epoch:16	Loss:7.101	translation_Loss:4.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.709                                                   	MRR:21.53	Hits@10:38.54	Best:21.53
2024-12-27 14:35:17,828: Snapshot:2	Epoch:17	Loss:7.168	translation_Loss:4.416	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.752                                                   	MRR:21.55	Hits@10:38.51	Best:21.55
2024-12-27 14:35:25,688: Snapshot:2	Epoch:18	Loss:7.093	translation_Loss:4.372	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.721                                                   	MRR:21.64	Hits@10:38.46	Best:21.64
2024-12-27 14:35:33,464: Snapshot:2	Epoch:19	Loss:7.001	translation_Loss:4.292	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.709                                                   	MRR:21.55	Hits@10:38.67	Best:21.64
2024-12-27 14:35:41,300: Snapshot:2	Epoch:20	Loss:6.943	translation_Loss:4.252	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.69                                                   	MRR:21.51	Hits@10:38.41	Best:21.64
2024-12-27 14:35:49,104: Snapshot:2	Epoch:21	Loss:6.913	translation_Loss:4.222	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.691                                                   	MRR:21.72	Hits@10:38.66	Best:21.72
2024-12-27 14:35:56,894: Snapshot:2	Epoch:22	Loss:6.87	translation_Loss:4.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.686                                                   	MRR:21.59	Hits@10:38.65	Best:21.72
2024-12-27 14:36:04,708: Snapshot:2	Epoch:23	Loss:6.932	translation_Loss:4.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.721                                                   	MRR:21.64	Hits@10:38.4	Best:21.72
2024-12-27 14:36:12,448: Snapshot:2	Epoch:24	Loss:6.809	translation_Loss:4.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.693                                                   	MRR:21.57	Hits@10:38.64	Best:21.72
2024-12-27 14:36:20,675: Snapshot:2	Epoch:25	Loss:6.861	translation_Loss:4.156	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.705                                                   	MRR:21.59	Hits@10:38.68	Best:21.72
2024-12-27 14:36:28,442: Early Stopping! Snapshot: 2 Epoch: 26 Best Results: 21.72
2024-12-27 14:36:28,443: Start to training tokens! Snapshot: 2 Epoch: 26 Loss:6.714 MRR:21.67 Best Results: 21.72
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 14:36:28,443: Snapshot:2	Epoch:26	Loss:6.714	translation_Loss:4.061	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.652                                                   	MRR:21.67	Hits@10:38.4	Best:21.72
2024-12-27 14:36:36,278: Snapshot:2	Epoch:27	Loss:93.321	translation_Loss:93.285	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.67	Hits@10:38.4	Best:21.72
2024-12-27 14:36:44,037: End of token training: 2 Epoch: 28 Loss:93.214 MRR:21.67 Best Results: 21.72
2024-12-27 14:36:44,038: Snapshot:2	Epoch:28	Loss:93.214	translation_Loss:93.214	multi_layer_Loss:-0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.67	Hits@10:38.4	Best:21.72
2024-12-27 14:36:44,275: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_2/2model_best.tar'
2024-12-27 14:36:50,597: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3157 | 0.1996 | 0.3649 | 0.437  |  0.5359 |
|     1      | 0.2387 | 0.1452 | 0.2665 | 0.3296 |  0.4242 |
|     2      | 0.221  | 0.1313 | 0.2515 | 0.3106 |  0.3941 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 14:37:17,110: Snapshot:3	Epoch:0	Loss:61.501	translation_Loss:28.033	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:33.468                                                   	MRR:18.05	Hits@10:33.18	Best:18.05
2024-12-27 14:37:25,060: Snapshot:3	Epoch:1	Loss:9.524	translation_Loss:8.269	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.255                                                   	MRR:19.02	Hits@10:34.83	Best:19.02
2024-12-27 14:37:33,023: Snapshot:3	Epoch:2	Loss:7.706	translation_Loss:6.376	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.33                                                   	MRR:19.52	Hits@10:35.51	Best:19.52
2024-12-27 14:37:40,982: Snapshot:3	Epoch:3	Loss:6.991	translation_Loss:5.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.42                                                   	MRR:19.75	Hits@10:35.81	Best:19.75
2024-12-27 14:37:49,007: Snapshot:3	Epoch:4	Loss:6.62	translation_Loss:5.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.532                                                   	MRR:20.01	Hits@10:36.46	Best:20.01
2024-12-27 14:37:56,980: Snapshot:3	Epoch:5	Loss:6.415	translation_Loss:4.81	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.605                                                   	MRR:20.23	Hits@10:36.86	Best:20.23
2024-12-27 14:38:04,945: Snapshot:3	Epoch:6	Loss:6.326	translation_Loss:4.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.716                                                   	MRR:20.06	Hits@10:36.63	Best:20.23
2024-12-27 14:38:12,802: Snapshot:3	Epoch:7	Loss:6.296	translation_Loss:4.47	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.826                                                   	MRR:20.22	Hits@10:37.11	Best:20.23
2024-12-27 14:38:20,713: Snapshot:3	Epoch:8	Loss:6.208	translation_Loss:4.294	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.914                                                   	MRR:20.34	Hits@10:37.17	Best:20.34
2024-12-27 14:38:28,727: Snapshot:3	Epoch:9	Loss:6.355	translation_Loss:4.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.171                                                   	MRR:20.49	Hits@10:37.21	Best:20.49
2024-12-27 14:38:36,666: Snapshot:3	Epoch:10	Loss:6.442	translation_Loss:4.061	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.382                                                   	MRR:20.56	Hits@10:37.54	Best:20.56
2024-12-27 14:38:44,528: Snapshot:3	Epoch:11	Loss:6.529	translation_Loss:4.034	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.494                                                   	MRR:20.52	Hits@10:37.67	Best:20.56
2024-12-27 14:38:52,405: Snapshot:3	Epoch:12	Loss:6.591	translation_Loss:3.994	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.597                                                   	MRR:20.61	Hits@10:37.56	Best:20.61
2024-12-27 14:39:00,425: Snapshot:3	Epoch:13	Loss:6.501	translation_Loss:3.908	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.593                                                   	MRR:20.66	Hits@10:37.55	Best:20.66
2024-12-27 14:39:08,365: Snapshot:3	Epoch:14	Loss:6.493	translation_Loss:3.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.639                                                   	MRR:20.75	Hits@10:37.51	Best:20.75
2024-12-27 14:39:16,251: Snapshot:3	Epoch:15	Loss:6.416	translation_Loss:3.785	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.631                                                   	MRR:20.63	Hits@10:37.69	Best:20.75
2024-12-27 14:39:24,099: Snapshot:3	Epoch:16	Loss:6.382	translation_Loss:3.751	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.632                                                   	MRR:20.46	Hits@10:37.55	Best:20.75
2024-12-27 14:39:32,059: Snapshot:3	Epoch:17	Loss:6.38	translation_Loss:3.732	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.648                                                   	MRR:20.73	Hits@10:37.76	Best:20.75
2024-12-27 14:39:39,909: Snapshot:3	Epoch:18	Loss:6.307	translation_Loss:3.693	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.614                                                   	MRR:20.7	Hits@10:37.81	Best:20.75
2024-12-27 14:39:47,816: Early Stopping! Snapshot: 3 Epoch: 19 Best Results: 20.75
2024-12-27 14:39:47,816: Start to training tokens! Snapshot: 3 Epoch: 19 Loss:6.239 MRR:20.68 Best Results: 20.75
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 14:39:47,817: Snapshot:3	Epoch:19	Loss:6.239	translation_Loss:3.622	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.617                                                   	MRR:20.68	Hits@10:37.93	Best:20.75
2024-12-27 14:39:55,790: Snapshot:3	Epoch:20	Loss:84.378	translation_Loss:84.341	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.68	Hits@10:37.93	Best:20.75
2024-12-27 14:40:03,781: End of token training: 3 Epoch: 21 Loss:84.354 MRR:20.68 Best Results: 20.75
2024-12-27 14:40:03,781: Snapshot:3	Epoch:21	Loss:84.354	translation_Loss:84.354	multi_layer_Loss:-0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.68	Hits@10:37.93	Best:20.75
2024-12-27 14:40:04,091: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_2/3model_best.tar'
2024-12-27 14:40:13,913: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3159 | 0.2003 | 0.3657 | 0.4373 |  0.5356 |
|     1      | 0.2389 | 0.1456 | 0.2668 | 0.3294 |  0.4244 |
|     2      | 0.2212 | 0.1313 | 0.2519 | 0.3108 |  0.3939 |
|     3      | 0.2083 | 0.122  | 0.2367 | 0.2937 |  0.3757 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 14:40:34,034: Snapshot:4	Epoch:0	Loss:51.585	translation_Loss:20.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:31.53                                                   	MRR:22.62	Hits@10:40.96	Best:22.62
2024-12-27 14:40:39,767: Snapshot:4	Epoch:1	Loss:5.24	translation_Loss:4.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.672                                                   	MRR:23.56	Hits@10:42.38	Best:23.56
2024-12-27 14:40:45,468: Snapshot:4	Epoch:2	Loss:3.778	translation_Loss:3.102	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.677                                                   	MRR:23.84	Hits@10:43.27	Best:23.84
2024-12-27 14:40:51,130: Snapshot:4	Epoch:3	Loss:3.317	translation_Loss:2.62	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.698                                                   	MRR:23.87	Hits@10:43.52	Best:23.87
2024-12-27 14:40:56,948: Snapshot:4	Epoch:4	Loss:3.06	translation_Loss:2.337	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.723                                                   	MRR:24.29	Hits@10:43.67	Best:24.29
2024-12-27 14:41:02,688: Snapshot:4	Epoch:5	Loss:2.944	translation_Loss:2.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.76                                                   	MRR:24.34	Hits@10:43.77	Best:24.34
2024-12-27 14:41:08,323: Snapshot:4	Epoch:6	Loss:2.886	translation_Loss:2.098	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.789                                                   	MRR:24.81	Hits@10:43.7	Best:24.81
2024-12-27 14:41:14,073: Snapshot:4	Epoch:7	Loss:2.802	translation_Loss:1.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.816                                                   	MRR:24.57	Hits@10:44.32	Best:24.81
2024-12-27 14:41:19,769: Snapshot:4	Epoch:8	Loss:2.779	translation_Loss:1.925	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.854                                                   	MRR:24.61	Hits@10:44.14	Best:24.81
2024-12-27 14:41:25,351: Snapshot:4	Epoch:9	Loss:2.716	translation_Loss:1.835	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.88                                                   	MRR:24.8	Hits@10:44.31	Best:24.81
2024-12-27 14:41:30,930: Snapshot:4	Epoch:10	Loss:2.732	translation_Loss:1.801	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.931                                                   	MRR:24.79	Hits@10:44.56	Best:24.81
2024-12-27 14:41:36,599: Snapshot:4	Epoch:11	Loss:2.673	translation_Loss:1.733	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.94                                                   	MRR:24.97	Hits@10:44.32	Best:24.97
2024-12-27 14:41:42,238: Snapshot:4	Epoch:12	Loss:2.718	translation_Loss:1.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.999                                                   	MRR:25.11	Hits@10:45.02	Best:25.11
2024-12-27 14:41:47,843: Snapshot:4	Epoch:13	Loss:2.777	translation_Loss:1.682	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.095                                                   	MRR:25.07	Hits@10:44.83	Best:25.11
2024-12-27 14:41:53,516: Snapshot:4	Epoch:14	Loss:2.959	translation_Loss:1.626	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.333                                                   	MRR:25.4	Hits@10:44.95	Best:25.4
2024-12-27 14:41:59,095: Snapshot:4	Epoch:15	Loss:2.992	translation_Loss:1.646	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.345                                                   	MRR:25.27	Hits@10:45.12	Best:25.4
2024-12-27 14:42:04,704: Snapshot:4	Epoch:16	Loss:2.958	translation_Loss:1.595	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.363                                                   	MRR:25.28	Hits@10:45.14	Best:25.4
2024-12-27 14:42:10,325: Snapshot:4	Epoch:17	Loss:3.038	translation_Loss:1.58	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.458                                                   	MRR:25.36	Hits@10:44.96	Best:25.4
2024-12-27 14:42:15,972: Snapshot:4	Epoch:18	Loss:3.052	translation_Loss:1.573	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.479                                                   	MRR:25.5	Hits@10:45.17	Best:25.5
2024-12-27 14:42:21,779: Snapshot:4	Epoch:19	Loss:3.073	translation_Loss:1.547	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.525                                                   	MRR:25.55	Hits@10:44.83	Best:25.55
2024-12-27 14:42:27,368: Snapshot:4	Epoch:20	Loss:3.066	translation_Loss:1.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.52                                                   	MRR:25.08	Hits@10:45.2	Best:25.55
2024-12-27 14:42:33,025: Snapshot:4	Epoch:21	Loss:3.034	translation_Loss:1.518	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.516                                                   	MRR:25.35	Hits@10:44.98	Best:25.55
2024-12-27 14:42:38,634: Snapshot:4	Epoch:22	Loss:3.036	translation_Loss:1.483	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.553                                                   	MRR:25.22	Hits@10:44.86	Best:25.55
2024-12-27 14:42:44,399: Snapshot:4	Epoch:23	Loss:2.983	translation_Loss:1.467	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.516                                                   	MRR:25.2	Hits@10:44.81	Best:25.55
2024-12-27 14:42:49,972: Early Stopping! Snapshot: 4 Epoch: 24 Best Results: 25.55
2024-12-27 14:42:49,972: Start to training tokens! Snapshot: 4 Epoch: 24 Loss:3.002 MRR:25.14 Best Results: 25.55
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 14:42:49,973: Snapshot:4	Epoch:24	Loss:3.002	translation_Loss:1.472	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.53                                                   	MRR:25.14	Hits@10:45.14	Best:25.55
2024-12-27 14:42:55,690: Snapshot:4	Epoch:25	Loss:46.078	translation_Loss:46.042	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.14	Hits@10:45.14	Best:25.55
2024-12-27 14:43:01,306: End of token training: 4 Epoch: 26 Loss:46.017 MRR:25.14 Best Results: 25.55
2024-12-27 14:43:01,306: Snapshot:4	Epoch:26	Loss:46.017	translation_Loss:46.017	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.14	Hits@10:45.14	Best:25.55
2024-12-27 14:43:01,615: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_2/4model_best.tar'
2024-12-27 14:43:13,805: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.316  | 0.2002 | 0.366  | 0.4369 |  0.5356 |
|     1      | 0.2393 | 0.146  | 0.267  | 0.3298 |  0.425  |
|     2      | 0.2216 | 0.132  | 0.2523 | 0.3109 |  0.3945 |
|     3      | 0.2086 | 0.1225 | 0.2373 | 0.294  |  0.3764 |
|     4      | 0.2558 | 0.1512 | 0.301  | 0.3703 |  0.4586 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 14:43:13,808: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3153 | 0.199  | 0.3645 | 0.4372 |  0.5359 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3154 | 0.1992 | 0.3647 | 0.4372 |  0.5358 |
|     1      | 0.2386 | 0.1453 | 0.2657 | 0.3294 |  0.4238 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3157 | 0.1996 | 0.3649 | 0.437  |  0.5359 |
|     1      | 0.2387 | 0.1452 | 0.2665 | 0.3296 |  0.4242 |
|     2      | 0.221  | 0.1313 | 0.2515 | 0.3106 |  0.3941 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3159 | 0.2003 | 0.3657 | 0.4373 |  0.5356 |
|     1      | 0.2389 | 0.1456 | 0.2668 | 0.3294 |  0.4244 |
|     2      | 0.2212 | 0.1313 | 0.2519 | 0.3108 |  0.3939 |
|     3      | 0.2083 | 0.122  | 0.2367 | 0.2937 |  0.3757 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.316  | 0.2002 | 0.366  | 0.4369 |  0.5356 |
|     1      | 0.2393 | 0.146  | 0.267  | 0.3298 |  0.425  |
|     2      | 0.2216 | 0.132  | 0.2523 | 0.3109 |  0.3945 |
|     3      | 0.2086 | 0.1225 | 0.2373 | 0.294  |  0.3764 |
|     4      | 0.2558 | 0.1512 | 0.301  | 0.3703 |  0.4586 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 14:43:13,808: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 48.66216993331909  |   0.315   |    0.199     |    0.364     |     0.536     |
|    1     | 297.2142734527588  |   0.269   |    0.166     |    0.304     |     0.468     |
|    2     | 243.38943099975586 |    0.25   |    0.153     |    0.284     |      0.44     |
|    3     | 189.9044704437256  |   0.239   |    0.145     |    0.272     |     0.422     |
|    4     | 164.66034960746765 |   0.242   |    0.146     |    0.277     |     0.428     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 14:43:13,808: Sum_Training_Time:943.830694437027
2024-12-27 14:43:13,808: Every_Training_Time:[48.66216993331909, 297.2142734527588, 243.38943099975586, 189.9044704437256, 164.66034960746765]
2024-12-27 14:43:13,808: Forward transfer: 0.038000000000000006 Backward transfer: 0.0005749999999999922
2024-12-27 14:43:47,796: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227144318/ENTITYentity_0.01_512_4', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_512_4', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_512_4', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=4, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 14:43:55,453: Snapshot:0	Epoch:0	Loss:52.473	translation_Loss:52.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.0	Hits@10:48.53	Best:26.0
2024-12-27 14:43:59,484: Snapshot:0	Epoch:1	Loss:15.795	translation_Loss:15.795	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.58	Hits@10:53.33	Best:30.58
2024-12-27 14:44:03,428: Snapshot:0	Epoch:2	Loss:6.254	translation_Loss:6.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.97	Hits@10:53.26	Best:30.97
2024-12-27 14:44:07,387: Snapshot:0	Epoch:3	Loss:3.612	translation_Loss:3.612	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.3	Hits@10:53.38	Best:31.3
2024-12-27 14:44:11,328: Snapshot:0	Epoch:4	Loss:2.598	translation_Loss:2.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.51	Hits@10:52.87	Best:31.3
2024-12-27 14:44:15,182: Snapshot:0	Epoch:5	Loss:2.123	translation_Loss:2.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.74	Hits@10:53.02	Best:31.3
2024-12-27 14:44:19,063: Snapshot:0	Epoch:6	Loss:1.878	translation_Loss:1.878	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.69	Hits@10:52.96	Best:31.3
2024-12-27 14:44:22,938: Snapshot:0	Epoch:7	Loss:1.671	translation_Loss:1.671	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.73	Hits@10:52.49	Best:31.3
2024-12-27 14:44:26,859: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 31.3
2024-12-27 14:44:26,859: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:1.496 MRR:30.36 Best Results: 31.3
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 14:44:26,859: Snapshot:0	Epoch:8	Loss:1.496	translation_Loss:1.496	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.36	Hits@10:52.55	Best:31.3
2024-12-27 14:44:31,560: Snapshot:0	Epoch:9	Loss:55.357	translation_Loss:55.321	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.36	Hits@10:52.55	Best:31.3
2024-12-27 14:44:35,762: End of token training: 0 Epoch: 10 Loss:55.339 MRR:30.36 Best Results: 31.3
2024-12-27 14:44:35,763: Snapshot:0	Epoch:10	Loss:55.339	translation_Loss:55.339	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.36	Hits@10:52.55	Best:31.3
2024-12-27 14:44:36,065: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_4/0model_best.tar'
2024-12-27 14:44:37,383: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3153 | 0.1995 | 0.3641 | 0.4348 |  0.5372 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 14:45:02,165: Snapshot:1	Epoch:0	Loss:103.494	translation_Loss:31.892	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:71.602                                                   	MRR:21.19	Hits@10:38.11	Best:21.19
2024-12-27 14:45:09,383: Snapshot:1	Epoch:1	Loss:9.924	translation_Loss:9.437	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.487                                                   	MRR:22.05	Hits@10:39.55	Best:22.05
2024-12-27 14:45:16,642: Snapshot:1	Epoch:2	Loss:7.738	translation_Loss:7.137	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.601                                                   	MRR:22.47	Hits@10:40.39	Best:22.47
2024-12-27 14:45:23,807: Snapshot:1	Epoch:3	Loss:8.122	translation_Loss:7.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.879                                                   	MRR:22.89	Hits@10:41.05	Best:22.89
2024-12-27 14:45:30,982: Snapshot:1	Epoch:4	Loss:6.749	translation_Loss:5.668	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.082                                                   	MRR:22.86	Hits@10:41.12	Best:22.89
2024-12-27 14:45:38,204: Snapshot:1	Epoch:5	Loss:6.354	translation_Loss:5.333	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.021                                                   	MRR:23.0	Hits@10:41.22	Best:23.0
2024-12-27 14:45:45,306: Snapshot:1	Epoch:6	Loss:6.197	translation_Loss:5.023	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.174                                                   	MRR:22.94	Hits@10:41.2	Best:23.0
2024-12-27 14:45:52,620: Snapshot:1	Epoch:7	Loss:6.268	translation_Loss:4.9	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.368                                                   	MRR:23.19	Hits@10:41.39	Best:23.19
2024-12-27 14:45:59,877: Snapshot:1	Epoch:8	Loss:6.231	translation_Loss:4.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.551                                                   	MRR:23.19	Hits@10:41.83	Best:23.19
2024-12-27 14:46:07,017: Snapshot:1	Epoch:9	Loss:6.683	translation_Loss:4.554	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.129                                                   	MRR:23.2	Hits@10:41.7	Best:23.2
2024-12-27 14:46:14,108: Snapshot:1	Epoch:10	Loss:7.035	translation_Loss:4.386	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.65                                                   	MRR:23.09	Hits@10:41.63	Best:23.2
2024-12-27 14:46:21,643: Snapshot:1	Epoch:11	Loss:7.31	translation_Loss:4.29	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.019                                                   	MRR:23.05	Hits@10:41.67	Best:23.2
2024-12-27 14:46:28,773: Snapshot:1	Epoch:12	Loss:7.597	translation_Loss:4.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.34                                                   	MRR:23.28	Hits@10:41.91	Best:23.28
2024-12-27 14:46:35,918: Snapshot:1	Epoch:13	Loss:7.59	translation_Loss:4.188	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.402                                                   	MRR:23.2	Hits@10:41.67	Best:23.28
2024-12-27 14:46:43,075: Snapshot:1	Epoch:14	Loss:7.519	translation_Loss:4.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.431                                                   	MRR:23.44	Hits@10:42.14	Best:23.44
2024-12-27 14:46:50,224: Snapshot:1	Epoch:15	Loss:7.49	translation_Loss:4.046	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.445                                                   	MRR:23.4	Hits@10:41.91	Best:23.44
2024-12-27 14:46:57,469: Snapshot:1	Epoch:16	Loss:7.448	translation_Loss:3.978	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.47                                                   	MRR:23.4	Hits@10:41.88	Best:23.44
2024-12-27 14:47:04,703: Snapshot:1	Epoch:17	Loss:7.469	translation_Loss:3.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.49                                                   	MRR:23.49	Hits@10:42.08	Best:23.49
2024-12-27 14:47:11,725: Snapshot:1	Epoch:18	Loss:7.391	translation_Loss:3.957	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.435                                                   	MRR:23.38	Hits@10:41.96	Best:23.49
2024-12-27 14:47:18,829: Snapshot:1	Epoch:19	Loss:7.349	translation_Loss:3.883	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.466                                                   	MRR:23.39	Hits@10:42.25	Best:23.49
2024-12-27 14:47:25,955: Snapshot:1	Epoch:20	Loss:7.282	translation_Loss:3.849	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.432                                                   	MRR:23.29	Hits@10:41.77	Best:23.49
2024-12-27 14:47:33,061: Snapshot:1	Epoch:21	Loss:7.304	translation_Loss:3.862	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.442                                                   	MRR:23.52	Hits@10:41.87	Best:23.52
2024-12-27 14:47:40,174: Snapshot:1	Epoch:22	Loss:7.263	translation_Loss:3.812	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.451                                                   	MRR:23.37	Hits@10:41.92	Best:23.52
2024-12-27 14:47:47,177: Snapshot:1	Epoch:23	Loss:7.216	translation_Loss:3.753	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.463                                                   	MRR:23.63	Hits@10:42.32	Best:23.63
2024-12-27 14:47:54,289: Snapshot:1	Epoch:24	Loss:7.157	translation_Loss:3.725	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.432                                                   	MRR:23.53	Hits@10:42.13	Best:23.63
2024-12-27 14:48:01,446: Snapshot:1	Epoch:25	Loss:7.131	translation_Loss:3.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.419                                                   	MRR:23.5	Hits@10:42.13	Best:23.63
2024-12-27 14:48:08,565: Snapshot:1	Epoch:26	Loss:7.037	translation_Loss:3.631	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.406                                                   	MRR:23.43	Hits@10:42.24	Best:23.63
2024-12-27 14:48:16,157: Snapshot:1	Epoch:27	Loss:6.994	translation_Loss:3.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.385                                                   	MRR:23.38	Hits@10:42.15	Best:23.63
2024-12-27 14:48:23,225: Early Stopping! Snapshot: 1 Epoch: 28 Best Results: 23.63
2024-12-27 14:48:23,225: Start to training tokens! Snapshot: 1 Epoch: 28 Loss:7.095 MRR:23.23 Best Results: 23.63
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 14:48:23,225: Snapshot:1	Epoch:28	Loss:7.095	translation_Loss:3.636	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.459                                                   	MRR:23.23	Hits@10:42.16	Best:23.63
2024-12-27 14:48:30,392: Snapshot:1	Epoch:29	Loss:92.622	translation_Loss:92.586	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.23	Hits@10:42.16	Best:23.63
2024-12-27 14:48:37,534: End of token training: 1 Epoch: 30 Loss:92.428 MRR:23.23 Best Results: 23.63
2024-12-27 14:48:37,534: Snapshot:1	Epoch:30	Loss:92.428	translation_Loss:92.428	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.23	Hits@10:42.16	Best:23.63
2024-12-27 14:48:37,771: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_4/1model_best.tar'
2024-12-27 14:48:41,325: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3151 | 0.1993 | 0.3636 | 0.4343 |  0.5369 |
|     1      | 0.2357 | 0.1404 | 0.2649 | 0.3311 |  0.4252 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 14:49:07,512: Snapshot:2	Epoch:0	Loss:96.241	translation_Loss:30.627	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:65.614                                                   	MRR:18.86	Hits@10:33.87	Best:18.86
2024-12-27 14:49:15,248: Snapshot:2	Epoch:1	Loss:10.239	translation_Loss:9.514	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.725                                                   	MRR:20.09	Hits@10:35.83	Best:20.09
2024-12-27 14:49:22,976: Snapshot:2	Epoch:2	Loss:8.194	translation_Loss:7.319	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.875                                                   	MRR:20.51	Hits@10:36.64	Best:20.51
2024-12-27 14:49:30,748: Snapshot:2	Epoch:3	Loss:7.463	translation_Loss:6.433	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.03                                                   	MRR:20.77	Hits@10:37.2	Best:20.77
2024-12-27 14:49:38,514: Snapshot:2	Epoch:4	Loss:7.146	translation_Loss:5.972	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.174                                                   	MRR:21.03	Hits@10:37.24	Best:21.03
2024-12-27 14:49:46,281: Snapshot:2	Epoch:5	Loss:6.972	translation_Loss:5.647	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.325                                                   	MRR:21.02	Hits@10:37.63	Best:21.03
2024-12-27 14:49:53,989: Snapshot:2	Epoch:6	Loss:6.882	translation_Loss:5.389	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.493                                                   	MRR:21.13	Hits@10:37.7	Best:21.13
2024-12-27 14:50:01,786: Snapshot:2	Epoch:7	Loss:6.84	translation_Loss:5.173	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.667                                                   	MRR:21.25	Hits@10:37.83	Best:21.25
2024-12-27 14:50:09,895: Snapshot:2	Epoch:8	Loss:6.916	translation_Loss:5.018	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.898                                                   	MRR:21.33	Hits@10:38.01	Best:21.33
2024-12-27 14:50:17,722: Snapshot:2	Epoch:9	Loss:7.7	translation_Loss:4.895	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.805                                                   	MRR:21.37	Hits@10:37.94	Best:21.37
2024-12-27 14:50:25,499: Snapshot:2	Epoch:10	Loss:7.901	translation_Loss:4.818	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.083                                                   	MRR:21.27	Hits@10:38.09	Best:21.37
2024-12-27 14:50:33,264: Snapshot:2	Epoch:11	Loss:8.081	translation_Loss:4.7	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.381                                                   	MRR:21.29	Hits@10:38.09	Best:21.37
2024-12-27 14:50:40,963: Snapshot:2	Epoch:12	Loss:8.175	translation_Loss:4.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.586                                                   	MRR:21.35	Hits@10:38.13	Best:21.37
2024-12-27 14:50:48,704: Snapshot:2	Epoch:13	Loss:8.23	translation_Loss:4.551	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.68                                                   	MRR:21.48	Hits@10:38.05	Best:21.48
2024-12-27 14:50:56,495: Snapshot:2	Epoch:14	Loss:8.122	translation_Loss:4.483	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.639                                                   	MRR:21.55	Hits@10:38.43	Best:21.55
2024-12-27 14:51:04,253: Snapshot:2	Epoch:15	Loss:8.007	translation_Loss:4.384	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.623                                                   	MRR:21.6	Hits@10:38.31	Best:21.6
2024-12-27 14:51:12,125: Snapshot:2	Epoch:16	Loss:8.016	translation_Loss:4.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.649                                                   	MRR:21.64	Hits@10:38.37	Best:21.64
2024-12-27 14:51:19,947: Snapshot:2	Epoch:17	Loss:8.033	translation_Loss:4.371	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.663                                                   	MRR:21.58	Hits@10:38.14	Best:21.64
2024-12-27 14:51:27,770: Snapshot:2	Epoch:18	Loss:7.895	translation_Loss:4.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.653                                                   	MRR:21.71	Hits@10:38.41	Best:21.71
2024-12-27 14:51:35,688: Snapshot:2	Epoch:19	Loss:7.955	translation_Loss:4.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.667                                                   	MRR:21.7	Hits@10:38.78	Best:21.71
2024-12-27 14:51:43,399: Snapshot:2	Epoch:20	Loss:7.833	translation_Loss:4.201	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.632                                                   	MRR:21.75	Hits@10:38.61	Best:21.75
2024-12-27 14:51:51,668: Snapshot:2	Epoch:21	Loss:7.867	translation_Loss:4.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.648                                                   	MRR:21.58	Hits@10:38.69	Best:21.75
2024-12-27 14:51:59,402: Snapshot:2	Epoch:22	Loss:7.809	translation_Loss:4.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.632                                                   	MRR:21.7	Hits@10:38.62	Best:21.75
2024-12-27 14:52:07,208: Snapshot:2	Epoch:23	Loss:7.86	translation_Loss:4.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.682                                                   	MRR:21.74	Hits@10:38.55	Best:21.75
2024-12-27 14:52:14,916: Snapshot:2	Epoch:24	Loss:7.774	translation_Loss:4.141	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.633                                                   	MRR:21.58	Hits@10:38.57	Best:21.75
2024-12-27 14:52:22,764: Early Stopping! Snapshot: 2 Epoch: 25 Best Results: 21.75
2024-12-27 14:52:22,764: Start to training tokens! Snapshot: 2 Epoch: 25 Loss:7.679 MRR:21.71 Best Results: 21.75
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 14:52:22,765: Snapshot:2	Epoch:25	Loss:7.679	translation_Loss:4.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.599                                                   	MRR:21.71	Hits@10:38.79	Best:21.75
2024-12-27 14:52:30,477: Snapshot:2	Epoch:26	Loss:93.54	translation_Loss:93.504	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.71	Hits@10:38.79	Best:21.75
2024-12-27 14:52:38,296: End of token training: 2 Epoch: 27 Loss:93.337 MRR:21.71 Best Results: 21.75
2024-12-27 14:52:38,296: Snapshot:2	Epoch:27	Loss:93.337	translation_Loss:93.337	multi_layer_Loss:-0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.71	Hits@10:38.79	Best:21.75
2024-12-27 14:52:38,574: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_4/2model_best.tar'
2024-12-27 14:52:45,298: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.315  | 0.1989 | 0.3642 | 0.4344 |  0.5369 |
|     1      | 0.2358 | 0.1404 | 0.2649 | 0.331  |  0.4253 |
|     2      | 0.2209 | 0.1324 | 0.2497 | 0.3062 |  0.3905 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 14:53:11,454: Snapshot:3	Epoch:0	Loss:93.528	translation_Loss:28.047	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:65.481                                                   	MRR:18.13	Hits@10:32.93	Best:18.13
2024-12-27 14:53:19,427: Snapshot:3	Epoch:1	Loss:9.015	translation_Loss:8.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.809                                                   	MRR:19.3	Hits@10:34.8	Best:19.3
2024-12-27 14:53:27,304: Snapshot:3	Epoch:2	Loss:7.259	translation_Loss:6.334	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.926                                                   	MRR:19.79	Hits@10:35.68	Best:19.79
2024-12-27 14:53:35,191: Snapshot:3	Epoch:3	Loss:6.652	translation_Loss:5.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.049                                                   	MRR:20.1	Hits@10:36.36	Best:20.1
2024-12-27 14:53:43,274: Snapshot:3	Epoch:4	Loss:6.241	translation_Loss:5.081	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.159                                                   	MRR:20.18	Hits@10:36.35	Best:20.18
2024-12-27 14:53:51,160: Snapshot:3	Epoch:5	Loss:6.179	translation_Loss:4.88	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.298                                                   	MRR:20.22	Hits@10:36.58	Best:20.22
2024-12-27 14:53:59,161: Snapshot:3	Epoch:6	Loss:6.086	translation_Loss:4.646	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.44                                                   	MRR:20.48	Hits@10:36.77	Best:20.48
2024-12-27 14:54:07,111: Snapshot:3	Epoch:7	Loss:6.021	translation_Loss:4.452	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.569                                                   	MRR:20.4	Hits@10:37.14	Best:20.48
2024-12-27 14:54:15,007: Snapshot:3	Epoch:8	Loss:6.091	translation_Loss:4.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.773                                                   	MRR:20.53	Hits@10:37.14	Best:20.53
2024-12-27 14:54:22,880: Snapshot:3	Epoch:9	Loss:6.638	translation_Loss:4.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.403                                                   	MRR:20.55	Hits@10:37.07	Best:20.55
2024-12-27 14:54:31,338: Snapshot:3	Epoch:10	Loss:6.882	translation_Loss:4.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.794                                                   	MRR:20.67	Hits@10:37.26	Best:20.67
2024-12-27 14:54:39,242: Snapshot:3	Epoch:11	Loss:7.133	translation_Loss:4.031	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.102                                                   	MRR:20.69	Hits@10:37.43	Best:20.69
2024-12-27 14:54:47,224: Snapshot:3	Epoch:12	Loss:7.394	translation_Loss:3.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.431                                                   	MRR:20.94	Hits@10:37.4	Best:20.94
2024-12-27 14:54:55,171: Snapshot:3	Epoch:13	Loss:7.413	translation_Loss:3.895	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.517                                                   	MRR:20.84	Hits@10:37.45	Best:20.94
2024-12-27 14:55:03,276: Snapshot:3	Epoch:14	Loss:7.394	translation_Loss:3.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.527                                                   	MRR:20.75	Hits@10:37.45	Best:20.94
2024-12-27 14:55:11,147: Snapshot:3	Epoch:15	Loss:7.329	translation_Loss:3.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.567                                                   	MRR:20.71	Hits@10:37.31	Best:20.94
2024-12-27 14:55:19,086: Snapshot:3	Epoch:16	Loss:7.329	translation_Loss:3.77	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.559                                                   	MRR:20.96	Hits@10:37.79	Best:20.96
2024-12-27 14:55:26,921: Snapshot:3	Epoch:17	Loss:7.241	translation_Loss:3.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.515                                                   	MRR:20.96	Hits@10:37.96	Best:20.96
2024-12-27 14:55:34,838: Snapshot:3	Epoch:18	Loss:7.225	translation_Loss:3.686	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.539                                                   	MRR:20.92	Hits@10:37.99	Best:20.96
2024-12-27 14:55:42,739: Snapshot:3	Epoch:19	Loss:7.158	translation_Loss:3.625	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.532                                                   	MRR:20.99	Hits@10:37.87	Best:20.99
2024-12-27 14:55:50,696: Snapshot:3	Epoch:20	Loss:7.145	translation_Loss:3.632	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.513                                                   	MRR:20.95	Hits@10:37.82	Best:20.99
2024-12-27 14:55:58,548: Snapshot:3	Epoch:21	Loss:7.1	translation_Loss:3.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.537                                                   	MRR:20.86	Hits@10:37.74	Best:20.99
2024-12-27 14:56:06,520: Snapshot:3	Epoch:22	Loss:7.048	translation_Loss:3.53	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.518                                                   	MRR:20.88	Hits@10:37.88	Best:20.99
2024-12-27 14:56:14,421: Snapshot:3	Epoch:23	Loss:7.145	translation_Loss:3.555	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.59                                                   	MRR:20.98	Hits@10:37.82	Best:20.99
2024-12-27 14:56:22,248: Early Stopping! Snapshot: 3 Epoch: 24 Best Results: 20.99
2024-12-27 14:56:22,248: Start to training tokens! Snapshot: 3 Epoch: 24 Loss:6.999 MRR:20.92 Best Results: 20.99
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 14:56:22,249: Snapshot:3	Epoch:24	Loss:6.999	translation_Loss:3.505	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.494                                                   	MRR:20.92	Hits@10:38.06	Best:20.99
2024-12-27 14:56:30,499: Snapshot:3	Epoch:25	Loss:84.321	translation_Loss:84.286	multi_layer_Loss:0.035	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.92	Hits@10:38.06	Best:20.99
2024-12-27 14:56:38,319: End of token training: 3 Epoch: 26 Loss:84.336 MRR:20.92 Best Results: 20.99
2024-12-27 14:56:38,319: Snapshot:3	Epoch:26	Loss:84.336	translation_Loss:84.336	multi_layer_Loss:-0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.92	Hits@10:38.06	Best:20.99
2024-12-27 14:56:38,558: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_4/3model_best.tar'
2024-12-27 14:56:47,835: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.315  | 0.1991 | 0.3642 | 0.4349 |  0.5371 |
|     1      | 0.2356 | 0.1401 | 0.2653 | 0.3308 |  0.425  |
|     2      | 0.221  | 0.1325 | 0.2501 | 0.3063 |  0.3907 |
|     3      | 0.2097 | 0.1234 | 0.2377 | 0.295  |  0.3772 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 14:57:08,069: Snapshot:4	Epoch:0	Loss:82.262	translation_Loss:19.904	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:62.358                                                   	MRR:22.74	Hits@10:40.97	Best:22.74
2024-12-27 14:57:13,718: Snapshot:4	Epoch:1	Loss:4.928	translation_Loss:4.503	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.425                                                   	MRR:23.84	Hits@10:42.35	Best:23.84
2024-12-27 14:57:19,382: Snapshot:4	Epoch:2	Loss:3.52	translation_Loss:3.078	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.443                                                   	MRR:24.15	Hits@10:43.08	Best:24.15
2024-12-27 14:57:25,007: Snapshot:4	Epoch:3	Loss:3.105	translation_Loss:2.627	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.478                                                   	MRR:24.34	Hits@10:43.63	Best:24.34
2024-12-27 14:57:30,627: Snapshot:4	Epoch:4	Loss:2.901	translation_Loss:2.381	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.519                                                   	MRR:24.08	Hits@10:43.61	Best:24.34
2024-12-27 14:57:36,279: Snapshot:4	Epoch:5	Loss:2.722	translation_Loss:2.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.545                                                   	MRR:24.3	Hits@10:43.39	Best:24.34
2024-12-27 14:57:41,972: Snapshot:4	Epoch:6	Loss:2.678	translation_Loss:2.103	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.575                                                   	MRR:24.41	Hits@10:43.64	Best:24.41
2024-12-27 14:57:47,590: Snapshot:4	Epoch:7	Loss:2.62	translation_Loss:1.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.626                                                   	MRR:24.84	Hits@10:44.51	Best:24.84
2024-12-27 14:57:53,188: Snapshot:4	Epoch:8	Loss:2.577	translation_Loss:1.919	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.658                                                   	MRR:24.95	Hits@10:44.59	Best:24.95
2024-12-27 14:57:58,803: Snapshot:4	Epoch:9	Loss:2.575	translation_Loss:1.865	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.71                                                   	MRR:24.75	Hits@10:44.64	Best:24.95
2024-12-27 14:58:04,403: Snapshot:4	Epoch:10	Loss:2.503	translation_Loss:1.778	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.725                                                   	MRR:24.53	Hits@10:44.17	Best:24.95
2024-12-27 14:58:10,047: Snapshot:4	Epoch:11	Loss:2.546	translation_Loss:1.749	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.797                                                   	MRR:24.71	Hits@10:44.26	Best:24.95
2024-12-27 14:58:15,616: Snapshot:4	Epoch:12	Loss:2.542	translation_Loss:1.666	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.877                                                   	MRR:24.82	Hits@10:44.2	Best:24.95
2024-12-27 14:58:21,218: Snapshot:4	Epoch:13	Loss:2.707	translation_Loss:1.688	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.019                                                   	MRR:25.08	Hits@10:44.76	Best:25.08
2024-12-27 14:58:26,799: Snapshot:4	Epoch:14	Loss:3.429	translation_Loss:1.655	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.773                                                   	MRR:25.05	Hits@10:44.75	Best:25.08
2024-12-27 14:58:32,488: Snapshot:4	Epoch:15	Loss:3.244	translation_Loss:1.63	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.614                                                   	MRR:25.19	Hits@10:44.7	Best:25.19
2024-12-27 14:58:38,043: Snapshot:4	Epoch:16	Loss:3.315	translation_Loss:1.555	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.761                                                   	MRR:25.14	Hits@10:44.81	Best:25.19
2024-12-27 14:58:43,616: Snapshot:4	Epoch:17	Loss:3.618	translation_Loss:1.617	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.001                                                   	MRR:24.91	Hits@10:44.83	Best:25.19
2024-12-27 14:58:49,231: Snapshot:4	Epoch:18	Loss:3.675	translation_Loss:1.591	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.084                                                   	MRR:24.78	Hits@10:44.39	Best:25.19
2024-12-27 14:58:54,787: Snapshot:4	Epoch:19	Loss:3.699	translation_Loss:1.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.132                                                   	MRR:25.17	Hits@10:44.88	Best:25.19
2024-12-27 14:59:00,463: Snapshot:4	Epoch:20	Loss:3.698	translation_Loss:1.523	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.175                                                   	MRR:25.31	Hits@10:44.92	Best:25.31
2024-12-27 14:59:06,135: Snapshot:4	Epoch:21	Loss:3.666	translation_Loss:1.496	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.17                                                   	MRR:25.24	Hits@10:44.71	Best:25.31
2024-12-27 14:59:11,721: Snapshot:4	Epoch:22	Loss:3.685	translation_Loss:1.511	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.174                                                   	MRR:25.07	Hits@10:44.72	Best:25.31
2024-12-27 14:59:17,354: Snapshot:4	Epoch:23	Loss:3.619	translation_Loss:1.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.139                                                   	MRR:25.35	Hits@10:44.99	Best:25.35
2024-12-27 14:59:22,965: Snapshot:4	Epoch:24	Loss:3.603	translation_Loss:1.457	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.145                                                   	MRR:25.57	Hits@10:44.82	Best:25.57
2024-12-27 14:59:28,561: Snapshot:4	Epoch:25	Loss:3.65	translation_Loss:1.479	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.171                                                   	MRR:25.56	Hits@10:45.0	Best:25.57
2024-12-27 14:59:34,168: Snapshot:4	Epoch:26	Loss:3.602	translation_Loss:1.446	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.156                                                   	MRR:25.42	Hits@10:44.97	Best:25.57
2024-12-27 14:59:39,821: Snapshot:4	Epoch:27	Loss:3.589	translation_Loss:1.446	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.143                                                   	MRR:25.27	Hits@10:44.46	Best:25.57
2024-12-27 14:59:45,416: Snapshot:4	Epoch:28	Loss:3.603	translation_Loss:1.44	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.163                                                   	MRR:25.23	Hits@10:44.69	Best:25.57
2024-12-27 14:59:51,058: Early Stopping! Snapshot: 4 Epoch: 29 Best Results: 25.57
2024-12-27 14:59:51,058: Start to training tokens! Snapshot: 4 Epoch: 29 Loss:3.573 MRR:25.37 Best Results: 25.57
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 14:59:51,059: Snapshot:4	Epoch:29	Loss:3.573	translation_Loss:1.421	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.153                                                   	MRR:25.37	Hits@10:44.74	Best:25.57
2024-12-27 14:59:56,754: Snapshot:4	Epoch:30	Loss:46.522	translation_Loss:46.486	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.37	Hits@10:44.74	Best:25.57
2024-12-27 15:00:02,366: End of token training: 4 Epoch: 31 Loss:46.471 MRR:25.37 Best Results: 25.57
2024-12-27 15:00:02,366: Snapshot:4	Epoch:31	Loss:46.471	translation_Loss:46.471	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.37	Hits@10:44.74	Best:25.57
2024-12-27 15:00:02,677: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_4/4model_best.tar'
2024-12-27 15:00:15,476: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3149 | 0.1987 | 0.3645 | 0.4347 |  0.5373 |
|     1      | 0.2355 | 0.1399 | 0.265  | 0.3308 |  0.425  |
|     2      | 0.2212 | 0.1329 | 0.2499 | 0.3065 |  0.3905 |
|     3      | 0.2097 | 0.1234 | 0.237  | 0.2951 |  0.3774 |
|     4      | 0.2561 | 0.1516 | 0.3033 | 0.3718 |  0.4543 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 15:00:15,478: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3153 | 0.1995 | 0.3641 | 0.4348 |  0.5372 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3151 | 0.1993 | 0.3636 | 0.4343 |  0.5369 |
|     1      | 0.2357 | 0.1404 | 0.2649 | 0.3311 |  0.4252 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.315  | 0.1989 | 0.3642 | 0.4344 |  0.5369 |
|     1      | 0.2358 | 0.1404 | 0.2649 | 0.331  |  0.4253 |
|     2      | 0.2209 | 0.1324 | 0.2497 | 0.3062 |  0.3905 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.315  | 0.1991 | 0.3642 | 0.4349 |  0.5371 |
|     1      | 0.2356 | 0.1401 | 0.2653 | 0.3308 |  0.425  |
|     2      | 0.221  | 0.1325 | 0.2501 | 0.3063 |  0.3907 |
|     3      | 0.2097 | 0.1234 | 0.2377 | 0.295  |  0.3772 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3149 | 0.1987 | 0.3645 | 0.4347 |  0.5373 |
|     1      | 0.2355 | 0.1399 | 0.265  | 0.3308 |  0.425  |
|     2      | 0.2212 | 0.1329 | 0.2499 | 0.3065 |  0.3905 |
|     3      | 0.2097 | 0.1234 | 0.237  | 0.2951 |  0.3774 |
|     4      | 0.2561 | 0.1516 | 0.3033 | 0.3718 |  0.4543 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 15:00:15,479: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 47.96569013595581  |   0.315   |     0.2      |    0.364     |     0.537     |
|    1     | 237.70489144325256 |   0.267   |    0.163     |    0.304     |     0.469     |
|    2     | 234.30062675476074 |   0.249   |    0.151     |    0.283     |     0.439     |
|    3     | 229.9863259792328  |   0.239   |    0.144     |    0.271     |     0.422     |
|    4     | 191.78968596458435 |   0.241   |    0.145     |    0.276     |     0.427     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 15:00:15,479: Sum_Training_Time:941.7472202777863
2024-12-27 15:00:15,479: Every_Training_Time:[47.96569013595581, 237.70489144325256, 234.30062675476074, 229.9863259792328, 191.78968596458435]
2024-12-27 15:00:15,479: Forward transfer: 0.038425 Backward transfer: -7.500000000000562e-05
2024-12-27 15:00:49,636: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227150020/ENTITYentity_0.01_512_6', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_512_6', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_512_6', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=6, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 15:00:57,461: Snapshot:0	Epoch:0	Loss:52.472	translation_Loss:52.472	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.93	Hits@10:48.37	Best:25.93
2024-12-27 15:01:01,564: Snapshot:0	Epoch:1	Loss:15.804	translation_Loss:15.804	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.57	Hits@10:53.1	Best:30.57
2024-12-27 15:01:05,675: Snapshot:0	Epoch:2	Loss:6.234	translation_Loss:6.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.88	Hits@10:53.68	Best:30.88
2024-12-27 15:01:09,618: Snapshot:0	Epoch:3	Loss:3.609	translation_Loss:3.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.03	Hits@10:53.39	Best:31.03
2024-12-27 15:01:13,607: Snapshot:0	Epoch:4	Loss:2.59	translation_Loss:2.59	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.53	Hits@10:53.07	Best:31.03
2024-12-27 15:01:17,512: Snapshot:0	Epoch:5	Loss:2.12	translation_Loss:2.12	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.89	Hits@10:53.04	Best:31.03
2024-12-27 15:01:21,485: Snapshot:0	Epoch:6	Loss:1.862	translation_Loss:1.862	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.77	Hits@10:53.31	Best:31.03
2024-12-27 15:01:25,382: Snapshot:0	Epoch:7	Loss:1.663	translation_Loss:1.663	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.83	Hits@10:52.83	Best:31.03
2024-12-27 15:01:29,264: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 31.03
2024-12-27 15:01:29,264: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:1.504 MRR:30.65 Best Results: 31.03
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 15:01:29,264: Snapshot:0	Epoch:8	Loss:1.504	translation_Loss:1.504	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.65	Hits@10:52.47	Best:31.03
2024-12-27 15:01:33,979: Snapshot:0	Epoch:9	Loss:55.403	translation_Loss:55.366	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.65	Hits@10:52.47	Best:31.03
2024-12-27 15:01:38,185: End of token training: 0 Epoch: 10 Loss:55.387 MRR:30.65 Best Results: 31.03
2024-12-27 15:01:38,185: Snapshot:0	Epoch:10	Loss:55.387	translation_Loss:55.387	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.65	Hits@10:52.47	Best:31.03
2024-12-27 15:01:38,487: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_6/0model_best.tar'
2024-12-27 15:01:39,842: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3126 | 0.1962 | 0.3593 | 0.4351 |  0.5411 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:02:04,652: Snapshot:1	Epoch:0	Loss:140.056	translation_Loss:31.937	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:108.119                                                   	MRR:20.94	Hits@10:37.75	Best:20.94
2024-12-27 15:02:11,778: Snapshot:1	Epoch:1	Loss:9.819	translation_Loss:9.482	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.337                                                   	MRR:21.99	Hits@10:39.52	Best:21.99
2024-12-27 15:02:18,960: Snapshot:1	Epoch:2	Loss:7.574	translation_Loss:7.149	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.425                                                   	MRR:22.33	Hits@10:40.07	Best:22.33
2024-12-27 15:02:26,149: Snapshot:1	Epoch:3	Loss:7.857	translation_Loss:7.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.658                                                   	MRR:22.51	Hits@10:40.37	Best:22.51
2024-12-27 15:02:33,342: Snapshot:1	Epoch:4	Loss:6.5	translation_Loss:5.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.817                                                   	MRR:22.55	Hits@10:40.71	Best:22.55
2024-12-27 15:02:40,530: Snapshot:1	Epoch:5	Loss:6.134	translation_Loss:5.355	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.779                                                   	MRR:22.84	Hits@10:41.08	Best:22.84
2024-12-27 15:02:47,773: Snapshot:1	Epoch:6	Loss:5.951	translation_Loss:5.022	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.928                                                   	MRR:22.96	Hits@10:41.24	Best:22.96
2024-12-27 15:02:54,958: Snapshot:1	Epoch:7	Loss:6.04	translation_Loss:4.905	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.136                                                   	MRR:23.11	Hits@10:40.93	Best:23.11
2024-12-27 15:03:02,227: Snapshot:1	Epoch:8	Loss:6.042	translation_Loss:4.685	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.358                                                   	MRR:23.0	Hits@10:41.11	Best:23.11
2024-12-27 15:03:09,398: Snapshot:1	Epoch:9	Loss:6.876	translation_Loss:4.58	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.296                                                   	MRR:23.06	Hits@10:41.02	Best:23.11
2024-12-27 15:03:16,497: Snapshot:1	Epoch:10	Loss:7.549	translation_Loss:4.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.147                                                   	MRR:22.93	Hits@10:41.49	Best:23.11
2024-12-27 15:03:24,061: Snapshot:1	Epoch:11	Loss:8.069	translation_Loss:4.314	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.755                                                   	MRR:22.89	Hits@10:41.09	Best:23.11
2024-12-27 15:03:31,191: Early Stopping! Snapshot: 1 Epoch: 12 Best Results: 23.11
2024-12-27 15:03:31,191: Start to training tokens! Snapshot: 1 Epoch: 12 Loss:8.686 MRR:22.92 Best Results: 23.11
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 15:03:31,192: Snapshot:1	Epoch:12	Loss:8.686	translation_Loss:4.288	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.398                                                   	MRR:22.92	Hits@10:41.25	Best:23.11
2024-12-27 15:03:38,472: Snapshot:1	Epoch:13	Loss:91.86	translation_Loss:91.822	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.92	Hits@10:41.25	Best:23.11
2024-12-27 15:03:45,656: End of token training: 1 Epoch: 14 Loss:91.947 MRR:22.92 Best Results: 23.11
2024-12-27 15:03:45,657: Snapshot:1	Epoch:14	Loss:91.947	translation_Loss:91.947	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.92	Hits@10:41.25	Best:23.11
2024-12-27 15:03:45,952: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_6/1model_best.tar'
2024-12-27 15:03:49,762: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3128 | 0.1964 | 0.3596 | 0.4352 |  0.5407 |
|     1      | 0.2315 | 0.1397 | 0.2591 | 0.3209 |  0.4127 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:04:16,298: Snapshot:2	Epoch:0	Loss:129.017	translation_Loss:30.599	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:98.418                                                   	MRR:18.84	Hits@10:33.88	Best:18.84
2024-12-27 15:04:24,167: Snapshot:2	Epoch:1	Loss:10.159	translation_Loss:9.551	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.608                                                   	MRR:20.24	Hits@10:36.01	Best:20.24
2024-12-27 15:04:31,982: Snapshot:2	Epoch:2	Loss:8.077	translation_Loss:7.321	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.755                                                   	MRR:20.53	Hits@10:36.36	Best:20.53
2024-12-27 15:04:39,744: Snapshot:2	Epoch:3	Loss:7.476	translation_Loss:6.552	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.924                                                   	MRR:20.86	Hits@10:37.11	Best:20.86
2024-12-27 15:04:47,657: Snapshot:2	Epoch:4	Loss:7.145	translation_Loss:6.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.109                                                   	MRR:20.98	Hits@10:37.42	Best:20.98
2024-12-27 15:04:55,593: Snapshot:2	Epoch:5	Loss:6.988	translation_Loss:5.699	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.289                                                   	MRR:21.04	Hits@10:37.69	Best:21.04
2024-12-27 15:05:03,486: Snapshot:2	Epoch:6	Loss:6.938	translation_Loss:5.427	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.51                                                   	MRR:21.15	Hits@10:37.68	Best:21.15
2024-12-27 15:05:11,253: Snapshot:2	Epoch:7	Loss:6.955	translation_Loss:5.213	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.742                                                   	MRR:21.05	Hits@10:37.67	Best:21.15
2024-12-27 15:05:19,070: Snapshot:2	Epoch:8	Loss:7.224	translation_Loss:5.126	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.098                                                   	MRR:21.17	Hits@10:37.47	Best:21.17
2024-12-27 15:05:26,865: Snapshot:2	Epoch:9	Loss:8.586	translation_Loss:4.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.607                                                   	MRR:21.34	Hits@10:37.8	Best:21.34
2024-12-27 15:05:34,663: Snapshot:2	Epoch:10	Loss:8.72	translation_Loss:4.834	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.886                                                   	MRR:21.28	Hits@10:38.01	Best:21.34
2024-12-27 15:05:42,453: Snapshot:2	Epoch:11	Loss:9.237	translation_Loss:4.77	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.467                                                   	MRR:21.41	Hits@10:38.09	Best:21.41
2024-12-27 15:05:50,219: Snapshot:2	Epoch:12	Loss:9.419	translation_Loss:4.668	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.751                                                   	MRR:21.21	Hits@10:37.93	Best:21.41
2024-12-27 15:05:57,980: Snapshot:2	Epoch:13	Loss:9.471	translation_Loss:4.584	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.887                                                   	MRR:21.24	Hits@10:38.14	Best:21.41
2024-12-27 15:06:05,823: Snapshot:2	Epoch:14	Loss:9.432	translation_Loss:4.543	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.889                                                   	MRR:21.26	Hits@10:38.08	Best:21.41
2024-12-27 15:06:13,586: Snapshot:2	Epoch:15	Loss:9.343	translation_Loss:4.469	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.874                                                   	MRR:21.4	Hits@10:38.14	Best:21.41
2024-12-27 15:06:21,372: Snapshot:2	Epoch:16	Loss:9.328	translation_Loss:4.415	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.914                                                   	MRR:21.54	Hits@10:38.34	Best:21.54
2024-12-27 15:06:29,140: Snapshot:2	Epoch:17	Loss:9.38	translation_Loss:4.46	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.92                                                   	MRR:21.46	Hits@10:38.28	Best:21.54
2024-12-27 15:06:36,863: Snapshot:2	Epoch:18	Loss:9.257	translation_Loss:4.365	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.892                                                   	MRR:21.47	Hits@10:38.3	Best:21.54
2024-12-27 15:06:44,632: Snapshot:2	Epoch:19	Loss:9.227	translation_Loss:4.333	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.894                                                   	MRR:21.66	Hits@10:38.61	Best:21.66
2024-12-27 15:06:52,457: Snapshot:2	Epoch:20	Loss:9.165	translation_Loss:4.285	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.88                                                   	MRR:21.71	Hits@10:38.4	Best:21.71
2024-12-27 15:07:00,249: Snapshot:2	Epoch:21	Loss:9.07	translation_Loss:4.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.835                                                   	MRR:21.63	Hits@10:38.57	Best:21.71
2024-12-27 15:07:08,038: Snapshot:2	Epoch:22	Loss:9.073	translation_Loss:4.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.865                                                   	MRR:21.79	Hits@10:38.54	Best:21.79
2024-12-27 15:07:15,844: Snapshot:2	Epoch:23	Loss:9.072	translation_Loss:4.188	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.884                                                   	MRR:21.61	Hits@10:38.61	Best:21.79
2024-12-27 15:07:23,614: Snapshot:2	Epoch:24	Loss:9.068	translation_Loss:4.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.888                                                   	MRR:21.72	Hits@10:38.56	Best:21.79
2024-12-27 15:07:31,336: Snapshot:2	Epoch:25	Loss:9.054	translation_Loss:4.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.882                                                   	MRR:21.69	Hits@10:38.56	Best:21.79
2024-12-27 15:07:39,063: Snapshot:2	Epoch:26	Loss:8.962	translation_Loss:4.127	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.835                                                   	MRR:21.72	Hits@10:38.57	Best:21.79
2024-12-27 15:07:46,806: Early Stopping! Snapshot: 2 Epoch: 27 Best Results: 21.79
2024-12-27 15:07:46,806: Start to training tokens! Snapshot: 2 Epoch: 27 Loss:8.947 MRR:21.74 Best Results: 21.79
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 15:07:46,807: Snapshot:2	Epoch:27	Loss:8.947	translation_Loss:4.085	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.862                                                   	MRR:21.74	Hits@10:38.43	Best:21.79
2024-12-27 15:07:55,041: Snapshot:2	Epoch:28	Loss:93.018	translation_Loss:92.981	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.74	Hits@10:38.43	Best:21.79
2024-12-27 15:08:02,838: End of token training: 2 Epoch: 29 Loss:92.991 MRR:21.74 Best Results: 21.79
2024-12-27 15:08:02,838: Snapshot:2	Epoch:29	Loss:92.991	translation_Loss:92.991	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.74	Hits@10:38.43	Best:21.79
2024-12-27 15:08:03,124: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_6/2model_best.tar'
2024-12-27 15:08:09,602: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3128 | 0.1964 | 0.3595 | 0.435  |  0.5403 |
|     1      | 0.2317 | 0.1398 | 0.2595 | 0.3213 |  0.4125 |
|     2      | 0.2202 | 0.1311 | 0.2511 | 0.3091 |  0.3907 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:08:36,230: Snapshot:3	Epoch:0	Loss:126.004	translation_Loss:27.824	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:98.179                                                   	MRR:18.28	Hits@10:32.8	Best:18.28
2024-12-27 15:08:44,120: Snapshot:3	Epoch:1	Loss:8.883	translation_Loss:8.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.676                                                   	MRR:19.33	Hits@10:34.73	Best:19.33
2024-12-27 15:08:52,034: Snapshot:3	Epoch:2	Loss:7.168	translation_Loss:6.357	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.81                                                   	MRR:19.58	Hits@10:35.27	Best:19.58
2024-12-27 15:09:00,153: Snapshot:3	Epoch:3	Loss:6.567	translation_Loss:5.612	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.955                                                   	MRR:20.07	Hits@10:36.0	Best:20.07
2024-12-27 15:09:08,022: Snapshot:3	Epoch:4	Loss:6.278	translation_Loss:5.192	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.086                                                   	MRR:19.98	Hits@10:36.0	Best:20.07
2024-12-27 15:09:15,912: Snapshot:3	Epoch:5	Loss:6.149	translation_Loss:4.908	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.242                                                   	MRR:20.3	Hits@10:36.39	Best:20.3
2024-12-27 15:09:23,781: Snapshot:3	Epoch:6	Loss:6.024	translation_Loss:4.616	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.408                                                   	MRR:20.46	Hits@10:36.73	Best:20.46
2024-12-27 15:09:31,719: Snapshot:3	Epoch:7	Loss:6.042	translation_Loss:4.465	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.577                                                   	MRR:20.59	Hits@10:37.13	Best:20.59
2024-12-27 15:09:39,579: Snapshot:3	Epoch:8	Loss:6.178	translation_Loss:4.336	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.842                                                   	MRR:20.51	Hits@10:36.88	Best:20.59
2024-12-27 15:09:47,548: Snapshot:3	Epoch:9	Loss:7.087	translation_Loss:4.197	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.89                                                   	MRR:20.67	Hits@10:36.95	Best:20.67
2024-12-27 15:09:55,565: Snapshot:3	Epoch:10	Loss:7.62	translation_Loss:4.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.509                                                   	MRR:20.72	Hits@10:37.42	Best:20.72
2024-12-27 15:10:03,620: Snapshot:3	Epoch:11	Loss:8.088	translation_Loss:4.112	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.975                                                   	MRR:20.68	Hits@10:37.11	Best:20.72
2024-12-27 15:10:11,644: Snapshot:3	Epoch:12	Loss:8.551	translation_Loss:3.993	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.558                                                   	MRR:20.52	Hits@10:37.36	Best:20.72
2024-12-27 15:10:19,646: Snapshot:3	Epoch:13	Loss:8.609	translation_Loss:3.923	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.687                                                   	MRR:20.51	Hits@10:37.39	Best:20.72
2024-12-27 15:10:27,532: Snapshot:3	Epoch:14	Loss:8.669	translation_Loss:3.916	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.754                                                   	MRR:20.74	Hits@10:37.49	Best:20.74
2024-12-27 15:10:35,440: Snapshot:3	Epoch:15	Loss:8.491	translation_Loss:3.821	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.669                                                   	MRR:20.78	Hits@10:37.32	Best:20.78
2024-12-27 15:10:43,326: Snapshot:3	Epoch:16	Loss:8.48	translation_Loss:3.768	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.713                                                   	MRR:20.89	Hits@10:37.54	Best:20.89
2024-12-27 15:10:51,273: Snapshot:3	Epoch:17	Loss:8.395	translation_Loss:3.728	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.667                                                   	MRR:20.89	Hits@10:37.26	Best:20.89
2024-12-27 15:10:59,168: Snapshot:3	Epoch:18	Loss:8.384	translation_Loss:3.704	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.679                                                   	MRR:20.87	Hits@10:37.76	Best:20.89
2024-12-27 15:11:07,101: Snapshot:3	Epoch:19	Loss:8.415	translation_Loss:3.682	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.733                                                   	MRR:20.83	Hits@10:37.63	Best:20.89
2024-12-27 15:11:15,107: Snapshot:3	Epoch:20	Loss:8.321	translation_Loss:3.635	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.686                                                   	MRR:20.93	Hits@10:37.81	Best:20.93
2024-12-27 15:11:23,168: Snapshot:3	Epoch:21	Loss:8.348	translation_Loss:3.624	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.724                                                   	MRR:20.9	Hits@10:37.62	Best:20.93
2024-12-27 15:11:31,081: Snapshot:3	Epoch:22	Loss:8.282	translation_Loss:3.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.685                                                   	MRR:21.01	Hits@10:37.87	Best:21.01
2024-12-27 15:11:38,968: Snapshot:3	Epoch:23	Loss:8.269	translation_Loss:3.58	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.689                                                   	MRR:20.99	Hits@10:37.83	Best:21.01
2024-12-27 15:11:46,993: Snapshot:3	Epoch:24	Loss:8.187	translation_Loss:3.54	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.647                                                   	MRR:20.95	Hits@10:37.69	Best:21.01
2024-12-27 15:11:54,905: Snapshot:3	Epoch:25	Loss:8.22	translation_Loss:3.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.714                                                   	MRR:21.06	Hits@10:37.95	Best:21.06
2024-12-27 15:12:02,790: Snapshot:3	Epoch:26	Loss:8.19	translation_Loss:3.496	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.694                                                   	MRR:20.95	Hits@10:37.62	Best:21.06
2024-12-27 15:12:10,759: Snapshot:3	Epoch:27	Loss:8.141	translation_Loss:3.485	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.656                                                   	MRR:20.97	Hits@10:37.65	Best:21.06
2024-12-27 15:12:18,649: Snapshot:3	Epoch:28	Loss:8.102	translation_Loss:3.448	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.653                                                   	MRR:20.87	Hits@10:37.74	Best:21.06
2024-12-27 15:12:26,453: Snapshot:3	Epoch:29	Loss:8.07	translation_Loss:3.438	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.631                                                   	MRR:21.03	Hits@10:38.09	Best:21.06
2024-12-27 15:12:34,365: Snapshot:3	Epoch:30	Loss:8.102	translation_Loss:3.384	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.718                                                   	MRR:21.07	Hits@10:37.78	Best:21.07
2024-12-27 15:12:42,221: Snapshot:3	Epoch:31	Loss:8.072	translation_Loss:3.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.673                                                   	MRR:20.94	Hits@10:38.02	Best:21.07
2024-12-27 15:12:50,114: Snapshot:3	Epoch:32	Loss:7.966	translation_Loss:3.343	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.624                                                   	MRR:20.82	Hits@10:37.76	Best:21.07
2024-12-27 15:12:58,131: Snapshot:3	Epoch:33	Loss:8.062	translation_Loss:3.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.684                                                   	MRR:20.85	Hits@10:37.9	Best:21.07
2024-12-27 15:13:05,972: Snapshot:3	Epoch:34	Loss:8.007	translation_Loss:3.355	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.651                                                   	MRR:20.89	Hits@10:37.86	Best:21.07
2024-12-27 15:13:13,779: Early Stopping! Snapshot: 3 Epoch: 35 Best Results: 21.07
2024-12-27 15:13:13,780: Start to training tokens! Snapshot: 3 Epoch: 35 Loss:8.014 MRR:20.97 Best Results: 21.07
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 15:13:13,780: Snapshot:3	Epoch:35	Loss:8.014	translation_Loss:3.38	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.634                                                   	MRR:20.97	Hits@10:37.97	Best:21.07
2024-12-27 15:13:21,623: Snapshot:3	Epoch:36	Loss:84.145	translation_Loss:84.109	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.97	Hits@10:37.97	Best:21.07
2024-12-27 15:13:29,899: End of token training: 3 Epoch: 37 Loss:84.293 MRR:20.97 Best Results: 21.07
2024-12-27 15:13:29,900: Snapshot:3	Epoch:37	Loss:84.293	translation_Loss:84.293	multi_layer_Loss:-0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.97	Hits@10:37.97	Best:21.07
2024-12-27 15:13:30,139: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_6/3model_best.tar'
2024-12-27 15:13:39,591: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3131 | 0.1971 | 0.3595 | 0.4348 |  0.5406 |
|     1      | 0.2318 | 0.1399 | 0.2597 | 0.3214 |  0.4124 |
|     2      | 0.2204 | 0.1313 | 0.2514 | 0.3087 |  0.3908 |
|     3      | 0.2107 | 0.1245 | 0.2399 | 0.295  |  0.3755 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:13:59,698: Snapshot:4	Epoch:0	Loss:113.896	translation_Loss:19.993	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:93.904                                                   	MRR:22.77	Hits@10:40.46	Best:22.77
2024-12-27 15:14:05,379: Snapshot:4	Epoch:1	Loss:4.841	translation_Loss:4.493	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.348                                                   	MRR:23.85	Hits@10:42.43	Best:23.85
2024-12-27 15:14:11,057: Snapshot:4	Epoch:2	Loss:3.404	translation_Loss:3.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.365                                                   	MRR:23.92	Hits@10:42.58	Best:23.92
2024-12-27 15:14:16,763: Snapshot:4	Epoch:3	Loss:3.024	translation_Loss:2.619	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.405                                                   	MRR:24.15	Hits@10:43.35	Best:24.15
2024-12-27 15:14:22,534: Snapshot:4	Epoch:4	Loss:2.799	translation_Loss:2.359	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.44                                                   	MRR:24.43	Hits@10:43.5	Best:24.43
2024-12-27 15:14:28,159: Snapshot:4	Epoch:5	Loss:2.668	translation_Loss:2.188	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.48                                                   	MRR:24.28	Hits@10:43.31	Best:24.43
2024-12-27 15:14:33,782: Snapshot:4	Epoch:6	Loss:2.554	translation_Loss:2.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.513                                                   	MRR:24.38	Hits@10:43.52	Best:24.43
2024-12-27 15:14:39,533: Snapshot:4	Epoch:7	Loss:2.56	translation_Loss:1.985	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.575                                                   	MRR:24.66	Hits@10:44.0	Best:24.66
2024-12-27 15:14:45,202: Snapshot:4	Epoch:8	Loss:2.572	translation_Loss:1.952	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.62                                                   	MRR:24.77	Hits@10:43.88	Best:24.77
2024-12-27 15:14:50,890: Snapshot:4	Epoch:9	Loss:2.486	translation_Loss:1.831	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.655                                                   	MRR:24.98	Hits@10:44.18	Best:24.98
2024-12-27 15:14:56,606: Snapshot:4	Epoch:10	Loss:2.515	translation_Loss:1.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.706                                                   	MRR:24.99	Hits@10:44.07	Best:24.99
2024-12-27 15:15:02,221: Snapshot:4	Epoch:11	Loss:2.467	translation_Loss:1.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.749                                                   	MRR:24.99	Hits@10:44.13	Best:24.99
2024-12-27 15:15:07,902: Snapshot:4	Epoch:12	Loss:2.583	translation_Loss:1.717	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.866                                                   	MRR:24.91	Hits@10:44.04	Best:24.99
2024-12-27 15:15:13,481: Snapshot:4	Epoch:13	Loss:2.707	translation_Loss:1.662	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.045                                                   	MRR:24.8	Hits@10:43.91	Best:24.99
2024-12-27 15:15:19,063: Snapshot:4	Epoch:14	Loss:3.957	translation_Loss:1.621	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.336                                                   	MRR:24.81	Hits@10:44.21	Best:24.99
2024-12-27 15:15:24,662: Early Stopping! Snapshot: 4 Epoch: 15 Best Results: 24.99
2024-12-27 15:15:24,663: Start to training tokens! Snapshot: 4 Epoch: 15 Loss:3.622 MRR:24.73 Best Results: 24.99
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 15:15:24,663: Snapshot:4	Epoch:15	Loss:3.622	translation_Loss:1.594	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.028                                                   	MRR:24.73	Hits@10:44.5	Best:24.99
2024-12-27 15:15:30,284: Snapshot:4	Epoch:16	Loss:46.179	translation_Loss:46.142	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.73	Hits@10:44.5	Best:24.99
2024-12-27 15:15:35,931: End of token training: 4 Epoch: 17 Loss:46.211 MRR:24.73 Best Results: 24.99
2024-12-27 15:15:35,931: Snapshot:4	Epoch:17	Loss:46.211	translation_Loss:46.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.73	Hits@10:44.5	Best:24.99
2024-12-27 15:15:36,237: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_6/4model_best.tar'
2024-12-27 15:15:48,393: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3133 | 0.1972 | 0.3595 | 0.4346 |  0.5404 |
|     1      | 0.2319 | 0.1402 | 0.2594 | 0.3213 |  0.4126 |
|     2      | 0.2203 | 0.1311 | 0.2512 | 0.3088 |  0.3907 |
|     3      | 0.2107 | 0.1245 | 0.2399 | 0.2949 |  0.3754 |
|     4      | 0.2488 | 0.1459 | 0.2946 | 0.3607 |  0.4433 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 15:15:48,395: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3126 | 0.1962 | 0.3593 | 0.4351 |  0.5411 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3128 | 0.1964 | 0.3596 | 0.4352 |  0.5407 |
|     1      | 0.2315 | 0.1397 | 0.2591 | 0.3209 |  0.4127 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3128 | 0.1964 | 0.3595 | 0.435  |  0.5403 |
|     1      | 0.2317 | 0.1398 | 0.2595 | 0.3213 |  0.4125 |
|     2      | 0.2202 | 0.1311 | 0.2511 | 0.3091 |  0.3907 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3131 | 0.1971 | 0.3595 | 0.4348 |  0.5406 |
|     1      | 0.2318 | 0.1399 | 0.2597 | 0.3214 |  0.4124 |
|     2      | 0.2204 | 0.1313 | 0.2514 | 0.3087 |  0.3908 |
|     3      | 0.2107 | 0.1245 | 0.2399 | 0.295  |  0.3755 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3133 | 0.1972 | 0.3595 | 0.4346 |  0.5404 |
|     1      | 0.2319 | 0.1402 | 0.2594 | 0.3213 |  0.4126 |
|     2      | 0.2203 | 0.1311 | 0.2512 | 0.3088 |  0.3907 |
|     3      | 0.2107 | 0.1245 | 0.2399 | 0.2949 |  0.3754 |
|     4      | 0.2488 | 0.1459 | 0.2946 | 0.3607 |  0.4433 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 15:15:48,396: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 48.54775857925415  |   0.313   |    0.196     |    0.359     |     0.541     |
|    1     | 123.35926961898804 |   0.263   |    0.162     |    0.298     |     0.463     |
|    2     | 250.4014275074005  |   0.247   |     0.15     |     0.28     |     0.435     |
|    3     | 317.2819697856903  |   0.237   |    0.143     |     0.27     |     0.419     |
|    4     | 113.87049531936646 |   0.239   |    0.144     |    0.273     |     0.423     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 15:15:48,396: Sum_Training_Time:853.4609208106995
2024-12-27 15:15:48,396: Every_Training_Time:[48.54775857925415, 123.35926961898804, 250.4014275074005, 317.2819697856903, 113.87049531936646]
2024-12-27 15:15:48,396: Forward transfer: 0.039125 Backward transfer: 0.00030000000000000165
2024-12-27 15:16:22,408: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227151552/ENTITYentity_0.01_512_8', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_512_8', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_512_8', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=8, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 15:16:30,133: Snapshot:0	Epoch:0	Loss:52.474	translation_Loss:52.474	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.04	Hits@10:48.59	Best:26.04
2024-12-27 15:16:34,112: Snapshot:0	Epoch:1	Loss:15.8	translation_Loss:15.8	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.67	Hits@10:52.87	Best:30.67
2024-12-27 15:16:38,166: Snapshot:0	Epoch:2	Loss:6.241	translation_Loss:6.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.95	Hits@10:53.33	Best:30.95
2024-12-27 15:16:42,122: Snapshot:0	Epoch:3	Loss:3.609	translation_Loss:3.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.04	Hits@10:53.57	Best:31.04
2024-12-27 15:16:46,057: Snapshot:0	Epoch:4	Loss:2.587	translation_Loss:2.587	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.7	Hits@10:52.73	Best:31.04
2024-12-27 15:16:49,965: Snapshot:0	Epoch:5	Loss:2.117	translation_Loss:2.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.74	Hits@10:53.21	Best:31.04
2024-12-27 15:16:53,876: Snapshot:0	Epoch:6	Loss:1.879	translation_Loss:1.879	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.52	Hits@10:52.81	Best:31.04
2024-12-27 15:16:57,845: Snapshot:0	Epoch:7	Loss:1.684	translation_Loss:1.684	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.98	Hits@10:53.35	Best:31.04
2024-12-27 15:17:01,805: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 31.04
2024-12-27 15:17:01,805: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:1.51 MRR:30.83 Best Results: 31.04
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 15:17:01,806: Snapshot:0	Epoch:8	Loss:1.51	translation_Loss:1.51	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.83	Hits@10:52.41	Best:31.04
2024-12-27 15:17:06,547: Snapshot:0	Epoch:9	Loss:55.334	translation_Loss:55.297	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.83	Hits@10:52.41	Best:31.04
2024-12-27 15:17:10,855: End of token training: 0 Epoch: 10 Loss:55.314 MRR:30.83 Best Results: 31.04
2024-12-27 15:17:10,855: Snapshot:0	Epoch:10	Loss:55.314	translation_Loss:55.314	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.83	Hits@10:52.41	Best:31.04
2024-12-27 15:17:11,157: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_8/0model_best.tar'
2024-12-27 15:17:12,476: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3123 | 0.1958 | 0.361  | 0.4338 |  0.5386 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:17:37,189: Snapshot:1	Epoch:0	Loss:175.69	translation_Loss:31.919	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:143.771                                                   	MRR:20.84	Hits@10:37.97	Best:20.84
2024-12-27 15:17:44,320: Snapshot:1	Epoch:1	Loss:9.735	translation_Loss:9.486	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.249                                                   	MRR:22.03	Hits@10:39.74	Best:22.03
2024-12-27 15:17:51,524: Snapshot:1	Epoch:2	Loss:7.498	translation_Loss:7.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.318                                                   	MRR:22.46	Hits@10:40.46	Best:22.46
2024-12-27 15:17:58,677: Snapshot:1	Epoch:3	Loss:7.765	translation_Loss:7.263	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.502                                                   	MRR:22.59	Hits@10:40.78	Best:22.59
2024-12-27 15:18:05,837: Snapshot:1	Epoch:4	Loss:6.339	translation_Loss:5.69	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.649                                                   	MRR:22.84	Hits@10:40.96	Best:22.84
2024-12-27 15:18:12,988: Snapshot:1	Epoch:5	Loss:5.957	translation_Loss:5.338	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.619                                                   	MRR:23.25	Hits@10:41.59	Best:23.25
2024-12-27 15:18:20,129: Snapshot:1	Epoch:6	Loss:5.801	translation_Loss:5.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.761                                                   	MRR:23.03	Hits@10:41.29	Best:23.25
2024-12-27 15:18:27,234: Snapshot:1	Epoch:7	Loss:5.896	translation_Loss:4.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.974                                                   	MRR:23.28	Hits@10:41.66	Best:23.28
2024-12-27 15:18:34,389: Snapshot:1	Epoch:8	Loss:5.897	translation_Loss:4.691	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.205                                                   	MRR:23.07	Hits@10:41.64	Best:23.28
2024-12-27 15:18:41,527: Snapshot:1	Epoch:9	Loss:7.067	translation_Loss:4.566	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.501                                                   	MRR:23.15	Hits@10:41.77	Best:23.28
2024-12-27 15:18:48,607: Snapshot:1	Epoch:10	Loss:8.03	translation_Loss:4.394	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.636                                                   	MRR:23.07	Hits@10:41.52	Best:23.28
2024-12-27 15:18:56,189: Snapshot:1	Epoch:11	Loss:8.841	translation_Loss:4.309	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.532                                                   	MRR:22.96	Hits@10:41.87	Best:23.28
2024-12-27 15:19:03,351: Early Stopping! Snapshot: 1 Epoch: 12 Best Results: 23.28
2024-12-27 15:19:03,351: Start to training tokens! Snapshot: 1 Epoch: 12 Loss:9.741 MRR:23.21 Best Results: 23.28
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 15:19:03,351: Snapshot:1	Epoch:12	Loss:9.741	translation_Loss:4.275	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.466                                                   	MRR:23.21	Hits@10:41.86	Best:23.28
2024-12-27 15:19:10,559: Snapshot:1	Epoch:13	Loss:92.024	translation_Loss:91.986	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.21	Hits@10:41.86	Best:23.28
2024-12-27 15:19:17,803: End of token training: 1 Epoch: 14 Loss:92.118 MRR:23.21 Best Results: 23.28
2024-12-27 15:19:17,803: Snapshot:1	Epoch:14	Loss:92.118	translation_Loss:92.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.21	Hits@10:41.86	Best:23.28
2024-12-27 15:19:18,111: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_8/1model_best.tar'
2024-12-27 15:19:21,650: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3123 | 0.1957 | 0.3613 | 0.4334 |  0.5387 |
|     1      | 0.2324 | 0.1393 | 0.2606 | 0.3245 |  0.4162 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:19:47,954: Snapshot:2	Epoch:0	Loss:161.536	translation_Loss:30.673	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:130.862                                                   	MRR:19.03	Hits@10:34.18	Best:19.03
2024-12-27 15:19:55,785: Snapshot:2	Epoch:1	Loss:10.038	translation_Loss:9.565	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.473                                                   	MRR:20.24	Hits@10:36.09	Best:20.24
2024-12-27 15:20:03,770: Snapshot:2	Epoch:2	Loss:7.923	translation_Loss:7.326	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.597                                                   	MRR:20.66	Hits@10:37.01	Best:20.66
2024-12-27 15:20:11,679: Snapshot:2	Epoch:3	Loss:7.265	translation_Loss:6.53	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.736                                                   	MRR:20.94	Hits@10:37.5	Best:20.94
2024-12-27 15:20:19,461: Snapshot:2	Epoch:4	Loss:6.954	translation_Loss:6.045	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.91                                                   	MRR:21.04	Hits@10:37.7	Best:21.04
2024-12-27 15:20:27,251: Snapshot:2	Epoch:5	Loss:6.775	translation_Loss:5.69	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.085                                                   	MRR:20.97	Hits@10:37.63	Best:21.04
2024-12-27 15:20:35,054: Snapshot:2	Epoch:6	Loss:6.745	translation_Loss:5.421	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.324                                                   	MRR:21.24	Hits@10:37.89	Best:21.24
2024-12-27 15:20:42,904: Snapshot:2	Epoch:7	Loss:6.788	translation_Loss:5.218	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.57                                                   	MRR:21.33	Hits@10:38.04	Best:21.33
2024-12-27 15:20:50,660: Snapshot:2	Epoch:8	Loss:7.095	translation_Loss:5.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.988                                                   	MRR:21.33	Hits@10:37.9	Best:21.33
2024-12-27 15:20:58,480: Snapshot:2	Epoch:9	Loss:9.127	translation_Loss:4.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.158                                                   	MRR:21.38	Hits@10:37.9	Best:21.38
2024-12-27 15:21:06,269: Snapshot:2	Epoch:10	Loss:9.339	translation_Loss:4.835	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.504                                                   	MRR:21.42	Hits@10:37.99	Best:21.42
2024-12-27 15:21:14,076: Snapshot:2	Epoch:11	Loss:10.122	translation_Loss:4.767	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.355                                                   	MRR:21.47	Hits@10:38.23	Best:21.47
2024-12-27 15:21:22,046: Snapshot:2	Epoch:12	Loss:10.504	translation_Loss:4.672	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.832                                                   	MRR:21.35	Hits@10:37.97	Best:21.47
2024-12-27 15:21:29,806: Snapshot:2	Epoch:13	Loss:10.515	translation_Loss:4.588	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.927                                                   	MRR:21.43	Hits@10:38.21	Best:21.47
2024-12-27 15:21:37,660: Snapshot:2	Epoch:14	Loss:10.483	translation_Loss:4.529	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.955                                                   	MRR:21.42	Hits@10:38.1	Best:21.47
2024-12-27 15:21:45,650: Snapshot:2	Epoch:15	Loss:10.447	translation_Loss:4.476	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.971                                                   	MRR:21.54	Hits@10:38.4	Best:21.54
2024-12-27 15:21:53,517: Snapshot:2	Epoch:16	Loss:10.391	translation_Loss:4.417	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.974                                                   	MRR:21.59	Hits@10:38.54	Best:21.59
2024-12-27 15:22:01,487: Snapshot:2	Epoch:17	Loss:10.429	translation_Loss:4.446	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.983                                                   	MRR:21.58	Hits@10:38.31	Best:21.59
2024-12-27 15:22:09,371: Snapshot:2	Epoch:18	Loss:10.309	translation_Loss:4.351	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.959                                                   	MRR:21.6	Hits@10:38.4	Best:21.6
2024-12-27 15:22:17,193: Snapshot:2	Epoch:19	Loss:10.282	translation_Loss:4.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.947                                                   	MRR:21.69	Hits@10:38.52	Best:21.69
2024-12-27 15:22:24,940: Snapshot:2	Epoch:20	Loss:10.254	translation_Loss:4.28	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.974                                                   	MRR:21.62	Hits@10:38.48	Best:21.69
2024-12-27 15:22:32,784: Snapshot:2	Epoch:21	Loss:10.104	translation_Loss:4.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.893                                                   	MRR:21.76	Hits@10:38.33	Best:21.76
2024-12-27 15:22:40,576: Snapshot:2	Epoch:22	Loss:10.171	translation_Loss:4.215	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.956                                                   	MRR:21.64	Hits@10:38.48	Best:21.76
2024-12-27 15:22:48,303: Snapshot:2	Epoch:23	Loss:10.111	translation_Loss:4.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.934                                                   	MRR:21.6	Hits@10:38.68	Best:21.76
2024-12-27 15:22:56,122: Snapshot:2	Epoch:24	Loss:10.119	translation_Loss:4.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.949                                                   	MRR:21.63	Hits@10:38.7	Best:21.76
2024-12-27 15:23:04,011: Snapshot:2	Epoch:25	Loss:10.129	translation_Loss:4.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.957                                                   	MRR:21.82	Hits@10:38.73	Best:21.82
2024-12-27 15:23:11,763: Snapshot:2	Epoch:26	Loss:10.081	translation_Loss:4.129	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.953                                                   	MRR:21.57	Hits@10:38.72	Best:21.82
2024-12-27 15:23:19,528: Snapshot:2	Epoch:27	Loss:9.983	translation_Loss:4.073	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.91                                                   	MRR:21.77	Hits@10:38.57	Best:21.82
2024-12-27 15:23:27,853: Snapshot:2	Epoch:28	Loss:10.064	translation_Loss:4.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.976                                                   	MRR:21.78	Hits@10:38.56	Best:21.82
2024-12-27 15:23:35,644: Snapshot:2	Epoch:29	Loss:9.936	translation_Loss:4.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.898                                                   	MRR:21.72	Hits@10:38.86	Best:21.82
2024-12-27 15:23:43,455: Early Stopping! Snapshot: 2 Epoch: 30 Best Results: 21.82
2024-12-27 15:23:43,455: Start to training tokens! Snapshot: 2 Epoch: 30 Loss:10.013 MRR:21.75 Best Results: 21.82
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 15:23:43,455: Snapshot:2	Epoch:30	Loss:10.013	translation_Loss:4.074	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.939                                                   	MRR:21.75	Hits@10:38.86	Best:21.82
2024-12-27 15:23:51,285: Snapshot:2	Epoch:31	Loss:93.153	translation_Loss:93.116	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.75	Hits@10:38.86	Best:21.82
2024-12-27 15:23:59,107: End of token training: 2 Epoch: 32 Loss:93.209 MRR:21.75 Best Results: 21.82
2024-12-27 15:23:59,107: Snapshot:2	Epoch:32	Loss:93.209	translation_Loss:93.209	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.75	Hits@10:38.86	Best:21.82
2024-12-27 15:23:59,413: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_8/2model_best.tar'
2024-12-27 15:24:05,702: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3122 | 0.1953 | 0.3618 | 0.434  |  0.5379 |
|     1      | 0.2326 | 0.1396 | 0.2607 | 0.3245 |  0.4162 |
|     2      | 0.2218 | 0.1336 | 0.2516 | 0.308  |  0.3912 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:24:32,209: Snapshot:3	Epoch:0	Loss:158.274	translation_Loss:27.815	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:130.459                                                   	MRR:18.31	Hits@10:33.41	Best:18.31
2024-12-27 15:24:40,208: Snapshot:3	Epoch:1	Loss:8.72	translation_Loss:8.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.525                                                   	MRR:19.25	Hits@10:35.17	Best:19.25
2024-12-27 15:24:48,107: Snapshot:3	Epoch:2	Loss:6.987	translation_Loss:6.347	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.64                                                   	MRR:19.63	Hits@10:35.7	Best:19.63
2024-12-27 15:24:56,056: Snapshot:3	Epoch:3	Loss:6.402	translation_Loss:5.629	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.773                                                   	MRR:19.87	Hits@10:35.77	Best:19.87
2024-12-27 15:25:04,204: Snapshot:3	Epoch:4	Loss:6.123	translation_Loss:5.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.917                                                   	MRR:20.15	Hits@10:36.35	Best:20.15
2024-12-27 15:25:12,088: Snapshot:3	Epoch:5	Loss:5.904	translation_Loss:4.844	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.06                                                   	MRR:20.01	Hits@10:36.44	Best:20.15
2024-12-27 15:25:19,971: Snapshot:3	Epoch:6	Loss:5.857	translation_Loss:4.644	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.214                                                   	MRR:20.24	Hits@10:36.62	Best:20.24
2024-12-27 15:25:27,930: Snapshot:3	Epoch:7	Loss:5.9	translation_Loss:4.486	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.414                                                   	MRR:20.41	Hits@10:37.08	Best:20.41
2024-12-27 15:25:35,894: Snapshot:3	Epoch:8	Loss:6.114	translation_Loss:4.387	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.727                                                   	MRR:20.58	Hits@10:36.89	Best:20.58
2024-12-27 15:25:43,751: Snapshot:3	Epoch:9	Loss:7.458	translation_Loss:4.228	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.23                                                   	MRR:20.58	Hits@10:37.32	Best:20.58
2024-12-27 15:25:51,645: Snapshot:3	Epoch:10	Loss:8.182	translation_Loss:4.143	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.039                                                   	MRR:20.53	Hits@10:37.35	Best:20.58
2024-12-27 15:25:59,476: Snapshot:3	Epoch:11	Loss:8.683	translation_Loss:4.106	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.577                                                   	MRR:20.55	Hits@10:37.27	Best:20.58
2024-12-27 15:26:07,523: Snapshot:3	Epoch:12	Loss:9.591	translation_Loss:3.976	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.615                                                   	MRR:20.61	Hits@10:37.42	Best:20.61
2024-12-27 15:26:15,418: Snapshot:3	Epoch:13	Loss:9.598	translation_Loss:3.88	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.718                                                   	MRR:20.62	Hits@10:37.19	Best:20.62
2024-12-27 15:26:23,309: Snapshot:3	Epoch:14	Loss:9.613	translation_Loss:3.87	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.742                                                   	MRR:20.69	Hits@10:37.47	Best:20.69
2024-12-27 15:26:31,152: Snapshot:3	Epoch:15	Loss:9.595	translation_Loss:3.845	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.75                                                   	MRR:20.67	Hits@10:37.3	Best:20.69
2024-12-27 15:26:39,112: Snapshot:3	Epoch:16	Loss:9.511	translation_Loss:3.791	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.72                                                   	MRR:20.73	Hits@10:37.53	Best:20.73
2024-12-27 15:26:47,113: Snapshot:3	Epoch:17	Loss:9.521	translation_Loss:3.754	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.767                                                   	MRR:20.78	Hits@10:37.62	Best:20.78
2024-12-27 15:26:54,996: Snapshot:3	Epoch:18	Loss:9.37	translation_Loss:3.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.69                                                   	MRR:20.7	Hits@10:37.58	Best:20.78
2024-12-27 15:27:03,324: Snapshot:3	Epoch:19	Loss:9.359	translation_Loss:3.635	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.724                                                   	MRR:20.82	Hits@10:37.64	Best:20.82
2024-12-27 15:27:11,307: Snapshot:3	Epoch:20	Loss:9.409	translation_Loss:3.645	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.764                                                   	MRR:21.0	Hits@10:37.96	Best:21.0
2024-12-27 15:27:19,160: Snapshot:3	Epoch:21	Loss:9.303	translation_Loss:3.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.706                                                   	MRR:20.82	Hits@10:37.84	Best:21.0
2024-12-27 15:27:27,037: Snapshot:3	Epoch:22	Loss:9.293	translation_Loss:3.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.696                                                   	MRR:20.77	Hits@10:37.76	Best:21.0
2024-12-27 15:27:34,931: Snapshot:3	Epoch:23	Loss:9.309	translation_Loss:3.58	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.728                                                   	MRR:20.78	Hits@10:37.97	Best:21.0
2024-12-27 15:27:42,811: Snapshot:3	Epoch:24	Loss:9.28	translation_Loss:3.52	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.761                                                   	MRR:20.97	Hits@10:38.03	Best:21.0
2024-12-27 15:27:50,706: Early Stopping! Snapshot: 3 Epoch: 25 Best Results: 21.0
2024-12-27 15:27:50,707: Start to training tokens! Snapshot: 3 Epoch: 25 Loss:9.2 MRR:20.9 Best Results: 21.0
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 15:27:50,707: Snapshot:3	Epoch:25	Loss:9.2	translation_Loss:3.497	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.703                                                   	MRR:20.9	Hits@10:37.87	Best:21.0
2024-12-27 15:27:58,696: Snapshot:3	Epoch:26	Loss:84.42	translation_Loss:84.384	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.9	Hits@10:37.87	Best:21.0
2024-12-27 15:28:06,682: End of token training: 3 Epoch: 27 Loss:84.437 MRR:20.9 Best Results: 21.0
2024-12-27 15:28:06,682: Snapshot:3	Epoch:27	Loss:84.437	translation_Loss:84.437	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.9	Hits@10:37.87	Best:21.0
2024-12-27 15:28:06,993: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_8/3model_best.tar'
2024-12-27 15:28:16,710: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3123 | 0.1955 | 0.3616 | 0.434  |  0.5378 |
|     1      | 0.2327 | 0.1398 | 0.261  | 0.3244 |  0.4163 |
|     2      | 0.2219 | 0.1336 | 0.2517 | 0.3083 |  0.3916 |
|     3      | 0.2108 | 0.1261 | 0.2372 | 0.2939 |  0.3756 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:28:36,340: Snapshot:4	Epoch:0	Loss:145.359	translation_Loss:19.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:125.38                                                   	MRR:22.8	Hits@10:41.08	Best:22.8
2024-12-27 15:28:42,068: Snapshot:4	Epoch:1	Loss:4.754	translation_Loss:4.479	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.275                                                   	MRR:24.03	Hits@10:42.8	Best:24.03
2024-12-27 15:28:47,682: Snapshot:4	Epoch:2	Loss:3.321	translation_Loss:3.029	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.292                                                   	MRR:24.02	Hits@10:43.03	Best:24.03
2024-12-27 15:28:53,591: Snapshot:4	Epoch:3	Loss:2.939	translation_Loss:2.605	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.334                                                   	MRR:24.36	Hits@10:43.48	Best:24.36
2024-12-27 15:28:59,312: Snapshot:4	Epoch:4	Loss:2.742	translation_Loss:2.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.368                                                   	MRR:24.59	Hits@10:43.94	Best:24.59
2024-12-27 15:29:05,036: Snapshot:4	Epoch:5	Loss:2.626	translation_Loss:2.218	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.409                                                   	MRR:24.33	Hits@10:43.59	Best:24.59
2024-12-27 15:29:10,699: Snapshot:4	Epoch:6	Loss:2.536	translation_Loss:2.084	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.453                                                   	MRR:24.72	Hits@10:43.8	Best:24.72
2024-12-27 15:29:16,831: Snapshot:4	Epoch:7	Loss:2.461	translation_Loss:1.977	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.483                                                   	MRR:24.96	Hits@10:43.93	Best:24.96
2024-12-27 15:29:22,472: Snapshot:4	Epoch:8	Loss:2.434	translation_Loss:1.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.535                                                   	MRR:24.84	Hits@10:43.98	Best:24.96
2024-12-27 15:29:28,056: Snapshot:4	Epoch:9	Loss:2.451	translation_Loss:1.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.591                                                   	MRR:24.62	Hits@10:43.93	Best:24.96
2024-12-27 15:29:33,663: Snapshot:4	Epoch:10	Loss:2.437	translation_Loss:1.794	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.643                                                   	MRR:24.59	Hits@10:44.14	Best:24.96
2024-12-27 15:29:39,356: Snapshot:4	Epoch:11	Loss:2.461	translation_Loss:1.746	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.715                                                   	MRR:24.85	Hits@10:44.29	Best:24.96
2024-12-27 15:29:45,116: Early Stopping! Snapshot: 4 Epoch: 12 Best Results: 24.96
2024-12-27 15:29:45,117: Start to training tokens! Snapshot: 4 Epoch: 12 Loss:2.578 MRR:24.92 Best Results: 24.96
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 15:29:45,117: Snapshot:4	Epoch:12	Loss:2.578	translation_Loss:1.749	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.829                                                   	MRR:24.92	Hits@10:44.64	Best:24.96
2024-12-27 15:29:50,880: Snapshot:4	Epoch:13	Loss:46.218	translation_Loss:46.181	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.92	Hits@10:44.64	Best:24.96
2024-12-27 15:29:56,510: End of token training: 4 Epoch: 14 Loss:46.242 MRR:24.92 Best Results: 24.96
2024-12-27 15:29:56,510: Snapshot:4	Epoch:14	Loss:46.242	translation_Loss:46.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.92	Hits@10:44.64	Best:24.96
2024-12-27 15:29:56,784: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_8/4model_best.tar'
2024-12-27 15:30:08,992: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3123 | 0.1955 | 0.3619 | 0.4345 |  0.5378 |
|     1      | 0.233  |  0.14  | 0.261  | 0.3248 |  0.4164 |
|     2      | 0.2219 | 0.1334 | 0.2518 | 0.3085 |  0.3915 |
|     3      | 0.211  | 0.1263 | 0.2376 | 0.2941 |  0.3759 |
|     4      | 0.2513 | 0.1503 | 0.2946 | 0.3617 |  0.449  |
+------------+--------+--------+--------+--------+---------+
2024-12-27 15:30:08,994: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3123 | 0.1958 | 0.361  | 0.4338 |  0.5386 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3123 | 0.1957 | 0.3613 | 0.4334 |  0.5387 |
|     1      | 0.2324 | 0.1393 | 0.2606 | 0.3245 |  0.4162 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3122 | 0.1953 | 0.3618 | 0.434  |  0.5379 |
|     1      | 0.2326 | 0.1396 | 0.2607 | 0.3245 |  0.4162 |
|     2      | 0.2218 | 0.1336 | 0.2516 | 0.308  |  0.3912 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3123 | 0.1955 | 0.3616 | 0.434  |  0.5378 |
|     1      | 0.2327 | 0.1398 | 0.261  | 0.3244 |  0.4163 |
|     2      | 0.2219 | 0.1336 | 0.2517 | 0.3083 |  0.3916 |
|     3      | 0.2108 | 0.1261 | 0.2372 | 0.2939 |  0.3756 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3123 | 0.1955 | 0.3619 | 0.4345 |  0.5378 |
|     1      | 0.233  |  0.14  | 0.261  | 0.3248 |  0.4164 |
|     2      | 0.2219 | 0.1334 | 0.2518 | 0.3085 |  0.3915 |
|     3      | 0.211  | 0.1263 | 0.2376 | 0.2941 |  0.3759 |
|     4      | 0.2513 | 0.1503 | 0.2946 | 0.3617 |  0.449  |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 15:30:08,994: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 48.44609045982361  |   0.312   |    0.196     |    0.361     |     0.539     |
|    1     | 122.85106825828552 |   0.264   |    0.161     |     0.3      |     0.464     |
|    2     | 274.77168893814087 |   0.248   |    0.151     |    0.282     |     0.436     |
|    3     | 237.7055537700653  |   0.238   |    0.144     |     0.27     |      0.42     |
|    4     | 97.32121205329895  |    0.24   |    0.145     |    0.274     |     0.424     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 15:30:08,994: Sum_Training_Time:781.0956134796143
2024-12-27 15:30:08,994: Every_Training_Time:[48.44609045982361, 122.85106825828552, 274.77168893814087, 237.7055537700653, 97.32121205329895]
2024-12-27 15:30:08,994: Forward transfer: 0.038724999999999996 Backward transfer: 0.00022500000000000298
2024-12-27 15:30:42,751: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227153013/ENTITYentity_0.01_512_10', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_512_10', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_512_10', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=10, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 15:30:50,537: Snapshot:0	Epoch:0	Loss:52.473	translation_Loss:52.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.0	Hits@10:48.46	Best:26.0
2024-12-27 15:30:54,610: Snapshot:0	Epoch:1	Loss:15.801	translation_Loss:15.801	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.85	Hits@10:53.28	Best:30.85
2024-12-27 15:30:58,651: Snapshot:0	Epoch:2	Loss:6.23	translation_Loss:6.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.02	Hits@10:53.31	Best:31.02
2024-12-27 15:31:02,620: Snapshot:0	Epoch:3	Loss:3.608	translation_Loss:3.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.3	Hits@10:53.64	Best:31.3
2024-12-27 15:31:06,653: Snapshot:0	Epoch:4	Loss:2.592	translation_Loss:2.592	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.61	Hits@10:53.02	Best:31.3
2024-12-27 15:31:10,576: Snapshot:0	Epoch:5	Loss:2.116	translation_Loss:2.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.65	Hits@10:52.85	Best:31.3
2024-12-27 15:31:14,540: Snapshot:0	Epoch:6	Loss:1.879	translation_Loss:1.879	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.48	Hits@10:52.9	Best:31.3
2024-12-27 15:31:18,520: Snapshot:0	Epoch:7	Loss:1.683	translation_Loss:1.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.71	Hits@10:52.68	Best:31.3
2024-12-27 15:31:22,501: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 31.3
2024-12-27 15:31:22,501: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:1.51 MRR:30.37 Best Results: 31.3
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 15:31:22,502: Snapshot:0	Epoch:8	Loss:1.51	translation_Loss:1.51	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.37	Hits@10:52.36	Best:31.3
2024-12-27 15:31:27,223: Snapshot:0	Epoch:9	Loss:55.34	translation_Loss:55.302	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.37	Hits@10:52.36	Best:31.3
2024-12-27 15:31:31,500: End of token training: 0 Epoch: 10 Loss:55.328 MRR:30.37 Best Results: 31.3
2024-12-27 15:31:31,500: Snapshot:0	Epoch:10	Loss:55.328	translation_Loss:55.328	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.37	Hits@10:52.36	Best:31.3
2024-12-27 15:31:31,805: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_10/0model_best.tar'
2024-12-27 15:31:33,124: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3154 | 0.1995 | 0.3632 | 0.4371 |  0.5389 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:31:57,853: Snapshot:1	Epoch:0	Loss:211.76	translation_Loss:31.962	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:179.798                                                   	MRR:21.29	Hits@10:38.08	Best:21.29
2024-12-27 15:32:05,052: Snapshot:1	Epoch:1	Loss:9.666	translation_Loss:9.465	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:22.22	Hits@10:39.63	Best:22.22
2024-12-27 15:32:12,265: Snapshot:1	Epoch:2	Loss:7.438	translation_Loss:7.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.258                                                   	MRR:22.66	Hits@10:40.65	Best:22.66
2024-12-27 15:32:19,492: Snapshot:1	Epoch:3	Loss:7.602	translation_Loss:7.192	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.41                                                   	MRR:22.62	Hits@10:40.75	Best:22.66
2024-12-27 15:32:26,872: Snapshot:1	Epoch:4	Loss:6.236	translation_Loss:5.696	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.54                                                   	MRR:22.69	Hits@10:41.01	Best:22.69
2024-12-27 15:32:34,143: Snapshot:1	Epoch:5	Loss:5.867	translation_Loss:5.352	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.515                                                   	MRR:23.03	Hits@10:41.13	Best:23.03
2024-12-27 15:32:41,397: Snapshot:1	Epoch:6	Loss:5.683	translation_Loss:5.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.644                                                   	MRR:22.9	Hits@10:41.22	Best:23.03
2024-12-27 15:32:48,763: Snapshot:1	Epoch:7	Loss:5.755	translation_Loss:4.919	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.835                                                   	MRR:23.27	Hits@10:41.38	Best:23.27
2024-12-27 15:32:55,984: Snapshot:1	Epoch:8	Loss:5.793	translation_Loss:4.698	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.096                                                   	MRR:23.01	Hits@10:41.28	Best:23.27
2024-12-27 15:33:03,274: Snapshot:1	Epoch:9	Loss:7.235	translation_Loss:4.573	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.662                                                   	MRR:23.11	Hits@10:41.26	Best:23.27
2024-12-27 15:33:10,472: Snapshot:1	Epoch:10	Loss:8.567	translation_Loss:4.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.168                                                   	MRR:23.07	Hits@10:41.64	Best:23.27
2024-12-27 15:33:18,105: Snapshot:1	Epoch:11	Loss:9.674	translation_Loss:4.304	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.369                                                   	MRR:22.99	Hits@10:41.53	Best:23.27
2024-12-27 15:33:25,252: Early Stopping! Snapshot: 1 Epoch: 12 Best Results: 23.27
2024-12-27 15:33:25,252: Start to training tokens! Snapshot: 1 Epoch: 12 Loss:10.913 MRR:23.25 Best Results: 23.27
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 15:33:25,252: Snapshot:1	Epoch:12	Loss:10.913	translation_Loss:4.284	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.63                                                   	MRR:23.25	Hits@10:41.69	Best:23.27
2024-12-27 15:33:32,537: Snapshot:1	Epoch:13	Loss:92.191	translation_Loss:92.152	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.25	Hits@10:41.69	Best:23.27
2024-12-27 15:33:39,761: End of token training: 1 Epoch: 14 Loss:92.273 MRR:23.25 Best Results: 23.27
2024-12-27 15:33:39,761: Snapshot:1	Epoch:14	Loss:92.273	translation_Loss:92.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.25	Hits@10:41.69	Best:23.27
2024-12-27 15:33:40,005: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_10/1model_best.tar'
2024-12-27 15:33:43,615: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3154 | 0.1994 | 0.3631 | 0.437  |  0.5389 |
|     1      | 0.2322 | 0.1402 | 0.2597 | 0.3237 |  0.4137 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:34:10,068: Snapshot:2	Epoch:0	Loss:194.314	translation_Loss:30.684	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:163.63                                                   	MRR:18.93	Hits@10:33.85	Best:18.93
2024-12-27 15:34:17,915: Snapshot:2	Epoch:1	Loss:9.941	translation_Loss:9.554	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.386                                                   	MRR:20.12	Hits@10:36.01	Best:20.12
2024-12-27 15:34:25,768: Snapshot:2	Epoch:2	Loss:7.853	translation_Loss:7.358	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.494                                                   	MRR:20.73	Hits@10:36.85	Best:20.73
2024-12-27 15:34:33,650: Snapshot:2	Epoch:3	Loss:7.204	translation_Loss:6.586	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.618                                                   	MRR:20.99	Hits@10:37.21	Best:20.99
2024-12-27 15:34:41,595: Snapshot:2	Epoch:4	Loss:6.826	translation_Loss:6.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.767                                                   	MRR:21.09	Hits@10:37.44	Best:21.09
2024-12-27 15:34:49,409: Snapshot:2	Epoch:5	Loss:6.66	translation_Loss:5.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.941                                                   	MRR:21.01	Hits@10:37.6	Best:21.09
2024-12-27 15:34:57,275: Snapshot:2	Epoch:6	Loss:6.634	translation_Loss:5.455	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.179                                                   	MRR:21.24	Hits@10:37.67	Best:21.24
2024-12-27 15:35:05,187: Snapshot:2	Epoch:7	Loss:6.698	translation_Loss:5.247	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.45                                                   	MRR:21.26	Hits@10:37.77	Best:21.26
2024-12-27 15:35:13,066: Snapshot:2	Epoch:8	Loss:7.052	translation_Loss:5.141	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.911                                                   	MRR:21.42	Hits@10:37.98	Best:21.42
2024-12-27 15:35:21,033: Snapshot:2	Epoch:9	Loss:9.679	translation_Loss:4.978	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.701                                                   	MRR:21.37	Hits@10:37.8	Best:21.42
2024-12-27 15:35:28,858: Snapshot:2	Epoch:10	Loss:10.023	translation_Loss:4.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.17                                                   	MRR:21.42	Hits@10:38.27	Best:21.42
2024-12-27 15:35:36,861: Snapshot:2	Epoch:11	Loss:11.121	translation_Loss:4.787	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.333                                                   	MRR:21.48	Hits@10:38.16	Best:21.48
2024-12-27 15:35:44,678: Snapshot:2	Epoch:12	Loss:11.623	translation_Loss:4.691	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.932                                                   	MRR:21.41	Hits@10:37.97	Best:21.48
2024-12-27 15:35:52,819: Snapshot:2	Epoch:13	Loss:11.648	translation_Loss:4.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.058                                                   	MRR:21.6	Hits@10:38.45	Best:21.6
2024-12-27 15:36:00,662: Snapshot:2	Epoch:14	Loss:11.605	translation_Loss:4.541	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.064                                                   	MRR:21.5	Hits@10:38.27	Best:21.6
2024-12-27 15:36:08,533: Snapshot:2	Epoch:15	Loss:11.574	translation_Loss:4.491	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.084                                                   	MRR:21.67	Hits@10:38.29	Best:21.67
2024-12-27 15:36:16,475: Snapshot:2	Epoch:16	Loss:11.493	translation_Loss:4.415	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.078                                                   	MRR:21.75	Hits@10:38.71	Best:21.75
2024-12-27 15:36:24,280: Snapshot:2	Epoch:17	Loss:11.586	translation_Loss:4.463	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.123                                                   	MRR:21.75	Hits@10:38.55	Best:21.75
2024-12-27 15:36:32,125: Snapshot:2	Epoch:18	Loss:11.452	translation_Loss:4.369	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.084                                                   	MRR:21.78	Hits@10:38.61	Best:21.78
2024-12-27 15:36:39,975: Snapshot:2	Epoch:19	Loss:11.418	translation_Loss:4.358	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.06                                                   	MRR:21.77	Hits@10:38.57	Best:21.78
2024-12-27 15:36:47,801: Snapshot:2	Epoch:20	Loss:11.407	translation_Loss:4.3	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.107                                                   	MRR:21.82	Hits@10:38.73	Best:21.82
2024-12-27 15:36:55,758: Snapshot:2	Epoch:21	Loss:11.218	translation_Loss:4.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.983                                                   	MRR:21.85	Hits@10:38.63	Best:21.85
2024-12-27 15:37:03,644: Snapshot:2	Epoch:22	Loss:11.346	translation_Loss:4.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.11                                                   	MRR:21.76	Hits@10:38.61	Best:21.85
2024-12-27 15:37:11,580: Snapshot:2	Epoch:23	Loss:11.25	translation_Loss:4.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.045                                                   	MRR:21.84	Hits@10:38.71	Best:21.85
2024-12-27 15:37:19,476: Snapshot:2	Epoch:24	Loss:11.258	translation_Loss:4.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.074                                                   	MRR:21.87	Hits@10:38.81	Best:21.87
2024-12-27 15:37:27,320: Snapshot:2	Epoch:25	Loss:11.241	translation_Loss:4.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.059                                                   	MRR:21.93	Hits@10:38.78	Best:21.93
2024-12-27 15:37:35,221: Snapshot:2	Epoch:26	Loss:11.189	translation_Loss:4.149	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.04                                                   	MRR:21.69	Hits@10:38.49	Best:21.93
2024-12-27 15:37:43,084: Snapshot:2	Epoch:27	Loss:11.155	translation_Loss:4.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.062                                                   	MRR:21.82	Hits@10:38.72	Best:21.93
2024-12-27 15:37:51,397: Snapshot:2	Epoch:28	Loss:11.207	translation_Loss:4.11	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.097                                                   	MRR:21.77	Hits@10:38.7	Best:21.93
2024-12-27 15:37:59,279: Snapshot:2	Epoch:29	Loss:11.064	translation_Loss:4.043	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.021                                                   	MRR:21.94	Hits@10:38.82	Best:21.94
2024-12-27 15:38:07,121: Snapshot:2	Epoch:30	Loss:11.171	translation_Loss:4.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.07                                                   	MRR:21.77	Hits@10:38.88	Best:21.94
2024-12-27 15:38:14,882: Snapshot:2	Epoch:31	Loss:11.05	translation_Loss:4.035	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.015                                                   	MRR:21.82	Hits@10:38.54	Best:21.94
2024-12-27 15:38:22,696: Snapshot:2	Epoch:32	Loss:11.009	translation_Loss:3.987	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.022                                                   	MRR:21.82	Hits@10:38.79	Best:21.94
2024-12-27 15:38:30,547: Snapshot:2	Epoch:33	Loss:11.071	translation_Loss:3.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.097                                                   	MRR:22.08	Hits@10:38.77	Best:22.08
2024-12-27 15:38:38,376: Snapshot:2	Epoch:34	Loss:11.015	translation_Loss:3.977	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.039                                                   	MRR:21.96	Hits@10:38.65	Best:22.08
2024-12-27 15:38:46,180: Snapshot:2	Epoch:35	Loss:10.951	translation_Loss:3.947	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.004                                                   	MRR:21.94	Hits@10:38.77	Best:22.08
2024-12-27 15:38:54,054: Snapshot:2	Epoch:36	Loss:10.972	translation_Loss:3.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.063                                                   	MRR:21.87	Hits@10:38.95	Best:22.08
2024-12-27 15:39:01,918: Snapshot:2	Epoch:37	Loss:10.921	translation_Loss:3.895	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.026                                                   	MRR:21.94	Hits@10:38.81	Best:22.08
2024-12-27 15:39:09,743: Early Stopping! Snapshot: 2 Epoch: 38 Best Results: 22.08
2024-12-27 15:39:09,743: Start to training tokens! Snapshot: 2 Epoch: 38 Loss:10.936 MRR:21.96 Best Results: 22.08
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 15:39:09,743: Snapshot:2	Epoch:38	Loss:10.936	translation_Loss:3.896	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.04                                                   	MRR:21.96	Hits@10:38.7	Best:22.08
2024-12-27 15:39:17,814: Snapshot:2	Epoch:39	Loss:93.217	translation_Loss:93.181	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.96	Hits@10:38.7	Best:22.08
2024-12-27 15:39:25,898: End of token training: 2 Epoch: 40 Loss:93.318 MRR:21.96 Best Results: 22.08
2024-12-27 15:39:25,898: Snapshot:2	Epoch:40	Loss:93.318	translation_Loss:93.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.96	Hits@10:38.7	Best:22.08
2024-12-27 15:39:26,208: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_10/2model_best.tar'
2024-12-27 15:39:33,098: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3155 | 0.1997 | 0.363  | 0.4364 |  0.5391 |
|     1      | 0.2322 | 0.1402 | 0.2601 | 0.3239 |  0.4142 |
|     2      | 0.2214 | 0.1314 | 0.2529 | 0.3093 |  0.3929 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:39:59,999: Snapshot:3	Epoch:0	Loss:190.799	translation_Loss:27.768	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:163.031                                                   	MRR:18.33	Hits@10:32.84	Best:18.33
2024-12-27 15:40:08,247: Snapshot:3	Epoch:1	Loss:8.683	translation_Loss:8.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.429                                                   	MRR:19.2	Hits@10:35.02	Best:19.2
2024-12-27 15:40:16,188: Snapshot:3	Epoch:2	Loss:6.896	translation_Loss:6.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.522                                                   	MRR:19.59	Hits@10:35.77	Best:19.59
2024-12-27 15:40:24,108: Snapshot:3	Epoch:3	Loss:6.283	translation_Loss:5.634	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.649                                                   	MRR:19.99	Hits@10:36.13	Best:19.99
2024-12-27 15:40:32,051: Snapshot:3	Epoch:4	Loss:5.909	translation_Loss:5.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.771                                                   	MRR:19.99	Hits@10:36.17	Best:19.99
2024-12-27 15:40:40,003: Snapshot:3	Epoch:5	Loss:5.789	translation_Loss:4.879	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.91                                                   	MRR:20.09	Hits@10:36.65	Best:20.09
2024-12-27 15:40:47,925: Snapshot:3	Epoch:6	Loss:5.773	translation_Loss:4.691	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.082                                                   	MRR:20.09	Hits@10:36.68	Best:20.09
2024-12-27 15:40:55,916: Snapshot:3	Epoch:7	Loss:5.787	translation_Loss:4.498	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.289                                                   	MRR:20.13	Hits@10:36.67	Best:20.13
2024-12-27 15:41:03,914: Snapshot:3	Epoch:8	Loss:5.973	translation_Loss:4.375	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.598                                                   	MRR:20.32	Hits@10:37.08	Best:20.32
2024-12-27 15:41:12,011: Snapshot:3	Epoch:9	Loss:7.897	translation_Loss:4.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.655                                                   	MRR:20.42	Hits@10:36.95	Best:20.42
2024-12-27 15:41:20,298: Snapshot:3	Epoch:10	Loss:8.703	translation_Loss:4.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.531                                                   	MRR:20.46	Hits@10:37.09	Best:20.46
2024-12-27 15:41:28,325: Snapshot:3	Epoch:11	Loss:9.189	translation_Loss:4.019	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.171                                                   	MRR:20.48	Hits@10:37.16	Best:20.48
2024-12-27 15:41:36,301: Snapshot:3	Epoch:12	Loss:10.842	translation_Loss:4.042	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.8                                                   	MRR:20.44	Hits@10:37.23	Best:20.48
2024-12-27 15:41:44,266: Snapshot:3	Epoch:13	Loss:10.735	translation_Loss:3.935	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.8                                                   	MRR:20.66	Hits@10:37.55	Best:20.66
2024-12-27 15:41:52,260: Snapshot:3	Epoch:14	Loss:10.669	translation_Loss:3.875	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.794                                                   	MRR:20.57	Hits@10:37.36	Best:20.66
2024-12-27 15:42:00,247: Snapshot:3	Epoch:15	Loss:10.632	translation_Loss:3.83	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.803                                                   	MRR:20.74	Hits@10:37.21	Best:20.74
2024-12-27 15:42:08,174: Snapshot:3	Epoch:16	Loss:10.488	translation_Loss:3.722	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.765                                                   	MRR:20.63	Hits@10:37.74	Best:20.74
2024-12-27 15:42:16,116: Snapshot:3	Epoch:17	Loss:10.518	translation_Loss:3.717	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.801                                                   	MRR:20.66	Hits@10:37.5	Best:20.74
2024-12-27 15:42:24,098: Snapshot:3	Epoch:18	Loss:10.476	translation_Loss:3.686	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.79                                                   	MRR:20.56	Hits@10:37.68	Best:20.74
2024-12-27 15:42:31,966: Snapshot:3	Epoch:19	Loss:10.538	translation_Loss:3.705	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.833                                                   	MRR:20.65	Hits@10:37.8	Best:20.74
2024-12-27 15:42:39,902: Early Stopping! Snapshot: 3 Epoch: 20 Best Results: 20.74
2024-12-27 15:42:39,902: Start to training tokens! Snapshot: 3 Epoch: 20 Loss:10.465 MRR:20.67 Best Results: 20.74
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 15:42:39,903: Snapshot:3	Epoch:20	Loss:10.465	translation_Loss:3.672	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.793                                                   	MRR:20.67	Hits@10:37.55	Best:20.74
2024-12-27 15:42:47,973: Snapshot:3	Epoch:21	Loss:84.384	translation_Loss:84.348	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.67	Hits@10:37.55	Best:20.74
2024-12-27 15:42:55,919: End of token training: 3 Epoch: 22 Loss:84.316 MRR:20.67 Best Results: 20.74
2024-12-27 15:42:55,920: Snapshot:3	Epoch:22	Loss:84.316	translation_Loss:84.316	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.67	Hits@10:37.55	Best:20.74
2024-12-27 15:42:56,230: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_10/3model_best.tar'
2024-12-27 15:43:05,762: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3154 | 0.1996 | 0.3632 | 0.4363 |  0.5392 |
|     1      | 0.2321 | 0.1403 | 0.2599 | 0.324  |  0.4139 |
|     2      | 0.2214 | 0.1315 | 0.2529 | 0.3092 |  0.3929 |
|     3      | 0.2076 | 0.1225 | 0.2351 | 0.2903 |  0.3726 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:43:25,755: Snapshot:4	Epoch:0	Loss:176.307	translation_Loss:19.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:156.312                                                   	MRR:22.34	Hits@10:40.32	Best:22.34
2024-12-27 15:43:31,514: Snapshot:4	Epoch:1	Loss:4.813	translation_Loss:4.58	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.233                                                   	MRR:23.35	Hits@10:42.43	Best:23.35
2024-12-27 15:43:37,220: Snapshot:4	Epoch:2	Loss:3.33	translation_Loss:3.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.25                                                   	MRR:23.37	Hits@10:42.45	Best:23.37
2024-12-27 15:43:42,969: Snapshot:4	Epoch:3	Loss:2.919	translation_Loss:2.63	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.289                                                   	MRR:23.5	Hits@10:42.52	Best:23.5
2024-12-27 15:43:48,641: Snapshot:4	Epoch:4	Loss:2.664	translation_Loss:2.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.318                                                   	MRR:24.36	Hits@10:43.04	Best:24.36
2024-12-27 15:43:54,272: Snapshot:4	Epoch:5	Loss:2.558	translation_Loss:2.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.353                                                   	MRR:23.45	Hits@10:42.71	Best:24.36
2024-12-27 15:44:00,028: Snapshot:4	Epoch:6	Loss:2.464	translation_Loss:2.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.401                                                   	MRR:24.05	Hits@10:43.22	Best:24.36
2024-12-27 15:44:05,698: Snapshot:4	Epoch:7	Loss:2.462	translation_Loss:2.015	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.447                                                   	MRR:24.15	Hits@10:43.57	Best:24.36
2024-12-27 15:44:11,300: Snapshot:4	Epoch:8	Loss:2.413	translation_Loss:1.925	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.488                                                   	MRR:24.26	Hits@10:43.78	Best:24.36
2024-12-27 15:44:16,924: Early Stopping! Snapshot: 4 Epoch: 9 Best Results: 24.36
2024-12-27 15:44:16,925: Start to training tokens! Snapshot: 4 Epoch: 9 Loss:2.415 MRR:24.27 Best Results: 24.36
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 15:44:16,925: Snapshot:4	Epoch:9	Loss:2.415	translation_Loss:1.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.54                                                   	MRR:24.27	Hits@10:43.83	Best:24.36
2024-12-27 15:44:22,588: Snapshot:4	Epoch:10	Loss:46.236	translation_Loss:46.199	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.27	Hits@10:43.83	Best:24.36
2024-12-27 15:44:28,292: End of token training: 4 Epoch: 11 Loss:46.21 MRR:24.27 Best Results: 24.36
2024-12-27 15:44:28,292: Snapshot:4	Epoch:11	Loss:46.21	translation_Loss:46.21	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.27	Hits@10:43.83	Best:24.36
2024-12-27 15:44:28,584: => loading checkpoint './checkpoint/ENTITYentity_0.01_512_10/4model_best.tar'
2024-12-27 15:44:40,775: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3151 | 0.199  | 0.3634 | 0.4364 |  0.5387 |
|     1      | 0.2321 | 0.1402 | 0.2598 | 0.3239 |  0.4138 |
|     2      | 0.2214 | 0.1314 | 0.253  | 0.3092 |  0.3931 |
|     3      | 0.2077 | 0.1226 | 0.2353 | 0.2905 |  0.3728 |
|     4      | 0.2439 | 0.1446 | 0.2852 | 0.3496 |  0.436  |
+------------+--------+--------+--------+--------+---------+
2024-12-27 15:44:40,779: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3154 | 0.1995 | 0.3632 | 0.4371 |  0.5389 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3154 | 0.1994 | 0.3631 | 0.437  |  0.5389 |
|     1      | 0.2322 | 0.1402 | 0.2597 | 0.3237 |  0.4137 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3155 | 0.1997 | 0.363  | 0.4364 |  0.5391 |
|     1      | 0.2322 | 0.1402 | 0.2601 | 0.3239 |  0.4142 |
|     2      | 0.2214 | 0.1314 | 0.2529 | 0.3093 |  0.3929 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3154 | 0.1996 | 0.3632 | 0.4363 |  0.5392 |
|     1      | 0.2321 | 0.1403 | 0.2599 | 0.324  |  0.4139 |
|     2      | 0.2214 | 0.1315 | 0.2529 | 0.3092 |  0.3929 |
|     3      | 0.2076 | 0.1225 | 0.2351 | 0.2903 |  0.3726 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3151 | 0.199  | 0.3634 | 0.4364 |  0.5387 |
|     1      | 0.2321 | 0.1402 | 0.2598 | 0.3239 |  0.4138 |
|     2      | 0.2214 | 0.1314 | 0.253  | 0.3092 |  0.3931 |
|     3      | 0.2077 | 0.1226 | 0.2353 | 0.2905 |  0.3728 |
|     4      | 0.2439 | 0.1446 | 0.2852 | 0.3496 |  0.436  |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 15:44:40,780: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     |  48.7474639415741  |   0.315   |     0.2      |    0.363     |     0.539     |
|    1     | 124.18819689750671 |   0.265   |    0.163     |     0.3      |     0.463     |
|    2     | 339.60183691978455 |   0.248   |    0.151     |    0.282     |     0.436     |
|    3     | 199.78826260566711 |   0.237   |    0.144     |     0.27     |     0.419     |
|    4     | 80.02109384536743  |   0.238   |    0.144     |    0.272     |     0.422     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 15:44:40,780: Sum_Training_Time:792.3468542098999
2024-12-27 15:44:40,780: Every_Training_Time:[48.7474639415741, 124.18819689750671, 339.60183691978455, 199.78826260566711, 80.02109384536743]
2024-12-27 15:44:40,780: Forward transfer: 0.0385 Backward transfer: -7.500000000000562e-05
2024-12-27 15:45:14,569: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227154444/ENTITYentity_0.01_1024_2', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_1024_2', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_1024_2', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=2, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 15:45:22,133: Snapshot:0	Epoch:0	Loss:28.546	translation_Loss:28.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.41	Hits@10:47.22	Best:24.41
2024-12-27 15:45:25,940: Snapshot:0	Epoch:1	Loss:9.982	translation_Loss:9.982	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.25	Hits@10:54.13	Best:31.25
2024-12-27 15:45:29,715: Snapshot:0	Epoch:2	Loss:3.789	translation_Loss:3.789	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.72	Hits@10:54.4	Best:31.72
2024-12-27 15:45:33,540: Snapshot:0	Epoch:3	Loss:2.047	translation_Loss:2.047	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.93	Hits@10:54.23	Best:31.93
2024-12-27 15:45:37,345: Snapshot:0	Epoch:4	Loss:1.388	translation_Loss:1.388	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.79	Hits@10:54.26	Best:31.93
2024-12-27 15:45:41,085: Snapshot:0	Epoch:5	Loss:1.103	translation_Loss:1.103	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.51	Hits@10:53.59	Best:31.93
2024-12-27 15:45:44,847: Snapshot:0	Epoch:6	Loss:0.949	translation_Loss:0.949	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.62	Hits@10:53.85	Best:31.93
2024-12-27 15:45:48,583: Snapshot:0	Epoch:7	Loss:0.839	translation_Loss:0.839	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.72	Hits@10:53.78	Best:31.93
2024-12-27 15:45:52,313: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 31.93
2024-12-27 15:45:52,313: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:0.754 MRR:31.62 Best Results: 31.93
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 15:45:52,313: Snapshot:0	Epoch:8	Loss:0.754	translation_Loss:0.754	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.62	Hits@10:53.21	Best:31.93
2024-12-27 15:45:56,754: Snapshot:0	Epoch:9	Loss:28.054	translation_Loss:28.02	multi_layer_Loss:0.035	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.62	Hits@10:53.21	Best:31.93
2024-12-27 15:46:00,629: End of token training: 0 Epoch: 10 Loss:28.03 MRR:31.62 Best Results: 31.93
2024-12-27 15:46:00,630: Snapshot:0	Epoch:10	Loss:28.03	translation_Loss:28.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.62	Hits@10:53.21	Best:31.93
2024-12-27 15:46:00,940: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_2/0model_best.tar'
2024-12-27 15:46:02,510: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3254 | 0.2075 | 0.3789 | 0.4496 |  0.5515 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:46:26,771: Snapshot:1	Epoch:0	Loss:55.73	translation_Loss:17.649	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:38.081                                                   	MRR:21.73	Hits@10:39.17	Best:21.73
2024-12-27 15:46:33,463: Snapshot:1	Epoch:1	Loss:5.437	translation_Loss:5.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.253                                                   	MRR:23.0	Hits@10:41.17	Best:23.0
2024-12-27 15:46:40,075: Snapshot:1	Epoch:2	Loss:4.12	translation_Loss:3.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.282                                                   	MRR:23.39	Hits@10:41.94	Best:23.39
2024-12-27 15:46:46,713: Snapshot:1	Epoch:3	Loss:3.652	translation_Loss:3.329	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.323                                                   	MRR:23.52	Hits@10:41.94	Best:23.52
2024-12-27 15:46:53,301: Snapshot:1	Epoch:4	Loss:3.391	translation_Loss:3.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.361                                                   	MRR:23.55	Hits@10:41.97	Best:23.55
2024-12-27 15:46:59,958: Snapshot:1	Epoch:5	Loss:3.267	translation_Loss:2.87	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.397                                                   	MRR:23.92	Hits@10:42.42	Best:23.92
2024-12-27 15:47:06,580: Snapshot:1	Epoch:6	Loss:3.151	translation_Loss:2.718	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.433                                                   	MRR:23.73	Hits@10:42.22	Best:23.92
2024-12-27 15:47:13,154: Snapshot:1	Epoch:7	Loss:3.121	translation_Loss:2.652	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.469                                                   	MRR:23.8	Hits@10:42.19	Best:23.92
2024-12-27 15:47:19,702: Snapshot:1	Epoch:8	Loss:3.019	translation_Loss:2.523	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.497                                                   	MRR:23.85	Hits@10:42.3	Best:23.92
2024-12-27 15:47:26,278: Snapshot:1	Epoch:9	Loss:2.993	translation_Loss:2.462	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.531                                                   	MRR:23.78	Hits@10:42.45	Best:23.92
2024-12-27 15:47:32,835: Early Stopping! Snapshot: 1 Epoch: 10 Best Results: 23.92
2024-12-27 15:47:32,835: Start to training tokens! Snapshot: 1 Epoch: 10 Loss:2.928 MRR:23.77 Best Results: 23.92
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 15:47:32,836: Snapshot:1	Epoch:10	Loss:2.928	translation_Loss:2.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.553                                                   	MRR:23.77	Hits@10:42.64	Best:23.92
2024-12-27 15:47:39,498: Snapshot:1	Epoch:11	Loss:46.12	translation_Loss:46.083	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.77	Hits@10:42.64	Best:23.92
2024-12-27 15:47:46,163: End of token training: 1 Epoch: 12 Loss:46.116 MRR:23.77 Best Results: 23.92
2024-12-27 15:47:46,163: Snapshot:1	Epoch:12	Loss:46.116	translation_Loss:46.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.77	Hits@10:42.64	Best:23.92
2024-12-27 15:47:46,466: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_2/1model_best.tar'
2024-12-27 15:47:49,687: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3252 | 0.2074 | 0.3791 | 0.4491 |  0.551  |
|     1      | 0.2391 | 0.1445 | 0.2689 | 0.3346 |  0.4254 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:48:15,019: Snapshot:2	Epoch:0	Loss:53.033	translation_Loss:16.942	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:36.092                                                   	MRR:19.7	Hits@10:35.14	Best:19.7
2024-12-27 15:48:22,253: Snapshot:2	Epoch:1	Loss:5.654	translation_Loss:5.183	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.472                                                   	MRR:21.12	Hits@10:37.55	Best:21.12
2024-12-27 15:48:29,537: Snapshot:2	Epoch:2	Loss:4.475	translation_Loss:3.945	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.53                                                   	MRR:21.62	Hits@10:38.46	Best:21.62
2024-12-27 15:48:36,766: Snapshot:2	Epoch:3	Loss:4.101	translation_Loss:3.512	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.59                                                   	MRR:21.94	Hits@10:38.84	Best:21.94
2024-12-27 15:48:44,025: Snapshot:2	Epoch:4	Loss:3.903	translation_Loss:3.25	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.654                                                   	MRR:21.99	Hits@10:38.71	Best:21.99
2024-12-27 15:48:51,263: Snapshot:2	Epoch:5	Loss:3.785	translation_Loss:3.074	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.711                                                   	MRR:22.17	Hits@10:38.94	Best:22.17
2024-12-27 15:48:58,554: Snapshot:2	Epoch:6	Loss:3.715	translation_Loss:2.957	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.758                                                   	MRR:22.15	Hits@10:39.11	Best:22.17
2024-12-27 15:49:05,815: Snapshot:2	Epoch:7	Loss:3.583	translation_Loss:2.799	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.783                                                   	MRR:22.09	Hits@10:39.26	Best:22.17
2024-12-27 15:49:13,029: Snapshot:2	Epoch:8	Loss:3.549	translation_Loss:2.725	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.824                                                   	MRR:22.42	Hits@10:39.41	Best:22.42
2024-12-27 15:49:20,258: Snapshot:2	Epoch:9	Loss:3.542	translation_Loss:2.672	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.87                                                   	MRR:22.45	Hits@10:39.59	Best:22.45
2024-12-27 15:49:27,481: Snapshot:2	Epoch:10	Loss:3.507	translation_Loss:2.604	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.902                                                   	MRR:22.58	Hits@10:39.77	Best:22.58
2024-12-27 15:49:34,801: Snapshot:2	Epoch:11	Loss:3.454	translation_Loss:2.536	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.918                                                   	MRR:22.45	Hits@10:39.48	Best:22.58
2024-12-27 15:49:42,026: Snapshot:2	Epoch:12	Loss:3.456	translation_Loss:2.502	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.954                                                   	MRR:22.42	Hits@10:39.71	Best:22.58
2024-12-27 15:49:49,201: Snapshot:2	Epoch:13	Loss:3.452	translation_Loss:2.465	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.987                                                   	MRR:22.55	Hits@10:39.82	Best:22.58
2024-12-27 15:49:56,527: Snapshot:2	Epoch:14	Loss:3.492	translation_Loss:2.46	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.031                                                   	MRR:22.54	Hits@10:39.84	Best:22.58
2024-12-27 15:50:03,835: Early Stopping! Snapshot: 2 Epoch: 15 Best Results: 22.58
2024-12-27 15:50:03,836: Start to training tokens! Snapshot: 2 Epoch: 15 Loss:3.448 MRR:22.54 Best Results: 22.58
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 15:50:03,836: Snapshot:2	Epoch:15	Loss:3.448	translation_Loss:2.395	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.053                                                   	MRR:22.54	Hits@10:39.82	Best:22.58
2024-12-27 15:50:11,245: Snapshot:2	Epoch:16	Loss:46.938	translation_Loss:46.901	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.54	Hits@10:39.82	Best:22.58
2024-12-27 15:50:18,508: End of token training: 2 Epoch: 17 Loss:46.975 MRR:22.54 Best Results: 22.58
2024-12-27 15:50:18,508: Snapshot:2	Epoch:17	Loss:46.975	translation_Loss:46.975	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.54	Hits@10:39.82	Best:22.58
2024-12-27 15:50:18,817: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_2/2model_best.tar'
2024-12-27 15:50:25,506: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3253 | 0.2075 | 0.3782 | 0.4494 |  0.5511 |
|     1      | 0.239  | 0.1442 | 0.2691 | 0.3343 |  0.4254 |
|     2      | 0.2275 | 0.137  | 0.2582 | 0.3176 |  0.4011 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:50:50,651: Snapshot:3	Epoch:0	Loss:51.102	translation_Loss:15.386	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:35.716                                                   	MRR:18.99	Hits@10:34.27	Best:18.99
2024-12-27 15:50:58,159: Snapshot:3	Epoch:1	Loss:4.996	translation_Loss:4.449	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.546                                                   	MRR:20.48	Hits@10:36.58	Best:20.48
2024-12-27 15:51:05,724: Snapshot:3	Epoch:2	Loss:3.944	translation_Loss:3.357	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.586                                                   	MRR:20.69	Hits@10:36.97	Best:20.69
2024-12-27 15:51:13,516: Snapshot:3	Epoch:3	Loss:3.623	translation_Loss:2.981	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.642                                                   	MRR:20.8	Hits@10:37.27	Best:20.8
2024-12-27 15:51:20,988: Snapshot:3	Epoch:4	Loss:3.429	translation_Loss:2.732	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.697                                                   	MRR:20.9	Hits@10:37.49	Best:20.9
2024-12-27 15:51:28,370: Snapshot:3	Epoch:5	Loss:3.343	translation_Loss:2.602	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.74                                                   	MRR:21.09	Hits@10:37.81	Best:21.09
2024-12-27 15:51:35,735: Snapshot:3	Epoch:6	Loss:3.257	translation_Loss:2.478	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.779                                                   	MRR:20.99	Hits@10:37.57	Best:21.09
2024-12-27 15:51:43,074: Snapshot:3	Epoch:7	Loss:3.192	translation_Loss:2.396	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.796                                                   	MRR:21.18	Hits@10:38.01	Best:21.18
2024-12-27 15:51:50,510: Snapshot:3	Epoch:8	Loss:3.173	translation_Loss:2.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.841                                                   	MRR:21.27	Hits@10:38.23	Best:21.27
2024-12-27 15:51:57,869: Snapshot:3	Epoch:9	Loss:3.122	translation_Loss:2.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.861                                                   	MRR:21.31	Hits@10:38.15	Best:21.31
2024-12-27 15:52:05,213: Snapshot:3	Epoch:10	Loss:3.07	translation_Loss:2.188	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.881                                                   	MRR:21.34	Hits@10:38.3	Best:21.34
2024-12-27 15:52:12,518: Snapshot:3	Epoch:11	Loss:3.11	translation_Loss:2.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.929                                                   	MRR:21.3	Hits@10:38.42	Best:21.34
2024-12-27 15:52:19,837: Snapshot:3	Epoch:12	Loss:3.034	translation_Loss:2.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.935                                                   	MRR:21.38	Hits@10:38.57	Best:21.38
2024-12-27 15:52:27,135: Snapshot:3	Epoch:13	Loss:3.06	translation_Loss:2.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.965                                                   	MRR:21.38	Hits@10:38.52	Best:21.38
2024-12-27 15:52:34,906: Snapshot:3	Epoch:14	Loss:3.051	translation_Loss:2.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.992                                                   	MRR:21.45	Hits@10:38.82	Best:21.45
2024-12-27 15:52:42,260: Snapshot:3	Epoch:15	Loss:3.023	translation_Loss:2.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.999                                                   	MRR:21.52	Hits@10:38.65	Best:21.52
2024-12-27 15:52:49,648: Snapshot:3	Epoch:16	Loss:3.02	translation_Loss:1.985	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.035                                                   	MRR:21.44	Hits@10:38.65	Best:21.52
2024-12-27 15:52:57,045: Snapshot:3	Epoch:17	Loss:3.04	translation_Loss:1.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.067                                                   	MRR:21.59	Hits@10:38.98	Best:21.59
2024-12-27 15:53:04,372: Snapshot:3	Epoch:18	Loss:3.045	translation_Loss:1.948	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.097                                                   	MRR:21.43	Hits@10:38.69	Best:21.59
2024-12-27 15:53:11,813: Snapshot:3	Epoch:19	Loss:3.123	translation_Loss:1.93	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.193                                                   	MRR:21.44	Hits@10:38.71	Best:21.59
2024-12-27 15:53:19,112: Snapshot:3	Epoch:20	Loss:3.136	translation_Loss:1.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.222                                                   	MRR:21.38	Hits@10:38.53	Best:21.59
2024-12-27 15:53:26,456: Snapshot:3	Epoch:21	Loss:3.16	translation_Loss:1.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.247                                                   	MRR:21.61	Hits@10:38.73	Best:21.61
2024-12-27 15:53:33,838: Snapshot:3	Epoch:22	Loss:3.162	translation_Loss:1.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.288                                                   	MRR:21.74	Hits@10:38.91	Best:21.74
2024-12-27 15:53:41,245: Snapshot:3	Epoch:23	Loss:3.213	translation_Loss:1.89	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.323                                                   	MRR:21.65	Hits@10:38.72	Best:21.74
2024-12-27 15:53:48,988: Snapshot:3	Epoch:24	Loss:3.248	translation_Loss:1.877	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.371                                                   	MRR:21.68	Hits@10:38.82	Best:21.74
2024-12-27 15:53:56,317: Snapshot:3	Epoch:25	Loss:3.216	translation_Loss:1.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.38                                                   	MRR:21.6	Hits@10:38.79	Best:21.74
2024-12-27 15:54:03,612: Snapshot:3	Epoch:26	Loss:3.201	translation_Loss:1.81	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.391                                                   	MRR:21.68	Hits@10:38.87	Best:21.74
2024-12-27 15:54:11,030: Early Stopping! Snapshot: 3 Epoch: 27 Best Results: 21.74
2024-12-27 15:54:11,030: Start to training tokens! Snapshot: 3 Epoch: 27 Loss:3.257 MRR:21.58 Best Results: 21.74
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 15:54:11,030: Snapshot:3	Epoch:27	Loss:3.257	translation_Loss:1.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.406                                                   	MRR:21.58	Hits@10:39.04	Best:21.74
2024-12-27 15:54:18,427: Snapshot:3	Epoch:28	Loss:42.289	translation_Loss:42.251	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.58	Hits@10:39.04	Best:21.74
2024-12-27 15:54:25,741: End of token training: 3 Epoch: 29 Loss:42.249 MRR:21.58 Best Results: 21.74
2024-12-27 15:54:25,741: Snapshot:3	Epoch:29	Loss:42.249	translation_Loss:42.249	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.58	Hits@10:39.04	Best:21.74
2024-12-27 15:54:25,997: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_2/3model_best.tar'
2024-12-27 15:54:35,473: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3256 | 0.2077 | 0.3787 | 0.4496 |  0.5513 |
|     1      | 0.239  | 0.1442 | 0.2695 | 0.3345 |  0.4255 |
|     2      | 0.2272 | 0.1365 | 0.2586 | 0.3171 |  0.4012 |
|     3      | 0.2162 | 0.1264 | 0.248  | 0.3061 |  0.3883 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:54:54,409: Snapshot:4	Epoch:0	Loss:45.109	translation_Loss:11.046	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:34.063                                                   	MRR:23.15	Hits@10:41.73	Best:23.15
2024-12-27 15:54:59,790: Snapshot:4	Epoch:1	Loss:2.837	translation_Loss:2.427	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.41                                                   	MRR:24.76	Hits@10:43.98	Best:24.76
2024-12-27 15:55:05,184: Snapshot:4	Epoch:2	Loss:1.817	translation_Loss:1.542	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.275                                                   	MRR:25.04	Hits@10:44.67	Best:25.04
2024-12-27 15:55:10,592: Snapshot:4	Epoch:3	Loss:1.636	translation_Loss:1.343	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.293                                                   	MRR:25.06	Hits@10:44.7	Best:25.06
2024-12-27 15:55:15,801: Snapshot:4	Epoch:4	Loss:1.513	translation_Loss:1.204	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.309                                                   	MRR:25.0	Hits@10:44.58	Best:25.06
2024-12-27 15:55:21,115: Snapshot:4	Epoch:5	Loss:1.45	translation_Loss:1.129	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.321                                                   	MRR:25.08	Hits@10:44.73	Best:25.08
2024-12-27 15:55:26,483: Snapshot:4	Epoch:6	Loss:1.397	translation_Loss:1.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.337                                                   	MRR:25.21	Hits@10:45.2	Best:25.21
2024-12-27 15:55:31,733: Snapshot:4	Epoch:7	Loss:1.374	translation_Loss:1.023	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.352                                                   	MRR:25.31	Hits@10:45.36	Best:25.31
2024-12-27 15:55:37,018: Snapshot:4	Epoch:8	Loss:1.339	translation_Loss:0.981	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.358                                                   	MRR:25.37	Hits@10:45.57	Best:25.37
2024-12-27 15:55:42,244: Snapshot:4	Epoch:9	Loss:1.326	translation_Loss:0.959	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.367                                                   	MRR:25.12	Hits@10:45.46	Best:25.37
2024-12-27 15:55:47,461: Snapshot:4	Epoch:10	Loss:1.307	translation_Loss:0.928	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.379                                                   	MRR:25.36	Hits@10:45.37	Best:25.37
2024-12-27 15:55:53,100: Snapshot:4	Epoch:11	Loss:1.303	translation_Loss:0.916	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.387                                                   	MRR:25.44	Hits@10:45.49	Best:25.44
2024-12-27 15:55:58,455: Snapshot:4	Epoch:12	Loss:1.295	translation_Loss:0.904	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.391                                                   	MRR:25.66	Hits@10:45.59	Best:25.66
2024-12-27 15:56:03,776: Snapshot:4	Epoch:13	Loss:1.298	translation_Loss:0.891	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.407                                                   	MRR:25.57	Hits@10:45.74	Best:25.66
2024-12-27 15:56:09,027: Snapshot:4	Epoch:14	Loss:1.245	translation_Loss:0.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.402                                                   	MRR:25.39	Hits@10:45.63	Best:25.66
2024-12-27 15:56:14,242: Snapshot:4	Epoch:15	Loss:1.261	translation_Loss:0.846	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.415                                                   	MRR:25.5	Hits@10:45.84	Best:25.66
2024-12-27 15:56:19,446: Snapshot:4	Epoch:16	Loss:1.265	translation_Loss:0.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.426                                                   	MRR:25.56	Hits@10:45.89	Best:25.66
2024-12-27 15:56:24,713: Snapshot:4	Epoch:17	Loss:1.247	translation_Loss:0.813	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.435                                                   	MRR:25.87	Hits@10:46.05	Best:25.87
2024-12-27 15:56:30,053: Snapshot:4	Epoch:18	Loss:1.243	translation_Loss:0.806	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.437                                                   	MRR:25.56	Hits@10:46.15	Best:25.87
2024-12-27 15:56:35,379: Snapshot:4	Epoch:19	Loss:1.261	translation_Loss:0.8	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.461                                                   	MRR:25.6	Hits@10:46.17	Best:25.87
2024-12-27 15:56:40,675: Snapshot:4	Epoch:20	Loss:1.239	translation_Loss:0.783	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.456                                                   	MRR:25.52	Hits@10:45.99	Best:25.87
2024-12-27 15:56:45,898: Snapshot:4	Epoch:21	Loss:1.251	translation_Loss:0.786	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.466                                                   	MRR:25.49	Hits@10:46.11	Best:25.87
2024-12-27 15:56:51,117: Early Stopping! Snapshot: 4 Epoch: 22 Best Results: 25.87
2024-12-27 15:56:51,117: Start to training tokens! Snapshot: 4 Epoch: 22 Loss:1.245 MRR:25.51 Best Results: 25.87
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 15:56:51,117: Snapshot:4	Epoch:22	Loss:1.245	translation_Loss:0.766	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.479                                                   	MRR:25.51	Hits@10:46.09	Best:25.87
2024-12-27 15:56:56,373: Snapshot:4	Epoch:23	Loss:23.42	translation_Loss:23.384	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.51	Hits@10:46.09	Best:25.87
2024-12-27 15:57:01,660: End of token training: 4 Epoch: 24 Loss:23.362 MRR:25.51 Best Results: 25.87
2024-12-27 15:57:01,660: Snapshot:4	Epoch:24	Loss:23.362	translation_Loss:23.362	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.51	Hits@10:46.09	Best:25.87
2024-12-27 15:57:01,971: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_2/4model_best.tar'
2024-12-27 15:57:14,134: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3259 | 0.2083 | 0.3783 | 0.4495 |  0.5512 |
|     1      | 0.2393 | 0.1446 | 0.2694 | 0.3346 |  0.4261 |
|     2      | 0.2277 | 0.1371 | 0.2587 | 0.3175 |  0.4011 |
|     3      | 0.2164 | 0.1263 | 0.2482 | 0.3066 |  0.3884 |
|     4      | 0.2581 | 0.1515 | 0.3078 | 0.3768 |  0.4657 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 15:57:14,136: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3254 | 0.2075 | 0.3789 | 0.4496 |  0.5515 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3252 | 0.2074 | 0.3791 | 0.4491 |  0.551  |
|     1      | 0.2391 | 0.1445 | 0.2689 | 0.3346 |  0.4254 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3253 | 0.2075 | 0.3782 | 0.4494 |  0.5511 |
|     1      | 0.239  | 0.1442 | 0.2691 | 0.3343 |  0.4254 |
|     2      | 0.2275 | 0.137  | 0.2582 | 0.3176 |  0.4011 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3256 | 0.2077 | 0.3787 | 0.4496 |  0.5513 |
|     1      | 0.239  | 0.1442 | 0.2695 | 0.3345 |  0.4255 |
|     2      | 0.2272 | 0.1365 | 0.2586 | 0.3171 |  0.4012 |
|     3      | 0.2162 | 0.1264 | 0.248  | 0.3061 |  0.3883 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3259 | 0.2083 | 0.3783 | 0.4495 |  0.5512 |
|     1      | 0.2393 | 0.1446 | 0.2694 | 0.3346 |  0.4261 |
|     2      | 0.2277 | 0.1371 | 0.2587 | 0.3175 |  0.4011 |
|     3      | 0.2164 | 0.1263 | 0.2482 | 0.3066 |  0.3884 |
|     4      | 0.2581 | 0.1515 | 0.3078 | 0.3768 |  0.4657 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 15:57:14,137: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 46.05960774421692  |   0.325   |    0.207     |    0.379     |     0.551     |
|    1     | 101.41547703742981 |   0.273   |    0.169     |    0.312     |     0.475     |
|    2     | 146.15653014183044 |   0.255   |    0.157     |    0.291     |     0.446     |
|    3     | 237.21300792694092 |   0.245   |    0.148     |     0.28     |     0.431     |
|    4     | 143.68206548690796 |   0.247   |    0.149     |    0.284     |     0.436     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 15:57:14,137: Sum_Training_Time:674.526688337326
2024-12-27 15:57:14,137: Every_Training_Time:[46.05960774421692, 101.41547703742981, 146.15653014183044, 237.21300792694092, 143.68206548690796]
2024-12-27 15:57:14,137: Forward transfer: 0.042675 Backward transfer: 0.0002750000000000044
2024-12-27 15:57:47,723: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227155718/ENTITYentity_0.01_1024_4', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_1024_4', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_1024_4', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=4, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 15:57:55,432: Snapshot:0	Epoch:0	Loss:28.546	translation_Loss:28.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.45	Hits@10:47.27	Best:24.45
2024-12-27 15:57:59,467: Snapshot:0	Epoch:1	Loss:9.986	translation_Loss:9.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.14	Hits@10:54.03	Best:31.14
2024-12-27 15:58:03,285: Snapshot:0	Epoch:2	Loss:3.794	translation_Loss:3.794	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.74	Hits@10:54.93	Best:31.74
2024-12-27 15:58:07,252: Snapshot:0	Epoch:3	Loss:2.041	translation_Loss:2.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.86	Hits@10:54.55	Best:31.86
2024-12-27 15:58:11,089: Snapshot:0	Epoch:4	Loss:1.394	translation_Loss:1.394	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.96	Hits@10:54.45	Best:31.96
2024-12-27 15:58:14,930: Snapshot:0	Epoch:5	Loss:1.101	translation_Loss:1.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.62	Hits@10:54.05	Best:31.96
2024-12-27 15:58:18,805: Snapshot:0	Epoch:6	Loss:0.949	translation_Loss:0.949	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.67	Hits@10:54.03	Best:31.96
2024-12-27 15:58:22,580: Snapshot:0	Epoch:7	Loss:0.832	translation_Loss:0.832	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.54	Hits@10:53.5	Best:31.96
2024-12-27 15:58:26,398: Snapshot:0	Epoch:8	Loss:0.75	translation_Loss:0.75	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.44	Hits@10:53.3	Best:31.96
2024-12-27 15:58:30,218: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 31.96
2024-12-27 15:58:30,218: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.693 MRR:31.38 Best Results: 31.96
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 15:58:30,219: Snapshot:0	Epoch:9	Loss:0.693	translation_Loss:0.693	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.38	Hits@10:53.17	Best:31.96
2024-12-27 15:58:34,728: Snapshot:0	Epoch:10	Loss:28.064	translation_Loss:28.028	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.38	Hits@10:53.17	Best:31.96
2024-12-27 15:58:39,123: End of token training: 0 Epoch: 11 Loss:28.029 MRR:31.38 Best Results: 31.96
2024-12-27 15:58:39,123: Snapshot:0	Epoch:11	Loss:28.029	translation_Loss:28.029	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.38	Hits@10:53.17	Best:31.96
2024-12-27 15:58:39,361: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_4/0model_best.tar'
2024-12-27 15:58:40,662: 
+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.325 | 0.2077 | 0.3743 | 0.4492 |  0.5541 |
+------------+-------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 15:59:04,785: Snapshot:1	Epoch:0	Loss:92.71	translation_Loss:17.113	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:75.598                                                   	MRR:21.73	Hits@10:38.7	Best:21.73
2024-12-27 15:59:11,647: Snapshot:1	Epoch:1	Loss:4.847	translation_Loss:4.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:22.84	Hits@10:40.93	Best:22.84
2024-12-27 15:59:18,377: Snapshot:1	Epoch:2	Loss:3.552	translation_Loss:3.419	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.133                                                   	MRR:23.38	Hits@10:41.24	Best:23.38
2024-12-27 15:59:25,031: Snapshot:1	Epoch:3	Loss:3.112	translation_Loss:2.958	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:23.59	Hits@10:41.48	Best:23.59
2024-12-27 15:59:31,703: Snapshot:1	Epoch:4	Loss:2.898	translation_Loss:2.723	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.175                                                   	MRR:23.53	Hits@10:41.78	Best:23.59
2024-12-27 15:59:38,451: Snapshot:1	Epoch:5	Loss:2.733	translation_Loss:2.539	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:23.8	Hits@10:41.98	Best:23.8
2024-12-27 15:59:45,192: Snapshot:1	Epoch:6	Loss:2.634	translation_Loss:2.415	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.219                                                   	MRR:23.72	Hits@10:42.1	Best:23.8
2024-12-27 15:59:51,884: Snapshot:1	Epoch:7	Loss:2.575	translation_Loss:2.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.24                                                   	MRR:24.0	Hits@10:42.27	Best:24.0
2024-12-27 15:59:58,650: Snapshot:1	Epoch:8	Loss:2.503	translation_Loss:2.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.265                                                   	MRR:23.93	Hits@10:42.38	Best:24.0
2024-12-27 16:00:05,576: Snapshot:1	Epoch:9	Loss:2.454	translation_Loss:2.165	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.29                                                   	MRR:24.01	Hits@10:42.37	Best:24.01
2024-12-27 16:00:12,345: Snapshot:1	Epoch:10	Loss:2.423	translation_Loss:2.106	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.317                                                   	MRR:24.01	Hits@10:42.48	Best:24.01
2024-12-27 16:00:19,457: Snapshot:1	Epoch:11	Loss:2.394	translation_Loss:2.049	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.346                                                   	MRR:23.98	Hits@10:42.52	Best:24.01
2024-12-27 16:00:26,125: Snapshot:1	Epoch:12	Loss:2.388	translation_Loss:2.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.376                                                   	MRR:24.03	Hits@10:42.48	Best:24.03
2024-12-27 16:00:32,798: Snapshot:1	Epoch:13	Loss:2.38	translation_Loss:1.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.407                                                   	MRR:24.04	Hits@10:42.35	Best:24.04
2024-12-27 16:00:39,455: Snapshot:1	Epoch:14	Loss:2.385	translation_Loss:1.943	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.442                                                   	MRR:23.88	Hits@10:42.36	Best:24.04
2024-12-27 16:00:46,118: Snapshot:1	Epoch:15	Loss:2.389	translation_Loss:1.912	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.477                                                   	MRR:24.03	Hits@10:42.4	Best:24.04
2024-12-27 16:00:52,790: Snapshot:1	Epoch:16	Loss:2.434	translation_Loss:1.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.525                                                   	MRR:24.15	Hits@10:42.54	Best:24.15
2024-12-27 16:00:59,566: Snapshot:1	Epoch:17	Loss:2.467	translation_Loss:1.892	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.574                                                   	MRR:24.18	Hits@10:42.74	Best:24.18
2024-12-27 16:01:06,395: Snapshot:1	Epoch:18	Loss:2.467	translation_Loss:1.834	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.633                                                   	MRR:24.23	Hits@10:42.83	Best:24.23
2024-12-27 16:01:13,122: Snapshot:1	Epoch:19	Loss:2.783	translation_Loss:1.848	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.935                                                   	MRR:24.34	Hits@10:42.65	Best:24.34
2024-12-27 16:01:19,854: Snapshot:1	Epoch:20	Loss:2.82	translation_Loss:1.822	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.999                                                   	MRR:24.2	Hits@10:42.9	Best:24.34
2024-12-27 16:01:27,030: Snapshot:1	Epoch:21	Loss:2.848	translation_Loss:1.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.075                                                   	MRR:24.19	Hits@10:43.07	Best:24.34
2024-12-27 16:01:33,736: Snapshot:1	Epoch:22	Loss:2.955	translation_Loss:1.776	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.179                                                   	MRR:24.39	Hits@10:43.18	Best:24.39
2024-12-27 16:01:40,426: Snapshot:1	Epoch:23	Loss:3.103	translation_Loss:1.755	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.348                                                   	MRR:24.24	Hits@10:42.67	Best:24.39
2024-12-27 16:01:47,093: Snapshot:1	Epoch:24	Loss:3.196	translation_Loss:1.738	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.458                                                   	MRR:24.28	Hits@10:42.73	Best:24.39
2024-12-27 16:01:53,761: Snapshot:1	Epoch:25	Loss:3.217	translation_Loss:1.717	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.5                                                   	MRR:24.28	Hits@10:43.01	Best:24.39
2024-12-27 16:02:00,444: Snapshot:1	Epoch:26	Loss:3.258	translation_Loss:1.712	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.546                                                   	MRR:24.21	Hits@10:42.77	Best:24.39
2024-12-27 16:02:07,086: Early Stopping! Snapshot: 1 Epoch: 27 Best Results: 24.39
2024-12-27 16:02:07,087: Start to training tokens! Snapshot: 1 Epoch: 27 Loss:3.258 MRR:24.21 Best Results: 24.39
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 16:02:07,087: Snapshot:1	Epoch:27	Loss:3.258	translation_Loss:1.709	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.548                                                   	MRR:24.21	Hits@10:42.99	Best:24.39
2024-12-27 16:02:13,846: Snapshot:1	Epoch:28	Loss:46.258	translation_Loss:46.221	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.21	Hits@10:42.99	Best:24.39
2024-12-27 16:02:20,592: End of token training: 1 Epoch: 29 Loss:46.201 MRR:24.21 Best Results: 24.39
2024-12-27 16:02:20,592: Snapshot:1	Epoch:29	Loss:46.201	translation_Loss:46.201	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.21	Hits@10:42.99	Best:24.39
2024-12-27 16:02:20,890: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_4/1model_best.tar'
2024-12-27 16:02:24,737: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3252 | 0.2081 | 0.3739 | 0.4486 |  0.5536 |
|     1      | 0.2414 | 0.1464 | 0.2712 | 0.3368 |  0.4291 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:02:50,607: Snapshot:2	Epoch:0	Loss:87.944	translation_Loss:16.443	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:71.501                                                   	MRR:19.28	Hits@10:34.44	Best:19.28
2024-12-27 16:02:58,049: Snapshot:2	Epoch:1	Loss:4.924	translation_Loss:4.731	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.193                                                   	MRR:20.8	Hits@10:36.97	Best:20.8
2024-12-27 16:03:05,342: Snapshot:2	Epoch:2	Loss:3.77	translation_Loss:3.559	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.21                                                   	MRR:21.3	Hits@10:37.69	Best:21.3
2024-12-27 16:03:12,820: Snapshot:2	Epoch:3	Loss:3.432	translation_Loss:3.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.247                                                   	MRR:21.43	Hits@10:38.29	Best:21.43
2024-12-27 16:03:20,169: Snapshot:2	Epoch:4	Loss:3.174	translation_Loss:2.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.275                                                   	MRR:21.65	Hits@10:38.35	Best:21.65
2024-12-27 16:03:27,440: Snapshot:2	Epoch:5	Loss:3.05	translation_Loss:2.743	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.306                                                   	MRR:21.62	Hits@10:38.25	Best:21.65
2024-12-27 16:03:34,801: Snapshot:2	Epoch:6	Loss:2.93	translation_Loss:2.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.332                                                   	MRR:21.86	Hits@10:38.66	Best:21.86
2024-12-27 16:03:42,335: Snapshot:2	Epoch:7	Loss:2.856	translation_Loss:2.496	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.36                                                   	MRR:22.0	Hits@10:38.86	Best:22.0
2024-12-27 16:03:49,646: Snapshot:2	Epoch:8	Loss:2.839	translation_Loss:2.441	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.398                                                   	MRR:21.89	Hits@10:38.88	Best:22.0
2024-12-27 16:03:56,956: Snapshot:2	Epoch:9	Loss:2.785	translation_Loss:2.362	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.423                                                   	MRR:21.98	Hits@10:38.96	Best:22.0
2024-12-27 16:04:04,272: Snapshot:2	Epoch:10	Loss:2.764	translation_Loss:2.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.459                                                   	MRR:22.11	Hits@10:39.17	Best:22.11
2024-12-27 16:04:11,584: Snapshot:2	Epoch:11	Loss:2.743	translation_Loss:2.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.49                                                   	MRR:22.2	Hits@10:39.24	Best:22.2
2024-12-27 16:04:18,974: Snapshot:2	Epoch:12	Loss:2.746	translation_Loss:2.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.527                                                   	MRR:22.22	Hits@10:39.21	Best:22.22
2024-12-27 16:04:26,372: Snapshot:2	Epoch:13	Loss:2.729	translation_Loss:2.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.563                                                   	MRR:22.17	Hits@10:39.26	Best:22.22
2024-12-27 16:04:33,695: Snapshot:2	Epoch:14	Loss:2.742	translation_Loss:2.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.603                                                   	MRR:22.31	Hits@10:39.3	Best:22.31
2024-12-27 16:04:41,012: Snapshot:2	Epoch:15	Loss:2.797	translation_Loss:2.143	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.653                                                   	MRR:22.26	Hits@10:39.58	Best:22.31
2024-12-27 16:04:48,318: Snapshot:2	Epoch:16	Loss:2.806	translation_Loss:2.108	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.698                                                   	MRR:22.34	Hits@10:39.53	Best:22.34
2024-12-27 16:04:55,770: Snapshot:2	Epoch:17	Loss:2.859	translation_Loss:2.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.77                                                   	MRR:22.38	Hits@10:39.43	Best:22.38
2024-12-27 16:05:03,200: Snapshot:2	Epoch:18	Loss:3.137	translation_Loss:2.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.07                                                   	MRR:22.3	Hits@10:39.46	Best:22.38
2024-12-27 16:05:10,596: Snapshot:2	Epoch:19	Loss:3.181	translation_Loss:2.05	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.13                                                   	MRR:22.37	Hits@10:39.42	Best:22.38
2024-12-27 16:05:17,925: Snapshot:2	Epoch:20	Loss:3.214	translation_Loss:2.021	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.193                                                   	MRR:22.44	Hits@10:39.5	Best:22.44
2024-12-27 16:05:25,177: Snapshot:2	Epoch:21	Loss:3.269	translation_Loss:2.001	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.268                                                   	MRR:22.33	Hits@10:39.45	Best:22.44
2024-12-27 16:05:32,616: Snapshot:2	Epoch:22	Loss:3.349	translation_Loss:1.965	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.384                                                   	MRR:22.55	Hits@10:39.8	Best:22.55
2024-12-27 16:05:39,970: Snapshot:2	Epoch:23	Loss:3.562	translation_Loss:1.961	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.601                                                   	MRR:22.48	Hits@10:39.75	Best:22.55
2024-12-27 16:05:47,321: Snapshot:2	Epoch:24	Loss:3.571	translation_Loss:1.953	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.618                                                   	MRR:22.49	Hits@10:39.78	Best:22.55
2024-12-27 16:05:54,699: Snapshot:2	Epoch:25	Loss:3.648	translation_Loss:1.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.679                                                   	MRR:22.46	Hits@10:39.83	Best:22.55
2024-12-27 16:06:02,229: Snapshot:2	Epoch:26	Loss:3.585	translation_Loss:1.92	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.665                                                   	MRR:22.26	Hits@10:39.6	Best:22.55
2024-12-27 16:06:09,683: Early Stopping! Snapshot: 2 Epoch: 27 Best Results: 22.55
2024-12-27 16:06:09,684: Start to training tokens! Snapshot: 2 Epoch: 27 Loss:3.612 MRR:22.52 Best Results: 22.55
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 16:06:09,684: Snapshot:2	Epoch:27	Loss:3.612	translation_Loss:1.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.683                                                   	MRR:22.52	Hits@10:39.6	Best:22.55
2024-12-27 16:06:17,014: Snapshot:2	Epoch:28	Loss:47.281	translation_Loss:47.245	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.52	Hits@10:39.6	Best:22.55
2024-12-27 16:06:24,270: End of token training: 2 Epoch: 29 Loss:47.241 MRR:22.52 Best Results: 22.55
2024-12-27 16:06:24,270: Snapshot:2	Epoch:29	Loss:47.241	translation_Loss:47.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.52	Hits@10:39.6	Best:22.55
2024-12-27 16:06:24,576: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_4/2model_best.tar'
2024-12-27 16:06:31,385: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3251 | 0.2081 | 0.3735 | 0.4486 |  0.5536 |
|     1      | 0.2416 | 0.1464 | 0.2715 | 0.3369 |  0.4291 |
|     2      | 0.2264 | 0.136  | 0.258  | 0.3153 |  0.4005 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:06:56,981: Snapshot:3	Epoch:0	Loss:85.695	translation_Loss:14.911	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:70.784                                                   	MRR:18.52	Hits@10:33.51	Best:18.52
2024-12-27 16:07:04,511: Snapshot:3	Epoch:1	Loss:4.263	translation_Loss:4.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.225                                                   	MRR:19.87	Hits@10:36.19	Best:19.87
2024-12-27 16:07:11,951: Snapshot:3	Epoch:2	Loss:3.27	translation_Loss:3.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.234                                                   	MRR:20.34	Hits@10:36.79	Best:20.34
2024-12-27 16:07:19,434: Snapshot:3	Epoch:3	Loss:2.926	translation_Loss:2.661	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.265                                                   	MRR:20.71	Hits@10:37.4	Best:20.71
2024-12-27 16:07:26,800: Snapshot:3	Epoch:4	Loss:2.74	translation_Loss:2.443	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.297                                                   	MRR:20.59	Hits@10:37.38	Best:20.71
2024-12-27 16:07:34,226: Snapshot:3	Epoch:5	Loss:2.645	translation_Loss:2.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.323                                                   	MRR:20.68	Hits@10:37.63	Best:20.71
2024-12-27 16:07:41,703: Snapshot:3	Epoch:6	Loss:2.568	translation_Loss:2.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.351                                                   	MRR:20.86	Hits@10:37.78	Best:20.86
2024-12-27 16:07:49,149: Snapshot:3	Epoch:7	Loss:2.507	translation_Loss:2.133	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.374                                                   	MRR:20.83	Hits@10:37.67	Best:20.86
2024-12-27 16:07:56,584: Snapshot:3	Epoch:8	Loss:2.475	translation_Loss:2.073	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.402                                                   	MRR:20.91	Hits@10:37.81	Best:20.91
2024-12-27 16:08:04,006: Snapshot:3	Epoch:9	Loss:2.434	translation_Loss:2.007	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.427                                                   	MRR:21.12	Hits@10:37.98	Best:21.12
2024-12-27 16:08:11,627: Snapshot:3	Epoch:10	Loss:2.442	translation_Loss:1.978	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.464                                                   	MRR:21.15	Hits@10:38.21	Best:21.15
2024-12-27 16:08:19,047: Snapshot:3	Epoch:11	Loss:2.398	translation_Loss:1.915	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.483                                                   	MRR:21.31	Hits@10:38.37	Best:21.31
2024-12-27 16:08:26,445: Snapshot:3	Epoch:12	Loss:2.382	translation_Loss:1.873	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.51                                                   	MRR:21.21	Hits@10:38.51	Best:21.31
2024-12-27 16:08:33,793: Snapshot:3	Epoch:13	Loss:2.4	translation_Loss:1.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.547                                                   	MRR:21.2	Hits@10:38.42	Best:21.31
2024-12-27 16:08:41,237: Snapshot:3	Epoch:14	Loss:2.392	translation_Loss:1.817	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.575                                                   	MRR:21.34	Hits@10:38.55	Best:21.34
2024-12-27 16:08:48,785: Snapshot:3	Epoch:15	Loss:2.421	translation_Loss:1.806	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.615                                                   	MRR:21.38	Hits@10:38.52	Best:21.38
2024-12-27 16:08:56,200: Snapshot:3	Epoch:16	Loss:2.424	translation_Loss:1.781	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.643                                                   	MRR:21.37	Hits@10:38.54	Best:21.38
2024-12-27 16:09:04,086: Snapshot:3	Epoch:17	Loss:2.419	translation_Loss:1.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.684                                                   	MRR:21.36	Hits@10:38.66	Best:21.38
2024-12-27 16:09:11,487: Snapshot:3	Epoch:18	Loss:2.497	translation_Loss:1.732	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.765                                                   	MRR:21.18	Hits@10:38.54	Best:21.38
2024-12-27 16:09:18,846: Snapshot:3	Epoch:19	Loss:2.798	translation_Loss:1.718	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.08                                                   	MRR:21.27	Hits@10:38.67	Best:21.38
2024-12-27 16:09:26,264: Snapshot:3	Epoch:20	Loss:2.777	translation_Loss:1.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.093                                                   	MRR:21.49	Hits@10:38.62	Best:21.49
2024-12-27 16:09:33,615: Snapshot:3	Epoch:21	Loss:2.847	translation_Loss:1.688	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.158                                                   	MRR:21.39	Hits@10:38.72	Best:21.49
2024-12-27 16:09:40,963: Snapshot:3	Epoch:22	Loss:2.899	translation_Loss:1.688	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.212                                                   	MRR:21.2	Hits@10:38.51	Best:21.49
2024-12-27 16:09:48,332: Snapshot:3	Epoch:23	Loss:2.987	translation_Loss:1.67	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.317                                                   	MRR:21.32	Hits@10:38.5	Best:21.49
2024-12-27 16:09:55,825: Snapshot:3	Epoch:24	Loss:3.207	translation_Loss:1.652	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.556                                                   	MRR:21.34	Hits@10:38.46	Best:21.49
2024-12-27 16:10:03,321: Early Stopping! Snapshot: 3 Epoch: 25 Best Results: 21.49
2024-12-27 16:10:03,321: Start to training tokens! Snapshot: 3 Epoch: 25 Loss:3.162 MRR:21.36 Best Results: 21.49
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 16:10:03,322: Snapshot:3	Epoch:25	Loss:3.162	translation_Loss:1.614	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.548                                                   	MRR:21.36	Hits@10:38.63	Best:21.49
2024-12-27 16:10:10,953: Snapshot:3	Epoch:26	Loss:42.477	translation_Loss:42.442	multi_layer_Loss:0.035	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.36	Hits@10:38.63	Best:21.49
2024-12-27 16:10:18,731: End of token training: 3 Epoch: 27 Loss:42.412 MRR:21.36 Best Results: 21.49
2024-12-27 16:10:18,731: Snapshot:3	Epoch:27	Loss:42.412	translation_Loss:42.412	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.36	Hits@10:38.63	Best:21.49
2024-12-27 16:10:18,972: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_4/3model_best.tar'
2024-12-27 16:10:28,549: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3251 | 0.2082 | 0.3737 | 0.4488 |  0.5534 |
|     1      | 0.2417 | 0.1467 | 0.2711 | 0.3372 |  0.429  |
|     2      | 0.2263 | 0.1358 | 0.2577 | 0.3156 |  0.4006 |
|     3      | 0.2147 | 0.1266 | 0.2446 | 0.3031 |  0.3837 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:10:48,052: Snapshot:4	Epoch:0	Loss:78.561	translation_Loss:10.753	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:67.808                                                   	MRR:22.59	Hits@10:40.95	Best:22.59
2024-12-27 16:10:53,373: Snapshot:4	Epoch:1	Loss:2.589	translation_Loss:2.24	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.349                                                   	MRR:24.41	Hits@10:43.62	Best:24.41
2024-12-27 16:10:58,797: Snapshot:4	Epoch:2	Loss:1.522	translation_Loss:1.401	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.121                                                   	MRR:24.73	Hits@10:43.9	Best:24.73
2024-12-27 16:11:04,254: Snapshot:4	Epoch:3	Loss:1.324	translation_Loss:1.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:24.81	Hits@10:44.27	Best:24.81
2024-12-27 16:11:09,609: Snapshot:4	Epoch:4	Loss:1.204	translation_Loss:1.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.137                                                   	MRR:24.98	Hits@10:44.63	Best:24.98
2024-12-27 16:11:14,899: Snapshot:4	Epoch:5	Loss:1.154	translation_Loss:1.005	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:24.92	Hits@10:44.83	Best:24.98
2024-12-27 16:11:20,328: Snapshot:4	Epoch:6	Loss:1.111	translation_Loss:0.955	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:24.75	Hits@10:44.22	Best:24.98
2024-12-27 16:11:25,620: Snapshot:4	Epoch:7	Loss:1.078	translation_Loss:0.91	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:24.72	Hits@10:44.78	Best:24.98
2024-12-27 16:11:30,963: Snapshot:4	Epoch:8	Loss:1.051	translation_Loss:0.875	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.176                                                   	MRR:24.96	Hits@10:44.55	Best:24.98
2024-12-27 16:11:36,220: Early Stopping! Snapshot: 4 Epoch: 9 Best Results: 24.98
2024-12-27 16:11:36,221: Start to training tokens! Snapshot: 4 Epoch: 9 Loss:1.025 MRR:24.98 Best Results: 24.98
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 16:11:36,221: Snapshot:4	Epoch:9	Loss:1.025	translation_Loss:0.845	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.18                                                   	MRR:24.98	Hits@10:44.72	Best:24.98
2024-12-27 16:11:41,503: Snapshot:4	Epoch:10	Loss:23.397	translation_Loss:23.36	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.98	Hits@10:44.72	Best:24.98
2024-12-27 16:11:46,760: End of token training: 4 Epoch: 11 Loss:23.303 MRR:24.98 Best Results: 24.98
2024-12-27 16:11:46,761: Snapshot:4	Epoch:11	Loss:23.303	translation_Loss:23.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.98	Hits@10:44.72	Best:24.98
2024-12-27 16:11:47,067: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_4/4model_best.tar'
2024-12-27 16:11:59,157: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3252 | 0.2084 | 0.3738 | 0.4481 |  0.5529 |
|     1      | 0.242  | 0.1472 | 0.271  | 0.3373 |  0.429  |
|     2      | 0.2264 | 0.1359 | 0.2579 | 0.3161 |  0.4004 |
|     3      | 0.2149 | 0.1268 | 0.2445 | 0.3039 |  0.3838 |
|     4      | 0.2493 | 0.1456 | 0.2955 | 0.3625 |  0.4476 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 16:11:59,159: Final Result:
[+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.325 | 0.2077 | 0.3743 | 0.4492 |  0.5541 |
+------------+-------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3252 | 0.2081 | 0.3739 | 0.4486 |  0.5536 |
|     1      | 0.2414 | 0.1464 | 0.2712 | 0.3368 |  0.4291 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3251 | 0.2081 | 0.3735 | 0.4486 |  0.5536 |
|     1      | 0.2416 | 0.1464 | 0.2715 | 0.3369 |  0.4291 |
|     2      | 0.2264 | 0.136  | 0.258  | 0.3153 |  0.4005 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3251 | 0.2082 | 0.3737 | 0.4488 |  0.5534 |
|     1      | 0.2417 | 0.1467 | 0.2711 | 0.3372 |  0.429  |
|     2      | 0.2263 | 0.1358 | 0.2577 | 0.3156 |  0.4006 |
|     3      | 0.2147 | 0.1266 | 0.2446 | 0.3031 |  0.3837 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3252 | 0.2084 | 0.3738 | 0.4481 |  0.5529 |
|     1      | 0.242  | 0.1472 | 0.271  | 0.3373 |  0.429  |
|     2      | 0.2264 | 0.1359 | 0.2579 | 0.3161 |  0.4004 |
|     3      | 0.2149 | 0.1268 | 0.2445 | 0.3039 |  0.3838 |
|     4      | 0.2493 | 0.1456 | 0.2955 | 0.3625 |  0.4476 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 16:11:59,160: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 51.39875555038452  |   0.325   |    0.208     |    0.374     |     0.554     |
|    1     | 217.70616960525513 |   0.274   |    0.171     |    0.311     |     0.478     |
|    2     | 236.80516266822815 |   0.256   |    0.157     |    0.291     |     0.448     |
|    3     | 224.31627702713013 |   0.245   |    0.149     |    0.278     |     0.431     |
|    4     |  75.7454023361206  |   0.246   |    0.149     |    0.281     |     0.433     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 16:11:59,160: Sum_Training_Time:805.9717671871185
2024-12-27 16:11:59,160: Every_Training_Time:[51.39875555038452, 217.70616960525513, 236.80516266822815, 224.31627702713013, 75.7454023361206]
2024-12-27 16:11:59,160: Forward transfer: 0.039875 Backward transfer: 0.0002499999999999933
2024-12-27 16:12:32,885: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227161202/ENTITYentity_0.01_1024_6', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_1024_6', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_1024_6', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=6, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 16:12:40,546: Snapshot:0	Epoch:0	Loss:28.546	translation_Loss:28.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.44	Hits@10:47.14	Best:24.44
2024-12-27 16:12:44,372: Snapshot:0	Epoch:1	Loss:9.987	translation_Loss:9.987	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.14	Hits@10:54.06	Best:31.14
2024-12-27 16:12:48,295: Snapshot:0	Epoch:2	Loss:3.796	translation_Loss:3.796	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.78	Hits@10:54.61	Best:31.78
2024-12-27 16:12:52,081: Snapshot:0	Epoch:3	Loss:2.048	translation_Loss:2.048	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.79	Hits@10:54.33	Best:31.79
2024-12-27 16:12:55,913: Snapshot:0	Epoch:4	Loss:1.392	translation_Loss:1.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.79	Hits@10:54.31	Best:31.79
2024-12-27 16:12:59,743: Snapshot:0	Epoch:5	Loss:1.101	translation_Loss:1.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.62	Hits@10:53.98	Best:31.79
2024-12-27 16:13:03,509: Snapshot:0	Epoch:6	Loss:0.95	translation_Loss:0.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.44	Hits@10:53.78	Best:31.79
2024-12-27 16:13:07,320: Snapshot:0	Epoch:7	Loss:0.841	translation_Loss:0.841	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.59	Hits@10:53.64	Best:31.79
2024-12-27 16:13:11,108: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 31.79
2024-12-27 16:13:11,108: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:0.751 MRR:31.32 Best Results: 31.79
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 16:13:11,108: Snapshot:0	Epoch:8	Loss:0.751	translation_Loss:0.751	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.32	Hits@10:53.2	Best:31.79
2024-12-27 16:13:15,507: Snapshot:0	Epoch:9	Loss:28.078	translation_Loss:28.042	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.32	Hits@10:53.2	Best:31.79
2024-12-27 16:13:19,396: End of token training: 0 Epoch: 10 Loss:28.058 MRR:31.32 Best Results: 31.79
2024-12-27 16:13:19,396: Snapshot:0	Epoch:10	Loss:28.058	translation_Loss:28.058	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.32	Hits@10:53.2	Best:31.79
2024-12-27 16:13:19,701: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_6/0model_best.tar'
2024-12-27 16:13:21,373: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3259 | 0.2088 | 0.3762 | 0.4522 |  0.552  |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:13:45,935: Snapshot:1	Epoch:0	Loss:131.389	translation_Loss:17.617	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:113.771                                                   	MRR:21.74	Hits@10:38.77	Best:21.74
2024-12-27 16:13:52,604: Snapshot:1	Epoch:1	Loss:5.294	translation_Loss:5.187	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:23.02	Hits@10:41.16	Best:23.02
2024-12-27 16:13:59,325: Snapshot:1	Epoch:2	Loss:3.932	translation_Loss:3.83	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:23.32	Hits@10:41.83	Best:23.32
2024-12-27 16:14:06,024: Snapshot:1	Epoch:3	Loss:3.45	translation_Loss:3.329	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.121                                                   	MRR:23.44	Hits@10:42.01	Best:23.44
2024-12-27 16:14:12,743: Snapshot:1	Epoch:4	Loss:3.182	translation_Loss:3.042	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.139                                                   	MRR:23.64	Hits@10:42.2	Best:23.64
2024-12-27 16:14:19,427: Snapshot:1	Epoch:5	Loss:3.039	translation_Loss:2.88	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.159                                                   	MRR:23.75	Hits@10:42.34	Best:23.75
2024-12-27 16:14:26,052: Snapshot:1	Epoch:6	Loss:2.893	translation_Loss:2.714	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.179                                                   	MRR:23.89	Hits@10:42.35	Best:23.89
2024-12-27 16:14:32,714: Snapshot:1	Epoch:7	Loss:2.846	translation_Loss:2.644	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:23.8	Hits@10:42.47	Best:23.89
2024-12-27 16:14:39,458: Snapshot:1	Epoch:8	Loss:2.74	translation_Loss:2.521	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:23.68	Hits@10:42.51	Best:23.89
2024-12-27 16:14:46,074: Snapshot:1	Epoch:9	Loss:2.703	translation_Loss:2.457	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.246                                                   	MRR:23.74	Hits@10:42.55	Best:23.89
2024-12-27 16:14:52,665: Snapshot:1	Epoch:10	Loss:2.632	translation_Loss:2.362	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.27                                                   	MRR:23.77	Hits@10:42.67	Best:23.89
2024-12-27 16:14:59,336: Early Stopping! Snapshot: 1 Epoch: 11 Best Results: 23.89
2024-12-27 16:14:59,336: Start to training tokens! Snapshot: 1 Epoch: 11 Loss:2.611 MRR:23.59 Best Results: 23.89
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 16:14:59,336: Snapshot:1	Epoch:11	Loss:2.611	translation_Loss:2.315	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.296                                                   	MRR:23.59	Hits@10:42.47	Best:23.89
2024-12-27 16:15:06,173: Snapshot:1	Epoch:12	Loss:46.228	translation_Loss:46.19	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.59	Hits@10:42.47	Best:23.89
2024-12-27 16:15:12,998: End of token training: 1 Epoch: 13 Loss:46.116 MRR:23.59 Best Results: 23.89
2024-12-27 16:15:12,998: Snapshot:1	Epoch:13	Loss:46.116	translation_Loss:46.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.59	Hits@10:42.47	Best:23.89
2024-12-27 16:15:13,298: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_6/1model_best.tar'
2024-12-27 16:15:16,676: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3258 | 0.2087 | 0.3757 | 0.4522 |  0.5521 |
|     1      | 0.2362 | 0.142  | 0.265  | 0.3303 |  0.4212 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:15:42,043: Snapshot:2	Epoch:0	Loss:124.538	translation_Loss:16.946	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:107.592                                                   	MRR:19.54	Hits@10:34.86	Best:19.54
2024-12-27 16:15:49,293: Snapshot:2	Epoch:1	Loss:5.349	translation_Loss:5.166	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.184                                                   	MRR:21.23	Hits@10:37.45	Best:21.23
2024-12-27 16:15:56,591: Snapshot:2	Epoch:2	Loss:4.149	translation_Loss:3.948	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:21.54	Hits@10:38.3	Best:21.54
2024-12-27 16:16:03,944: Snapshot:2	Epoch:3	Loss:3.715	translation_Loss:3.484	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.23                                                   	MRR:21.77	Hits@10:38.62	Best:21.77
2024-12-27 16:16:11,246: Snapshot:2	Epoch:4	Loss:3.512	translation_Loss:3.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.268                                                   	MRR:21.83	Hits@10:38.87	Best:21.83
2024-12-27 16:16:18,531: Snapshot:2	Epoch:5	Loss:3.369	translation_Loss:3.068	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.301                                                   	MRR:21.87	Hits@10:39.13	Best:21.87
2024-12-27 16:16:25,755: Snapshot:2	Epoch:6	Loss:3.266	translation_Loss:2.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.337                                                   	MRR:21.84	Hits@10:38.94	Best:21.87
2024-12-27 16:16:33,076: Snapshot:2	Epoch:7	Loss:3.175	translation_Loss:2.805	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.371                                                   	MRR:22.02	Hits@10:39.14	Best:22.02
2024-12-27 16:16:40,378: Snapshot:2	Epoch:8	Loss:3.141	translation_Loss:2.731	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.41                                                   	MRR:22.21	Hits@10:39.24	Best:22.21
2024-12-27 16:16:47,649: Snapshot:2	Epoch:9	Loss:3.119	translation_Loss:2.665	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.454                                                   	MRR:22.27	Hits@10:39.54	Best:22.27
2024-12-27 16:16:54,921: Snapshot:2	Epoch:10	Loss:3.079	translation_Loss:2.591	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.487                                                   	MRR:22.27	Hits@10:39.57	Best:22.27
2024-12-27 16:17:02,388: Snapshot:2	Epoch:11	Loss:3.091	translation_Loss:2.554	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.537                                                   	MRR:22.37	Hits@10:39.65	Best:22.37
2024-12-27 16:17:09,651: Snapshot:2	Epoch:12	Loss:3.088	translation_Loss:2.508	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.58                                                   	MRR:22.3	Hits@10:39.49	Best:22.37
2024-12-27 16:17:16,887: Snapshot:2	Epoch:13	Loss:3.087	translation_Loss:2.46	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.627                                                   	MRR:22.32	Hits@10:39.64	Best:22.37
2024-12-27 16:17:24,520: Snapshot:2	Epoch:14	Loss:3.114	translation_Loss:2.428	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.686                                                   	MRR:22.21	Hits@10:39.41	Best:22.37
2024-12-27 16:17:31,719: Snapshot:2	Epoch:15	Loss:3.153	translation_Loss:2.413	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.74                                                   	MRR:22.22	Hits@10:39.66	Best:22.37
2024-12-27 16:17:38,959: Early Stopping! Snapshot: 2 Epoch: 16 Best Results: 22.37
2024-12-27 16:17:38,959: Start to training tokens! Snapshot: 2 Epoch: 16 Loss:3.171 MRR:22.33 Best Results: 22.37
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 16:17:38,960: Snapshot:2	Epoch:16	Loss:3.171	translation_Loss:2.353	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.818                                                   	MRR:22.33	Hits@10:39.59	Best:22.37
2024-12-27 16:17:46,210: Snapshot:2	Epoch:17	Loss:47.013	translation_Loss:46.976	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.33	Hits@10:39.59	Best:22.37
2024-12-27 16:17:53,495: End of token training: 2 Epoch: 18 Loss:46.994 MRR:22.33 Best Results: 22.37
2024-12-27 16:17:53,496: Snapshot:2	Epoch:18	Loss:46.994	translation_Loss:46.994	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.33	Hits@10:39.59	Best:22.37
2024-12-27 16:17:53,715: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_6/2model_best.tar'
2024-12-27 16:18:00,301: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3257 | 0.2086 | 0.3756 | 0.452  |  0.5522 |
|     1      | 0.2361 | 0.142  | 0.265  | 0.3302 |  0.4211 |
|     2      | 0.2264 | 0.1361 | 0.2584 | 0.3165 |  0.3989 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:18:25,228: Snapshot:3	Epoch:0	Loss:121.745	translation_Loss:15.441	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:106.304                                                   	MRR:18.77	Hits@10:34.12	Best:18.77
2024-12-27 16:18:32,628: Snapshot:3	Epoch:1	Loss:4.67	translation_Loss:4.444	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.226                                                   	MRR:20.04	Hits@10:36.21	Best:20.04
2024-12-27 16:18:39,989: Snapshot:3	Epoch:2	Loss:3.593	translation_Loss:3.362	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.231                                                   	MRR:20.31	Hits@10:36.87	Best:20.31
2024-12-27 16:18:47,477: Snapshot:3	Epoch:3	Loss:3.233	translation_Loss:2.965	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.268                                                   	MRR:20.65	Hits@10:37.06	Best:20.65
2024-12-27 16:18:55,145: Snapshot:3	Epoch:4	Loss:3.057	translation_Loss:2.756	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.301                                                   	MRR:20.66	Hits@10:37.52	Best:20.66
2024-12-27 16:19:02,510: Snapshot:3	Epoch:5	Loss:2.923	translation_Loss:2.588	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.335                                                   	MRR:20.77	Hits@10:37.66	Best:20.77
2024-12-27 16:19:09,895: Snapshot:3	Epoch:6	Loss:2.876	translation_Loss:2.505	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.371                                                   	MRR:20.79	Hits@10:37.71	Best:20.79
2024-12-27 16:19:17,255: Snapshot:3	Epoch:7	Loss:2.772	translation_Loss:2.367	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.405                                                   	MRR:20.99	Hits@10:37.96	Best:20.99
2024-12-27 16:19:24,635: Snapshot:3	Epoch:8	Loss:2.743	translation_Loss:2.308	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.435                                                   	MRR:21.11	Hits@10:38.19	Best:21.11
2024-12-27 16:19:32,100: Snapshot:3	Epoch:9	Loss:2.738	translation_Loss:2.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.477                                                   	MRR:21.15	Hits@10:37.93	Best:21.15
2024-12-27 16:19:39,477: Snapshot:3	Epoch:10	Loss:2.689	translation_Loss:2.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.508                                                   	MRR:21.31	Hits@10:38.35	Best:21.31
2024-12-27 16:19:46,890: Snapshot:3	Epoch:11	Loss:2.681	translation_Loss:2.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.543                                                   	MRR:21.35	Hits@10:38.39	Best:21.35
2024-12-27 16:19:54,242: Snapshot:3	Epoch:12	Loss:2.681	translation_Loss:2.09	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.59                                                   	MRR:21.36	Hits@10:38.29	Best:21.36
2024-12-27 16:20:01,574: Snapshot:3	Epoch:13	Loss:2.683	translation_Loss:2.058	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.625                                                   	MRR:21.23	Hits@10:38.4	Best:21.36
2024-12-27 16:20:09,613: Snapshot:3	Epoch:14	Loss:2.718	translation_Loss:2.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.681                                                   	MRR:21.25	Hits@10:38.47	Best:21.36
2024-12-27 16:20:16,958: Snapshot:3	Epoch:15	Loss:2.725	translation_Loss:2.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.715                                                   	MRR:21.44	Hits@10:38.63	Best:21.44
2024-12-27 16:20:24,320: Snapshot:3	Epoch:16	Loss:2.75	translation_Loss:1.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.771                                                   	MRR:21.52	Hits@10:38.67	Best:21.52
2024-12-27 16:20:31,599: Snapshot:3	Epoch:17	Loss:2.803	translation_Loss:1.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.84                                                   	MRR:21.38	Hits@10:38.35	Best:21.52
2024-12-27 16:20:38,918: Snapshot:3	Epoch:18	Loss:2.887	translation_Loss:1.949	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.938                                                   	MRR:21.49	Hits@10:38.53	Best:21.52
2024-12-27 16:20:46,316: Snapshot:3	Epoch:19	Loss:3.379	translation_Loss:1.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.458                                                   	MRR:21.43	Hits@10:38.75	Best:21.52
2024-12-27 16:20:53,619: Snapshot:3	Epoch:20	Loss:3.344	translation_Loss:1.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.431                                                   	MRR:21.35	Hits@10:38.59	Best:21.52
2024-12-27 16:21:00,992: Early Stopping! Snapshot: 3 Epoch: 21 Best Results: 21.52
2024-12-27 16:21:00,993: Start to training tokens! Snapshot: 3 Epoch: 21 Loss:3.416 MRR:21.51 Best Results: 21.52
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 16:21:00,993: Snapshot:3	Epoch:21	Loss:3.416	translation_Loss:1.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.523                                                   	MRR:21.51	Hits@10:38.6	Best:21.52
2024-12-27 16:21:08,305: Snapshot:3	Epoch:22	Loss:42.364	translation_Loss:42.328	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.51	Hits@10:38.6	Best:21.52
2024-12-27 16:21:15,607: End of token training: 3 Epoch: 23 Loss:42.293 MRR:21.51 Best Results: 21.52
2024-12-27 16:21:15,608: Snapshot:3	Epoch:23	Loss:42.293	translation_Loss:42.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.51	Hits@10:38.6	Best:21.52
2024-12-27 16:21:15,877: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_6/3model_best.tar'
2024-12-27 16:21:25,334: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3262 | 0.2094 | 0.3761 | 0.452  |  0.5518 |
|     1      | 0.2362 | 0.1423 | 0.2648 | 0.3302 |  0.4209 |
|     2      | 0.2264 | 0.136  | 0.2584 | 0.3165 |  0.3989 |
|     3      | 0.2146 | 0.1263 | 0.2449 | 0.3027 |  0.3862 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:21:44,551: Snapshot:4	Epoch:0	Loss:113.088	translation_Loss:10.987	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:102.101                                                   	MRR:22.91	Hits@10:41.02	Best:22.91
2024-12-27 16:21:49,819: Snapshot:4	Epoch:1	Loss:2.861	translation_Loss:2.41	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.451                                                   	MRR:24.58	Hits@10:43.83	Best:24.58
2024-12-27 16:21:55,104: Snapshot:4	Epoch:2	Loss:1.662	translation_Loss:1.544	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.118                                                   	MRR:24.97	Hits@10:44.24	Best:24.97
2024-12-27 16:22:00,351: Snapshot:4	Epoch:3	Loss:1.458	translation_Loss:1.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:24.87	Hits@10:44.07	Best:24.97
2024-12-27 16:22:05,694: Snapshot:4	Epoch:4	Loss:1.335	translation_Loss:1.197	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.137                                                   	MRR:25.1	Hits@10:44.53	Best:25.1
2024-12-27 16:22:11,007: Snapshot:4	Epoch:5	Loss:1.26	translation_Loss:1.112	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:25.23	Hits@10:44.73	Best:25.23
2024-12-27 16:22:16,238: Snapshot:4	Epoch:6	Loss:1.221	translation_Loss:1.06	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:25.15	Hits@10:44.82	Best:25.23
2024-12-27 16:22:21,520: Snapshot:4	Epoch:7	Loss:1.212	translation_Loss:1.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:25.33	Hits@10:45.35	Best:25.33
2024-12-27 16:22:26,813: Snapshot:4	Epoch:8	Loss:1.157	translation_Loss:0.976	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.181                                                   	MRR:25.21	Hits@10:44.81	Best:25.33
2024-12-27 16:22:32,111: Snapshot:4	Epoch:9	Loss:1.131	translation_Loss:0.941	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.189                                                   	MRR:25.46	Hits@10:44.99	Best:25.46
2024-12-27 16:22:37,432: Snapshot:4	Epoch:10	Loss:1.123	translation_Loss:0.922	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:25.39	Hits@10:45.21	Best:25.46
2024-12-27 16:22:42,709: Snapshot:4	Epoch:11	Loss:1.107	translation_Loss:0.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:25.51	Hits@10:45.31	Best:25.51
2024-12-27 16:22:48,072: Snapshot:4	Epoch:12	Loss:1.107	translation_Loss:0.881	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.226                                                   	MRR:25.56	Hits@10:45.51	Best:25.56
2024-12-27 16:22:53,347: Snapshot:4	Epoch:13	Loss:1.11	translation_Loss:0.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.236                                                   	MRR:25.63	Hits@10:45.4	Best:25.63
2024-12-27 16:22:58,665: Snapshot:4	Epoch:14	Loss:1.098	translation_Loss:0.854	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.244                                                   	MRR:25.79	Hits@10:45.52	Best:25.79
2024-12-27 16:23:03,926: Snapshot:4	Epoch:15	Loss:1.079	translation_Loss:0.828	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.251                                                   	MRR:25.56	Hits@10:45.27	Best:25.79
2024-12-27 16:23:09,213: Snapshot:4	Epoch:16	Loss:1.066	translation_Loss:0.805	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.261                                                   	MRR:25.57	Hits@10:45.39	Best:25.79
2024-12-27 16:23:14,428: Snapshot:4	Epoch:17	Loss:1.08	translation_Loss:0.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.272                                                   	MRR:25.5	Hits@10:45.82	Best:25.79
2024-12-27 16:23:19,729: Snapshot:4	Epoch:18	Loss:1.1	translation_Loss:0.807	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.293                                                   	MRR:25.79	Hits@10:45.97	Best:25.79
2024-12-27 16:23:24,985: Early Stopping! Snapshot: 4 Epoch: 19 Best Results: 25.79
2024-12-27 16:23:24,986: Start to training tokens! Snapshot: 4 Epoch: 19 Loss:1.084 MRR:25.43 Best Results: 25.79
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 16:23:24,986: Snapshot:4	Epoch:19	Loss:1.084	translation_Loss:0.79	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.294                                                   	MRR:25.43	Hits@10:45.83	Best:25.79
2024-12-27 16:23:30,762: Snapshot:4	Epoch:20	Loss:23.289	translation_Loss:23.253	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.43	Hits@10:45.83	Best:25.79
2024-12-27 16:23:36,045: End of token training: 4 Epoch: 21 Loss:23.272 MRR:25.43 Best Results: 25.79
2024-12-27 16:23:36,045: Snapshot:4	Epoch:21	Loss:23.272	translation_Loss:23.272	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.43	Hits@10:45.83	Best:25.79
2024-12-27 16:23:36,293: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_6/4model_best.tar'
2024-12-27 16:23:48,213: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3261 | 0.2092 | 0.3764 | 0.4517 |  0.5524 |
|     1      | 0.2364 | 0.1424 | 0.2651 |  0.33  |  0.421  |
|     2      | 0.2264 | 0.1361 | 0.2585 | 0.3164 |  0.3991 |
|     3      | 0.2148 | 0.1265 | 0.2454 | 0.3028 |  0.3864 |
|     4      | 0.2559 | 0.1495 | 0.3032 | 0.3753 |  0.461  |
+------------+--------+--------+--------+--------+---------+
2024-12-27 16:23:48,216: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3259 | 0.2088 | 0.3762 | 0.4522 |  0.552  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3258 | 0.2087 | 0.3757 | 0.4522 |  0.5521 |
|     1      | 0.2362 | 0.142  | 0.265  | 0.3303 |  0.4212 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3257 | 0.2086 | 0.3756 | 0.452  |  0.5522 |
|     1      | 0.2361 | 0.142  | 0.265  | 0.3302 |  0.4211 |
|     2      | 0.2264 | 0.1361 | 0.2584 | 0.3165 |  0.3989 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3262 | 0.2094 | 0.3761 | 0.452  |  0.5518 |
|     1      | 0.2362 | 0.1423 | 0.2648 | 0.3302 |  0.4209 |
|     2      | 0.2264 | 0.136  | 0.2584 | 0.3165 |  0.3989 |
|     3      | 0.2146 | 0.1263 | 0.2449 | 0.3027 |  0.3862 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3261 | 0.2092 | 0.3764 | 0.4517 |  0.5524 |
|     1      | 0.2364 | 0.1424 | 0.2651 |  0.33  |  0.421  |
|     2      | 0.2264 | 0.1361 | 0.2585 | 0.3164 |  0.3991 |
|     3      | 0.2148 | 0.1265 | 0.2454 | 0.3028 |  0.3864 |
|     4      | 0.2559 | 0.1495 | 0.3032 | 0.3753 |  0.461  |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 16:23:48,216: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 46.510772705078125 |   0.326   |    0.209     |    0.376     |     0.552     |
|    1     | 109.41566705703735 |   0.271   |    0.168     |    0.308     |     0.472     |
|    2     | 154.16031575202942 |   0.254   |    0.156     |    0.289     |     0.444     |
|    3     | 192.3084101676941  |   0.244   |    0.148     |    0.277     |     0.429     |
|    4     | 128.02281403541565 |   0.246   |    0.148     |    0.282     |     0.434     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 16:23:48,216: Sum_Training_Time:630.4179797172546
2024-12-27 16:23:48,216: Every_Training_Time:[46.510772705078125, 109.41566705703735, 154.16031575202942, 192.3084101676941, 128.02281403541565]
2024-12-27 16:23:48,216: Forward transfer: 0.042874999999999996 Backward transfer: 0.00014999999999999042
2024-12-27 16:24:21,890: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227162352/ENTITYentity_0.01_1024_8', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_1024_8', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_1024_8', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=8, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 16:24:29,557: Snapshot:0	Epoch:0	Loss:28.545	translation_Loss:28.545	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.42	Hits@10:47.18	Best:24.42
2024-12-27 16:24:33,406: Snapshot:0	Epoch:1	Loss:9.984	translation_Loss:9.984	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.18	Hits@10:54.12	Best:31.18
2024-12-27 16:24:37,267: Snapshot:0	Epoch:2	Loss:3.792	translation_Loss:3.792	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.76	Hits@10:54.91	Best:31.76
2024-12-27 16:24:41,169: Snapshot:0	Epoch:3	Loss:2.04	translation_Loss:2.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.77	Hits@10:54.6	Best:31.77
2024-12-27 16:24:45,146: Snapshot:0	Epoch:4	Loss:1.393	translation_Loss:1.393	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.86	Hits@10:54.4	Best:31.86
2024-12-27 16:24:48,968: Snapshot:0	Epoch:5	Loss:1.102	translation_Loss:1.102	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.68	Hits@10:53.81	Best:31.86
2024-12-27 16:24:52,868: Snapshot:0	Epoch:6	Loss:0.952	translation_Loss:0.952	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.81	Hits@10:54.24	Best:31.86
2024-12-27 16:24:56,760: Snapshot:0	Epoch:7	Loss:0.84	translation_Loss:0.84	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.77	Hits@10:53.34	Best:31.86
2024-12-27 16:25:00,605: Snapshot:0	Epoch:8	Loss:0.755	translation_Loss:0.755	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.57	Hits@10:53.38	Best:31.86
2024-12-27 16:25:04,570: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 31.86
2024-12-27 16:25:04,570: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.694 MRR:31.44 Best Results: 31.86
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 16:25:04,570: Snapshot:0	Epoch:9	Loss:0.694	translation_Loss:0.694	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.44	Hits@10:53.2	Best:31.86
2024-12-27 16:25:09,051: Snapshot:0	Epoch:10	Loss:28.089	translation_Loss:28.052	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.44	Hits@10:53.2	Best:31.86
2024-12-27 16:25:13,514: End of token training: 0 Epoch: 11 Loss:28.06 MRR:31.44 Best Results: 31.86
2024-12-27 16:25:13,514: Snapshot:0	Epoch:11	Loss:28.06	translation_Loss:28.06	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.44	Hits@10:53.2	Best:31.86
2024-12-27 16:25:13,750: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_8/0model_best.tar'
2024-12-27 16:25:15,061: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3213 | 0.204  | 0.3711 | 0.4453 |  0.5516 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:25:39,076: Snapshot:1	Epoch:0	Loss:168.85	translation_Loss:17.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:151.732                                                   	MRR:21.58	Hits@10:38.54	Best:21.58
2024-12-27 16:25:45,868: Snapshot:1	Epoch:1	Loss:4.802	translation_Loss:4.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.084                                                   	MRR:22.74	Hits@10:40.74	Best:22.74
2024-12-27 16:25:52,573: Snapshot:1	Epoch:2	Loss:3.483	translation_Loss:3.417	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.066                                                   	MRR:23.15	Hits@10:41.13	Best:23.15
2024-12-27 16:25:59,401: Snapshot:1	Epoch:3	Loss:3.045	translation_Loss:2.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.077                                                   	MRR:23.4	Hits@10:41.53	Best:23.4
2024-12-27 16:26:06,187: Snapshot:1	Epoch:4	Loss:2.809	translation_Loss:2.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:23.45	Hits@10:41.61	Best:23.45
2024-12-27 16:26:12,984: Snapshot:1	Epoch:5	Loss:2.635	translation_Loss:2.533	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:23.69	Hits@10:41.95	Best:23.69
2024-12-27 16:26:19,723: Snapshot:1	Epoch:6	Loss:2.529	translation_Loss:2.413	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.116                                                   	MRR:23.75	Hits@10:42.14	Best:23.75
2024-12-27 16:26:26,677: Snapshot:1	Epoch:7	Loss:2.464	translation_Loss:2.336	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.128                                                   	MRR:23.82	Hits@10:42.3	Best:23.82
2024-12-27 16:26:33,397: Snapshot:1	Epoch:8	Loss:2.382	translation_Loss:2.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.144                                                   	MRR:23.83	Hits@10:42.53	Best:23.83
2024-12-27 16:26:40,118: Snapshot:1	Epoch:9	Loss:2.327	translation_Loss:2.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:23.81	Hits@10:42.19	Best:23.83
2024-12-27 16:26:46,853: Snapshot:1	Epoch:10	Loss:2.286	translation_Loss:2.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.179                                                   	MRR:23.97	Hits@10:42.43	Best:23.97
2024-12-27 16:26:53,977: Snapshot:1	Epoch:11	Loss:2.245	translation_Loss:2.046	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:23.83	Hits@10:42.24	Best:23.97
2024-12-27 16:27:00,717: Snapshot:1	Epoch:12	Loss:2.235	translation_Loss:2.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.223                                                   	MRR:23.75	Hits@10:42.17	Best:23.97
2024-12-27 16:27:07,468: Snapshot:1	Epoch:13	Loss:2.229	translation_Loss:1.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.25                                                   	MRR:23.9	Hits@10:42.37	Best:23.97
2024-12-27 16:27:14,142: Snapshot:1	Epoch:14	Loss:2.23	translation_Loss:1.948	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.282                                                   	MRR:23.73	Hits@10:42.09	Best:23.97
2024-12-27 16:27:20,832: Early Stopping! Snapshot: 1 Epoch: 15 Best Results: 23.97
2024-12-27 16:27:20,832: Start to training tokens! Snapshot: 1 Epoch: 15 Loss:2.23 MRR:23.87 Best Results: 23.97
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 16:27:20,833: Snapshot:1	Epoch:15	Loss:2.23	translation_Loss:1.912	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.318                                                   	MRR:23.87	Hits@10:42.34	Best:23.97
2024-12-27 16:27:27,531: Snapshot:1	Epoch:16	Loss:46.175	translation_Loss:46.137	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.87	Hits@10:42.34	Best:23.97
2024-12-27 16:27:34,244: End of token training: 1 Epoch: 17 Loss:46.144 MRR:23.87 Best Results: 23.97
2024-12-27 16:27:34,244: Snapshot:1	Epoch:17	Loss:46.144	translation_Loss:46.144	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.87	Hits@10:42.34	Best:23.97
2024-12-27 16:27:34,486: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_8/1model_best.tar'
2024-12-27 16:27:38,310: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3212 | 0.2038 | 0.3715 | 0.4454 |  0.5514 |
|     1      | 0.239  | 0.1452 | 0.2683 | 0.3318 |  0.4238 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:28:03,515: Snapshot:2	Epoch:0	Loss:159.808	translation_Loss:16.482	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:143.326                                                   	MRR:19.3	Hits@10:34.85	Best:19.3
2024-12-27 16:28:11,250: Snapshot:2	Epoch:1	Loss:4.849	translation_Loss:4.722	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:20.85	Hits@10:36.9	Best:20.85
2024-12-27 16:28:18,570: Snapshot:2	Epoch:2	Loss:3.7	translation_Loss:3.576	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.124                                                   	MRR:21.19	Hits@10:37.75	Best:21.19
2024-12-27 16:28:26,005: Snapshot:2	Epoch:3	Loss:3.302	translation_Loss:3.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.145                                                   	MRR:21.55	Hits@10:38.35	Best:21.55
2024-12-27 16:28:33,351: Snapshot:2	Epoch:4	Loss:3.068	translation_Loss:2.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:21.92	Hits@10:38.58	Best:21.92
2024-12-27 16:28:40,727: Snapshot:2	Epoch:5	Loss:2.944	translation_Loss:2.755	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.189                                                   	MRR:21.87	Hits@10:38.8	Best:21.92
2024-12-27 16:28:48,149: Snapshot:2	Epoch:6	Loss:2.824	translation_Loss:2.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:21.92	Hits@10:38.7	Best:21.92
2024-12-27 16:28:55,441: Snapshot:2	Epoch:7	Loss:2.754	translation_Loss:2.517	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.237                                                   	MRR:21.92	Hits@10:38.82	Best:21.92
2024-12-27 16:29:02,856: Snapshot:2	Epoch:8	Loss:2.705	translation_Loss:2.439	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.266                                                   	MRR:21.97	Hits@10:39.16	Best:21.97
2024-12-27 16:29:10,437: Snapshot:2	Epoch:9	Loss:2.662	translation_Loss:2.37	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.292                                                   	MRR:21.98	Hits@10:39.25	Best:21.98
2024-12-27 16:29:18,141: Snapshot:2	Epoch:10	Loss:2.627	translation_Loss:2.304	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.323                                                   	MRR:22.19	Hits@10:39.17	Best:22.19
2024-12-27 16:29:25,465: Snapshot:2	Epoch:11	Loss:2.622	translation_Loss:2.262	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.36                                                   	MRR:22.31	Hits@10:39.48	Best:22.31
2024-12-27 16:29:32,852: Snapshot:2	Epoch:12	Loss:2.597	translation_Loss:2.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.399                                                   	MRR:22.13	Hits@10:39.42	Best:22.31
2024-12-27 16:29:40,253: Snapshot:2	Epoch:13	Loss:2.629	translation_Loss:2.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.444                                                   	MRR:22.26	Hits@10:39.29	Best:22.31
2024-12-27 16:29:47,678: Snapshot:2	Epoch:14	Loss:2.622	translation_Loss:2.13	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.493                                                   	MRR:22.34	Hits@10:39.37	Best:22.34
2024-12-27 16:29:54,931: Snapshot:2	Epoch:15	Loss:2.681	translation_Loss:2.13	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.551                                                   	MRR:22.3	Hits@10:39.34	Best:22.34
2024-12-27 16:30:02,339: Snapshot:2	Epoch:16	Loss:2.726	translation_Loss:2.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.627                                                   	MRR:22.35	Hits@10:39.6	Best:22.35
2024-12-27 16:30:10,058: Snapshot:2	Epoch:17	Loss:2.827	translation_Loss:2.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.738                                                   	MRR:22.32	Hits@10:39.4	Best:22.35
2024-12-27 16:30:17,382: Snapshot:2	Epoch:18	Loss:3.602	translation_Loss:2.028	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.573                                                   	MRR:22.38	Hits@10:39.52	Best:22.38
2024-12-27 16:30:24,823: Snapshot:2	Epoch:19	Loss:3.532	translation_Loss:2.048	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.484                                                   	MRR:22.43	Hits@10:39.73	Best:22.43
2024-12-27 16:30:32,524: Snapshot:2	Epoch:20	Loss:3.629	translation_Loss:2.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.619                                                   	MRR:22.39	Hits@10:39.76	Best:22.43
2024-12-27 16:30:39,820: Snapshot:2	Epoch:21	Loss:3.753	translation_Loss:1.98	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.772                                                   	MRR:22.36	Hits@10:39.73	Best:22.43
2024-12-27 16:30:47,120: Snapshot:2	Epoch:22	Loss:4.05	translation_Loss:1.98	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.07                                                   	MRR:22.28	Hits@10:39.39	Best:22.43
2024-12-27 16:30:54,425: Snapshot:2	Epoch:23	Loss:4.767	translation_Loss:1.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.793                                                   	MRR:22.23	Hits@10:39.49	Best:22.43
2024-12-27 16:31:01,772: Early Stopping! Snapshot: 2 Epoch: 24 Best Results: 22.43
2024-12-27 16:31:01,772: Start to training tokens! Snapshot: 2 Epoch: 24 Loss:4.689 MRR:22.43 Best Results: 22.43
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 16:31:01,772: Snapshot:2	Epoch:24	Loss:4.689	translation_Loss:1.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.716                                                   	MRR:22.43	Hits@10:39.56	Best:22.43
2024-12-27 16:31:09,081: Snapshot:2	Epoch:25	Loss:47.148	translation_Loss:47.112	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.43	Hits@10:39.56	Best:22.43
2024-12-27 16:31:16,387: End of token training: 2 Epoch: 26 Loss:47.072 MRR:22.43 Best Results: 22.43
2024-12-27 16:31:16,388: Snapshot:2	Epoch:26	Loss:47.072	translation_Loss:47.072	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.43	Hits@10:39.56	Best:22.43
2024-12-27 16:31:16,654: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_8/2model_best.tar'
2024-12-27 16:31:23,421: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3214 | 0.204  | 0.3715 | 0.4455 |  0.551  |
|     1      | 0.2391 | 0.1453 | 0.2685 | 0.3318 |  0.4238 |
|     2      | 0.2255 | 0.135  | 0.2564 | 0.3163 |  0.3993 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:31:49,126: Snapshot:3	Epoch:0	Loss:156.518	translation_Loss:14.945	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:141.573                                                   	MRR:18.66	Hits@10:33.92	Best:18.66
2024-12-27 16:31:56,529: Snapshot:3	Epoch:1	Loss:4.196	translation_Loss:4.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:20.08	Hits@10:36.27	Best:20.08
2024-12-27 16:32:04,043: Snapshot:3	Epoch:2	Loss:3.182	translation_Loss:3.042	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.14                                                   	MRR:20.32	Hits@10:36.9	Best:20.32
2024-12-27 16:32:11,532: Snapshot:3	Epoch:3	Loss:2.835	translation_Loss:2.673	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.162                                                   	MRR:20.56	Hits@10:36.93	Best:20.56
2024-12-27 16:32:18,947: Snapshot:3	Epoch:4	Loss:2.644	translation_Loss:2.458	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.186                                                   	MRR:20.68	Hits@10:37.19	Best:20.68
2024-12-27 16:32:26,385: Snapshot:3	Epoch:5	Loss:2.552	translation_Loss:2.341	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.211                                                   	MRR:20.74	Hits@10:37.68	Best:20.74
2024-12-27 16:32:33,845: Snapshot:3	Epoch:6	Loss:2.447	translation_Loss:2.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.233                                                   	MRR:20.66	Hits@10:37.45	Best:20.74
2024-12-27 16:32:41,339: Snapshot:3	Epoch:7	Loss:2.397	translation_Loss:2.144	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.253                                                   	MRR:20.8	Hits@10:37.95	Best:20.8
2024-12-27 16:32:48,720: Snapshot:3	Epoch:8	Loss:2.353	translation_Loss:2.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.283                                                   	MRR:20.76	Hits@10:37.79	Best:20.8
2024-12-27 16:32:56,217: Snapshot:3	Epoch:9	Loss:2.302	translation_Loss:1.996	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.306                                                   	MRR:20.92	Hits@10:38.15	Best:20.92
2024-12-27 16:33:03,651: Snapshot:3	Epoch:10	Loss:2.259	translation_Loss:1.923	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.335                                                   	MRR:21.05	Hits@10:38.19	Best:21.05
2024-12-27 16:33:11,068: Snapshot:3	Epoch:11	Loss:2.286	translation_Loss:1.919	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.367                                                   	MRR:21.22	Hits@10:38.44	Best:21.22
2024-12-27 16:33:18,436: Snapshot:3	Epoch:12	Loss:2.29	translation_Loss:1.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.402                                                   	MRR:21.06	Hits@10:38.28	Best:21.22
2024-12-27 16:33:25,775: Snapshot:3	Epoch:13	Loss:2.286	translation_Loss:1.852	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.435                                                   	MRR:20.97	Hits@10:38.05	Best:21.22
2024-12-27 16:33:33,157: Snapshot:3	Epoch:14	Loss:2.302	translation_Loss:1.82	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.482                                                   	MRR:21.18	Hits@10:38.57	Best:21.22
2024-12-27 16:33:40,559: Snapshot:3	Epoch:15	Loss:2.323	translation_Loss:1.8	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.523                                                   	MRR:21.3	Hits@10:38.63	Best:21.3
2024-12-27 16:33:47,883: Snapshot:3	Epoch:16	Loss:2.359	translation_Loss:1.783	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.575                                                   	MRR:21.02	Hits@10:38.3	Best:21.3
2024-12-27 16:33:55,243: Snapshot:3	Epoch:17	Loss:2.386	translation_Loss:1.748	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.638                                                   	MRR:21.27	Hits@10:38.64	Best:21.3
2024-12-27 16:34:02,706: Snapshot:3	Epoch:18	Loss:2.53	translation_Loss:1.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.771                                                   	MRR:21.31	Hits@10:38.62	Best:21.31
2024-12-27 16:34:10,098: Snapshot:3	Epoch:19	Loss:3.352	translation_Loss:1.714	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.638                                                   	MRR:21.27	Hits@10:38.52	Best:21.31
2024-12-27 16:34:17,410: Snapshot:3	Epoch:20	Loss:3.154	translation_Loss:1.709	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.445                                                   	MRR:21.11	Hits@10:38.55	Best:21.31
2024-12-27 16:34:24,756: Snapshot:3	Epoch:21	Loss:3.295	translation_Loss:1.695	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.6                                                   	MRR:21.24	Hits@10:38.68	Best:21.31
2024-12-27 16:34:32,130: Snapshot:3	Epoch:22	Loss:3.401	translation_Loss:1.692	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.709                                                   	MRR:21.33	Hits@10:38.6	Best:21.33
2024-12-27 16:34:39,598: Snapshot:3	Epoch:23	Loss:3.617	translation_Loss:1.673	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.944                                                   	MRR:21.34	Hits@10:38.64	Best:21.34
2024-12-27 16:34:47,011: Snapshot:3	Epoch:24	Loss:4.377	translation_Loss:1.653	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.725                                                   	MRR:21.37	Hits@10:38.85	Best:21.37
2024-12-27 16:34:54,384: Snapshot:3	Epoch:25	Loss:4.274	translation_Loss:1.668	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.606                                                   	MRR:21.3	Hits@10:38.74	Best:21.37
2024-12-27 16:35:01,879: Snapshot:3	Epoch:26	Loss:4.316	translation_Loss:1.62	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.696                                                   	MRR:21.34	Hits@10:39.0	Best:21.37
2024-12-27 16:35:09,426: Snapshot:3	Epoch:27	Loss:4.343	translation_Loss:1.628	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.715                                                   	MRR:21.45	Hits@10:38.93	Best:21.45
2024-12-27 16:35:16,838: Snapshot:3	Epoch:28	Loss:4.317	translation_Loss:1.599	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.718                                                   	MRR:21.48	Hits@10:39.14	Best:21.48
2024-12-27 16:35:24,214: Snapshot:3	Epoch:29	Loss:4.292	translation_Loss:1.591	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.7                                                   	MRR:21.35	Hits@10:38.87	Best:21.48
2024-12-27 16:35:31,555: Snapshot:3	Epoch:30	Loss:4.292	translation_Loss:1.582	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.71                                                   	MRR:21.37	Hits@10:38.79	Best:21.48
2024-12-27 16:35:39,463: Snapshot:3	Epoch:31	Loss:4.302	translation_Loss:1.578	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.725                                                   	MRR:21.36	Hits@10:38.79	Best:21.48
2024-12-27 16:35:46,814: Snapshot:3	Epoch:32	Loss:4.34	translation_Loss:1.6	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.74                                                   	MRR:21.47	Hits@10:38.88	Best:21.48
2024-12-27 16:35:54,162: Early Stopping! Snapshot: 3 Epoch: 33 Best Results: 21.48
2024-12-27 16:35:54,162: Start to training tokens! Snapshot: 3 Epoch: 33 Loss:4.293 MRR:21.43 Best Results: 21.48
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 16:35:54,162: Snapshot:3	Epoch:33	Loss:4.293	translation_Loss:1.573	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.72                                                   	MRR:21.43	Hits@10:38.75	Best:21.48
2024-12-27 16:36:01,523: Snapshot:3	Epoch:34	Loss:42.407	translation_Loss:42.37	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.43	Hits@10:38.75	Best:21.48
2024-12-27 16:36:08,900: End of token training: 3 Epoch: 35 Loss:42.347 MRR:21.43 Best Results: 21.48
2024-12-27 16:36:08,901: Snapshot:3	Epoch:35	Loss:42.347	translation_Loss:42.347	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.43	Hits@10:38.75	Best:21.48
2024-12-27 16:36:09,170: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_8/3model_best.tar'
2024-12-27 16:36:18,838: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3211 | 0.2036 | 0.3719 | 0.4454 |  0.5507 |
|     1      | 0.2389 | 0.1451 | 0.268  | 0.3321 |  0.4243 |
|     2      | 0.2255 | 0.1349 | 0.2566 | 0.3163 |  0.3992 |
|     3      | 0.215  | 0.126  | 0.2452 | 0.3038 |   0.39  |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:36:38,224: Snapshot:4	Epoch:0	Loss:146.852	translation_Loss:10.764	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:136.088                                                   	MRR:22.78	Hits@10:40.75	Best:22.78
2024-12-27 16:36:43,541: Snapshot:4	Epoch:1	Loss:2.778	translation_Loss:2.262	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.516                                                   	MRR:24.5	Hits@10:43.83	Best:24.5
2024-12-27 16:36:48,942: Snapshot:4	Epoch:2	Loss:1.498	translation_Loss:1.425	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.074                                                   	MRR:24.75	Hits@10:44.73	Best:24.75
2024-12-27 16:36:54,236: Snapshot:4	Epoch:3	Loss:1.261	translation_Loss:1.185	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.076                                                   	MRR:24.71	Hits@10:44.54	Best:24.75
2024-12-27 16:36:59,627: Snapshot:4	Epoch:4	Loss:1.165	translation_Loss:1.079	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:24.86	Hits@10:45.08	Best:24.86
2024-12-27 16:37:05,043: Snapshot:4	Epoch:5	Loss:1.104	translation_Loss:1.013	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:24.97	Hits@10:44.87	Best:24.97
2024-12-27 16:37:10,355: Snapshot:4	Epoch:6	Loss:1.052	translation_Loss:0.952	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:24.66	Hits@10:45.0	Best:24.97
2024-12-27 16:37:15,601: Snapshot:4	Epoch:7	Loss:1.022	translation_Loss:0.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:24.87	Hits@10:44.9	Best:24.97
2024-12-27 16:37:20,841: Snapshot:4	Epoch:8	Loss:1.007	translation_Loss:0.892	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:24.58	Hits@10:44.94	Best:24.97
2024-12-27 16:37:26,089: Snapshot:4	Epoch:9	Loss:0.973	translation_Loss:0.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.12                                                   	MRR:24.75	Hits@10:45.02	Best:24.97
2024-12-27 16:37:31,340: Early Stopping! Snapshot: 4 Epoch: 10 Best Results: 24.97
2024-12-27 16:37:31,341: Start to training tokens! Snapshot: 4 Epoch: 10 Loss:0.952 MRR:24.86 Best Results: 24.97
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 16:37:31,341: Snapshot:4	Epoch:10	Loss:0.952	translation_Loss:0.822	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.13                                                   	MRR:24.86	Hits@10:45.13	Best:24.97
2024-12-27 16:37:36,687: Snapshot:4	Epoch:11	Loss:23.274	translation_Loss:23.237	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.86	Hits@10:45.13	Best:24.97
2024-12-27 16:37:41,979: End of token training: 4 Epoch: 12 Loss:23.236 MRR:24.86 Best Results: 24.97
2024-12-27 16:37:41,979: Snapshot:4	Epoch:12	Loss:23.236	translation_Loss:23.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.86	Hits@10:45.13	Best:24.97
2024-12-27 16:37:42,257: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_8/4model_best.tar'
2024-12-27 16:37:54,289: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3214 | 0.2043 | 0.372  | 0.4451 |  0.5505 |
|     1      | 0.239  | 0.1453 | 0.2681 | 0.3323 |  0.4239 |
|     2      | 0.2255 | 0.1349 | 0.2568 | 0.3166 |  0.3992 |
|     3      | 0.215  | 0.1259 | 0.2455 | 0.3036 |  0.3899 |
|     4      | 0.2494 | 0.1436 | 0.2973 | 0.3687 |  0.4568 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 16:37:54,291: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3213 | 0.204  | 0.3711 | 0.4453 |  0.5516 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3212 | 0.2038 | 0.3715 | 0.4454 |  0.5514 |
|     1      | 0.239  | 0.1452 | 0.2683 | 0.3318 |  0.4238 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3214 | 0.204  | 0.3715 | 0.4455 |  0.551  |
|     1      | 0.2391 | 0.1453 | 0.2685 | 0.3318 |  0.4238 |
|     2      | 0.2255 | 0.135  | 0.2564 | 0.3163 |  0.3993 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3211 | 0.2036 | 0.3719 | 0.4454 |  0.5507 |
|     1      | 0.2389 | 0.1451 | 0.268  | 0.3321 |  0.4243 |
|     2      | 0.2255 | 0.1349 | 0.2566 | 0.3163 |  0.3992 |
|     3      | 0.215  | 0.126  | 0.2452 | 0.3038 |   0.39  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3214 | 0.2043 | 0.372  | 0.4451 |  0.5505 |
|     1      | 0.239  | 0.1453 | 0.2681 | 0.3323 |  0.4239 |
|     2      | 0.2255 | 0.1349 | 0.2568 | 0.3166 |  0.3992 |
|     3      | 0.215  | 0.1259 | 0.2455 | 0.3036 |  0.3899 |
|     4      | 0.2494 | 0.1436 | 0.2973 | 0.3687 |  0.4568 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 16:37:54,292: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 51.62320256233215  |   0.321   |    0.204     |    0.371     |     0.552     |
|    1     | 136.92527031898499 |   0.271   |    0.168     |    0.309     |     0.474     |
|    2     | 215.35753750801086 |   0.254   |    0.156     |    0.289     |     0.445     |
|    3     | 282.48746132850647 |   0.243   |    0.147     |    0.277     |      0.43     |
|    4     | 80.70306253433228  |   0.244   |    0.147     |     0.28     |     0.434     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 16:37:54,292: Sum_Training_Time:767.0965342521667
2024-12-27 16:37:54,292: Every_Training_Time:[51.62320256233215, 136.92527031898499, 215.35753750801086, 282.48746132850647, 80.70306253433228]
2024-12-27 16:37:54,292: Forward transfer: 0.040125 Backward transfer: 2.5000000000011124e-05
2024-12-27 16:38:27,934: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227163758/ENTITYentity_0.01_1024_10', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_1024_10', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_1024_10', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=10, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 16:38:35,546: Snapshot:0	Epoch:0	Loss:28.546	translation_Loss:28.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.45	Hits@10:47.19	Best:24.45
2024-12-27 16:38:39,421: Snapshot:0	Epoch:1	Loss:9.983	translation_Loss:9.983	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.22	Hits@10:54.08	Best:31.22
2024-12-27 16:38:43,275: Snapshot:0	Epoch:2	Loss:3.796	translation_Loss:3.796	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.63	Hits@10:54.79	Best:31.63
2024-12-27 16:38:47,134: Snapshot:0	Epoch:3	Loss:2.045	translation_Loss:2.045	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.88	Hits@10:54.62	Best:31.88
2024-12-27 16:38:50,949: Snapshot:0	Epoch:4	Loss:1.392	translation_Loss:1.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.94	Hits@10:54.38	Best:31.94
2024-12-27 16:38:54,739: Snapshot:0	Epoch:5	Loss:1.104	translation_Loss:1.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.65	Hits@10:54.08	Best:31.94
2024-12-27 16:38:58,620: Snapshot:0	Epoch:6	Loss:0.951	translation_Loss:0.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.69	Hits@10:54.04	Best:31.94
2024-12-27 16:39:02,377: Snapshot:0	Epoch:7	Loss:0.84	translation_Loss:0.84	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.81	Hits@10:53.65	Best:31.94
2024-12-27 16:39:06,154: Snapshot:0	Epoch:8	Loss:0.753	translation_Loss:0.753	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.54	Hits@10:53.33	Best:31.94
2024-12-27 16:39:09,937: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 31.94
2024-12-27 16:39:09,937: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.693 MRR:31.31 Best Results: 31.94
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 16:39:09,937: Snapshot:0	Epoch:9	Loss:0.693	translation_Loss:0.693	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.31	Hits@10:53.13	Best:31.94
2024-12-27 16:39:14,331: Snapshot:0	Epoch:10	Loss:28.1	translation_Loss:28.063	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.31	Hits@10:53.13	Best:31.94
2024-12-27 16:39:18,651: End of token training: 0 Epoch: 11 Loss:28.066 MRR:31.31 Best Results: 31.94
2024-12-27 16:39:18,651: Snapshot:0	Epoch:11	Loss:28.066	translation_Loss:28.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.31	Hits@10:53.13	Best:31.94
2024-12-27 16:39:18,884: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_10/0model_best.tar'
2024-12-27 16:39:20,201: 
+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.323 | 0.206  | 0.3721 | 0.4463 |  0.5497 |
+------------+-------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:39:44,020: Snapshot:1	Epoch:0	Loss:207.031	translation_Loss:17.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:189.914                                                   	MRR:21.61	Hits@10:38.53	Best:21.61
2024-12-27 16:39:50,805: Snapshot:1	Epoch:1	Loss:4.814	translation_Loss:4.735	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.079                                                   	MRR:22.74	Hits@10:40.92	Best:22.74
2024-12-27 16:39:57,518: Snapshot:1	Epoch:2	Loss:3.472	translation_Loss:3.418	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.054                                                   	MRR:23.11	Hits@10:41.48	Best:23.11
2024-12-27 16:40:04,402: Snapshot:1	Epoch:3	Loss:3.026	translation_Loss:2.964	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.062                                                   	MRR:23.4	Hits@10:41.59	Best:23.4
2024-12-27 16:40:11,324: Snapshot:1	Epoch:4	Loss:2.796	translation_Loss:2.723	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.073                                                   	MRR:23.54	Hits@10:41.86	Best:23.54
2024-12-27 16:40:17,979: Snapshot:1	Epoch:5	Loss:2.623	translation_Loss:2.541	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.082                                                   	MRR:23.61	Hits@10:42.09	Best:23.61
2024-12-27 16:40:24,633: Snapshot:1	Epoch:6	Loss:2.506	translation_Loss:2.412	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:23.77	Hits@10:42.17	Best:23.77
2024-12-27 16:40:31,276: Snapshot:1	Epoch:7	Loss:2.438	translation_Loss:2.334	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.104                                                   	MRR:24.02	Hits@10:42.39	Best:24.02
2024-12-27 16:40:37,901: Snapshot:1	Epoch:8	Loss:2.359	translation_Loss:2.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.118                                                   	MRR:23.88	Hits@10:42.34	Best:24.02
2024-12-27 16:40:44,546: Snapshot:1	Epoch:9	Loss:2.297	translation_Loss:2.166	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.131                                                   	MRR:23.9	Hits@10:42.53	Best:24.02
2024-12-27 16:40:51,144: Snapshot:1	Epoch:10	Loss:2.255	translation_Loss:2.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.146                                                   	MRR:24.02	Hits@10:42.47	Best:24.02
2024-12-27 16:40:58,269: Snapshot:1	Epoch:11	Loss:2.215	translation_Loss:2.05	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:24.09	Hits@10:42.32	Best:24.09
2024-12-27 16:41:04,930: Snapshot:1	Epoch:12	Loss:2.205	translation_Loss:2.018	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:24.06	Hits@10:42.32	Best:24.09
2024-12-27 16:41:11,688: Snapshot:1	Epoch:13	Loss:2.182	translation_Loss:1.972	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.211                                                   	MRR:24.06	Hits@10:42.43	Best:24.09
2024-12-27 16:41:18,313: Snapshot:1	Epoch:14	Loss:2.183	translation_Loss:1.944	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.239                                                   	MRR:24.09	Hits@10:42.52	Best:24.09
2024-12-27 16:41:25,025: Snapshot:1	Epoch:15	Loss:2.183	translation_Loss:1.91	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.273                                                   	MRR:24.11	Hits@10:42.37	Best:24.11
2024-12-27 16:41:31,703: Snapshot:1	Epoch:16	Loss:2.23	translation_Loss:1.91	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.32                                                   	MRR:24.14	Hits@10:42.51	Best:24.14
2024-12-27 16:41:38,364: Snapshot:1	Epoch:17	Loss:2.264	translation_Loss:1.889	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.375                                                   	MRR:24.28	Hits@10:42.71	Best:24.28
2024-12-27 16:41:45,123: Snapshot:1	Epoch:18	Loss:2.292	translation_Loss:1.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.456                                                   	MRR:24.36	Hits@10:42.97	Best:24.36
2024-12-27 16:41:51,752: Snapshot:1	Epoch:19	Loss:3.265	translation_Loss:1.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.414                                                   	MRR:24.2	Hits@10:42.85	Best:24.36
2024-12-27 16:41:58,387: Snapshot:1	Epoch:20	Loss:3.263	translation_Loss:1.822	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.441                                                   	MRR:24.12	Hits@10:42.83	Best:24.36
2024-12-27 16:42:05,448: Snapshot:1	Epoch:21	Loss:3.38	translation_Loss:1.772	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.608                                                   	MRR:24.22	Hits@10:42.99	Best:24.36
2024-12-27 16:42:12,127: Snapshot:1	Epoch:22	Loss:3.656	translation_Loss:1.77	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.887                                                   	MRR:24.35	Hits@10:43.1	Best:24.36
2024-12-27 16:42:18,723: Early Stopping! Snapshot: 1 Epoch: 23 Best Results: 24.36
2024-12-27 16:42:18,723: Start to training tokens! Snapshot: 1 Epoch: 23 Loss:4.444 MRR:24.28 Best Results: 24.36
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 16:42:18,723: Snapshot:1	Epoch:23	Loss:4.444	translation_Loss:1.748	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.696                                                   	MRR:24.28	Hits@10:42.66	Best:24.36
2024-12-27 16:42:25,329: Snapshot:1	Epoch:24	Loss:46.233	translation_Loss:46.194	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.28	Hits@10:42.66	Best:24.36
2024-12-27 16:42:31,970: End of token training: 1 Epoch: 25 Loss:46.156 MRR:24.28 Best Results: 24.36
2024-12-27 16:42:31,971: Snapshot:1	Epoch:25	Loss:46.156	translation_Loss:46.156	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.28	Hits@10:42.66	Best:24.36
2024-12-27 16:42:32,197: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_10/1model_best.tar'
2024-12-27 16:42:35,625: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3228 | 0.2056 | 0.372  | 0.4464 |   0.55  |
|     1      | 0.2432 | 0.1485 | 0.2733 | 0.3361 |  0.4286 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:43:01,044: Snapshot:2	Epoch:0	Loss:195.342	translation_Loss:16.574	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:178.768                                                   	MRR:19.47	Hits@10:34.46	Best:19.47
2024-12-27 16:43:08,411: Snapshot:2	Epoch:1	Loss:4.818	translation_Loss:4.713	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.106                                                   	MRR:20.76	Hits@10:36.88	Best:20.76
2024-12-27 16:43:15,727: Snapshot:2	Epoch:2	Loss:3.646	translation_Loss:3.552	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:21.33	Hits@10:37.66	Best:21.33
2024-12-27 16:43:23,023: Snapshot:2	Epoch:3	Loss:3.238	translation_Loss:3.128	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:21.62	Hits@10:38.25	Best:21.62
2024-12-27 16:43:30,432: Snapshot:2	Epoch:4	Loss:3.011	translation_Loss:2.886	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.125                                                   	MRR:21.89	Hits@10:38.66	Best:21.89
2024-12-27 16:43:37,730: Snapshot:2	Epoch:5	Loss:2.888	translation_Loss:2.745	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.143                                                   	MRR:21.74	Hits@10:38.52	Best:21.89
2024-12-27 16:43:45,023: Snapshot:2	Epoch:6	Loss:2.761	translation_Loss:2.6	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:21.84	Hits@10:38.52	Best:21.89
2024-12-27 16:43:52,291: Snapshot:2	Epoch:7	Loss:2.686	translation_Loss:2.505	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.181                                                   	MRR:21.99	Hits@10:39.0	Best:21.99
2024-12-27 16:43:59,572: Snapshot:2	Epoch:8	Loss:2.644	translation_Loss:2.44	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:22.07	Hits@10:39.22	Best:22.07
2024-12-27 16:44:07,211: Snapshot:2	Epoch:9	Loss:2.563	translation_Loss:2.339	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.224                                                   	MRR:22.1	Hits@10:39.04	Best:22.1
2024-12-27 16:44:14,522: Snapshot:2	Epoch:10	Loss:2.565	translation_Loss:2.311	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.253                                                   	MRR:22.24	Hits@10:39.25	Best:22.24
2024-12-27 16:44:21,764: Snapshot:2	Epoch:11	Loss:2.537	translation_Loss:2.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.282                                                   	MRR:22.21	Hits@10:39.2	Best:22.24
2024-12-27 16:44:29,116: Snapshot:2	Epoch:12	Loss:2.548	translation_Loss:2.229	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.318                                                   	MRR:22.33	Hits@10:39.17	Best:22.33
2024-12-27 16:44:36,496: Snapshot:2	Epoch:13	Loss:2.537	translation_Loss:2.176	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.361                                                   	MRR:22.52	Hits@10:39.27	Best:22.52
2024-12-27 16:44:43,771: Snapshot:2	Epoch:14	Loss:2.578	translation_Loss:2.173	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.405                                                   	MRR:22.53	Hits@10:39.56	Best:22.53
2024-12-27 16:44:51,093: Snapshot:2	Epoch:15	Loss:2.58	translation_Loss:2.124	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.456                                                   	MRR:22.31	Hits@10:39.11	Best:22.53
2024-12-27 16:44:58,373: Snapshot:2	Epoch:16	Loss:2.639	translation_Loss:2.108	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.53                                                   	MRR:22.38	Hits@10:39.31	Best:22.53
2024-12-27 16:45:05,671: Snapshot:2	Epoch:17	Loss:2.69	translation_Loss:2.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.636                                                   	MRR:22.32	Hits@10:39.28	Best:22.53
2024-12-27 16:45:12,953: Snapshot:2	Epoch:18	Loss:3.871	translation_Loss:2.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.817                                                   	MRR:22.35	Hits@10:39.39	Best:22.53
2024-12-27 16:45:20,587: Early Stopping! Snapshot: 2 Epoch: 19 Best Results: 22.53
2024-12-27 16:45:20,587: Start to training tokens! Snapshot: 2 Epoch: 19 Loss:3.585 MRR:22.34 Best Results: 22.53
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 16:45:20,588: Snapshot:2	Epoch:19	Loss:3.585	translation_Loss:2.007	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.578                                                   	MRR:22.34	Hits@10:39.75	Best:22.53
2024-12-27 16:45:27,808: Snapshot:2	Epoch:20	Loss:47.102	translation_Loss:47.066	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.34	Hits@10:39.75	Best:22.53
2024-12-27 16:45:35,080: End of token training: 2 Epoch: 21 Loss:47.11 MRR:22.34 Best Results: 22.53
2024-12-27 16:45:35,080: Snapshot:2	Epoch:21	Loss:47.11	translation_Loss:47.11	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.34	Hits@10:39.75	Best:22.53
2024-12-27 16:45:35,294: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_10/2model_best.tar'
2024-12-27 16:45:41,413: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3228 | 0.2056 | 0.372  | 0.4463 |  0.5501 |
|     1      | 0.2431 | 0.1484 | 0.2735 | 0.336  |  0.4288 |
|     2      | 0.2267 | 0.136  | 0.2603 | 0.3183 |  0.397  |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:46:06,841: Snapshot:3	Epoch:0	Loss:192.042	translation_Loss:15.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:177.006                                                   	MRR:18.83	Hits@10:33.76	Best:18.83
2024-12-27 16:46:14,345: Snapshot:3	Epoch:1	Loss:4.176	translation_Loss:4.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.135                                                   	MRR:20.13	Hits@10:35.94	Best:20.13
2024-12-27 16:46:21,867: Snapshot:3	Epoch:2	Loss:3.103	translation_Loss:2.993	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:20.61	Hits@10:36.95	Best:20.61
2024-12-27 16:46:29,248: Snapshot:3	Epoch:3	Loss:2.796	translation_Loss:2.668	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.128                                                   	MRR:20.64	Hits@10:37.08	Best:20.64
2024-12-27 16:46:36,604: Snapshot:3	Epoch:4	Loss:2.614	translation_Loss:2.469	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.145                                                   	MRR:20.74	Hits@10:37.25	Best:20.74
2024-12-27 16:46:44,042: Snapshot:3	Epoch:5	Loss:2.519	translation_Loss:2.352	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:20.88	Hits@10:37.33	Best:20.88
2024-12-27 16:46:51,469: Snapshot:3	Epoch:6	Loss:2.391	translation_Loss:2.209	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.183                                                   	MRR:21.25	Hits@10:37.91	Best:21.25
2024-12-27 16:46:58,844: Snapshot:3	Epoch:7	Loss:2.338	translation_Loss:2.135	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.203                                                   	MRR:21.22	Hits@10:38.06	Best:21.25
2024-12-27 16:47:06,168: Snapshot:3	Epoch:8	Loss:2.269	translation_Loss:2.044	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.225                                                   	MRR:20.99	Hits@10:37.79	Best:21.25
2024-12-27 16:47:13,519: Snapshot:3	Epoch:9	Loss:2.243	translation_Loss:1.994	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.249                                                   	MRR:20.94	Hits@10:37.97	Best:21.25
2024-12-27 16:47:20,822: Snapshot:3	Epoch:10	Loss:2.252	translation_Loss:1.975	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.276                                                   	MRR:20.93	Hits@10:38.11	Best:21.25
2024-12-27 16:47:28,132: Early Stopping! Snapshot: 3 Epoch: 11 Best Results: 21.25
2024-12-27 16:47:28,132: Start to training tokens! Snapshot: 3 Epoch: 11 Loss:2.208 MRR:21.19 Best Results: 21.25
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 16:47:28,133: Snapshot:3	Epoch:11	Loss:2.208	translation_Loss:1.908	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.3                                                   	MRR:21.19	Hits@10:38.36	Best:21.25
2024-12-27 16:47:35,489: Snapshot:3	Epoch:12	Loss:42.363	translation_Loss:42.326	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.19	Hits@10:38.36	Best:21.25
2024-12-27 16:47:42,844: End of token training: 3 Epoch: 13 Loss:42.282 MRR:21.19 Best Results: 21.25
2024-12-27 16:47:42,844: Snapshot:3	Epoch:13	Loss:42.282	translation_Loss:42.282	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.19	Hits@10:38.36	Best:21.25
2024-12-27 16:47:43,117: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_10/3model_best.tar'
2024-12-27 16:47:52,870: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3229 | 0.2056 | 0.3721 | 0.4466 |  0.5502 |
|     1      | 0.2433 | 0.1489 | 0.2732 | 0.3359 |  0.4289 |
|     2      | 0.2268 | 0.1362 | 0.2603 | 0.3183 |  0.3972 |
|     3      | 0.212  | 0.1258 | 0.2413 | 0.2989 |  0.3758 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:48:11,723: Snapshot:4	Epoch:0	Loss:180.846	translation_Loss:10.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:170.105                                                   	MRR:23.01	Hits@10:41.08	Best:23.01
2024-12-27 16:48:16,996: Snapshot:4	Epoch:1	Loss:2.859	translation_Loss:2.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.616                                                   	MRR:24.81	Hits@10:44.39	Best:24.81
2024-12-27 16:48:22,312: Snapshot:4	Epoch:2	Loss:1.469	translation_Loss:1.404	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.065                                                   	MRR:25.19	Hits@10:44.62	Best:25.19
2024-12-27 16:48:28,017: Snapshot:4	Epoch:3	Loss:1.271	translation_Loss:1.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.069                                                   	MRR:25.21	Hits@10:44.95	Best:25.21
2024-12-27 16:48:33,334: Snapshot:4	Epoch:4	Loss:1.128	translation_Loss:1.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.076                                                   	MRR:25.41	Hits@10:45.12	Best:25.41
2024-12-27 16:48:38,611: Snapshot:4	Epoch:5	Loss:1.078	translation_Loss:0.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.083                                                   	MRR:25.21	Hits@10:45.2	Best:25.41
2024-12-27 16:48:43,848: Snapshot:4	Epoch:6	Loss:1.038	translation_Loss:0.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:25.36	Hits@10:44.96	Best:25.41
2024-12-27 16:48:49,158: Snapshot:4	Epoch:7	Loss:1.014	translation_Loss:0.919	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:25.62	Hits@10:45.59	Best:25.62
2024-12-27 16:48:54,391: Snapshot:4	Epoch:8	Loss:0.973	translation_Loss:0.871	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:25.56	Hits@10:45.46	Best:25.62
2024-12-27 16:48:59,741: Snapshot:4	Epoch:9	Loss:0.954	translation_Loss:0.845	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:25.69	Hits@10:45.64	Best:25.69
2024-12-27 16:49:05,007: Snapshot:4	Epoch:10	Loss:0.931	translation_Loss:0.814	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.117                                                   	MRR:25.69	Hits@10:45.79	Best:25.69
2024-12-27 16:49:10,263: Snapshot:4	Epoch:11	Loss:0.941	translation_Loss:0.815	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:25.4	Hits@10:45.46	Best:25.69
2024-12-27 16:49:15,555: Snapshot:4	Epoch:12	Loss:0.925	translation_Loss:0.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.132                                                   	MRR:25.61	Hits@10:45.81	Best:25.69
2024-12-27 16:49:20,816: Snapshot:4	Epoch:13	Loss:0.915	translation_Loss:0.774	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.142                                                   	MRR:25.3	Hits@10:45.45	Best:25.69
2024-12-27 16:49:26,076: Early Stopping! Snapshot: 4 Epoch: 14 Best Results: 25.69
2024-12-27 16:49:26,077: Start to training tokens! Snapshot: 4 Epoch: 14 Loss:0.902 MRR:25.42 Best Results: 25.69
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 16:49:26,077: Snapshot:4	Epoch:14	Loss:0.902	translation_Loss:0.755	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:25.42	Hits@10:45.67	Best:25.69
2024-12-27 16:49:31,319: Snapshot:4	Epoch:15	Loss:23.346	translation_Loss:23.308	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.42	Hits@10:45.67	Best:25.69
2024-12-27 16:49:36,627: End of token training: 4 Epoch: 16 Loss:23.317 MRR:25.42 Best Results: 25.69
2024-12-27 16:49:36,627: Snapshot:4	Epoch:16	Loss:23.317	translation_Loss:23.317	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.42	Hits@10:45.67	Best:25.69
2024-12-27 16:49:36,903: => loading checkpoint './checkpoint/ENTITYentity_0.01_1024_10/4model_best.tar'
2024-12-27 16:49:49,154: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3228 | 0.2056 | 0.3725 | 0.4465 |  0.5499 |
|     1      | 0.2434 | 0.149  | 0.2735 | 0.3357 |  0.4288 |
|     2      | 0.2269 | 0.1364 | 0.2603 | 0.3183 |  0.397  |
|     3      | 0.2118 | 0.1254 | 0.2413 | 0.2988 |  0.3757 |
|     4      | 0.255  | 0.148  | 0.3041 | 0.3763 |  0.4608 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 16:49:49,156: Final Result:
[+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.323 | 0.206  | 0.3721 | 0.4463 |  0.5497 |
+------------+-------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3228 | 0.2056 | 0.372  | 0.4464 |   0.55  |
|     1      | 0.2432 | 0.1485 | 0.2733 | 0.3361 |  0.4286 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3228 | 0.2056 | 0.372  | 0.4463 |  0.5501 |
|     1      | 0.2431 | 0.1484 | 0.2735 | 0.336  |  0.4288 |
|     2      | 0.2267 | 0.136  | 0.2603 | 0.3183 |  0.397  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3229 | 0.2056 | 0.3721 | 0.4466 |  0.5502 |
|     1      | 0.2433 | 0.1489 | 0.2732 | 0.3359 |  0.4289 |
|     2      | 0.2268 | 0.1362 | 0.2603 | 0.3183 |  0.3972 |
|     3      | 0.212  | 0.1258 | 0.2413 | 0.2989 |  0.3758 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3228 | 0.2056 | 0.3725 | 0.4465 |  0.5499 |
|     1      | 0.2434 | 0.149  | 0.2735 | 0.3357 |  0.4288 |
|     2      | 0.2269 | 0.1364 | 0.2603 | 0.3183 |  0.397  |
|     3      | 0.2118 | 0.1254 | 0.2413 | 0.2988 |  0.3757 |
|     4      | 0.255  | 0.148  | 0.3041 | 0.3763 |  0.4608 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 16:49:49,156: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 50.71592831611633  |   0.323   |    0.206     |    0.372     |      0.55     |
|    1     | 189.53209328651428 |   0.274   |    0.171     |    0.312     |     0.476     |
|    2     | 176.5426881313324  |   0.256   |    0.157     |    0.292     |     0.446     |
|    3     | 118.17626166343689 |   0.244   |    0.149     |    0.278     |     0.427     |
|    4     | 101.30817747116089 |   0.246   |    0.149     |    0.283     |     0.432     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 16:49:49,156: Sum_Training_Time:636.2751488685608
2024-12-27 16:49:49,156: Every_Training_Time:[50.71592831611633, 189.53209328651428, 176.5426881313324, 118.17626166343689, 101.30817747116089]
2024-12-27 16:49:49,156: Forward transfer: 0.040425 Backward transfer: -1.3877787807814457e-17
2024-12-27 16:50:23,560: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227164953/ENTITYentity_0.01_2048_2', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_2048_2', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_2048_2', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=2, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 16:50:31,112: Snapshot:0	Epoch:0	Loss:15.487	translation_Loss:15.487	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.49	Hits@10:44.43	Best:21.49
2024-12-27 16:50:34,927: Snapshot:0	Epoch:1	Loss:6.378	translation_Loss:6.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.62	Hits@10:53.86	Best:30.62
2024-12-27 16:50:38,650: Snapshot:0	Epoch:2	Loss:2.563	translation_Loss:2.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.29	Hits@10:55.48	Best:32.29
2024-12-27 16:50:42,336: Snapshot:0	Epoch:3	Loss:1.287	translation_Loss:1.287	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.65	Hits@10:55.34	Best:32.65
2024-12-27 16:50:46,403: Snapshot:0	Epoch:4	Loss:0.813	translation_Loss:0.813	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.85	Hits@10:55.24	Best:32.85
2024-12-27 16:50:50,077: Snapshot:0	Epoch:5	Loss:0.605	translation_Loss:0.605	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.53	Hits@10:54.96	Best:32.85
2024-12-27 16:50:53,740: Snapshot:0	Epoch:6	Loss:0.505	translation_Loss:0.505	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.56	Hits@10:55.16	Best:32.85
2024-12-27 16:50:57,496: Snapshot:0	Epoch:7	Loss:0.436	translation_Loss:0.436	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.37	Hits@10:54.63	Best:32.85
2024-12-27 16:51:01,174: Snapshot:0	Epoch:8	Loss:0.385	translation_Loss:0.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.24	Hits@10:54.58	Best:32.85
2024-12-27 16:51:04,845: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 32.85
2024-12-27 16:51:04,845: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.355 MRR:32.22 Best Results: 32.85
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 16:51:04,846: Snapshot:0	Epoch:9	Loss:0.355	translation_Loss:0.355	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.22	Hits@10:54.65	Best:32.85
2024-12-27 16:51:09,091: Snapshot:0	Epoch:10	Loss:14.304	translation_Loss:14.27	multi_layer_Loss:0.034	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.22	Hits@10:54.65	Best:32.85
2024-12-27 16:51:13,257: End of token training: 0 Epoch: 11 Loss:14.276 MRR:32.22 Best Results: 32.85
2024-12-27 16:51:13,258: Snapshot:0	Epoch:11	Loss:14.276	translation_Loss:14.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:32.22	Hits@10:54.65	Best:32.85
2024-12-27 16:51:13,488: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_2/0model_best.tar'
2024-12-27 16:51:14,769: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3337 | 0.2181 | 0.3828 | 0.4545 |  0.5548 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:51:38,014: Snapshot:1	Epoch:0	Loss:49.045	translation_Loss:9.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:39.474                                                   	MRR:21.67	Hits@10:38.53	Best:21.67
2024-12-27 16:51:44,735: Snapshot:1	Epoch:1	Loss:3.28	translation_Loss:2.707	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.573                                                   	MRR:23.33	Hits@10:41.65	Best:23.33
2024-12-27 16:51:51,116: Snapshot:1	Epoch:2	Loss:1.916	translation_Loss:1.844	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.072                                                   	MRR:23.94	Hits@10:42.35	Best:23.94
2024-12-27 16:51:57,505: Snapshot:1	Epoch:3	Loss:1.661	translation_Loss:1.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.072                                                   	MRR:24.4	Hits@10:42.47	Best:24.4
2024-12-27 16:52:03,861: Snapshot:1	Epoch:4	Loss:1.549	translation_Loss:1.469	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.08                                                   	MRR:24.36	Hits@10:42.69	Best:24.4
2024-12-27 16:52:10,658: Snapshot:1	Epoch:5	Loss:1.474	translation_Loss:1.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:24.6	Hits@10:42.77	Best:24.6
2024-12-27 16:52:17,029: Snapshot:1	Epoch:6	Loss:1.414	translation_Loss:1.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:24.58	Hits@10:43.12	Best:24.6
2024-12-27 16:52:23,369: Snapshot:1	Epoch:7	Loss:1.385	translation_Loss:1.283	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:24.63	Hits@10:43.1	Best:24.63
2024-12-27 16:52:29,713: Snapshot:1	Epoch:8	Loss:1.355	translation_Loss:1.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.112                                                   	MRR:24.62	Hits@10:43.24	Best:24.63
2024-12-27 16:52:36,441: Snapshot:1	Epoch:9	Loss:1.317	translation_Loss:1.203	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:24.7	Hits@10:43.15	Best:24.7
2024-12-27 16:52:42,840: Snapshot:1	Epoch:10	Loss:1.294	translation_Loss:1.173	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.121                                                   	MRR:24.75	Hits@10:43.37	Best:24.75
2024-12-27 16:52:49,243: Snapshot:1	Epoch:11	Loss:1.273	translation_Loss:1.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.131                                                   	MRR:24.71	Hits@10:43.05	Best:24.75
2024-12-27 16:52:55,717: Snapshot:1	Epoch:12	Loss:1.257	translation_Loss:1.122	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.136                                                   	MRR:24.67	Hits@10:43.22	Best:24.75
2024-12-27 16:53:02,484: Snapshot:1	Epoch:13	Loss:1.242	translation_Loss:1.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.141                                                   	MRR:24.67	Hits@10:43.17	Best:24.75
2024-12-27 16:53:08,804: Snapshot:1	Epoch:14	Loss:1.231	translation_Loss:1.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.145                                                   	MRR:24.65	Hits@10:43.48	Best:24.75
2024-12-27 16:53:15,216: Snapshot:1	Epoch:15	Loss:1.225	translation_Loss:1.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:24.77	Hits@10:43.53	Best:24.77
2024-12-27 16:53:21,584: Snapshot:1	Epoch:16	Loss:1.235	translation_Loss:1.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.164                                                   	MRR:24.83	Hits@10:43.37	Best:24.83
2024-12-27 16:53:28,287: Snapshot:1	Epoch:17	Loss:1.225	translation_Loss:1.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:25.05	Hits@10:43.65	Best:25.05
2024-12-27 16:53:34,619: Snapshot:1	Epoch:18	Loss:1.203	translation_Loss:1.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:24.78	Hits@10:43.48	Best:25.05
2024-12-27 16:53:41,033: Snapshot:1	Epoch:19	Loss:1.222	translation_Loss:1.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.182                                                   	MRR:24.83	Hits@10:43.34	Best:25.05
2024-12-27 16:53:47,390: Snapshot:1	Epoch:20	Loss:1.21	translation_Loss:1.022	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:24.77	Hits@10:43.52	Best:25.05
2024-12-27 16:53:54,057: Snapshot:1	Epoch:21	Loss:1.192	translation_Loss:0.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.193                                                   	MRR:24.87	Hits@10:43.6	Best:25.05
2024-12-27 16:54:00,406: Early Stopping! Snapshot: 1 Epoch: 22 Best Results: 25.05
2024-12-27 16:54:00,407: Start to training tokens! Snapshot: 1 Epoch: 22 Loss:1.199 MRR:24.86 Best Results: 25.05
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 16:54:00,407: Snapshot:1	Epoch:22	Loss:1.199	translation_Loss:0.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:24.86	Hits@10:43.98	Best:25.05
2024-12-27 16:54:06,749: Snapshot:1	Epoch:23	Loss:23.435	translation_Loss:23.398	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.86	Hits@10:43.98	Best:25.05
2024-12-27 16:54:13,112: End of token training: 1 Epoch: 24 Loss:23.406 MRR:24.86 Best Results: 25.05
2024-12-27 16:54:13,113: Snapshot:1	Epoch:24	Loss:23.406	translation_Loss:23.406	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.86	Hits@10:43.98	Best:25.05
2024-12-27 16:54:13,383: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_2/1model_best.tar'
2024-12-27 16:54:17,301: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3336 | 0.2178 | 0.383  | 0.4548 |  0.5542 |
|     1      | 0.2501 | 0.1563 | 0.2806 | 0.3423 |  0.4356 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:54:41,759: Snapshot:2	Epoch:0	Loss:47.343	translation_Loss:9.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:38.197                                                   	MRR:19.29	Hits@10:33.89	Best:19.29
2024-12-27 16:54:48,761: Snapshot:2	Epoch:1	Loss:3.168	translation_Loss:2.62	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.547                                                   	MRR:21.44	Hits@10:37.5	Best:21.44
2024-12-27 16:54:56,141: Snapshot:2	Epoch:2	Loss:2.006	translation_Loss:1.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.117                                                   	MRR:21.87	Hits@10:38.57	Best:21.87
2024-12-27 16:55:03,186: Snapshot:2	Epoch:3	Loss:1.772	translation_Loss:1.652	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.12                                                   	MRR:22.06	Hits@10:39.06	Best:22.06
2024-12-27 16:55:10,314: Snapshot:2	Epoch:4	Loss:1.681	translation_Loss:1.544	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.137                                                   	MRR:22.42	Hits@10:39.3	Best:22.42
2024-12-27 16:55:17,311: Snapshot:2	Epoch:5	Loss:1.62	translation_Loss:1.472	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:22.46	Hits@10:39.83	Best:22.46
2024-12-27 16:55:24,678: Snapshot:2	Epoch:6	Loss:1.565	translation_Loss:1.408	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.157                                                   	MRR:22.49	Hits@10:39.45	Best:22.49
2024-12-27 16:55:31,705: Snapshot:2	Epoch:7	Loss:1.545	translation_Loss:1.369	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.176                                                   	MRR:22.5	Hits@10:39.49	Best:22.5
2024-12-27 16:55:38,695: Snapshot:2	Epoch:8	Loss:1.51	translation_Loss:1.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.179                                                   	MRR:22.75	Hits@10:39.8	Best:22.75
2024-12-27 16:55:45,701: Snapshot:2	Epoch:9	Loss:1.482	translation_Loss:1.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.186                                                   	MRR:22.57	Hits@10:39.67	Best:22.75
2024-12-27 16:55:53,015: Snapshot:2	Epoch:10	Loss:1.469	translation_Loss:1.27	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:22.55	Hits@10:39.84	Best:22.75
2024-12-27 16:56:00,066: Snapshot:2	Epoch:11	Loss:1.435	translation_Loss:1.228	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:22.63	Hits@10:40.04	Best:22.75
2024-12-27 16:56:07,079: Snapshot:2	Epoch:12	Loss:1.428	translation_Loss:1.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.217                                                   	MRR:22.78	Hits@10:40.03	Best:22.78
2024-12-27 16:56:14,150: Snapshot:2	Epoch:13	Loss:1.429	translation_Loss:1.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.224                                                   	MRR:22.82	Hits@10:40.17	Best:22.82
2024-12-27 16:56:21,549: Snapshot:2	Epoch:14	Loss:1.409	translation_Loss:1.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.229                                                   	MRR:22.94	Hits@10:39.99	Best:22.94
2024-12-27 16:56:28,557: Snapshot:2	Epoch:15	Loss:1.401	translation_Loss:1.163	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.238                                                   	MRR:23.04	Hits@10:40.15	Best:23.04
2024-12-27 16:56:35,541: Snapshot:2	Epoch:16	Loss:1.393	translation_Loss:1.148	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.245                                                   	MRR:22.73	Hits@10:40.0	Best:23.04
2024-12-27 16:56:42,572: Snapshot:2	Epoch:17	Loss:1.412	translation_Loss:1.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.257                                                   	MRR:22.88	Hits@10:40.14	Best:23.04
2024-12-27 16:56:49,882: Snapshot:2	Epoch:18	Loss:1.378	translation_Loss:1.115	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.263                                                   	MRR:22.87	Hits@10:40.14	Best:23.04
2024-12-27 16:56:56,878: Snapshot:2	Epoch:19	Loss:1.401	translation_Loss:1.129	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.272                                                   	MRR:22.9	Hits@10:40.29	Best:23.04
2024-12-27 16:57:03,840: Early Stopping! Snapshot: 2 Epoch: 20 Best Results: 23.04
2024-12-27 16:57:03,840: Start to training tokens! Snapshot: 2 Epoch: 20 Loss:1.387 MRR:22.91 Best Results: 23.04
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 16:57:03,840: Snapshot:2	Epoch:20	Loss:1.387	translation_Loss:1.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.278                                                   	MRR:22.91	Hits@10:40.21	Best:23.04
2024-12-27 16:57:10,813: Snapshot:2	Epoch:21	Loss:23.847	translation_Loss:23.811	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.91	Hits@10:40.21	Best:23.04
2024-12-27 16:57:18,157: End of token training: 2 Epoch: 22 Loss:23.816 MRR:22.91 Best Results: 23.04
2024-12-27 16:57:18,158: Snapshot:2	Epoch:22	Loss:23.816	translation_Loss:23.816	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.91	Hits@10:40.21	Best:23.04
2024-12-27 16:57:18,359: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_2/2model_best.tar'
2024-12-27 16:57:24,604: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3332 | 0.2171 | 0.3828 | 0.4555 |  0.5542 |
|     1      | 0.2501 | 0.1564 | 0.2805 | 0.3424 |  0.4358 |
|     2      | 0.2322 | 0.1408 | 0.2663 | 0.3229 |  0.4061 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:57:49,460: Snapshot:3	Epoch:0	Loss:46.308	translation_Loss:8.281	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:38.027                                                   	MRR:18.61	Hits@10:33.35	Best:18.61
2024-12-27 16:57:56,604: Snapshot:3	Epoch:1	Loss:2.892	translation_Loss:2.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.657                                                   	MRR:20.68	Hits@10:37.09	Best:20.68
2024-12-27 16:58:03,856: Snapshot:3	Epoch:2	Loss:1.715	translation_Loss:1.578	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.137                                                   	MRR:21.05	Hits@10:37.86	Best:21.05
2024-12-27 16:58:10,972: Snapshot:3	Epoch:3	Loss:1.547	translation_Loss:1.4	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.146                                                   	MRR:21.23	Hits@10:38.18	Best:21.23
2024-12-27 16:58:18,149: Snapshot:3	Epoch:4	Loss:1.446	translation_Loss:1.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.151                                                   	MRR:21.36	Hits@10:38.07	Best:21.36
2024-12-27 16:58:25,250: Snapshot:3	Epoch:5	Loss:1.408	translation_Loss:1.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:21.59	Hits@10:38.79	Best:21.59
2024-12-27 16:58:32,391: Snapshot:3	Epoch:6	Loss:1.358	translation_Loss:1.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.18                                                   	MRR:21.7	Hits@10:38.62	Best:21.7
2024-12-27 16:58:39,431: Snapshot:3	Epoch:7	Loss:1.336	translation_Loss:1.151	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.185                                                   	MRR:21.35	Hits@10:38.47	Best:21.7
2024-12-27 16:58:46,857: Snapshot:3	Epoch:8	Loss:1.316	translation_Loss:1.115	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:21.55	Hits@10:38.72	Best:21.7
2024-12-27 16:58:53,890: Snapshot:3	Epoch:9	Loss:1.297	translation_Loss:1.085	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.211                                                   	MRR:21.63	Hits@10:38.74	Best:21.7
2024-12-27 16:59:01,192: Snapshot:3	Epoch:10	Loss:1.273	translation_Loss:1.057	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.216                                                   	MRR:21.83	Hits@10:39.06	Best:21.83
2024-12-27 16:59:08,229: Snapshot:3	Epoch:11	Loss:1.262	translation_Loss:1.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:21.76	Hits@10:38.86	Best:21.83
2024-12-27 16:59:15,616: Snapshot:3	Epoch:12	Loss:1.25	translation_Loss:1.017	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.233                                                   	MRR:21.7	Hits@10:39.01	Best:21.83
2024-12-27 16:59:22,666: Snapshot:3	Epoch:13	Loss:1.248	translation_Loss:1.009	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.24                                                   	MRR:21.77	Hits@10:38.98	Best:21.83
2024-12-27 16:59:29,699: Snapshot:3	Epoch:14	Loss:1.225	translation_Loss:0.982	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.243                                                   	MRR:21.91	Hits@10:39.05	Best:21.91
2024-12-27 16:59:36,702: Snapshot:3	Epoch:15	Loss:1.222	translation_Loss:0.972	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.25                                                   	MRR:21.79	Hits@10:39.03	Best:21.91
2024-12-27 16:59:44,094: Snapshot:3	Epoch:16	Loss:1.248	translation_Loss:0.984	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.263                                                   	MRR:21.9	Hits@10:39.29	Best:21.91
2024-12-27 16:59:51,123: Snapshot:3	Epoch:17	Loss:1.22	translation_Loss:0.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.27                                                   	MRR:21.83	Hits@10:39.11	Best:21.91
2024-12-27 16:59:58,168: Snapshot:3	Epoch:18	Loss:1.201	translation_Loss:0.932	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.269                                                   	MRR:21.84	Hits@10:39.18	Best:21.91
2024-12-27 17:00:05,342: Early Stopping! Snapshot: 3 Epoch: 19 Best Results: 21.91
2024-12-27 17:00:05,343: Start to training tokens! Snapshot: 3 Epoch: 19 Loss:1.209 MRR:21.84 Best Results: 21.91
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 17:00:05,343: Snapshot:3	Epoch:19	Loss:1.209	translation_Loss:0.93	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.279                                                   	MRR:21.84	Hits@10:38.9	Best:21.91
2024-12-27 17:00:12,998: Snapshot:3	Epoch:20	Loss:21.464	translation_Loss:21.426	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.84	Hits@10:38.9	Best:21.91
2024-12-27 17:00:20,102: End of token training: 3 Epoch: 21 Loss:21.43 MRR:21.84 Best Results: 21.91
2024-12-27 17:00:20,103: Snapshot:3	Epoch:21	Loss:21.43	translation_Loss:21.43	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.84	Hits@10:38.9	Best:21.91
2024-12-27 17:00:20,320: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_2/3model_best.tar'
2024-12-27 17:00:29,912: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3333 | 0.2169 | 0.3832 | 0.4553 |  0.5537 |
|     1      | 0.2502 | 0.1565 | 0.2808 | 0.3426 |  0.4359 |
|     2      | 0.2324 | 0.1411 | 0.2666 | 0.3226 |  0.4059 |
|     3      | 0.2204 | 0.1325 | 0.2505 | 0.3061 |  0.3882 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:00:48,430: Snapshot:4	Epoch:0	Loss:41.078	translation_Loss:5.959	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:35.118                                                   	MRR:22.45	Hits@10:40.23	Best:22.45
2024-12-27 17:00:53,631: Snapshot:4	Epoch:1	Loss:3.276	translation_Loss:1.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.98                                                   	MRR:25.0	Hits@10:44.5	Best:25.0
2024-12-27 17:00:58,822: Snapshot:4	Epoch:2	Loss:0.929	translation_Loss:0.75	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.179                                                   	MRR:25.62	Hits@10:45.44	Best:25.62
2024-12-27 17:01:04,025: Snapshot:4	Epoch:3	Loss:0.679	translation_Loss:0.601	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.078                                                   	MRR:25.9	Hits@10:45.66	Best:25.9
2024-12-27 17:01:09,150: Snapshot:4	Epoch:4	Loss:0.617	translation_Loss:0.545	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.072                                                   	MRR:25.88	Hits@10:45.95	Best:25.9
2024-12-27 17:01:14,264: Snapshot:4	Epoch:5	Loss:0.578	translation_Loss:0.507	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.072                                                   	MRR:26.08	Hits@10:46.29	Best:26.08
2024-12-27 17:01:19,309: Snapshot:4	Epoch:6	Loss:0.553	translation_Loss:0.477	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.076                                                   	MRR:25.86	Hits@10:45.73	Best:26.08
2024-12-27 17:01:24,426: Snapshot:4	Epoch:7	Loss:0.556	translation_Loss:0.474	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.083                                                   	MRR:26.14	Hits@10:46.2	Best:26.14
2024-12-27 17:01:29,868: Snapshot:4	Epoch:8	Loss:0.543	translation_Loss:0.454	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:26.05	Hits@10:46.4	Best:26.14
2024-12-27 17:01:34,983: Snapshot:4	Epoch:9	Loss:0.533	translation_Loss:0.439	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.17	Hits@10:46.59	Best:26.17
2024-12-27 17:01:40,202: Snapshot:4	Epoch:10	Loss:0.523	translation_Loss:0.428	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:26.32	Hits@10:46.38	Best:26.32
2024-12-27 17:01:45,335: Snapshot:4	Epoch:11	Loss:0.502	translation_Loss:0.408	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.34	Hits@10:46.29	Best:26.34
2024-12-27 17:01:50,400: Snapshot:4	Epoch:12	Loss:0.512	translation_Loss:0.415	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:26.23	Hits@10:46.47	Best:26.34
2024-12-27 17:01:55,458: Snapshot:4	Epoch:13	Loss:0.502	translation_Loss:0.403	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:26.09	Hits@10:46.74	Best:26.34
2024-12-27 17:02:00,894: Snapshot:4	Epoch:14	Loss:0.506	translation_Loss:0.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.104                                                   	MRR:26.27	Hits@10:46.38	Best:26.34
2024-12-27 17:02:05,944: Snapshot:4	Epoch:15	Loss:0.504	translation_Loss:0.396	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:26.05	Hits@10:46.34	Best:26.34
2024-12-27 17:02:11,022: Early Stopping! Snapshot: 4 Epoch: 16 Best Results: 26.34
2024-12-27 17:02:11,022: Start to training tokens! Snapshot: 4 Epoch: 16 Loss:0.492 MRR:26.26 Best Results: 26.34
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 17:02:11,022: Snapshot:4	Epoch:16	Loss:0.492	translation_Loss:0.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.11                                                   	MRR:26.26	Hits@10:46.55	Best:26.34
2024-12-27 17:02:16,123: Snapshot:4	Epoch:17	Loss:11.751	translation_Loss:11.716	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.26	Hits@10:46.55	Best:26.34
2024-12-27 17:02:21,180: End of token training: 4 Epoch: 18 Loss:11.725 MRR:26.26 Best Results: 26.34
2024-12-27 17:02:21,180: Snapshot:4	Epoch:18	Loss:11.725	translation_Loss:11.724	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.26	Hits@10:46.55	Best:26.34
2024-12-27 17:02:21,445: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_2/4model_best.tar'
2024-12-27 17:02:33,464: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3336 | 0.2176 | 0.3825 | 0.4555 |  0.5536 |
|     1      | 0.2507 | 0.157  | 0.2809 | 0.3428 |  0.4364 |
|     2      | 0.2328 | 0.1416 | 0.2671 | 0.3229 |  0.4063 |
|     3      | 0.2207 | 0.1327 | 0.251  | 0.307  |  0.3887 |
|     4      | 0.2635 | 0.155  | 0.3168 | 0.3866 |  0.4676 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 17:02:33,466: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3337 | 0.2181 | 0.3828 | 0.4545 |  0.5548 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3336 | 0.2178 | 0.383  | 0.4548 |  0.5542 |
|     1      | 0.2501 | 0.1563 | 0.2806 | 0.3423 |  0.4356 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3332 | 0.2171 | 0.3828 | 0.4555 |  0.5542 |
|     1      | 0.2501 | 0.1564 | 0.2805 | 0.3424 |  0.4358 |
|     2      | 0.2322 | 0.1408 | 0.2663 | 0.3229 |  0.4061 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3333 | 0.2169 | 0.3832 | 0.4553 |  0.5537 |
|     1      | 0.2502 | 0.1565 | 0.2808 | 0.3426 |  0.4359 |
|     2      | 0.2324 | 0.1411 | 0.2666 | 0.3226 |  0.4059 |
|     3      | 0.2204 | 0.1325 | 0.2505 | 0.3061 |  0.3882 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3336 | 0.2176 | 0.3825 | 0.4555 |  0.5536 |
|     1      | 0.2507 | 0.157  | 0.2809 | 0.3428 |  0.4364 |
|     2      | 0.2328 | 0.1416 | 0.2671 | 0.3229 |  0.4063 |
|     3      | 0.2207 | 0.1327 | 0.251  | 0.307  |  0.3887 |
|     4      | 0.2635 | 0.155  | 0.3168 | 0.3866 |  0.4676 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 17:02:33,467: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 49.69652581214905  |   0.334   |    0.218     |    0.383     |     0.555     |
|    1     |  176.132465839386  |   0.283   |     0.18     |    0.321     |     0.482     |
|    2     | 178.18682646751404 |   0.263   |    0.165     |     0.3      |     0.453     |
|    3     | 172.51614570617676 |   0.252   |    0.156     |    0.287     |     0.435     |
|    4     | 108.82386779785156 |   0.254   |    0.157     |    0.291     |     0.441     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 17:02:33,467: Sum_Training_Time:685.3558316230774
2024-12-27 17:02:33,467: Every_Training_Time:[49.69652581214905, 176.132465839386, 178.18682646751404, 172.51614570617676, 108.82386779785156]
2024-12-27 17:02:33,467: Forward transfer: 0.043250000000000004 Backward transfer: 0.0003500000000000031
2024-12-27 17:03:07,007: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227170237/ENTITYentity_0.01_2048_4', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_2048_4', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_2048_4', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=4, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 17:03:14,485: Snapshot:0	Epoch:0	Loss:15.487	translation_Loss:15.487	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.5	Hits@10:44.43	Best:21.5
2024-12-27 17:03:18,152: Snapshot:0	Epoch:1	Loss:6.378	translation_Loss:6.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.6	Hits@10:53.86	Best:30.6
2024-12-27 17:03:21,828: Snapshot:0	Epoch:2	Loss:2.563	translation_Loss:2.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.32	Hits@10:55.36	Best:32.32
2024-12-27 17:03:25,502: Snapshot:0	Epoch:3	Loss:1.286	translation_Loss:1.286	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.69	Hits@10:55.4	Best:32.69
2024-12-27 17:03:29,520: Snapshot:0	Epoch:4	Loss:0.814	translation_Loss:0.814	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.85	Hits@10:55.34	Best:32.85
2024-12-27 17:03:33,154: Snapshot:0	Epoch:5	Loss:0.605	translation_Loss:0.605	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.63	Hits@10:54.91	Best:32.85
2024-12-27 17:03:36,804: Snapshot:0	Epoch:6	Loss:0.506	translation_Loss:0.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.79	Hits@10:55.31	Best:32.85
2024-12-27 17:03:40,440: Snapshot:0	Epoch:7	Loss:0.433	translation_Loss:0.433	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.3	Hits@10:54.31	Best:32.85
2024-12-27 17:03:44,093: Snapshot:0	Epoch:8	Loss:0.385	translation_Loss:0.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.38	Hits@10:54.52	Best:32.85
2024-12-27 17:03:47,745: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 32.85
2024-12-27 17:03:47,745: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.355 MRR:32.04 Best Results: 32.85
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 17:03:47,745: Snapshot:0	Epoch:9	Loss:0.355	translation_Loss:0.355	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.04	Hits@10:54.2	Best:32.85
2024-12-27 17:03:51,930: Snapshot:0	Epoch:10	Loss:14.328	translation_Loss:14.293	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.04	Hits@10:54.2	Best:32.85
2024-12-27 17:03:56,037: End of token training: 0 Epoch: 11 Loss:14.303 MRR:32.04 Best Results: 32.85
2024-12-27 17:03:56,038: Snapshot:0	Epoch:11	Loss:14.303	translation_Loss:14.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:32.04	Hits@10:54.2	Best:32.85
2024-12-27 17:03:56,275: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_4/0model_best.tar'
2024-12-27 17:03:57,644: 
+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.333 | 0.2168 | 0.3847 | 0.4552 |  0.5536 |
+------------+-------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:04:20,918: Snapshot:1	Epoch:0	Loss:88.389	translation_Loss:9.572	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:78.817                                                   	MRR:21.89	Hits@10:38.61	Best:21.89
2024-12-27 17:04:27,582: Snapshot:1	Epoch:1	Loss:3.76	translation_Loss:2.71	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.05                                                   	MRR:23.5	Hits@10:41.56	Best:23.5
2024-12-27 17:04:33,863: Snapshot:1	Epoch:2	Loss:1.886	translation_Loss:1.84	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.046                                                   	MRR:23.95	Hits@10:42.31	Best:23.95
2024-12-27 17:04:40,226: Snapshot:1	Epoch:3	Loss:1.623	translation_Loss:1.586	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.037                                                   	MRR:24.32	Hits@10:42.61	Best:24.32
2024-12-27 17:04:46,526: Snapshot:1	Epoch:4	Loss:1.512	translation_Loss:1.47	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.043                                                   	MRR:24.33	Hits@10:43.21	Best:24.33
2024-12-27 17:04:53,156: Snapshot:1	Epoch:5	Loss:1.428	translation_Loss:1.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.046                                                   	MRR:24.49	Hits@10:43.05	Best:24.49
2024-12-27 17:04:59,585: Snapshot:1	Epoch:6	Loss:1.37	translation_Loss:1.321	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.049                                                   	MRR:24.29	Hits@10:43.12	Best:24.49
2024-12-27 17:05:06,010: Snapshot:1	Epoch:7	Loss:1.339	translation_Loss:1.282	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.056                                                   	MRR:24.55	Hits@10:43.18	Best:24.55
2024-12-27 17:05:12,346: Snapshot:1	Epoch:8	Loss:1.301	translation_Loss:1.24	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.061                                                   	MRR:24.63	Hits@10:43.39	Best:24.63
2024-12-27 17:05:19,047: Snapshot:1	Epoch:9	Loss:1.266	translation_Loss:1.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.061                                                   	MRR:24.58	Hits@10:43.36	Best:24.63
2024-12-27 17:05:25,343: Snapshot:1	Epoch:10	Loss:1.239	translation_Loss:1.173	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.067                                                   	MRR:24.77	Hits@10:43.45	Best:24.77
2024-12-27 17:05:31,636: Snapshot:1	Epoch:11	Loss:1.216	translation_Loss:1.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.075                                                   	MRR:24.57	Hits@10:43.33	Best:24.77
2024-12-27 17:05:38,045: Snapshot:1	Epoch:12	Loss:1.194	translation_Loss:1.119	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.075                                                   	MRR:24.7	Hits@10:43.27	Best:24.77
2024-12-27 17:05:44,744: Snapshot:1	Epoch:13	Loss:1.177	translation_Loss:1.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.077                                                   	MRR:24.59	Hits@10:43.2	Best:24.77
2024-12-27 17:05:51,108: Snapshot:1	Epoch:14	Loss:1.172	translation_Loss:1.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.084                                                   	MRR:24.5	Hits@10:43.19	Best:24.77
2024-12-27 17:05:57,455: Early Stopping! Snapshot: 1 Epoch: 15 Best Results: 24.77
2024-12-27 17:05:57,455: Start to training tokens! Snapshot: 1 Epoch: 15 Loss:1.162 MRR:24.6 Best Results: 24.77
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 17:05:57,455: Snapshot:1	Epoch:15	Loss:1.162	translation_Loss:1.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:24.6	Hits@10:43.33	Best:24.77
2024-12-27 17:06:03,708: Snapshot:1	Epoch:16	Loss:23.398	translation_Loss:23.362	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.6	Hits@10:43.33	Best:24.77
2024-12-27 17:06:10,296: End of token training: 1 Epoch: 17 Loss:23.366 MRR:24.6 Best Results: 24.77
2024-12-27 17:06:10,296: Snapshot:1	Epoch:17	Loss:23.366	translation_Loss:23.366	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.6	Hits@10:43.33	Best:24.77
2024-12-27 17:06:10,521: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_4/1model_best.tar'
2024-12-27 17:06:14,113: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3331 | 0.2169 | 0.3849 | 0.4553 |  0.5535 |
|     1      | 0.2467 | 0.151  | 0.278  | 0.3418 |  0.4331 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:06:39,032: Snapshot:2	Epoch:0	Loss:85.532	translation_Loss:9.127	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:76.405                                                   	MRR:19.3	Hits@10:34.44	Best:19.3
2024-12-27 17:06:46,108: Snapshot:2	Epoch:1	Loss:3.575	translation_Loss:2.636	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.939                                                   	MRR:21.51	Hits@10:38.05	Best:21.51
2024-12-27 17:06:53,041: Snapshot:2	Epoch:2	Loss:1.973	translation_Loss:1.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.073                                                   	MRR:21.97	Hits@10:38.72	Best:21.97
2024-12-27 17:07:00,153: Snapshot:2	Epoch:3	Loss:1.746	translation_Loss:1.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.07                                                   	MRR:22.11	Hits@10:39.01	Best:22.11
2024-12-27 17:07:07,229: Snapshot:2	Epoch:4	Loss:1.63	translation_Loss:1.549	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.082                                                   	MRR:22.45	Hits@10:39.47	Best:22.45
2024-12-27 17:07:14,164: Snapshot:2	Epoch:5	Loss:1.569	translation_Loss:1.484	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:22.38	Hits@10:39.58	Best:22.45
2024-12-27 17:07:21,128: Snapshot:2	Epoch:6	Loss:1.516	translation_Loss:1.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:22.52	Hits@10:39.57	Best:22.52
2024-12-27 17:07:28,059: Snapshot:2	Epoch:7	Loss:1.482	translation_Loss:1.377	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.105                                                   	MRR:22.54	Hits@10:39.59	Best:22.54
2024-12-27 17:07:35,025: Snapshot:2	Epoch:8	Loss:1.445	translation_Loss:1.338	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:22.77	Hits@10:39.89	Best:22.77
2024-12-27 17:07:41,908: Snapshot:2	Epoch:9	Loss:1.416	translation_Loss:1.301	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.115                                                   	MRR:22.67	Hits@10:40.02	Best:22.77
2024-12-27 17:07:48,814: Snapshot:2	Epoch:10	Loss:1.396	translation_Loss:1.269	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:22.75	Hits@10:39.93	Best:22.77
2024-12-27 17:07:56,187: Snapshot:2	Epoch:11	Loss:1.381	translation_Loss:1.248	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.133                                                   	MRR:22.86	Hits@10:40.14	Best:22.86
2024-12-27 17:08:03,262: Snapshot:2	Epoch:12	Loss:1.345	translation_Loss:1.212	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.134                                                   	MRR:22.7	Hits@10:40.02	Best:22.86
2024-12-27 17:08:10,237: Snapshot:2	Epoch:13	Loss:1.353	translation_Loss:1.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.145                                                   	MRR:22.81	Hits@10:39.95	Best:22.86
2024-12-27 17:08:17,141: Snapshot:2	Epoch:14	Loss:1.338	translation_Loss:1.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:22.93	Hits@10:40.12	Best:22.93
2024-12-27 17:08:24,415: Snapshot:2	Epoch:15	Loss:1.336	translation_Loss:1.175	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:22.98	Hits@10:40.24	Best:22.98
2024-12-27 17:08:31,322: Snapshot:2	Epoch:16	Loss:1.331	translation_Loss:1.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:23.01	Hits@10:40.23	Best:23.01
2024-12-27 17:08:38,266: Snapshot:2	Epoch:17	Loss:1.327	translation_Loss:1.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.175                                                   	MRR:22.86	Hits@10:40.16	Best:23.01
2024-12-27 17:08:45,125: Snapshot:2	Epoch:18	Loss:1.314	translation_Loss:1.127	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:22.97	Hits@10:40.55	Best:23.01
2024-12-27 17:08:52,309: Snapshot:2	Epoch:19	Loss:1.328	translation_Loss:1.132	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:22.87	Hits@10:40.27	Best:23.01
2024-12-27 17:08:59,223: Snapshot:2	Epoch:20	Loss:1.309	translation_Loss:1.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:22.83	Hits@10:40.1	Best:23.01
2024-12-27 17:09:06,128: Early Stopping! Snapshot: 2 Epoch: 21 Best Results: 23.01
2024-12-27 17:09:06,128: Start to training tokens! Snapshot: 2 Epoch: 21 Loss:1.308 MRR:22.93 Best Results: 23.01
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 17:09:06,128: Snapshot:2	Epoch:21	Loss:1.308	translation_Loss:1.098	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.21                                                   	MRR:22.93	Hits@10:40.39	Best:23.01
2024-12-27 17:09:12,994: Snapshot:2	Epoch:22	Loss:23.809	translation_Loss:23.773	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.93	Hits@10:40.39	Best:23.01
2024-12-27 17:09:20,217: End of token training: 2 Epoch: 23 Loss:23.776 MRR:22.93 Best Results: 23.01
2024-12-27 17:09:20,217: Snapshot:2	Epoch:23	Loss:23.776	translation_Loss:23.776	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.93	Hits@10:40.39	Best:23.01
2024-12-27 17:09:20,436: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_4/2model_best.tar'
2024-12-27 17:09:26,761: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3329 | 0.2165 | 0.3842 | 0.4547 |  0.5537 |
|     1      | 0.2466 | 0.1508 | 0.2781 | 0.3416 |  0.4331 |
|     2      | 0.2319 | 0.1398 | 0.2659 | 0.3247 |  0.4074 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:09:51,558: Snapshot:3	Epoch:0	Loss:84.386	translation_Loss:8.316	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:76.07                                                   	MRR:18.58	Hits@10:33.82	Best:18.58
2024-12-27 17:09:58,617: Snapshot:3	Epoch:1	Loss:3.356	translation_Loss:2.232	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.124                                                   	MRR:20.65	Hits@10:37.23	Best:20.65
2024-12-27 17:10:05,732: Snapshot:3	Epoch:2	Loss:1.691	translation_Loss:1.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:21.11	Hits@10:37.85	Best:21.11
2024-12-27 17:10:12,971: Snapshot:3	Epoch:3	Loss:1.489	translation_Loss:1.403	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:21.19	Hits@10:38.06	Best:21.19
2024-12-27 17:10:19,981: Snapshot:3	Epoch:4	Loss:1.389	translation_Loss:1.301	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:21.48	Hits@10:38.39	Best:21.48
2024-12-27 17:10:26,982: Snapshot:3	Epoch:5	Loss:1.34	translation_Loss:1.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.104                                                   	MRR:21.33	Hits@10:38.46	Best:21.48
2024-12-27 17:10:33,969: Snapshot:3	Epoch:6	Loss:1.311	translation_Loss:1.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:21.53	Hits@10:38.74	Best:21.53
2024-12-27 17:10:40,939: Snapshot:3	Epoch:7	Loss:1.268	translation_Loss:1.154	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:21.48	Hits@10:38.53	Best:21.53
2024-12-27 17:10:47,923: Snapshot:3	Epoch:8	Loss:1.251	translation_Loss:1.124	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:21.61	Hits@10:38.63	Best:21.61
2024-12-27 17:10:55,401: Snapshot:3	Epoch:9	Loss:1.228	translation_Loss:1.094	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.133                                                   	MRR:21.91	Hits@10:39.0	Best:21.91
2024-12-27 17:11:02,507: Snapshot:3	Epoch:10	Loss:1.204	translation_Loss:1.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.137                                                   	MRR:21.68	Hits@10:38.89	Best:21.91
2024-12-27 17:11:09,430: Snapshot:3	Epoch:11	Loss:1.196	translation_Loss:1.051	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.145                                                   	MRR:21.83	Hits@10:39.1	Best:21.91
2024-12-27 17:11:16,472: Snapshot:3	Epoch:12	Loss:1.178	translation_Loss:1.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:21.85	Hits@10:39.0	Best:21.91
2024-12-27 17:11:23,938: Snapshot:3	Epoch:13	Loss:1.158	translation_Loss:0.998	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.16                                                   	MRR:21.95	Hits@10:39.02	Best:21.95
2024-12-27 17:11:30,954: Snapshot:3	Epoch:14	Loss:1.154	translation_Loss:0.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:21.97	Hits@10:39.3	Best:21.97
2024-12-27 17:11:38,106: Snapshot:3	Epoch:15	Loss:1.152	translation_Loss:0.983	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:21.95	Hits@10:39.35	Best:21.97
2024-12-27 17:11:45,154: Snapshot:3	Epoch:16	Loss:1.149	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.182                                                   	MRR:22.11	Hits@10:39.31	Best:22.11
2024-12-27 17:11:52,446: Snapshot:3	Epoch:17	Loss:1.152	translation_Loss:0.961	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.19                                                   	MRR:21.93	Hits@10:39.12	Best:22.11
2024-12-27 17:11:59,573: Snapshot:3	Epoch:18	Loss:1.141	translation_Loss:0.947	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:22.03	Hits@10:39.31	Best:22.11
2024-12-27 17:12:06,656: Snapshot:3	Epoch:19	Loss:1.141	translation_Loss:0.94	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:22.01	Hits@10:39.17	Best:22.11
2024-12-27 17:12:13,608: Snapshot:3	Epoch:20	Loss:1.148	translation_Loss:0.939	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:21.85	Hits@10:39.19	Best:22.11
2024-12-27 17:12:20,946: Early Stopping! Snapshot: 3 Epoch: 21 Best Results: 22.11
2024-12-27 17:12:20,947: Start to training tokens! Snapshot: 3 Epoch: 21 Loss:1.129 MRR:22.0 Best Results: 22.11
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 17:12:20,947: Snapshot:3	Epoch:21	Loss:1.129	translation_Loss:0.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.216                                                   	MRR:22.0	Hits@10:39.17	Best:22.11
2024-12-27 17:12:27,900: Snapshot:3	Epoch:22	Loss:21.446	translation_Loss:21.411	multi_layer_Loss:0.035	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.0	Hits@10:39.17	Best:22.11
2024-12-27 17:12:34,895: End of token training: 3 Epoch: 23 Loss:21.443 MRR:22.0 Best Results: 22.11
2024-12-27 17:12:34,895: Snapshot:3	Epoch:23	Loss:21.443	translation_Loss:21.443	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.0	Hits@10:39.17	Best:22.11
2024-12-27 17:12:35,127: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_4/3model_best.tar'
2024-12-27 17:12:44,476: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3328 | 0.2166 | 0.3841 | 0.4548 |  0.5535 |
|     1      | 0.2466 | 0.1509 | 0.2782 | 0.3414 |  0.4334 |
|     2      | 0.2318 | 0.1396 | 0.2661 | 0.3244 |  0.4071 |
|     3      | 0.2217 | 0.1331 | 0.2514 | 0.3098 |  0.3941 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:13:02,969: Snapshot:4	Epoch:0	Loss:76.285	translation_Loss:5.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:70.29                                                   	MRR:22.5	Hits@10:39.77	Best:22.5
2024-12-27 17:13:08,082: Snapshot:4	Epoch:1	Loss:5.16	translation_Loss:1.309	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.85                                                   	MRR:24.92	Hits@10:43.88	Best:24.92
2024-12-27 17:13:13,160: Snapshot:4	Epoch:2	Loss:1.018	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.26                                                   	MRR:25.72	Hits@10:45.11	Best:25.72
2024-12-27 17:13:18,623: Snapshot:4	Epoch:3	Loss:0.659	translation_Loss:0.604	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.055                                                   	MRR:25.98	Hits@10:45.26	Best:25.98
2024-12-27 17:13:23,583: Snapshot:4	Epoch:4	Loss:0.589	translation_Loss:0.548	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.041                                                   	MRR:25.88	Hits@10:45.93	Best:25.98
2024-12-27 17:13:28,644: Snapshot:4	Epoch:5	Loss:0.553	translation_Loss:0.51	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.043                                                   	MRR:25.87	Hits@10:46.04	Best:25.98
2024-12-27 17:13:33,605: Snapshot:4	Epoch:6	Loss:0.533	translation_Loss:0.487	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.046                                                   	MRR:25.84	Hits@10:46.04	Best:25.98
2024-12-27 17:13:38,675: Snapshot:4	Epoch:7	Loss:0.523	translation_Loss:0.472	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.051                                                   	MRR:26.07	Hits@10:45.8	Best:26.07
2024-12-27 17:13:43,806: Snapshot:4	Epoch:8	Loss:0.503	translation_Loss:0.447	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.057                                                   	MRR:26.09	Hits@10:46.14	Best:26.09
2024-12-27 17:13:49,174: Snapshot:4	Epoch:9	Loss:0.503	translation_Loss:0.446	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.057                                                   	MRR:26.07	Hits@10:46.14	Best:26.09
2024-12-27 17:13:54,174: Snapshot:4	Epoch:10	Loss:0.484	translation_Loss:0.426	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.058                                                   	MRR:25.88	Hits@10:46.2	Best:26.09
2024-12-27 17:13:59,238: Snapshot:4	Epoch:11	Loss:0.489	translation_Loss:0.43	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.059                                                   	MRR:26.16	Hits@10:46.37	Best:26.16
2024-12-27 17:14:04,322: Snapshot:4	Epoch:12	Loss:0.472	translation_Loss:0.412	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.06                                                   	MRR:26.41	Hits@10:46.09	Best:26.41
2024-12-27 17:14:09,311: Snapshot:4	Epoch:13	Loss:0.479	translation_Loss:0.415	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.064                                                   	MRR:26.41	Hits@10:46.47	Best:26.41
2024-12-27 17:14:14,325: Snapshot:4	Epoch:14	Loss:0.462	translation_Loss:0.395	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.067                                                   	MRR:26.26	Hits@10:46.43	Best:26.41
2024-12-27 17:14:19,676: Snapshot:4	Epoch:15	Loss:0.466	translation_Loss:0.395	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.071                                                   	MRR:26.36	Hits@10:46.52	Best:26.41
2024-12-27 17:14:24,670: Snapshot:4	Epoch:16	Loss:0.455	translation_Loss:0.381	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.074                                                   	MRR:26.21	Hits@10:46.39	Best:26.41
2024-12-27 17:14:29,667: Early Stopping! Snapshot: 4 Epoch: 17 Best Results: 26.41
2024-12-27 17:14:29,668: Start to training tokens! Snapshot: 4 Epoch: 17 Loss:0.46 MRR:26.16 Best Results: 26.41
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 17:14:29,668: Snapshot:4	Epoch:17	Loss:0.46	translation_Loss:0.383	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.077                                                   	MRR:26.16	Hits@10:46.39	Best:26.41
2024-12-27 17:14:34,665: Snapshot:4	Epoch:18	Loss:11.779	translation_Loss:11.743	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.16	Hits@10:46.39	Best:26.41
2024-12-27 17:14:39,672: End of token training: 4 Epoch: 19 Loss:11.719 MRR:26.16 Best Results: 26.41
2024-12-27 17:14:39,672: Snapshot:4	Epoch:19	Loss:11.719	translation_Loss:11.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.16	Hits@10:46.39	Best:26.41
2024-12-27 17:14:39,930: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_4/4model_best.tar'
2024-12-27 17:14:51,778: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3328 | 0.2166 | 0.3842 | 0.4548 |  0.5534 |
|     1      | 0.2467 | 0.1508 | 0.2782 | 0.3417 |  0.4333 |
|     2      | 0.2322 | 0.1402 | 0.2661 | 0.3247 |  0.4075 |
|     3      | 0.2218 | 0.1331 | 0.2513 | 0.3098 |  0.3941 |
|     4      | 0.263  | 0.1576 | 0.3102 | 0.3799 |  0.4672 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 17:14:51,780: Final Result:
[+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.333 | 0.2168 | 0.3847 | 0.4552 |  0.5536 |
+------------+-------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3331 | 0.2169 | 0.3849 | 0.4553 |  0.5535 |
|     1      | 0.2467 | 0.151  | 0.278  | 0.3418 |  0.4331 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3329 | 0.2165 | 0.3842 | 0.4547 |  0.5537 |
|     1      | 0.2466 | 0.1508 | 0.2781 | 0.3416 |  0.4331 |
|     2      | 0.2319 | 0.1398 | 0.2659 | 0.3247 |  0.4074 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3328 | 0.2166 | 0.3841 | 0.4548 |  0.5535 |
|     1      | 0.2466 | 0.1509 | 0.2782 | 0.3414 |  0.4334 |
|     2      | 0.2318 | 0.1396 | 0.2661 | 0.3244 |  0.4071 |
|     3      | 0.2217 | 0.1331 | 0.2514 | 0.3098 |  0.3941 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3328 | 0.2166 | 0.3842 | 0.4548 |  0.5534 |
|     1      | 0.2467 | 0.1508 | 0.2782 | 0.3417 |  0.4333 |
|     2      | 0.2322 | 0.1402 | 0.2661 | 0.3247 |  0.4075 |
|     3      | 0.2218 | 0.1331 | 0.2513 | 0.3098 |  0.3941 |
|     4      | 0.263  | 0.1576 | 0.3102 | 0.3799 |  0.4672 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 17:14:51,781: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     |  49.0300977230072  |   0.333   |    0.217     |    0.385     |     0.554     |
|    1     | 130.4172534942627  |   0.281   |    0.177     |     0.32     |      0.48     |
|    2     | 183.45992136001587 |   0.262   |    0.162     |    0.299     |     0.452     |
|    3     | 185.17339634895325 |   0.251   |    0.155     |    0.286     |     0.437     |
|    4     | 112.74291443824768 |   0.253   |    0.155     |     0.29     |     0.441     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 17:14:51,781: Sum_Training_Time:660.8235833644867
2024-12-27 17:14:51,781: Every_Training_Time:[49.0300977230072, 130.4172534942627, 183.45992136001587, 185.17339634895325, 112.74291443824768]
2024-12-27 17:14:51,781: Forward transfer: 0.04345 Backward transfer: 4.9999999999987554e-05
2024-12-27 17:15:25,748: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227171455/ENTITYentity_0.01_2048_6', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_2048_6', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_2048_6', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=6, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 17:15:33,265: Snapshot:0	Epoch:0	Loss:15.487	translation_Loss:15.487	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.49	Hits@10:44.43	Best:21.49
2024-12-27 17:15:37,009: Snapshot:0	Epoch:1	Loss:6.378	translation_Loss:6.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.58	Hits@10:53.9	Best:30.58
2024-12-27 17:15:40,753: Snapshot:0	Epoch:2	Loss:2.563	translation_Loss:2.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.34	Hits@10:55.45	Best:32.34
2024-12-27 17:15:44,498: Snapshot:0	Epoch:3	Loss:1.287	translation_Loss:1.287	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.71	Hits@10:55.37	Best:32.71
2024-12-27 17:15:48,577: Snapshot:0	Epoch:4	Loss:0.812	translation_Loss:0.812	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.84	Hits@10:55.29	Best:32.84
2024-12-27 17:15:52,273: Snapshot:0	Epoch:5	Loss:0.605	translation_Loss:0.605	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.59	Hits@10:54.97	Best:32.84
2024-12-27 17:15:56,013: Snapshot:0	Epoch:6	Loss:0.504	translation_Loss:0.504	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.6	Hits@10:55.07	Best:32.84
2024-12-27 17:15:59,749: Snapshot:0	Epoch:7	Loss:0.434	translation_Loss:0.434	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.26	Hits@10:54.67	Best:32.84
2024-12-27 17:16:03,429: Snapshot:0	Epoch:8	Loss:0.386	translation_Loss:0.386	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.3	Hits@10:54.64	Best:32.84
2024-12-27 17:16:07,140: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 32.84
2024-12-27 17:16:07,140: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.356 MRR:32.07 Best Results: 32.84
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 17:16:07,141: Snapshot:0	Epoch:9	Loss:0.356	translation_Loss:0.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.07	Hits@10:54.11	Best:32.84
2024-12-27 17:16:11,371: Snapshot:0	Epoch:10	Loss:14.309	translation_Loss:14.273	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.07	Hits@10:54.11	Best:32.84
2024-12-27 17:16:15,595: End of token training: 0 Epoch: 11 Loss:14.281 MRR:32.07 Best Results: 32.84
2024-12-27 17:16:15,596: Snapshot:0	Epoch:11	Loss:14.281	translation_Loss:14.28	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:32.07	Hits@10:54.11	Best:32.84
2024-12-27 17:16:15,828: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_6/0model_best.tar'
2024-12-27 17:16:17,133: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3342 | 0.2191 | 0.3825 | 0.4569 |  0.5563 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:16:40,538: Snapshot:1	Epoch:0	Loss:127.988	translation_Loss:9.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:118.421                                                   	MRR:21.83	Hits@10:38.5	Best:21.83
2024-12-27 17:16:47,271: Snapshot:1	Epoch:1	Loss:4.261	translation_Loss:2.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.55                                                   	MRR:23.57	Hits@10:41.59	Best:23.57
2024-12-27 17:16:53,718: Snapshot:1	Epoch:2	Loss:1.885	translation_Loss:1.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.041                                                   	MRR:23.92	Hits@10:42.08	Best:23.92
2024-12-27 17:17:00,254: Snapshot:1	Epoch:3	Loss:1.616	translation_Loss:1.591	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.025                                                   	MRR:24.38	Hits@10:42.6	Best:24.38
2024-12-27 17:17:06,625: Snapshot:1	Epoch:4	Loss:1.503	translation_Loss:1.474	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.029                                                   	MRR:24.41	Hits@10:42.82	Best:24.41
2024-12-27 17:17:13,446: Snapshot:1	Epoch:5	Loss:1.421	translation_Loss:1.389	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.031                                                   	MRR:24.47	Hits@10:43.07	Best:24.47
2024-12-27 17:17:19,911: Snapshot:1	Epoch:6	Loss:1.354	translation_Loss:1.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.033                                                   	MRR:24.48	Hits@10:43.22	Best:24.48
2024-12-27 17:17:26,342: Snapshot:1	Epoch:7	Loss:1.325	translation_Loss:1.286	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.038                                                   	MRR:24.66	Hits@10:43.26	Best:24.66
2024-12-27 17:17:32,707: Snapshot:1	Epoch:8	Loss:1.287	translation_Loss:1.246	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.041                                                   	MRR:24.69	Hits@10:43.33	Best:24.69
2024-12-27 17:17:39,453: Snapshot:1	Epoch:9	Loss:1.249	translation_Loss:1.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.041                                                   	MRR:24.77	Hits@10:43.32	Best:24.77
2024-12-27 17:17:45,867: Snapshot:1	Epoch:10	Loss:1.218	translation_Loss:1.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.047                                                   	MRR:24.82	Hits@10:43.55	Best:24.82
2024-12-27 17:17:52,340: Snapshot:1	Epoch:11	Loss:1.197	translation_Loss:1.145	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.052                                                   	MRR:24.78	Hits@10:43.29	Best:24.82
2024-12-27 17:17:58,798: Snapshot:1	Epoch:12	Loss:1.172	translation_Loss:1.121	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.051                                                   	MRR:24.84	Hits@10:43.51	Best:24.84
2024-12-27 17:18:05,553: Snapshot:1	Epoch:13	Loss:1.156	translation_Loss:1.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.053                                                   	MRR:24.8	Hits@10:43.24	Best:24.84
2024-12-27 17:18:11,912: Snapshot:1	Epoch:14	Loss:1.148	translation_Loss:1.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.059                                                   	MRR:24.6	Hits@10:43.32	Best:24.84
2024-12-27 17:18:18,285: Snapshot:1	Epoch:15	Loss:1.135	translation_Loss:1.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.064                                                   	MRR:24.71	Hits@10:43.27	Best:24.84
2024-12-27 17:18:24,638: Snapshot:1	Epoch:16	Loss:1.136	translation_Loss:1.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.066                                                   	MRR:24.82	Hits@10:43.34	Best:24.84
2024-12-27 17:18:31,356: Snapshot:1	Epoch:17	Loss:1.123	translation_Loss:1.056	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.067                                                   	MRR:24.94	Hits@10:43.63	Best:24.94
2024-12-27 17:18:37,879: Snapshot:1	Epoch:18	Loss:1.103	translation_Loss:1.031	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.072                                                   	MRR:24.84	Hits@10:43.33	Best:24.94
2024-12-27 17:18:44,245: Snapshot:1	Epoch:19	Loss:1.119	translation_Loss:1.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.081                                                   	MRR:24.82	Hits@10:43.4	Best:24.94
2024-12-27 17:18:50,595: Snapshot:1	Epoch:20	Loss:1.106	translation_Loss:1.022	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.084                                                   	MRR:24.87	Hits@10:43.42	Best:24.94
2024-12-27 17:18:57,361: Snapshot:1	Epoch:21	Loss:1.084	translation_Loss:0.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:24.9	Hits@10:43.49	Best:24.94
2024-12-27 17:19:03,703: Early Stopping! Snapshot: 1 Epoch: 22 Best Results: 24.94
2024-12-27 17:19:03,703: Start to training tokens! Snapshot: 1 Epoch: 22 Loss:1.088 MRR:24.92 Best Results: 24.94
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 17:19:03,703: Snapshot:1	Epoch:22	Loss:1.088	translation_Loss:0.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:24.92	Hits@10:43.6	Best:24.94
2024-12-27 17:19:10,063: Snapshot:1	Epoch:23	Loss:23.425	translation_Loss:23.387	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.92	Hits@10:43.6	Best:24.94
2024-12-27 17:19:16,431: End of token training: 1 Epoch: 24 Loss:23.392 MRR:24.92 Best Results: 24.94
2024-12-27 17:19:16,432: Snapshot:1	Epoch:24	Loss:23.392	translation_Loss:23.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.92	Hits@10:43.6	Best:24.94
2024-12-27 17:19:16,710: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_6/1model_best.tar'
2024-12-27 17:19:20,411: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3342 | 0.2191 | 0.3825 | 0.4573 |  0.556  |
|     1      | 0.2495 | 0.1554 | 0.2782 | 0.343  |  0.4335 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:19:44,940: Snapshot:2	Epoch:0	Loss:123.838	translation_Loss:9.13	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:114.708                                                   	MRR:19.26	Hits@10:34.02	Best:19.26
2024-12-27 17:19:51,941: Snapshot:2	Epoch:1	Loss:3.976	translation_Loss:2.621	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.355                                                   	MRR:21.54	Hits@10:37.76	Best:21.54
2024-12-27 17:19:59,303: Snapshot:2	Epoch:2	Loss:1.94	translation_Loss:1.885	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.055                                                   	MRR:21.86	Hits@10:38.55	Best:21.86
2024-12-27 17:20:06,458: Snapshot:2	Epoch:3	Loss:1.697	translation_Loss:1.653	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.044                                                   	MRR:22.27	Hits@10:39.07	Best:22.27
2024-12-27 17:20:13,614: Snapshot:2	Epoch:4	Loss:1.592	translation_Loss:1.54	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.051                                                   	MRR:22.3	Hits@10:39.38	Best:22.3
2024-12-27 17:20:20,631: Snapshot:2	Epoch:5	Loss:1.524	translation_Loss:1.47	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.054                                                   	MRR:22.49	Hits@10:39.54	Best:22.49
2024-12-27 17:20:27,967: Snapshot:2	Epoch:6	Loss:1.475	translation_Loss:1.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.061                                                   	MRR:22.7	Hits@10:39.56	Best:22.7
2024-12-27 17:20:34,895: Snapshot:2	Epoch:7	Loss:1.438	translation_Loss:1.369	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.069                                                   	MRR:22.7	Hits@10:39.66	Best:22.7
2024-12-27 17:20:41,881: Snapshot:2	Epoch:8	Loss:1.399	translation_Loss:1.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.067                                                   	MRR:22.82	Hits@10:39.73	Best:22.82
2024-12-27 17:20:48,869: Snapshot:2	Epoch:9	Loss:1.372	translation_Loss:1.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.074                                                   	MRR:22.77	Hits@10:39.75	Best:22.82
2024-12-27 17:20:56,217: Snapshot:2	Epoch:10	Loss:1.354	translation_Loss:1.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.084                                                   	MRR:22.85	Hits@10:39.95	Best:22.85
2024-12-27 17:21:03,200: Snapshot:2	Epoch:11	Loss:1.312	translation_Loss:1.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:22.81	Hits@10:40.01	Best:22.85
2024-12-27 17:21:10,255: Snapshot:2	Epoch:12	Loss:1.302	translation_Loss:1.215	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:22.97	Hits@10:40.15	Best:22.97
2024-12-27 17:21:17,306: Snapshot:2	Epoch:13	Loss:1.304	translation_Loss:1.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:22.91	Hits@10:39.88	Best:22.97
2024-12-27 17:21:24,748: Snapshot:2	Epoch:14	Loss:1.287	translation_Loss:1.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:23.07	Hits@10:40.17	Best:23.07
2024-12-27 17:21:31,792: Snapshot:2	Epoch:15	Loss:1.269	translation_Loss:1.163	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.105                                                   	MRR:23.05	Hits@10:40.23	Best:23.07
2024-12-27 17:21:38,751: Snapshot:2	Epoch:16	Loss:1.26	translation_Loss:1.151	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:22.79	Hits@10:40.1	Best:23.07
2024-12-27 17:21:45,737: Snapshot:2	Epoch:17	Loss:1.272	translation_Loss:1.154	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.119                                                   	MRR:23.0	Hits@10:40.13	Best:23.07
2024-12-27 17:21:53,065: Snapshot:2	Epoch:18	Loss:1.243	translation_Loss:1.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.128                                                   	MRR:22.91	Hits@10:40.08	Best:23.07
2024-12-27 17:22:00,102: Snapshot:2	Epoch:19	Loss:1.261	translation_Loss:1.129	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.132                                                   	MRR:23.13	Hits@10:40.56	Best:23.13
2024-12-27 17:22:07,062: Snapshot:2	Epoch:20	Loss:1.243	translation_Loss:1.106	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.137                                                   	MRR:23.13	Hits@10:40.38	Best:23.13
2024-12-27 17:22:14,005: Snapshot:2	Epoch:21	Loss:1.259	translation_Loss:1.115	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.144                                                   	MRR:23.08	Hits@10:40.33	Best:23.13
2024-12-27 17:22:21,318: Snapshot:2	Epoch:22	Loss:1.244	translation_Loss:1.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:23.21	Hits@10:40.34	Best:23.21
2024-12-27 17:22:28,288: Snapshot:2	Epoch:23	Loss:1.246	translation_Loss:1.085	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:23.07	Hits@10:40.2	Best:23.21
2024-12-27 17:22:35,220: Snapshot:2	Epoch:24	Loss:1.247	translation_Loss:1.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:23.02	Hits@10:40.37	Best:23.21
2024-12-27 17:22:42,185: Snapshot:2	Epoch:25	Loss:1.25	translation_Loss:1.074	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.176                                                   	MRR:23.08	Hits@10:40.36	Best:23.21
2024-12-27 17:22:49,510: Snapshot:2	Epoch:26	Loss:1.273	translation_Loss:1.081	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.191                                                   	MRR:23.11	Hits@10:40.46	Best:23.21
2024-12-27 17:22:56,510: Early Stopping! Snapshot: 2 Epoch: 27 Best Results: 23.21
2024-12-27 17:22:56,510: Start to training tokens! Snapshot: 2 Epoch: 27 Loss:1.254 MRR:23.17 Best Results: 23.21
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 17:22:56,510: Snapshot:2	Epoch:27	Loss:1.254	translation_Loss:1.058	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:23.17	Hits@10:40.32	Best:23.21
2024-12-27 17:23:03,482: Snapshot:2	Epoch:28	Loss:23.858	translation_Loss:23.821	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.17	Hits@10:40.32	Best:23.21
2024-12-27 17:23:10,418: End of token training: 2 Epoch: 29 Loss:23.811 MRR:23.17 Best Results: 23.21
2024-12-27 17:23:10,418: Snapshot:2	Epoch:29	Loss:23.811	translation_Loss:23.811	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.17	Hits@10:40.32	Best:23.21
2024-12-27 17:23:10,631: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_6/2model_best.tar'
2024-12-27 17:23:17,000: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.334  | 0.2187 | 0.3827 | 0.4572 |  0.5563 |
|     1      | 0.2494 | 0.1552 | 0.2781 | 0.3431 |  0.4339 |
|     2      | 0.2343 | 0.1435 | 0.2679 | 0.3243 |  0.4073 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:23:42,076: Snapshot:3	Epoch:0	Loss:122.503	translation_Loss:8.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:114.208                                                   	MRR:18.76	Hits@10:33.13	Best:18.76
2024-12-27 17:23:49,199: Snapshot:3	Epoch:1	Loss:3.872	translation_Loss:2.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.627                                                   	MRR:20.61	Hits@10:36.91	Best:20.61
2024-12-27 17:23:56,315: Snapshot:3	Epoch:2	Loss:1.652	translation_Loss:1.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.067                                                   	MRR:21.01	Hits@10:37.67	Best:21.01
2024-12-27 17:24:03,440: Snapshot:3	Epoch:3	Loss:1.444	translation_Loss:1.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.054                                                   	MRR:21.26	Hits@10:37.94	Best:21.26
2024-12-27 17:24:10,525: Snapshot:3	Epoch:4	Loss:1.354	translation_Loss:1.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.056                                                   	MRR:21.4	Hits@10:38.23	Best:21.4
2024-12-27 17:24:17,647: Snapshot:3	Epoch:5	Loss:1.305	translation_Loss:1.239	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.066                                                   	MRR:21.51	Hits@10:38.33	Best:21.51
2024-12-27 17:24:24,721: Snapshot:3	Epoch:6	Loss:1.258	translation_Loss:1.19	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.068                                                   	MRR:21.66	Hits@10:38.61	Best:21.66
2024-12-27 17:24:31,837: Snapshot:3	Epoch:7	Loss:1.221	translation_Loss:1.149	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.072                                                   	MRR:21.66	Hits@10:38.71	Best:21.66
2024-12-27 17:24:38,913: Snapshot:3	Epoch:8	Loss:1.2	translation_Loss:1.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.083                                                   	MRR:21.87	Hits@10:38.7	Best:21.87
2024-12-27 17:24:46,382: Snapshot:3	Epoch:9	Loss:1.179	translation_Loss:1.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:21.89	Hits@10:38.92	Best:21.89
2024-12-27 17:24:53,411: Snapshot:3	Epoch:10	Loss:1.146	translation_Loss:1.061	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:21.72	Hits@10:38.76	Best:21.89
2024-12-27 17:25:00,645: Snapshot:3	Epoch:11	Loss:1.131	translation_Loss:1.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:21.65	Hits@10:38.71	Best:21.89
2024-12-27 17:25:07,878: Snapshot:3	Epoch:12	Loss:1.125	translation_Loss:1.022	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:21.86	Hits@10:38.87	Best:21.89
2024-12-27 17:25:15,354: Snapshot:3	Epoch:13	Loss:1.119	translation_Loss:1.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:21.73	Hits@10:38.77	Best:21.89
2024-12-27 17:25:22,409: Snapshot:3	Epoch:14	Loss:1.098	translation_Loss:0.99	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:22.08	Hits@10:39.13	Best:22.08
2024-12-27 17:25:29,440: Snapshot:3	Epoch:15	Loss:1.107	translation_Loss:0.992	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.115                                                   	MRR:21.91	Hits@10:39.19	Best:22.08
2024-12-27 17:25:36,490: Snapshot:3	Epoch:16	Loss:1.09	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.123                                                   	MRR:21.8	Hits@10:39.19	Best:22.08
2024-12-27 17:25:43,857: Snapshot:3	Epoch:17	Loss:1.081	translation_Loss:0.952	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.128                                                   	MRR:21.9	Hits@10:39.0	Best:22.08
2024-12-27 17:25:50,898: Snapshot:3	Epoch:18	Loss:1.076	translation_Loss:0.943	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.133                                                   	MRR:21.91	Hits@10:39.46	Best:22.08
2024-12-27 17:25:57,942: Early Stopping! Snapshot: 3 Epoch: 19 Best Results: 22.08
2024-12-27 17:25:57,943: Start to training tokens! Snapshot: 3 Epoch: 19 Loss:1.078 MRR:22.05 Best Results: 22.08
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 17:25:57,943: Snapshot:3	Epoch:19	Loss:1.078	translation_Loss:0.942	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.137                                                   	MRR:22.05	Hits@10:39.13	Best:22.08
2024-12-27 17:26:04,982: Snapshot:3	Epoch:20	Loss:21.465	translation_Loss:21.429	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.05	Hits@10:39.13	Best:22.08
2024-12-27 17:26:12,410: End of token training: 3 Epoch: 21 Loss:21.426 MRR:22.05 Best Results: 22.08
2024-12-27 17:26:12,411: Snapshot:3	Epoch:21	Loss:21.426	translation_Loss:21.425	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.05	Hits@10:39.13	Best:22.08
2024-12-27 17:26:12,632: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_6/3model_best.tar'
2024-12-27 17:26:21,717: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.334  | 0.2188 | 0.3827 | 0.457  |  0.5566 |
|     1      | 0.2495 | 0.1553 | 0.2783 | 0.3429 |  0.4339 |
|     2      | 0.2344 | 0.1437 | 0.268  | 0.3246 |  0.4076 |
|     3      | 0.2194 | 0.1313 | 0.2493 | 0.305  |  0.3878 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:26:40,711: Snapshot:4	Epoch:0	Loss:111.437	translation_Loss:5.993	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:105.444                                                   	MRR:22.38	Hits@10:40.19	Best:22.38
2024-12-27 17:26:45,817: Snapshot:4	Epoch:1	Loss:7.038	translation_Loss:1.3	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.738                                                   	MRR:25.15	Hits@10:44.08	Best:25.15
2024-12-27 17:26:50,960: Snapshot:4	Epoch:2	Loss:1.11	translation_Loss:0.754	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.356                                                   	MRR:25.72	Hits@10:45.27	Best:25.72
2024-12-27 17:26:56,178: Snapshot:4	Epoch:3	Loss:0.648	translation_Loss:0.602	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.047                                                   	MRR:25.86	Hits@10:45.73	Best:25.86
2024-12-27 17:27:01,310: Snapshot:4	Epoch:4	Loss:0.568	translation_Loss:0.54	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.028                                                   	MRR:25.86	Hits@10:45.94	Best:25.86
2024-12-27 17:27:06,440: Snapshot:4	Epoch:5	Loss:0.529	translation_Loss:0.501	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.028                                                   	MRR:25.91	Hits@10:45.67	Best:25.91
2024-12-27 17:27:11,572: Snapshot:4	Epoch:6	Loss:0.525	translation_Loss:0.494	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.031                                                   	MRR:25.99	Hits@10:45.94	Best:25.99
2024-12-27 17:27:16,736: Snapshot:4	Epoch:7	Loss:0.499	translation_Loss:0.464	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.034                                                   	MRR:26.08	Hits@10:46.07	Best:26.08
2024-12-27 17:27:21,934: Snapshot:4	Epoch:8	Loss:0.497	translation_Loss:0.459	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.038                                                   	MRR:26.28	Hits@10:46.23	Best:26.28
2024-12-27 17:27:27,017: Snapshot:4	Epoch:9	Loss:0.477	translation_Loss:0.439	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.038                                                   	MRR:26.16	Hits@10:46.21	Best:26.28
2024-12-27 17:27:32,067: Snapshot:4	Epoch:10	Loss:0.47	translation_Loss:0.433	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.038                                                   	MRR:26.15	Hits@10:46.15	Best:26.28
2024-12-27 17:27:37,560: Snapshot:4	Epoch:11	Loss:0.463	translation_Loss:0.424	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.039                                                   	MRR:26.28	Hits@10:46.24	Best:26.28
2024-12-27 17:27:42,674: Snapshot:4	Epoch:12	Loss:0.451	translation_Loss:0.411	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.04                                                   	MRR:26.29	Hits@10:46.23	Best:26.29
2024-12-27 17:27:47,715: Snapshot:4	Epoch:13	Loss:0.451	translation_Loss:0.408	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.043                                                   	MRR:26.22	Hits@10:46.25	Best:26.29
2024-12-27 17:27:52,880: Snapshot:4	Epoch:14	Loss:0.452	translation_Loss:0.405	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.047                                                   	MRR:26.37	Hits@10:46.37	Best:26.37
2024-12-27 17:27:58,010: Snapshot:4	Epoch:15	Loss:0.451	translation_Loss:0.4	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.05                                                   	MRR:26.36	Hits@10:46.32	Best:26.37
2024-12-27 17:28:03,092: Snapshot:4	Epoch:16	Loss:0.44	translation_Loss:0.387	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.053                                                   	MRR:26.16	Hits@10:46.45	Best:26.37
2024-12-27 17:28:08,483: Snapshot:4	Epoch:17	Loss:0.439	translation_Loss:0.386	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.053                                                   	MRR:26.04	Hits@10:46.57	Best:26.37
2024-12-27 17:28:13,536: Snapshot:4	Epoch:18	Loss:0.427	translation_Loss:0.375	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.052                                                   	MRR:26.09	Hits@10:46.41	Best:26.37
2024-12-27 17:28:18,622: Early Stopping! Snapshot: 4 Epoch: 19 Best Results: 26.37
2024-12-27 17:28:18,622: Start to training tokens! Snapshot: 4 Epoch: 19 Loss:0.429 MRR:26.17 Best Results: 26.37
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 17:28:18,623: Snapshot:4	Epoch:19	Loss:0.429	translation_Loss:0.376	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.053                                                   	MRR:26.17	Hits@10:46.6	Best:26.37
2024-12-27 17:28:23,673: Snapshot:4	Epoch:20	Loss:11.775	translation_Loss:11.738	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.17	Hits@10:46.6	Best:26.37
2024-12-27 17:28:28,702: End of token training: 4 Epoch: 21 Loss:11.726 MRR:26.17 Best Results: 26.37
2024-12-27 17:28:28,702: Snapshot:4	Epoch:21	Loss:11.726	translation_Loss:11.725	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.17	Hits@10:46.6	Best:26.37
2024-12-27 17:28:28,986: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_6/4model_best.tar'
2024-12-27 17:28:40,909: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.334  | 0.2187 | 0.3824 | 0.4572 |  0.5567 |
|     1      | 0.2496 | 0.1553 | 0.2783 | 0.3431 |  0.434  |
|     2      | 0.2344 | 0.1437 | 0.2677 | 0.3246 |  0.4075 |
|     3      | 0.2195 | 0.1314 | 0.2494 | 0.3047 |  0.3877 |
|     4      | 0.2644 | 0.1586 | 0.3137 | 0.3825 |  0.4668 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 17:28:40,911: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3342 | 0.2191 | 0.3825 | 0.4569 |  0.5563 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3342 | 0.2191 | 0.3825 | 0.4573 |  0.556  |
|     1      | 0.2495 | 0.1554 | 0.2782 | 0.343  |  0.4335 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.334  | 0.2187 | 0.3827 | 0.4572 |  0.5563 |
|     1      | 0.2494 | 0.1552 | 0.2781 | 0.3431 |  0.4339 |
|     2      | 0.2343 | 0.1435 | 0.2679 | 0.3243 |  0.4073 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.334  | 0.2188 | 0.3827 | 0.457  |  0.5566 |
|     1      | 0.2495 | 0.1553 | 0.2783 | 0.3429 |  0.4339 |
|     2      | 0.2344 | 0.1437 | 0.268  | 0.3246 |  0.4076 |
|     3      | 0.2194 | 0.1313 | 0.2493 | 0.305  |  0.3878 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.334  | 0.2187 | 0.3824 | 0.4572 |  0.5567 |
|     1      | 0.2496 | 0.1553 | 0.2783 | 0.3431 |  0.434  |
|     2      | 0.2344 | 0.1437 | 0.2677 | 0.3246 |  0.4075 |
|     3      | 0.2195 | 0.1314 | 0.2494 | 0.3047 |  0.3877 |
|     4      | 0.2644 | 0.1586 | 0.3137 | 0.3825 |  0.4668 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 17:28:40,912: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 49.84673500061035  |   0.334   |    0.219     |    0.383     |     0.556     |
|    1     | 177.08975410461426 |   0.283   |     0.18     |    0.319     |     0.481     |
|    2     | 227.33673548698425 |   0.264   |    0.166     |    0.299     |     0.453     |
|    3     | 172.4248161315918  |   0.252   |    0.157     |    0.286     |     0.436     |
|    4     | 124.27656245231628 |   0.254   |    0.157     |     0.29     |     0.441     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 17:28:40,912: Sum_Training_Time:750.974603176117
2024-12-27 17:28:40,912: Every_Training_Time:[49.84673500061035, 177.08975410461426, 227.33673548698425, 172.4248161315918, 124.27656245231628]
2024-12-27 17:28:40,912: Forward transfer: 0.043475 Backward transfer: 2.4999999999997247e-05
2024-12-27 17:29:14,781: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227172844/ENTITYentity_0.01_2048_8', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_2048_8', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_2048_8', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=8, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 17:29:22,301: Snapshot:0	Epoch:0	Loss:15.487	translation_Loss:15.487	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.49	Hits@10:44.43	Best:21.49
2024-12-27 17:29:26,033: Snapshot:0	Epoch:1	Loss:6.378	translation_Loss:6.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.62	Hits@10:53.85	Best:30.62
2024-12-27 17:29:29,881: Snapshot:0	Epoch:2	Loss:2.564	translation_Loss:2.564	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.4	Hits@10:55.55	Best:32.4
2024-12-27 17:29:33,611: Snapshot:0	Epoch:3	Loss:1.286	translation_Loss:1.286	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.63	Hits@10:55.29	Best:32.63
2024-12-27 17:29:37,750: Snapshot:0	Epoch:4	Loss:0.812	translation_Loss:0.812	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.83	Hits@10:55.23	Best:32.83
2024-12-27 17:29:41,503: Snapshot:0	Epoch:5	Loss:0.604	translation_Loss:0.604	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.63	Hits@10:54.73	Best:32.83
2024-12-27 17:29:45,269: Snapshot:0	Epoch:6	Loss:0.505	translation_Loss:0.505	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.68	Hits@10:54.97	Best:32.83
2024-12-27 17:29:48,993: Snapshot:0	Epoch:7	Loss:0.435	translation_Loss:0.435	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.36	Hits@10:54.66	Best:32.83
2024-12-27 17:29:52,697: Snapshot:0	Epoch:8	Loss:0.384	translation_Loss:0.384	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.25	Hits@10:54.59	Best:32.83
2024-12-27 17:29:56,411: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 32.83
2024-12-27 17:29:56,411: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.355 MRR:31.94 Best Results: 32.83
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 17:29:56,411: Snapshot:0	Epoch:9	Loss:0.355	translation_Loss:0.355	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.94	Hits@10:54.25	Best:32.83
2024-12-27 17:30:00,658: Snapshot:0	Epoch:10	Loss:14.318	translation_Loss:14.281	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.94	Hits@10:54.25	Best:32.83
2024-12-27 17:30:05,006: End of token training: 0 Epoch: 11 Loss:14.291 MRR:31.94 Best Results: 32.83
2024-12-27 17:30:05,007: Snapshot:0	Epoch:11	Loss:14.291	translation_Loss:14.291	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.94	Hits@10:54.25	Best:32.83
2024-12-27 17:30:05,245: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_8/0model_best.tar'
2024-12-27 17:30:06,641: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3332 | 0.2171 | 0.3829 | 0.4546 |  0.5561 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:30:30,169: Snapshot:1	Epoch:0	Loss:167.495	translation_Loss:9.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:157.924                                                   	MRR:21.85	Hits@10:38.47	Best:21.85
2024-12-27 17:30:36,873: Snapshot:1	Epoch:1	Loss:4.765	translation_Loss:2.712	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.053                                                   	MRR:23.52	Hits@10:41.36	Best:23.52
2024-12-27 17:30:43,286: Snapshot:1	Epoch:2	Loss:1.883	translation_Loss:1.841	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.042                                                   	MRR:23.91	Hits@10:42.1	Best:23.91
2024-12-27 17:30:49,692: Snapshot:1	Epoch:3	Loss:1.607	translation_Loss:1.588	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.019                                                   	MRR:24.25	Hits@10:42.6	Best:24.25
2024-12-27 17:30:56,134: Snapshot:1	Epoch:4	Loss:1.495	translation_Loss:1.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.022                                                   	MRR:24.22	Hits@10:42.77	Best:24.25
2024-12-27 17:31:02,980: Snapshot:1	Epoch:5	Loss:1.41	translation_Loss:1.387	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.023                                                   	MRR:24.55	Hits@10:43.07	Best:24.55
2024-12-27 17:31:09,369: Snapshot:1	Epoch:6	Loss:1.35	translation_Loss:1.325	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.025                                                   	MRR:24.51	Hits@10:42.96	Best:24.55
2024-12-27 17:31:15,752: Snapshot:1	Epoch:7	Loss:1.313	translation_Loss:1.284	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.029                                                   	MRR:24.45	Hits@10:42.99	Best:24.55
2024-12-27 17:31:22,239: Snapshot:1	Epoch:8	Loss:1.272	translation_Loss:1.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.031                                                   	MRR:24.59	Hits@10:43.29	Best:24.59
2024-12-27 17:31:29,086: Snapshot:1	Epoch:9	Loss:1.232	translation_Loss:1.201	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.031                                                   	MRR:24.63	Hits@10:43.13	Best:24.63
2024-12-27 17:31:35,515: Snapshot:1	Epoch:10	Loss:1.207	translation_Loss:1.171	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.035                                                   	MRR:24.71	Hits@10:43.25	Best:24.71
2024-12-27 17:31:41,902: Snapshot:1	Epoch:11	Loss:1.181	translation_Loss:1.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.039                                                   	MRR:24.5	Hits@10:43.29	Best:24.71
2024-12-27 17:31:48,318: Snapshot:1	Epoch:12	Loss:1.155	translation_Loss:1.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.038                                                   	MRR:24.52	Hits@10:43.21	Best:24.71
2024-12-27 17:31:55,102: Snapshot:1	Epoch:13	Loss:1.144	translation_Loss:1.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.04                                                   	MRR:24.65	Hits@10:43.16	Best:24.71
2024-12-27 17:32:01,515: Snapshot:1	Epoch:14	Loss:1.136	translation_Loss:1.091	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.045                                                   	MRR:24.48	Hits@10:43.13	Best:24.71
2024-12-27 17:32:07,906: Early Stopping! Snapshot: 1 Epoch: 15 Best Results: 24.71
2024-12-27 17:32:07,907: Start to training tokens! Snapshot: 1 Epoch: 15 Loss:1.119 MRR:24.54 Best Results: 24.71
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 17:32:07,907: Snapshot:1	Epoch:15	Loss:1.119	translation_Loss:1.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.049                                                   	MRR:24.54	Hits@10:42.86	Best:24.71
2024-12-27 17:32:14,327: Snapshot:1	Epoch:16	Loss:23.433	translation_Loss:23.395	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.54	Hits@10:42.86	Best:24.71
2024-12-27 17:32:21,000: End of token training: 1 Epoch: 17 Loss:23.401 MRR:24.54 Best Results: 24.71
2024-12-27 17:32:21,000: Snapshot:1	Epoch:17	Loss:23.401	translation_Loss:23.401	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.54	Hits@10:42.86	Best:24.71
2024-12-27 17:32:21,232: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_8/1model_best.tar'
2024-12-27 17:32:25,418: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3332 | 0.2172 | 0.3829 | 0.4546 |  0.5563 |
|     1      | 0.2465 | 0.1531 | 0.2759 | 0.3383 |  0.4296 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:32:50,831: Snapshot:2	Epoch:0	Loss:162.062	translation_Loss:9.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:152.92                                                   	MRR:19.17	Hits@10:34.07	Best:19.17
2024-12-27 17:32:57,924: Snapshot:2	Epoch:1	Loss:4.423	translation_Loss:2.636	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.787                                                   	MRR:21.61	Hits@10:38.13	Best:21.61
2024-12-27 17:33:05,050: Snapshot:2	Epoch:2	Loss:1.952	translation_Loss:1.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.051                                                   	MRR:22.14	Hits@10:38.85	Best:22.14
2024-12-27 17:33:12,075: Snapshot:2	Epoch:3	Loss:1.716	translation_Loss:1.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.036                                                   	MRR:22.17	Hits@10:39.27	Best:22.17
2024-12-27 17:33:19,164: Snapshot:2	Epoch:4	Loss:1.593	translation_Loss:1.551	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.043                                                   	MRR:22.48	Hits@10:39.59	Best:22.48
2024-12-27 17:33:26,200: Snapshot:2	Epoch:5	Loss:1.526	translation_Loss:1.482	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.044                                                   	MRR:22.54	Hits@10:39.64	Best:22.54
2024-12-27 17:33:33,195: Snapshot:2	Epoch:6	Loss:1.469	translation_Loss:1.418	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.05                                                   	MRR:22.47	Hits@10:39.68	Best:22.54
2024-12-27 17:33:40,222: Snapshot:2	Epoch:7	Loss:1.431	translation_Loss:1.375	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.056                                                   	MRR:22.58	Hits@10:40.01	Best:22.58
2024-12-27 17:33:47,310: Snapshot:2	Epoch:8	Loss:1.389	translation_Loss:1.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.057                                                   	MRR:22.64	Hits@10:40.16	Best:22.64
2024-12-27 17:33:54,383: Snapshot:2	Epoch:9	Loss:1.363	translation_Loss:1.3	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.063                                                   	MRR:22.75	Hits@10:40.16	Best:22.75
2024-12-27 17:34:01,424: Snapshot:2	Epoch:10	Loss:1.339	translation_Loss:1.269	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.07                                                   	MRR:22.78	Hits@10:40.17	Best:22.78
2024-12-27 17:34:08,858: Snapshot:2	Epoch:11	Loss:1.315	translation_Loss:1.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.071                                                   	MRR:22.93	Hits@10:40.44	Best:22.93
2024-12-27 17:34:15,879: Snapshot:2	Epoch:12	Loss:1.288	translation_Loss:1.216	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.072                                                   	MRR:22.83	Hits@10:40.41	Best:22.93
2024-12-27 17:34:22,960: Snapshot:2	Epoch:13	Loss:1.286	translation_Loss:1.204	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.082                                                   	MRR:23.01	Hits@10:40.46	Best:23.01
2024-12-27 17:34:29,969: Snapshot:2	Epoch:14	Loss:1.269	translation_Loss:1.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:23.0	Hits@10:40.39	Best:23.01
2024-12-27 17:34:37,290: Snapshot:2	Epoch:15	Loss:1.266	translation_Loss:1.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:22.93	Hits@10:40.43	Best:23.01
2024-12-27 17:34:44,237: Snapshot:2	Epoch:16	Loss:1.253	translation_Loss:1.16	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:22.99	Hits@10:40.44	Best:23.01
2024-12-27 17:34:51,197: Snapshot:2	Epoch:17	Loss:1.255	translation_Loss:1.153	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:23.01	Hits@10:40.3	Best:23.01
2024-12-27 17:34:58,328: Early Stopping! Snapshot: 2 Epoch: 18 Best Results: 23.01
2024-12-27 17:34:58,328: Start to training tokens! Snapshot: 2 Epoch: 18 Loss:1.236 MRR:22.95 Best Results: 23.01
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 17:34:58,329: Snapshot:2	Epoch:18	Loss:1.236	translation_Loss:1.124	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.112                                                   	MRR:22.95	Hits@10:40.61	Best:23.01
2024-12-27 17:35:05,786: Snapshot:2	Epoch:19	Loss:23.883	translation_Loss:23.847	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.95	Hits@10:40.61	Best:23.01
2024-12-27 17:35:12,765: End of token training: 2 Epoch: 20 Loss:23.831 MRR:22.95 Best Results: 23.01
2024-12-27 17:35:12,765: Snapshot:2	Epoch:20	Loss:23.831	translation_Loss:23.831	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.95	Hits@10:40.61	Best:23.01
2024-12-27 17:35:13,000: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_8/2model_best.tar'
2024-12-27 17:35:19,488: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3334 | 0.2177 | 0.3829 | 0.4548 |  0.5563 |
|     1      | 0.2466 | 0.1532 | 0.2761 | 0.3382 |  0.4296 |
|     2      | 0.2311 | 0.1406 | 0.2627 |  0.32  |  0.4047 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:35:44,258: Snapshot:3	Epoch:0	Loss:160.752	translation_Loss:8.347	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:152.405                                                   	MRR:18.56	Hits@10:33.18	Best:18.56
2024-12-27 17:35:51,386: Snapshot:3	Epoch:1	Loss:4.403	translation_Loss:2.256	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.147                                                   	MRR:20.58	Hits@10:36.96	Best:20.58
2024-12-27 17:35:58,517: Snapshot:3	Epoch:2	Loss:1.663	translation_Loss:1.596	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.067                                                   	MRR:21.05	Hits@10:37.81	Best:21.05
2024-12-27 17:36:05,652: Snapshot:3	Epoch:3	Loss:1.44	translation_Loss:1.395	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.045                                                   	MRR:21.22	Hits@10:37.79	Best:21.22
2024-12-27 17:36:12,751: Snapshot:3	Epoch:4	Loss:1.343	translation_Loss:1.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.048                                                   	MRR:21.36	Hits@10:38.31	Best:21.36
2024-12-27 17:36:20,211: Snapshot:3	Epoch:5	Loss:1.301	translation_Loss:1.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.057                                                   	MRR:21.34	Hits@10:38.39	Best:21.36
2024-12-27 17:36:27,308: Snapshot:3	Epoch:6	Loss:1.247	translation_Loss:1.189	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.058                                                   	MRR:21.47	Hits@10:38.23	Best:21.47
2024-12-27 17:36:34,373: Snapshot:3	Epoch:7	Loss:1.207	translation_Loss:1.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.062                                                   	MRR:21.46	Hits@10:38.45	Best:21.47
2024-12-27 17:36:41,499: Snapshot:3	Epoch:8	Loss:1.206	translation_Loss:1.134	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.071                                                   	MRR:21.62	Hits@10:38.58	Best:21.62
2024-12-27 17:36:48,978: Snapshot:3	Epoch:9	Loss:1.162	translation_Loss:1.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.074                                                   	MRR:21.68	Hits@10:38.75	Best:21.68
2024-12-27 17:36:56,130: Snapshot:3	Epoch:10	Loss:1.128	translation_Loss:1.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.073                                                   	MRR:21.74	Hits@10:38.71	Best:21.74
2024-12-27 17:37:03,280: Snapshot:3	Epoch:11	Loss:1.12	translation_Loss:1.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.083                                                   	MRR:21.85	Hits@10:39.02	Best:21.85
2024-12-27 17:37:10,320: Snapshot:3	Epoch:12	Loss:1.107	translation_Loss:1.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:21.81	Hits@10:38.96	Best:21.85
2024-12-27 17:37:17,769: Snapshot:3	Epoch:13	Loss:1.1	translation_Loss:1.007	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:21.86	Hits@10:38.75	Best:21.86
2024-12-27 17:37:24,873: Snapshot:3	Epoch:14	Loss:1.083	translation_Loss:0.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:21.86	Hits@10:38.85	Best:21.86
2024-12-27 17:37:32,025: Snapshot:3	Epoch:15	Loss:1.075	translation_Loss:0.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:22.05	Hits@10:39.35	Best:22.05
2024-12-27 17:37:39,109: Snapshot:3	Epoch:16	Loss:1.077	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:22.0	Hits@10:38.87	Best:22.05
2024-12-27 17:37:46,595: Snapshot:3	Epoch:17	Loss:1.064	translation_Loss:0.949	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.116                                                   	MRR:21.93	Hits@10:39.26	Best:22.05
2024-12-27 17:37:53,633: Snapshot:3	Epoch:18	Loss:1.061	translation_Loss:0.943	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.118                                                   	MRR:21.79	Hits@10:39.31	Best:22.05
2024-12-27 17:38:00,846: Snapshot:3	Epoch:19	Loss:1.065	translation_Loss:0.943	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.122                                                   	MRR:21.76	Hits@10:39.13	Best:22.05
2024-12-27 17:38:07,911: Early Stopping! Snapshot: 3 Epoch: 20 Best Results: 22.05
2024-12-27 17:38:07,911: Start to training tokens! Snapshot: 3 Epoch: 20 Loss:1.065 MRR:21.98 Best Results: 22.05
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 17:38:07,912: Snapshot:3	Epoch:20	Loss:1.065	translation_Loss:0.932	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.132                                                   	MRR:21.98	Hits@10:39.52	Best:22.05
2024-12-27 17:38:15,323: Snapshot:3	Epoch:21	Loss:21.487	translation_Loss:21.45	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.98	Hits@10:39.52	Best:22.05
2024-12-27 17:38:22,347: End of token training: 3 Epoch: 22 Loss:21.443 MRR:21.98 Best Results: 22.05
2024-12-27 17:38:22,347: Snapshot:3	Epoch:22	Loss:21.443	translation_Loss:21.443	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.98	Hits@10:39.52	Best:22.05
2024-12-27 17:38:22,570: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_8/3model_best.tar'
2024-12-27 17:38:32,424: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3333 | 0.2174 | 0.383  | 0.4549 |  0.5564 |
|     1      | 0.2466 | 0.1534 | 0.2761 | 0.3379 |  0.4297 |
|     2      | 0.2311 | 0.1406 | 0.2626 |  0.32  |  0.4047 |
|     3      | 0.2208 | 0.1313 | 0.2537 | 0.3105 |  0.392  |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:38:50,982: Snapshot:4	Epoch:0	Loss:146.926	translation_Loss:5.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:140.937                                                   	MRR:22.02	Hits@10:39.94	Best:22.02
2024-12-27 17:38:56,205: Snapshot:4	Epoch:1	Loss:8.961	translation_Loss:1.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.654                                                   	MRR:24.83	Hits@10:43.85	Best:24.83
2024-12-27 17:39:01,675: Snapshot:4	Epoch:2	Loss:1.216	translation_Loss:0.756	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.46                                                   	MRR:25.6	Hits@10:45.04	Best:25.6
2024-12-27 17:39:06,835: Snapshot:4	Epoch:3	Loss:0.662	translation_Loss:0.614	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.048                                                   	MRR:26.05	Hits@10:45.72	Best:26.05
2024-12-27 17:39:11,926: Snapshot:4	Epoch:4	Loss:0.573	translation_Loss:0.55	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.023                                                   	MRR:25.88	Hits@10:45.93	Best:26.05
2024-12-27 17:39:17,077: Snapshot:4	Epoch:5	Loss:0.544	translation_Loss:0.521	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.023                                                   	MRR:25.88	Hits@10:45.77	Best:26.05
2024-12-27 17:39:22,155: Snapshot:4	Epoch:6	Loss:0.514	translation_Loss:0.488	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.026                                                   	MRR:25.95	Hits@10:46.0	Best:26.05
2024-12-27 17:39:27,261: Snapshot:4	Epoch:7	Loss:0.502	translation_Loss:0.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.029                                                   	MRR:25.98	Hits@10:46.11	Best:26.05
2024-12-27 17:39:32,372: Early Stopping! Snapshot: 4 Epoch: 8 Best Results: 26.05
2024-12-27 17:39:32,373: Start to training tokens! Snapshot: 4 Epoch: 8 Loss:0.489 MRR:25.98 Best Results: 26.05
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 17:39:32,373: Snapshot:4	Epoch:8	Loss:0.489	translation_Loss:0.457	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.032                                                   	MRR:25.98	Hits@10:45.96	Best:26.05
2024-12-27 17:39:37,814: Snapshot:4	Epoch:9	Loss:11.77	translation_Loss:11.733	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.98	Hits@10:45.96	Best:26.05
2024-12-27 17:39:42,928: End of token training: 4 Epoch: 10 Loss:11.708 MRR:25.98 Best Results: 26.05
2024-12-27 17:39:42,928: Snapshot:4	Epoch:10	Loss:11.708	translation_Loss:11.708	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.98	Hits@10:45.96	Best:26.05
2024-12-27 17:39:43,161: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_8/4model_best.tar'
2024-12-27 17:39:55,257: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3334 | 0.2174 | 0.3835 | 0.4547 |  0.5565 |
|     1      | 0.2467 | 0.1535 | 0.2761 | 0.3381 |  0.4294 |
|     2      | 0.2311 | 0.1405 | 0.2628 |  0.32  |  0.405  |
|     3      | 0.2208 | 0.1313 | 0.2539 | 0.3105 |  0.3923 |
|     4      | 0.2632 | 0.158  | 0.3136 | 0.3804 |  0.4619 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 17:39:55,259: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3332 | 0.2171 | 0.3829 | 0.4546 |  0.5561 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3332 | 0.2172 | 0.3829 | 0.4546 |  0.5563 |
|     1      | 0.2465 | 0.1531 | 0.2759 | 0.3383 |  0.4296 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3334 | 0.2177 | 0.3829 | 0.4548 |  0.5563 |
|     1      | 0.2466 | 0.1532 | 0.2761 | 0.3382 |  0.4296 |
|     2      | 0.2311 | 0.1406 | 0.2627 |  0.32  |  0.4047 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3333 | 0.2174 | 0.383  | 0.4549 |  0.5564 |
|     1      | 0.2466 | 0.1534 | 0.2761 | 0.3379 |  0.4297 |
|     2      | 0.2311 | 0.1406 | 0.2626 |  0.32  |  0.4047 |
|     3      | 0.2208 | 0.1313 | 0.2537 | 0.3105 |  0.392  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3334 | 0.2174 | 0.3835 | 0.4547 |  0.5565 |
|     1      | 0.2467 | 0.1535 | 0.2761 | 0.3381 |  0.4294 |
|     2      | 0.2311 | 0.1405 | 0.2628 |  0.32  |  0.405  |
|     3      | 0.2208 | 0.1313 | 0.2539 | 0.3105 |  0.3923 |
|     4      | 0.2632 | 0.158  | 0.3136 | 0.3804 |  0.4619 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 17:39:55,259: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 50.22414231300354  |   0.333   |    0.217     |    0.383     |     0.556     |
|    1     | 132.06907963752747 |    0.28   |    0.178     |    0.318     |     0.479     |
|    2     | 164.63538885116577 |   0.262   |    0.164     |    0.297     |     0.451     |
|    3     | 179.86604046821594 |   0.251   |    0.155     |    0.285     |     0.435     |
|    4     | 68.05973601341248  |   0.253   |    0.156     |     0.29     |     0.439     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 17:39:55,260: Sum_Training_Time:594.8543872833252
2024-12-27 17:39:55,260: Every_Training_Time:[50.22414231300354, 132.06907963752747, 164.63538885116577, 179.86604046821594, 68.05973601341248]
2024-12-27 17:39:55,260: Forward transfer: 0.04355 Backward transfer: 9.999999999999593e-05
2024-12-27 17:40:29,154: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227173959/ENTITYentity_0.01_2048_10', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.01_2048_10', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.01_2048_10', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=10, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 17:40:36,693: Snapshot:0	Epoch:0	Loss:15.487	translation_Loss:15.487	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.49	Hits@10:44.43	Best:21.49
2024-12-27 17:40:40,436: Snapshot:0	Epoch:1	Loss:6.378	translation_Loss:6.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.6	Hits@10:53.87	Best:30.6
2024-12-27 17:40:44,171: Snapshot:0	Epoch:2	Loss:2.563	translation_Loss:2.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.28	Hits@10:55.4	Best:32.28
2024-12-27 17:40:47,904: Snapshot:0	Epoch:3	Loss:1.287	translation_Loss:1.287	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.7	Hits@10:55.45	Best:32.7
2024-12-27 17:40:52,040: Snapshot:0	Epoch:4	Loss:0.812	translation_Loss:0.812	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.81	Hits@10:55.32	Best:32.81
2024-12-27 17:40:55,882: Snapshot:0	Epoch:5	Loss:0.606	translation_Loss:0.606	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.67	Hits@10:54.83	Best:32.81
2024-12-27 17:40:59,615: Snapshot:0	Epoch:6	Loss:0.505	translation_Loss:0.505	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.57	Hits@10:55.08	Best:32.81
2024-12-27 17:41:03,309: Snapshot:0	Epoch:7	Loss:0.436	translation_Loss:0.436	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.26	Hits@10:54.86	Best:32.81
2024-12-27 17:41:06,993: Snapshot:0	Epoch:8	Loss:0.385	translation_Loss:0.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.35	Hits@10:54.96	Best:32.81
2024-12-27 17:41:10,688: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 32.81
2024-12-27 17:41:10,688: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.356 MRR:32.05 Best Results: 32.81
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 17:41:10,688: Snapshot:0	Epoch:9	Loss:0.356	translation_Loss:0.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.05	Hits@10:54.74	Best:32.81
2024-12-27 17:41:14,926: Snapshot:0	Epoch:10	Loss:14.314	translation_Loss:14.277	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.05	Hits@10:54.74	Best:32.81
2024-12-27 17:41:19,153: End of token training: 0 Epoch: 11 Loss:14.287 MRR:32.05 Best Results: 32.81
2024-12-27 17:41:19,153: Snapshot:0	Epoch:11	Loss:14.287	translation_Loss:14.287	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:32.05	Hits@10:54.74	Best:32.81
2024-12-27 17:41:19,416: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_10/0model_best.tar'
2024-12-27 17:41:20,718: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3335 | 0.2176 | 0.3829 | 0.4571 |  0.5569 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:41:44,035: Snapshot:1	Epoch:0	Loss:207.117	translation_Loss:9.565	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:197.551                                                   	MRR:21.71	Hits@10:38.3	Best:21.71
2024-12-27 17:41:50,791: Snapshot:1	Epoch:1	Loss:5.262	translation_Loss:2.703	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.56                                                   	MRR:23.44	Hits@10:41.4	Best:23.44
2024-12-27 17:41:57,219: Snapshot:1	Epoch:2	Loss:1.885	translation_Loss:1.84	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.045                                                   	MRR:24.14	Hits@10:42.13	Best:24.14
2024-12-27 17:42:03,662: Snapshot:1	Epoch:3	Loss:1.601	translation_Loss:1.586	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.015                                                   	MRR:24.28	Hits@10:42.64	Best:24.28
2024-12-27 17:42:10,117: Snapshot:1	Epoch:4	Loss:1.486	translation_Loss:1.468	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.017                                                   	MRR:24.36	Hits@10:42.79	Best:24.36
2024-12-27 17:42:17,005: Snapshot:1	Epoch:5	Loss:1.402	translation_Loss:1.383	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.019                                                   	MRR:24.53	Hits@10:43.12	Best:24.53
2024-12-27 17:42:23,371: Snapshot:1	Epoch:6	Loss:1.341	translation_Loss:1.321	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.02                                                   	MRR:24.47	Hits@10:42.94	Best:24.53
2024-12-27 17:42:29,748: Snapshot:1	Epoch:7	Loss:1.305	translation_Loss:1.281	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.023                                                   	MRR:24.71	Hits@10:43.13	Best:24.71
2024-12-27 17:42:36,239: Snapshot:1	Epoch:8	Loss:1.27	translation_Loss:1.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.025                                                   	MRR:24.77	Hits@10:43.46	Best:24.77
2024-12-27 17:42:42,977: Snapshot:1	Epoch:9	Loss:1.227	translation_Loss:1.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.025                                                   	MRR:24.79	Hits@10:43.47	Best:24.79
2024-12-27 17:42:49,491: Snapshot:1	Epoch:10	Loss:1.198	translation_Loss:1.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.029                                                   	MRR:24.85	Hits@10:43.45	Best:24.85
2024-12-27 17:42:55,868: Snapshot:1	Epoch:11	Loss:1.17	translation_Loss:1.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.032                                                   	MRR:24.72	Hits@10:43.15	Best:24.85
2024-12-27 17:43:02,322: Snapshot:1	Epoch:12	Loss:1.153	translation_Loss:1.122	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.031                                                   	MRR:24.62	Hits@10:43.16	Best:24.85
2024-12-27 17:43:09,023: Snapshot:1	Epoch:13	Loss:1.134	translation_Loss:1.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.033                                                   	MRR:24.84	Hits@10:43.36	Best:24.85
2024-12-27 17:43:15,437: Snapshot:1	Epoch:14	Loss:1.121	translation_Loss:1.084	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.037                                                   	MRR:24.7	Hits@10:43.36	Best:24.85
2024-12-27 17:43:21,787: Early Stopping! Snapshot: 1 Epoch: 15 Best Results: 24.85
2024-12-27 17:43:21,788: Start to training tokens! Snapshot: 1 Epoch: 15 Loss:1.109 MRR:24.75 Best Results: 24.85
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 17:43:21,788: Snapshot:1	Epoch:15	Loss:1.109	translation_Loss:1.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.04                                                   	MRR:24.75	Hits@10:43.18	Best:24.85
2024-12-27 17:43:28,171: Snapshot:1	Epoch:16	Loss:23.402	translation_Loss:23.364	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.75	Hits@10:43.18	Best:24.85
2024-12-27 17:43:35,002: End of token training: 1 Epoch: 17 Loss:23.37 MRR:24.75 Best Results: 24.85
2024-12-27 17:43:35,002: Snapshot:1	Epoch:17	Loss:23.37	translation_Loss:23.369	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.75	Hits@10:43.18	Best:24.85
2024-12-27 17:43:35,226: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_10/1model_best.tar'
2024-12-27 17:43:38,724: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3335 | 0.2176 | 0.3831 | 0.4572 |  0.557  |
|     1      | 0.2475 | 0.1532 | 0.2785 | 0.3408 |  0.4312 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:44:04,016: Snapshot:2	Epoch:0	Loss:200.378	translation_Loss:9.127	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:191.25                                                   	MRR:19.26	Hits@10:34.53	Best:19.26
2024-12-27 17:44:11,021: Snapshot:2	Epoch:1	Loss:4.855	translation_Loss:2.633	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.222                                                   	MRR:21.47	Hits@10:38.1	Best:21.47
2024-12-27 17:44:18,179: Snapshot:2	Epoch:2	Loss:1.949	translation_Loss:1.9	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.049                                                   	MRR:22.14	Hits@10:39.01	Best:22.14
2024-12-27 17:44:25,215: Snapshot:2	Epoch:3	Loss:1.707	translation_Loss:1.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.029                                                   	MRR:22.34	Hits@10:39.34	Best:22.34
2024-12-27 17:44:32,250: Snapshot:2	Epoch:4	Loss:1.582	translation_Loss:1.548	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.034                                                   	MRR:22.7	Hits@10:39.82	Best:22.7
2024-12-27 17:44:39,270: Snapshot:2	Epoch:5	Loss:1.515	translation_Loss:1.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.035                                                   	MRR:22.66	Hits@10:40.02	Best:22.7
2024-12-27 17:44:46,262: Snapshot:2	Epoch:6	Loss:1.453	translation_Loss:1.412	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.041                                                   	MRR:22.55	Hits@10:39.92	Best:22.7
2024-12-27 17:44:53,219: Snapshot:2	Epoch:7	Loss:1.418	translation_Loss:1.372	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.045                                                   	MRR:22.69	Hits@10:40.16	Best:22.7
2024-12-27 17:45:00,304: Snapshot:2	Epoch:8	Loss:1.377	translation_Loss:1.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.046                                                   	MRR:22.68	Hits@10:40.18	Best:22.7
2024-12-27 17:45:07,474: Snapshot:2	Epoch:9	Loss:1.344	translation_Loss:1.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.051                                                   	MRR:22.74	Hits@10:39.95	Best:22.74
2024-12-27 17:45:14,582: Snapshot:2	Epoch:10	Loss:1.321	translation_Loss:1.264	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.057                                                   	MRR:22.96	Hits@10:40.22	Best:22.96
2024-12-27 17:45:22,098: Snapshot:2	Epoch:11	Loss:1.298	translation_Loss:1.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.057                                                   	MRR:23.02	Hits@10:40.47	Best:23.02
2024-12-27 17:45:29,115: Snapshot:2	Epoch:12	Loss:1.27	translation_Loss:1.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.059                                                   	MRR:23.0	Hits@10:40.35	Best:23.02
2024-12-27 17:45:36,104: Snapshot:2	Epoch:13	Loss:1.266	translation_Loss:1.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.067                                                   	MRR:23.01	Hits@10:40.37	Best:23.02
2024-12-27 17:45:43,123: Snapshot:2	Epoch:14	Loss:1.252	translation_Loss:1.179	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.073                                                   	MRR:23.06	Hits@10:40.2	Best:23.06
2024-12-27 17:45:50,519: Snapshot:2	Epoch:15	Loss:1.241	translation_Loss:1.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.071                                                   	MRR:23.16	Hits@10:40.35	Best:23.16
2024-12-27 17:45:57,554: Snapshot:2	Epoch:16	Loss:1.232	translation_Loss:1.156	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.076                                                   	MRR:23.13	Hits@10:40.46	Best:23.16
2024-12-27 17:46:04,491: Snapshot:2	Epoch:17	Loss:1.238	translation_Loss:1.153	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:23.16	Hits@10:40.37	Best:23.16
2024-12-27 17:46:11,502: Snapshot:2	Epoch:18	Loss:1.216	translation_Loss:1.124	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:23.17	Hits@10:40.61	Best:23.17
2024-12-27 17:46:18,821: Snapshot:2	Epoch:19	Loss:1.222	translation_Loss:1.129	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:23.13	Hits@10:40.61	Best:23.17
2024-12-27 17:46:25,769: Snapshot:2	Epoch:20	Loss:1.208	translation_Loss:1.112	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.096                                                   	MRR:23.08	Hits@10:40.54	Best:23.17
2024-12-27 17:46:32,744: Snapshot:2	Epoch:21	Loss:1.201	translation_Loss:1.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.106                                                   	MRR:23.12	Hits@10:40.6	Best:23.17
2024-12-27 17:46:39,726: Snapshot:2	Epoch:22	Loss:1.209	translation_Loss:1.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:23.14	Hits@10:40.36	Best:23.17
2024-12-27 17:46:47,108: Early Stopping! Snapshot: 2 Epoch: 23 Best Results: 23.17
2024-12-27 17:46:47,108: Start to training tokens! Snapshot: 2 Epoch: 23 Loss:1.21 MRR:23.06 Best Results: 23.17
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 17:46:47,108: Snapshot:2	Epoch:23	Loss:1.21	translation_Loss:1.09	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.119                                                   	MRR:23.06	Hits@10:40.43	Best:23.17
2024-12-27 17:46:54,057: Snapshot:2	Epoch:24	Loss:23.856	translation_Loss:23.819	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.06	Hits@10:40.43	Best:23.17
2024-12-27 17:47:01,143: End of token training: 2 Epoch: 25 Loss:23.797 MRR:23.06 Best Results: 23.17
2024-12-27 17:47:01,143: Snapshot:2	Epoch:25	Loss:23.797	translation_Loss:23.797	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.06	Hits@10:40.43	Best:23.17
2024-12-27 17:47:01,366: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_10/2model_best.tar'
2024-12-27 17:47:07,956: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3335 | 0.2177 | 0.3829 | 0.4569 |  0.5569 |
|     1      | 0.2476 | 0.1535 | 0.2784 | 0.3406 |  0.4313 |
|     2      | 0.2315 | 0.1404 | 0.2631 | 0.323  |  0.4071 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:47:32,514: Snapshot:3	Epoch:0	Loss:198.885	translation_Loss:8.282	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:190.603                                                   	MRR:18.63	Hits@10:33.52	Best:18.63
2024-12-27 17:47:40,089: Snapshot:3	Epoch:1	Loss:4.913	translation_Loss:2.246	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.667                                                   	MRR:20.66	Hits@10:36.95	Best:20.66
2024-12-27 17:47:47,235: Snapshot:3	Epoch:2	Loss:1.667	translation_Loss:1.602	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.065                                                   	MRR:21.22	Hits@10:37.85	Best:21.22
2024-12-27 17:47:54,361: Snapshot:3	Epoch:3	Loss:1.445	translation_Loss:1.409	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.036                                                   	MRR:21.31	Hits@10:38.09	Best:21.31
2024-12-27 17:48:01,559: Snapshot:3	Epoch:4	Loss:1.34	translation_Loss:1.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.038                                                   	MRR:21.44	Hits@10:38.29	Best:21.44
2024-12-27 17:48:09,075: Snapshot:3	Epoch:5	Loss:1.273	translation_Loss:1.228	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.044                                                   	MRR:21.48	Hits@10:38.63	Best:21.48
2024-12-27 17:48:16,233: Snapshot:3	Epoch:6	Loss:1.222	translation_Loss:1.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.044                                                   	MRR:21.55	Hits@10:38.72	Best:21.55
2024-12-27 17:48:23,436: Snapshot:3	Epoch:7	Loss:1.199	translation_Loss:1.15	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.049                                                   	MRR:21.67	Hits@10:38.63	Best:21.67
2024-12-27 17:48:30,554: Snapshot:3	Epoch:8	Loss:1.168	translation_Loss:1.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.057                                                   	MRR:21.68	Hits@10:38.75	Best:21.68
2024-12-27 17:48:37,686: Snapshot:3	Epoch:9	Loss:1.14	translation_Loss:1.082	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.058                                                   	MRR:21.71	Hits@10:38.83	Best:21.71
2024-12-27 17:48:45,229: Snapshot:3	Epoch:10	Loss:1.124	translation_Loss:1.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.058                                                   	MRR:21.93	Hits@10:39.18	Best:21.93
2024-12-27 17:48:52,355: Snapshot:3	Epoch:11	Loss:1.107	translation_Loss:1.042	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.066                                                   	MRR:21.81	Hits@10:38.78	Best:21.93
2024-12-27 17:48:59,503: Snapshot:3	Epoch:12	Loss:1.103	translation_Loss:1.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.073                                                   	MRR:21.9	Hits@10:38.97	Best:21.93
2024-12-27 17:49:06,567: Snapshot:3	Epoch:13	Loss:1.098	translation_Loss:1.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.074                                                   	MRR:21.89	Hits@10:38.95	Best:21.93
2024-12-27 17:49:14,049: Snapshot:3	Epoch:14	Loss:1.069	translation_Loss:0.994	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.075                                                   	MRR:21.97	Hits@10:38.95	Best:21.97
2024-12-27 17:49:21,110: Snapshot:3	Epoch:15	Loss:1.069	translation_Loss:0.988	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.081                                                   	MRR:21.94	Hits@10:39.26	Best:21.97
2024-12-27 17:49:28,206: Snapshot:3	Epoch:16	Loss:1.064	translation_Loss:0.975	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:21.94	Hits@10:38.99	Best:21.97
2024-12-27 17:49:35,249: Snapshot:3	Epoch:17	Loss:1.042	translation_Loss:0.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:21.93	Hits@10:39.26	Best:21.97
2024-12-27 17:49:42,712: Snapshot:3	Epoch:18	Loss:1.033	translation_Loss:0.94	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:22.04	Hits@10:39.46	Best:22.04
2024-12-27 17:49:49,877: Snapshot:3	Epoch:19	Loss:1.039	translation_Loss:0.94	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:21.92	Hits@10:39.31	Best:22.04
2024-12-27 17:49:56,942: Snapshot:3	Epoch:20	Loss:1.035	translation_Loss:0.928	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:21.99	Hits@10:39.41	Best:22.04
2024-12-27 17:50:04,094: Snapshot:3	Epoch:21	Loss:1.028	translation_Loss:0.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.115                                                   	MRR:22.01	Hits@10:39.31	Best:22.04
2024-12-27 17:50:11,823: Snapshot:3	Epoch:22	Loss:1.028	translation_Loss:0.908	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.12                                                   	MRR:21.94	Hits@10:39.48	Best:22.04
2024-12-27 17:50:18,982: Early Stopping! Snapshot: 3 Epoch: 23 Best Results: 22.04
2024-12-27 17:50:18,983: Start to training tokens! Snapshot: 3 Epoch: 23 Loss:1.023 MRR:21.95 Best Results: 22.04
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 17:50:18,983: Snapshot:3	Epoch:23	Loss:1.023	translation_Loss:0.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.122                                                   	MRR:21.95	Hits@10:39.43	Best:22.04
2024-12-27 17:50:26,045: Snapshot:3	Epoch:24	Loss:21.417	translation_Loss:21.381	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.95	Hits@10:39.43	Best:22.04
2024-12-27 17:50:33,123: End of token training: 3 Epoch: 25 Loss:21.405 MRR:21.95 Best Results: 22.04
2024-12-27 17:50:33,123: Snapshot:3	Epoch:25	Loss:21.405	translation_Loss:21.405	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.95	Hits@10:39.43	Best:22.04
2024-12-27 17:50:33,355: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_10/3model_best.tar'
2024-12-27 17:50:43,268: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3335 | 0.2176 | 0.3827 | 0.4569 |  0.5574 |
|     1      | 0.2476 | 0.1536 | 0.2784 | 0.3408 |  0.4311 |
|     2      | 0.2314 | 0.1402 | 0.2631 | 0.3227 |  0.4072 |
|     3      | 0.2211 | 0.1301 | 0.2544 | 0.3128 |  0.3938 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:51:02,237: Snapshot:4	Epoch:0	Loss:182.073	translation_Loss:6.057	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:176.017                                                   	MRR:21.88	Hits@10:39.72	Best:21.88
2024-12-27 17:51:07,370: Snapshot:4	Epoch:1	Loss:10.868	translation_Loss:1.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.55                                                   	MRR:24.51	Hits@10:43.65	Best:24.51
2024-12-27 17:51:12,521: Snapshot:4	Epoch:2	Loss:1.325	translation_Loss:0.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.565                                                   	MRR:25.13	Hits@10:44.98	Best:25.13
2024-12-27 17:51:17,706: Snapshot:4	Epoch:3	Loss:0.664	translation_Loss:0.614	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.05                                                   	MRR:25.46	Hits@10:45.23	Best:25.46
2024-12-27 17:51:22,927: Snapshot:4	Epoch:4	Loss:0.569	translation_Loss:0.55	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.019                                                   	MRR:25.67	Hits@10:45.49	Best:25.67
2024-12-27 17:51:28,064: Snapshot:4	Epoch:5	Loss:0.533	translation_Loss:0.515	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.018                                                   	MRR:26.14	Hits@10:45.94	Best:26.14
2024-12-27 17:51:33,144: Snapshot:4	Epoch:6	Loss:0.509	translation_Loss:0.489	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.02                                                   	MRR:25.91	Hits@10:45.65	Best:26.14
2024-12-27 17:51:38,355: Snapshot:4	Epoch:7	Loss:0.494	translation_Loss:0.471	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.023                                                   	MRR:25.94	Hits@10:45.98	Best:26.14
2024-12-27 17:51:43,450: Snapshot:4	Epoch:8	Loss:0.479	translation_Loss:0.455	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.025                                                   	MRR:26.04	Hits@10:45.83	Best:26.14
2024-12-27 17:51:48,622: Snapshot:4	Epoch:9	Loss:0.468	translation_Loss:0.444	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.025                                                   	MRR:26.17	Hits@10:45.92	Best:26.17
2024-12-27 17:51:53,684: Snapshot:4	Epoch:10	Loss:0.464	translation_Loss:0.439	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.025                                                   	MRR:25.94	Hits@10:46.18	Best:26.17
2024-12-27 17:51:59,257: Snapshot:4	Epoch:11	Loss:0.448	translation_Loss:0.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.026                                                   	MRR:25.85	Hits@10:46.29	Best:26.17
2024-12-27 17:52:04,324: Snapshot:4	Epoch:12	Loss:0.44	translation_Loss:0.413	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.026                                                   	MRR:25.86	Hits@10:46.27	Best:26.17
2024-12-27 17:52:09,410: Snapshot:4	Epoch:13	Loss:0.44	translation_Loss:0.411	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.029                                                   	MRR:25.86	Hits@10:46.12	Best:26.17
2024-12-27 17:52:14,510: Early Stopping! Snapshot: 4 Epoch: 14 Best Results: 26.17
2024-12-27 17:52:14,510: Start to training tokens! Snapshot: 4 Epoch: 14 Loss:0.425 MRR:26.01 Best Results: 26.17
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 17:52:14,511: Snapshot:4	Epoch:14	Loss:0.425	translation_Loss:0.394	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.031                                                   	MRR:26.01	Hits@10:46.47	Best:26.17
2024-12-27 17:52:19,664: Snapshot:4	Epoch:15	Loss:11.758	translation_Loss:11.721	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.01	Hits@10:46.47	Best:26.17
2024-12-27 17:52:24,754: End of token training: 4 Epoch: 16 Loss:11.741 MRR:26.01 Best Results: 26.17
2024-12-27 17:52:24,754: Snapshot:4	Epoch:16	Loss:11.741	translation_Loss:11.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.01	Hits@10:46.47	Best:26.17
2024-12-27 17:52:25,040: => loading checkpoint './checkpoint/ENTITYentity_0.01_2048_10/4model_best.tar'
2024-12-27 17:52:37,178: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3335 | 0.2177 | 0.3827 | 0.457  |  0.5574 |
|     1      | 0.2475 | 0.1533 | 0.2783 | 0.3408 |  0.4312 |
|     2      | 0.2315 | 0.1403 | 0.263  | 0.3224 |  0.407  |
|     3      | 0.2211 | 0.1298 | 0.2544 | 0.313  |  0.3941 |
|     4      | 0.2641 | 0.1568 | 0.3175 | 0.381  |  0.4659 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 17:52:37,181: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3335 | 0.2176 | 0.3829 | 0.4571 |  0.5569 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3335 | 0.2176 | 0.3831 | 0.4572 |  0.557  |
|     1      | 0.2475 | 0.1532 | 0.2785 | 0.3408 |  0.4312 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3335 | 0.2177 | 0.3829 | 0.4569 |  0.5569 |
|     1      | 0.2476 | 0.1535 | 0.2784 | 0.3406 |  0.4313 |
|     2      | 0.2315 | 0.1404 | 0.2631 | 0.323  |  0.4071 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3335 | 0.2176 | 0.3827 | 0.4569 |  0.5574 |
|     1      | 0.2476 | 0.1536 | 0.2784 | 0.3408 |  0.4311 |
|     2      | 0.2314 | 0.1402 | 0.2631 | 0.3227 |  0.4072 |
|     3      | 0.2211 | 0.1301 | 0.2544 | 0.3128 |  0.3938 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3335 | 0.2177 | 0.3827 | 0.457  |  0.5574 |
|     1      | 0.2475 | 0.1533 | 0.2783 | 0.3408 |  0.4312 |
|     2      | 0.2315 | 0.1403 | 0.263  | 0.3224 |  0.407  |
|     3      | 0.2211 | 0.1298 | 0.2544 | 0.313  |  0.3941 |
|     4      | 0.2641 | 0.1568 | 0.3175 | 0.381  |  0.4659 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 17:52:37,181: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 49.998374223709106 |   0.334   |    0.218     |    0.383     |     0.557     |
|    1     | 132.06454157829285 |   0.281   |    0.178     |    0.319     |      0.48     |
|    2     | 199.74595475196838 |   0.262   |    0.164     |    0.298     |     0.452     |
|    3     | 202.16251730918884 |   0.251   |    0.155     |    0.286     |     0.437     |
|    4     | 99.04670596122742  |   0.253   |    0.155     |    0.291     |     0.441     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 17:52:37,181: Sum_Training_Time:683.0180938243866
2024-12-27 17:52:37,182: Every_Training_Time:[49.998374223709106, 132.06454157829285, 199.74595475196838, 202.16251730918884, 99.04670596122742]
2024-12-27 17:52:37,182: Forward transfer: 0.043475 Backward transfer: 0.0
2024-12-27 17:53:10,468: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227175241/ENTITYentity_0.001_512_2', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.001_512_2', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.001_512_2', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=2, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 17:53:18,276: Snapshot:0	Epoch:0	Loss:69.32	translation_Loss:69.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.71	Hits@10:32.99	Best:13.71
2024-12-27 17:53:22,274: Snapshot:0	Epoch:1	Loss:39.171	translation_Loss:39.171	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.18	Hits@10:49.26	Best:26.18
2024-12-27 17:53:26,282: Snapshot:0	Epoch:2	Loss:18.413	translation_Loss:18.413	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.84	Hits@10:54.17	Best:30.84
2024-12-27 17:53:30,344: Snapshot:0	Epoch:3	Loss:9.28	translation_Loss:9.28	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.2	Hits@10:55.42	Best:32.2
2024-12-27 17:53:34,293: Snapshot:0	Epoch:4	Loss:5.428	translation_Loss:5.428	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.65	Hits@10:55.64	Best:32.65
2024-12-27 17:53:38,342: Snapshot:0	Epoch:5	Loss:3.683	translation_Loss:3.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.67	Hits@10:55.32	Best:32.67
2024-12-27 17:53:42,337: Snapshot:0	Epoch:6	Loss:2.806	translation_Loss:2.806	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.51	Hits@10:55.42	Best:32.67
2024-12-27 17:53:46,258: Snapshot:0	Epoch:7	Loss:2.268	translation_Loss:2.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.37	Hits@10:55.13	Best:32.67
2024-12-27 17:53:50,172: Snapshot:0	Epoch:8	Loss:1.942	translation_Loss:1.942	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.15	Hits@10:54.75	Best:32.67
2024-12-27 17:53:54,074: Snapshot:0	Epoch:9	Loss:1.698	translation_Loss:1.698	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.2	Hits@10:54.88	Best:32.67
2024-12-27 17:53:58,004: Early Stopping! Snapshot: 0 Epoch: 10 Best Results: 32.67
2024-12-27 17:53:58,004: Start to training tokens! Snapshot: 0 Epoch: 10 Loss:1.555 MRR:31.88 Best Results: 32.67
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 17:53:58,005: Snapshot:0	Epoch:10	Loss:1.555	translation_Loss:1.555	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.88	Hits@10:54.59	Best:32.67
2024-12-27 17:54:02,719: Snapshot:0	Epoch:11	Loss:56.242	translation_Loss:56.152	multi_layer_Loss:0.09	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.88	Hits@10:54.59	Best:32.67
2024-12-27 17:54:06,953: End of token training: 0 Epoch: 12 Loss:56.141 MRR:31.88 Best Results: 32.67
2024-12-27 17:54:06,954: Snapshot:0	Epoch:12	Loss:56.141	translation_Loss:56.141	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.88	Hits@10:54.59	Best:32.67
2024-12-27 17:54:07,259: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_2/0model_best.tar'
2024-12-27 17:54:08,861: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3305 | 0.211  | 0.3836 | 0.461  |  0.5606 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:54:33,493: Snapshot:1	Epoch:0	Loss:51.196	translation_Loss:48.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.127                                                   	MRR:21.11	Hits@10:37.58	Best:21.11
2024-12-27 17:54:40,669: Snapshot:1	Epoch:1	Loss:16.094	translation_Loss:14.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.002                                                   	MRR:23.13	Hits@10:41.26	Best:23.13
2024-12-27 17:54:47,878: Snapshot:1	Epoch:2	Loss:11.392	translation_Loss:9.529	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.863                                                   	MRR:23.73	Hits@10:42.56	Best:23.73
2024-12-27 17:54:55,060: Snapshot:1	Epoch:3	Loss:9.656	translation_Loss:7.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.683                                                   	MRR:23.83	Hits@10:42.73	Best:23.83
2024-12-27 17:55:02,378: Snapshot:1	Epoch:4	Loss:8.923	translation_Loss:7.188	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.735                                                   	MRR:24.05	Hits@10:43.0	Best:24.05
2024-12-27 17:55:09,698: Snapshot:1	Epoch:5	Loss:8.363	translation_Loss:6.725	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.638                                                   	MRR:24.3	Hits@10:42.96	Best:24.3
2024-12-27 17:55:16,827: Snapshot:1	Epoch:6	Loss:8.017	translation_Loss:6.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.639                                                   	MRR:24.21	Hits@10:43.19	Best:24.3
2024-12-27 17:55:24,010: Snapshot:1	Epoch:7	Loss:7.698	translation_Loss:6.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.621                                                   	MRR:24.39	Hits@10:43.3	Best:24.39
2024-12-27 17:55:31,139: Snapshot:1	Epoch:8	Loss:7.488	translation_Loss:5.873	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.615                                                   	MRR:24.28	Hits@10:43.36	Best:24.39
2024-12-27 17:55:38,352: Snapshot:1	Epoch:9	Loss:7.279	translation_Loss:5.673	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.606                                                   	MRR:24.27	Hits@10:43.36	Best:24.39
2024-12-27 17:55:45,538: Snapshot:1	Epoch:10	Loss:7.219	translation_Loss:5.611	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.608                                                   	MRR:24.27	Hits@10:43.07	Best:24.39
2024-12-27 17:55:52,731: Snapshot:1	Epoch:11	Loss:7.046	translation_Loss:5.443	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.603                                                   	MRR:24.51	Hits@10:43.74	Best:24.51
2024-12-27 17:56:00,077: Snapshot:1	Epoch:12	Loss:6.91	translation_Loss:5.328	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.582                                                   	MRR:24.48	Hits@10:43.6	Best:24.51
2024-12-27 17:56:07,305: Snapshot:1	Epoch:13	Loss:6.785	translation_Loss:5.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.59                                                   	MRR:24.48	Hits@10:43.41	Best:24.51
2024-12-27 17:56:14,449: Snapshot:1	Epoch:14	Loss:6.687	translation_Loss:5.119	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.568                                                   	MRR:24.64	Hits@10:43.85	Best:24.64
2024-12-27 17:56:21,693: Snapshot:1	Epoch:15	Loss:6.671	translation_Loss:5.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.585                                                   	MRR:24.69	Hits@10:43.6	Best:24.69
2024-12-27 17:56:28,843: Snapshot:1	Epoch:16	Loss:6.645	translation_Loss:5.049	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.596                                                   	MRR:24.51	Hits@10:43.65	Best:24.69
2024-12-27 17:56:36,037: Snapshot:1	Epoch:17	Loss:6.49	translation_Loss:4.933	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.558                                                   	MRR:24.76	Hits@10:43.69	Best:24.76
2024-12-27 17:56:43,200: Snapshot:1	Epoch:18	Loss:6.401	translation_Loss:4.834	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.567                                                   	MRR:24.56	Hits@10:43.69	Best:24.76
2024-12-27 17:56:50,402: Snapshot:1	Epoch:19	Loss:6.445	translation_Loss:4.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.579                                                   	MRR:24.77	Hits@10:43.62	Best:24.77
2024-12-27 17:56:58,000: Snapshot:1	Epoch:20	Loss:6.317	translation_Loss:4.767	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.549                                                   	MRR:24.74	Hits@10:43.77	Best:24.77
2024-12-27 17:57:05,154: Snapshot:1	Epoch:21	Loss:6.313	translation_Loss:4.749	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.564                                                   	MRR:24.76	Hits@10:43.88	Best:24.77
2024-12-27 17:57:12,397: Snapshot:1	Epoch:22	Loss:6.243	translation_Loss:4.681	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.562                                                   	MRR:24.64	Hits@10:43.69	Best:24.77
2024-12-27 17:57:19,629: Snapshot:1	Epoch:23	Loss:6.239	translation_Loss:4.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.563                                                   	MRR:24.65	Hits@10:43.7	Best:24.77
2024-12-27 17:57:26,877: Early Stopping! Snapshot: 1 Epoch: 24 Best Results: 24.77
2024-12-27 17:57:26,877: Start to training tokens! Snapshot: 1 Epoch: 24 Loss:6.24 MRR:24.61 Best Results: 24.77
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 17:57:26,877: Snapshot:1	Epoch:24	Loss:6.24	translation_Loss:4.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.564                                                   	MRR:24.61	Hits@10:43.84	Best:24.77
2024-12-27 17:57:34,071: Snapshot:1	Epoch:25	Loss:93.105	translation_Loss:93.011	multi_layer_Loss:0.093	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.61	Hits@10:43.84	Best:24.77
2024-12-27 17:57:41,280: End of token training: 1 Epoch: 26 Loss:92.867 MRR:24.61 Best Results: 24.77
2024-12-27 17:57:41,280: Snapshot:1	Epoch:26	Loss:92.867	translation_Loss:92.867	multi_layer_Loss:-0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.61	Hits@10:43.84	Best:24.77
2024-12-27 17:57:41,558: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_2/1model_best.tar'
2024-12-27 17:57:45,000: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.331  | 0.2121 | 0.3841 | 0.4603 |  0.5602 |
|     1      | 0.2478 | 0.1505 | 0.283  | 0.3458 |  0.4352 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:58:11,364: Snapshot:2	Epoch:0	Loss:46.759	translation_Loss:42.997	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.762                                                   	MRR:18.37	Hits@10:32.45	Best:18.37
2024-12-27 17:58:19,212: Snapshot:2	Epoch:1	Loss:15.334	translation_Loss:12.869	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.466                                                   	MRR:20.64	Hits@10:36.51	Best:20.64
2024-12-27 17:58:27,021: Snapshot:2	Epoch:2	Loss:11.628	translation_Loss:9.405	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.223                                                   	MRR:21.28	Hits@10:37.7	Best:21.28
2024-12-27 17:58:34,946: Snapshot:2	Epoch:3	Loss:10.249	translation_Loss:8.103	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.146                                                   	MRR:22.01	Hits@10:38.68	Best:22.01
2024-12-27 17:58:42,784: Snapshot:2	Epoch:4	Loss:9.551	translation_Loss:7.428	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.124                                                   	MRR:22.17	Hits@10:38.97	Best:22.17
2024-12-27 17:58:50,608: Snapshot:2	Epoch:5	Loss:9.056	translation_Loss:6.978	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.078                                                   	MRR:22.18	Hits@10:39.23	Best:22.18
2024-12-27 17:58:58,479: Snapshot:2	Epoch:6	Loss:8.701	translation_Loss:6.624	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.077                                                   	MRR:22.37	Hits@10:39.51	Best:22.37
2024-12-27 17:59:06,308: Snapshot:2	Epoch:7	Loss:8.479	translation_Loss:6.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.08                                                   	MRR:22.49	Hits@10:39.6	Best:22.49
2024-12-27 17:59:14,082: Snapshot:2	Epoch:8	Loss:8.269	translation_Loss:6.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.073                                                   	MRR:22.45	Hits@10:39.84	Best:22.49
2024-12-27 17:59:21,887: Snapshot:2	Epoch:9	Loss:8.082	translation_Loss:6.02	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.062                                                   	MRR:22.54	Hits@10:39.83	Best:22.54
2024-12-27 17:59:29,680: Snapshot:2	Epoch:10	Loss:7.975	translation_Loss:5.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.061                                                   	MRR:22.62	Hits@10:40.03	Best:22.62
2024-12-27 17:59:37,526: Snapshot:2	Epoch:11	Loss:7.827	translation_Loss:5.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.054                                                   	MRR:22.72	Hits@10:40.31	Best:22.72
2024-12-27 17:59:45,320: Snapshot:2	Epoch:12	Loss:7.725	translation_Loss:5.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.051                                                   	MRR:22.81	Hits@10:40.17	Best:22.81
2024-12-27 17:59:53,341: Snapshot:2	Epoch:13	Loss:7.664	translation_Loss:5.63	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.034                                                   	MRR:22.74	Hits@10:40.1	Best:22.81
2024-12-27 18:00:01,223: Snapshot:2	Epoch:14	Loss:7.556	translation_Loss:5.53	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.026                                                   	MRR:22.86	Hits@10:40.26	Best:22.86
2024-12-27 18:00:09,721: Snapshot:2	Epoch:15	Loss:7.533	translation_Loss:5.49	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.043                                                   	MRR:22.8	Hits@10:40.35	Best:22.86
2024-12-27 18:00:17,560: Snapshot:2	Epoch:16	Loss:7.39	translation_Loss:5.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.022                                                   	MRR:22.81	Hits@10:40.41	Best:22.86
2024-12-27 18:00:25,424: Snapshot:2	Epoch:17	Loss:7.383	translation_Loss:5.359	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.024                                                   	MRR:22.91	Hits@10:40.32	Best:22.91
2024-12-27 18:00:33,213: Snapshot:2	Epoch:18	Loss:7.32	translation_Loss:5.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.025                                                   	MRR:22.84	Hits@10:40.43	Best:22.91
2024-12-27 18:00:41,085: Snapshot:2	Epoch:19	Loss:7.301	translation_Loss:5.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.03                                                   	MRR:22.97	Hits@10:40.52	Best:22.97
2024-12-27 18:00:49,021: Snapshot:2	Epoch:20	Loss:7.255	translation_Loss:5.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.02                                                   	MRR:23.0	Hits@10:40.43	Best:23.0
2024-12-27 18:00:56,870: Snapshot:2	Epoch:21	Loss:7.14	translation_Loss:5.131	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.009                                                   	MRR:22.94	Hits@10:40.63	Best:23.0
2024-12-27 18:01:04,835: Snapshot:2	Epoch:22	Loss:7.101	translation_Loss:5.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.0                                                   	MRR:22.84	Hits@10:40.48	Best:23.0
2024-12-27 18:01:12,671: Snapshot:2	Epoch:23	Loss:7.03	translation_Loss:5.032	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.998                                                   	MRR:22.82	Hits@10:40.24	Best:23.0
2024-12-27 18:01:20,658: Snapshot:2	Epoch:24	Loss:7.026	translation_Loss:5.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.986                                                   	MRR:22.94	Hits@10:40.44	Best:23.0
2024-12-27 18:01:28,611: Snapshot:2	Epoch:25	Loss:6.994	translation_Loss:5.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.983                                                   	MRR:23.12	Hits@10:40.56	Best:23.12
2024-12-27 18:01:36,465: Snapshot:2	Epoch:26	Loss:6.948	translation_Loss:4.971	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.977                                                   	MRR:23.19	Hits@10:40.7	Best:23.19
2024-12-27 18:01:44,198: Snapshot:2	Epoch:27	Loss:6.919	translation_Loss:4.94	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.978                                                   	MRR:23.04	Hits@10:40.46	Best:23.19
2024-12-27 18:01:51,971: Snapshot:2	Epoch:28	Loss:6.872	translation_Loss:4.908	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.965                                                   	MRR:23.08	Hits@10:40.57	Best:23.19
2024-12-27 18:01:59,879: Snapshot:2	Epoch:29	Loss:6.913	translation_Loss:4.923	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.99                                                   	MRR:23.06	Hits@10:40.71	Best:23.19
2024-12-27 18:02:08,038: Snapshot:2	Epoch:30	Loss:6.894	translation_Loss:4.907	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.987                                                   	MRR:22.95	Hits@10:40.61	Best:23.19
2024-12-27 18:02:15,815: Early Stopping! Snapshot: 2 Epoch: 31 Best Results: 23.19
2024-12-27 18:02:15,816: Start to training tokens! Snapshot: 2 Epoch: 31 Loss:6.791 MRR:23.13 Best Results: 23.19
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 18:02:15,816: Snapshot:2	Epoch:31	Loss:6.791	translation_Loss:4.833	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.958                                                   	MRR:23.13	Hits@10:40.67	Best:23.19
2024-12-27 18:02:23,636: Snapshot:2	Epoch:32	Loss:93.834	translation_Loss:93.734	multi_layer_Loss:0.1	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.13	Hits@10:40.67	Best:23.19
2024-12-27 18:02:31,488: End of token training: 2 Epoch: 33 Loss:93.725 MRR:23.13 Best Results: 23.19
2024-12-27 18:02:31,488: Snapshot:2	Epoch:33	Loss:93.725	translation_Loss:93.725	multi_layer_Loss:-0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.13	Hits@10:40.67	Best:23.19
2024-12-27 18:02:31,700: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_2/2model_best.tar'
2024-12-27 18:02:38,337: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3305 | 0.2107 | 0.385  | 0.4599 |  0.5612 |
|     1      | 0.2472 | 0.1491 | 0.2829 | 0.3457 |  0.436  |
|     2      | 0.2309 | 0.1351 | 0.2668 | 0.3297 |  0.4134 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:03:05,144: Snapshot:3	Epoch:0	Loss:42.019	translation_Loss:38.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.783                                                   	MRR:18.12	Hits@10:32.66	Best:18.12
2024-12-27 18:03:13,040: Snapshot:3	Epoch:1	Loss:13.307	translation_Loss:10.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.44                                                   	MRR:19.83	Hits@10:35.92	Best:19.83
2024-12-27 18:03:21,015: Snapshot:3	Epoch:2	Loss:9.967	translation_Loss:7.8	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.167                                                   	MRR:20.51	Hits@10:36.83	Best:20.51
2024-12-27 18:03:28,939: Snapshot:3	Epoch:3	Loss:8.81	translation_Loss:6.717	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.092                                                   	MRR:20.88	Hits@10:37.52	Best:20.88
2024-12-27 18:03:36,920: Snapshot:3	Epoch:4	Loss:8.264	translation_Loss:6.201	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.062                                                   	MRR:21.25	Hits@10:38.08	Best:21.25
2024-12-27 18:03:44,967: Snapshot:3	Epoch:5	Loss:7.87	translation_Loss:5.84	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.029                                                   	MRR:21.35	Hits@10:38.33	Best:21.35
2024-12-27 18:03:52,915: Snapshot:3	Epoch:6	Loss:7.504	translation_Loss:5.49	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.013                                                   	MRR:21.45	Hits@10:38.58	Best:21.45
2024-12-27 18:04:00,852: Snapshot:3	Epoch:7	Loss:7.363	translation_Loss:5.337	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.026                                                   	MRR:21.69	Hits@10:38.79	Best:21.69
2024-12-27 18:04:08,709: Snapshot:3	Epoch:8	Loss:7.173	translation_Loss:5.147	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.026                                                   	MRR:21.43	Hits@10:38.63	Best:21.69
2024-12-27 18:04:16,542: Snapshot:3	Epoch:9	Loss:7.058	translation_Loss:5.049	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.009                                                   	MRR:21.42	Hits@10:39.19	Best:21.69
2024-12-27 18:04:24,452: Snapshot:3	Epoch:10	Loss:6.922	translation_Loss:4.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.008                                                   	MRR:21.7	Hits@10:39.19	Best:21.7
2024-12-27 18:04:32,242: Snapshot:3	Epoch:11	Loss:6.807	translation_Loss:4.816	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.99                                                   	MRR:21.71	Hits@10:39.32	Best:21.71
2024-12-27 18:04:40,307: Snapshot:3	Epoch:12	Loss:6.75	translation_Loss:4.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.016                                                   	MRR:21.83	Hits@10:39.13	Best:21.83
2024-12-27 18:04:48,150: Snapshot:3	Epoch:13	Loss:6.613	translation_Loss:4.629	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.984                                                   	MRR:21.83	Hits@10:39.44	Best:21.83
2024-12-27 18:04:56,128: Snapshot:3	Epoch:14	Loss:6.555	translation_Loss:4.573	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.982                                                   	MRR:21.85	Hits@10:39.44	Best:21.85
2024-12-27 18:05:04,134: Snapshot:3	Epoch:15	Loss:6.527	translation_Loss:4.56	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.967                                                   	MRR:21.89	Hits@10:39.54	Best:21.89
2024-12-27 18:05:12,016: Snapshot:3	Epoch:16	Loss:6.432	translation_Loss:4.462	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.97                                                   	MRR:21.84	Hits@10:39.6	Best:21.89
2024-12-27 18:05:19,973: Snapshot:3	Epoch:17	Loss:6.332	translation_Loss:4.396	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.937                                                   	MRR:22.05	Hits@10:39.52	Best:22.05
2024-12-27 18:05:27,904: Snapshot:3	Epoch:18	Loss:6.281	translation_Loss:4.334	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.946                                                   	MRR:21.9	Hits@10:39.65	Best:22.05
2024-12-27 18:05:35,726: Snapshot:3	Epoch:19	Loss:6.32	translation_Loss:4.334	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.986                                                   	MRR:21.91	Hits@10:39.8	Best:22.05
2024-12-27 18:05:43,568: Snapshot:3	Epoch:20	Loss:6.247	translation_Loss:4.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.953                                                   	MRR:21.82	Hits@10:39.72	Best:22.05
2024-12-27 18:05:51,393: Snapshot:3	Epoch:21	Loss:6.192	translation_Loss:4.249	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.943                                                   	MRR:21.89	Hits@10:39.61	Best:22.05
2024-12-27 18:05:59,302: Snapshot:3	Epoch:22	Loss:6.201	translation_Loss:4.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.972                                                   	MRR:22.1	Hits@10:39.98	Best:22.1
2024-12-27 18:06:07,211: Snapshot:3	Epoch:23	Loss:6.123	translation_Loss:4.193	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.93                                                   	MRR:22.11	Hits@10:39.88	Best:22.11
2024-12-27 18:06:15,095: Snapshot:3	Epoch:24	Loss:6.07	translation_Loss:4.139	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.931                                                   	MRR:22.14	Hits@10:40.1	Best:22.14
2024-12-27 18:06:22,915: Snapshot:3	Epoch:25	Loss:6.124	translation_Loss:4.169	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.955                                                   	MRR:22.12	Hits@10:39.91	Best:22.14
2024-12-27 18:06:30,725: Snapshot:3	Epoch:26	Loss:5.976	translation_Loss:4.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.911                                                   	MRR:21.99	Hits@10:39.81	Best:22.14
2024-12-27 18:06:38,577: Snapshot:3	Epoch:27	Loss:6.011	translation_Loss:4.097	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.914                                                   	MRR:22.11	Hits@10:39.59	Best:22.14
2024-12-27 18:06:46,798: Snapshot:3	Epoch:28	Loss:6.031	translation_Loss:4.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.941                                                   	MRR:22.13	Hits@10:39.78	Best:22.14
2024-12-27 18:06:54,700: Snapshot:3	Epoch:29	Loss:5.911	translation_Loss:4.0	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.912                                                   	MRR:22.22	Hits@10:39.87	Best:22.22
2024-12-27 18:07:02,688: Snapshot:3	Epoch:30	Loss:5.822	translation_Loss:3.93	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.892                                                   	MRR:22.36	Hits@10:40.18	Best:22.36
2024-12-27 18:07:10,579: Snapshot:3	Epoch:31	Loss:5.816	translation_Loss:3.931	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.886                                                   	MRR:22.37	Hits@10:40.26	Best:22.37
2024-12-27 18:07:18,452: Snapshot:3	Epoch:32	Loss:5.951	translation_Loss:4.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.94                                                   	MRR:22.16	Hits@10:40.11	Best:22.37
2024-12-27 18:07:26,252: Snapshot:3	Epoch:33	Loss:5.865	translation_Loss:3.957	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.908                                                   	MRR:22.16	Hits@10:40.2	Best:22.37
2024-12-27 18:07:34,066: Snapshot:3	Epoch:34	Loss:5.867	translation_Loss:3.948	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.919                                                   	MRR:22.04	Hits@10:39.94	Best:22.37
2024-12-27 18:07:41,867: Snapshot:3	Epoch:35	Loss:5.808	translation_Loss:3.903	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.905                                                   	MRR:22.27	Hits@10:39.9	Best:22.37
2024-12-27 18:07:49,706: Early Stopping! Snapshot: 3 Epoch: 36 Best Results: 22.37
2024-12-27 18:07:49,706: Start to training tokens! Snapshot: 3 Epoch: 36 Loss:5.811 MRR:22.33 Best Results: 22.37
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 18:07:49,707: Snapshot:3	Epoch:36	Loss:5.811	translation_Loss:3.918	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.893                                                   	MRR:22.33	Hits@10:40.15	Best:22.37
2024-12-27 18:07:57,615: Snapshot:3	Epoch:37	Loss:84.437	translation_Loss:84.329	multi_layer_Loss:0.108	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.33	Hits@10:40.15	Best:22.37
2024-12-27 18:08:05,448: End of token training: 3 Epoch: 38 Loss:84.351 MRR:22.33 Best Results: 22.37
2024-12-27 18:08:05,450: Snapshot:3	Epoch:38	Loss:84.351	translation_Loss:84.351	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.33	Hits@10:40.15	Best:22.37
2024-12-27 18:08:05,733: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_2/3model_best.tar'
2024-12-27 18:08:15,385: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3306 | 0.2105 | 0.3851 | 0.4601 |  0.5604 |
|     1      | 0.2477 | 0.1497 | 0.2835 | 0.3452 |  0.4362 |
|     2      | 0.2316 | 0.1361 | 0.2672 | 0.3293 |  0.4131 |
|     3      | 0.2236 | 0.1321 | 0.2583 | 0.3181 |  0.3971 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:08:35,504: Snapshot:4	Epoch:0	Loss:30.607	translation_Loss:28.081	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.526                                                   	MRR:21.8	Hits@10:40.14	Best:21.8
2024-12-27 18:08:41,172: Snapshot:4	Epoch:1	Loss:7.731	translation_Loss:6.325	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.405                                                   	MRR:24.22	Hits@10:43.33	Best:24.22
2024-12-27 18:08:46,877: Snapshot:4	Epoch:2	Loss:4.998	translation_Loss:3.85	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.148                                                   	MRR:24.98	Hits@10:44.54	Best:24.98
2024-12-27 18:08:52,541: Snapshot:4	Epoch:3	Loss:4.162	translation_Loss:3.119	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.043                                                   	MRR:25.19	Hits@10:44.98	Best:25.19
2024-12-27 18:08:58,242: Snapshot:4	Epoch:4	Loss:3.754	translation_Loss:2.735	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.019                                                   	MRR:25.28	Hits@10:45.09	Best:25.28
2024-12-27 18:09:03,888: Snapshot:4	Epoch:5	Loss:3.537	translation_Loss:2.538	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.999                                                   	MRR:25.41	Hits@10:45.29	Best:25.41
2024-12-27 18:09:09,521: Snapshot:4	Epoch:6	Loss:3.422	translation_Loss:2.407	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.015                                                   	MRR:25.56	Hits@10:45.5	Best:25.56
2024-12-27 18:09:15,176: Snapshot:4	Epoch:7	Loss:3.251	translation_Loss:2.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.98                                                   	MRR:25.86	Hits@10:45.87	Best:25.86
2024-12-27 18:09:20,803: Snapshot:4	Epoch:8	Loss:3.174	translation_Loss:2.185	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.989                                                   	MRR:25.71	Hits@10:46.08	Best:25.86
2024-12-27 18:09:26,368: Snapshot:4	Epoch:9	Loss:3.086	translation_Loss:2.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.97                                                   	MRR:25.82	Hits@10:46.14	Best:25.86
2024-12-27 18:09:31,969: Snapshot:4	Epoch:10	Loss:3.009	translation_Loss:2.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.971                                                   	MRR:25.8	Hits@10:46.37	Best:25.86
2024-12-27 18:09:37,554: Snapshot:4	Epoch:11	Loss:2.981	translation_Loss:2.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.971                                                   	MRR:25.66	Hits@10:46.14	Best:25.86
2024-12-27 18:09:43,115: Early Stopping! Snapshot: 4 Epoch: 12 Best Results: 25.86
2024-12-27 18:09:43,115: Start to training tokens! Snapshot: 4 Epoch: 12 Loss:2.941 MRR:25.6 Best Results: 25.86
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 18:09:43,116: Snapshot:4	Epoch:12	Loss:2.941	translation_Loss:1.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.967                                                   	MRR:25.6	Hits@10:46.06	Best:25.86
2024-12-27 18:09:48,688: Snapshot:4	Epoch:13	Loss:45.939	translation_Loss:45.839	multi_layer_Loss:0.1	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.6	Hits@10:46.06	Best:25.86
2024-12-27 18:09:54,248: End of token training: 4 Epoch: 14 Loss:45.807 MRR:25.6 Best Results: 25.86
2024-12-27 18:09:54,249: Snapshot:4	Epoch:14	Loss:45.807	translation_Loss:45.807	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.6	Hits@10:46.06	Best:25.86
2024-12-27 18:09:54,540: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_2/4model_best.tar'
2024-12-27 18:10:06,445: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3291 | 0.2095 | 0.3813 | 0.4572 |  0.5603 |
|     1      | 0.2471 | 0.1482 | 0.2836 | 0.347  |  0.4356 |
|     2      | 0.2322 | 0.1366 | 0.2679 | 0.331  |  0.4136 |
|     3      | 0.2255 | 0.1347 | 0.2592 | 0.3192 |  0.3985 |
|     4      | 0.2609 | 0.1532 | 0.3121 | 0.3838 |  0.465  |
+------------+--------+--------+--------+--------+---------+
2024-12-27 18:10:06,447: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3305 | 0.211  | 0.3836 | 0.461  |  0.5606 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.331  | 0.2121 | 0.3841 | 0.4603 |  0.5602 |
|     1      | 0.2478 | 0.1505 | 0.283  | 0.3458 |  0.4352 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3305 | 0.2107 | 0.385  | 0.4599 |  0.5612 |
|     1      | 0.2472 | 0.1491 | 0.2829 | 0.3457 |  0.436  |
|     2      | 0.2309 | 0.1351 | 0.2668 | 0.3297 |  0.4134 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3306 | 0.2105 | 0.3851 | 0.4601 |  0.5604 |
|     1      | 0.2477 | 0.1497 | 0.2835 | 0.3452 |  0.4362 |
|     2      | 0.2316 | 0.1361 | 0.2672 | 0.3293 |  0.4131 |
|     3      | 0.2236 | 0.1321 | 0.2583 | 0.3181 |  0.3971 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3291 | 0.2095 | 0.3813 | 0.4572 |  0.5603 |
|     1      | 0.2471 | 0.1482 | 0.2836 | 0.347  |  0.4356 |
|     2      | 0.2322 | 0.1366 | 0.2679 | 0.331  |  0.4136 |
|     3      | 0.2255 | 0.1347 | 0.2592 | 0.3192 |  0.3985 |
|     4      | 0.2609 | 0.1532 | 0.3121 | 0.3838 |  0.465  |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 18:10:06,448: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 56.48476982116699  |   0.331   |    0.211     |    0.384     |     0.561     |
|    1     | 210.16266560554504 |    0.28   |    0.175     |    0.323     |     0.484     |
|    2     | 283.56172800064087 |   0.261   |    0.159     |    0.301     |     0.458     |
|    3     | 323.8816759586334  |   0.251   |    0.152     |     0.29     |     0.441     |
|    4     | 96.16609477996826  |   0.253   |    0.152     |    0.293     |     0.445     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 18:10:06,448: Sum_Training_Time:970.2569341659546
2024-12-27 18:10:06,448: Every_Training_Time:[56.48476982116699, 210.16266560554504, 283.56172800064087, 323.8816759586334, 96.16609477996826]
2024-12-27 18:10:06,448: Forward transfer: 0.046450000000000005 Backward transfer: 0.00027499999999999747
2024-12-27 18:10:41,277: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227181011/ENTITYentity_0.001_512_4', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.001_512_4', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.001_512_4', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=4, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 18:10:49,012: Snapshot:0	Epoch:0	Loss:69.32	translation_Loss:69.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.71	Hits@10:32.99	Best:13.71
2024-12-27 18:10:53,030: Snapshot:0	Epoch:1	Loss:39.17	translation_Loss:39.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.17	Hits@10:49.22	Best:26.17
2024-12-27 18:10:57,072: Snapshot:0	Epoch:2	Loss:18.413	translation_Loss:18.413	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.93	Hits@10:54.23	Best:30.93
2024-12-27 18:11:01,045: Snapshot:0	Epoch:3	Loss:9.28	translation_Loss:9.28	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.2	Hits@10:55.41	Best:32.2
2024-12-27 18:11:05,003: Snapshot:0	Epoch:4	Loss:5.425	translation_Loss:5.425	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.61	Hits@10:55.68	Best:32.61
2024-12-27 18:11:08,951: Snapshot:0	Epoch:5	Loss:3.692	translation_Loss:3.692	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.64	Hits@10:55.67	Best:32.64
2024-12-27 18:11:12,888: Snapshot:0	Epoch:6	Loss:2.81	translation_Loss:2.81	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.58	Hits@10:55.57	Best:32.64
2024-12-27 18:11:16,829: Snapshot:0	Epoch:7	Loss:2.277	translation_Loss:2.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.44	Hits@10:55.3	Best:32.64
2024-12-27 18:11:20,778: Snapshot:0	Epoch:8	Loss:1.939	translation_Loss:1.939	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.27	Hits@10:54.72	Best:32.64
2024-12-27 18:11:24,718: Snapshot:0	Epoch:9	Loss:1.704	translation_Loss:1.704	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.24	Hits@10:54.68	Best:32.64
2024-12-27 18:11:28,643: Early Stopping! Snapshot: 0 Epoch: 10 Best Results: 32.64
2024-12-27 18:11:28,643: Start to training tokens! Snapshot: 0 Epoch: 10 Loss:1.557 MRR:31.79 Best Results: 32.64
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 18:11:28,643: Snapshot:0	Epoch:10	Loss:1.557	translation_Loss:1.557	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.79	Hits@10:54.5	Best:32.64
2024-12-27 18:11:33,316: Snapshot:0	Epoch:11	Loss:56.267	translation_Loss:56.129	multi_layer_Loss:0.138	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.79	Hits@10:54.5	Best:32.64
2024-12-27 18:11:37,559: End of token training: 0 Epoch: 12 Loss:56.115 MRR:31.79 Best Results: 32.64
2024-12-27 18:11:37,560: Snapshot:0	Epoch:12	Loss:56.115	translation_Loss:56.115	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.79	Hits@10:54.5	Best:32.64
2024-12-27 18:11:37,868: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_4/0model_best.tar'
2024-12-27 18:11:39,427: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3315 | 0.2132 | 0.3835 | 0.4597 |  0.5588 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:12:03,964: Snapshot:1	Epoch:0	Loss:51.239	translation_Loss:48.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.084                                                   	MRR:20.98	Hits@10:37.44	Best:20.98
2024-12-27 18:12:11,143: Snapshot:1	Epoch:1	Loss:15.974	translation_Loss:14.122	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.852                                                   	MRR:23.09	Hits@10:41.18	Best:23.09
2024-12-27 18:12:18,396: Snapshot:1	Epoch:2	Loss:11.214	translation_Loss:9.543	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.671                                                   	MRR:23.52	Hits@10:42.43	Best:23.52
2024-12-27 18:12:25,495: Snapshot:1	Epoch:3	Loss:9.486	translation_Loss:7.966	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.519                                                   	MRR:23.61	Hits@10:42.39	Best:23.61
2024-12-27 18:12:32,636: Snapshot:1	Epoch:4	Loss:8.699	translation_Loss:7.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.5                                                   	MRR:23.82	Hits@10:42.7	Best:23.82
2024-12-27 18:12:39,848: Snapshot:1	Epoch:5	Loss:8.238	translation_Loss:6.743	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.495                                                   	MRR:24.22	Hits@10:42.86	Best:24.22
2024-12-27 18:12:47,142: Snapshot:1	Epoch:6	Loss:7.88	translation_Loss:6.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.49                                                   	MRR:24.23	Hits@10:43.23	Best:24.23
2024-12-27 18:12:54,294: Snapshot:1	Epoch:7	Loss:7.565	translation_Loss:6.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.471                                                   	MRR:24.26	Hits@10:42.99	Best:24.26
2024-12-27 18:13:01,630: Snapshot:1	Epoch:8	Loss:7.355	translation_Loss:5.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.466                                                   	MRR:24.11	Hits@10:43.15	Best:24.26
2024-12-27 18:13:08,782: Snapshot:1	Epoch:9	Loss:7.155	translation_Loss:5.703	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.452                                                   	MRR:24.25	Hits@10:43.22	Best:24.26
2024-12-27 18:13:16,049: Snapshot:1	Epoch:10	Loss:7.09	translation_Loss:5.638	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.452                                                   	MRR:24.29	Hits@10:43.11	Best:24.29
2024-12-27 18:13:23,175: Snapshot:1	Epoch:11	Loss:6.898	translation_Loss:5.461	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.438                                                   	MRR:24.47	Hits@10:43.5	Best:24.47
2024-12-27 18:13:30,402: Snapshot:1	Epoch:12	Loss:6.794	translation_Loss:5.348	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.446                                                   	MRR:24.53	Hits@10:43.46	Best:24.53
2024-12-27 18:13:37,532: Snapshot:1	Epoch:13	Loss:6.664	translation_Loss:5.225	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.439                                                   	MRR:24.46	Hits@10:43.28	Best:24.53
2024-12-27 18:13:44,654: Snapshot:1	Epoch:14	Loss:6.561	translation_Loss:5.143	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.418                                                   	MRR:24.52	Hits@10:43.4	Best:24.53
2024-12-27 18:13:51,894: Snapshot:1	Epoch:15	Loss:6.543	translation_Loss:5.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.431                                                   	MRR:24.54	Hits@10:43.3	Best:24.54
2024-12-27 18:13:59,157: Snapshot:1	Epoch:16	Loss:6.527	translation_Loss:5.079	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.448                                                   	MRR:24.41	Hits@10:43.52	Best:24.54
2024-12-27 18:14:06,433: Snapshot:1	Epoch:17	Loss:6.367	translation_Loss:4.955	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.412                                                   	MRR:24.58	Hits@10:43.51	Best:24.58
2024-12-27 18:14:13,571: Snapshot:1	Epoch:18	Loss:6.287	translation_Loss:4.868	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.419                                                   	MRR:24.48	Hits@10:43.6	Best:24.58
2024-12-27 18:14:20,779: Snapshot:1	Epoch:19	Loss:6.312	translation_Loss:4.885	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.427                                                   	MRR:24.67	Hits@10:43.61	Best:24.67
2024-12-27 18:14:28,358: Snapshot:1	Epoch:20	Loss:6.188	translation_Loss:4.792	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.396                                                   	MRR:24.45	Hits@10:43.64	Best:24.67
2024-12-27 18:14:35,479: Snapshot:1	Epoch:21	Loss:6.194	translation_Loss:4.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.415                                                   	MRR:24.67	Hits@10:43.77	Best:24.67
2024-12-27 18:14:42,639: Snapshot:1	Epoch:22	Loss:6.129	translation_Loss:4.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.413                                                   	MRR:24.49	Hits@10:43.45	Best:24.67
2024-12-27 18:14:49,780: Snapshot:1	Epoch:23	Loss:6.093	translation_Loss:4.688	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.405                                                   	MRR:24.65	Hits@10:43.47	Best:24.67
2024-12-27 18:14:57,040: Early Stopping! Snapshot: 1 Epoch: 24 Best Results: 24.67
2024-12-27 18:14:57,040: Start to training tokens! Snapshot: 1 Epoch: 24 Loss:6.103 MRR:24.54 Best Results: 24.67
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 18:14:57,040: Snapshot:1	Epoch:24	Loss:6.103	translation_Loss:4.691	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.411                                                   	MRR:24.54	Hits@10:43.26	Best:24.67
2024-12-27 18:15:04,262: Snapshot:1	Epoch:25	Loss:93.082	translation_Loss:92.938	multi_layer_Loss:0.144	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.54	Hits@10:43.26	Best:24.67
2024-12-27 18:15:11,526: End of token training: 1 Epoch: 26 Loss:92.78 MRR:24.54 Best Results: 24.67
2024-12-27 18:15:11,526: Snapshot:1	Epoch:26	Loss:92.78	translation_Loss:92.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.54	Hits@10:43.26	Best:24.67
2024-12-27 18:15:11,806: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_4/1model_best.tar'
2024-12-27 18:15:15,470: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.331  | 0.2123 | 0.3831 | 0.4594 |  0.5593 |
|     1      | 0.2478 | 0.1505 | 0.2829 | 0.3486 |  0.4349 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:15:41,754: Snapshot:2	Epoch:0	Loss:46.786	translation_Loss:43.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.693                                                   	MRR:18.41	Hits@10:32.54	Best:18.41
2024-12-27 18:15:49,584: Snapshot:2	Epoch:1	Loss:15.157	translation_Loss:12.891	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.266                                                   	MRR:20.64	Hits@10:36.64	Best:20.64
2024-12-27 18:15:57,365: Snapshot:2	Epoch:2	Loss:11.5	translation_Loss:9.455	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.045                                                   	MRR:21.13	Hits@10:37.74	Best:21.13
2024-12-27 18:16:05,241: Snapshot:2	Epoch:3	Loss:10.116	translation_Loss:8.144	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.972                                                   	MRR:21.96	Hits@10:38.73	Best:21.96
2024-12-27 18:16:13,119: Snapshot:2	Epoch:4	Loss:9.419	translation_Loss:7.471	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.948                                                   	MRR:21.99	Hits@10:39.04	Best:21.99
2024-12-27 18:16:21,044: Snapshot:2	Epoch:5	Loss:8.933	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.919                                                   	MRR:22.16	Hits@10:39.2	Best:22.16
2024-12-27 18:16:28,951: Snapshot:2	Epoch:6	Loss:8.584	translation_Loss:6.672	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.912                                                   	MRR:22.14	Hits@10:39.51	Best:22.16
2024-12-27 18:16:36,726: Snapshot:2	Epoch:7	Loss:8.365	translation_Loss:6.444	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.921                                                   	MRR:22.46	Hits@10:39.91	Best:22.46
2024-12-27 18:16:44,567: Snapshot:2	Epoch:8	Loss:8.135	translation_Loss:6.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.901                                                   	MRR:22.44	Hits@10:39.98	Best:22.46
2024-12-27 18:16:52,415: Snapshot:2	Epoch:9	Loss:7.955	translation_Loss:6.05	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.905                                                   	MRR:22.6	Hits@10:40.02	Best:22.6
2024-12-27 18:17:00,285: Snapshot:2	Epoch:10	Loss:7.831	translation_Loss:5.948	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.882                                                   	MRR:22.7	Hits@10:39.97	Best:22.7
2024-12-27 18:17:08,030: Snapshot:2	Epoch:11	Loss:7.662	translation_Loss:5.792	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.869                                                   	MRR:22.72	Hits@10:40.16	Best:22.72
2024-12-27 18:17:15,908: Snapshot:2	Epoch:12	Loss:7.576	translation_Loss:5.709	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.867                                                   	MRR:22.66	Hits@10:40.04	Best:22.72
2024-12-27 18:17:23,711: Snapshot:2	Epoch:13	Loss:7.53	translation_Loss:5.662	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.868                                                   	MRR:22.72	Hits@10:40.17	Best:22.72
2024-12-27 18:17:31,483: Snapshot:2	Epoch:14	Loss:7.442	translation_Loss:5.577	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.865                                                   	MRR:22.77	Hits@10:40.24	Best:22.77
2024-12-27 18:17:39,737: Snapshot:2	Epoch:15	Loss:7.379	translation_Loss:5.513	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.865                                                   	MRR:22.78	Hits@10:40.32	Best:22.78
2024-12-27 18:17:47,590: Snapshot:2	Epoch:16	Loss:7.253	translation_Loss:5.4	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.853                                                   	MRR:22.79	Hits@10:40.35	Best:22.79
2024-12-27 18:17:55,335: Snapshot:2	Epoch:17	Loss:7.228	translation_Loss:5.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.843                                                   	MRR:22.76	Hits@10:40.4	Best:22.79
2024-12-27 18:18:03,223: Snapshot:2	Epoch:18	Loss:7.191	translation_Loss:5.336	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.855                                                   	MRR:22.81	Hits@10:40.16	Best:22.81
2024-12-27 18:18:10,993: Snapshot:2	Epoch:19	Loss:7.171	translation_Loss:5.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.866                                                   	MRR:22.93	Hits@10:40.54	Best:22.93
2024-12-27 18:18:18,765: Snapshot:2	Epoch:20	Loss:7.109	translation_Loss:5.259	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.85                                                   	MRR:22.89	Hits@10:40.56	Best:22.93
2024-12-27 18:18:26,644: Snapshot:2	Epoch:21	Loss:6.999	translation_Loss:5.168	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.831                                                   	MRR:22.82	Hits@10:40.6	Best:22.93
2024-12-27 18:18:34,427: Snapshot:2	Epoch:22	Loss:6.964	translation_Loss:5.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.826                                                   	MRR:22.82	Hits@10:40.53	Best:22.93
2024-12-27 18:18:42,211: Snapshot:2	Epoch:23	Loss:6.895	translation_Loss:5.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.829                                                   	MRR:22.95	Hits@10:40.56	Best:22.95
2024-12-27 18:18:50,081: Snapshot:2	Epoch:24	Loss:6.885	translation_Loss:5.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.819                                                   	MRR:22.89	Hits@10:40.66	Best:22.95
2024-12-27 18:18:57,891: Snapshot:2	Epoch:25	Loss:6.85	translation_Loss:5.044	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.807                                                   	MRR:22.98	Hits@10:40.51	Best:22.98
2024-12-27 18:19:05,706: Snapshot:2	Epoch:26	Loss:6.797	translation_Loss:4.994	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.803                                                   	MRR:23.01	Hits@10:40.72	Best:23.01
2024-12-27 18:19:13,391: Snapshot:2	Epoch:27	Loss:6.768	translation_Loss:4.972	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.796                                                   	MRR:22.93	Hits@10:40.55	Best:23.01
2024-12-27 18:19:21,151: Snapshot:2	Epoch:28	Loss:6.733	translation_Loss:4.942	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.791                                                   	MRR:22.98	Hits@10:40.66	Best:23.01
2024-12-27 18:19:28,861: Snapshot:2	Epoch:29	Loss:6.774	translation_Loss:4.957	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.817                                                   	MRR:22.99	Hits@10:40.7	Best:23.01
2024-12-27 18:19:37,037: Snapshot:2	Epoch:30	Loss:6.758	translation_Loss:4.938	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.82                                                   	MRR:23.05	Hits@10:40.77	Best:23.05
2024-12-27 18:19:44,822: Snapshot:2	Epoch:31	Loss:6.65	translation_Loss:4.869	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.781                                                   	MRR:23.05	Hits@10:40.96	Best:23.05
2024-12-27 18:19:52,626: Snapshot:2	Epoch:32	Loss:6.677	translation_Loss:4.871	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.806                                                   	MRR:22.96	Hits@10:40.79	Best:23.05
2024-12-27 18:20:00,347: Snapshot:2	Epoch:33	Loss:6.608	translation_Loss:4.811	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.797                                                   	MRR:22.93	Hits@10:40.84	Best:23.05
2024-12-27 18:20:08,357: Snapshot:2	Epoch:34	Loss:6.602	translation_Loss:4.81	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.792                                                   	MRR:23.0	Hits@10:40.85	Best:23.05
2024-12-27 18:20:16,199: Snapshot:2	Epoch:35	Loss:6.598	translation_Loss:4.802	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.796                                                   	MRR:23.07	Hits@10:40.94	Best:23.07
2024-12-27 18:20:23,980: Snapshot:2	Epoch:36	Loss:6.582	translation_Loss:4.778	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.803                                                   	MRR:23.18	Hits@10:40.84	Best:23.18
2024-12-27 18:20:31,741: Snapshot:2	Epoch:37	Loss:6.461	translation_Loss:4.705	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.756                                                   	MRR:23.1	Hits@10:40.96	Best:23.18
2024-12-27 18:20:39,511: Snapshot:2	Epoch:38	Loss:6.521	translation_Loss:4.733	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.788                                                   	MRR:23.04	Hits@10:40.95	Best:23.18
2024-12-27 18:20:47,361: Snapshot:2	Epoch:39	Loss:6.436	translation_Loss:4.673	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.763                                                   	MRR:23.1	Hits@10:41.05	Best:23.18
2024-12-27 18:20:55,081: Snapshot:2	Epoch:40	Loss:6.423	translation_Loss:4.667	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.756                                                   	MRR:23.1	Hits@10:41.03	Best:23.18
2024-12-27 18:21:02,962: Early Stopping! Snapshot: 2 Epoch: 41 Best Results: 23.18
2024-12-27 18:21:02,962: Start to training tokens! Snapshot: 2 Epoch: 41 Loss:6.409 MRR:22.98 Best Results: 23.18
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 18:21:02,963: Snapshot:2	Epoch:41	Loss:6.409	translation_Loss:4.641	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.768                                                   	MRR:22.98	Hits@10:40.64	Best:23.18
2024-12-27 18:21:10,747: Snapshot:2	Epoch:42	Loss:93.761	translation_Loss:93.619	multi_layer_Loss:0.142	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.98	Hits@10:40.64	Best:23.18
2024-12-27 18:21:18,567: End of token training: 2 Epoch: 43 Loss:93.772 MRR:22.98 Best Results: 23.18
2024-12-27 18:21:18,568: Snapshot:2	Epoch:43	Loss:93.772	translation_Loss:93.772	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.98	Hits@10:40.64	Best:23.18
2024-12-27 18:21:18,823: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_4/2model_best.tar'
2024-12-27 18:21:25,263: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3311 | 0.2118 | 0.3845 | 0.4589 |  0.5588 |
|     1      | 0.2485 | 0.1513 | 0.2834 | 0.349  |  0.4362 |
|     2      | 0.233  | 0.1381 | 0.2687 | 0.3318 |  0.4127 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:21:51,918: Snapshot:3	Epoch:0	Loss:41.85	translation_Loss:38.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.619                                                   	MRR:17.98	Hits@10:32.44	Best:17.98
2024-12-27 18:21:59,807: Snapshot:3	Epoch:1	Loss:13.073	translation_Loss:10.908	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.165                                                   	MRR:19.61	Hits@10:35.8	Best:19.61
2024-12-27 18:22:07,696: Snapshot:3	Epoch:2	Loss:9.825	translation_Loss:7.891	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.933                                                   	MRR:20.37	Hits@10:36.92	Best:20.37
2024-12-27 18:22:15,564: Snapshot:3	Epoch:3	Loss:8.761	translation_Loss:6.875	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.885                                                   	MRR:20.69	Hits@10:37.4	Best:20.69
2024-12-27 18:22:23,523: Snapshot:3	Epoch:4	Loss:8.112	translation_Loss:6.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.859                                                   	MRR:20.92	Hits@10:37.67	Best:20.92
2024-12-27 18:22:31,376: Snapshot:3	Epoch:5	Loss:7.766	translation_Loss:5.919	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.847                                                   	MRR:20.99	Hits@10:38.16	Best:20.99
2024-12-27 18:22:39,245: Snapshot:3	Epoch:6	Loss:7.486	translation_Loss:5.659	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.827                                                   	MRR:21.14	Hits@10:38.16	Best:21.14
2024-12-27 18:22:47,146: Snapshot:3	Epoch:7	Loss:7.228	translation_Loss:5.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.814                                                   	MRR:21.21	Hits@10:38.54	Best:21.21
2024-12-27 18:22:55,030: Snapshot:3	Epoch:8	Loss:7.045	translation_Loss:5.228	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.817                                                   	MRR:21.33	Hits@10:38.77	Best:21.33
2024-12-27 18:23:03,036: Snapshot:3	Epoch:9	Loss:6.895	translation_Loss:5.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.784                                                   	MRR:21.52	Hits@10:38.75	Best:21.52
2024-12-27 18:23:10,899: Snapshot:3	Epoch:10	Loss:6.805	translation_Loss:5.001	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.804                                                   	MRR:21.5	Hits@10:38.97	Best:21.52
2024-12-27 18:23:18,829: Snapshot:3	Epoch:11	Loss:6.654	translation_Loss:4.873	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.781                                                   	MRR:21.57	Hits@10:38.82	Best:21.57
2024-12-27 18:23:26,648: Snapshot:3	Epoch:12	Loss:6.594	translation_Loss:4.812	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.782                                                   	MRR:21.45	Hits@10:39.07	Best:21.57
2024-12-27 18:23:34,894: Snapshot:3	Epoch:13	Loss:6.497	translation_Loss:4.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.767                                                   	MRR:21.64	Hits@10:39.26	Best:21.64
2024-12-27 18:23:42,879: Snapshot:3	Epoch:14	Loss:6.349	translation_Loss:4.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.751                                                   	MRR:21.57	Hits@10:39.43	Best:21.64
2024-12-27 18:23:50,812: Snapshot:3	Epoch:15	Loss:6.368	translation_Loss:4.602	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.766                                                   	MRR:21.68	Hits@10:39.27	Best:21.68
2024-12-27 18:23:58,731: Snapshot:3	Epoch:16	Loss:6.28	translation_Loss:4.517	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.763                                                   	MRR:21.71	Hits@10:39.46	Best:21.71
2024-12-27 18:24:06,606: Snapshot:3	Epoch:17	Loss:6.236	translation_Loss:4.491	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.745                                                   	MRR:21.68	Hits@10:39.57	Best:21.71
2024-12-27 18:24:14,450: Snapshot:3	Epoch:18	Loss:6.217	translation_Loss:4.462	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.755                                                   	MRR:21.8	Hits@10:39.44	Best:21.8
2024-12-27 18:24:22,370: Snapshot:3	Epoch:19	Loss:6.181	translation_Loss:4.433	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.748                                                   	MRR:21.75	Hits@10:39.39	Best:21.8
2024-12-27 18:24:30,330: Snapshot:3	Epoch:20	Loss:6.077	translation_Loss:4.337	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.739                                                   	MRR:21.86	Hits@10:39.61	Best:21.86
2024-12-27 18:24:38,224: Snapshot:3	Epoch:21	Loss:6.066	translation_Loss:4.317	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.749                                                   	MRR:21.96	Hits@10:39.77	Best:21.96
2024-12-27 18:24:46,106: Snapshot:3	Epoch:22	Loss:6.064	translation_Loss:4.319	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.745                                                   	MRR:21.93	Hits@10:39.79	Best:21.96
2024-12-27 18:24:53,980: Snapshot:3	Epoch:23	Loss:5.947	translation_Loss:4.225	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.722                                                   	MRR:22.09	Hits@10:39.83	Best:22.09
2024-12-27 18:25:01,884: Snapshot:3	Epoch:24	Loss:5.944	translation_Loss:4.213	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.731                                                   	MRR:22.03	Hits@10:39.96	Best:22.09
2024-12-27 18:25:09,798: Snapshot:3	Epoch:25	Loss:5.927	translation_Loss:4.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.725                                                   	MRR:22.02	Hits@10:39.94	Best:22.09
2024-12-27 18:25:17,682: Snapshot:3	Epoch:26	Loss:5.896	translation_Loss:4.166	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.731                                                   	MRR:22.03	Hits@10:39.99	Best:22.09
2024-12-27 18:25:25,523: Snapshot:3	Epoch:27	Loss:5.826	translation_Loss:4.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.708                                                   	MRR:21.97	Hits@10:40.01	Best:22.09
2024-12-27 18:25:33,418: Early Stopping! Snapshot: 3 Epoch: 28 Best Results: 22.09
2024-12-27 18:25:33,419: Start to training tokens! Snapshot: 3 Epoch: 28 Loss:5.796 MRR:21.83 Best Results: 22.09
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 18:25:33,419: Snapshot:3	Epoch:28	Loss:5.796	translation_Loss:4.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.701                                                   	MRR:21.83	Hits@10:39.67	Best:22.09
2024-12-27 18:25:41,273: Snapshot:3	Epoch:29	Loss:84.565	translation_Loss:84.429	multi_layer_Loss:0.137	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.83	Hits@10:39.67	Best:22.09
2024-12-27 18:25:49,126: End of token training: 3 Epoch: 30 Loss:84.495 MRR:21.83 Best Results: 22.09
2024-12-27 18:25:49,127: Snapshot:3	Epoch:30	Loss:84.495	translation_Loss:84.495	multi_layer_Loss:-0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.83	Hits@10:39.67	Best:22.09
2024-12-27 18:25:49,427: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_4/3model_best.tar'
2024-12-27 18:25:58,989: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3315 | 0.2121 | 0.3851 | 0.4602 |  0.5585 |
|     1      | 0.2487 | 0.1515 | 0.2839 | 0.3487 |  0.4362 |
|     2      | 0.2338 | 0.1393 | 0.269  | 0.3318 |  0.4131 |
|     3      | 0.2197 | 0.1284 | 0.2538 | 0.3154 |  0.3936 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:26:18,655: Snapshot:4	Epoch:0	Loss:30.683	translation_Loss:28.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.575                                                   	MRR:21.69	Hits@10:39.85	Best:21.69
2024-12-27 18:26:24,212: Snapshot:4	Epoch:1	Loss:7.673	translation_Loss:6.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.288                                                   	MRR:24.48	Hits@10:43.53	Best:24.48
2024-12-27 18:26:29,828: Snapshot:4	Epoch:2	Loss:4.948	translation_Loss:3.889	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.059                                                   	MRR:24.98	Hits@10:44.89	Best:24.98
2024-12-27 18:26:35,477: Snapshot:4	Epoch:3	Loss:4.129	translation_Loss:3.149	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.98                                                   	MRR:25.26	Hits@10:45.38	Best:25.26
2024-12-27 18:26:41,176: Snapshot:4	Epoch:4	Loss:3.736	translation_Loss:2.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.943                                                   	MRR:25.37	Hits@10:45.42	Best:25.37
2024-12-27 18:26:46,838: Snapshot:4	Epoch:5	Loss:3.545	translation_Loss:2.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.935                                                   	MRR:25.2	Hits@10:45.49	Best:25.37
2024-12-27 18:26:52,489: Snapshot:4	Epoch:6	Loss:3.367	translation_Loss:2.437	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.93                                                   	MRR:25.4	Hits@10:45.75	Best:25.4
2024-12-27 18:26:58,220: Snapshot:4	Epoch:7	Loss:3.22	translation_Loss:2.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.924                                                   	MRR:25.67	Hits@10:45.82	Best:25.67
2024-12-27 18:27:03,803: Snapshot:4	Epoch:8	Loss:3.164	translation_Loss:2.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.922                                                   	MRR:25.59	Hits@10:45.7	Best:25.67
2024-12-27 18:27:09,419: Snapshot:4	Epoch:9	Loss:3.087	translation_Loss:2.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.906                                                   	MRR:25.5	Hits@10:46.06	Best:25.67
2024-12-27 18:27:15,042: Snapshot:4	Epoch:10	Loss:3.037	translation_Loss:2.112	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.925                                                   	MRR:25.74	Hits@10:46.26	Best:25.74
2024-12-27 18:27:20,701: Snapshot:4	Epoch:11	Loss:2.983	translation_Loss:2.075	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.908                                                   	MRR:25.87	Hits@10:46.32	Best:25.87
2024-12-27 18:27:26,315: Snapshot:4	Epoch:12	Loss:2.931	translation_Loss:2.013	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.918                                                   	MRR:25.95	Hits@10:46.26	Best:25.95
2024-12-27 18:27:31,894: Snapshot:4	Epoch:13	Loss:2.822	translation_Loss:1.936	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.886                                                   	MRR:25.91	Hits@10:46.09	Best:25.95
2024-12-27 18:27:37,490: Snapshot:4	Epoch:14	Loss:2.802	translation_Loss:1.906	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.896                                                   	MRR:25.71	Hits@10:46.14	Best:25.95
2024-12-27 18:27:43,059: Snapshot:4	Epoch:15	Loss:2.774	translation_Loss:1.876	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.898                                                   	MRR:25.74	Hits@10:46.28	Best:25.95
2024-12-27 18:27:48,772: Snapshot:4	Epoch:16	Loss:2.779	translation_Loss:1.873	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.907                                                   	MRR:25.91	Hits@10:46.39	Best:25.95
2024-12-27 18:27:54,350: Early Stopping! Snapshot: 4 Epoch: 17 Best Results: 25.95
2024-12-27 18:27:54,351: Start to training tokens! Snapshot: 4 Epoch: 17 Loss:2.738 MRR:25.82 Best Results: 25.95
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 18:27:54,351: Snapshot:4	Epoch:17	Loss:2.738	translation_Loss:1.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.901                                                   	MRR:25.82	Hits@10:46.36	Best:25.95
2024-12-27 18:27:59,968: Snapshot:4	Epoch:18	Loss:45.94	translation_Loss:45.795	multi_layer_Loss:0.145	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.82	Hits@10:46.36	Best:25.95
2024-12-27 18:28:05,620: End of token training: 4 Epoch: 19 Loss:45.819 MRR:25.82 Best Results: 25.95
2024-12-27 18:28:05,620: Snapshot:4	Epoch:19	Loss:45.819	translation_Loss:45.819	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.82	Hits@10:46.36	Best:25.95
2024-12-27 18:28:05,904: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_4/4model_best.tar'
2024-12-27 18:28:18,021: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.331  | 0.2119 | 0.3838 | 0.4588 |  0.5587 |
|     1      | 0.2495 | 0.1526 | 0.2836 | 0.3491 |  0.4359 |
|     2      | 0.235  | 0.141  | 0.2706 | 0.3331 |  0.4135 |
|     3      | 0.2208 | 0.1294 | 0.2551 | 0.3158 |  0.3954 |
|     4      | 0.2612 | 0.1531 | 0.3121 | 0.3823 |  0.4665 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 18:28:18,023: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3315 | 0.2132 | 0.3835 | 0.4597 |  0.5588 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.331  | 0.2123 | 0.3831 | 0.4594 |  0.5593 |
|     1      | 0.2478 | 0.1505 | 0.2829 | 0.3486 |  0.4349 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3311 | 0.2118 | 0.3845 | 0.4589 |  0.5588 |
|     1      | 0.2485 | 0.1513 | 0.2834 | 0.349  |  0.4362 |
|     2      | 0.233  | 0.1381 | 0.2687 | 0.3318 |  0.4127 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3315 | 0.2121 | 0.3851 | 0.4602 |  0.5585 |
|     1      | 0.2487 | 0.1515 | 0.2839 | 0.3487 |  0.4362 |
|     2      | 0.2338 | 0.1393 | 0.269  | 0.3318 |  0.4131 |
|     3      | 0.2197 | 0.1284 | 0.2538 | 0.3154 |  0.3936 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.331  | 0.2119 | 0.3838 | 0.4588 |  0.5587 |
|     1      | 0.2495 | 0.1526 | 0.2836 | 0.3491 |  0.4359 |
|     2      | 0.235  | 0.141  | 0.2706 | 0.3331 |  0.4135 |
|     3      | 0.2208 | 0.1294 | 0.2551 | 0.3158 |  0.3954 |
|     4      | 0.2612 | 0.1531 | 0.3121 | 0.3823 |  0.4665 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 18:28:18,024: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     |  56.2821319103241  |   0.332   |    0.213     |    0.384     |     0.559     |
|    1     | 209.8370385169983  |    0.28   |    0.175     |    0.322     |     0.484     |
|    2     | 360.1379644870758  |   0.262   |    0.161     |    0.302     |     0.457     |
|    3     | 260.56858253479004 |   0.251   |    0.153     |     0.29     |      0.44     |
|    4     | 124.1712532043457  |   0.254   |    0.154     |    0.293     |     0.444     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 18:28:18,024: Sum_Training_Time:1010.9969706535339
2024-12-27 18:28:18,024: Every_Training_Time:[56.2821319103241, 209.8370385169983, 360.1379644870758, 260.56858253479004, 124.1712532043457]
2024-12-27 18:28:18,024: Forward transfer: 0.046450000000000005 Backward transfer: 0.0010749999999999926
2024-12-27 18:28:51,287: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227182821/ENTITYentity_0.001_512_6', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.001_512_6', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.001_512_6', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=6, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 18:28:59,109: Snapshot:0	Epoch:0	Loss:69.32	translation_Loss:69.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.71	Hits@10:32.99	Best:13.71
2024-12-27 18:29:03,047: Snapshot:0	Epoch:1	Loss:39.17	translation_Loss:39.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.18	Hits@10:49.24	Best:26.18
2024-12-27 18:29:07,114: Snapshot:0	Epoch:2	Loss:18.416	translation_Loss:18.416	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.94	Hits@10:54.13	Best:30.94
2024-12-27 18:29:11,115: Snapshot:0	Epoch:3	Loss:9.282	translation_Loss:9.282	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.06	Hits@10:55.25	Best:32.06
2024-12-27 18:29:15,030: Snapshot:0	Epoch:4	Loss:5.429	translation_Loss:5.429	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.48	Hits@10:55.78	Best:32.48
2024-12-27 18:29:19,132: Snapshot:0	Epoch:5	Loss:3.689	translation_Loss:3.689	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.6	Hits@10:55.63	Best:32.6
2024-12-27 18:29:23,099: Snapshot:0	Epoch:6	Loss:2.807	translation_Loss:2.807	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.65	Hits@10:55.52	Best:32.65
2024-12-27 18:29:27,030: Snapshot:0	Epoch:7	Loss:2.272	translation_Loss:2.272	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.3	Hits@10:55.09	Best:32.65
2024-12-27 18:29:30,990: Snapshot:0	Epoch:8	Loss:1.943	translation_Loss:1.943	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.32	Hits@10:54.74	Best:32.65
2024-12-27 18:29:34,968: Snapshot:0	Epoch:9	Loss:1.702	translation_Loss:1.702	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.17	Hits@10:54.72	Best:32.65
2024-12-27 18:29:38,924: Snapshot:0	Epoch:10	Loss:1.562	translation_Loss:1.562	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.93	Hits@10:54.58	Best:32.65
2024-12-27 18:29:42,854: Early Stopping! Snapshot: 0 Epoch: 11 Best Results: 32.65
2024-12-27 18:29:42,854: Start to training tokens! Snapshot: 0 Epoch: 11 Loss:1.44 MRR:32.0 Best Results: 32.65
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 18:29:42,855: Snapshot:0	Epoch:11	Loss:1.44	translation_Loss:1.44	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.0	Hits@10:54.58	Best:32.65
2024-12-27 18:29:47,597: Snapshot:0	Epoch:12	Loss:56.29	translation_Loss:56.131	multi_layer_Loss:0.159	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.0	Hits@10:54.58	Best:32.65
2024-12-27 18:29:51,818: End of token training: 0 Epoch: 13 Loss:56.133 MRR:32.0 Best Results: 32.65
2024-12-27 18:29:51,818: Snapshot:0	Epoch:13	Loss:56.133	translation_Loss:56.133	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:32.0	Hits@10:54.58	Best:32.65
2024-12-27 18:29:52,113: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_6/0model_best.tar'
2024-12-27 18:29:53,708: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3316 | 0.2125 | 0.3849 | 0.459  |  0.5594 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:30:18,604: Snapshot:1	Epoch:0	Loss:50.327	translation_Loss:47.225	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.102                                                   	MRR:20.89	Hits@10:37.25	Best:20.89
2024-12-27 18:30:25,727: Snapshot:1	Epoch:1	Loss:14.77	translation_Loss:13.157	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.613                                                   	MRR:22.98	Hits@10:40.98	Best:22.98
2024-12-27 18:30:32,908: Snapshot:1	Epoch:2	Loss:10.207	translation_Loss:8.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.495                                                   	MRR:23.43	Hits@10:41.86	Best:23.43
2024-12-27 18:30:40,200: Snapshot:1	Epoch:3	Loss:8.579	translation_Loss:7.266	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.314                                                   	MRR:23.48	Hits@10:42.1	Best:23.48
2024-12-27 18:30:47,466: Snapshot:1	Epoch:4	Loss:7.804	translation_Loss:6.509	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.295                                                   	MRR:23.85	Hits@10:42.48	Best:23.85
2024-12-27 18:30:54,613: Snapshot:1	Epoch:5	Loss:7.309	translation_Loss:6.02	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.289                                                   	MRR:23.66	Hits@10:42.37	Best:23.85
2024-12-27 18:31:01,801: Snapshot:1	Epoch:6	Loss:7.025	translation_Loss:5.742	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.284                                                   	MRR:24.0	Hits@10:42.79	Best:24.0
2024-12-27 18:31:08,937: Snapshot:1	Epoch:7	Loss:6.698	translation_Loss:5.415	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.283                                                   	MRR:23.98	Hits@10:42.71	Best:24.0
2024-12-27 18:31:16,095: Snapshot:1	Epoch:8	Loss:6.517	translation_Loss:5.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.263                                                   	MRR:24.15	Hits@10:42.99	Best:24.15
2024-12-27 18:31:23,324: Snapshot:1	Epoch:9	Loss:6.336	translation_Loss:5.083	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.253                                                   	MRR:24.14	Hits@10:43.18	Best:24.15
2024-12-27 18:31:30,477: Snapshot:1	Epoch:10	Loss:6.247	translation_Loss:4.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.26                                                   	MRR:24.09	Hits@10:43.06	Best:24.15
2024-12-27 18:31:37,655: Snapshot:1	Epoch:11	Loss:6.09	translation_Loss:4.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.247                                                   	MRR:24.16	Hits@10:42.88	Best:24.16
2024-12-27 18:31:44,845: Snapshot:1	Epoch:12	Loss:6.014	translation_Loss:4.756	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.258                                                   	MRR:24.39	Hits@10:43.21	Best:24.39
2024-12-27 18:31:52,070: Snapshot:1	Epoch:13	Loss:5.899	translation_Loss:4.65	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.249                                                   	MRR:24.4	Hits@10:43.28	Best:24.4
2024-12-27 18:31:59,306: Snapshot:1	Epoch:14	Loss:5.761	translation_Loss:4.536	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.225                                                   	MRR:24.39	Hits@10:43.14	Best:24.4
2024-12-27 18:32:06,480: Snapshot:1	Epoch:15	Loss:5.81	translation_Loss:4.56	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.25                                                   	MRR:24.28	Hits@10:43.07	Best:24.4
2024-12-27 18:32:13,595: Snapshot:1	Epoch:16	Loss:5.744	translation_Loss:4.489	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.255                                                   	MRR:24.38	Hits@10:43.39	Best:24.4
2024-12-27 18:32:21,223: Snapshot:1	Epoch:17	Loss:5.611	translation_Loss:4.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.229                                                   	MRR:24.61	Hits@10:43.44	Best:24.61
2024-12-27 18:32:28,381: Snapshot:1	Epoch:18	Loss:5.62	translation_Loss:4.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.246                                                   	MRR:24.55	Hits@10:43.3	Best:24.61
2024-12-27 18:32:35,509: Snapshot:1	Epoch:19	Loss:5.525	translation_Loss:4.301	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.223                                                   	MRR:24.32	Hits@10:43.21	Best:24.61
2024-12-27 18:32:42,695: Snapshot:1	Epoch:20	Loss:5.488	translation_Loss:4.25	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.238                                                   	MRR:24.37	Hits@10:43.32	Best:24.61
2024-12-27 18:32:49,920: Snapshot:1	Epoch:21	Loss:5.45	translation_Loss:4.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.217                                                   	MRR:24.22	Hits@10:43.23	Best:24.61
2024-12-27 18:32:57,094: Early Stopping! Snapshot: 1 Epoch: 22 Best Results: 24.61
2024-12-27 18:32:57,094: Start to training tokens! Snapshot: 1 Epoch: 22 Loss:5.351 MRR:24.45 Best Results: 24.61
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 18:32:57,094: Snapshot:1	Epoch:22	Loss:5.351	translation_Loss:4.15	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.201                                                   	MRR:24.45	Hits@10:43.43	Best:24.61
2024-12-27 18:33:04,380: Snapshot:1	Epoch:23	Loss:93.181	translation_Loss:93.01	multi_layer_Loss:0.172	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.45	Hits@10:43.43	Best:24.61
2024-12-27 18:33:11,532: End of token training: 1 Epoch: 24 Loss:92.964 MRR:24.45 Best Results: 24.61
2024-12-27 18:33:11,533: Snapshot:1	Epoch:24	Loss:92.964	translation_Loss:92.964	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.45	Hits@10:43.43	Best:24.61
2024-12-27 18:33:11,794: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_6/1model_best.tar'
2024-12-27 18:33:15,576: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3319 | 0.2131 | 0.3842 | 0.4585 |  0.5597 |
|     1      | 0.246  | 0.1507 | 0.2779 | 0.339  |  0.433  |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:33:41,700: Snapshot:2	Epoch:0	Loss:45.941	translation_Loss:42.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.734                                                   	MRR:18.19	Hits@10:32.03	Best:18.19
2024-12-27 18:33:49,483: Snapshot:2	Epoch:1	Loss:14.029	translation_Loss:11.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.056                                                   	MRR:20.59	Hits@10:36.31	Best:20.59
2024-12-27 18:33:57,289: Snapshot:2	Epoch:2	Loss:10.434	translation_Loss:8.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.837                                                   	MRR:21.24	Hits@10:37.66	Best:21.24
2024-12-27 18:34:05,119: Snapshot:2	Epoch:3	Loss:9.201	translation_Loss:7.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.787                                                   	MRR:21.66	Hits@10:38.27	Best:21.66
2024-12-27 18:34:12,978: Snapshot:2	Epoch:4	Loss:8.504	translation_Loss:6.747	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.756                                                   	MRR:21.91	Hits@10:38.6	Best:21.91
2024-12-27 18:34:20,814: Snapshot:2	Epoch:5	Loss:8.084	translation_Loss:6.347	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.737                                                   	MRR:22.11	Hits@10:39.12	Best:22.11
2024-12-27 18:34:28,798: Snapshot:2	Epoch:6	Loss:7.825	translation_Loss:6.079	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.747                                                   	MRR:22.31	Hits@10:39.22	Best:22.31
2024-12-27 18:34:36,657: Snapshot:2	Epoch:7	Loss:7.502	translation_Loss:5.786	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.716                                                   	MRR:22.3	Hits@10:39.22	Best:22.31
2024-12-27 18:34:44,478: Snapshot:2	Epoch:8	Loss:7.376	translation_Loss:5.658	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.718                                                   	MRR:22.46	Hits@10:39.54	Best:22.46
2024-12-27 18:34:52,208: Snapshot:2	Epoch:9	Loss:7.146	translation_Loss:5.444	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.702                                                   	MRR:22.44	Hits@10:39.61	Best:22.46
2024-12-27 18:35:00,143: Snapshot:2	Epoch:10	Loss:7.064	translation_Loss:5.362	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.702                                                   	MRR:22.57	Hits@10:39.63	Best:22.57
2024-12-27 18:35:08,114: Snapshot:2	Epoch:11	Loss:6.96	translation_Loss:5.26	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.701                                                   	MRR:22.68	Hits@10:39.88	Best:22.68
2024-12-27 18:35:15,898: Snapshot:2	Epoch:12	Loss:6.846	translation_Loss:5.153	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.692                                                   	MRR:22.57	Hits@10:39.77	Best:22.68
2024-12-27 18:35:23,770: Snapshot:2	Epoch:13	Loss:6.747	translation_Loss:5.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.676                                                   	MRR:22.7	Hits@10:39.92	Best:22.7
2024-12-27 18:35:31,655: Snapshot:2	Epoch:14	Loss:6.702	translation_Loss:5.025	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.677                                                   	MRR:22.53	Hits@10:39.8	Best:22.7
2024-12-27 18:35:39,411: Snapshot:2	Epoch:15	Loss:6.662	translation_Loss:4.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.693                                                   	MRR:22.84	Hits@10:39.97	Best:22.84
2024-12-27 18:35:47,163: Snapshot:2	Epoch:16	Loss:6.562	translation_Loss:4.891	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.67                                                   	MRR:22.74	Hits@10:39.81	Best:22.84
2024-12-27 18:35:54,976: Snapshot:2	Epoch:17	Loss:6.535	translation_Loss:4.865	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.67                                                   	MRR:22.64	Hits@10:40.15	Best:22.84
2024-12-27 18:36:02,914: Snapshot:2	Epoch:18	Loss:6.438	translation_Loss:4.786	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.651                                                   	MRR:22.81	Hits@10:39.97	Best:22.84
2024-12-27 18:36:10,669: Snapshot:2	Epoch:19	Loss:6.399	translation_Loss:4.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.669                                                   	MRR:22.76	Hits@10:40.09	Best:22.84
2024-12-27 18:36:18,500: Snapshot:2	Epoch:20	Loss:6.407	translation_Loss:4.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.677                                                   	MRR:22.88	Hits@10:40.18	Best:22.88
2024-12-27 18:36:26,227: Snapshot:2	Epoch:21	Loss:6.31	translation_Loss:4.654	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.657                                                   	MRR:22.7	Hits@10:40.15	Best:22.88
2024-12-27 18:36:34,036: Snapshot:2	Epoch:22	Loss:6.306	translation_Loss:4.653	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.653                                                   	MRR:22.89	Hits@10:40.35	Best:22.89
2024-12-27 18:36:41,798: Snapshot:2	Epoch:23	Loss:6.201	translation_Loss:4.557	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.644                                                   	MRR:22.87	Hits@10:40.14	Best:22.89
2024-12-27 18:36:49,993: Snapshot:2	Epoch:24	Loss:6.158	translation_Loss:4.535	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.623                                                   	MRR:22.83	Hits@10:40.25	Best:22.89
2024-12-27 18:36:57,830: Snapshot:2	Epoch:25	Loss:6.167	translation_Loss:4.539	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.627                                                   	MRR:22.89	Hits@10:40.24	Best:22.89
2024-12-27 18:37:05,752: Snapshot:2	Epoch:26	Loss:6.128	translation_Loss:4.489	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.639                                                   	MRR:22.9	Hits@10:40.22	Best:22.9
2024-12-27 18:37:13,661: Snapshot:2	Epoch:27	Loss:6.097	translation_Loss:4.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.624                                                   	MRR:22.98	Hits@10:40.37	Best:22.98
2024-12-27 18:37:21,555: Snapshot:2	Epoch:28	Loss:6.073	translation_Loss:4.459	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.614                                                   	MRR:22.87	Hits@10:40.35	Best:22.98
2024-12-27 18:37:29,365: Snapshot:2	Epoch:29	Loss:6.006	translation_Loss:4.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.614                                                   	MRR:22.7	Hits@10:40.45	Best:22.98
2024-12-27 18:37:37,158: Snapshot:2	Epoch:30	Loss:5.961	translation_Loss:4.351	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.61                                                   	MRR:22.74	Hits@10:40.31	Best:22.98
2024-12-27 18:37:44,958: Snapshot:2	Epoch:31	Loss:6.001	translation_Loss:4.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.626                                                   	MRR:22.96	Hits@10:40.5	Best:22.98
2024-12-27 18:37:52,823: Early Stopping! Snapshot: 2 Epoch: 32 Best Results: 22.98
2024-12-27 18:37:52,823: Start to training tokens! Snapshot: 2 Epoch: 32 Loss:5.929 MRR:22.98 Best Results: 22.98
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 18:37:52,824: Snapshot:2	Epoch:32	Loss:5.929	translation_Loss:4.323	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.606                                                   	MRR:22.98	Hits@10:40.32	Best:22.98
2024-12-27 18:38:00,711: Snapshot:2	Epoch:33	Loss:94.028	translation_Loss:93.866	multi_layer_Loss:0.162	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.98	Hits@10:40.32	Best:22.98
2024-12-27 18:38:08,582: End of token training: 2 Epoch: 34 Loss:93.853 MRR:22.98 Best Results: 22.98
2024-12-27 18:38:08,582: Snapshot:2	Epoch:34	Loss:93.853	translation_Loss:93.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.98	Hits@10:40.32	Best:22.98
2024-12-27 18:38:08,834: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_6/2model_best.tar'
2024-12-27 18:38:15,382: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3321 | 0.2127 | 0.3851 | 0.4585 |  0.5599 |
|     1      | 0.2463 | 0.151  | 0.2779 | 0.3397 |  0.4333 |
|     2      | 0.2313 | 0.1371 | 0.2666 | 0.3279 |  0.4096 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:38:41,521: Snapshot:3	Epoch:0	Loss:41.24	translation_Loss:37.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.76                                                   	MRR:17.78	Hits@10:31.91	Best:17.78
2024-12-27 18:38:49,416: Snapshot:3	Epoch:1	Loss:12.132	translation_Loss:10.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.027                                                   	MRR:19.63	Hits@10:35.31	Best:19.63
2024-12-27 18:38:57,347: Snapshot:3	Epoch:2	Loss:9.075	translation_Loss:7.266	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.81                                                   	MRR:20.3	Hits@10:36.48	Best:20.3
2024-12-27 18:39:05,293: Snapshot:3	Epoch:3	Loss:7.974	translation_Loss:6.22	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.754                                                   	MRR:20.64	Hits@10:36.97	Best:20.64
2024-12-27 18:39:13,305: Snapshot:3	Epoch:4	Loss:7.483	translation_Loss:5.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.749                                                   	MRR:20.86	Hits@10:37.56	Best:20.86
2024-12-27 18:39:21,226: Snapshot:3	Epoch:5	Loss:7.083	translation_Loss:5.367	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.716                                                   	MRR:20.99	Hits@10:37.77	Best:20.99
2024-12-27 18:39:29,122: Snapshot:3	Epoch:6	Loss:6.82	translation_Loss:5.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.711                                                   	MRR:21.12	Hits@10:37.73	Best:21.12
2024-12-27 18:39:36,986: Snapshot:3	Epoch:7	Loss:6.663	translation_Loss:4.964	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.699                                                   	MRR:21.11	Hits@10:37.98	Best:21.12
2024-12-27 18:39:44,868: Snapshot:3	Epoch:8	Loss:6.478	translation_Loss:4.789	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.688                                                   	MRR:21.42	Hits@10:38.29	Best:21.42
2024-12-27 18:39:52,823: Snapshot:3	Epoch:9	Loss:6.274	translation_Loss:4.612	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.662                                                   	MRR:21.37	Hits@10:38.16	Best:21.42
2024-12-27 18:40:00,778: Snapshot:3	Epoch:10	Loss:6.192	translation_Loss:4.526	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.666                                                   	MRR:21.48	Hits@10:38.51	Best:21.48
2024-12-27 18:40:08,921: Snapshot:3	Epoch:11	Loss:6.122	translation_Loss:4.467	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.655                                                   	MRR:21.45	Hits@10:38.46	Best:21.48
2024-12-27 18:40:16,906: Snapshot:3	Epoch:12	Loss:6.039	translation_Loss:4.367	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.671                                                   	MRR:21.58	Hits@10:38.74	Best:21.58
2024-12-27 18:40:25,205: Snapshot:3	Epoch:13	Loss:6.006	translation_Loss:4.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.675                                                   	MRR:21.61	Hits@10:39.08	Best:21.61
2024-12-27 18:40:33,057: Snapshot:3	Epoch:14	Loss:5.841	translation_Loss:4.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.639                                                   	MRR:21.7	Hits@10:39.09	Best:21.7
2024-12-27 18:40:40,902: Snapshot:3	Epoch:15	Loss:5.783	translation_Loss:4.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.625                                                   	MRR:21.55	Hits@10:38.9	Best:21.7
2024-12-27 18:40:48,803: Snapshot:3	Epoch:16	Loss:5.766	translation_Loss:4.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.643                                                   	MRR:21.55	Hits@10:38.91	Best:21.7
2024-12-27 18:40:56,733: Snapshot:3	Epoch:17	Loss:5.721	translation_Loss:4.083	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.638                                                   	MRR:21.77	Hits@10:39.05	Best:21.77
2024-12-27 18:41:04,665: Snapshot:3	Epoch:18	Loss:5.622	translation_Loss:3.994	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.629                                                   	MRR:21.8	Hits@10:39.14	Best:21.8
2024-12-27 18:41:12,443: Snapshot:3	Epoch:19	Loss:5.638	translation_Loss:4.002	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.635                                                   	MRR:21.71	Hits@10:39.07	Best:21.8
2024-12-27 18:41:20,354: Snapshot:3	Epoch:20	Loss:5.589	translation_Loss:3.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.626                                                   	MRR:21.84	Hits@10:39.32	Best:21.84
2024-12-27 18:41:28,364: Snapshot:3	Epoch:21	Loss:5.581	translation_Loss:3.957	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.624                                                   	MRR:21.81	Hits@10:38.98	Best:21.84
2024-12-27 18:41:36,184: Snapshot:3	Epoch:22	Loss:5.478	translation_Loss:3.859	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.619                                                   	MRR:21.7	Hits@10:38.97	Best:21.84
2024-12-27 18:41:44,165: Snapshot:3	Epoch:23	Loss:5.458	translation_Loss:3.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.597                                                   	MRR:22.0	Hits@10:39.25	Best:22.0
2024-12-27 18:41:52,084: Snapshot:3	Epoch:24	Loss:5.49	translation_Loss:3.868	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.623                                                   	MRR:21.89	Hits@10:39.11	Best:22.0
2024-12-27 18:41:59,909: Snapshot:3	Epoch:25	Loss:5.38	translation_Loss:3.777	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.603                                                   	MRR:21.88	Hits@10:39.34	Best:22.0
2024-12-27 18:42:07,788: Snapshot:3	Epoch:26	Loss:5.384	translation_Loss:3.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.611                                                   	MRR:21.88	Hits@10:39.3	Best:22.0
2024-12-27 18:42:15,647: Snapshot:3	Epoch:27	Loss:5.335	translation_Loss:3.744	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.59                                                   	MRR:21.93	Hits@10:39.34	Best:22.0
2024-12-27 18:42:23,512: Snapshot:3	Epoch:28	Loss:5.28	translation_Loss:3.681	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.599                                                   	MRR:22.01	Hits@10:39.54	Best:22.01
2024-12-27 18:42:31,694: Snapshot:3	Epoch:29	Loss:5.326	translation_Loss:3.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.601                                                   	MRR:21.78	Hits@10:39.21	Best:22.01
2024-12-27 18:42:39,489: Snapshot:3	Epoch:30	Loss:5.28	translation_Loss:3.699	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.581                                                   	MRR:21.98	Hits@10:39.51	Best:22.01
2024-12-27 18:42:47,375: Snapshot:3	Epoch:31	Loss:5.218	translation_Loss:3.641	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.578                                                   	MRR:21.9	Hits@10:39.62	Best:22.01
2024-12-27 18:42:55,149: Snapshot:3	Epoch:32	Loss:5.236	translation_Loss:3.65	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.586                                                   	MRR:21.98	Hits@10:39.49	Best:22.01
2024-12-27 18:43:03,129: Early Stopping! Snapshot: 3 Epoch: 33 Best Results: 22.01
2024-12-27 18:43:03,129: Start to training tokens! Snapshot: 3 Epoch: 33 Loss:5.165 MRR:21.91 Best Results: 22.01
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 18:43:03,129: Snapshot:3	Epoch:33	Loss:5.165	translation_Loss:3.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.567                                                   	MRR:21.91	Hits@10:39.37	Best:22.01
2024-12-27 18:43:11,050: Snapshot:3	Epoch:34	Loss:84.827	translation_Loss:84.671	multi_layer_Loss:0.156	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.91	Hits@10:39.37	Best:22.01
2024-12-27 18:43:18,914: End of token training: 3 Epoch: 35 Loss:84.646 MRR:21.91 Best Results: 22.01
2024-12-27 18:43:18,915: Snapshot:3	Epoch:35	Loss:84.646	translation_Loss:84.646	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.91	Hits@10:39.37	Best:22.01
2024-12-27 18:43:19,192: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_6/3model_best.tar'
2024-12-27 18:43:28,800: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3326 | 0.2137 | 0.3853 | 0.4582 |  0.5589 |
|     1      | 0.2466 | 0.1515 | 0.2782 | 0.3397 |  0.4336 |
|     2      | 0.2324 | 0.1387 | 0.2672 | 0.328  |  0.4096 |
|     3      | 0.2184 | 0.1284 | 0.2513 | 0.3108 |  0.391  |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:43:48,894: Snapshot:4	Epoch:0	Loss:30.412	translation_Loss:27.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.693                                                   	MRR:21.42	Hits@10:39.43	Best:21.42
2024-12-27 18:43:54,540: Snapshot:4	Epoch:1	Loss:7.145	translation_Loss:5.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.177                                                   	MRR:23.93	Hits@10:42.96	Best:23.93
2024-12-27 18:44:00,185: Snapshot:4	Epoch:2	Loss:4.553	translation_Loss:3.606	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.947                                                   	MRR:24.62	Hits@10:44.05	Best:24.62
2024-12-27 18:44:05,826: Snapshot:4	Epoch:3	Loss:3.797	translation_Loss:2.904	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.893                                                   	MRR:24.91	Hits@10:44.96	Best:24.91
2024-12-27 18:44:11,482: Snapshot:4	Epoch:4	Loss:3.441	translation_Loss:2.58	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.861                                                   	MRR:24.94	Hits@10:44.72	Best:24.94
2024-12-27 18:44:17,115: Snapshot:4	Epoch:5	Loss:3.203	translation_Loss:2.375	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.828                                                   	MRR:25.1	Hits@10:44.75	Best:25.1
2024-12-27 18:44:22,827: Snapshot:4	Epoch:6	Loss:3.075	translation_Loss:2.246	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.829                                                   	MRR:25.4	Hits@10:44.96	Best:25.4
2024-12-27 18:44:28,445: Snapshot:4	Epoch:7	Loss:2.994	translation_Loss:2.147	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.847                                                   	MRR:25.58	Hits@10:45.45	Best:25.58
2024-12-27 18:44:33,993: Snapshot:4	Epoch:8	Loss:2.882	translation_Loss:2.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.842                                                   	MRR:25.43	Hits@10:45.46	Best:25.58
2024-12-27 18:44:39,579: Snapshot:4	Epoch:9	Loss:2.843	translation_Loss:2.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.832                                                   	MRR:25.38	Hits@10:45.89	Best:25.58
2024-12-27 18:44:45,162: Snapshot:4	Epoch:10	Loss:2.79	translation_Loss:1.946	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.843                                                   	MRR:25.35	Hits@10:45.64	Best:25.58
2024-12-27 18:44:50,764: Snapshot:4	Epoch:11	Loss:2.726	translation_Loss:1.885	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.841                                                   	MRR:25.37	Hits@10:45.72	Best:25.58
2024-12-27 18:44:56,383: Early Stopping! Snapshot: 4 Epoch: 12 Best Results: 25.58
2024-12-27 18:44:56,384: Start to training tokens! Snapshot: 4 Epoch: 12 Loss:2.666 MRR:25.41 Best Results: 25.58
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 18:44:56,385: Snapshot:4	Epoch:12	Loss:2.666	translation_Loss:1.834	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.832                                                   	MRR:25.41	Hits@10:45.59	Best:25.58
2024-12-27 18:45:02,175: Snapshot:4	Epoch:13	Loss:46.203	translation_Loss:46.042	multi_layer_Loss:0.16	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.41	Hits@10:45.59	Best:25.58
2024-12-27 18:45:07,910: End of token training: 4 Epoch: 14 Loss:46.022 MRR:25.41 Best Results: 25.58
2024-12-27 18:45:07,911: Snapshot:4	Epoch:14	Loss:46.022	translation_Loss:46.022	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.41	Hits@10:45.59	Best:25.58
2024-12-27 18:45:08,211: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_6/4model_best.tar'
2024-12-27 18:45:20,112: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3321 | 0.2134 | 0.3829 | 0.4576 |  0.5594 |
|     1      | 0.2473 | 0.152  | 0.2793 | 0.3403 |  0.4338 |
|     2      | 0.2329 | 0.1391 | 0.2678 | 0.3283 |  0.4105 |
|     3      | 0.2196 | 0.1296 | 0.2528 | 0.3119 |  0.3924 |
|     4      | 0.2582 | 0.1525 | 0.3083 | 0.3753 |  0.4593 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 18:45:20,114: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3316 | 0.2125 | 0.3849 | 0.459  |  0.5594 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3319 | 0.2131 | 0.3842 | 0.4585 |  0.5597 |
|     1      | 0.246  | 0.1507 | 0.2779 | 0.339  |  0.433  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3321 | 0.2127 | 0.3851 | 0.4585 |  0.5599 |
|     1      | 0.2463 | 0.151  | 0.2779 | 0.3397 |  0.4333 |
|     2      | 0.2313 | 0.1371 | 0.2666 | 0.3279 |  0.4096 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3326 | 0.2137 | 0.3853 | 0.4582 |  0.5589 |
|     1      | 0.2466 | 0.1515 | 0.2782 | 0.3397 |  0.4336 |
|     2      | 0.2324 | 0.1387 | 0.2672 | 0.328  |  0.4096 |
|     3      | 0.2184 | 0.1284 | 0.2513 | 0.3108 |  0.391  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3321 | 0.2134 | 0.3829 | 0.4576 |  0.5594 |
|     1      | 0.2473 | 0.152  | 0.2793 | 0.3403 |  0.4338 |
|     2      | 0.2329 | 0.1391 | 0.2678 | 0.3283 |  0.4105 |
|     3      | 0.2196 | 0.1296 | 0.2528 | 0.3119 |  0.3924 |
|     4      | 0.2582 | 0.1525 | 0.3083 | 0.3753 |  0.4593 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 18:45:20,114: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 60.53012275695801  |   0.332   |    0.212     |    0.385     |     0.559     |
|    1     | 195.53760051727295 |    0.28   |    0.175     |     0.32     |     0.483     |
|    2     | 290.30374455451965 |   0.261   |    0.161     |    0.299     |     0.455     |
|    3     | 300.4926965236664  |    0.25   |    0.153     |    0.287     |     0.438     |
|    4     | 96.66779685020447  |   0.252   |    0.153     |     0.29     |     0.442     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 18:45:20,114: Sum_Training_Time:943.5319612026215
2024-12-27 18:45:20,114: Every_Training_Time:[60.53012275695801, 195.53760051727295, 290.30374455451965, 300.4926965236664, 96.66779685020447]
2024-12-27 18:45:20,114: Forward transfer: 0.045024999999999996 Backward transfer: 0.0011499999999999913
2024-12-27 18:45:53,536: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227184524/ENTITYentity_0.001_512_8', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.001_512_8', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.001_512_8', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=8, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 18:46:01,262: Snapshot:0	Epoch:0	Loss:69.32	translation_Loss:69.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.71	Hits@10:32.99	Best:13.71
2024-12-27 18:46:05,297: Snapshot:0	Epoch:1	Loss:39.17	translation_Loss:39.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.16	Hits@10:49.28	Best:26.16
2024-12-27 18:46:09,266: Snapshot:0	Epoch:2	Loss:18.414	translation_Loss:18.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.87	Hits@10:54.17	Best:30.87
2024-12-27 18:46:13,201: Snapshot:0	Epoch:3	Loss:9.286	translation_Loss:9.286	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.17	Hits@10:55.35	Best:32.17
2024-12-27 18:46:17,179: Snapshot:0	Epoch:4	Loss:5.424	translation_Loss:5.424	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.55	Hits@10:55.79	Best:32.55
2024-12-27 18:46:21,069: Snapshot:0	Epoch:5	Loss:3.693	translation_Loss:3.693	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.52	Hits@10:55.7	Best:32.55
2024-12-27 18:46:24,985: Snapshot:0	Epoch:6	Loss:2.807	translation_Loss:2.807	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.68	Hits@10:55.59	Best:32.68
2024-12-27 18:46:28,909: Snapshot:0	Epoch:7	Loss:2.273	translation_Loss:2.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.44	Hits@10:55.02	Best:32.68
2024-12-27 18:46:32,789: Snapshot:0	Epoch:8	Loss:1.945	translation_Loss:1.945	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.13	Hits@10:54.65	Best:32.68
2024-12-27 18:46:36,713: Snapshot:0	Epoch:9	Loss:1.703	translation_Loss:1.703	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.18	Hits@10:54.71	Best:32.68
2024-12-27 18:46:40,605: Snapshot:0	Epoch:10	Loss:1.556	translation_Loss:1.556	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.77	Hits@10:54.49	Best:32.68
2024-12-27 18:46:44,481: Early Stopping! Snapshot: 0 Epoch: 11 Best Results: 32.68
2024-12-27 18:46:44,481: Start to training tokens! Snapshot: 0 Epoch: 11 Loss:1.433 MRR:31.87 Best Results: 32.68
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 18:46:44,482: Snapshot:0	Epoch:11	Loss:1.433	translation_Loss:1.433	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.87	Hits@10:54.43	Best:32.68
2024-12-27 18:46:49,160: Snapshot:0	Epoch:12	Loss:56.191	translation_Loss:56.02	multi_layer_Loss:0.171	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.87	Hits@10:54.43	Best:32.68
2024-12-27 18:46:53,324: End of token training: 0 Epoch: 13 Loss:56.029 MRR:31.87 Best Results: 32.68
2024-12-27 18:46:53,324: Snapshot:0	Epoch:13	Loss:56.029	translation_Loss:56.029	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.87	Hits@10:54.43	Best:32.68
2024-12-27 18:46:53,614: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_8/0model_best.tar'
2024-12-27 18:46:55,179: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3305 | 0.2121 | 0.3822 | 0.4546 |  0.5572 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:47:19,762: Snapshot:1	Epoch:0	Loss:50.481	translation_Loss:47.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.247                                                   	MRR:20.79	Hits@10:37.23	Best:20.79
2024-12-27 18:47:26,905: Snapshot:1	Epoch:1	Loss:14.695	translation_Loss:13.179	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.516                                                   	MRR:22.95	Hits@10:40.74	Best:22.95
2024-12-27 18:47:34,041: Snapshot:1	Epoch:2	Loss:10.128	translation_Loss:8.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.402                                                   	MRR:23.58	Hits@10:41.88	Best:23.58
2024-12-27 18:47:41,174: Snapshot:1	Epoch:3	Loss:8.515	translation_Loss:7.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.243                                                   	MRR:23.55	Hits@10:42.13	Best:23.58
2024-12-27 18:47:48,337: Snapshot:1	Epoch:4	Loss:7.763	translation_Loss:6.534	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.23                                                   	MRR:23.88	Hits@10:42.42	Best:23.88
2024-12-27 18:47:55,404: Snapshot:1	Epoch:5	Loss:7.234	translation_Loss:6.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.218                                                   	MRR:23.65	Hits@10:42.37	Best:23.88
2024-12-27 18:48:02,552: Snapshot:1	Epoch:6	Loss:6.995	translation_Loss:5.767	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.227                                                   	MRR:23.95	Hits@10:42.56	Best:23.95
2024-12-27 18:48:09,623: Snapshot:1	Epoch:7	Loss:6.661	translation_Loss:5.435	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.226                                                   	MRR:23.97	Hits@10:42.43	Best:23.97
2024-12-27 18:48:16,749: Snapshot:1	Epoch:8	Loss:6.471	translation_Loss:5.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.203                                                   	MRR:24.09	Hits@10:42.74	Best:24.09
2024-12-27 18:48:23,939: Snapshot:1	Epoch:9	Loss:6.306	translation_Loss:5.102	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.205                                                   	MRR:24.13	Hits@10:42.71	Best:24.13
2024-12-27 18:48:31,047: Snapshot:1	Epoch:10	Loss:6.196	translation_Loss:4.997	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.199                                                   	MRR:24.18	Hits@10:42.79	Best:24.18
2024-12-27 18:48:38,180: Snapshot:1	Epoch:11	Loss:6.047	translation_Loss:4.86	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.186                                                   	MRR:24.29	Hits@10:42.79	Best:24.29
2024-12-27 18:48:45,331: Snapshot:1	Epoch:12	Loss:5.986	translation_Loss:4.779	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.208                                                   	MRR:24.29	Hits@10:42.89	Best:24.29
2024-12-27 18:48:52,486: Snapshot:1	Epoch:13	Loss:5.858	translation_Loss:4.661	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.197                                                   	MRR:24.23	Hits@10:42.87	Best:24.29
2024-12-27 18:48:59,780: Snapshot:1	Epoch:14	Loss:5.742	translation_Loss:4.559	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.184                                                   	MRR:24.39	Hits@10:43.09	Best:24.39
2024-12-27 18:49:06,951: Snapshot:1	Epoch:15	Loss:5.775	translation_Loss:4.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.189                                                   	MRR:24.13	Hits@10:42.87	Best:24.39
2024-12-27 18:49:14,074: Snapshot:1	Epoch:16	Loss:5.699	translation_Loss:4.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.193                                                   	MRR:24.46	Hits@10:43.18	Best:24.46
2024-12-27 18:49:21,634: Snapshot:1	Epoch:17	Loss:5.574	translation_Loss:4.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.175                                                   	MRR:24.55	Hits@10:43.31	Best:24.55
2024-12-27 18:49:28,805: Snapshot:1	Epoch:18	Loss:5.575	translation_Loss:4.388	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.187                                                   	MRR:24.49	Hits@10:43.25	Best:24.55
2024-12-27 18:49:35,881: Snapshot:1	Epoch:19	Loss:5.502	translation_Loss:4.328	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.174                                                   	MRR:24.4	Hits@10:43.01	Best:24.55
2024-12-27 18:49:43,076: Snapshot:1	Epoch:20	Loss:6.28	translation_Loss:4.955	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.325                                                   	MRR:24.41	Hits@10:43.31	Best:24.55
2024-12-27 18:49:50,168: Snapshot:1	Epoch:21	Loss:5.617	translation_Loss:4.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.307                                                   	MRR:24.28	Hits@10:43.21	Best:24.55
2024-12-27 18:49:57,254: Early Stopping! Snapshot: 1 Epoch: 22 Best Results: 24.55
2024-12-27 18:49:57,255: Start to training tokens! Snapshot: 1 Epoch: 22 Loss:5.339 MRR:24.46 Best Results: 24.55
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 18:49:57,255: Snapshot:1	Epoch:22	Loss:5.339	translation_Loss:4.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.144                                                   	MRR:24.46	Hits@10:43.24	Best:24.55
2024-12-27 18:50:04,451: Snapshot:1	Epoch:23	Loss:92.802	translation_Loss:92.619	multi_layer_Loss:0.182	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.46	Hits@10:43.24	Best:24.55
2024-12-27 18:50:11,925: End of token training: 1 Epoch: 24 Loss:92.557 MRR:24.46 Best Results: 24.55
2024-12-27 18:50:11,925: Snapshot:1	Epoch:24	Loss:92.557	translation_Loss:92.557	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.46	Hits@10:43.24	Best:24.55
2024-12-27 18:50:12,191: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_8/1model_best.tar'
2024-12-27 18:50:16,005: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3306 | 0.2129 | 0.3819 | 0.4546 |  0.5569 |
|     1      | 0.2453 | 0.1487 | 0.2783 | 0.3431 |  0.4334 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:50:42,030: Snapshot:2	Epoch:0	Loss:46.056	translation_Loss:42.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.832                                                   	MRR:18.21	Hits@10:32.16	Best:18.21
2024-12-27 18:50:49,771: Snapshot:2	Epoch:1	Loss:13.902	translation_Loss:11.965	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.937                                                   	MRR:20.65	Hits@10:36.47	Best:20.65
2024-12-27 18:50:57,683: Snapshot:2	Epoch:2	Loss:10.367	translation_Loss:8.613	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.754                                                   	MRR:21.33	Hits@10:37.81	Best:21.33
2024-12-27 18:51:05,397: Snapshot:2	Epoch:3	Loss:9.132	translation_Loss:7.421	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.711                                                   	MRR:21.77	Hits@10:38.6	Best:21.77
2024-12-27 18:51:13,233: Snapshot:2	Epoch:4	Loss:8.429	translation_Loss:6.753	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.676                                                   	MRR:21.97	Hits@10:38.75	Best:21.97
2024-12-27 18:51:20,995: Snapshot:2	Epoch:5	Loss:8.005	translation_Loss:6.345	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.661                                                   	MRR:22.15	Hits@10:39.29	Best:22.15
2024-12-27 18:51:28,826: Snapshot:2	Epoch:6	Loss:7.734	translation_Loss:6.073	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.661                                                   	MRR:22.33	Hits@10:39.12	Best:22.33
2024-12-27 18:51:36,551: Snapshot:2	Epoch:7	Loss:7.459	translation_Loss:5.804	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.655                                                   	MRR:22.21	Hits@10:39.25	Best:22.33
2024-12-27 18:51:44,287: Snapshot:2	Epoch:8	Loss:7.309	translation_Loss:5.663	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.646                                                   	MRR:22.55	Hits@10:39.81	Best:22.55
2024-12-27 18:51:52,083: Snapshot:2	Epoch:9	Loss:7.069	translation_Loss:5.437	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.633                                                   	MRR:22.54	Hits@10:39.8	Best:22.55
2024-12-27 18:51:59,865: Snapshot:2	Epoch:10	Loss:6.989	translation_Loss:5.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.632                                                   	MRR:22.59	Hits@10:39.81	Best:22.59
2024-12-27 18:52:07,582: Snapshot:2	Epoch:11	Loss:6.891	translation_Loss:5.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.63                                                   	MRR:22.75	Hits@10:40.09	Best:22.75
2024-12-27 18:52:15,270: Snapshot:2	Epoch:12	Loss:6.774	translation_Loss:5.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.616                                                   	MRR:22.67	Hits@10:40.18	Best:22.75
2024-12-27 18:52:23,031: Snapshot:2	Epoch:13	Loss:6.685	translation_Loss:5.075	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.61                                                   	MRR:22.77	Hits@10:40.14	Best:22.77
2024-12-27 18:52:30,780: Snapshot:2	Epoch:14	Loss:6.648	translation_Loss:5.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.611                                                   	MRR:22.68	Hits@10:39.88	Best:22.77
2024-12-27 18:52:38,533: Snapshot:2	Epoch:15	Loss:6.601	translation_Loss:4.972	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.628                                                   	MRR:22.78	Hits@10:40.07	Best:22.78
2024-12-27 18:52:46,293: Snapshot:2	Epoch:16	Loss:6.51	translation_Loss:4.907	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.602                                                   	MRR:22.82	Hits@10:40.02	Best:22.82
2024-12-27 18:52:54,009: Snapshot:2	Epoch:17	Loss:6.466	translation_Loss:4.871	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.594                                                   	MRR:22.71	Hits@10:40.08	Best:22.82
2024-12-27 18:53:01,813: Snapshot:2	Epoch:18	Loss:6.376	translation_Loss:4.795	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.581                                                   	MRR:22.7	Hits@10:40.06	Best:22.82
2024-12-27 18:53:09,615: Snapshot:2	Epoch:19	Loss:6.334	translation_Loss:4.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.6                                                   	MRR:22.71	Hits@10:40.24	Best:22.82
2024-12-27 18:53:17,298: Snapshot:2	Epoch:20	Loss:6.32	translation_Loss:4.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.594                                                   	MRR:22.82	Hits@10:40.15	Best:22.82
2024-12-27 18:53:25,032: Early Stopping! Snapshot: 2 Epoch: 21 Best Results: 22.82
2024-12-27 18:53:25,032: Start to training tokens! Snapshot: 2 Epoch: 21 Loss:6.237 MRR:22.74 Best Results: 22.82
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 18:53:25,033: Snapshot:2	Epoch:21	Loss:6.237	translation_Loss:4.66	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.577                                                   	MRR:22.74	Hits@10:40.12	Best:22.82
2024-12-27 18:53:32,787: Snapshot:2	Epoch:22	Loss:94.029	translation_Loss:93.858	multi_layer_Loss:0.171	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.74	Hits@10:40.12	Best:22.82
2024-12-27 18:53:40,544: End of token training: 2 Epoch: 23 Loss:93.837 MRR:22.74 Best Results: 22.82
2024-12-27 18:53:40,544: Snapshot:2	Epoch:23	Loss:93.837	translation_Loss:93.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.74	Hits@10:40.12	Best:22.82
2024-12-27 18:53:40,794: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_8/2model_best.tar'
2024-12-27 18:53:47,313: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3302 | 0.2124 | 0.3817 | 0.454  |  0.5563 |
|     1      | 0.2456 | 0.1493 | 0.2787 | 0.3429 |  0.4322 |
|     2      | 0.2294 | 0.1369 | 0.2648 | 0.323  |  0.4079 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:54:13,797: Snapshot:3	Epoch:0	Loss:41.607	translation_Loss:37.547	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.059                                                   	MRR:17.83	Hits@10:32.18	Best:17.83
2024-12-27 18:54:21,680: Snapshot:3	Epoch:1	Loss:12.12	translation_Loss:10.063	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.057                                                   	MRR:19.71	Hits@10:35.61	Best:19.71
2024-12-27 18:54:29,491: Snapshot:3	Epoch:2	Loss:9.129	translation_Loss:7.283	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.847                                                   	MRR:20.28	Hits@10:36.79	Best:20.28
2024-12-27 18:54:37,330: Snapshot:3	Epoch:3	Loss:8.019	translation_Loss:6.248	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.77                                                   	MRR:20.67	Hits@10:37.44	Best:20.67
2024-12-27 18:54:45,214: Snapshot:3	Epoch:4	Loss:7.463	translation_Loss:5.709	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.755                                                   	MRR:20.86	Hits@10:37.68	Best:20.86
2024-12-27 18:54:53,069: Snapshot:3	Epoch:5	Loss:7.131	translation_Loss:5.38	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.752                                                   	MRR:21.0	Hits@10:37.98	Best:21.0
2024-12-27 18:55:01,006: Snapshot:3	Epoch:6	Loss:6.783	translation_Loss:5.073	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.71                                                   	MRR:21.35	Hits@10:38.32	Best:21.35
2024-12-27 18:55:08,965: Snapshot:3	Epoch:7	Loss:6.648	translation_Loss:4.928	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.721                                                   	MRR:21.25	Hits@10:38.37	Best:21.35
2024-12-27 18:55:16,765: Snapshot:3	Epoch:8	Loss:6.487	translation_Loss:4.749	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.738                                                   	MRR:21.29	Hits@10:38.55	Best:21.35
2024-12-27 18:55:24,677: Snapshot:3	Epoch:9	Loss:6.29	translation_Loss:4.604	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.686                                                   	MRR:21.31	Hits@10:38.46	Best:21.35
2024-12-27 18:55:32,434: Snapshot:3	Epoch:10	Loss:6.146	translation_Loss:4.456	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.691                                                   	MRR:21.33	Hits@10:38.66	Best:21.35
2024-12-27 18:55:40,265: Snapshot:3	Epoch:11	Loss:6.106	translation_Loss:4.417	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.689                                                   	MRR:21.39	Hits@10:38.98	Best:21.39
2024-12-27 18:55:48,103: Snapshot:3	Epoch:12	Loss:6.042	translation_Loss:4.339	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.703                                                   	MRR:21.5	Hits@10:38.92	Best:21.5
2024-12-27 18:55:55,947: Snapshot:3	Epoch:13	Loss:5.984	translation_Loss:4.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.689                                                   	MRR:21.52	Hits@10:39.06	Best:21.52
2024-12-27 18:56:03,834: Snapshot:3	Epoch:14	Loss:5.935	translation_Loss:4.249	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.686                                                   	MRR:21.66	Hits@10:39.0	Best:21.66
2024-12-27 18:56:11,683: Snapshot:3	Epoch:15	Loss:5.77	translation_Loss:4.113	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.657                                                   	MRR:21.69	Hits@10:39.31	Best:21.69
2024-12-27 18:56:19,477: Snapshot:3	Epoch:16	Loss:5.759	translation_Loss:4.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.66                                                   	MRR:21.65	Hits@10:39.09	Best:21.69
2024-12-27 18:56:27,253: Snapshot:3	Epoch:17	Loss:5.708	translation_Loss:4.05	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.658                                                   	MRR:21.59	Hits@10:39.21	Best:21.69
2024-12-27 18:56:35,071: Snapshot:3	Epoch:18	Loss:5.649	translation_Loss:4.002	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.647                                                   	MRR:21.7	Hits@10:39.28	Best:21.7
2024-12-27 18:56:42,925: Snapshot:3	Epoch:19	Loss:5.619	translation_Loss:3.962	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.657                                                   	MRR:21.81	Hits@10:39.42	Best:21.81
2024-12-27 18:56:50,922: Snapshot:3	Epoch:20	Loss:5.569	translation_Loss:3.928	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.641                                                   	MRR:21.64	Hits@10:39.23	Best:21.81
2024-12-27 18:56:58,803: Snapshot:3	Epoch:21	Loss:5.546	translation_Loss:3.906	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.64                                                   	MRR:21.72	Hits@10:39.35	Best:21.81
2024-12-27 18:57:06,634: Snapshot:3	Epoch:22	Loss:5.529	translation_Loss:3.889	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.64                                                   	MRR:21.85	Hits@10:39.8	Best:21.85
2024-12-27 18:57:14,373: Snapshot:3	Epoch:23	Loss:5.485	translation_Loss:3.849	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.636                                                   	MRR:21.85	Hits@10:39.4	Best:21.85
2024-12-27 18:57:22,168: Snapshot:3	Epoch:24	Loss:5.454	translation_Loss:3.831	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.623                                                   	MRR:21.88	Hits@10:39.42	Best:21.88
2024-12-27 18:57:29,972: Snapshot:3	Epoch:25	Loss:5.36	translation_Loss:3.746	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.614                                                   	MRR:21.79	Hits@10:39.26	Best:21.88
2024-12-27 18:57:37,751: Snapshot:3	Epoch:26	Loss:5.396	translation_Loss:3.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.636                                                   	MRR:21.85	Hits@10:39.61	Best:21.88
2024-12-27 18:57:45,596: Snapshot:3	Epoch:27	Loss:5.356	translation_Loss:3.741	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.615                                                   	MRR:21.93	Hits@10:39.56	Best:21.93
2024-12-27 18:57:53,766: Snapshot:3	Epoch:28	Loss:5.342	translation_Loss:3.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.622                                                   	MRR:21.84	Hits@10:39.42	Best:21.93
2024-12-27 18:58:01,684: Snapshot:3	Epoch:29	Loss:5.356	translation_Loss:3.712	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.644                                                   	MRR:21.95	Hits@10:39.8	Best:21.95
2024-12-27 18:58:09,437: Snapshot:3	Epoch:30	Loss:5.294	translation_Loss:3.675	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.619                                                   	MRR:21.91	Hits@10:39.64	Best:21.95
2024-12-27 18:58:17,194: Snapshot:3	Epoch:31	Loss:5.238	translation_Loss:3.643	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.595                                                   	MRR:21.83	Hits@10:39.51	Best:21.95
2024-12-27 18:58:24,997: Snapshot:3	Epoch:32	Loss:5.231	translation_Loss:3.629	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.602                                                   	MRR:21.85	Hits@10:39.5	Best:21.95
2024-12-27 18:58:32,742: Snapshot:3	Epoch:33	Loss:5.193	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.583                                                   	MRR:21.88	Hits@10:39.58	Best:21.95
2024-12-27 18:58:40,526: Early Stopping! Snapshot: 3 Epoch: 34 Best Results: 21.95
2024-12-27 18:58:40,526: Start to training tokens! Snapshot: 3 Epoch: 34 Loss:5.175 MRR:21.93 Best Results: 21.95
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 18:58:40,526: Snapshot:3	Epoch:34	Loss:5.175	translation_Loss:3.572	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.603                                                   	MRR:21.93	Hits@10:39.68	Best:21.95
2024-12-27 18:58:48,373: Snapshot:3	Epoch:35	Loss:84.593	translation_Loss:84.424	multi_layer_Loss:0.169	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.93	Hits@10:39.68	Best:21.95
2024-12-27 18:58:56,193: End of token training: 3 Epoch: 36 Loss:84.451 MRR:21.93 Best Results: 21.95
2024-12-27 18:58:56,193: Snapshot:3	Epoch:36	Loss:84.451	translation_Loss:84.451	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.93	Hits@10:39.68	Best:21.95
2024-12-27 18:58:56,464: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_8/3model_best.tar'
2024-12-27 18:59:06,019: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3302 | 0.2124 | 0.3803 | 0.4542 |  0.5559 |
|     1      | 0.2455 | 0.149  | 0.2789 | 0.3434 |  0.4329 |
|     2      | 0.2299 | 0.1374 | 0.265  | 0.3234 |  0.4068 |
|     3      | 0.2208 | 0.1293 | 0.2541 | 0.3149 |  0.3951 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:59:25,533: Snapshot:4	Epoch:0	Loss:30.617	translation_Loss:27.718	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.899                                                   	MRR:21.69	Hits@10:39.93	Best:21.69
2024-12-27 18:59:31,166: Snapshot:4	Epoch:1	Loss:7.161	translation_Loss:6.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.15                                                   	MRR:24.28	Hits@10:43.19	Best:24.28
2024-12-27 18:59:36,749: Snapshot:4	Epoch:2	Loss:4.487	translation_Loss:3.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.941                                                   	MRR:24.88	Hits@10:44.17	Best:24.88
2024-12-27 18:59:42,400: Snapshot:4	Epoch:3	Loss:3.778	translation_Loss:2.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.877                                                   	MRR:25.13	Hits@10:44.44	Best:25.13
2024-12-27 18:59:47,994: Snapshot:4	Epoch:4	Loss:3.372	translation_Loss:2.536	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.837                                                   	MRR:25.14	Hits@10:44.67	Best:25.14
2024-12-27 18:59:53,617: Snapshot:4	Epoch:5	Loss:3.234	translation_Loss:2.383	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.851                                                   	MRR:25.18	Hits@10:44.88	Best:25.18
2024-12-27 18:59:59,346: Snapshot:4	Epoch:6	Loss:3.1	translation_Loss:2.25	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.85                                                   	MRR:25.32	Hits@10:45.02	Best:25.32
2024-12-27 19:00:05,056: Snapshot:4	Epoch:7	Loss:3.007	translation_Loss:2.161	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.847                                                   	MRR:25.39	Hits@10:45.29	Best:25.39
2024-12-27 19:00:11,206: Snapshot:4	Epoch:8	Loss:2.886	translation_Loss:2.052	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.834                                                   	MRR:25.66	Hits@10:45.49	Best:25.66
2024-12-27 19:00:16,830: Snapshot:4	Epoch:9	Loss:2.816	translation_Loss:1.987	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.829                                                   	MRR:25.67	Hits@10:45.72	Best:25.67
2024-12-27 19:00:22,452: Snapshot:4	Epoch:10	Loss:2.715	translation_Loss:1.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.814                                                   	MRR:25.4	Hits@10:45.78	Best:25.67
2024-12-27 19:00:28,045: Snapshot:4	Epoch:11	Loss:2.681	translation_Loss:1.86	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.821                                                   	MRR:25.74	Hits@10:45.54	Best:25.74
2024-12-27 19:00:33,634: Snapshot:4	Epoch:12	Loss:2.653	translation_Loss:1.829	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.824                                                   	MRR:25.68	Hits@10:45.55	Best:25.74
2024-12-27 19:00:39,145: Snapshot:4	Epoch:13	Loss:2.627	translation_Loss:1.801	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.826                                                   	MRR:25.6	Hits@10:45.83	Best:25.74
2024-12-27 19:00:44,692: Snapshot:4	Epoch:14	Loss:2.616	translation_Loss:1.786	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.831                                                   	MRR:25.56	Hits@10:45.65	Best:25.74
2024-12-27 19:00:50,442: Snapshot:4	Epoch:15	Loss:2.546	translation_Loss:1.724	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.822                                                   	MRR:25.54	Hits@10:46.1	Best:25.74
2024-12-27 19:00:56,114: Early Stopping! Snapshot: 4 Epoch: 16 Best Results: 25.74
2024-12-27 19:00:56,114: Start to training tokens! Snapshot: 4 Epoch: 16 Loss:2.552 MRR:25.58 Best Results: 25.74
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 19:00:56,114: Snapshot:4	Epoch:16	Loss:2.552	translation_Loss:1.723	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.83                                                   	MRR:25.58	Hits@10:45.81	Best:25.74
2024-12-27 19:01:01,726: Snapshot:4	Epoch:17	Loss:45.955	translation_Loss:45.781	multi_layer_Loss:0.174	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.58	Hits@10:45.81	Best:25.74
2024-12-27 19:01:07,499: End of token training: 4 Epoch: 18 Loss:45.722 MRR:25.58 Best Results: 25.74
2024-12-27 19:01:07,499: Snapshot:4	Epoch:18	Loss:45.722	translation_Loss:45.722	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.58	Hits@10:45.81	Best:25.74
2024-12-27 19:01:07,754: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_8/4model_best.tar'
2024-12-27 19:01:19,841: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3301 | 0.2122 | 0.3804 | 0.4535 |  0.5554 |
|     1      | 0.2462 |  0.15  | 0.2798 | 0.343  |  0.4335 |
|     2      | 0.2307 | 0.1386 | 0.2652 | 0.3233 |  0.4069 |
|     3      | 0.2216 | 0.1305 | 0.2542 | 0.3158 |  0.3952 |
|     4      | 0.2576 | 0.1491 | 0.3101 | 0.3776 |  0.4628 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 19:01:19,843: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3305 | 0.2121 | 0.3822 | 0.4546 |  0.5572 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3306 | 0.2129 | 0.3819 | 0.4546 |  0.5569 |
|     1      | 0.2453 | 0.1487 | 0.2783 | 0.3431 |  0.4334 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3302 | 0.2124 | 0.3817 | 0.454  |  0.5563 |
|     1      | 0.2456 | 0.1493 | 0.2787 | 0.3429 |  0.4322 |
|     2      | 0.2294 | 0.1369 | 0.2648 | 0.323  |  0.4079 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3302 | 0.2124 | 0.3803 | 0.4542 |  0.5559 |
|     1      | 0.2455 | 0.149  | 0.2789 | 0.3434 |  0.4329 |
|     2      | 0.2299 | 0.1374 | 0.265  | 0.3234 |  0.4068 |
|     3      | 0.2208 | 0.1293 | 0.2541 | 0.3149 |  0.3951 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3301 | 0.2122 | 0.3804 | 0.4535 |  0.5554 |
|     1      | 0.2462 |  0.15  | 0.2798 | 0.343  |  0.4335 |
|     2      | 0.2307 | 0.1386 | 0.2652 | 0.3233 |  0.4069 |
|     3      | 0.2216 | 0.1305 | 0.2542 | 0.3158 |  0.3952 |
|     4      | 0.2576 | 0.1491 | 0.3101 | 0.3776 |  0.4628 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 19:01:19,844: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 59.787235736846924 |   0.331   |    0.212     |    0.382     |     0.557     |
|    1     | 194.5081021785736  |   0.279   |    0.174     |    0.319     |     0.482     |
|    2     | 201.81772351264954 |    0.26   |     0.16     |    0.298     |     0.453     |
|    3     | 305.6232488155365  |   0.249   |    0.152     |    0.286     |     0.437     |
|    4     | 119.03136277198792 |   0.251   |    0.152     |     0.29     |     0.441     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 19:01:19,844: Sum_Training_Time:880.7676730155945
2024-12-27 19:01:19,844: Every_Training_Time:[59.787235736846924, 194.5081021785736, 201.81772351264954, 305.6232488155365, 119.03136277198792]
2024-12-27 19:01:19,844: Forward transfer: 0.045024999999999996 Backward transfer: 0.0006499999999999978
2024-12-27 19:01:53,549: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227190123/ENTITYentity_0.001_512_10', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.001_512_10', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.001_512_10', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=10, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 19:02:01,347: Snapshot:0	Epoch:0	Loss:69.32	translation_Loss:69.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.71	Hits@10:32.99	Best:13.71
2024-12-27 19:02:05,347: Snapshot:0	Epoch:1	Loss:39.171	translation_Loss:39.171	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.19	Hits@10:49.18	Best:26.19
2024-12-27 19:02:09,343: Snapshot:0	Epoch:2	Loss:18.414	translation_Loss:18.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.98	Hits@10:54.27	Best:30.98
2024-12-27 19:02:13,412: Snapshot:0	Epoch:3	Loss:9.284	translation_Loss:9.284	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.14	Hits@10:55.44	Best:32.14
2024-12-27 19:02:17,342: Snapshot:0	Epoch:4	Loss:5.429	translation_Loss:5.429	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.58	Hits@10:55.63	Best:32.58
2024-12-27 19:02:21,364: Snapshot:0	Epoch:5	Loss:3.681	translation_Loss:3.681	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.54	Hits@10:55.67	Best:32.58
2024-12-27 19:02:25,330: Snapshot:0	Epoch:6	Loss:2.806	translation_Loss:2.806	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.6	Hits@10:55.68	Best:32.6
2024-12-27 19:02:29,369: Snapshot:0	Epoch:7	Loss:2.268	translation_Loss:2.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.34	Hits@10:55.15	Best:32.6
2024-12-27 19:02:33,289: Snapshot:0	Epoch:8	Loss:1.948	translation_Loss:1.948	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.32	Hits@10:54.68	Best:32.6
2024-12-27 19:02:37,212: Snapshot:0	Epoch:9	Loss:1.709	translation_Loss:1.709	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.29	Hits@10:54.81	Best:32.6
2024-12-27 19:02:41,245: Snapshot:0	Epoch:10	Loss:1.559	translation_Loss:1.559	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.85	Hits@10:54.48	Best:32.6
2024-12-27 19:02:45,224: Early Stopping! Snapshot: 0 Epoch: 11 Best Results: 32.6
2024-12-27 19:02:45,224: Start to training tokens! Snapshot: 0 Epoch: 11 Loss:1.438 MRR:31.93 Best Results: 32.6
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 19:02:45,224: Snapshot:0	Epoch:11	Loss:1.438	translation_Loss:1.438	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.93	Hits@10:54.5	Best:32.6
2024-12-27 19:02:50,057: Snapshot:0	Epoch:12	Loss:56.206	translation_Loss:56.024	multi_layer_Loss:0.181	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.93	Hits@10:54.5	Best:32.6
2024-12-27 19:02:54,265: End of token training: 0 Epoch: 13 Loss:56.025 MRR:31.93 Best Results: 32.6
2024-12-27 19:02:54,265: Snapshot:0	Epoch:13	Loss:56.025	translation_Loss:56.025	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.93	Hits@10:54.5	Best:32.6
2024-12-27 19:02:54,578: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_10/0model_best.tar'
2024-12-27 19:02:56,344: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3302 | 0.2093 | 0.3841 | 0.4601 |  0.5596 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:03:20,985: Snapshot:1	Epoch:0	Loss:50.661	translation_Loss:47.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.426                                                   	MRR:20.9	Hits@10:37.31	Best:20.9
2024-12-27 19:03:28,193: Snapshot:1	Epoch:1	Loss:14.622	translation_Loss:13.193	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.429                                                   	MRR:22.97	Hits@10:40.85	Best:22.97
2024-12-27 19:03:35,359: Snapshot:1	Epoch:2	Loss:10.043	translation_Loss:8.707	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.337                                                   	MRR:23.48	Hits@10:41.59	Best:23.48
2024-12-27 19:03:42,554: Snapshot:1	Epoch:3	Loss:8.436	translation_Loss:7.252	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.183                                                   	MRR:23.59	Hits@10:41.95	Best:23.59
2024-12-27 19:03:49,842: Snapshot:1	Epoch:4	Loss:7.686	translation_Loss:6.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.179                                                   	MRR:23.83	Hits@10:42.54	Best:23.83
2024-12-27 19:03:57,150: Snapshot:1	Epoch:5	Loss:7.197	translation_Loss:6.027	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.17                                                   	MRR:23.8	Hits@10:42.49	Best:23.83
2024-12-27 19:04:04,344: Snapshot:1	Epoch:6	Loss:6.928	translation_Loss:5.75	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.178                                                   	MRR:23.97	Hits@10:42.4	Best:23.97
2024-12-27 19:04:11,495: Snapshot:1	Epoch:7	Loss:6.595	translation_Loss:5.421	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.174                                                   	MRR:23.85	Hits@10:42.52	Best:23.97
2024-12-27 19:04:18,657: Snapshot:1	Epoch:8	Loss:6.399	translation_Loss:5.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.155                                                   	MRR:23.96	Hits@10:42.91	Best:23.97
2024-12-27 19:04:25,914: Snapshot:1	Epoch:9	Loss:6.251	translation_Loss:5.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.154                                                   	MRR:24.02	Hits@10:42.86	Best:24.02
2024-12-27 19:04:33,091: Snapshot:1	Epoch:10	Loss:6.147	translation_Loss:4.987	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.16                                                   	MRR:23.97	Hits@10:42.65	Best:24.02
2024-12-27 19:04:40,262: Snapshot:1	Epoch:11	Loss:6.003	translation_Loss:4.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.15                                                   	MRR:24.05	Hits@10:42.72	Best:24.05
2024-12-27 19:04:47,454: Snapshot:1	Epoch:12	Loss:5.93	translation_Loss:4.77	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.16                                                   	MRR:24.26	Hits@10:43.04	Best:24.26
2024-12-27 19:04:54,721: Snapshot:1	Epoch:13	Loss:5.801	translation_Loss:4.65	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.151                                                   	MRR:24.24	Hits@10:43.02	Best:24.26
2024-12-27 19:05:02,084: Snapshot:1	Epoch:14	Loss:5.678	translation_Loss:4.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.132                                                   	MRR:24.29	Hits@10:42.93	Best:24.29
2024-12-27 19:05:09,436: Snapshot:1	Epoch:15	Loss:5.737	translation_Loss:4.582	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.155                                                   	MRR:24.23	Hits@10:43.06	Best:24.29
2024-12-27 19:05:16,840: Snapshot:1	Epoch:16	Loss:5.635	translation_Loss:4.486	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.148                                                   	MRR:24.44	Hits@10:43.24	Best:24.44
2024-12-27 19:05:24,520: Snapshot:1	Epoch:17	Loss:5.521	translation_Loss:4.394	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.127                                                   	MRR:24.44	Hits@10:43.24	Best:24.44
2024-12-27 19:05:31,843: Snapshot:1	Epoch:18	Loss:5.519	translation_Loss:4.375	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.144                                                   	MRR:24.41	Hits@10:42.97	Best:24.44
2024-12-27 19:05:39,057: Snapshot:1	Epoch:19	Loss:5.432	translation_Loss:4.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.125                                                   	MRR:24.28	Hits@10:43.05	Best:24.44
2024-12-27 19:05:46,257: Snapshot:1	Epoch:20	Loss:5.381	translation_Loss:4.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.128                                                   	MRR:24.39	Hits@10:43.18	Best:24.44
2024-12-27 19:05:53,543: Early Stopping! Snapshot: 1 Epoch: 21 Best Results: 24.44
2024-12-27 19:05:53,544: Start to training tokens! Snapshot: 1 Epoch: 21 Loss:5.356 MRR:24.35 Best Results: 24.44
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 19:05:53,544: Snapshot:1	Epoch:21	Loss:5.356	translation_Loss:4.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.122                                                   	MRR:24.35	Hits@10:43.24	Best:24.44
2024-12-27 19:06:00,787: Snapshot:1	Epoch:22	Loss:93.115	translation_Loss:92.927	multi_layer_Loss:0.188	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.35	Hits@10:43.24	Best:24.44
2024-12-27 19:06:08,097: End of token training: 1 Epoch: 23 Loss:92.993 MRR:24.35 Best Results: 24.44
2024-12-27 19:06:08,097: Snapshot:1	Epoch:23	Loss:92.993	translation_Loss:92.993	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.35	Hits@10:43.24	Best:24.44
2024-12-27 19:06:08,409: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_10/1model_best.tar'
2024-12-27 19:06:12,097: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3303 | 0.2095 | 0.3844 | 0.4603 |  0.5599 |
|     1      | 0.2461 | 0.1494 | 0.2797 | 0.3438 |  0.4333 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:06:38,631: Snapshot:2	Epoch:0	Loss:46.249	translation_Loss:42.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.998                                                   	MRR:18.11	Hits@10:32.16	Best:18.11
2024-12-27 19:06:46,481: Snapshot:2	Epoch:1	Loss:13.85	translation_Loss:11.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.877                                                   	MRR:20.57	Hits@10:36.36	Best:20.57
2024-12-27 19:06:54,292: Snapshot:2	Epoch:2	Loss:10.256	translation_Loss:8.564	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.692                                                   	MRR:21.33	Hits@10:37.62	Best:21.33
2024-12-27 19:07:02,311: Snapshot:2	Epoch:3	Loss:9.032	translation_Loss:7.386	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.645                                                   	MRR:21.58	Hits@10:38.3	Best:21.58
2024-12-27 19:07:10,266: Snapshot:2	Epoch:4	Loss:8.445	translation_Loss:6.81	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.636                                                   	MRR:22.05	Hits@10:38.65	Best:22.05
2024-12-27 19:07:18,279: Snapshot:2	Epoch:5	Loss:8.003	translation_Loss:6.372	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.632                                                   	MRR:21.86	Hits@10:38.85	Best:22.05
2024-12-27 19:07:26,060: Snapshot:2	Epoch:6	Loss:7.642	translation_Loss:6.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.604                                                   	MRR:22.15	Hits@10:39.12	Best:22.15
2024-12-27 19:07:33,877: Snapshot:2	Epoch:7	Loss:7.427	translation_Loss:5.827	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.6                                                   	MRR:22.09	Hits@10:39.25	Best:22.15
2024-12-27 19:07:41,701: Snapshot:2	Epoch:8	Loss:7.29	translation_Loss:5.695	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.595                                                   	MRR:22.2	Hits@10:39.11	Best:22.2
2024-12-27 19:07:49,548: Snapshot:2	Epoch:9	Loss:7.069	translation_Loss:5.481	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.588                                                   	MRR:22.42	Hits@10:39.53	Best:22.42
2024-12-27 19:07:57,475: Snapshot:2	Epoch:10	Loss:6.925	translation_Loss:5.349	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.575                                                   	MRR:22.45	Hits@10:39.48	Best:22.45
2024-12-27 19:08:05,748: Snapshot:2	Epoch:11	Loss:6.84	translation_Loss:5.265	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.575                                                   	MRR:22.45	Hits@10:39.45	Best:22.45
2024-12-27 19:08:13,490: Snapshot:2	Epoch:12	Loss:6.77	translation_Loss:5.185	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.585                                                   	MRR:22.42	Hits@10:39.54	Best:22.45
2024-12-27 19:08:21,404: Snapshot:2	Epoch:13	Loss:6.648	translation_Loss:5.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.578                                                   	MRR:22.48	Hits@10:39.58	Best:22.48
2024-12-27 19:08:29,312: Snapshot:2	Epoch:14	Loss:6.558	translation_Loss:4.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.558                                                   	MRR:22.59	Hits@10:39.85	Best:22.59
2024-12-27 19:08:37,148: Snapshot:2	Epoch:15	Loss:6.543	translation_Loss:4.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.579                                                   	MRR:22.51	Hits@10:39.84	Best:22.59
2024-12-27 19:08:45,021: Snapshot:2	Epoch:16	Loss:6.42	translation_Loss:4.877	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.543                                                   	MRR:22.61	Hits@10:39.99	Best:22.61
2024-12-27 19:08:52,920: Snapshot:2	Epoch:17	Loss:6.377	translation_Loss:4.824	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.553                                                   	MRR:22.62	Hits@10:39.8	Best:22.62
2024-12-27 19:09:00,875: Snapshot:2	Epoch:18	Loss:6.305	translation_Loss:4.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.544                                                   	MRR:22.88	Hits@10:39.91	Best:22.88
2024-12-27 19:09:08,689: Snapshot:2	Epoch:19	Loss:6.23	translation_Loss:4.691	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.539                                                   	MRR:22.75	Hits@10:40.1	Best:22.88
2024-12-27 19:09:16,446: Snapshot:2	Epoch:20	Loss:6.21	translation_Loss:4.671	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.54                                                   	MRR:22.75	Hits@10:40.05	Best:22.88
2024-12-27 19:09:24,240: Snapshot:2	Epoch:21	Loss:6.227	translation_Loss:4.681	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.546                                                   	MRR:22.8	Hits@10:40.16	Best:22.88
2024-12-27 19:09:32,028: Snapshot:2	Epoch:22	Loss:6.194	translation_Loss:4.644	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.55                                                   	MRR:22.87	Hits@10:40.22	Best:22.88
2024-12-27 19:09:39,940: Early Stopping! Snapshot: 2 Epoch: 23 Best Results: 22.88
2024-12-27 19:09:39,940: Start to training tokens! Snapshot: 2 Epoch: 23 Loss:6.134 MRR:22.78 Best Results: 22.88
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 19:09:39,940: Snapshot:2	Epoch:23	Loss:6.134	translation_Loss:4.604	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.53                                                   	MRR:22.78	Hits@10:40.11	Best:22.88
2024-12-27 19:09:47,916: Snapshot:2	Epoch:24	Loss:93.877	translation_Loss:93.701	multi_layer_Loss:0.177	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.78	Hits@10:40.11	Best:22.88
2024-12-27 19:09:56,231: End of token training: 2 Epoch: 25 Loss:93.797 MRR:22.78 Best Results: 22.88
2024-12-27 19:09:56,231: Snapshot:2	Epoch:25	Loss:93.797	translation_Loss:93.797	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.78	Hits@10:40.11	Best:22.88
2024-12-27 19:09:56,473: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_10/2model_best.tar'
2024-12-27 19:10:02,981: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3301 | 0.2095 | 0.3846 | 0.4589 |  0.5602 |
|     1      | 0.2462 | 0.1493 | 0.2798 | 0.3439 |  0.4343 |
|     2      | 0.2283 | 0.1345 | 0.2629 | 0.3255 |  0.4083 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:10:29,471: Snapshot:3	Epoch:0	Loss:41.726	translation_Loss:37.548	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.178                                                   	MRR:17.89	Hits@10:32.42	Best:17.89
2024-12-27 19:10:37,403: Snapshot:3	Epoch:1	Loss:12.101	translation_Loss:10.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.964                                                   	MRR:19.63	Hits@10:35.69	Best:19.63
2024-12-27 19:10:45,322: Snapshot:3	Epoch:2	Loss:9.007	translation_Loss:7.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.746                                                   	MRR:20.54	Hits@10:36.97	Best:20.54
2024-12-27 19:10:53,267: Snapshot:3	Epoch:3	Loss:7.975	translation_Loss:6.275	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.699                                                   	MRR:20.7	Hits@10:37.3	Best:20.7
2024-12-27 19:11:01,704: Snapshot:3	Epoch:4	Loss:7.419	translation_Loss:5.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.68                                                   	MRR:20.87	Hits@10:37.87	Best:20.87
2024-12-27 19:11:09,621: Snapshot:3	Epoch:5	Loss:7.075	translation_Loss:5.403	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.672                                                   	MRR:21.13	Hits@10:38.21	Best:21.13
2024-12-27 19:11:17,617: Snapshot:3	Epoch:6	Loss:6.798	translation_Loss:5.14	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.658                                                   	MRR:21.2	Hits@10:38.31	Best:21.2
2024-12-27 19:11:25,712: Snapshot:3	Epoch:7	Loss:6.554	translation_Loss:4.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.655                                                   	MRR:21.38	Hits@10:38.45	Best:21.38
2024-12-27 19:11:33,709: Snapshot:3	Epoch:8	Loss:6.354	translation_Loss:4.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.634                                                   	MRR:21.45	Hits@10:38.65	Best:21.45
2024-12-27 19:11:41,776: Snapshot:3	Epoch:9	Loss:6.329	translation_Loss:4.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.655                                                   	MRR:21.46	Hits@10:38.73	Best:21.46
2024-12-27 19:11:49,942: Snapshot:3	Epoch:10	Loss:6.172	translation_Loss:4.526	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.646                                                   	MRR:21.42	Hits@10:38.88	Best:21.46
2024-12-27 19:11:57,861: Snapshot:3	Epoch:11	Loss:6.104	translation_Loss:4.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.632                                                   	MRR:21.4	Hits@10:39.0	Best:21.46
2024-12-27 19:12:05,897: Snapshot:3	Epoch:12	Loss:6.03	translation_Loss:4.41	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.62                                                   	MRR:21.6	Hits@10:39.15	Best:21.6
2024-12-27 19:12:13,903: Snapshot:3	Epoch:13	Loss:5.865	translation_Loss:4.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.61                                                   	MRR:21.73	Hits@10:39.16	Best:21.73
2024-12-27 19:12:21,776: Snapshot:3	Epoch:14	Loss:5.877	translation_Loss:4.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.626                                                   	MRR:21.61	Hits@10:39.13	Best:21.73
2024-12-27 19:12:29,673: Snapshot:3	Epoch:15	Loss:5.782	translation_Loss:4.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.612                                                   	MRR:21.61	Hits@10:39.22	Best:21.73
2024-12-27 19:12:37,537: Snapshot:3	Epoch:16	Loss:5.697	translation_Loss:4.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.604                                                   	MRR:21.7	Hits@10:39.45	Best:21.73
2024-12-27 19:12:45,465: Snapshot:3	Epoch:17	Loss:5.635	translation_Loss:4.062	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.573                                                   	MRR:21.76	Hits@10:39.34	Best:21.76
2024-12-27 19:12:53,401: Snapshot:3	Epoch:18	Loss:5.598	translation_Loss:4.003	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.595                                                   	MRR:21.7	Hits@10:39.18	Best:21.76
2024-12-27 19:13:01,478: Snapshot:3	Epoch:19	Loss:5.565	translation_Loss:3.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.597                                                   	MRR:21.84	Hits@10:39.65	Best:21.84
2024-12-27 19:13:09,785: Snapshot:3	Epoch:20	Loss:5.551	translation_Loss:3.954	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.598                                                   	MRR:21.86	Hits@10:39.65	Best:21.86
2024-12-27 19:13:17,686: Snapshot:3	Epoch:21	Loss:5.495	translation_Loss:3.912	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.583                                                   	MRR:21.87	Hits@10:39.51	Best:21.87
2024-12-27 19:13:25,619: Snapshot:3	Epoch:22	Loss:5.498	translation_Loss:3.908	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.591                                                   	MRR:22.06	Hits@10:39.59	Best:22.06
2024-12-27 19:13:33,522: Snapshot:3	Epoch:23	Loss:5.403	translation_Loss:3.831	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.572                                                   	MRR:21.91	Hits@10:39.6	Best:22.06
2024-12-27 19:13:41,357: Snapshot:3	Epoch:24	Loss:5.409	translation_Loss:3.824	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.586                                                   	MRR:21.84	Hits@10:39.72	Best:22.06
2024-12-27 19:13:49,229: Snapshot:3	Epoch:25	Loss:5.348	translation_Loss:3.796	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.552                                                   	MRR:21.98	Hits@10:39.64	Best:22.06
2024-12-27 19:13:57,199: Snapshot:3	Epoch:26	Loss:5.361	translation_Loss:3.786	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.575                                                   	MRR:21.97	Hits@10:39.77	Best:22.06
2024-12-27 19:14:05,225: Early Stopping! Snapshot: 3 Epoch: 27 Best Results: 22.06
2024-12-27 19:14:05,225: Start to training tokens! Snapshot: 3 Epoch: 27 Loss:5.333 MRR:21.92 Best Results: 22.06
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 19:14:05,225: Snapshot:3	Epoch:27	Loss:5.333	translation_Loss:3.768	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.565                                                   	MRR:21.92	Hits@10:39.51	Best:22.06
2024-12-27 19:14:13,150: Snapshot:3	Epoch:28	Loss:84.693	translation_Loss:84.516	multi_layer_Loss:0.177	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.92	Hits@10:39.51	Best:22.06
2024-12-27 19:14:21,122: End of token training: 3 Epoch: 29 Loss:84.534 MRR:21.92 Best Results: 22.06
2024-12-27 19:14:21,122: Snapshot:3	Epoch:29	Loss:84.534	translation_Loss:84.534	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.92	Hits@10:39.51	Best:22.06
2024-12-27 19:14:21,436: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_10/3model_best.tar'
2024-12-27 19:14:31,137: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3306 |  0.21  | 0.3856 | 0.4596 |  0.5603 |
|     1      | 0.2466 | 0.1498 | 0.2805 | 0.3442 |  0.4341 |
|     2      | 0.2287 | 0.1349 | 0.2636 | 0.3256 |  0.4085 |
|     3      | 0.2187 | 0.1277 | 0.2531 | 0.3116 |  0.3919 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:14:50,999: Snapshot:4	Epoch:0	Loss:30.948	translation_Loss:27.847	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.102                                                   	MRR:21.75	Hits@10:40.22	Best:21.75
2024-12-27 19:14:57,070: Snapshot:4	Epoch:1	Loss:7.077	translation_Loss:5.949	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.127                                                   	MRR:24.2	Hits@10:43.69	Best:24.2
2024-12-27 19:15:02,782: Snapshot:4	Epoch:2	Loss:4.513	translation_Loss:3.587	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.926                                                   	MRR:24.71	Hits@10:44.3	Best:24.71
2024-12-27 19:15:08,593: Snapshot:4	Epoch:3	Loss:3.777	translation_Loss:2.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.864                                                   	MRR:24.99	Hits@10:44.68	Best:24.99
2024-12-27 19:15:14,325: Snapshot:4	Epoch:4	Loss:3.423	translation_Loss:2.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.834                                                   	MRR:25.17	Hits@10:44.96	Best:25.17
2024-12-27 19:15:20,056: Snapshot:4	Epoch:5	Loss:3.216	translation_Loss:2.376	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.84                                                   	MRR:25.3	Hits@10:45.11	Best:25.3
2024-12-27 19:15:25,758: Snapshot:4	Epoch:6	Loss:3.08	translation_Loss:2.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.826                                                   	MRR:25.51	Hits@10:45.75	Best:25.51
2024-12-27 19:15:31,564: Snapshot:4	Epoch:7	Loss:2.975	translation_Loss:2.151	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.824                                                   	MRR:25.6	Hits@10:45.65	Best:25.6
2024-12-27 19:15:37,156: Snapshot:4	Epoch:8	Loss:2.9	translation_Loss:2.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.829                                                   	MRR:25.4	Hits@10:45.42	Best:25.6
2024-12-27 19:15:42,873: Snapshot:4	Epoch:9	Loss:2.822	translation_Loss:2.005	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.817                                                   	MRR:25.54	Hits@10:45.86	Best:25.6
2024-12-27 19:15:48,487: Snapshot:4	Epoch:10	Loss:2.75	translation_Loss:1.932	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.817                                                   	MRR:25.35	Hits@10:45.46	Best:25.6
2024-12-27 19:15:54,111: Snapshot:4	Epoch:11	Loss:2.706	translation_Loss:1.898	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.807                                                   	MRR:25.58	Hits@10:45.76	Best:25.6
2024-12-27 19:15:59,822: Snapshot:4	Epoch:12	Loss:2.641	translation_Loss:1.829	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.812                                                   	MRR:25.69	Hits@10:46.06	Best:25.69
2024-12-27 19:16:05,556: Snapshot:4	Epoch:13	Loss:2.63	translation_Loss:1.812	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.818                                                   	MRR:25.6	Hits@10:45.9	Best:25.69
2024-12-27 19:16:11,189: Snapshot:4	Epoch:14	Loss:2.586	translation_Loss:1.759	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.827                                                   	MRR:25.78	Hits@10:46.26	Best:25.78
2024-12-27 19:16:16,855: Snapshot:4	Epoch:15	Loss:2.531	translation_Loss:1.724	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.807                                                   	MRR:25.52	Hits@10:46.08	Best:25.78
2024-12-27 19:16:22,620: Snapshot:4	Epoch:16	Loss:2.524	translation_Loss:1.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.809                                                   	MRR:25.68	Hits@10:46.27	Best:25.78
2024-12-27 19:16:28,233: Snapshot:4	Epoch:17	Loss:2.518	translation_Loss:1.702	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.817                                                   	MRR:25.72	Hits@10:46.34	Best:25.78
2024-12-27 19:16:33,844: Snapshot:4	Epoch:18	Loss:2.439	translation_Loss:1.638	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.801                                                   	MRR:25.68	Hits@10:46.13	Best:25.78
2024-12-27 19:16:39,536: Early Stopping! Snapshot: 4 Epoch: 19 Best Results: 25.78
2024-12-27 19:16:39,536: Start to training tokens! Snapshot: 4 Epoch: 19 Loss:2.437 MRR:25.52 Best Results: 25.78
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 19:16:39,536: Snapshot:4	Epoch:19	Loss:2.437	translation_Loss:1.635	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.802                                                   	MRR:25.52	Hits@10:46.08	Best:25.78
2024-12-27 19:16:45,254: Snapshot:4	Epoch:20	Loss:46.098	translation_Loss:45.918	multi_layer_Loss:0.18	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.52	Hits@10:46.08	Best:25.78
2024-12-27 19:16:50,891: End of token training: 4 Epoch: 21 Loss:45.859 MRR:25.52 Best Results: 25.78
2024-12-27 19:16:50,892: Snapshot:4	Epoch:21	Loss:45.859	translation_Loss:45.859	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.52	Hits@10:46.08	Best:25.78
2024-12-27 19:16:51,269: => loading checkpoint './checkpoint/ENTITYentity_0.001_512_10/4model_best.tar'
2024-12-27 19:17:03,662: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3306 |  0.21  | 0.385  | 0.459  |  0.5592 |
|     1      | 0.2472 | 0.1505 | 0.2814 | 0.3451 |  0.4348 |
|     2      | 0.229  | 0.1353 | 0.2636 | 0.3256 |  0.4083 |
|     3      | 0.2196 | 0.1285 | 0.2537 | 0.3123 |  0.393  |
|     4      | 0.2598 | 0.1508 | 0.3121 | 0.3816 |  0.4682 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 19:17:03,664: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3302 | 0.2093 | 0.3841 | 0.4601 |  0.5596 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3303 | 0.2095 | 0.3844 | 0.4603 |  0.5599 |
|     1      | 0.2461 | 0.1494 | 0.2797 | 0.3438 |  0.4333 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3301 | 0.2095 | 0.3846 | 0.4589 |  0.5602 |
|     1      | 0.2462 | 0.1493 | 0.2798 | 0.3439 |  0.4343 |
|     2      | 0.2283 | 0.1345 | 0.2629 | 0.3255 |  0.4083 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3306 |  0.21  | 0.3856 | 0.4596 |  0.5603 |
|     1      | 0.2466 | 0.1498 | 0.2805 | 0.3442 |  0.4341 |
|     2      | 0.2287 | 0.1349 | 0.2636 | 0.3256 |  0.4085 |
|     3      | 0.2187 | 0.1277 | 0.2531 | 0.3116 |  0.3919 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3306 |  0.21  | 0.385  | 0.459  |  0.5592 |
|     1      | 0.2472 | 0.1505 | 0.2814 | 0.3451 |  0.4348 |
|     2      | 0.229  | 0.1353 | 0.2636 | 0.3256 |  0.4083 |
|     3      | 0.2196 | 0.1285 | 0.2537 | 0.3123 |  0.393  |
|     4      | 0.2598 | 0.1508 | 0.3121 | 0.3816 |  0.4682 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 19:17:03,664: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 60.71579909324646  |    0.33   |    0.209     |    0.384     |      0.56     |
|    1     | 189.51629090309143 |   0.279   |    0.173     |    0.321     |     0.483     |
|    2     | 221.19063925743103 |    0.26   |    0.158     |    0.299     |     0.455     |
|    3     | 255.01000881195068 |   0.249   |     0.15     |    0.287     |     0.438     |
|    4     | 137.0093960762024  |   0.251   |    0.151     |    0.291     |     0.443     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 19:17:03,664: Sum_Training_Time:863.442134141922
2024-12-27 19:17:03,664: Every_Training_Time:[60.71579909324646, 189.51629090309143, 221.19063925743103, 255.01000881195068, 137.0093960762024]
2024-12-27 19:17:03,664: Forward transfer: 0.0452 Backward transfer: 0.0007749999999999979
2024-12-27 19:17:37,733: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227191707/ENTITYentity_0.001_1024_2', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.001_1024_2', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.001_1024_2', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=2, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 19:17:45,410: Snapshot:0	Epoch:0	Loss:36.581	translation_Loss:36.581	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.12	Hits@10:21.84	Best:9.12
2024-12-27 19:17:49,199: Snapshot:0	Epoch:1	Loss:25.656	translation_Loss:25.656	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.49	Hits@10:42.49	Best:19.49
2024-12-27 19:17:52,996: Snapshot:0	Epoch:2	Loss:15.145	translation_Loss:15.145	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.61	Hits@10:50.86	Best:27.61
2024-12-27 19:17:56,864: Snapshot:0	Epoch:3	Loss:8.399	translation_Loss:8.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.91	Hits@10:54.33	Best:30.91
2024-12-27 19:18:00,678: Snapshot:0	Epoch:4	Loss:4.826	translation_Loss:4.826	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.61	Hits@10:55.78	Best:32.61
2024-12-27 19:18:04,630: Snapshot:0	Epoch:5	Loss:3.039	translation_Loss:3.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.14	Hits@10:56.38	Best:33.14
2024-12-27 19:18:08,443: Snapshot:0	Epoch:6	Loss:2.11	translation_Loss:2.11	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.28	Hits@10:56.5	Best:33.28
2024-12-27 19:18:12,267: Snapshot:0	Epoch:7	Loss:1.589	translation_Loss:1.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.14	Hits@10:56.33	Best:33.28
2024-12-27 19:18:16,068: Snapshot:0	Epoch:8	Loss:1.274	translation_Loss:1.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.18	Hits@10:56.34	Best:33.28
2024-12-27 19:18:19,875: Snapshot:0	Epoch:9	Loss:1.064	translation_Loss:1.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.93	Hits@10:55.88	Best:33.28
2024-12-27 19:18:23,677: Snapshot:0	Epoch:10	Loss:0.94	translation_Loss:0.94	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.97	Hits@10:55.81	Best:33.28
2024-12-27 19:18:27,961: Early Stopping! Snapshot: 0 Epoch: 11 Best Results: 33.28
2024-12-27 19:18:27,961: Start to training tokens! Snapshot: 0 Epoch: 11 Loss:0.838 MRR:32.99 Best Results: 33.28
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 19:18:27,962: Snapshot:0	Epoch:11	Loss:0.838	translation_Loss:0.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.99	Hits@10:55.81	Best:33.28
2024-12-27 19:18:32,353: Snapshot:0	Epoch:12	Loss:28.471	translation_Loss:28.381	multi_layer_Loss:0.09	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.99	Hits@10:55.81	Best:33.28
2024-12-27 19:18:36,250: End of token training: 0 Epoch: 13 Loss:28.391 MRR:32.99 Best Results: 33.28
2024-12-27 19:18:36,250: Snapshot:0	Epoch:13	Loss:28.391	translation_Loss:28.391	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:32.99	Hits@10:55.81	Best:33.28
2024-12-27 19:18:36,513: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_2/0model_best.tar'
2024-12-27 19:18:37,922: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3369 | 0.2156 | 0.3953 | 0.4669 |  0.5692 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:19:01,713: Snapshot:1	Epoch:0	Loss:30.533	translation_Loss:29.05	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.483                                                   	MRR:19.65	Hits@10:35.11	Best:19.65
2024-12-27 19:19:08,432: Snapshot:1	Epoch:1	Loss:9.959	translation_Loss:9.128	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.831                                                   	MRR:23.35	Hits@10:41.26	Best:23.35
2024-12-27 19:19:15,093: Snapshot:1	Epoch:2	Loss:6.596	translation_Loss:5.889	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.707                                                   	MRR:24.05	Hits@10:42.45	Best:24.05
2024-12-27 19:19:22,146: Snapshot:1	Epoch:3	Loss:5.447	translation_Loss:4.784	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.663                                                   	MRR:24.24	Hits@10:43.06	Best:24.24
2024-12-27 19:19:28,880: Snapshot:1	Epoch:4	Loss:4.872	translation_Loss:4.226	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.646                                                   	MRR:24.45	Hits@10:43.45	Best:24.45
2024-12-27 19:19:35,579: Snapshot:1	Epoch:5	Loss:4.542	translation_Loss:3.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.64                                                   	MRR:24.51	Hits@10:43.64	Best:24.51
2024-12-27 19:19:42,264: Snapshot:1	Epoch:6	Loss:4.345	translation_Loss:3.706	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.64                                                   	MRR:24.6	Hits@10:43.89	Best:24.6
2024-12-27 19:19:48,920: Snapshot:1	Epoch:7	Loss:4.149	translation_Loss:3.512	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.636                                                   	MRR:24.36	Hits@10:43.72	Best:24.6
2024-12-27 19:19:55,578: Snapshot:1	Epoch:8	Loss:4.019	translation_Loss:3.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.627                                                   	MRR:24.52	Hits@10:43.75	Best:24.6
2024-12-27 19:20:02,380: Snapshot:1	Epoch:9	Loss:3.923	translation_Loss:3.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.628                                                   	MRR:24.79	Hits@10:43.96	Best:24.79
2024-12-27 19:20:09,349: Snapshot:1	Epoch:10	Loss:3.839	translation_Loss:3.216	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.623                                                   	MRR:24.77	Hits@10:44.05	Best:24.79
2024-12-27 19:20:16,039: Snapshot:1	Epoch:11	Loss:3.758	translation_Loss:3.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.62                                                   	MRR:24.8	Hits@10:44.01	Best:24.8
2024-12-27 19:20:22,782: Snapshot:1	Epoch:12	Loss:3.701	translation_Loss:3.078	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.623                                                   	MRR:25.01	Hits@10:44.25	Best:25.01
2024-12-27 19:20:29,910: Snapshot:1	Epoch:13	Loss:3.642	translation_Loss:3.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.626                                                   	MRR:24.89	Hits@10:43.89	Best:25.01
2024-12-27 19:20:36,646: Snapshot:1	Epoch:14	Loss:3.567	translation_Loss:2.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.617                                                   	MRR:24.97	Hits@10:44.22	Best:25.01
2024-12-27 19:20:43,278: Snapshot:1	Epoch:15	Loss:3.585	translation_Loss:2.962	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.623                                                   	MRR:24.93	Hits@10:43.99	Best:25.01
2024-12-27 19:20:49,952: Snapshot:1	Epoch:16	Loss:3.53	translation_Loss:2.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.621                                                   	MRR:24.97	Hits@10:43.91	Best:25.01
2024-12-27 19:20:56,643: Snapshot:1	Epoch:17	Loss:3.463	translation_Loss:2.85	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.612                                                   	MRR:25.07	Hits@10:44.15	Best:25.07
2024-12-27 19:21:03,279: Snapshot:1	Epoch:18	Loss:3.454	translation_Loss:2.835	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.619                                                   	MRR:25.03	Hits@10:44.1	Best:25.07
2024-12-27 19:21:09,941: Snapshot:1	Epoch:19	Loss:3.414	translation_Loss:2.802	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.612                                                   	MRR:24.97	Hits@10:44.23	Best:25.07
2024-12-27 19:21:16,651: Snapshot:1	Epoch:20	Loss:3.394	translation_Loss:2.776	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.618                                                   	MRR:25.01	Hits@10:44.28	Best:25.07
2024-12-27 19:21:23,401: Snapshot:1	Epoch:21	Loss:3.367	translation_Loss:2.755	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.613                                                   	MRR:24.82	Hits@10:44.02	Best:25.07
2024-12-27 19:21:30,154: Early Stopping! Snapshot: 1 Epoch: 22 Best Results: 25.07
2024-12-27 19:21:30,154: Start to training tokens! Snapshot: 1 Epoch: 22 Loss:3.311 MRR:24.96 Best Results: 25.07
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 19:21:30,155: Snapshot:1	Epoch:22	Loss:3.311	translation_Loss:2.703	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.608                                                   	MRR:24.96	Hits@10:44.21	Best:25.07
2024-12-27 19:21:36,820: Snapshot:1	Epoch:23	Loss:46.582	translation_Loss:46.489	multi_layer_Loss:0.093	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.96	Hits@10:44.21	Best:25.07
2024-12-27 19:21:43,960: End of token training: 1 Epoch: 24 Loss:46.524 MRR:24.96 Best Results: 25.07
2024-12-27 19:21:43,960: Snapshot:1	Epoch:24	Loss:46.524	translation_Loss:46.524	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.96	Hits@10:44.21	Best:25.07
2024-12-27 19:21:44,199: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_2/1model_best.tar'
2024-12-27 19:21:47,661: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3364 | 0.2148 | 0.3947 | 0.4664 |  0.5682 |
|     1      | 0.2541 | 0.1562 | 0.2889 | 0.3519 |  0.4426 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:22:12,781: Snapshot:2	Epoch:0	Loss:27.804	translation_Loss:25.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.916                                                   	MRR:17.33	Hits@10:30.19	Best:17.33
2024-12-27 19:22:20,165: Snapshot:2	Epoch:1	Loss:9.209	translation_Loss:8.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.14                                                   	MRR:20.53	Hits@10:36.4	Best:20.53
2024-12-27 19:22:27,833: Snapshot:2	Epoch:2	Loss:6.54	translation_Loss:5.559	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.98                                                   	MRR:21.72	Hits@10:37.97	Best:21.72
2024-12-27 19:22:35,169: Snapshot:2	Epoch:3	Loss:5.646	translation_Loss:4.709	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.937                                                   	MRR:22.1	Hits@10:38.99	Best:22.1
2024-12-27 19:22:42,468: Snapshot:2	Epoch:4	Loss:5.17	translation_Loss:4.259	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.911                                                   	MRR:22.45	Hits@10:39.35	Best:22.45
2024-12-27 19:22:49,754: Snapshot:2	Epoch:5	Loss:4.903	translation_Loss:4.004	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.899                                                   	MRR:22.46	Hits@10:39.68	Best:22.46
2024-12-27 19:22:57,147: Snapshot:2	Epoch:6	Loss:4.714	translation_Loss:3.822	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.892                                                   	MRR:22.85	Hits@10:39.91	Best:22.85
2024-12-27 19:23:04,534: Snapshot:2	Epoch:7	Loss:4.538	translation_Loss:3.653	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.884                                                   	MRR:22.64	Hits@10:40.01	Best:22.85
2024-12-27 19:23:11,806: Snapshot:2	Epoch:8	Loss:4.452	translation_Loss:3.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.889                                                   	MRR:22.97	Hits@10:40.33	Best:22.97
2024-12-27 19:23:19,157: Snapshot:2	Epoch:9	Loss:4.312	translation_Loss:3.436	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.876                                                   	MRR:23.02	Hits@10:40.57	Best:23.02
2024-12-27 19:23:26,505: Snapshot:2	Epoch:10	Loss:4.247	translation_Loss:3.371	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.876                                                   	MRR:23.13	Hits@10:40.56	Best:23.13
2024-12-27 19:23:34,190: Snapshot:2	Epoch:11	Loss:4.187	translation_Loss:3.313	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.874                                                   	MRR:23.11	Hits@10:40.58	Best:23.13
2024-12-27 19:23:41,500: Snapshot:2	Epoch:12	Loss:4.118	translation_Loss:3.249	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.87                                                   	MRR:23.15	Hits@10:40.57	Best:23.15
2024-12-27 19:23:48,804: Snapshot:2	Epoch:13	Loss:4.065	translation_Loss:3.194	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.871                                                   	MRR:23.23	Hits@10:40.88	Best:23.23
2024-12-27 19:23:56,130: Snapshot:2	Epoch:14	Loss:4.038	translation_Loss:3.166	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.872                                                   	MRR:23.03	Hits@10:40.74	Best:23.23
2024-12-27 19:24:03,415: Snapshot:2	Epoch:15	Loss:4.005	translation_Loss:3.128	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.877                                                   	MRR:23.18	Hits@10:40.97	Best:23.23
2024-12-27 19:24:10,712: Snapshot:2	Epoch:16	Loss:3.966	translation_Loss:3.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.871                                                   	MRR:23.18	Hits@10:40.87	Best:23.23
2024-12-27 19:24:18,116: Snapshot:2	Epoch:17	Loss:3.928	translation_Loss:3.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.862                                                   	MRR:23.17	Hits@10:41.09	Best:23.23
2024-12-27 19:24:25,423: Early Stopping! Snapshot: 2 Epoch: 18 Best Results: 23.23
2024-12-27 19:24:25,424: Start to training tokens! Snapshot: 2 Epoch: 18 Loss:3.886 MRR:23.22 Best Results: 23.23
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 19:24:25,424: Snapshot:2	Epoch:18	Loss:3.886	translation_Loss:3.023	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.863                                                   	MRR:23.22	Hits@10:40.98	Best:23.23
2024-12-27 19:24:32,707: Snapshot:2	Epoch:19	Loss:47.336	translation_Loss:47.236	multi_layer_Loss:0.1	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.22	Hits@10:40.98	Best:23.23
2024-12-27 19:24:39,955: End of token training: 2 Epoch: 20 Loss:47.218 MRR:23.22 Best Results: 23.23
2024-12-27 19:24:39,955: Snapshot:2	Epoch:20	Loss:47.218	translation_Loss:47.218	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.22	Hits@10:40.98	Best:23.23
2024-12-27 19:24:40,280: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_2/2model_best.tar'
2024-12-27 19:24:47,295: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.335  | 0.2128 | 0.3932 | 0.467  |  0.5686 |
|     1      | 0.254  | 0.1558 | 0.2904 | 0.3526 |  0.4424 |
|     2      | 0.2336 | 0.1393 | 0.2691 | 0.3313 |  0.4118 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:25:13,288: Snapshot:3	Epoch:0	Loss:25.091	translation_Loss:22.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.123                                                   	MRR:17.24	Hits@10:30.88	Best:17.24
2024-12-27 19:25:20,709: Snapshot:3	Epoch:1	Loss:7.827	translation_Loss:6.599	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.228                                                   	MRR:20.07	Hits@10:36.0	Best:20.07
2024-12-27 19:25:28,143: Snapshot:3	Epoch:2	Loss:5.61	translation_Loss:4.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.047                                                   	MRR:20.9	Hits@10:37.62	Best:20.9
2024-12-27 19:25:35,590: Snapshot:3	Epoch:3	Loss:4.839	translation_Loss:3.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.988                                                   	MRR:21.51	Hits@10:38.22	Best:21.51
2024-12-27 19:25:42,941: Snapshot:3	Epoch:4	Loss:4.509	translation_Loss:3.528	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.981                                                   	MRR:21.42	Hits@10:38.68	Best:21.51
2024-12-27 19:25:50,376: Snapshot:3	Epoch:5	Loss:4.237	translation_Loss:3.281	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.955                                                   	MRR:21.77	Hits@10:39.05	Best:21.77
2024-12-27 19:25:57,776: Snapshot:3	Epoch:6	Loss:4.087	translation_Loss:3.133	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.954                                                   	MRR:21.84	Hits@10:39.25	Best:21.84
2024-12-27 19:26:05,203: Snapshot:3	Epoch:7	Loss:3.957	translation_Loss:3.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.945                                                   	MRR:21.86	Hits@10:39.48	Best:21.86
2024-12-27 19:26:12,646: Snapshot:3	Epoch:8	Loss:3.868	translation_Loss:2.927	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.941                                                   	MRR:22.05	Hits@10:39.49	Best:22.05
2024-12-27 19:26:20,017: Snapshot:3	Epoch:9	Loss:3.79	translation_Loss:2.85	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.94                                                   	MRR:22.04	Hits@10:39.59	Best:22.05
2024-12-27 19:26:27,466: Snapshot:3	Epoch:10	Loss:3.717	translation_Loss:2.779	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.938                                                   	MRR:22.19	Hits@10:39.91	Best:22.19
2024-12-27 19:26:34,807: Snapshot:3	Epoch:11	Loss:3.638	translation_Loss:2.708	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.93                                                   	MRR:22.18	Hits@10:39.93	Best:22.19
2024-12-27 19:26:42,316: Snapshot:3	Epoch:12	Loss:3.599	translation_Loss:2.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.929                                                   	MRR:22.3	Hits@10:39.92	Best:22.3
2024-12-27 19:26:49,676: Snapshot:3	Epoch:13	Loss:3.548	translation_Loss:2.614	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.934                                                   	MRR:22.28	Hits@10:40.01	Best:22.3
2024-12-27 19:26:57,545: Snapshot:3	Epoch:14	Loss:3.564	translation_Loss:2.62	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.944                                                   	MRR:22.31	Hits@10:40.19	Best:22.31
2024-12-27 19:27:04,919: Snapshot:3	Epoch:15	Loss:3.483	translation_Loss:2.556	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.927                                                   	MRR:22.23	Hits@10:40.02	Best:22.31
2024-12-27 19:27:12,261: Snapshot:3	Epoch:16	Loss:3.461	translation_Loss:2.531	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.93                                                   	MRR:22.27	Hits@10:40.18	Best:22.31
2024-12-27 19:27:19,628: Snapshot:3	Epoch:17	Loss:3.424	translation_Loss:2.501	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.923                                                   	MRR:22.23	Hits@10:40.07	Best:22.31
2024-12-27 19:27:26,985: Snapshot:3	Epoch:18	Loss:3.376	translation_Loss:2.462	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.915                                                   	MRR:22.3	Hits@10:40.29	Best:22.31
2024-12-27 19:27:34,429: Snapshot:3	Epoch:19	Loss:3.376	translation_Loss:2.45	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.927                                                   	MRR:22.39	Hits@10:40.24	Best:22.39
2024-12-27 19:27:41,795: Snapshot:3	Epoch:20	Loss:3.332	translation_Loss:2.416	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.916                                                   	MRR:22.38	Hits@10:40.22	Best:22.39
2024-12-27 19:27:49,272: Snapshot:3	Epoch:21	Loss:3.329	translation_Loss:2.404	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.925                                                   	MRR:22.46	Hits@10:40.19	Best:22.46
2024-12-27 19:27:56,643: Snapshot:3	Epoch:22	Loss:3.309	translation_Loss:2.398	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.911                                                   	MRR:22.38	Hits@10:40.44	Best:22.46
2024-12-27 19:28:04,045: Snapshot:3	Epoch:23	Loss:3.282	translation_Loss:2.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.914                                                   	MRR:22.51	Hits@10:40.55	Best:22.51
2024-12-27 19:28:11,843: Snapshot:3	Epoch:24	Loss:3.266	translation_Loss:2.349	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.917                                                   	MRR:22.26	Hits@10:40.28	Best:22.51
2024-12-27 19:28:19,228: Snapshot:3	Epoch:25	Loss:3.247	translation_Loss:2.327	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.92                                                   	MRR:22.48	Hits@10:40.34	Best:22.51
2024-12-27 19:28:26,661: Snapshot:3	Epoch:26	Loss:3.241	translation_Loss:2.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.919                                                   	MRR:22.54	Hits@10:40.31	Best:22.54
2024-12-27 19:28:34,045: Snapshot:3	Epoch:27	Loss:3.232	translation_Loss:2.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.912                                                   	MRR:22.46	Hits@10:40.47	Best:22.54
2024-12-27 19:28:41,390: Snapshot:3	Epoch:28	Loss:3.214	translation_Loss:2.298	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.917                                                   	MRR:22.51	Hits@10:40.59	Best:22.54
2024-12-27 19:28:48,834: Snapshot:3	Epoch:29	Loss:3.201	translation_Loss:2.287	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.914                                                   	MRR:22.66	Hits@10:40.5	Best:22.66
2024-12-27 19:28:56,294: Snapshot:3	Epoch:30	Loss:3.177	translation_Loss:2.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.906                                                   	MRR:22.61	Hits@10:40.64	Best:22.66
2024-12-27 19:29:03,703: Snapshot:3	Epoch:31	Loss:3.157	translation_Loss:2.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.897                                                   	MRR:22.67	Hits@10:40.58	Best:22.67
2024-12-27 19:29:11,114: Snapshot:3	Epoch:32	Loss:3.154	translation_Loss:2.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.912                                                   	MRR:22.54	Hits@10:40.53	Best:22.67
2024-12-27 19:29:18,460: Snapshot:3	Epoch:33	Loss:3.166	translation_Loss:2.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.912                                                   	MRR:22.54	Hits@10:40.52	Best:22.67
2024-12-27 19:29:25,839: Snapshot:3	Epoch:34	Loss:3.146	translation_Loss:2.24	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.906                                                   	MRR:22.63	Hits@10:40.77	Best:22.67
2024-12-27 19:29:33,620: Snapshot:3	Epoch:35	Loss:3.159	translation_Loss:2.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.914                                                   	MRR:22.63	Hits@10:40.48	Best:22.67
2024-12-27 19:29:41,011: Early Stopping! Snapshot: 3 Epoch: 36 Best Results: 22.67
2024-12-27 19:29:41,011: Start to training tokens! Snapshot: 3 Epoch: 36 Loss:3.129 MRR:22.52 Best Results: 22.67
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 19:29:41,011: Snapshot:3	Epoch:36	Loss:3.129	translation_Loss:2.221	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.908                                                   	MRR:22.52	Hits@10:40.63	Best:22.67
2024-12-27 19:29:48,394: Snapshot:3	Epoch:37	Loss:42.337	translation_Loss:42.229	multi_layer_Loss:0.108	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.52	Hits@10:40.63	Best:22.67
2024-12-27 19:29:55,756: End of token training: 3 Epoch: 38 Loss:42.224 MRR:22.52 Best Results: 22.67
2024-12-27 19:29:55,756: Snapshot:3	Epoch:38	Loss:42.224	translation_Loss:42.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.52	Hits@10:40.63	Best:22.67
2024-12-27 19:29:56,068: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_2/3model_best.tar'
2024-12-27 19:30:05,592: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3359 | 0.2135 | 0.3936 | 0.4677 |  0.5671 |
|     1      | 0.2552 | 0.1582 |  0.29  | 0.3522 |  0.4434 |
|     2      | 0.2343 | 0.1403 |  0.27  | 0.331  |  0.4132 |
|     3      | 0.2256 | 0.1327 | 0.2612 | 0.3219 |  0.4033 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:30:25,260: Snapshot:4	Epoch:0	Loss:18.546	translation_Loss:17.034	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.512                                                   	MRR:20.03	Hits@10:38.05	Best:20.03
2024-12-27 19:30:30,596: Snapshot:4	Epoch:1	Loss:4.787	translation_Loss:4.004	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.783                                                   	MRR:24.23	Hits@10:43.6	Best:24.23
2024-12-27 19:30:35,920: Snapshot:4	Epoch:2	Loss:2.859	translation_Loss:2.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.582                                                   	MRR:25.05	Hits@10:44.89	Best:25.05
2024-12-27 19:30:41,372: Snapshot:4	Epoch:3	Loss:2.25	translation_Loss:1.743	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.507                                                   	MRR:25.53	Hits@10:45.73	Best:25.53
2024-12-27 19:30:46,781: Snapshot:4	Epoch:4	Loss:2.023	translation_Loss:1.539	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.484                                                   	MRR:25.69	Hits@10:46.07	Best:25.69
2024-12-27 19:30:52,240: Snapshot:4	Epoch:5	Loss:1.888	translation_Loss:1.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.474                                                   	MRR:25.67	Hits@10:46.18	Best:25.69
2024-12-27 19:30:57,613: Snapshot:4	Epoch:6	Loss:1.799	translation_Loss:1.333	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.466                                                   	MRR:26.06	Hits@10:46.32	Best:26.06
2024-12-27 19:31:02,934: Snapshot:4	Epoch:7	Loss:1.749	translation_Loss:1.283	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.467                                                   	MRR:26.01	Hits@10:46.28	Best:26.06
2024-12-27 19:31:08,322: Snapshot:4	Epoch:8	Loss:1.702	translation_Loss:1.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.472                                                   	MRR:26.12	Hits@10:46.64	Best:26.12
2024-12-27 19:31:13,576: Snapshot:4	Epoch:9	Loss:1.648	translation_Loss:1.183	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.465                                                   	MRR:25.98	Hits@10:46.52	Best:26.12
2024-12-27 19:31:18,835: Snapshot:4	Epoch:10	Loss:1.612	translation_Loss:1.154	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.458                                                   	MRR:26.12	Hits@10:46.68	Best:26.12
2024-12-27 19:31:24,254: Snapshot:4	Epoch:11	Loss:1.576	translation_Loss:1.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.46                                                   	MRR:26.18	Hits@10:46.91	Best:26.18
2024-12-27 19:31:29,581: Snapshot:4	Epoch:12	Loss:1.56	translation_Loss:1.099	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.461                                                   	MRR:25.95	Hits@10:46.6	Best:26.18
2024-12-27 19:31:34,841: Snapshot:4	Epoch:13	Loss:1.527	translation_Loss:1.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.457                                                   	MRR:26.16	Hits@10:47.08	Best:26.18
2024-12-27 19:31:40,147: Snapshot:4	Epoch:14	Loss:1.525	translation_Loss:1.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.459                                                   	MRR:26.22	Hits@10:47.26	Best:26.22
2024-12-27 19:31:45,497: Snapshot:4	Epoch:15	Loss:1.497	translation_Loss:1.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.46                                                   	MRR:26.23	Hits@10:47.26	Best:26.23
2024-12-27 19:31:50,850: Snapshot:4	Epoch:16	Loss:1.475	translation_Loss:1.02	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.455                                                   	MRR:26.37	Hits@10:47.08	Best:26.37
2024-12-27 19:31:56,202: Snapshot:4	Epoch:17	Loss:1.471	translation_Loss:1.021	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.45                                                   	MRR:26.42	Hits@10:47.37	Best:26.42
2024-12-27 19:32:01,564: Snapshot:4	Epoch:18	Loss:1.467	translation_Loss:1.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.457                                                   	MRR:26.41	Hits@10:47.49	Best:26.42
2024-12-27 19:32:07,007: Snapshot:4	Epoch:19	Loss:1.445	translation_Loss:0.992	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.452                                                   	MRR:26.55	Hits@10:47.52	Best:26.55
2024-12-27 19:32:12,385: Snapshot:4	Epoch:20	Loss:1.425	translation_Loss:0.971	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.454                                                   	MRR:26.81	Hits@10:47.42	Best:26.81
2024-12-27 19:32:17,686: Snapshot:4	Epoch:21	Loss:1.423	translation_Loss:0.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.454                                                   	MRR:26.62	Hits@10:47.46	Best:26.81
2024-12-27 19:32:22,965: Snapshot:4	Epoch:22	Loss:1.414	translation_Loss:0.957	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.457                                                   	MRR:26.55	Hits@10:47.47	Best:26.81
2024-12-27 19:32:28,218: Snapshot:4	Epoch:23	Loss:1.396	translation_Loss:0.948	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.448                                                   	MRR:26.37	Hits@10:47.6	Best:26.81
2024-12-27 19:32:33,483: Snapshot:4	Epoch:24	Loss:1.399	translation_Loss:0.946	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.453                                                   	MRR:26.47	Hits@10:47.57	Best:26.81
2024-12-27 19:32:38,772: Early Stopping! Snapshot: 4 Epoch: 25 Best Results: 26.81
2024-12-27 19:32:38,772: Start to training tokens! Snapshot: 4 Epoch: 25 Loss:1.395 MRR:26.65 Best Results: 26.81
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 19:32:38,773: Snapshot:4	Epoch:25	Loss:1.395	translation_Loss:0.941	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.454                                                   	MRR:26.65	Hits@10:47.73	Best:26.81
2024-12-27 19:32:44,038: Snapshot:4	Epoch:26	Loss:23.242	translation_Loss:23.142	multi_layer_Loss:0.1	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.65	Hits@10:47.73	Best:26.81
2024-12-27 19:32:49,288: End of token training: 4 Epoch: 27 Loss:23.121 MRR:26.65 Best Results: 26.81
2024-12-27 19:32:49,289: Snapshot:4	Epoch:27	Loss:23.121	translation_Loss:23.121	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.65	Hits@10:47.73	Best:26.81
2024-12-27 19:32:49,602: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_2/4model_best.tar'
2024-12-27 19:33:01,660: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3351 | 0.213  | 0.3925 | 0.4667 |  0.565  |
|     1      | 0.2549 | 0.1576 | 0.2897 | 0.3523 |  0.4426 |
|     2      | 0.2347 | 0.1407 | 0.2697 | 0.331  |  0.413  |
|     3      | 0.2272 | 0.1347 | 0.2623 | 0.322  |  0.4047 |
|     4      | 0.2687 | 0.1583 | 0.3224 | 0.3918 |  0.4793 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 19:33:01,662: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3369 | 0.2156 | 0.3953 | 0.4669 |  0.5692 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3364 | 0.2148 | 0.3947 | 0.4664 |  0.5682 |
|     1      | 0.2541 | 0.1562 | 0.2889 | 0.3519 |  0.4426 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.335  | 0.2128 | 0.3932 | 0.467  |  0.5686 |
|     1      | 0.254  | 0.1558 | 0.2904 | 0.3526 |  0.4424 |
|     2      | 0.2336 | 0.1393 | 0.2691 | 0.3313 |  0.4118 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3359 | 0.2135 | 0.3936 | 0.4677 |  0.5671 |
|     1      | 0.2552 | 0.1582 |  0.29  | 0.3522 |  0.4434 |
|     2      | 0.2343 | 0.1403 |  0.27  | 0.331  |  0.4132 |
|     3      | 0.2256 | 0.1327 | 0.2612 | 0.3219 |  0.4033 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3351 | 0.213  | 0.3925 | 0.4667 |  0.565  |
|     1      | 0.2549 | 0.1576 | 0.2897 | 0.3523 |  0.4426 |
|     2      | 0.2347 | 0.1407 | 0.2697 | 0.331  |  0.413  |
|     3      | 0.2272 | 0.1347 | 0.2623 | 0.322  |  0.4047 |
|     4      | 0.2687 | 0.1583 | 0.3224 | 0.3918 |  0.4793 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 19:33:01,663: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 58.51560616493225  |   0.337   |    0.216     |    0.395     |     0.569     |
|    1     | 183.83378529548645 |   0.286   |    0.179     |     0.33     |     0.492     |
|    2     | 169.5995032787323  |   0.266   |    0.163     |    0.307     |     0.461     |
|    3     | 305.16010642051697 |   0.256   |    0.156     |    0.295     |     0.446     |
|    4     | 161.15168929100037 |   0.258   |    0.157     |    0.299     |     0.451     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 19:33:01,663: Sum_Training_Time:878.2606904506683
2024-12-27 19:33:01,663: Every_Training_Time:[58.51560616493225, 183.83378529548645, 169.5995032787323, 305.16010642051697, 161.15168929100037]
2024-12-27 19:33:01,663: Forward transfer: 0.048625 Backward transfer: 0.00042500000000001564
2024-12-27 19:33:35,517: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227193305/ENTITYentity_0.001_1024_4', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.001_1024_4', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.001_1024_4', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=4, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 19:33:43,107: Snapshot:0	Epoch:0	Loss:36.581	translation_Loss:36.581	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.12	Hits@10:21.85	Best:9.12
2024-12-27 19:33:47,032: Snapshot:0	Epoch:1	Loss:25.656	translation_Loss:25.656	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.5	Hits@10:42.46	Best:19.5
2024-12-27 19:33:50,843: Snapshot:0	Epoch:2	Loss:15.145	translation_Loss:15.145	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.54	Hits@10:50.84	Best:27.54
2024-12-27 19:33:54,701: Snapshot:0	Epoch:3	Loss:8.398	translation_Loss:8.398	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.0	Hits@10:54.41	Best:31.0
2024-12-27 19:33:58,514: Snapshot:0	Epoch:4	Loss:4.823	translation_Loss:4.823	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.57	Hits@10:55.74	Best:32.57
2024-12-27 19:34:02,327: Snapshot:0	Epoch:5	Loss:3.04	translation_Loss:3.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.12	Hits@10:56.5	Best:33.12
2024-12-27 19:34:06,103: Snapshot:0	Epoch:6	Loss:2.111	translation_Loss:2.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.4	Hits@10:56.62	Best:33.4
2024-12-27 19:34:09,872: Snapshot:0	Epoch:7	Loss:1.587	translation_Loss:1.587	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.23	Hits@10:56.29	Best:33.4
2024-12-27 19:34:13,629: Snapshot:0	Epoch:8	Loss:1.277	translation_Loss:1.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.18	Hits@10:56.3	Best:33.4
2024-12-27 19:34:17,394: Snapshot:0	Epoch:9	Loss:1.065	translation_Loss:1.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.19	Hits@10:55.99	Best:33.4
2024-12-27 19:34:21,195: Snapshot:0	Epoch:10	Loss:0.938	translation_Loss:0.938	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.93	Hits@10:55.84	Best:33.4
2024-12-27 19:34:25,449: Early Stopping! Snapshot: 0 Epoch: 11 Best Results: 33.4
2024-12-27 19:34:25,449: Start to training tokens! Snapshot: 0 Epoch: 11 Loss:0.841 MRR:32.96 Best Results: 33.4
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 19:34:25,450: Snapshot:0	Epoch:11	Loss:0.841	translation_Loss:0.841	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.96	Hits@10:55.67	Best:33.4
2024-12-27 19:34:29,817: Snapshot:0	Epoch:12	Loss:28.51	translation_Loss:28.372	multi_layer_Loss:0.138	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.96	Hits@10:55.67	Best:33.4
2024-12-27 19:34:33,685: End of token training: 0 Epoch: 13 Loss:28.383 MRR:32.96 Best Results: 33.4
2024-12-27 19:34:33,686: Snapshot:0	Epoch:13	Loss:28.383	translation_Loss:28.383	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:32.96	Hits@10:55.67	Best:33.4
2024-12-27 19:34:33,929: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_4/0model_best.tar'
2024-12-27 19:34:35,279: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3378 | 0.216  | 0.3964 | 0.4676 |  0.5689 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:34:59,142: Snapshot:1	Epoch:0	Loss:30.738	translation_Loss:29.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.63                                                   	MRR:19.72	Hits@10:35.27	Best:19.72
2024-12-27 19:35:05,920: Snapshot:1	Epoch:1	Loss:9.841	translation_Loss:9.127	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.714                                                   	MRR:23.25	Hits@10:41.37	Best:23.25
2024-12-27 19:35:12,648: Snapshot:1	Epoch:2	Loss:6.512	translation_Loss:5.896	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.616                                                   	MRR:24.16	Hits@10:42.43	Best:24.16
2024-12-27 19:35:19,694: Snapshot:1	Epoch:3	Loss:5.372	translation_Loss:4.79	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.582                                                   	MRR:24.24	Hits@10:43.06	Best:24.24
2024-12-27 19:35:26,407: Snapshot:1	Epoch:4	Loss:4.815	translation_Loss:4.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.572                                                   	MRR:24.4	Hits@10:43.33	Best:24.4
2024-12-27 19:35:33,028: Snapshot:1	Epoch:5	Loss:4.479	translation_Loss:3.912	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.568                                                   	MRR:24.39	Hits@10:43.38	Best:24.4
2024-12-27 19:35:39,698: Snapshot:1	Epoch:6	Loss:4.283	translation_Loss:3.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.568                                                   	MRR:24.55	Hits@10:43.56	Best:24.55
2024-12-27 19:35:46,333: Snapshot:1	Epoch:7	Loss:4.092	translation_Loss:3.524	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.568                                                   	MRR:24.54	Hits@10:43.6	Best:24.55
2024-12-27 19:35:52,977: Snapshot:1	Epoch:8	Loss:3.971	translation_Loss:3.407	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.564                                                   	MRR:24.58	Hits@10:43.8	Best:24.58
2024-12-27 19:35:59,721: Snapshot:1	Epoch:9	Loss:3.855	translation_Loss:3.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.558                                                   	MRR:24.67	Hits@10:43.86	Best:24.67
2024-12-27 19:36:06,345: Snapshot:1	Epoch:10	Loss:3.787	translation_Loss:3.229	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.558                                                   	MRR:24.7	Hits@10:43.98	Best:24.7
2024-12-27 19:36:12,962: Snapshot:1	Epoch:11	Loss:3.698	translation_Loss:3.144	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.554                                                   	MRR:24.86	Hits@10:44.05	Best:24.86
2024-12-27 19:36:19,611: Snapshot:1	Epoch:12	Loss:3.649	translation_Loss:3.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.56                                                   	MRR:24.91	Hits@10:44.07	Best:24.91
2024-12-27 19:36:26,719: Snapshot:1	Epoch:13	Loss:3.582	translation_Loss:3.021	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.561                                                   	MRR:24.78	Hits@10:44.0	Best:24.91
2024-12-27 19:36:33,333: Snapshot:1	Epoch:14	Loss:3.51	translation_Loss:2.959	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.551                                                   	MRR:24.98	Hits@10:44.11	Best:24.98
2024-12-27 19:36:40,030: Snapshot:1	Epoch:15	Loss:3.525	translation_Loss:2.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.557                                                   	MRR:24.86	Hits@10:44.08	Best:24.98
2024-12-27 19:36:46,675: Snapshot:1	Epoch:16	Loss:3.471	translation_Loss:2.915	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.556                                                   	MRR:24.98	Hits@10:44.02	Best:24.98
2024-12-27 19:36:53,453: Snapshot:1	Epoch:17	Loss:3.405	translation_Loss:2.856	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.549                                                   	MRR:25.03	Hits@10:44.23	Best:25.03
2024-12-27 19:37:00,191: Snapshot:1	Epoch:18	Loss:3.4	translation_Loss:2.845	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.554                                                   	MRR:25.01	Hits@10:44.25	Best:25.03
2024-12-27 19:37:06,840: Snapshot:1	Epoch:19	Loss:3.36	translation_Loss:2.812	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.549                                                   	MRR:24.96	Hits@10:44.18	Best:25.03
2024-12-27 19:37:13,417: Snapshot:1	Epoch:20	Loss:3.339	translation_Loss:2.786	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.553                                                   	MRR:24.82	Hits@10:44.21	Best:25.03
2024-12-27 19:37:20,004: Snapshot:1	Epoch:21	Loss:3.31	translation_Loss:2.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.549                                                   	MRR:24.73	Hits@10:44.14	Best:25.03
2024-12-27 19:37:26,633: Early Stopping! Snapshot: 1 Epoch: 22 Best Results: 25.03
2024-12-27 19:37:26,633: Start to training tokens! Snapshot: 1 Epoch: 22 Loss:3.252 MRR:24.91 Best Results: 25.03
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 19:37:26,633: Snapshot:1	Epoch:22	Loss:3.252	translation_Loss:2.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.541                                                   	MRR:24.91	Hits@10:44.08	Best:25.03
2024-12-27 19:37:33,253: Snapshot:1	Epoch:23	Loss:46.646	translation_Loss:46.502	multi_layer_Loss:0.144	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.91	Hits@10:44.08	Best:25.03
2024-12-27 19:37:40,337: End of token training: 1 Epoch: 24 Loss:46.538 MRR:24.91 Best Results: 25.03
2024-12-27 19:37:40,338: Snapshot:1	Epoch:24	Loss:46.538	translation_Loss:46.538	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.91	Hits@10:44.08	Best:25.03
2024-12-27 19:37:40,608: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_4/1model_best.tar'
2024-12-27 19:37:44,560: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3378 | 0.2163 | 0.3955 | 0.468  |  0.5685 |
|     1      | 0.2537 | 0.1561 | 0.2886 | 0.3518 |  0.4427 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:38:09,633: Snapshot:2	Epoch:0	Loss:27.96	translation_Loss:25.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.031                                                   	MRR:17.21	Hits@10:30.14	Best:17.21
2024-12-27 19:38:16,932: Snapshot:2	Epoch:1	Loss:9.09	translation_Loss:8.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.013                                                   	MRR:20.47	Hits@10:36.24	Best:20.47
2024-12-27 19:38:24,720: Snapshot:2	Epoch:2	Loss:6.45	translation_Loss:5.573	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.876                                                   	MRR:21.57	Hits@10:37.74	Best:21.57
2024-12-27 19:38:32,037: Snapshot:2	Epoch:3	Loss:5.566	translation_Loss:4.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.836                                                   	MRR:22.03	Hits@10:38.67	Best:22.03
2024-12-27 19:38:39,356: Snapshot:2	Epoch:4	Loss:5.093	translation_Loss:4.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.815                                                   	MRR:22.26	Hits@10:39.02	Best:22.26
2024-12-27 19:38:46,677: Snapshot:2	Epoch:5	Loss:4.832	translation_Loss:4.022	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.81                                                   	MRR:22.4	Hits@10:39.69	Best:22.4
2024-12-27 19:38:54,020: Snapshot:2	Epoch:6	Loss:4.652	translation_Loss:3.842	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.81                                                   	MRR:22.65	Hits@10:39.89	Best:22.65
2024-12-27 19:39:01,404: Snapshot:2	Epoch:7	Loss:4.475	translation_Loss:3.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.799                                                   	MRR:22.7	Hits@10:39.9	Best:22.7
2024-12-27 19:39:08,673: Snapshot:2	Epoch:8	Loss:4.383	translation_Loss:3.579	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.803                                                   	MRR:22.95	Hits@10:40.34	Best:22.95
2024-12-27 19:39:15,940: Snapshot:2	Epoch:9	Loss:4.249	translation_Loss:3.454	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.795                                                   	MRR:22.9	Hits@10:40.48	Best:22.95
2024-12-27 19:39:23,236: Snapshot:2	Epoch:10	Loss:4.182	translation_Loss:3.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.792                                                   	MRR:22.97	Hits@10:40.32	Best:22.97
2024-12-27 19:39:30,952: Snapshot:2	Epoch:11	Loss:4.128	translation_Loss:3.334	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.794                                                   	MRR:23.16	Hits@10:40.54	Best:23.16
2024-12-27 19:39:38,196: Snapshot:2	Epoch:12	Loss:4.056	translation_Loss:3.269	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.787                                                   	MRR:23.06	Hits@10:40.43	Best:23.16
2024-12-27 19:39:45,483: Snapshot:2	Epoch:13	Loss:3.991	translation_Loss:3.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.785                                                   	MRR:23.18	Hits@10:40.71	Best:23.18
2024-12-27 19:39:52,743: Snapshot:2	Epoch:14	Loss:3.977	translation_Loss:3.188	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.79                                                   	MRR:23.16	Hits@10:40.72	Best:23.18
2024-12-27 19:40:00,064: Snapshot:2	Epoch:15	Loss:3.944	translation_Loss:3.153	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.791                                                   	MRR:23.2	Hits@10:40.63	Best:23.2
2024-12-27 19:40:07,555: Snapshot:2	Epoch:16	Loss:3.901	translation_Loss:3.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.785                                                   	MRR:23.15	Hits@10:40.81	Best:23.2
2024-12-27 19:40:14,879: Snapshot:2	Epoch:17	Loss:3.86	translation_Loss:3.082	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.778                                                   	MRR:23.26	Hits@10:40.87	Best:23.26
2024-12-27 19:40:22,167: Snapshot:2	Epoch:18	Loss:3.825	translation_Loss:3.043	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.782                                                   	MRR:23.26	Hits@10:40.74	Best:23.26
2024-12-27 19:40:29,490: Snapshot:2	Epoch:19	Loss:3.798	translation_Loss:3.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.784                                                   	MRR:23.21	Hits@10:40.94	Best:23.26
2024-12-27 19:40:36,829: Snapshot:2	Epoch:20	Loss:3.786	translation_Loss:3.003	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.784                                                   	MRR:23.24	Hits@10:40.77	Best:23.26
2024-12-27 19:40:44,549: Snapshot:2	Epoch:21	Loss:3.743	translation_Loss:2.962	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.78                                                   	MRR:23.3	Hits@10:40.82	Best:23.3
2024-12-27 19:40:51,767: Snapshot:2	Epoch:22	Loss:3.74	translation_Loss:2.958	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.782                                                   	MRR:23.29	Hits@10:40.88	Best:23.3
2024-12-27 19:40:59,102: Snapshot:2	Epoch:23	Loss:3.698	translation_Loss:2.917	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.781                                                   	MRR:23.25	Hits@10:40.87	Best:23.3
2024-12-27 19:41:06,368: Snapshot:2	Epoch:24	Loss:3.668	translation_Loss:2.898	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.77                                                   	MRR:23.38	Hits@10:40.8	Best:23.38
2024-12-27 19:41:13,641: Snapshot:2	Epoch:25	Loss:3.667	translation_Loss:2.894	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.773                                                   	MRR:23.24	Hits@10:40.92	Best:23.38
2024-12-27 19:41:20,866: Snapshot:2	Epoch:26	Loss:3.635	translation_Loss:2.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.774                                                   	MRR:23.36	Hits@10:40.99	Best:23.38
2024-12-27 19:41:28,308: Snapshot:2	Epoch:27	Loss:3.628	translation_Loss:2.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.777                                                   	MRR:23.37	Hits@10:41.12	Best:23.38
2024-12-27 19:41:35,558: Snapshot:2	Epoch:28	Loss:3.623	translation_Loss:2.848	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.774                                                   	MRR:23.39	Hits@10:41.07	Best:23.39
2024-12-27 19:41:42,882: Snapshot:2	Epoch:29	Loss:3.595	translation_Loss:2.823	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.772                                                   	MRR:23.47	Hits@10:41.15	Best:23.47
2024-12-27 19:41:50,155: Snapshot:2	Epoch:30	Loss:3.569	translation_Loss:2.795	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.774                                                   	MRR:23.38	Hits@10:41.05	Best:23.47
2024-12-27 19:41:58,015: Snapshot:2	Epoch:31	Loss:3.581	translation_Loss:2.809	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.773                                                   	MRR:23.51	Hits@10:41.3	Best:23.51
2024-12-27 19:42:05,265: Snapshot:2	Epoch:32	Loss:3.544	translation_Loss:2.775	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.769                                                   	MRR:23.4	Hits@10:40.94	Best:23.51
2024-12-27 19:42:12,500: Snapshot:2	Epoch:33	Loss:3.547	translation_Loss:2.783	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.764                                                   	MRR:23.28	Hits@10:40.97	Best:23.51
2024-12-27 19:42:19,847: Snapshot:2	Epoch:34	Loss:3.528	translation_Loss:2.759	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.77                                                   	MRR:23.45	Hits@10:41.08	Best:23.51
2024-12-27 19:42:27,166: Snapshot:2	Epoch:35	Loss:3.524	translation_Loss:2.755	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.769                                                   	MRR:23.37	Hits@10:41.25	Best:23.51
2024-12-27 19:42:34,467: Early Stopping! Snapshot: 2 Epoch: 36 Best Results: 23.51
2024-12-27 19:42:34,467: Start to training tokens! Snapshot: 2 Epoch: 36 Loss:3.511 MRR:23.5 Best Results: 23.51
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 19:42:34,467: Snapshot:2	Epoch:36	Loss:3.511	translation_Loss:2.743	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.768                                                   	MRR:23.5	Hits@10:41.07	Best:23.51
2024-12-27 19:42:41,670: Snapshot:2	Epoch:37	Loss:47.344	translation_Loss:47.203	multi_layer_Loss:0.142	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.5	Hits@10:41.07	Best:23.51
2024-12-27 19:42:48,909: End of token training: 2 Epoch: 38 Loss:47.204 MRR:23.5 Best Results: 23.51
2024-12-27 19:42:48,909: Snapshot:2	Epoch:38	Loss:47.204	translation_Loss:47.204	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.5	Hits@10:41.07	Best:23.51
2024-12-27 19:42:49,219: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_4/2model_best.tar'
2024-12-27 19:42:55,741: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3374 | 0.2157 | 0.3966 | 0.4684 |  0.5692 |
|     1      | 0.2538 | 0.1565 | 0.2884 | 0.3513 |  0.4427 |
|     2      | 0.2369 | 0.1419 | 0.2729 | 0.3339 |  0.4188 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:43:21,448: Snapshot:3	Epoch:0	Loss:25.129	translation_Loss:23.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.093                                                   	MRR:17.01	Hits@10:30.79	Best:17.01
2024-12-27 19:43:28,812: Snapshot:3	Epoch:1	Loss:7.65	translation_Loss:6.639	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.011                                                   	MRR:19.77	Hits@10:35.82	Best:19.77
2024-12-27 19:43:36,360: Snapshot:3	Epoch:2	Loss:5.467	translation_Loss:4.596	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.871                                                   	MRR:20.75	Hits@10:37.19	Best:20.75
2024-12-27 19:43:43,844: Snapshot:3	Epoch:3	Loss:4.723	translation_Loss:3.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.824                                                   	MRR:21.09	Hits@10:37.72	Best:21.09
2024-12-27 19:43:51,339: Snapshot:3	Epoch:4	Loss:4.378	translation_Loss:3.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.815                                                   	MRR:21.22	Hits@10:38.38	Best:21.22
2024-12-27 19:43:58,707: Snapshot:3	Epoch:5	Loss:4.112	translation_Loss:3.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.807                                                   	MRR:21.4	Hits@10:38.92	Best:21.4
2024-12-27 19:44:06,058: Snapshot:3	Epoch:6	Loss:3.976	translation_Loss:3.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.798                                                   	MRR:21.56	Hits@10:39.02	Best:21.56
2024-12-27 19:44:13,403: Snapshot:3	Epoch:7	Loss:3.836	translation_Loss:3.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.797                                                   	MRR:21.48	Hits@10:39.19	Best:21.56
2024-12-27 19:44:20,787: Snapshot:3	Epoch:8	Loss:3.762	translation_Loss:2.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.792                                                   	MRR:21.64	Hits@10:39.29	Best:21.64
2024-12-27 19:44:28,193: Snapshot:3	Epoch:9	Loss:3.684	translation_Loss:2.889	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.795                                                   	MRR:21.74	Hits@10:39.47	Best:21.74
2024-12-27 19:44:35,753: Snapshot:3	Epoch:10	Loss:3.583	translation_Loss:2.799	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.783                                                   	MRR:21.83	Hits@10:39.47	Best:21.83
2024-12-27 19:44:43,179: Snapshot:3	Epoch:11	Loss:3.533	translation_Loss:2.748	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.785                                                   	MRR:21.86	Hits@10:39.7	Best:21.86
2024-12-27 19:44:50,584: Snapshot:3	Epoch:12	Loss:3.485	translation_Loss:2.701	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.784                                                   	MRR:22.0	Hits@10:39.87	Best:22.0
2024-12-27 19:44:57,970: Snapshot:3	Epoch:13	Loss:3.43	translation_Loss:2.66	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.771                                                   	MRR:21.91	Hits@10:39.61	Best:22.0
2024-12-27 19:45:05,392: Snapshot:3	Epoch:14	Loss:3.421	translation_Loss:2.634	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.787                                                   	MRR:22.0	Hits@10:39.88	Best:22.0
2024-12-27 19:45:12,732: Snapshot:3	Epoch:15	Loss:3.353	translation_Loss:2.578	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.775                                                   	MRR:21.97	Hits@10:39.88	Best:22.0
2024-12-27 19:45:20,109: Snapshot:3	Epoch:16	Loss:3.333	translation_Loss:2.554	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.779                                                   	MRR:22.12	Hits@10:39.97	Best:22.12
2024-12-27 19:45:27,574: Snapshot:3	Epoch:17	Loss:3.29	translation_Loss:2.511	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.778                                                   	MRR:22.19	Hits@10:39.91	Best:22.19
2024-12-27 19:45:34,898: Snapshot:3	Epoch:18	Loss:3.261	translation_Loss:2.484	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.778                                                   	MRR:22.18	Hits@10:40.21	Best:22.19
2024-12-27 19:45:42,279: Snapshot:3	Epoch:19	Loss:3.259	translation_Loss:2.483	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.776                                                   	MRR:22.27	Hits@10:40.14	Best:22.27
2024-12-27 19:45:49,708: Snapshot:3	Epoch:20	Loss:3.227	translation_Loss:2.457	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.77                                                   	MRR:22.29	Hits@10:40.22	Best:22.29
2024-12-27 19:45:57,154: Snapshot:3	Epoch:21	Loss:3.198	translation_Loss:2.428	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.77                                                   	MRR:22.18	Hits@10:40.22	Best:22.29
2024-12-27 19:46:04,491: Snapshot:3	Epoch:22	Loss:3.207	translation_Loss:2.439	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.767                                                   	MRR:22.16	Hits@10:40.13	Best:22.29
2024-12-27 19:46:11,821: Snapshot:3	Epoch:23	Loss:3.192	translation_Loss:2.419	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.774                                                   	MRR:22.2	Hits@10:40.29	Best:22.29
2024-12-27 19:46:19,130: Snapshot:3	Epoch:24	Loss:3.17	translation_Loss:2.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.769                                                   	MRR:22.26	Hits@10:40.09	Best:22.29
2024-12-27 19:46:26,927: Early Stopping! Snapshot: 3 Epoch: 25 Best Results: 22.29
2024-12-27 19:46:26,928: Start to training tokens! Snapshot: 3 Epoch: 25 Loss:3.167 MRR:22.09 Best Results: 22.29
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 19:46:26,928: Snapshot:3	Epoch:25	Loss:3.167	translation_Loss:2.397	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.77                                                   	MRR:22.09	Hits@10:40.15	Best:22.29
2024-12-27 19:46:34,341: Snapshot:3	Epoch:26	Loss:42.515	translation_Loss:42.379	multi_layer_Loss:0.137	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.09	Hits@10:40.15	Best:22.29
2024-12-27 19:46:41,763: End of token training: 3 Epoch: 27 Loss:42.346 MRR:22.09 Best Results: 22.29
2024-12-27 19:46:41,763: Snapshot:3	Epoch:27	Loss:42.346	translation_Loss:42.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.09	Hits@10:40.15	Best:22.29
2024-12-27 19:46:42,015: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_4/3model_best.tar'
2024-12-27 19:46:51,585: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3375 | 0.216  | 0.3964 | 0.4687 |  0.5689 |
|     1      | 0.2544 | 0.157  | 0.2886 | 0.3519 |  0.4423 |
|     2      | 0.2379 | 0.1429 | 0.2734 | 0.3349 |  0.4202 |
|     3      | 0.2229 | 0.1309 | 0.2578 | 0.3184 |  0.4008 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:47:10,550: Snapshot:4	Epoch:0	Loss:18.819	translation_Loss:17.166	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.652                                                   	MRR:19.74	Hits@10:37.84	Best:19.74
2024-12-27 19:47:15,818: Snapshot:4	Epoch:1	Loss:4.73	translation_Loss:4.052	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.678                                                   	MRR:24.21	Hits@10:43.37	Best:24.21
2024-12-27 19:47:21,115: Snapshot:4	Epoch:2	Loss:2.78	translation_Loss:2.27	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.51                                                   	MRR:25.15	Hits@10:45.01	Best:25.15
2024-12-27 19:47:26,503: Snapshot:4	Epoch:3	Loss:2.204	translation_Loss:1.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.446                                                   	MRR:25.43	Hits@10:45.07	Best:25.43
2024-12-27 19:47:31,796: Snapshot:4	Epoch:4	Loss:1.997	translation_Loss:1.568	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.429                                                   	MRR:25.52	Hits@10:45.91	Best:25.52
2024-12-27 19:47:37,457: Snapshot:4	Epoch:5	Loss:1.852	translation_Loss:1.435	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.418                                                   	MRR:25.98	Hits@10:46.09	Best:25.98
2024-12-27 19:47:42,744: Snapshot:4	Epoch:6	Loss:1.784	translation_Loss:1.367	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.417                                                   	MRR:25.91	Hits@10:46.17	Best:25.98
2024-12-27 19:47:48,054: Snapshot:4	Epoch:7	Loss:1.708	translation_Loss:1.292	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.416                                                   	MRR:25.78	Hits@10:46.2	Best:25.98
2024-12-27 19:47:53,334: Snapshot:4	Epoch:8	Loss:1.667	translation_Loss:1.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.416                                                   	MRR:26.16	Hits@10:46.37	Best:26.16
2024-12-27 19:47:58,746: Snapshot:4	Epoch:9	Loss:1.642	translation_Loss:1.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.416                                                   	MRR:26.13	Hits@10:46.6	Best:26.16
2024-12-27 19:48:04,148: Snapshot:4	Epoch:10	Loss:1.581	translation_Loss:1.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.409                                                   	MRR:26.25	Hits@10:47.2	Best:26.25
2024-12-27 19:48:09,484: Snapshot:4	Epoch:11	Loss:1.541	translation_Loss:1.13	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.411                                                   	MRR:26.33	Hits@10:46.87	Best:26.33
2024-12-27 19:48:14,785: Snapshot:4	Epoch:12	Loss:1.547	translation_Loss:1.13	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.416                                                   	MRR:26.23	Hits@10:46.89	Best:26.33
2024-12-27 19:48:20,037: Snapshot:4	Epoch:13	Loss:1.49	translation_Loss:1.091	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.399                                                   	MRR:26.3	Hits@10:46.99	Best:26.33
2024-12-27 19:48:25,303: Snapshot:4	Epoch:14	Loss:1.484	translation_Loss:1.077	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.407                                                   	MRR:26.27	Hits@10:46.89	Best:26.33
2024-12-27 19:48:30,521: Snapshot:4	Epoch:15	Loss:1.453	translation_Loss:1.049	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.405                                                   	MRR:26.22	Hits@10:47.07	Best:26.33
2024-12-27 19:48:35,747: Early Stopping! Snapshot: 4 Epoch: 16 Best Results: 26.33
2024-12-27 19:48:35,748: Start to training tokens! Snapshot: 4 Epoch: 16 Loss:1.442 MRR:26.32 Best Results: 26.33
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-27 19:48:35,748: Snapshot:4	Epoch:16	Loss:1.442	translation_Loss:1.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.405                                                   	MRR:26.32	Hits@10:47.05	Best:26.33
2024-12-27 19:48:41,018: Snapshot:4	Epoch:17	Loss:23.411	translation_Loss:23.266	multi_layer_Loss:0.145	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.32	Hits@10:47.05	Best:26.33
2024-12-27 19:48:46,347: End of token training: 4 Epoch: 18 Loss:23.215 MRR:26.32 Best Results: 26.33
2024-12-27 19:48:46,347: Snapshot:4	Epoch:18	Loss:23.215	translation_Loss:23.215	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.32	Hits@10:47.05	Best:26.33
2024-12-27 19:48:46,675: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_4/4model_best.tar'
2024-12-27 19:48:58,963: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3362 | 0.2144 | 0.3959 | 0.4665 |  0.5668 |
|     1      | 0.2538 | 0.156  | 0.2891 | 0.3521 |  0.4421 |
|     2      | 0.2374 | 0.1419 | 0.274  | 0.3346 |  0.4201 |
|     3      | 0.2235 | 0.131  | 0.2588 | 0.319  |  0.4026 |
|     4      | 0.2651 | 0.157  | 0.3168 | 0.3855 |  0.4727 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 19:48:58,965: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3378 | 0.216  | 0.3964 | 0.4676 |  0.5689 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3378 | 0.2163 | 0.3955 | 0.468  |  0.5685 |
|     1      | 0.2537 | 0.1561 | 0.2886 | 0.3518 |  0.4427 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3374 | 0.2157 | 0.3966 | 0.4684 |  0.5692 |
|     1      | 0.2538 | 0.1565 | 0.2884 | 0.3513 |  0.4427 |
|     2      | 0.2369 | 0.1419 | 0.2729 | 0.3339 |  0.4188 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3375 | 0.216  | 0.3964 | 0.4687 |  0.5689 |
|     1      | 0.2544 | 0.157  | 0.2886 | 0.3519 |  0.4423 |
|     2      | 0.2379 | 0.1429 | 0.2734 | 0.3349 |  0.4202 |
|     3      | 0.2229 | 0.1309 | 0.2578 | 0.3184 |  0.4008 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3362 | 0.2144 | 0.3959 | 0.4665 |  0.5668 |
|     1      | 0.2538 | 0.156  | 0.2891 | 0.3521 |  0.4421 |
|     2      | 0.2374 | 0.1419 | 0.274  | 0.3346 |  0.4201 |
|     3      | 0.2235 | 0.131  | 0.2588 | 0.319  |  0.4026 |
|     4      | 0.2651 | 0.157  | 0.3168 | 0.3855 |  0.4727 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 19:48:58,966: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 58.16785526275635  |   0.338   |    0.216     |    0.396     |     0.569     |
|    1     | 182.85303664207458 |   0.287   |     0.18     |     0.33     |     0.492     |
|    2     | 301.63656401634216 |   0.267   |    0.165     |    0.309     |     0.464     |
|    3     |  222.982679605484  |   0.256   |    0.156     |    0.295     |     0.447     |
|    4     | 112.2828528881073  |   0.257   |    0.156     |    0.299     |     0.451     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 19:48:58,966: Sum_Training_Time:877.9229884147644
2024-12-27 19:48:58,966: Every_Training_Time:[58.16785526275635, 182.85303664207458, 301.63656401634216, 222.982679605484, 112.2828528881073]
2024-12-27 19:48:58,966: Forward transfer: 0.048825 Backward transfer: -9.999999999998205e-05
2024-12-27 19:49:32,424: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227194902/ENTITYentity_0.001_1024_6', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.001_1024_6', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.001_1024_6', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=6, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 19:49:39,999: Snapshot:0	Epoch:0	Loss:36.581	translation_Loss:36.581	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.12	Hits@10:21.85	Best:9.12
2024-12-27 19:49:43,844: Snapshot:0	Epoch:1	Loss:25.656	translation_Loss:25.656	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.5	Hits@10:42.47	Best:19.5
2024-12-27 19:49:47,663: Snapshot:0	Epoch:2	Loss:15.145	translation_Loss:15.145	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.59	Hits@10:50.89	Best:27.59
2024-12-27 19:49:51,541: Snapshot:0	Epoch:3	Loss:8.399	translation_Loss:8.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.86	Hits@10:54.37	Best:30.86
2024-12-27 19:49:55,433: Snapshot:0	Epoch:4	Loss:4.825	translation_Loss:4.825	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.62	Hits@10:55.74	Best:32.62
2024-12-27 19:49:59,260: Snapshot:0	Epoch:5	Loss:3.04	translation_Loss:3.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.2	Hits@10:56.61	Best:33.2
2024-12-27 19:50:03,106: Snapshot:0	Epoch:6	Loss:2.113	translation_Loss:2.113	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.27	Hits@10:56.81	Best:33.27
2024-12-27 19:50:07,098: Snapshot:0	Epoch:7	Loss:1.588	translation_Loss:1.588	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.21	Hits@10:56.48	Best:33.27
2024-12-27 19:50:10,974: Snapshot:0	Epoch:8	Loss:1.276	translation_Loss:1.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.29	Hits@10:56.22	Best:33.29
2024-12-27 19:50:14,876: Snapshot:0	Epoch:9	Loss:1.065	translation_Loss:1.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.09	Hits@10:55.91	Best:33.29
2024-12-27 19:50:18,679: Snapshot:0	Epoch:10	Loss:0.936	translation_Loss:0.936	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.0	Hits@10:55.98	Best:33.29
2024-12-27 19:50:22,978: Snapshot:0	Epoch:11	Loss:0.838	translation_Loss:0.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.0	Hits@10:55.67	Best:33.29
2024-12-27 19:50:26,743: Snapshot:0	Epoch:12	Loss:0.759	translation_Loss:0.759	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.92	Hits@10:55.55	Best:33.29
2024-12-27 19:50:30,502: Early Stopping! Snapshot: 0 Epoch: 13 Best Results: 33.29
2024-12-27 19:50:30,502: Start to training tokens! Snapshot: 0 Epoch: 13 Loss:0.688 MRR:32.47 Best Results: 33.29
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 19:50:30,502: Snapshot:0	Epoch:13	Loss:0.688	translation_Loss:0.688	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.47	Hits@10:55.15	Best:33.29
2024-12-27 19:50:34,891: Snapshot:0	Epoch:14	Loss:28.565	translation_Loss:28.406	multi_layer_Loss:0.159	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.47	Hits@10:55.15	Best:33.29
2024-12-27 19:50:38,855: End of token training: 0 Epoch: 15 Loss:28.428 MRR:32.47 Best Results: 33.29
2024-12-27 19:50:38,855: Snapshot:0	Epoch:15	Loss:28.428	translation_Loss:28.428	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:32.47	Hits@10:55.15	Best:33.29
2024-12-27 19:50:39,138: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_6/0model_best.tar'
2024-12-27 19:50:40,439: 
+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.337 | 0.2172 | 0.3929 | 0.4625 |  0.5636 |
+------------+-------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:51:04,731: Snapshot:1	Epoch:0	Loss:30.382	translation_Loss:28.555	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.827                                                   	MRR:19.16	Hits@10:34.28	Best:19.16
2024-12-27 19:51:11,381: Snapshot:1	Epoch:1	Loss:8.632	translation_Loss:8.045	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.587                                                   	MRR:23.09	Hits@10:40.85	Best:23.09
2024-12-27 19:51:18,070: Snapshot:1	Epoch:2	Loss:5.409	translation_Loss:4.908	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.5                                                   	MRR:23.94	Hits@10:42.19	Best:23.94
2024-12-27 19:51:24,824: Snapshot:1	Epoch:3	Loss:4.401	translation_Loss:3.926	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.475                                                   	MRR:24.08	Hits@10:42.63	Best:24.08
2024-12-27 19:51:31,494: Snapshot:1	Epoch:4	Loss:3.915	translation_Loss:3.45	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.465                                                   	MRR:24.29	Hits@10:43.35	Best:24.29
2024-12-27 19:51:38,128: Snapshot:1	Epoch:5	Loss:3.64	translation_Loss:3.185	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.455                                                   	MRR:24.12	Hits@10:43.2	Best:24.29
2024-12-27 19:51:44,828: Snapshot:1	Epoch:6	Loss:3.444	translation_Loss:2.985	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.459                                                   	MRR:24.35	Hits@10:43.33	Best:24.35
2024-12-27 19:51:51,529: Snapshot:1	Epoch:7	Loss:3.312	translation_Loss:2.854	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.458                                                   	MRR:24.65	Hits@10:43.38	Best:24.65
2024-12-27 19:51:58,163: Snapshot:1	Epoch:8	Loss:3.2	translation_Loss:2.745	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.455                                                   	MRR:24.59	Hits@10:43.69	Best:24.65
2024-12-27 19:52:04,880: Snapshot:1	Epoch:9	Loss:3.094	translation_Loss:2.641	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.454                                                   	MRR:24.32	Hits@10:43.54	Best:24.65
2024-12-27 19:52:11,585: Snapshot:1	Epoch:10	Loss:3.027	translation_Loss:2.575	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.452                                                   	MRR:24.66	Hits@10:43.64	Best:24.66
2024-12-27 19:52:18,240: Snapshot:1	Epoch:11	Loss:2.999	translation_Loss:2.539	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.46                                                   	MRR:24.73	Hits@10:43.74	Best:24.73
2024-12-27 19:52:24,918: Snapshot:1	Epoch:12	Loss:2.917	translation_Loss:2.462	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.454                                                   	MRR:24.83	Hits@10:43.9	Best:24.83
2024-12-27 19:52:31,553: Snapshot:1	Epoch:13	Loss:2.885	translation_Loss:2.426	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.459                                                   	MRR:24.76	Hits@10:43.69	Best:24.83
2024-12-27 19:52:38,153: Snapshot:1	Epoch:14	Loss:2.825	translation_Loss:2.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.452                                                   	MRR:24.87	Hits@10:43.79	Best:24.87
2024-12-27 19:52:44,801: Snapshot:1	Epoch:15	Loss:2.797	translation_Loss:2.348	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.449                                                   	MRR:24.91	Hits@10:43.79	Best:24.91
2024-12-27 19:52:51,439: Snapshot:1	Epoch:16	Loss:2.759	translation_Loss:2.306	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.453                                                   	MRR:24.77	Hits@10:43.67	Best:24.91
2024-12-27 19:52:58,107: Snapshot:1	Epoch:17	Loss:2.748	translation_Loss:2.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.455                                                   	MRR:24.79	Hits@10:43.76	Best:24.91
2024-12-27 19:53:04,697: Snapshot:1	Epoch:18	Loss:2.714	translation_Loss:2.264	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.45                                                   	MRR:24.83	Hits@10:44.08	Best:24.91
2024-12-27 19:53:11,294: Snapshot:1	Epoch:19	Loss:2.695	translation_Loss:2.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.452                                                   	MRR:24.89	Hits@10:43.97	Best:24.91
2024-12-27 19:53:17,996: Early Stopping! Snapshot: 1 Epoch: 20 Best Results: 24.91
2024-12-27 19:53:17,997: Start to training tokens! Snapshot: 1 Epoch: 20 Loss:2.662 MRR:24.75 Best Results: 24.91
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 19:53:17,997: Snapshot:1	Epoch:20	Loss:2.662	translation_Loss:2.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.448                                                   	MRR:24.75	Hits@10:43.78	Best:24.91
2024-12-27 19:53:24,687: Snapshot:1	Epoch:21	Loss:46.838	translation_Loss:46.667	multi_layer_Loss:0.172	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.75	Hits@10:43.78	Best:24.91
2024-12-27 19:53:31,334: End of token training: 1 Epoch: 22 Loss:46.633 MRR:24.75 Best Results: 24.91
2024-12-27 19:53:31,334: Snapshot:1	Epoch:22	Loss:46.633	translation_Loss:46.633	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.75	Hits@10:43.78	Best:24.91
2024-12-27 19:53:31,642: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_6/1model_best.tar'
2024-12-27 19:53:35,361: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3369 | 0.217  | 0.3928 | 0.463  |  0.5634 |
|     1      | 0.2499 | 0.1529 | 0.2833 | 0.3477 |  0.4385 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:54:01,034: Snapshot:2	Epoch:0	Loss:27.417	translation_Loss:25.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.233                                                   	MRR:17.11	Hits@10:30.2	Best:17.11
2024-12-27 19:54:08,519: Snapshot:2	Epoch:1	Loss:7.934	translation_Loss:7.048	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.886                                                   	MRR:20.44	Hits@10:35.99	Best:20.44
2024-12-27 19:54:15,781: Snapshot:2	Epoch:2	Loss:5.448	translation_Loss:4.698	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.751                                                   	MRR:21.44	Hits@10:37.93	Best:21.44
2024-12-27 19:54:23,066: Snapshot:2	Epoch:3	Loss:4.643	translation_Loss:3.933	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.71                                                   	MRR:22.04	Hits@10:38.61	Best:22.04
2024-12-27 19:54:30,348: Snapshot:2	Epoch:4	Loss:4.268	translation_Loss:3.566	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.702                                                   	MRR:22.22	Hits@10:39.09	Best:22.22
2024-12-27 19:54:37,670: Snapshot:2	Epoch:5	Loss:4.011	translation_Loss:3.323	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.688                                                   	MRR:22.52	Hits@10:39.6	Best:22.52
2024-12-27 19:54:44,945: Snapshot:2	Epoch:6	Loss:3.856	translation_Loss:3.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.689                                                   	MRR:22.49	Hits@10:39.6	Best:22.52
2024-12-27 19:54:52,274: Snapshot:2	Epoch:7	Loss:3.732	translation_Loss:3.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.692                                                   	MRR:22.68	Hits@10:40.04	Best:22.68
2024-12-27 19:54:59,632: Snapshot:2	Epoch:8	Loss:3.616	translation_Loss:2.928	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.688                                                   	MRR:22.89	Hits@10:40.17	Best:22.89
2024-12-27 19:55:07,074: Snapshot:2	Epoch:9	Loss:3.521	translation_Loss:2.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.684                                                   	MRR:22.93	Hits@10:40.24	Best:22.93
2024-12-27 19:55:14,339: Snapshot:2	Epoch:10	Loss:3.439	translation_Loss:2.761	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.678                                                   	MRR:23.01	Hits@10:40.34	Best:23.01
2024-12-27 19:55:21,625: Snapshot:2	Epoch:11	Loss:3.427	translation_Loss:2.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.687                                                   	MRR:23.16	Hits@10:40.41	Best:23.16
2024-12-27 19:55:28,924: Snapshot:2	Epoch:12	Loss:3.356	translation_Loss:2.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.681                                                   	MRR:23.07	Hits@10:40.32	Best:23.16
2024-12-27 19:55:36,270: Snapshot:2	Epoch:13	Loss:3.275	translation_Loss:2.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.668                                                   	MRR:23.04	Hits@10:40.52	Best:23.16
2024-12-27 19:55:43,516: Snapshot:2	Epoch:14	Loss:3.262	translation_Loss:2.584	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.679                                                   	MRR:22.97	Hits@10:40.57	Best:23.16
2024-12-27 19:55:50,794: Snapshot:2	Epoch:15	Loss:3.235	translation_Loss:2.557	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.679                                                   	MRR:23.12	Hits@10:40.46	Best:23.16
2024-12-27 19:55:58,043: Early Stopping! Snapshot: 2 Epoch: 16 Best Results: 23.16
2024-12-27 19:55:58,043: Start to training tokens! Snapshot: 2 Epoch: 16 Loss:3.214 MRR:23.13 Best Results: 23.16
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 19:55:58,044: Snapshot:2	Epoch:16	Loss:3.214	translation_Loss:2.534	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.681                                                   	MRR:23.13	Hits@10:40.63	Best:23.16
2024-12-27 19:56:05,295: Snapshot:2	Epoch:17	Loss:47.554	translation_Loss:47.392	multi_layer_Loss:0.162	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.13	Hits@10:40.63	Best:23.16
2024-12-27 19:56:12,526: End of token training: 2 Epoch: 18 Loss:47.47 MRR:23.13 Best Results: 23.16
2024-12-27 19:56:12,527: Snapshot:2	Epoch:18	Loss:47.47	translation_Loss:47.47	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.13	Hits@10:40.63	Best:23.16
2024-12-27 19:56:12,846: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_6/2model_best.tar'
2024-12-27 19:56:19,187: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3368 | 0.2167 | 0.3924 | 0.4639 |  0.5628 |
|     1      | 0.2498 | 0.1529 | 0.2823 | 0.347  |  0.439  |
|     2      | 0.2309 | 0.1383 | 0.2656 | 0.3246 |  0.4072 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:56:44,352: Snapshot:3	Epoch:0	Loss:24.745	translation_Loss:22.292	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.453                                                   	MRR:17.0	Hits@10:30.41	Best:17.0
2024-12-27 19:56:51,746: Snapshot:3	Epoch:1	Loss:6.791	translation_Loss:5.8	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.992                                                   	MRR:19.79	Hits@10:35.7	Best:19.79
2024-12-27 19:56:59,241: Snapshot:3	Epoch:2	Loss:4.681	translation_Loss:3.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.828                                                   	MRR:20.57	Hits@10:37.09	Best:20.57
2024-12-27 19:57:07,057: Snapshot:3	Epoch:3	Loss:4.069	translation_Loss:3.275	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.794                                                   	MRR:20.88	Hits@10:38.12	Best:20.88
2024-12-27 19:57:14,472: Snapshot:3	Epoch:4	Loss:3.735	translation_Loss:2.967	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.768                                                   	MRR:21.32	Hits@10:38.36	Best:21.32
2024-12-27 19:57:21,941: Snapshot:3	Epoch:5	Loss:3.546	translation_Loss:2.776	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.771                                                   	MRR:21.35	Hits@10:38.71	Best:21.35
2024-12-27 19:57:29,332: Snapshot:3	Epoch:6	Loss:3.411	translation_Loss:2.65	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.761                                                   	MRR:21.6	Hits@10:38.91	Best:21.6
2024-12-27 19:57:36,713: Snapshot:3	Epoch:7	Loss:3.277	translation_Loss:2.519	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.759                                                   	MRR:21.69	Hits@10:38.93	Best:21.69
2024-12-27 19:57:44,044: Snapshot:3	Epoch:8	Loss:3.21	translation_Loss:2.449	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.761                                                   	MRR:21.63	Hits@10:39.24	Best:21.69
2024-12-27 19:57:51,376: Snapshot:3	Epoch:9	Loss:3.128	translation_Loss:2.371	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.757                                                   	MRR:21.66	Hits@10:39.28	Best:21.69
2024-12-27 19:57:58,908: Snapshot:3	Epoch:10	Loss:3.079	translation_Loss:2.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.757                                                   	MRR:21.86	Hits@10:39.6	Best:21.86
2024-12-27 19:58:06,274: Snapshot:3	Epoch:11	Loss:2.996	translation_Loss:2.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.745                                                   	MRR:21.84	Hits@10:39.7	Best:21.86
2024-12-27 19:58:13,589: Snapshot:3	Epoch:12	Loss:2.964	translation_Loss:2.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.75                                                   	MRR:21.86	Hits@10:39.44	Best:21.86
2024-12-27 19:58:20,951: Snapshot:3	Epoch:13	Loss:2.934	translation_Loss:2.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.748                                                   	MRR:22.01	Hits@10:39.6	Best:22.01
2024-12-27 19:58:28,813: Snapshot:3	Epoch:14	Loss:2.916	translation_Loss:2.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.753                                                   	MRR:22.07	Hits@10:39.72	Best:22.07
2024-12-27 19:58:36,159: Snapshot:3	Epoch:15	Loss:2.851	translation_Loss:2.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.74                                                   	MRR:22.06	Hits@10:40.01	Best:22.07
2024-12-27 19:58:43,506: Snapshot:3	Epoch:16	Loss:2.864	translation_Loss:2.114	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.749                                                   	MRR:22.04	Hits@10:39.87	Best:22.07
2024-12-27 19:58:50,971: Snapshot:3	Epoch:17	Loss:2.82	translation_Loss:2.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.744                                                   	MRR:22.1	Hits@10:39.98	Best:22.1
2024-12-27 19:58:58,409: Snapshot:3	Epoch:18	Loss:2.813	translation_Loss:2.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.749                                                   	MRR:22.09	Hits@10:39.97	Best:22.1
2024-12-27 19:59:05,780: Snapshot:3	Epoch:19	Loss:2.788	translation_Loss:2.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.747                                                   	MRR:22.14	Hits@10:39.93	Best:22.14
2024-12-27 19:59:13,342: Snapshot:3	Epoch:20	Loss:2.765	translation_Loss:2.023	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.742                                                   	MRR:22.18	Hits@10:40.08	Best:22.18
2024-12-27 19:59:20,691: Snapshot:3	Epoch:21	Loss:2.721	translation_Loss:1.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.736                                                   	MRR:22.13	Hits@10:39.97	Best:22.18
2024-12-27 19:59:28,069: Snapshot:3	Epoch:22	Loss:2.712	translation_Loss:1.975	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.737                                                   	MRR:22.04	Hits@10:40.21	Best:22.18
2024-12-27 19:59:35,426: Snapshot:3	Epoch:23	Loss:2.71	translation_Loss:1.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.74                                                   	MRR:22.17	Hits@10:39.96	Best:22.18
2024-12-27 19:59:43,260: Snapshot:3	Epoch:24	Loss:2.7	translation_Loss:1.96	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.74                                                   	MRR:22.1	Hits@10:40.07	Best:22.18
2024-12-27 19:59:50,579: Early Stopping! Snapshot: 3 Epoch: 25 Best Results: 22.18
2024-12-27 19:59:50,579: Start to training tokens! Snapshot: 3 Epoch: 25 Loss:2.689 MRR:22.18 Best Results: 22.18
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 19:59:50,580: Snapshot:3	Epoch:25	Loss:2.689	translation_Loss:1.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.737                                                   	MRR:22.18	Hits@10:40.13	Best:22.18
2024-12-27 19:59:57,922: Snapshot:3	Epoch:26	Loss:42.538	translation_Loss:42.382	multi_layer_Loss:0.156	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.18	Hits@10:40.13	Best:22.18
2024-12-27 20:00:05,550: End of token training: 3 Epoch: 27 Loss:42.417 MRR:22.18 Best Results: 22.18
2024-12-27 20:00:05,550: Snapshot:3	Epoch:27	Loss:42.417	translation_Loss:42.417	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.18	Hits@10:40.13	Best:22.18
2024-12-27 20:00:05,817: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_6/3model_best.tar'
2024-12-27 20:00:15,467: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3373 | 0.2179 | 0.393  | 0.4641 |  0.5638 |
|     1      | 0.2495 | 0.1523 | 0.2827 | 0.347  |  0.4399 |
|     2      | 0.2309 | 0.1383 | 0.265  | 0.3246 |  0.4076 |
|     3      | 0.2209 | 0.1302 | 0.2528 | 0.315  |  0.3956 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:00:34,622: Snapshot:4	Epoch:0	Loss:18.701	translation_Loss:16.743	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.958                                                   	MRR:19.52	Hits@10:37.79	Best:19.52
2024-12-27 20:00:39,911: Snapshot:4	Epoch:1	Loss:4.257	translation_Loss:3.613	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.645                                                   	MRR:24.09	Hits@10:43.4	Best:24.09
2024-12-27 20:00:45,233: Snapshot:4	Epoch:2	Loss:2.396	translation_Loss:1.935	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.461                                                   	MRR:24.96	Hits@10:44.89	Best:24.96
2024-12-27 20:00:50,568: Snapshot:4	Epoch:3	Loss:1.879	translation_Loss:1.472	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.407                                                   	MRR:25.33	Hits@10:45.31	Best:25.33
2024-12-27 20:00:55,882: Snapshot:4	Epoch:4	Loss:1.678	translation_Loss:1.288	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.389                                                   	MRR:25.48	Hits@10:45.61	Best:25.48
2024-12-27 20:01:01,203: Snapshot:4	Epoch:5	Loss:1.577	translation_Loss:1.197	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.379                                                   	MRR:25.58	Hits@10:46.0	Best:25.58
2024-12-27 20:01:06,665: Snapshot:4	Epoch:6	Loss:1.517	translation_Loss:1.133	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.384                                                   	MRR:25.78	Hits@10:46.27	Best:25.78
2024-12-27 20:01:11,944: Snapshot:4	Epoch:7	Loss:1.448	translation_Loss:1.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.38                                                   	MRR:26.07	Hits@10:46.38	Best:26.07
2024-12-27 20:01:17,282: Snapshot:4	Epoch:8	Loss:1.42	translation_Loss:1.042	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.378                                                   	MRR:26.09	Hits@10:46.41	Best:26.09
2024-12-27 20:01:22,650: Snapshot:4	Epoch:9	Loss:1.378	translation_Loss:1.002	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.376                                                   	MRR:26.27	Hits@10:46.71	Best:26.27
2024-12-27 20:01:27,950: Snapshot:4	Epoch:10	Loss:1.351	translation_Loss:0.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.377                                                   	MRR:26.21	Hits@10:46.73	Best:26.27
2024-12-27 20:01:33,202: Snapshot:4	Epoch:11	Loss:1.329	translation_Loss:0.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.377                                                   	MRR:26.02	Hits@10:46.51	Best:26.27
2024-12-27 20:01:38,527: Snapshot:4	Epoch:12	Loss:1.298	translation_Loss:0.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.377                                                   	MRR:26.0	Hits@10:46.64	Best:26.27
2024-12-27 20:01:43,769: Snapshot:4	Epoch:13	Loss:1.274	translation_Loss:0.896	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.379                                                   	MRR:26.14	Hits@10:46.87	Best:26.27
2024-12-27 20:01:49,459: Early Stopping! Snapshot: 4 Epoch: 14 Best Results: 26.27
2024-12-27 20:01:49,460: Start to training tokens! Snapshot: 4 Epoch: 14 Loss:1.262 MRR:26.21 Best Results: 26.27
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-27 20:01:49,460: Snapshot:4	Epoch:14	Loss:1.262	translation_Loss:0.884	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.378                                                   	MRR:26.21	Hits@10:46.66	Best:26.27
2024-12-27 20:01:54,718: Snapshot:4	Epoch:15	Loss:23.341	translation_Loss:23.181	multi_layer_Loss:0.16	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.21	Hits@10:46.66	Best:26.27
2024-12-27 20:02:00,025: End of token training: 4 Epoch: 16 Loss:23.2 MRR:26.21 Best Results: 26.27
2024-12-27 20:02:00,026: Snapshot:4	Epoch:16	Loss:23.2	translation_Loss:23.2	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.21	Hits@10:46.66	Best:26.27
2024-12-27 20:02:00,332: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_6/4model_best.tar'
2024-12-27 20:02:12,617: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3363 | 0.216  | 0.3926 | 0.463  |  0.5626 |
|     1      |  0.25  | 0.153  | 0.283  | 0.3479 |  0.4401 |
|     2      | 0.2311 | 0.1389 | 0.2659 | 0.325  |  0.4078 |
|     3      | 0.2214 | 0.1307 | 0.2533 | 0.315  |  0.3969 |
|     4      | 0.2617 | 0.154  | 0.3122 | 0.3819 |  0.4697 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 20:02:12,618: Final Result:
[+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.337 | 0.2172 | 0.3929 | 0.4625 |  0.5636 |
+------------+-------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3369 | 0.217  | 0.3928 | 0.463  |  0.5634 |
|     1      | 0.2499 | 0.1529 | 0.2833 | 0.3477 |  0.4385 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3368 | 0.2167 | 0.3924 | 0.4639 |  0.5628 |
|     1      | 0.2498 | 0.1529 | 0.2823 | 0.347  |  0.439  |
|     2      | 0.2309 | 0.1383 | 0.2656 | 0.3246 |  0.4072 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3373 | 0.2179 | 0.393  | 0.4641 |  0.5638 |
|     1      | 0.2495 | 0.1523 | 0.2827 | 0.347  |  0.4399 |
|     2      | 0.2309 | 0.1383 | 0.265  | 0.3246 |  0.4076 |
|     3      | 0.2209 | 0.1302 | 0.2528 | 0.315  |  0.3956 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3363 | 0.216  | 0.3926 | 0.463  |  0.5626 |
|     1      |  0.25  | 0.153  | 0.283  | 0.3479 |  0.4401 |
|     2      | 0.2311 | 0.1389 | 0.2659 | 0.325  |  0.4078 |
|     3      | 0.2214 | 0.1307 | 0.2533 | 0.315  |  0.3969 |
|     4      | 0.2617 | 0.154  | 0.3122 | 0.3819 |  0.4697 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 20:02:12,619: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 66.42980217933655  |   0.337   |    0.217     |    0.393     |     0.564     |
|    1     | 168.68804454803467 |   0.284   |    0.178     |    0.326     |     0.487     |
|    2     | 154.46530318260193 |   0.264   |    0.163     |    0.302     |     0.457     |
|    3     | 223.34177947044373 |   0.252   |    0.154     |    0.289     |     0.441     |
|    4     | 102.07843136787415 |   0.254   |    0.154     |    0.293     |     0.445     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 20:02:12,619: Sum_Training_Time:715.003360748291
2024-12-27 20:02:12,619: Every_Training_Time:[66.42980217933655, 168.68804454803467, 154.46530318260193, 223.34177947044373, 102.07843136787415]
2024-12-27 20:02:12,619: Forward transfer: 0.046225 Backward transfer: 2.4999999999990308e-05
2024-12-27 20:02:46,504: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227200216/ENTITYentity_0.001_1024_8', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.001_1024_8', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.001_1024_8', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=8, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 20:02:54,150: Snapshot:0	Epoch:0	Loss:36.581	translation_Loss:36.581	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.12	Hits@10:21.84	Best:9.12
2024-12-27 20:02:58,071: Snapshot:0	Epoch:1	Loss:25.656	translation_Loss:25.656	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.49	Hits@10:42.49	Best:19.49
2024-12-27 20:03:01,999: Snapshot:0	Epoch:2	Loss:15.145	translation_Loss:15.145	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.61	Hits@10:50.84	Best:27.61
2024-12-27 20:03:05,815: Snapshot:0	Epoch:3	Loss:8.4	translation_Loss:8.4	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.87	Hits@10:54.37	Best:30.87
2024-12-27 20:03:09,656: Snapshot:0	Epoch:4	Loss:4.826	translation_Loss:4.826	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.54	Hits@10:55.79	Best:32.54
2024-12-27 20:03:13,459: Snapshot:0	Epoch:5	Loss:3.038	translation_Loss:3.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.22	Hits@10:56.58	Best:33.22
2024-12-27 20:03:17,310: Snapshot:0	Epoch:6	Loss:2.114	translation_Loss:2.114	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.41	Hits@10:56.7	Best:33.41
2024-12-27 20:03:21,116: Snapshot:0	Epoch:7	Loss:1.589	translation_Loss:1.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.38	Hits@10:56.33	Best:33.41
2024-12-27 20:03:24,954: Snapshot:0	Epoch:8	Loss:1.273	translation_Loss:1.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.17	Hits@10:56.18	Best:33.41
2024-12-27 20:03:28,773: Snapshot:0	Epoch:9	Loss:1.063	translation_Loss:1.063	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.03	Hits@10:55.91	Best:33.41
2024-12-27 20:03:32,685: Snapshot:0	Epoch:10	Loss:0.936	translation_Loss:0.936	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.01	Hits@10:55.81	Best:33.41
2024-12-27 20:03:36,935: Early Stopping! Snapshot: 0 Epoch: 11 Best Results: 33.41
2024-12-27 20:03:36,935: Start to training tokens! Snapshot: 0 Epoch: 11 Loss:0.839 MRR:33.0 Best Results: 33.41
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 20:03:36,936: Snapshot:0	Epoch:11	Loss:0.839	translation_Loss:0.839	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.0	Hits@10:55.91	Best:33.41
2024-12-27 20:03:41,331: Snapshot:0	Epoch:12	Loss:28.565	translation_Loss:28.394	multi_layer_Loss:0.17	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.0	Hits@10:55.91	Best:33.41
2024-12-27 20:03:45,334: End of token training: 0 Epoch: 13 Loss:28.404 MRR:33.0 Best Results: 33.41
2024-12-27 20:03:45,334: Snapshot:0	Epoch:13	Loss:28.404	translation_Loss:28.404	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.0	Hits@10:55.91	Best:33.41
2024-12-27 20:03:45,613: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_8/0model_best.tar'
2024-12-27 20:03:46,976: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3371 | 0.2149 | 0.3964 | 0.469  |  0.5682 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:04:11,025: Snapshot:1	Epoch:0	Loss:31.239	translation_Loss:29.134	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.105                                                   	MRR:19.65	Hits@10:35.32	Best:19.65
2024-12-27 20:04:17,725: Snapshot:1	Epoch:1	Loss:9.698	translation_Loss:9.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.576                                                   	MRR:23.32	Hits@10:41.41	Best:23.32
2024-12-27 20:04:24,425: Snapshot:1	Epoch:2	Loss:6.405	translation_Loss:5.892	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.513                                                   	MRR:24.13	Hits@10:42.67	Best:24.13
2024-12-27 20:04:31,464: Snapshot:1	Epoch:3	Loss:5.282	translation_Loss:4.79	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.492                                                   	MRR:24.13	Hits@10:43.06	Best:24.13
2024-12-27 20:04:38,171: Snapshot:1	Epoch:4	Loss:4.731	translation_Loss:4.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.488                                                   	MRR:24.42	Hits@10:43.4	Best:24.42
2024-12-27 20:04:44,837: Snapshot:1	Epoch:5	Loss:4.41	translation_Loss:3.92	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.489                                                   	MRR:24.27	Hits@10:43.55	Best:24.42
2024-12-27 20:04:51,542: Snapshot:1	Epoch:6	Loss:4.215	translation_Loss:3.725	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.49                                                   	MRR:24.52	Hits@10:43.82	Best:24.52
2024-12-27 20:04:58,321: Snapshot:1	Epoch:7	Loss:4.012	translation_Loss:3.523	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.489                                                   	MRR:24.5	Hits@10:43.6	Best:24.52
2024-12-27 20:05:05,106: Snapshot:1	Epoch:8	Loss:3.893	translation_Loss:3.406	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.487                                                   	MRR:24.54	Hits@10:43.95	Best:24.54
2024-12-27 20:05:11,875: Snapshot:1	Epoch:9	Loss:3.793	translation_Loss:3.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.488                                                   	MRR:24.68	Hits@10:44.04	Best:24.68
2024-12-27 20:05:18,571: Snapshot:1	Epoch:10	Loss:3.722	translation_Loss:3.233	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.489                                                   	MRR:24.63	Hits@10:44.08	Best:24.68
2024-12-27 20:05:25,339: Snapshot:1	Epoch:11	Loss:3.634	translation_Loss:3.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.483                                                   	MRR:24.81	Hits@10:44.18	Best:24.81
2024-12-27 20:05:32,113: Snapshot:1	Epoch:12	Loss:3.584	translation_Loss:3.092	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.492                                                   	MRR:24.96	Hits@10:44.16	Best:24.96
2024-12-27 20:05:39,210: Snapshot:1	Epoch:13	Loss:3.52	translation_Loss:3.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.49                                                   	MRR:24.84	Hits@10:43.85	Best:24.96
2024-12-27 20:05:45,848: Snapshot:1	Epoch:14	Loss:3.45	translation_Loss:2.964	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.486                                                   	MRR:24.96	Hits@10:44.22	Best:24.96
2024-12-27 20:05:52,502: Snapshot:1	Epoch:15	Loss:3.47	translation_Loss:2.977	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.493                                                   	MRR:24.89	Hits@10:44.08	Best:24.96
2024-12-27 20:05:59,189: Snapshot:1	Epoch:16	Loss:3.41	translation_Loss:2.919	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.492                                                   	MRR:24.89	Hits@10:44.28	Best:24.96
2024-12-27 20:06:05,857: Early Stopping! Snapshot: 1 Epoch: 17 Best Results: 24.96
2024-12-27 20:06:05,858: Start to training tokens! Snapshot: 1 Epoch: 17 Loss:3.344 MRR:24.92 Best Results: 24.96
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 20:06:05,858: Snapshot:1	Epoch:17	Loss:3.344	translation_Loss:2.86	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.484                                                   	MRR:24.92	Hits@10:44.09	Best:24.96
2024-12-27 20:06:12,514: Snapshot:1	Epoch:18	Loss:46.715	translation_Loss:46.533	multi_layer_Loss:0.182	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.92	Hits@10:44.09	Best:24.96
2024-12-27 20:06:19,176: End of token training: 1 Epoch: 19 Loss:46.494 MRR:24.92 Best Results: 24.96
2024-12-27 20:06:19,176: Snapshot:1	Epoch:19	Loss:46.494	translation_Loss:46.494	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.92	Hits@10:44.09	Best:24.96
2024-12-27 20:06:19,485: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_8/1model_best.tar'
2024-12-27 20:06:23,481: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.337  | 0.2145 | 0.3966 | 0.4691 |  0.568  |
|     1      | 0.2509 | 0.1519 | 0.2864 | 0.3526 |  0.443  |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:06:48,678: Snapshot:2	Epoch:0	Loss:28.495	translation_Loss:25.983	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.512                                                   	MRR:17.26	Hits@10:30.52	Best:17.26
2024-12-27 20:06:56,035: Snapshot:2	Epoch:1	Loss:8.988	translation_Loss:8.084	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.904                                                   	MRR:20.69	Hits@10:36.46	Best:20.69
2024-12-27 20:07:03,399: Snapshot:2	Epoch:2	Loss:6.378	translation_Loss:5.586	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.792                                                   	MRR:21.68	Hits@10:38.11	Best:21.68
2024-12-27 20:07:10,850: Snapshot:2	Epoch:3	Loss:5.551	translation_Loss:4.789	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.761                                                   	MRR:22.03	Hits@10:38.83	Best:22.03
2024-12-27 20:07:18,155: Snapshot:2	Epoch:4	Loss:5.073	translation_Loss:4.327	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.746                                                   	MRR:22.25	Hits@10:39.41	Best:22.25
2024-12-27 20:07:25,939: Snapshot:2	Epoch:5	Loss:4.808	translation_Loss:4.062	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.746                                                   	MRR:22.6	Hits@10:39.79	Best:22.6
2024-12-27 20:07:33,332: Snapshot:2	Epoch:6	Loss:4.576	translation_Loss:3.835	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.741                                                   	MRR:22.62	Hits@10:39.71	Best:22.62
2024-12-27 20:07:40,675: Snapshot:2	Epoch:7	Loss:4.453	translation_Loss:3.707	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.746                                                   	MRR:22.91	Hits@10:40.2	Best:22.91
2024-12-27 20:07:48,051: Snapshot:2	Epoch:8	Loss:4.346	translation_Loss:3.606	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.741                                                   	MRR:23.05	Hits@10:40.36	Best:23.05
2024-12-27 20:07:55,538: Snapshot:2	Epoch:9	Loss:4.25	translation_Loss:3.509	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.74                                                   	MRR:22.98	Hits@10:40.55	Best:23.05
2024-12-27 20:08:02,956: Snapshot:2	Epoch:10	Loss:4.185	translation_Loss:3.441	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.744                                                   	MRR:23.24	Hits@10:40.64	Best:23.24
2024-12-27 20:08:10,259: Snapshot:2	Epoch:11	Loss:4.113	translation_Loss:3.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.739                                                   	MRR:23.02	Hits@10:40.61	Best:23.24
2024-12-27 20:08:17,528: Snapshot:2	Epoch:12	Loss:4.03	translation_Loss:3.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.737                                                   	MRR:23.15	Hits@10:40.66	Best:23.24
2024-12-27 20:08:24,877: Snapshot:2	Epoch:13	Loss:3.984	translation_Loss:3.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.733                                                   	MRR:23.09	Hits@10:40.53	Best:23.24
2024-12-27 20:08:32,287: Snapshot:2	Epoch:14	Loss:3.915	translation_Loss:3.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.734                                                   	MRR:23.26	Hits@10:40.67	Best:23.26
2024-12-27 20:08:40,284: Snapshot:2	Epoch:15	Loss:3.879	translation_Loss:3.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.733                                                   	MRR:23.5	Hits@10:41.13	Best:23.5
2024-12-27 20:08:47,546: Snapshot:2	Epoch:16	Loss:3.878	translation_Loss:3.134	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.744                                                   	MRR:23.29	Hits@10:40.91	Best:23.5
2024-12-27 20:08:54,803: Snapshot:2	Epoch:17	Loss:3.817	translation_Loss:3.087	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.73                                                   	MRR:23.24	Hits@10:40.84	Best:23.5
2024-12-27 20:09:02,198: Snapshot:2	Epoch:18	Loss:3.802	translation_Loss:3.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.731                                                   	MRR:23.26	Hits@10:40.95	Best:23.5
2024-12-27 20:09:09,430: Snapshot:2	Epoch:19	Loss:3.783	translation_Loss:3.052	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.732                                                   	MRR:23.35	Hits@10:40.96	Best:23.5
2024-12-27 20:09:16,848: Early Stopping! Snapshot: 2 Epoch: 20 Best Results: 23.5
2024-12-27 20:09:16,848: Start to training tokens! Snapshot: 2 Epoch: 20 Loss:3.718 MRR:23.35 Best Results: 23.5
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 20:09:16,848: Snapshot:2	Epoch:20	Loss:3.718	translation_Loss:2.996	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.722                                                   	MRR:23.35	Hits@10:40.9	Best:23.5
2024-12-27 20:09:24,199: Snapshot:2	Epoch:21	Loss:47.39	translation_Loss:47.219	multi_layer_Loss:0.171	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.35	Hits@10:40.9	Best:23.5
2024-12-27 20:09:31,525: End of token training: 2 Epoch: 22 Loss:47.249 MRR:23.35 Best Results: 23.5
2024-12-27 20:09:31,525: Snapshot:2	Epoch:22	Loss:47.249	translation_Loss:47.249	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.35	Hits@10:40.9	Best:23.5
2024-12-27 20:09:31,789: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_8/2model_best.tar'
2024-12-27 20:09:38,340: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3369 | 0.2148 | 0.3959 | 0.4687 |  0.5678 |
|     1      | 0.2507 | 0.1516 | 0.287  | 0.3528 |  0.4427 |
|     2      | 0.2337 | 0.1381 | 0.2712 | 0.3314 |  0.415  |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:10:03,662: Snapshot:3	Epoch:0	Loss:25.717	translation_Loss:23.051	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.666                                                   	MRR:17.12	Hits@10:30.7	Best:17.12
2024-12-27 20:10:11,404: Snapshot:3	Epoch:1	Loss:7.647	translation_Loss:6.67	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.977                                                   	MRR:19.94	Hits@10:35.87	Best:19.94
2024-12-27 20:10:18,856: Snapshot:3	Epoch:2	Loss:5.468	translation_Loss:4.623	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.845                                                   	MRR:20.8	Hits@10:37.45	Best:20.8
2024-12-27 20:10:26,353: Snapshot:3	Epoch:3	Loss:4.755	translation_Loss:3.947	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.808                                                   	MRR:21.15	Hits@10:38.14	Best:21.15
2024-12-27 20:10:33,849: Snapshot:3	Epoch:4	Loss:4.379	translation_Loss:3.578	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.801                                                   	MRR:21.62	Hits@10:38.74	Best:21.62
2024-12-27 20:10:41,705: Snapshot:3	Epoch:5	Loss:4.107	translation_Loss:3.325	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.782                                                   	MRR:21.63	Hits@10:38.9	Best:21.63
2024-12-27 20:10:49,209: Snapshot:3	Epoch:6	Loss:3.974	translation_Loss:3.191	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.783                                                   	MRR:21.69	Hits@10:39.01	Best:21.69
2024-12-27 20:10:56,669: Snapshot:3	Epoch:7	Loss:3.862	translation_Loss:3.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.783                                                   	MRR:21.78	Hits@10:39.14	Best:21.78
2024-12-27 20:11:04,072: Snapshot:3	Epoch:8	Loss:3.772	translation_Loss:2.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.783                                                   	MRR:21.73	Hits@10:39.12	Best:21.78
2024-12-27 20:11:11,483: Snapshot:3	Epoch:9	Loss:3.693	translation_Loss:2.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.784                                                   	MRR:21.94	Hits@10:39.43	Best:21.94
2024-12-27 20:11:18,888: Snapshot:3	Epoch:10	Loss:3.625	translation_Loss:2.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.781                                                   	MRR:21.97	Hits@10:39.55	Best:21.97
2024-12-27 20:11:26,406: Snapshot:3	Epoch:11	Loss:3.555	translation_Loss:2.777	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.778                                                   	MRR:21.96	Hits@10:39.51	Best:21.97
2024-12-27 20:11:33,809: Snapshot:3	Epoch:12	Loss:3.54	translation_Loss:2.753	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.787                                                   	MRR:22.07	Hits@10:39.54	Best:22.07
2024-12-27 20:11:41,249: Snapshot:3	Epoch:13	Loss:3.485	translation_Loss:2.71	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.774                                                   	MRR:22.18	Hits@10:39.94	Best:22.18
2024-12-27 20:11:48,648: Snapshot:3	Epoch:14	Loss:3.428	translation_Loss:2.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.777                                                   	MRR:22.17	Hits@10:39.81	Best:22.18
2024-12-27 20:11:56,131: Snapshot:3	Epoch:15	Loss:3.408	translation_Loss:2.63	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.778                                                   	MRR:22.24	Hits@10:40.02	Best:22.24
2024-12-27 20:12:04,052: Snapshot:3	Epoch:16	Loss:3.361	translation_Loss:2.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.772                                                   	MRR:22.4	Hits@10:40.11	Best:22.4
2024-12-27 20:12:11,429: Snapshot:3	Epoch:17	Loss:3.324	translation_Loss:2.544	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.781                                                   	MRR:22.27	Hits@10:40.16	Best:22.4
2024-12-27 20:12:18,913: Snapshot:3	Epoch:18	Loss:3.317	translation_Loss:2.538	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.78                                                   	MRR:22.32	Hits@10:40.26	Best:22.4
2024-12-27 20:12:26,378: Snapshot:3	Epoch:19	Loss:3.273	translation_Loss:2.502	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.771                                                   	MRR:22.34	Hits@10:40.11	Best:22.4
2024-12-27 20:12:33,740: Snapshot:3	Epoch:20	Loss:3.251	translation_Loss:2.483	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.768                                                   	MRR:22.19	Hits@10:40.13	Best:22.4
2024-12-27 20:12:41,192: Early Stopping! Snapshot: 3 Epoch: 21 Best Results: 22.4
2024-12-27 20:12:41,193: Start to training tokens! Snapshot: 3 Epoch: 21 Loss:3.235 MRR:22.4 Best Results: 22.4
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 20:12:41,193: Snapshot:3	Epoch:21	Loss:3.235	translation_Loss:2.462	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.773                                                   	MRR:22.4	Hits@10:40.3	Best:22.4
2024-12-27 20:12:48,632: Snapshot:3	Epoch:22	Loss:42.448	translation_Loss:42.28	multi_layer_Loss:0.169	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.4	Hits@10:40.3	Best:22.4
2024-12-27 20:12:56,040: End of token training: 3 Epoch: 23 Loss:42.322 MRR:22.4 Best Results: 22.4
2024-12-27 20:12:56,040: Snapshot:3	Epoch:23	Loss:42.322	translation_Loss:42.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.4	Hits@10:40.3	Best:22.4
2024-12-27 20:12:56,301: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_8/3model_best.tar'
2024-12-27 20:13:06,253: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3372 | 0.2154 | 0.3957 | 0.469  |  0.568  |
|     1      | 0.2515 | 0.1528 | 0.2873 | 0.3536 |  0.443  |
|     2      | 0.2336 | 0.1376 | 0.271  | 0.331  |  0.4162 |
|     3      | 0.2239 | 0.1313 | 0.2597 | 0.3195 |  0.399  |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:13:25,720: Snapshot:4	Epoch:0	Loss:19.422	translation_Loss:17.216	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.206                                                   	MRR:19.72	Hits@10:38.06	Best:19.72
2024-12-27 20:13:31,083: Snapshot:4	Epoch:1	Loss:4.688	translation_Loss:4.043	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.646                                                   	MRR:24.26	Hits@10:43.39	Best:24.26
2024-12-27 20:13:36,406: Snapshot:4	Epoch:2	Loss:2.773	translation_Loss:2.291	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.483                                                   	MRR:25.06	Hits@10:44.72	Best:25.06
2024-12-27 20:13:41,746: Snapshot:4	Epoch:3	Loss:2.212	translation_Loss:1.782	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.43                                                   	MRR:25.65	Hits@10:45.62	Best:25.65
2024-12-27 20:13:47,305: Snapshot:4	Epoch:4	Loss:1.976	translation_Loss:1.568	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.408                                                   	MRR:25.73	Hits@10:46.09	Best:25.73
2024-12-27 20:13:52,610: Snapshot:4	Epoch:5	Loss:1.859	translation_Loss:1.456	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.403                                                   	MRR:25.76	Hits@10:45.99	Best:25.76
2024-12-27 20:13:57,941: Snapshot:4	Epoch:6	Loss:1.79	translation_Loss:1.387	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.403                                                   	MRR:26.03	Hits@10:46.28	Best:26.03
2024-12-27 20:14:03,334: Snapshot:4	Epoch:7	Loss:1.736	translation_Loss:1.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.405                                                   	MRR:25.95	Hits@10:46.28	Best:26.03
2024-12-27 20:14:08,652: Snapshot:4	Epoch:8	Loss:1.677	translation_Loss:1.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.403                                                   	MRR:26.0	Hits@10:46.45	Best:26.03
2024-12-27 20:14:13,957: Snapshot:4	Epoch:9	Loss:1.631	translation_Loss:1.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.408                                                   	MRR:26.04	Hits@10:46.65	Best:26.04
2024-12-27 20:14:19,279: Snapshot:4	Epoch:10	Loss:1.601	translation_Loss:1.197	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.405                                                   	MRR:26.2	Hits@10:46.84	Best:26.2
2024-12-27 20:14:24,574: Snapshot:4	Epoch:11	Loss:1.586	translation_Loss:1.175	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.411                                                   	MRR:26.17	Hits@10:46.78	Best:26.2
2024-12-27 20:14:29,880: Snapshot:4	Epoch:12	Loss:1.54	translation_Loss:1.132	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.408                                                   	MRR:26.34	Hits@10:47.13	Best:26.34
2024-12-27 20:14:35,188: Snapshot:4	Epoch:13	Loss:1.512	translation_Loss:1.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.401                                                   	MRR:26.14	Hits@10:46.82	Best:26.34
2024-12-27 20:14:40,536: Snapshot:4	Epoch:14	Loss:1.491	translation_Loss:1.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.403                                                   	MRR:25.83	Hits@10:46.76	Best:26.34
2024-12-27 20:14:45,930: Snapshot:4	Epoch:15	Loss:1.501	translation_Loss:1.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.406                                                   	MRR:26.03	Hits@10:47.08	Best:26.34
2024-12-27 20:14:51,273: Snapshot:4	Epoch:16	Loss:1.473	translation_Loss:1.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.403                                                   	MRR:26.48	Hits@10:47.29	Best:26.48
2024-12-27 20:14:56,612: Snapshot:4	Epoch:17	Loss:1.445	translation_Loss:1.045	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.4                                                   	MRR:26.36	Hits@10:47.45	Best:26.48
2024-12-27 20:15:01,966: Snapshot:4	Epoch:18	Loss:1.43	translation_Loss:1.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.4                                                   	MRR:26.41	Hits@10:47.45	Best:26.48
2024-12-27 20:15:07,423: Snapshot:4	Epoch:19	Loss:1.439	translation_Loss:1.035	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.404                                                   	MRR:26.57	Hits@10:47.37	Best:26.57
2024-12-27 20:15:12,694: Snapshot:4	Epoch:20	Loss:1.43	translation_Loss:1.029	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.401                                                   	MRR:26.54	Hits@10:47.84	Best:26.57
2024-12-27 20:15:17,999: Snapshot:4	Epoch:21	Loss:1.414	translation_Loss:1.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.403                                                   	MRR:26.43	Hits@10:47.63	Best:26.57
2024-12-27 20:15:23,722: Snapshot:4	Epoch:22	Loss:1.39	translation_Loss:0.992	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.398                                                   	MRR:26.57	Hits@10:47.61	Best:26.57
2024-12-27 20:15:29,068: Snapshot:4	Epoch:23	Loss:1.381	translation_Loss:0.983	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.398                                                   	MRR:26.86	Hits@10:47.87	Best:26.86
2024-12-27 20:15:34,463: Snapshot:4	Epoch:24	Loss:1.393	translation_Loss:0.988	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.405                                                   	MRR:26.78	Hits@10:47.84	Best:26.86
2024-12-27 20:15:39,763: Snapshot:4	Epoch:25	Loss:1.377	translation_Loss:0.976	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.401                                                   	MRR:26.68	Hits@10:47.62	Best:26.86
2024-12-27 20:15:45,071: Snapshot:4	Epoch:26	Loss:1.347	translation_Loss:0.946	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.402                                                   	MRR:26.62	Hits@10:47.76	Best:26.86
2024-12-27 20:15:50,396: Snapshot:4	Epoch:27	Loss:1.357	translation_Loss:0.957	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.401                                                   	MRR:26.67	Hits@10:47.75	Best:26.86
2024-12-27 20:15:55,683: Early Stopping! Snapshot: 4 Epoch: 28 Best Results: 26.86
2024-12-27 20:15:55,683: Start to training tokens! Snapshot: 4 Epoch: 28 Loss:1.349 MRR:26.8 Best Results: 26.86
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-27 20:15:55,683: Snapshot:4	Epoch:28	Loss:1.349	translation_Loss:0.952	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.396                                                   	MRR:26.8	Hits@10:47.98	Best:26.86
2024-12-27 20:16:01,003: Snapshot:4	Epoch:29	Loss:23.367	translation_Loss:23.194	multi_layer_Loss:0.174	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.8	Hits@10:47.98	Best:26.86
2024-12-27 20:16:06,318: End of token training: 4 Epoch: 30 Loss:23.22 MRR:26.8 Best Results: 26.86
2024-12-27 20:16:06,319: Snapshot:4	Epoch:30	Loss:23.22	translation_Loss:23.22	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.8	Hits@10:47.98	Best:26.86
2024-12-27 20:16:06,566: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_8/4model_best.tar'
2024-12-27 20:16:18,553: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3368 | 0.2146 | 0.3953 | 0.4682 |  0.5682 |
|     1      | 0.2516 | 0.1528 | 0.2871 | 0.3533 |  0.4426 |
|     2      | 0.2344 | 0.1388 | 0.2721 | 0.331  |  0.4168 |
|     3      | 0.2245 | 0.1319 | 0.2599 | 0.3198 |  0.3999 |
|     4      | 0.2689 | 0.1578 | 0.3239 | 0.3948 |  0.4806 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 20:16:18,555: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3371 | 0.2149 | 0.3964 | 0.469  |  0.5682 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.337  | 0.2145 | 0.3966 | 0.4691 |  0.568  |
|     1      | 0.2509 | 0.1519 | 0.2864 | 0.3526 |  0.443  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3369 | 0.2148 | 0.3959 | 0.4687 |  0.5678 |
|     1      | 0.2507 | 0.1516 | 0.287  | 0.3528 |  0.4427 |
|     2      | 0.2337 | 0.1381 | 0.2712 | 0.3314 |  0.415  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3372 | 0.2154 | 0.3957 | 0.469  |  0.568  |
|     1      | 0.2515 | 0.1528 | 0.2873 | 0.3536 |  0.443  |
|     2      | 0.2336 | 0.1376 | 0.271  | 0.331  |  0.4162 |
|     3      | 0.2239 | 0.1313 | 0.2597 | 0.3195 |  0.399  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3368 | 0.2146 | 0.3953 | 0.4682 |  0.5682 |
|     1      | 0.2516 | 0.1528 | 0.2871 | 0.3533 |  0.4426 |
|     2      | 0.2344 | 0.1388 | 0.2721 | 0.331  |  0.4168 |
|     3      | 0.2245 | 0.1319 | 0.2599 | 0.3198 |  0.3999 |
|     4      | 0.2689 | 0.1578 | 0.3239 | 0.3948 |  0.4806 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 20:16:18,556: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 58.82961392402649  |   0.337   |    0.215     |    0.396     |     0.568     |
|    1     | 149.96446990966797 |   0.285   |    0.176     |     0.33     |     0.492     |
|    2     | 185.3198676109314  |   0.265   |    0.162     |    0.307     |     0.462     |
|    3     |  194.657546043396  |   0.254   |    0.154     |    0.294     |     0.446     |
|    4     | 177.59451246261597 |   0.257   |    0.155     |    0.299     |     0.451     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 20:16:18,556: Sum_Training_Time:766.3660099506378
2024-12-27 20:16:18,556: Every_Training_Time:[58.82961392402649, 149.96446990966797, 185.3198676109314, 194.657546043396, 177.59451246261597]
2024-12-27 20:16:18,556: Forward transfer: 0.048925 Backward transfer: 0.0004249999999999948
2024-12-27 20:16:51,814: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227201622/ENTITYentity_0.001_1024_10', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='entity_0.001_1024_10', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITYentity_0.001_1024_10', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000, token_num=10, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 20:16:59,492: Snapshot:0	Epoch:0	Loss:36.581	translation_Loss:36.581	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.12	Hits@10:21.84	Best:9.12
2024-12-27 20:17:03,288: Snapshot:0	Epoch:1	Loss:25.656	translation_Loss:25.656	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.49	Hits@10:42.48	Best:19.49
2024-12-27 20:17:07,113: Snapshot:0	Epoch:2	Loss:15.145	translation_Loss:15.145	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.6	Hits@10:50.87	Best:27.6
2024-12-27 20:17:10,923: Snapshot:0	Epoch:3	Loss:8.399	translation_Loss:8.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.91	Hits@10:54.33	Best:30.91
2024-12-27 20:17:14,762: Snapshot:0	Epoch:4	Loss:4.825	translation_Loss:4.825	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.54	Hits@10:55.91	Best:32.54
2024-12-27 20:17:18,647: Snapshot:0	Epoch:5	Loss:3.038	translation_Loss:3.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.17	Hits@10:56.66	Best:33.17
2024-12-27 20:17:22,457: Snapshot:0	Epoch:6	Loss:2.113	translation_Loss:2.113	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.34	Hits@10:56.69	Best:33.34
2024-12-27 20:17:26,304: Snapshot:0	Epoch:7	Loss:1.59	translation_Loss:1.59	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.18	Hits@10:56.3	Best:33.34
2024-12-27 20:17:30,110: Snapshot:0	Epoch:8	Loss:1.276	translation_Loss:1.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.17	Hits@10:56.39	Best:33.34
2024-12-27 20:17:33,891: Snapshot:0	Epoch:9	Loss:1.064	translation_Loss:1.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.01	Hits@10:56.1	Best:33.34
2024-12-27 20:17:37,753: Snapshot:0	Epoch:10	Loss:0.94	translation_Loss:0.94	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.96	Hits@10:55.9	Best:33.34
2024-12-27 20:17:42,014: Early Stopping! Snapshot: 0 Epoch: 11 Best Results: 33.34
2024-12-27 20:17:42,014: Start to training tokens! Snapshot: 0 Epoch: 11 Loss:0.838 MRR:32.96 Best Results: 33.34
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 20:17:42,015: Snapshot:0	Epoch:11	Loss:0.838	translation_Loss:0.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.96	Hits@10:55.81	Best:33.34
2024-12-27 20:17:46,409: Snapshot:0	Epoch:12	Loss:28.559	translation_Loss:28.378	multi_layer_Loss:0.181	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.96	Hits@10:55.81	Best:33.34
2024-12-27 20:17:50,325: End of token training: 0 Epoch: 13 Loss:28.389 MRR:32.96 Best Results: 33.34
2024-12-27 20:17:50,325: Snapshot:0	Epoch:13	Loss:28.389	translation_Loss:28.389	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:32.96	Hits@10:55.81	Best:33.34
2024-12-27 20:17:50,596: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_10/0model_best.tar'
2024-12-27 20:17:51,963: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3362 | 0.2134 | 0.3958 | 0.4689 |  0.5687 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:18:15,810: Snapshot:1	Epoch:0	Loss:31.539	translation_Loss:29.147	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.392                                                   	MRR:19.63	Hits@10:35.16	Best:19.63
2024-12-27 20:18:22,579: Snapshot:1	Epoch:1	Loss:9.653	translation_Loss:9.126	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.527                                                   	MRR:23.15	Hits@10:41.51	Best:23.15
2024-12-27 20:18:29,241: Snapshot:1	Epoch:2	Loss:6.368	translation_Loss:5.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.475                                                   	MRR:23.96	Hits@10:42.67	Best:23.96
2024-12-27 20:18:36,219: Snapshot:1	Epoch:3	Loss:5.263	translation_Loss:4.8	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.463                                                   	MRR:24.04	Hits@10:43.1	Best:24.04
2024-12-27 20:18:42,886: Snapshot:1	Epoch:4	Loss:4.704	translation_Loss:4.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.461                                                   	MRR:24.42	Hits@10:43.41	Best:24.42
2024-12-27 20:18:49,587: Snapshot:1	Epoch:5	Loss:4.377	translation_Loss:3.917	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.46                                                   	MRR:24.41	Hits@10:43.68	Best:24.42
2024-12-27 20:18:56,292: Snapshot:1	Epoch:6	Loss:4.178	translation_Loss:3.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.463                                                   	MRR:24.51	Hits@10:44.05	Best:24.51
2024-12-27 20:19:03,032: Snapshot:1	Epoch:7	Loss:3.991	translation_Loss:3.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.466                                                   	MRR:24.39	Hits@10:43.67	Best:24.51
2024-12-27 20:19:09,700: Snapshot:1	Epoch:8	Loss:3.87	translation_Loss:3.405	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.465                                                   	MRR:24.52	Hits@10:43.73	Best:24.52
2024-12-27 20:19:16,338: Snapshot:1	Epoch:9	Loss:3.777	translation_Loss:3.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.467                                                   	MRR:24.71	Hits@10:43.78	Best:24.71
2024-12-27 20:19:22,974: Snapshot:1	Epoch:10	Loss:3.701	translation_Loss:3.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.464                                                   	MRR:24.66	Hits@10:43.87	Best:24.71
2024-12-27 20:19:29,658: Snapshot:1	Epoch:11	Loss:3.621	translation_Loss:3.157	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.465                                                   	MRR:24.73	Hits@10:44.02	Best:24.73
2024-12-27 20:19:36,319: Snapshot:1	Epoch:12	Loss:3.567	translation_Loss:3.097	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.47                                                   	MRR:24.75	Hits@10:43.91	Best:24.75
2024-12-27 20:19:43,401: Snapshot:1	Epoch:13	Loss:3.499	translation_Loss:3.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.469                                                   	MRR:24.72	Hits@10:43.94	Best:24.75
2024-12-27 20:19:50,052: Snapshot:1	Epoch:14	Loss:3.437	translation_Loss:2.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.467                                                   	MRR:24.81	Hits@10:44.1	Best:24.81
2024-12-27 20:19:56,769: Snapshot:1	Epoch:15	Loss:3.447	translation_Loss:2.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.473                                                   	MRR:24.81	Hits@10:43.98	Best:24.81
2024-12-27 20:20:03,654: Snapshot:1	Epoch:16	Loss:3.397	translation_Loss:2.925	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.472                                                   	MRR:24.81	Hits@10:43.94	Best:24.81
2024-12-27 20:20:10,685: Snapshot:1	Epoch:17	Loss:3.333	translation_Loss:2.866	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.468                                                   	MRR:24.81	Hits@10:44.23	Best:24.81
2024-12-27 20:20:17,297: Snapshot:1	Epoch:18	Loss:3.321	translation_Loss:2.849	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.473                                                   	MRR:24.71	Hits@10:43.99	Best:24.81
2024-12-27 20:20:23,996: Snapshot:1	Epoch:19	Loss:3.285	translation_Loss:2.818	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.468                                                   	MRR:24.85	Hits@10:44.3	Best:24.85
2024-12-27 20:20:30,618: Snapshot:1	Epoch:20	Loss:3.266	translation_Loss:2.792	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.474                                                   	MRR:24.81	Hits@10:44.18	Best:24.85
2024-12-27 20:20:37,257: Snapshot:1	Epoch:21	Loss:3.236	translation_Loss:2.766	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.47                                                   	MRR:24.83	Hits@10:44.32	Best:24.85
2024-12-27 20:20:43,901: Snapshot:1	Epoch:22	Loss:3.182	translation_Loss:2.718	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.464                                                   	MRR:24.83	Hits@10:44.31	Best:24.85
2024-12-27 20:20:50,608: Snapshot:1	Epoch:23	Loss:3.216	translation_Loss:2.745	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.471                                                   	MRR:24.95	Hits@10:44.36	Best:24.95
2024-12-27 20:20:57,766: Snapshot:1	Epoch:24	Loss:3.17	translation_Loss:2.701	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.469                                                   	MRR:24.95	Hits@10:44.29	Best:24.95
2024-12-27 20:21:04,436: Snapshot:1	Epoch:25	Loss:3.193	translation_Loss:2.722	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.471                                                   	MRR:24.97	Hits@10:44.49	Best:24.97
2024-12-27 20:21:11,098: Snapshot:1	Epoch:26	Loss:3.147	translation_Loss:2.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.47                                                   	MRR:25.02	Hits@10:44.34	Best:25.02
2024-12-27 20:21:17,770: Snapshot:1	Epoch:27	Loss:3.124	translation_Loss:2.656	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.468                                                   	MRR:25.08	Hits@10:44.56	Best:25.08
2024-12-27 20:21:24,532: Snapshot:1	Epoch:28	Loss:3.103	translation_Loss:2.634	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.469                                                   	MRR:25.02	Hits@10:44.64	Best:25.08
2024-12-27 20:21:31,251: Snapshot:1	Epoch:29	Loss:3.09	translation_Loss:2.622	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.468                                                   	MRR:24.97	Hits@10:44.42	Best:25.08
2024-12-27 20:21:37,952: Snapshot:1	Epoch:30	Loss:3.064	translation_Loss:2.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.466                                                   	MRR:25.0	Hits@10:44.4	Best:25.08
2024-12-27 20:21:44,568: Snapshot:1	Epoch:31	Loss:3.097	translation_Loss:2.629	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.467                                                   	MRR:24.94	Hits@10:44.39	Best:25.08
2024-12-27 20:21:51,207: Snapshot:1	Epoch:32	Loss:3.077	translation_Loss:2.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.468                                                   	MRR:25.09	Hits@10:44.46	Best:25.09
2024-12-27 20:21:57,914: Snapshot:1	Epoch:33	Loss:3.053	translation_Loss:2.586	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.467                                                   	MRR:24.93	Hits@10:44.45	Best:25.09
2024-12-27 20:22:04,974: Snapshot:1	Epoch:34	Loss:3.022	translation_Loss:2.558	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.465                                                   	MRR:25.02	Hits@10:44.66	Best:25.09
2024-12-27 20:22:11,622: Snapshot:1	Epoch:35	Loss:3.014	translation_Loss:2.552	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.462                                                   	MRR:25.19	Hits@10:44.65	Best:25.19
2024-12-27 20:22:18,280: Snapshot:1	Epoch:36	Loss:3.004	translation_Loss:2.543	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.461                                                   	MRR:25.08	Hits@10:44.63	Best:25.19
2024-12-27 20:22:24,901: Snapshot:1	Epoch:37	Loss:2.984	translation_Loss:2.524	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.459                                                   	MRR:25.0	Hits@10:44.81	Best:25.19
2024-12-27 20:22:31,559: Snapshot:1	Epoch:38	Loss:2.982	translation_Loss:2.52	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.462                                                   	MRR:25.06	Hits@10:44.73	Best:25.19
2024-12-27 20:22:38,180: Snapshot:1	Epoch:39	Loss:2.982	translation_Loss:2.518	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.464                                                   	MRR:25.13	Hits@10:44.74	Best:25.19
2024-12-27 20:22:44,832: Early Stopping! Snapshot: 1 Epoch: 40 Best Results: 25.19
2024-12-27 20:22:44,832: Start to training tokens! Snapshot: 1 Epoch: 40 Loss:2.97 MRR:25.13 Best Results: 25.19
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 20:22:44,833: Snapshot:1	Epoch:40	Loss:2.97	translation_Loss:2.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.465                                                   	MRR:25.13	Hits@10:44.66	Best:25.19
2024-12-27 20:22:51,500: Snapshot:1	Epoch:41	Loss:46.6	translation_Loss:46.412	multi_layer_Loss:0.188	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.13	Hits@10:44.66	Best:25.19
2024-12-27 20:22:58,249: End of token training: 1 Epoch: 42 Loss:46.497 MRR:25.13 Best Results: 25.19
2024-12-27 20:22:58,249: Snapshot:1	Epoch:42	Loss:46.497	translation_Loss:46.497	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.13	Hits@10:44.66	Best:25.19
2024-12-27 20:22:58,498: => loading checkpoint './checkpoint/ENTITYentity_0.001_1024_10/1model_best.tar'
2024-12-27 20:23:02,279: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3365 | 0.2143 | 0.3957 | 0.4684 |  0.5685 |
|     1      | 0.2536 | 0.1551 | 0.2891 | 0.3536 |  0.4453 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:23:28,096: Snapshot:2	Epoch:0	Loss:28.62	translation_Loss:26.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.579                                                   	MRR:17.24	Hits@10:30.28	Best:17.24
2024-12-27 20:23:35,476: Snapshot:2	Epoch:1	Loss:8.797	translation_Loss:8.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.708                                                   	MRR:20.48	Hits@10:35.96	Best:20.48
2024-12-27 20:23:42,810: Snapshot:2	Epoch:2	Loss:6.22	translation_Loss:5.592	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.628                                                   	MRR:21.35	Hits@10:37.85	Best:21.35
2024-12-27 20:23:50,150: Snapshot:2	Epoch:3	Loss:5.345	translation_Loss:4.732	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.613                                                   	MRR:22.01	Hits@10:38.97	Best:22.01
2024-12-27 20:23:57,508: Snapshot:2	Epoch:4	Loss:4.876	translation_Loss:4.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.608                                                   	MRR:22.2	Hits@10:39.14	Best:22.2
2024-12-27 20:24:04,821: Snapshot:2	Epoch:5	Loss:4.618	translation_Loss:4.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.604                                                   	MRR:22.43	Hits@10:39.54	Best:22.43
2024-12-27 20:24:12,168: Snapshot:2	Epoch:6	Loss:4.458	translation_Loss:3.854	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.603                                                   	MRR:22.56	Hits@10:39.61	Best:22.56
2024-12-27 20:24:19,520: Snapshot:2	Epoch:7	Loss:4.326	translation_Loss:3.716	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.61                                                   	MRR:22.67	Hits@10:39.81	Best:22.67
2024-12-27 20:24:26,862: Snapshot:2	Epoch:8	Loss:4.209	translation_Loss:3.6	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.609                                                   	MRR:22.67	Hits@10:39.94	Best:22.67
2024-12-27 20:24:34,206: Snapshot:2	Epoch:9	Loss:4.107	translation_Loss:3.501	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.606                                                   	MRR:22.78	Hits@10:40.05	Best:22.78
2024-12-27 20:24:41,484: Snapshot:2	Epoch:10	Loss:4.013	translation_Loss:3.407	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.606                                                   	MRR:22.83	Hits@10:40.19	Best:22.83
2024-12-27 20:24:48,804: Snapshot:2	Epoch:11	Loss:3.925	translation_Loss:3.317	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.608                                                   	MRR:22.97	Hits@10:40.26	Best:22.97
2024-12-27 20:24:56,139: Snapshot:2	Epoch:12	Loss:3.886	translation_Loss:3.279	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.607                                                   	MRR:22.96	Hits@10:40.37	Best:22.97
2024-12-27 20:25:03,505: Snapshot:2	Epoch:13	Loss:3.843	translation_Loss:3.24	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.603                                                   	MRR:23.06	Hits@10:40.56	Best:23.06
2024-12-27 20:25:10,882: Snapshot:2	Epoch:14	Loss:3.8	translation_Loss:3.191	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.608                                                   	MRR:23.06	Hits@10:40.55	Best:23.06
2024-12-27 20:25:18,211: Snapshot:2	Epoch:15	Loss:3.744	translation_Loss:3.139	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.605                                                   	MRR:23.08	Hits@10:40.57	Best:23.08
2024-12-27 20:25:25,618: Snapshot:2	Epoch:16	Loss:3.719	translation_Loss:3.108	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.611                                                   	MRR:23.25	Hits@10:40.69	Best:23.25
2024-12-27 20:25:32,975: Snapshot:2	Epoch:17	Loss:3.68	translation_Loss:3.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.604                                                   	MRR:23.24	Hits@10:40.89	Best:23.25
2024-12-27 20:25:40,284: Snapshot:2	Epoch:18	Loss:3.66	translation_Loss:3.05	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.61                                                   	MRR:23.33	Hits@10:40.87	Best:23.33
2024-12-27 20:25:47,565: Snapshot:2	Epoch:19	Loss:3.605	translation_Loss:2.997	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.608                                                   	MRR:23.28	Hits@10:40.96	Best:23.33
2024-12-27 20:25:54,834: Snapshot:2	Epoch:20	Loss:3.59	translation_Loss:2.985	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.605                                                   	MRR:23.28	Hits@10:40.89	Best:23.33
2024-12-27 20:26:02,116: Snapshot:2	Epoch:21	Loss:3.557	translation_Loss:2.953	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.604                                                   	MRR:23.2	Hits@10:41.05	Best:23.33
2024-12-27 20:26:09,399: Snapshot:2	Epoch:22	Loss:3.539	translation_Loss:2.937	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.602                                                   	MRR:23.37	Hits@10:41.08	Best:23.37
2024-12-27 20:26:16,656: Snapshot:2	Epoch:23	Loss:3.53	translation_Loss:2.925	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.605                                                   	MRR:23.29	Hits@10:41.07	Best:23.37
