2024-12-27 02:48:05,359: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227024732/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=50000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 02:48:14,583: Snapshot:0	Epoch:0	Loss:24.869	translation_Loss:24.869	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.15	Hits@10:15.62	Best:7.15
2024-12-27 02:48:20,618: Snapshot:0	Epoch:1	Loss:16.859	translation_Loss:16.859	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.6	Hits@10:25.86	Best:11.6
2024-12-27 02:48:26,888: Snapshot:0	Epoch:2	Loss:11.571	translation_Loss:11.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.35	Hits@10:32.19	Best:15.35
2024-12-27 02:48:32,987: Snapshot:0	Epoch:3	Loss:7.838	translation_Loss:7.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.55	Hits@10:35.92	Best:18.55
2024-12-27 02:48:38,985: Snapshot:0	Epoch:4	Loss:5.22	translation_Loss:5.22	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.0	Hits@10:37.89	Best:21.0
2024-12-27 02:48:44,944: Snapshot:0	Epoch:5	Loss:3.483	translation_Loss:3.483	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.67	Hits@10:39.21	Best:22.67
2024-12-27 02:48:50,830: Snapshot:0	Epoch:6	Loss:2.322	translation_Loss:2.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.76	Hits@10:39.79	Best:23.76
2024-12-27 02:48:57,304: Snapshot:0	Epoch:7	Loss:1.61	translation_Loss:1.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.37	Hits@10:40.0	Best:24.37
2024-12-27 02:49:03,237: Snapshot:0	Epoch:8	Loss:1.154	translation_Loss:1.154	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.6	Hits@10:40.29	Best:24.6
2024-12-27 02:49:09,224: Snapshot:0	Epoch:9	Loss:0.879	translation_Loss:0.879	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.65	Hits@10:40.17	Best:24.65
2024-12-27 02:49:15,146: Snapshot:0	Epoch:10	Loss:0.704	translation_Loss:0.704	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.78	Hits@10:40.29	Best:24.78
2024-12-27 02:49:21,059: Snapshot:0	Epoch:11	Loss:0.579	translation_Loss:0.579	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.82	Hits@10:40.42	Best:24.82
2024-12-27 02:49:26,975: Snapshot:0	Epoch:12	Loss:0.498	translation_Loss:0.498	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.89	Hits@10:40.33	Best:24.89
2024-12-27 02:49:33,492: Snapshot:0	Epoch:13	Loss:0.442	translation_Loss:0.442	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.98	Hits@10:40.43	Best:24.98
2024-12-27 02:49:39,352: Snapshot:0	Epoch:14	Loss:0.403	translation_Loss:0.403	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.88	Hits@10:40.4	Best:24.98
2024-12-27 02:49:45,223: Snapshot:0	Epoch:15	Loss:0.362	translation_Loss:0.362	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.78	Hits@10:40.25	Best:24.98
2024-12-27 02:49:51,066: Early Stopping! Snapshot: 0 Epoch: 16 Best Results: 24.98
2024-12-27 02:49:51,066: Start to training tokens! Snapshot: 0 Epoch: 16 Loss:0.331 MRR:24.73 Best Results: 24.98
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 02:49:51,067: Snapshot:0	Epoch:16	Loss:0.331	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.73	Hits@10:40.38	Best:24.98
2024-12-27 02:49:57,624: Snapshot:0	Epoch:17	Loss:33.895	translation_Loss:18.335	multi_layer_Loss:15.559	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.73	Hits@10:40.38	Best:24.98
2024-12-27 02:50:04,060: End of token training: 0 Epoch: 18 Loss:18.441 MRR:24.73 Best Results: 24.98
2024-12-27 02:50:04,061: Snapshot:0	Epoch:18	Loss:18.441	translation_Loss:18.333	multi_layer_Loss:0.107	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.73	Hits@10:40.38	Best:24.98
2024-12-27 02:50:04,319: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2024-12-27 02:50:06,543: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2409 | 0.1559 | 0.2821 | 0.3316 |  0.3948 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 02:50:29,842: Snapshot:1	Epoch:0	Loss:13.191	translation_Loss:11.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.004                                                   	MRR:18.84	Hits@10:31.7	Best:18.84
2024-12-27 02:50:36,248: Snapshot:1	Epoch:1	Loss:10.767	translation_Loss:9.102	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.666                                                   	MRR:19.67	Hits@10:32.81	Best:19.67
2024-12-27 02:50:42,653: Snapshot:1	Epoch:2	Loss:9.781	translation_Loss:8.139	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.642                                                   	MRR:20.04	Hits@10:33.29	Best:20.04
2024-12-27 02:50:49,100: Snapshot:1	Epoch:3	Loss:9.382	translation_Loss:7.774	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.608                                                   	MRR:20.24	Hits@10:33.58	Best:20.24
2024-12-27 02:50:55,532: Snapshot:1	Epoch:4	Loss:9.218	translation_Loss:7.631	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.587                                                   	MRR:20.24	Hits@10:33.64	Best:20.24
2024-12-27 02:51:01,889: Snapshot:1	Epoch:5	Loss:9.128	translation_Loss:7.551	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.577                                                   	MRR:20.32	Hits@10:33.69	Best:20.32
2024-12-27 02:51:08,234: Snapshot:1	Epoch:6	Loss:9.104	translation_Loss:7.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.579                                                   	MRR:20.27	Hits@10:33.73	Best:20.32
2024-12-27 02:51:14,591: Snapshot:1	Epoch:7	Loss:9.046	translation_Loss:7.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.573                                                   	MRR:20.38	Hits@10:33.7	Best:20.38
2024-12-27 02:51:21,044: Snapshot:1	Epoch:8	Loss:9.039	translation_Loss:7.463	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.577                                                   	MRR:20.31	Hits@10:33.71	Best:20.38
2024-12-27 02:51:27,464: Snapshot:1	Epoch:9	Loss:9.025	translation_Loss:7.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.572                                                   	MRR:20.33	Hits@10:33.62	Best:20.38
2024-12-27 02:51:33,826: Early Stopping! Snapshot: 1 Epoch: 10 Best Results: 20.38
2024-12-27 02:51:33,826: Start to training tokens! Snapshot: 1 Epoch: 10 Loss:9.014 MRR:20.27 Best Results: 20.38
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 02:51:33,827: Snapshot:1	Epoch:10	Loss:9.014	translation_Loss:7.445	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.569                                                   	MRR:20.27	Hits@10:33.65	Best:20.38
2024-12-27 02:51:40,292: Snapshot:1	Epoch:11	Loss:37.652	translation_Loss:22.624	multi_layer_Loss:15.028	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.27	Hits@10:33.65	Best:20.38
2024-12-27 02:51:46,608: End of token training: 1 Epoch: 12 Loss:22.724 MRR:20.27 Best Results: 20.38
2024-12-27 02:51:46,609: Snapshot:1	Epoch:12	Loss:22.724	translation_Loss:22.618	multi_layer_Loss:0.106	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.27	Hits@10:33.65	Best:20.38
2024-12-27 02:51:46,943: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2024-12-27 02:51:52,555: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2446 |  0.16  | 0.285  | 0.3343 |  0.3988 |
|     1      | 0.2012 | 0.1245 | 0.2396 | 0.2843 |  0.3388 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 02:52:16,018: Snapshot:2	Epoch:0	Loss:11.839	translation_Loss:9.605	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.234                                                   	MRR:18.34	Hits@10:31.84	Best:18.34
2024-12-27 02:52:22,630: Snapshot:2	Epoch:1	Loss:10.653	translation_Loss:8.661	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.992                                                   	MRR:18.68	Hits@10:32.27	Best:18.68
2024-12-27 02:52:29,173: Snapshot:2	Epoch:2	Loss:10.334	translation_Loss:8.338	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.996                                                   	MRR:18.74	Hits@10:32.42	Best:18.74
2024-12-27 02:52:35,758: Snapshot:2	Epoch:3	Loss:10.218	translation_Loss:8.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.98                                                   	MRR:18.78	Hits@10:32.36	Best:18.78
2024-12-27 02:52:42,329: Snapshot:2	Epoch:4	Loss:10.176	translation_Loss:8.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.974                                                   	MRR:18.71	Hits@10:32.33	Best:18.78
2024-12-27 02:52:48,871: Snapshot:2	Epoch:5	Loss:10.163	translation_Loss:8.191	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.972                                                   	MRR:18.77	Hits@10:32.41	Best:18.78
2024-12-27 02:52:55,438: Snapshot:2	Epoch:6	Loss:10.136	translation_Loss:8.164	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.972                                                   	MRR:18.8	Hits@10:32.39	Best:18.8
2024-12-27 02:53:01,965: Snapshot:2	Epoch:7	Loss:10.14	translation_Loss:8.169	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.971                                                   	MRR:18.87	Hits@10:32.31	Best:18.87
2024-12-27 02:53:08,571: Snapshot:2	Epoch:8	Loss:10.132	translation_Loss:8.161	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.972                                                   	MRR:18.82	Hits@10:32.35	Best:18.87
2024-12-27 02:53:15,123: Snapshot:2	Epoch:9	Loss:10.128	translation_Loss:8.156	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.972                                                   	MRR:18.77	Hits@10:32.37	Best:18.87
2024-12-27 02:53:21,602: Early Stopping! Snapshot: 2 Epoch: 10 Best Results: 18.87
2024-12-27 02:53:21,602: Start to training tokens! Snapshot: 2 Epoch: 10 Loss:10.135 MRR:18.83 Best Results: 18.87
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 02:53:21,602: Snapshot:2	Epoch:10	Loss:10.135	translation_Loss:8.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.973                                                   	MRR:18.83	Hits@10:32.28	Best:18.87
2024-12-27 02:53:28,055: Snapshot:2	Epoch:11	Loss:38.931	translation_Loss:23.201	multi_layer_Loss:15.729	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.83	Hits@10:32.28	Best:18.87
2024-12-27 02:53:34,536: End of token training: 2 Epoch: 12 Loss:23.312 MRR:18.83 Best Results: 18.87
2024-12-27 02:53:34,536: Snapshot:2	Epoch:12	Loss:23.312	translation_Loss:23.201	multi_layer_Loss:0.11	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:18.83	Hits@10:32.28	Best:18.87
2024-12-27 02:53:34,872: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2024-12-27 02:53:43,082: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.245  | 0.1595 | 0.2861 | 0.3362 |  0.4001 |
|     1      | 0.2046 | 0.1275 | 0.2431 | 0.2877 |  0.3446 |
|     2      | 0.186  | 0.1118 | 0.2198 | 0.2632 |  0.3222 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 02:54:06,950: Snapshot:3	Epoch:0	Loss:10.635	translation_Loss:8.342	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.292                                                   	MRR:16.27	Hits@10:30.17	Best:16.27
2024-12-27 02:54:13,526: Snapshot:3	Epoch:1	Loss:9.982	translation_Loss:7.946	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.036                                                   	MRR:16.57	Hits@10:30.52	Best:16.57
2024-12-27 02:54:20,255: Snapshot:3	Epoch:2	Loss:9.934	translation_Loss:7.892	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.042                                                   	MRR:16.66	Hits@10:30.55	Best:16.66
2024-12-27 02:54:26,754: Snapshot:3	Epoch:3	Loss:9.878	translation_Loss:7.844	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.033                                                   	MRR:16.65	Hits@10:30.67	Best:16.66
2024-12-27 02:54:33,266: Snapshot:3	Epoch:4	Loss:9.878	translation_Loss:7.849	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.028                                                   	MRR:16.66	Hits@10:30.56	Best:16.66
2024-12-27 02:54:39,913: Early Stopping! Snapshot: 3 Epoch: 5 Best Results: 16.66
2024-12-27 02:54:39,913: Start to training tokens! Snapshot: 3 Epoch: 5 Loss:9.886 MRR:16.6 Best Results: 16.66
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 02:54:39,914: Snapshot:3	Epoch:5	Loss:9.886	translation_Loss:7.85	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.036                                                   	MRR:16.6	Hits@10:30.56	Best:16.66
2024-12-27 02:54:46,481: Snapshot:3	Epoch:6	Loss:37.891	translation_Loss:22.977	multi_layer_Loss:14.914	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.6	Hits@10:30.56	Best:16.66
2024-12-27 02:54:52,963: End of token training: 3 Epoch: 7 Loss:23.074 MRR:16.6 Best Results: 16.66
2024-12-27 02:54:52,963: Snapshot:3	Epoch:7	Loss:23.074	translation_Loss:22.968	multi_layer_Loss:0.106	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:16.6	Hits@10:30.56	Best:16.66
2024-12-27 02:54:53,242: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2024-12-27 02:55:04,593: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2442 | 0.1585 | 0.2853 | 0.3349 |  0.4003 |
|     1      | 0.2055 | 0.1281 | 0.2424 | 0.2894 |  0.3467 |
|     2      | 0.189  | 0.114  | 0.2213 | 0.2679 |  0.3295 |
|     3      | 0.1665 | 0.0929 | 0.1936 | 0.2423 |  0.3078 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 02:55:27,538: Snapshot:4	Epoch:0	Loss:8.777	translation_Loss:6.403	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.374                                                   	MRR:16.24	Hits@10:33.4	Best:16.24
2024-12-27 02:55:34,607: Snapshot:4	Epoch:1	Loss:7.647	translation_Loss:5.539	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.109                                                   	MRR:16.89	Hits@10:33.57	Best:16.89
2024-12-27 02:55:41,286: Snapshot:4	Epoch:2	Loss:7.491	translation_Loss:5.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.092                                                   	MRR:16.99	Hits@10:33.58	Best:16.99
2024-12-27 02:55:47,953: Snapshot:4	Epoch:3	Loss:7.443	translation_Loss:5.344	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.099                                                   	MRR:17.06	Hits@10:33.83	Best:17.06
2024-12-27 02:55:54,548: Snapshot:4	Epoch:4	Loss:7.43	translation_Loss:5.34	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.09                                                   	MRR:17.15	Hits@10:33.84	Best:17.15
2024-12-27 02:56:01,269: Snapshot:4	Epoch:5	Loss:7.421	translation_Loss:5.336	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.086                                                   	MRR:17.09	Hits@10:33.97	Best:17.15
2024-12-27 02:56:08,271: Snapshot:4	Epoch:6	Loss:7.418	translation_Loss:5.323	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.095                                                   	MRR:17.09	Hits@10:34.03	Best:17.15
2024-12-27 02:56:14,868: Snapshot:4	Epoch:7	Loss:7.402	translation_Loss:5.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.092                                                   	MRR:17.16	Hits@10:33.85	Best:17.16
2024-12-27 02:56:21,437: Snapshot:4	Epoch:8	Loss:7.407	translation_Loss:5.315	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.092                                                   	MRR:17.06	Hits@10:33.92	Best:17.16
2024-12-27 02:56:27,974: Snapshot:4	Epoch:9	Loss:7.419	translation_Loss:5.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.1                                                   	MRR:17.03	Hits@10:33.78	Best:17.16
2024-12-27 02:56:34,613: Early Stopping! Snapshot: 4 Epoch: 10 Best Results: 17.16
2024-12-27 02:56:34,613: Start to training tokens! Snapshot: 4 Epoch: 10 Loss:7.403 MRR:17.03 Best Results: 17.16
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 02:56:34,613: Snapshot:4	Epoch:10	Loss:7.403	translation_Loss:5.311	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.092                                                   	MRR:17.03	Hits@10:33.95	Best:17.16
2024-12-27 02:56:41,347: Snapshot:4	Epoch:11	Loss:34.959	translation_Loss:19.955	multi_layer_Loss:15.004	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.03	Hits@10:33.95	Best:17.16
2024-12-27 02:56:48,400: End of token training: 4 Epoch: 12 Loss:20.051 MRR:17.03 Best Results: 17.16
2024-12-27 02:56:48,400: Snapshot:4	Epoch:12	Loss:20.051	translation_Loss:19.943	multi_layer_Loss:0.108	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:17.03	Hits@10:33.95	Best:17.16
2024-12-27 02:56:48,663: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2024-12-27 02:57:02,875: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2409 | 0.1559 | 0.2802 | 0.3316 |  0.3967 |
|     1      | 0.2029 | 0.1255 | 0.2392 | 0.2867 |  0.3458 |
|     2      | 0.1878 | 0.1126 | 0.2202 | 0.2674 |  0.3285 |
|     3      | 0.1684 | 0.0927 | 0.1951 | 0.2468 |  0.3163 |
|     4      | 0.1724 | 0.0884 | 0.1985 | 0.2553 |  0.3369 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 02:57:02,877: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2409 | 0.1559 | 0.2821 | 0.3316 |  0.3948 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2446 |  0.16  | 0.285  | 0.3343 |  0.3988 |
|     1      | 0.2012 | 0.1245 | 0.2396 | 0.2843 |  0.3388 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.245  | 0.1595 | 0.2861 | 0.3362 |  0.4001 |
|     1      | 0.2046 | 0.1275 | 0.2431 | 0.2877 |  0.3446 |
|     2      | 0.186  | 0.1118 | 0.2198 | 0.2632 |  0.3222 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2442 | 0.1585 | 0.2853 | 0.3349 |  0.4003 |
|     1      | 0.2055 | 0.1281 | 0.2424 | 0.2894 |  0.3467 |
|     2      | 0.189  | 0.114  | 0.2213 | 0.2679 |  0.3295 |
|     3      | 0.1665 | 0.0929 | 0.1936 | 0.2423 |  0.3078 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2409 | 0.1559 | 0.2802 | 0.3316 |  0.3967 |
|     1      | 0.2029 | 0.1255 | 0.2392 | 0.2867 |  0.3458 |
|     2      | 0.1878 | 0.1126 | 0.2202 | 0.2674 |  0.3285 |
|     3      | 0.1684 | 0.0927 | 0.1951 | 0.2468 |  0.3163 |
|     4      | 0.1724 | 0.0884 | 0.1985 | 0.2553 |  0.3369 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 02:57:02,878: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 118.70136046409607 |   0.241   |    0.156     |    0.282     |     0.395     |
|    1     | 96.91993117332458  |   0.223   |    0.142     |    0.262     |     0.369     |
|    2     | 98.92431879043579  |   0.212   |    0.133     |     0.25     |     0.356     |
|    3     | 66.55011248588562  |   0.201   |    0.123     |    0.236     |     0.346     |
|    4     | 100.60728240013123 |   0.194   |    0.115     |    0.227     |     0.345     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 02:57:02,878: Sum_Training_Time:481.7030053138733
2024-12-27 02:57:02,878: Every_Training_Time:[118.70136046409607, 96.91993117332458, 98.92431879043579, 66.55011248588562, 100.60728240013123]
2024-12-27 02:57:02,878: Forward transfer: 0.152975 Backward transfer: 0.001349999999999997
2024-12-27 02:57:39,558: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227025707/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=2, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 02:57:48,875: Snapshot:0	Epoch:0	Loss:24.869	translation_Loss:24.869	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.15	Hits@10:15.62	Best:7.15
2024-12-27 02:57:54,910: Snapshot:0	Epoch:1	Loss:16.859	translation_Loss:16.859	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.6	Hits@10:25.86	Best:11.6
2024-12-27 02:58:01,260: Snapshot:0	Epoch:2	Loss:11.571	translation_Loss:11.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.35	Hits@10:32.18	Best:15.35
2024-12-27 02:58:07,259: Snapshot:0	Epoch:3	Loss:7.838	translation_Loss:7.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.55	Hits@10:35.84	Best:18.55
2024-12-27 02:58:13,211: Snapshot:0	Epoch:4	Loss:5.219	translation_Loss:5.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.0	Hits@10:38.02	Best:21.0
2024-12-27 02:58:19,135: Snapshot:0	Epoch:5	Loss:3.478	translation_Loss:3.478	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.68	Hits@10:39.27	Best:22.68
2024-12-27 02:58:25,220: Snapshot:0	Epoch:6	Loss:2.329	translation_Loss:2.329	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.77	Hits@10:39.7	Best:23.77
2024-12-27 02:58:31,635: Snapshot:0	Epoch:7	Loss:1.608	translation_Loss:1.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.29	Hits@10:39.97	Best:24.29
2024-12-27 02:58:37,593: Snapshot:0	Epoch:8	Loss:1.154	translation_Loss:1.154	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.62	Hits@10:40.2	Best:24.62
2024-12-27 02:58:43,613: Snapshot:0	Epoch:9	Loss:0.881	translation_Loss:0.881	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.69	Hits@10:40.12	Best:24.69
2024-12-27 02:58:49,602: Snapshot:0	Epoch:10	Loss:0.706	translation_Loss:0.706	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.71	Hits@10:40.33	Best:24.71
2024-12-27 02:58:55,690: Snapshot:0	Epoch:11	Loss:0.579	translation_Loss:0.579	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.77	Hits@10:40.21	Best:24.77
2024-12-27 02:59:01,703: Snapshot:0	Epoch:12	Loss:0.499	translation_Loss:0.499	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.85	Hits@10:40.33	Best:24.85
2024-12-27 02:59:08,152: Snapshot:0	Epoch:13	Loss:0.439	translation_Loss:0.439	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.86	Hits@10:40.4	Best:24.86
2024-12-27 02:59:14,080: Snapshot:0	Epoch:14	Loss:0.4	translation_Loss:0.4	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.78	Hits@10:40.29	Best:24.86
2024-12-27 02:59:20,171: Snapshot:0	Epoch:15	Loss:0.36	translation_Loss:0.36	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.75	Hits@10:40.09	Best:24.86
2024-12-27 02:59:26,127: Snapshot:0	Epoch:16	Loss:0.326	translation_Loss:0.326	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.87	Hits@10:40.33	Best:24.87
2024-12-27 02:59:32,076: Snapshot:0	Epoch:17	Loss:0.305	translation_Loss:0.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.85	Hits@10:40.25	Best:24.87
2024-12-27 02:59:38,420: Snapshot:0	Epoch:18	Loss:0.289	translation_Loss:0.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.75	Hits@10:40.13	Best:24.87
2024-12-27 02:59:44,356: Early Stopping! Snapshot: 0 Epoch: 19 Best Results: 24.87
2024-12-27 02:59:44,356: Start to training tokens! Snapshot: 0 Epoch: 19 Loss:0.268 MRR:24.78 Best Results: 24.87
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 02:59:44,356: Snapshot:0	Epoch:19	Loss:0.268	translation_Loss:0.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.78	Hits@10:40.08	Best:24.87
2024-12-27 02:59:50,848: Snapshot:0	Epoch:20	Loss:29.02	translation_Loss:18.346	multi_layer_Loss:10.673	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.78	Hits@10:40.08	Best:24.87
2024-12-27 02:59:56,855: End of token training: 0 Epoch: 21 Loss:18.413 MRR:24.78 Best Results: 24.87
2024-12-27 02:59:56,855: Snapshot:0	Epoch:21	Loss:18.413	translation_Loss:18.328	multi_layer_Loss:0.085	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.78	Hits@10:40.08	Best:24.87
2024-12-27 02:59:57,170: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2024-12-27 02:59:59,679: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2416 | 0.1568 | 0.2824 | 0.3313 |  0.3944 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 03:00:22,592: Snapshot:1	Epoch:0	Loss:11.074	translation_Loss:9.93	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.144                                                   	MRR:20.71	Hits@10:34.62	Best:20.71
2024-12-27 03:00:29,065: Snapshot:1	Epoch:1	Loss:7.187	translation_Loss:5.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.071                                                   	MRR:22.04	Hits@10:36.59	Best:22.04
2024-12-27 03:00:35,522: Snapshot:1	Epoch:2	Loss:6.139	translation_Loss:3.849	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.291                                                   	MRR:22.49	Hits@10:37.35	Best:22.49
2024-12-27 03:00:41,962: Snapshot:1	Epoch:3	Loss:5.743	translation_Loss:3.352	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.39                                                   	MRR:22.48	Hits@10:37.45	Best:22.49
2024-12-27 03:00:48,759: Snapshot:1	Epoch:4	Loss:5.637	translation_Loss:3.225	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.412                                                   	MRR:22.62	Hits@10:37.45	Best:22.62
2024-12-27 03:00:55,245: Snapshot:1	Epoch:5	Loss:5.582	translation_Loss:3.143	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.439                                                   	MRR:22.66	Hits@10:37.54	Best:22.66
2024-12-27 03:01:01,669: Snapshot:1	Epoch:6	Loss:5.549	translation_Loss:3.105	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.444                                                   	MRR:22.54	Hits@10:37.33	Best:22.66
2024-12-27 03:01:08,185: Snapshot:1	Epoch:7	Loss:5.521	translation_Loss:3.061	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.46                                                   	MRR:22.63	Hits@10:37.47	Best:22.66
2024-12-27 03:01:14,563: Early Stopping! Snapshot: 1 Epoch: 8 Best Results: 22.66
2024-12-27 03:01:14,563: Start to training tokens! Snapshot: 1 Epoch: 8 Loss:5.536 MRR:22.61 Best Results: 22.66
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 03:01:14,563: Snapshot:1	Epoch:8	Loss:5.536	translation_Loss:3.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.465                                                   	MRR:22.61	Hits@10:37.41	Best:22.66
2024-12-27 03:01:21,455: Snapshot:1	Epoch:9	Loss:31.21	translation_Loss:20.701	multi_layer_Loss:10.51	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.61	Hits@10:37.41	Best:22.66
2024-12-27 03:01:27,783: End of token training: 1 Epoch: 10 Loss:20.772 MRR:22.61 Best Results: 22.66
2024-12-27 03:01:27,783: Snapshot:1	Epoch:10	Loss:20.772	translation_Loss:20.682	multi_layer_Loss:0.09	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.61	Hits@10:37.41	Best:22.66
2024-12-27 03:01:28,047: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2024-12-27 03:01:33,417: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2539 | 0.1651 | 0.2965 | 0.3501 |  0.418  |
|     1      | 0.2254 | 0.1443 | 0.2628 | 0.3127 |  0.3755 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 03:01:56,825: Snapshot:2	Epoch:0	Loss:7.159	translation_Loss:6.112	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.047                                                   	MRR:21.36	Hits@10:37.52	Best:21.36
2024-12-27 03:02:03,559: Snapshot:2	Epoch:1	Loss:4.381	translation_Loss:2.634	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.748                                                   	MRR:22.13	Hits@10:38.11	Best:22.13
2024-12-27 03:02:10,222: Snapshot:2	Epoch:2	Loss:3.968	translation_Loss:2.14	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.828                                                   	MRR:22.16	Hits@10:38.48	Best:22.16
2024-12-27 03:02:16,880: Snapshot:2	Epoch:3	Loss:3.872	translation_Loss:1.939	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.933                                                   	MRR:22.26	Hits@10:38.31	Best:22.26
2024-12-27 03:02:23,516: Snapshot:2	Epoch:4	Loss:3.882	translation_Loss:1.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.961                                                   	MRR:22.08	Hits@10:38.43	Best:22.26
2024-12-27 03:02:30,130: Snapshot:2	Epoch:5	Loss:3.889	translation_Loss:1.885	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.004                                                   	MRR:22.19	Hits@10:38.22	Best:22.26
2024-12-27 03:02:36,809: Early Stopping! Snapshot: 2 Epoch: 6 Best Results: 22.26
2024-12-27 03:02:36,810: Start to training tokens! Snapshot: 2 Epoch: 6 Loss:3.882 MRR:22.17 Best Results: 22.26
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 03:02:36,810: Snapshot:2	Epoch:6	Loss:3.882	translation_Loss:1.876	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.006                                                   	MRR:22.17	Hits@10:38.38	Best:22.26
2024-12-27 03:02:43,361: Snapshot:2	Epoch:7	Loss:31.11	translation_Loss:20.219	multi_layer_Loss:10.891	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.17	Hits@10:38.38	Best:22.26
2024-12-27 03:02:49,989: End of token training: 2 Epoch: 8 Loss:20.302 MRR:22.17 Best Results: 22.26
2024-12-27 03:02:49,989: Snapshot:2	Epoch:8	Loss:20.302	translation_Loss:20.213	multi_layer_Loss:0.088	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.17	Hits@10:38.38	Best:22.26
2024-12-27 03:02:50,353: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2024-12-27 03:02:58,742: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2474 | 0.1602 | 0.2858 | 0.3401 |  0.412  |
|     1      | 0.2292 | 0.147  | 0.2641 | 0.3165 |  0.3859 |
|     2      | 0.2215 | 0.1374 | 0.2564 | 0.3104 |  0.384  |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 03:03:22,053: Snapshot:3	Epoch:0	Loss:3.805	translation_Loss:2.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.836                                                   	MRR:20.48	Hits@10:38.93	Best:20.48
2024-12-27 03:03:28,672: Snapshot:3	Epoch:1	Loss:2.256	translation_Loss:1.122	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.134                                                   	MRR:20.47	Hits@10:39.02	Best:20.48
2024-12-27 03:03:35,170: Snapshot:3	Epoch:2	Loss:2.106	translation_Loss:1.013	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.093                                                   	MRR:20.44	Hits@10:38.63	Best:20.48
2024-12-27 03:03:41,829: Early Stopping! Snapshot: 3 Epoch: 3 Best Results: 20.48
2024-12-27 03:03:41,830: Start to training tokens! Snapshot: 3 Epoch: 3 Loss:2.106 MRR:20.32 Best Results: 20.48
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 03:03:41,830: Snapshot:3	Epoch:3	Loss:2.106	translation_Loss:0.948	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.158                                                   	MRR:20.32	Hits@10:38.63	Best:20.48
2024-12-27 03:03:48,479: Snapshot:3	Epoch:4	Loss:28.659	translation_Loss:19.298	multi_layer_Loss:9.362	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.32	Hits@10:38.63	Best:20.48
2024-12-27 03:03:55,065: End of token training: 3 Epoch: 5 Loss:19.409 MRR:20.32 Best Results: 20.48
2024-12-27 03:03:55,065: Snapshot:3	Epoch:5	Loss:19.409	translation_Loss:19.332	multi_layer_Loss:0.077	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.32	Hits@10:38.63	Best:20.48
2024-12-27 03:03:55,353: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2024-12-27 03:04:06,986: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2334 | 0.1494 | 0.2676 | 0.3183 |  0.3915 |
|     1      | 0.2176 | 0.1379 | 0.246  | 0.3017 |  0.375  |
|     2      | 0.2108 | 0.1256 | 0.2424 | 0.2993 |  0.383  |
|     3      | 0.2048 | 0.1125 | 0.2383 | 0.3022 |  0.3934 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 03:04:29,875: Snapshot:4	Epoch:0	Loss:2.129	translation_Loss:1.631	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.498                                                   	MRR:21.41	Hits@10:46.19	Best:21.41
2024-12-27 03:04:36,679: Snapshot:4	Epoch:1	Loss:0.956	translation_Loss:0.434	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.521                                                   	MRR:22.14	Hits@10:45.76	Best:22.14
2024-12-27 03:04:43,807: Snapshot:4	Epoch:2	Loss:0.797	translation_Loss:0.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.462                                                   	MRR:22.1	Hits@10:46.17	Best:22.14
2024-12-27 03:04:50,394: Snapshot:4	Epoch:3	Loss:0.78	translation_Loss:0.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.485                                                   	MRR:21.83	Hits@10:45.68	Best:22.14
2024-12-27 03:04:56,992: Early Stopping! Snapshot: 4 Epoch: 4 Best Results: 22.14
2024-12-27 03:04:56,992: Start to training tokens! Snapshot: 4 Epoch: 4 Loss:0.777 MRR:21.91 Best Results: 22.14
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-27 03:04:56,992: Snapshot:4	Epoch:4	Loss:0.777	translation_Loss:0.288	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.489                                                   	MRR:21.91	Hits@10:45.84	Best:22.14
2024-12-27 03:05:03,715: Snapshot:4	Epoch:5	Loss:25.933	translation_Loss:16.152	multi_layer_Loss:9.781	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.91	Hits@10:45.84	Best:22.14
2024-12-27 03:05:10,297: End of token training: 4 Epoch: 6 Loss:16.18 MRR:21.91 Best Results: 22.14
2024-12-27 03:05:10,297: Snapshot:4	Epoch:6	Loss:16.18	translation_Loss:16.099	multi_layer_Loss:0.081	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.91	Hits@10:45.84	Best:22.14
2024-12-27 03:05:10,570: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2024-12-27 03:05:25,229: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2198 | 0.1389 | 0.2508 | 0.3009 |  0.3743 |
|     1      | 0.203  | 0.1262 | 0.2283 | 0.2816 |  0.3547 |
|     2      | 0.1962 | 0.1152 | 0.2223 | 0.278  |  0.3617 |
|     3      | 0.1908 | 0.101  | 0.2193 | 0.2817 |  0.3743 |
|     4      | 0.2213 | 0.106  | 0.2588 | 0.346  |  0.4585 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 03:05:25,231: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2416 | 0.1568 | 0.2824 | 0.3313 |  0.3944 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2539 | 0.1651 | 0.2965 | 0.3501 |  0.418  |
|     1      | 0.2254 | 0.1443 | 0.2628 | 0.3127 |  0.3755 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2474 | 0.1602 | 0.2858 | 0.3401 |  0.412  |
|     1      | 0.2292 | 0.147  | 0.2641 | 0.3165 |  0.3859 |
|     2      | 0.2215 | 0.1374 | 0.2564 | 0.3104 |  0.384  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2334 | 0.1494 | 0.2676 | 0.3183 |  0.3915 |
|     1      | 0.2176 | 0.1379 | 0.246  | 0.3017 |  0.375  |
|     2      | 0.2108 | 0.1256 | 0.2424 | 0.2993 |  0.383  |
|     3      | 0.2048 | 0.1125 | 0.2383 | 0.3022 |  0.3934 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2198 | 0.1389 | 0.2508 | 0.3009 |  0.3743 |
|     1      | 0.203  | 0.1262 | 0.2283 | 0.2816 |  0.3547 |
|     2      | 0.1962 | 0.1152 | 0.2223 | 0.278  |  0.3617 |
|     3      | 0.1908 | 0.101  | 0.2193 | 0.2817 |  0.3743 |
|     4      | 0.2213 | 0.106  | 0.2588 | 0.346  |  0.4585 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 03:05:25,231: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 137.2966365814209  |   0.242   |    0.157     |    0.282     |     0.394     |
|    1     |  85.2870454788208  |    0.24   |    0.155     |     0.28     |     0.397     |
|    2     | 73.57960081100464  |   0.233   |    0.148     |    0.269     |     0.394     |
|    3     |  53.2662935256958  |   0.217   |    0.131     |    0.249     |     0.386     |
|    4     | 60.221903800964355 |   0.206   |    0.117     |    0.236     |     0.385     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 03:05:25,232: Sum_Training_Time:409.6514801979065
2024-12-27 03:05:25,232: Every_Training_Time:[137.2966365814209, 85.2870454788208, 73.57960081100464, 53.2662935256958, 60.221903800964355]
2024-12-27 03:05:25,232: Forward transfer: 0.177275 Backward transfer: -0.020874999999999998
2024-12-27 03:06:02,313: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227030529/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=10, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 03:06:11,534: Snapshot:0	Epoch:0	Loss:24.869	translation_Loss:24.869	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.15	Hits@10:15.62	Best:7.15
2024-12-27 03:06:17,433: Snapshot:0	Epoch:1	Loss:16.859	translation_Loss:16.859	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.6	Hits@10:25.86	Best:11.6
2024-12-27 03:06:23,639: Snapshot:0	Epoch:2	Loss:11.571	translation_Loss:11.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.35	Hits@10:32.18	Best:15.35
2024-12-27 03:06:29,498: Snapshot:0	Epoch:3	Loss:7.838	translation_Loss:7.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.53	Hits@10:35.87	Best:18.53
2024-12-27 03:06:35,342: Snapshot:0	Epoch:4	Loss:5.219	translation_Loss:5.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.99	Hits@10:37.98	Best:20.99
2024-12-27 03:06:41,268: Snapshot:0	Epoch:5	Loss:3.481	translation_Loss:3.481	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.6	Hits@10:39.11	Best:22.6
2024-12-27 03:06:47,092: Snapshot:0	Epoch:6	Loss:2.325	translation_Loss:2.325	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.76	Hits@10:39.68	Best:23.76
2024-12-27 03:06:53,405: Snapshot:0	Epoch:7	Loss:1.609	translation_Loss:1.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.31	Hits@10:39.95	Best:24.31
2024-12-27 03:06:59,407: Snapshot:0	Epoch:8	Loss:1.152	translation_Loss:1.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.53	Hits@10:40.12	Best:24.53
2024-12-27 03:07:05,238: Snapshot:0	Epoch:9	Loss:0.882	translation_Loss:0.882	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.75	Hits@10:40.3	Best:24.75
2024-12-27 03:07:11,080: Snapshot:0	Epoch:10	Loss:0.706	translation_Loss:0.706	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.78	Hits@10:40.44	Best:24.78
2024-12-27 03:07:16,952: Snapshot:0	Epoch:11	Loss:0.577	translation_Loss:0.577	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.86	Hits@10:40.56	Best:24.86
2024-12-27 03:07:22,758: Snapshot:0	Epoch:12	Loss:0.496	translation_Loss:0.496	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.85	Hits@10:40.41	Best:24.86
2024-12-27 03:07:29,034: Snapshot:0	Epoch:13	Loss:0.437	translation_Loss:0.437	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.95	Hits@10:40.55	Best:24.95
2024-12-27 03:07:34,857: Snapshot:0	Epoch:14	Loss:0.4	translation_Loss:0.4	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.99	Hits@10:40.5	Best:24.99
2024-12-27 03:07:40,765: Snapshot:0	Epoch:15	Loss:0.361	translation_Loss:0.361	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.73	Hits@10:40.33	Best:24.99
2024-12-27 03:07:46,536: Snapshot:0	Epoch:16	Loss:0.33	translation_Loss:0.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.86	Hits@10:40.35	Best:24.99
2024-12-27 03:07:52,319: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 24.99
2024-12-27 03:07:52,319: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.305 MRR:24.87 Best Results: 24.99
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 03:07:52,319: Snapshot:0	Epoch:17	Loss:0.305	translation_Loss:0.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.87	Hits@10:40.42	Best:24.99
2024-12-27 03:07:59,220: Snapshot:0	Epoch:18	Loss:35.89	translation_Loss:18.336	multi_layer_Loss:17.554	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.87	Hits@10:40.42	Best:24.99
2024-12-27 03:08:05,093: End of token training: 0 Epoch: 19 Loss:18.473 MRR:24.87 Best Results: 24.99
2024-12-27 03:08:05,093: Snapshot:0	Epoch:19	Loss:18.473	translation_Loss:18.359	multi_layer_Loss:0.114	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.87	Hits@10:40.42	Best:24.99
2024-12-27 03:08:05,395: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2024-12-27 03:08:07,911: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2416 | 0.1559 | 0.2844 | 0.3337 |  0.3948 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 03:08:30,159: Snapshot:1	Epoch:0	Loss:12.355	translation_Loss:10.528	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.827                                                   	MRR:19.74	Hits@10:33.12	Best:19.74
2024-12-27 03:08:37,066: Snapshot:1	Epoch:1	Loss:10.298	translation_Loss:8.477	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.821                                                   	MRR:20.54	Hits@10:34.28	Best:20.54
2024-12-27 03:08:43,366: Snapshot:1	Epoch:2	Loss:9.19	translation_Loss:7.458	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.732                                                   	MRR:20.97	Hits@10:34.7	Best:20.97
2024-12-27 03:08:49,688: Snapshot:1	Epoch:3	Loss:8.815	translation_Loss:7.112	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.704                                                   	MRR:21.0	Hits@10:34.97	Best:21.0
2024-12-27 03:08:56,143: Snapshot:1	Epoch:4	Loss:8.664	translation_Loss:6.976	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.688                                                   	MRR:21.07	Hits@10:34.92	Best:21.07
2024-12-27 03:09:02,511: Snapshot:1	Epoch:5	Loss:8.577	translation_Loss:6.903	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.674                                                   	MRR:21.12	Hits@10:34.94	Best:21.12
2024-12-27 03:09:09,216: Snapshot:1	Epoch:6	Loss:8.545	translation_Loss:6.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.67                                                   	MRR:21.1	Hits@10:34.9	Best:21.12
2024-12-27 03:09:15,807: Snapshot:1	Epoch:7	Loss:8.519	translation_Loss:6.84	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.679                                                   	MRR:21.11	Hits@10:34.91	Best:21.12
2024-12-27 03:09:22,411: Snapshot:1	Epoch:8	Loss:8.494	translation_Loss:6.818	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.676                                                   	MRR:21.18	Hits@10:35.05	Best:21.18
2024-12-27 03:09:28,847: Snapshot:1	Epoch:9	Loss:8.48	translation_Loss:6.807	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.673                                                   	MRR:21.03	Hits@10:35.06	Best:21.18
2024-12-27 03:09:35,145: Snapshot:1	Epoch:10	Loss:8.471	translation_Loss:6.789	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.682                                                   	MRR:21.12	Hits@10:35.04	Best:21.18
2024-12-27 03:09:41,480: Early Stopping! Snapshot: 1 Epoch: 11 Best Results: 21.18
2024-12-27 03:09:41,480: Start to training tokens! Snapshot: 1 Epoch: 11 Loss:8.446 MRR:21.09 Best Results: 21.18
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 03:09:41,481: Snapshot:1	Epoch:11	Loss:8.446	translation_Loss:6.769	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.677                                                   	MRR:21.09	Hits@10:34.96	Best:21.18
2024-12-27 03:09:48,251: Snapshot:1	Epoch:12	Loss:39.199	translation_Loss:22.084	multi_layer_Loss:17.115	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.09	Hits@10:34.96	Best:21.18
2024-12-27 03:09:54,540: End of token training: 1 Epoch: 13 Loss:22.205 MRR:21.09 Best Results: 21.18
2024-12-27 03:09:54,541: Snapshot:1	Epoch:13	Loss:22.205	translation_Loss:22.095	multi_layer_Loss:0.11	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.09	Hits@10:34.96	Best:21.18
2024-12-27 03:09:54,804: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2024-12-27 03:10:00,173: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2496 | 0.1641 | 0.2914 | 0.3395 |  0.4043 |
|     1      | 0.2096 | 0.1314 | 0.2474 | 0.2935 |  0.3527 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 03:10:23,409: Snapshot:2	Epoch:0	Loss:10.007	translation_Loss:8.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.927                                                   	MRR:19.74	Hits@10:34.33	Best:19.74
2024-12-27 03:10:30,049: Snapshot:2	Epoch:1	Loss:8.838	translation_Loss:6.774	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.063                                                   	MRR:20.01	Hits@10:34.62	Best:20.01
2024-12-27 03:10:36,617: Snapshot:2	Epoch:2	Loss:8.367	translation_Loss:6.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.965                                                   	MRR:19.99	Hits@10:34.68	Best:20.01
2024-12-27 03:10:43,160: Snapshot:2	Epoch:3	Loss:8.272	translation_Loss:6.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.967                                                   	MRR:20.05	Hits@10:34.72	Best:20.05
2024-12-27 03:10:49,667: Snapshot:2	Epoch:4	Loss:8.236	translation_Loss:6.269	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.967                                                   	MRR:20.07	Hits@10:34.84	Best:20.07
2024-12-27 03:10:56,192: Snapshot:2	Epoch:5	Loss:8.227	translation_Loss:6.26	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.967                                                   	MRR:20.09	Hits@10:34.75	Best:20.09
2024-12-27 03:11:02,808: Snapshot:2	Epoch:6	Loss:8.215	translation_Loss:6.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.973                                                   	MRR:20.14	Hits@10:34.81	Best:20.14
2024-12-27 03:11:09,281: Snapshot:2	Epoch:7	Loss:8.19	translation_Loss:6.22	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.97                                                   	MRR:20.11	Hits@10:34.84	Best:20.14
2024-12-27 03:11:15,729: Snapshot:2	Epoch:8	Loss:8.221	translation_Loss:6.246	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.974                                                   	MRR:20.0	Hits@10:34.77	Best:20.14
2024-12-27 03:11:22,779: Early Stopping! Snapshot: 2 Epoch: 9 Best Results: 20.14
2024-12-27 03:11:22,779: Start to training tokens! Snapshot: 2 Epoch: 9 Loss:8.195 MRR:20.09 Best Results: 20.14
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 03:11:22,780: Snapshot:2	Epoch:9	Loss:8.195	translation_Loss:6.221	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.975                                                   	MRR:20.09	Hits@10:34.78	Best:20.14
2024-12-27 03:11:29,187: Snapshot:2	Epoch:10	Loss:40.129	translation_Loss:22.157	multi_layer_Loss:17.971	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.09	Hits@10:34.78	Best:20.14
2024-12-27 03:11:35,670: End of token training: 2 Epoch: 11 Loss:22.303 MRR:20.09 Best Results: 20.14
2024-12-27 03:11:35,670: Snapshot:2	Epoch:11	Loss:22.303	translation_Loss:22.188	multi_layer_Loss:0.115	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.09	Hits@10:34.78	Best:20.14
2024-12-27 03:11:36,007: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2024-12-27 03:11:44,285: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2494 | 0.1628 | 0.2902 | 0.3415 |  0.4093 |
|     1      | 0.2143 | 0.1337 | 0.2518 | 0.3005 |  0.3633 |
|     2      | 0.2015 | 0.123  | 0.2348 | 0.2847 |  0.3493 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 03:12:07,338: Snapshot:3	Epoch:0	Loss:7.386	translation_Loss:5.57	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.816                                                   	MRR:18.65	Hits@10:34.97	Best:18.65
2024-12-27 03:12:14,354: Snapshot:3	Epoch:1	Loss:6.534	translation_Loss:4.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.009                                                   	MRR:18.97	Hits@10:35.13	Best:18.97
2024-12-27 03:12:20,975: Snapshot:3	Epoch:2	Loss:6.353	translation_Loss:4.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.939                                                   	MRR:19.0	Hits@10:35.2	Best:19.0
2024-12-27 03:12:27,562: Snapshot:3	Epoch:3	Loss:6.329	translation_Loss:4.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.951                                                   	MRR:18.91	Hits@10:35.28	Best:19.0
2024-12-27 03:12:34,184: Snapshot:3	Epoch:4	Loss:6.335	translation_Loss:4.371	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.964                                                   	MRR:19.0	Hits@10:35.36	Best:19.0
2024-12-27 03:12:40,863: Snapshot:3	Epoch:5	Loss:6.334	translation_Loss:4.363	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.972                                                   	MRR:19.1	Hits@10:35.52	Best:19.1
2024-12-27 03:12:47,422: Snapshot:3	Epoch:6	Loss:6.318	translation_Loss:4.348	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.97                                                   	MRR:19.08	Hits@10:35.4	Best:19.1
2024-12-27 03:12:54,474: Snapshot:3	Epoch:7	Loss:6.328	translation_Loss:4.352	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.976                                                   	MRR:19.04	Hits@10:35.36	Best:19.1
2024-12-27 03:13:01,058: Early Stopping! Snapshot: 3 Epoch: 8 Best Results: 19.1
2024-12-27 03:13:01,058: Start to training tokens! Snapshot: 3 Epoch: 8 Loss:6.324 MRR:19.01 Best Results: 19.1
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 03:13:01,058: Snapshot:3	Epoch:8	Loss:6.324	translation_Loss:4.347	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.977                                                   	MRR:19.01	Hits@10:35.38	Best:19.1
2024-12-27 03:13:07,587: Snapshot:3	Epoch:9	Loss:38.932	translation_Loss:21.244	multi_layer_Loss:17.688	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.01	Hits@10:35.38	Best:19.1
2024-12-27 03:13:14,043: End of token training: 3 Epoch: 10 Loss:21.377 MRR:19.01 Best Results: 19.1
2024-12-27 03:13:14,043: Snapshot:3	Epoch:10	Loss:21.377	translation_Loss:21.263	multi_layer_Loss:0.114	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.01	Hits@10:35.38	Best:19.1
2024-12-27 03:13:14,305: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2024-12-27 03:13:25,908: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2431 | 0.1568 | 0.2827 | 0.3333 |  0.4052 |
|     1      | 0.2139 | 0.1327 | 0.2504 | 0.3008 |  0.3647 |
|     2      | 0.2037 | 0.1232 | 0.2364 | 0.2897 |  0.3601 |
|     3      | 0.1906 | 0.1072 | 0.2187 | 0.279  |  0.3577 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 03:13:49,427: Snapshot:4	Epoch:0	Loss:4.182	translation_Loss:2.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.283                                                   	MRR:20.02	Hits@10:43.37	Best:20.02
2024-12-27 03:13:56,224: Snapshot:4	Epoch:1	Loss:2.947	translation_Loss:1.66	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.287                                                   	MRR:20.71	Hits@10:43.36	Best:20.71
2024-12-27 03:14:02,795: Snapshot:4	Epoch:2	Loss:2.76	translation_Loss:1.504	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.256                                                   	MRR:20.61	Hits@10:43.29	Best:20.71
2024-12-27 03:14:09,471: Snapshot:4	Epoch:3	Loss:2.746	translation_Loss:1.481	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.265                                                   	MRR:20.76	Hits@10:43.2	Best:20.76
2024-12-27 03:14:16,098: Snapshot:4	Epoch:4	Loss:2.741	translation_Loss:1.474	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.267                                                   	MRR:20.64	Hits@10:43.17	Best:20.76
2024-12-27 03:14:22,629: Snapshot:4	Epoch:5	Loss:2.741	translation_Loss:1.462	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.279                                                   	MRR:20.76	Hits@10:43.12	Best:20.76
2024-12-27 03:14:29,278: Snapshot:4	Epoch:6	Loss:2.741	translation_Loss:1.465	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.276                                                   	MRR:20.77	Hits@10:43.35	Best:20.77
2024-12-27 03:14:35,839: Snapshot:4	Epoch:7	Loss:2.744	translation_Loss:1.461	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.283                                                   	MRR:20.73	Hits@10:43.13	Best:20.77
2024-12-27 03:14:42,510: Snapshot:4	Epoch:8	Loss:2.742	translation_Loss:1.463	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.278                                                   	MRR:20.76	Hits@10:43.18	Best:20.77
2024-12-27 03:14:49,071: Snapshot:4	Epoch:9	Loss:2.733	translation_Loss:1.452	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.281                                                   	MRR:20.81	Hits@10:43.19	Best:20.81
2024-12-27 03:14:55,645: Snapshot:4	Epoch:10	Loss:2.735	translation_Loss:1.448	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.287                                                   	MRR:20.68	Hits@10:43.35	Best:20.81
2024-12-27 03:15:02,304: Snapshot:4	Epoch:11	Loss:2.745	translation_Loss:1.454	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.29                                                   	MRR:20.68	Hits@10:43.6	Best:20.81
2024-12-27 03:15:08,972: Early Stopping! Snapshot: 4 Epoch: 12 Best Results: 20.81
2024-12-27 03:15:08,973: Start to training tokens! Snapshot: 4 Epoch: 12 Loss:2.745 MRR:20.71 Best Results: 20.81
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-27 03:15:08,973: Snapshot:4	Epoch:12	Loss:2.745	translation_Loss:1.455	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.29                                                   	MRR:20.71	Hits@10:43.03	Best:20.81
2024-12-27 03:15:16,023: Snapshot:4	Epoch:13	Loss:34.819	translation_Loss:17.506	multi_layer_Loss:17.314	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.71	Hits@10:43.03	Best:20.81
2024-12-27 03:15:22,632: End of token training: 4 Epoch: 14 Loss:17.614 MRR:20.71 Best Results: 20.81
2024-12-27 03:15:22,632: Snapshot:4	Epoch:14	Loss:17.614	translation_Loss:17.503	multi_layer_Loss:0.11	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.71	Hits@10:43.03	Best:20.81
2024-12-27 03:15:22,894: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2024-12-27 03:15:37,614: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2348 | 0.1497 | 0.2726 | 0.3226 |  0.394  |
|     1      | 0.2054 | 0.1258 | 0.2378 | 0.2879 |  0.3552 |
|     2      | 0.1961 | 0.1164 | 0.2252 | 0.2782 |  0.3529 |
|     3      | 0.1845 | 0.1004 | 0.2091 | 0.2704 |  0.3588 |
|     4      | 0.208  | 0.0977 | 0.2452 | 0.3256 |  0.4365 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 03:15:37,616: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2416 | 0.1559 | 0.2844 | 0.3337 |  0.3948 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2496 | 0.1641 | 0.2914 | 0.3395 |  0.4043 |
|     1      | 0.2096 | 0.1314 | 0.2474 | 0.2935 |  0.3527 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2494 | 0.1628 | 0.2902 | 0.3415 |  0.4093 |
|     1      | 0.2143 | 0.1337 | 0.2518 | 0.3005 |  0.3633 |
|     2      | 0.2015 | 0.123  | 0.2348 | 0.2847 |  0.3493 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2431 | 0.1568 | 0.2827 | 0.3333 |  0.4052 |
|     1      | 0.2139 | 0.1327 | 0.2504 | 0.3008 |  0.3647 |
|     2      | 0.2037 | 0.1232 | 0.2364 | 0.2897 |  0.3601 |
|     3      | 0.1906 | 0.1072 | 0.2187 | 0.279  |  0.3577 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2348 | 0.1497 | 0.2726 | 0.3226 |  0.394  |
|     1      | 0.2054 | 0.1258 | 0.2378 | 0.2879 |  0.3552 |
|     2      | 0.1961 | 0.1164 | 0.2252 | 0.2782 |  0.3529 |
|     3      | 0.1845 | 0.1004 | 0.2091 | 0.2704 |  0.3588 |
|     4      | 0.208  | 0.0977 | 0.2452 | 0.3256 |  0.4365 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 03:15:37,617: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 122.77982115745544 |   0.242   |    0.156     |    0.284     |     0.395     |
|    1     | 103.81163549423218 |    0.23   |    0.148     |    0.269     |     0.378     |
|    2     | 92.46531748771667  |   0.222   |     0.14     |    0.259     |     0.374     |
|    3     | 86.75199222564697  |   0.213   |     0.13     |    0.247     |     0.372     |
|    4     | 113.94075870513916 |   0.206   |    0.118     |    0.238     |     0.379     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 03:15:37,617: Sum_Training_Time:519.7495250701904
2024-12-27 03:15:37,617: Every_Training_Time:[122.77982115745544, 103.81163549423218, 92.46531748771667, 86.75199222564697, 113.94075870513916]
2024-12-27 03:15:37,617: Forward transfer: 0.165225 Backward transfer: -0.005625000000000005
