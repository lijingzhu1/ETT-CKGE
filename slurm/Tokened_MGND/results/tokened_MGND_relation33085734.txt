2025-01-06 22:02:03,646: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106220143/RELATION', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=1111, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATION', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[3000.0, 15000.0, 80000.0, 80000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 22:02:19,210: Snapshot:0	Epoch:0	Loss:24.059	translation_Loss:24.059	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:11.1	Hits@10:26.27	Best:11.1
2025-01-06 22:02:30,550: Snapshot:0	Epoch:1	Loss:14.887	translation_Loss:14.887	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.9	Hits@10:40.17	Best:18.9
2025-01-06 22:02:42,075: Snapshot:0	Epoch:2	Loss:8.522	translation_Loss:8.522	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.89	Hits@10:45.09	Best:23.89
2025-01-06 22:02:53,103: Snapshot:0	Epoch:3	Loss:4.75	translation_Loss:4.75	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.42	Hits@10:47.24	Best:26.42
2025-01-06 22:03:04,402: Snapshot:0	Epoch:4	Loss:2.781	translation_Loss:2.781	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.31	Hits@10:47.95	Best:27.31
2025-01-06 22:03:15,698: Snapshot:0	Epoch:5	Loss:1.837	translation_Loss:1.837	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.6	Hits@10:48.26	Best:27.6
2025-01-06 22:03:26,611: Snapshot:0	Epoch:6	Loss:1.368	translation_Loss:1.368	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.81	Hits@10:48.43	Best:27.81
2025-01-06 22:03:37,981: Snapshot:0	Epoch:7	Loss:1.122	translation_Loss:1.122	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.66	Hits@10:48.28	Best:27.81
2025-01-06 22:03:49,318: Snapshot:0	Epoch:8	Loss:0.968	translation_Loss:0.968	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.59	Hits@10:48.16	Best:27.81
2025-01-06 22:04:00,193: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 27.81
2025-01-06 22:04:00,193: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.86 MRR:27.66 Best Results: 27.81
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:04:00,194: Snapshot:0	Epoch:9	Loss:0.86	translation_Loss:0.86	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.66	Hits@10:48.04	Best:27.81
2025-01-06 22:04:12,009: Snapshot:0	Epoch:10	Loss:31.153	translation_Loss:16.429	token_training_loss:14.724	distillation_Loss:0.0                                                   	MRR:27.66	Hits@10:48.04	Best:27.81
2025-01-06 22:04:23,025: End of token training: 0 Epoch: 11 Loss:16.504 MRR:27.66 Best Results: 27.81
2025-01-06 22:04:23,025: Snapshot:0	Epoch:11	Loss:16.504	translation_Loss:16.42	token_training_loss:0.084	distillation_Loss:0.0                                                           	MRR:27.66	Hits@10:48.04	Best:27.81
2025-01-06 22:04:23,305: => loading checkpoint './checkpoint/RELATION/0model_best.tar'
2025-01-06 22:04:28,950: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2819 | 0.1704 | 0.3478 | 0.4177 |  0.4868 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:04:47,374: Snapshot:1	Epoch:0	Loss:20.234	translation_Loss:19.007	token_training_loss:0.0	distillation_Loss:1.228                                                   	MRR:10.13	Hits@10:24.96	Best:10.13
2025-01-06 22:04:57,911: Snapshot:1	Epoch:1	Loss:10.659	translation_Loss:8.417	token_training_loss:0.0	distillation_Loss:2.242                                                   	MRR:15.82	Hits@10:32.36	Best:15.82
2025-01-06 22:05:08,762: Snapshot:1	Epoch:2	Loss:6.843	translation_Loss:4.4	token_training_loss:0.0	distillation_Loss:2.443                                                   	MRR:16.81	Hits@10:33.79	Best:16.81
2025-01-06 22:05:18,948: Snapshot:1	Epoch:3	Loss:5.443	translation_Loss:3.136	token_training_loss:0.0	distillation_Loss:2.307                                                   	MRR:16.97	Hits@10:33.54	Best:16.97
2025-01-06 22:05:29,488: Snapshot:1	Epoch:4	Loss:4.916	translation_Loss:2.738	token_training_loss:0.0	distillation_Loss:2.178                                                   	MRR:17.21	Hits@10:33.54	Best:17.21
2025-01-06 22:05:40,007: Snapshot:1	Epoch:5	Loss:4.669	translation_Loss:2.567	token_training_loss:0.0	distillation_Loss:2.101                                                   	MRR:16.98	Hits@10:32.98	Best:17.21
2025-01-06 22:05:50,032: Snapshot:1	Epoch:6	Loss:4.57	translation_Loss:2.515	token_training_loss:0.0	distillation_Loss:2.055                                                   	MRR:16.88	Hits@10:32.83	Best:17.21
2025-01-06 22:06:00,516: Early Stopping! Snapshot: 1 Epoch: 7 Best Results: 17.21
2025-01-06 22:06:00,516: Start to training tokens! Snapshot: 1 Epoch: 7 Loss:4.495 MRR:16.73 Best Results: 17.21
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:06:00,517: Snapshot:1	Epoch:7	Loss:4.495	translation_Loss:2.472	token_training_loss:0.0	distillation_Loss:2.023                                                   	MRR:16.73	Hits@10:32.7	Best:17.21
2025-01-06 22:06:10,413: Snapshot:1	Epoch:8	Loss:34.622	translation_Loss:19.442	token_training_loss:15.18	distillation_Loss:0.0                                                   	MRR:16.73	Hits@10:32.7	Best:17.21
2025-01-06 22:06:20,698: End of token training: 1 Epoch: 9 Loss:19.531 MRR:16.73 Best Results: 17.21
2025-01-06 22:06:20,698: Snapshot:1	Epoch:9	Loss:19.531	translation_Loss:19.424	token_training_loss:0.107	distillation_Loss:0.0                                                           	MRR:16.73	Hits@10:32.7	Best:17.21
2025-01-06 22:06:21,027: => loading checkpoint './checkpoint/RELATION/1model_best.tar'
2025-01-06 22:06:30,487: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2503 | 0.1416 | 0.3126 | 0.378  |  0.4512 |
|     1      | 0.1736 | 0.0894 | 0.2084 | 0.2641 |  0.3337 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:06:45,867: Snapshot:2	Epoch:0	Loss:13.669	translation_Loss:11.872	token_training_loss:0.0	distillation_Loss:1.798                                                   	MRR:10.92	Hits@10:26.39	Best:10.92
2025-01-06 22:06:53,414: Snapshot:2	Epoch:1	Loss:7.734	translation_Loss:5.152	token_training_loss:0.0	distillation_Loss:2.582                                                   	MRR:17.99	Hits@10:34.93	Best:17.99
2025-01-06 22:07:01,311: Snapshot:2	Epoch:2	Loss:5.429	translation_Loss:3.451	token_training_loss:0.0	distillation_Loss:1.977                                                   	MRR:19.83	Hits@10:35.75	Best:19.83
2025-01-06 22:07:08,904: Snapshot:2	Epoch:3	Loss:4.293	translation_Loss:2.676	token_training_loss:0.0	distillation_Loss:1.617                                                   	MRR:21.07	Hits@10:36.99	Best:21.07
2025-01-06 22:07:16,876: Snapshot:2	Epoch:4	Loss:3.695	translation_Loss:2.319	token_training_loss:0.0	distillation_Loss:1.376                                                   	MRR:21.37	Hits@10:37.27	Best:21.37
2025-01-06 22:07:24,465: Snapshot:2	Epoch:5	Loss:3.404	translation_Loss:2.161	token_training_loss:0.0	distillation_Loss:1.243                                                   	MRR:21.33	Hits@10:37.13	Best:21.37
2025-01-06 22:07:32,408: Snapshot:2	Epoch:6	Loss:3.254	translation_Loss:2.085	token_training_loss:0.0	distillation_Loss:1.169                                                   	MRR:21.15	Hits@10:36.73	Best:21.37
2025-01-06 22:07:39,844: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 21.37
2025-01-06 22:07:39,844: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:3.181 MRR:21.25 Best Results: 21.37
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:07:39,844: Snapshot:2	Epoch:7	Loss:3.181	translation_Loss:2.045	token_training_loss:0.0	distillation_Loss:1.136                                                   	MRR:21.25	Hits@10:36.76	Best:21.37
2025-01-06 22:07:47,125: Snapshot:2	Epoch:8	Loss:30.095	translation_Loss:14.996	token_training_loss:15.099	distillation_Loss:0.0                                                   	MRR:21.25	Hits@10:36.76	Best:21.37
2025-01-06 22:07:54,888: End of token training: 2 Epoch: 9 Loss:15.28 MRR:21.25 Best Results: 21.37
2025-01-06 22:07:54,888: Snapshot:2	Epoch:9	Loss:15.28	translation_Loss:14.99	token_training_loss:0.29	distillation_Loss:0.0                                                           	MRR:21.25	Hits@10:36.76	Best:21.37
2025-01-06 22:07:55,167: => loading checkpoint './checkpoint/RELATION/2model_best.tar'
2025-01-06 22:08:07,943: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2173 | 0.1177 | 0.274  | 0.3353 |  0.4017 |
|     1      | 0.1611 | 0.0785 | 0.1944 | 0.2477 |  0.316  |
|     2      | 0.2106 | 0.1298 | 0.2375 | 0.2929 |  0.3719 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:08:17,816: Snapshot:3	Epoch:0	Loss:6.944	translation_Loss:6.251	token_training_loss:0.0	distillation_Loss:0.693                                                   	MRR:6.2	Hits@10:14.84	Best:6.2
2025-01-06 22:08:21,333: Snapshot:3	Epoch:1	Loss:4.992	translation_Loss:4.29	token_training_loss:0.0	distillation_Loss:0.702                                                   	MRR:13.56	Hits@10:28.91	Best:13.56
2025-01-06 22:08:24,857: Snapshot:3	Epoch:2	Loss:3.689	translation_Loss:3.086	token_training_loss:0.0	distillation_Loss:0.603                                                   	MRR:17.18	Hits@10:33.78	Best:17.18
2025-01-06 22:08:28,323: Snapshot:3	Epoch:3	Loss:2.929	translation_Loss:2.409	token_training_loss:0.0	distillation_Loss:0.52                                                   	MRR:20.37	Hits@10:35.83	Best:20.37
2025-01-06 22:08:31,812: Snapshot:3	Epoch:4	Loss:2.503	translation_Loss:2.028	token_training_loss:0.0	distillation_Loss:0.475                                                   	MRR:22.05	Hits@10:37.63	Best:22.05
2025-01-06 22:08:35,324: Snapshot:3	Epoch:5	Loss:2.213	translation_Loss:1.781	token_training_loss:0.0	distillation_Loss:0.432                                                   	MRR:23.28	Hits@10:38.23	Best:23.28
2025-01-06 22:08:39,258: Snapshot:3	Epoch:6	Loss:1.989	translation_Loss:1.592	token_training_loss:0.0	distillation_Loss:0.397                                                   	MRR:23.87	Hits@10:38.61	Best:23.87
2025-01-06 22:08:42,830: Snapshot:3	Epoch:7	Loss:1.829	translation_Loss:1.461	token_training_loss:0.0	distillation_Loss:0.367                                                   	MRR:24.26	Hits@10:38.95	Best:24.26
2025-01-06 22:08:46,324: Snapshot:3	Epoch:8	Loss:1.711	translation_Loss:1.368	token_training_loss:0.0	distillation_Loss:0.343                                                   	MRR:24.74	Hits@10:39.3	Best:24.74
2025-01-06 22:08:49,855: Snapshot:3	Epoch:9	Loss:1.627	translation_Loss:1.301	token_training_loss:0.0	distillation_Loss:0.326                                                   	MRR:25.13	Hits@10:39.37	Best:25.13
2025-01-06 22:08:53,371: Snapshot:3	Epoch:10	Loss:1.566	translation_Loss:1.253	token_training_loss:0.0	distillation_Loss:0.313                                                   	MRR:25.41	Hits@10:39.45	Best:25.41
2025-01-06 22:08:57,282: Snapshot:3	Epoch:11	Loss:1.522	translation_Loss:1.215	token_training_loss:0.0	distillation_Loss:0.307                                                   	MRR:25.54	Hits@10:39.5	Best:25.54
2025-01-06 22:09:00,820: Snapshot:3	Epoch:12	Loss:1.493	translation_Loss:1.194	token_training_loss:0.0	distillation_Loss:0.299                                                   	MRR:25.76	Hits@10:39.54	Best:25.76
2025-01-06 22:09:04,277: Snapshot:3	Epoch:13	Loss:1.464	translation_Loss:1.167	token_training_loss:0.0	distillation_Loss:0.297                                                   	MRR:25.82	Hits@10:39.64	Best:25.82
2025-01-06 22:09:07,774: Snapshot:3	Epoch:14	Loss:1.449	translation_Loss:1.156	token_training_loss:0.0	distillation_Loss:0.293                                                   	MRR:25.59	Hits@10:39.4	Best:25.82
2025-01-06 22:09:11,165: Snapshot:3	Epoch:15	Loss:1.432	translation_Loss:1.143	token_training_loss:0.0	distillation_Loss:0.289                                                   	MRR:25.74	Hits@10:39.58	Best:25.82
2025-01-06 22:09:14,958: Early Stopping! Snapshot: 3 Epoch: 16 Best Results: 25.82
2025-01-06 22:09:14,958: Start to training tokens! Snapshot: 3 Epoch: 16 Loss:1.423 MRR:25.76 Best Results: 25.82
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:09:14,958: Snapshot:3	Epoch:16	Loss:1.423	translation_Loss:1.135	token_training_loss:0.0	distillation_Loss:0.287                                                   	MRR:25.76	Hits@10:39.49	Best:25.82
2025-01-06 22:09:18,415: Snapshot:3	Epoch:17	Loss:18.726	translation_Loss:5.753	token_training_loss:12.973	distillation_Loss:0.0                                                   	MRR:25.76	Hits@10:39.49	Best:25.82
2025-01-06 22:09:21,820: End of token training: 3 Epoch: 18 Loss:7.231 MRR:25.76 Best Results: 25.82
2025-01-06 22:09:21,820: Snapshot:3	Epoch:18	Loss:7.231	translation_Loss:5.749	token_training_loss:1.482	distillation_Loss:0.0                                                           	MRR:25.76	Hits@10:39.49	Best:25.82
2025-01-06 22:09:22,104: => loading checkpoint './checkpoint/RELATION/3model_best.tar'
2025-01-06 22:09:36,720: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2175 | 0.1184 | 0.2739 | 0.3359 |  0.4015 |
|     1      | 0.1612 | 0.0785 | 0.1945 | 0.2477 |  0.3175 |
|     2      | 0.207  | 0.1251 | 0.2343 | 0.2916 |  0.3704 |
|     3      | 0.2527 | 0.1744 | 0.2857 | 0.3319 |  0.3957 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:09:45,133: Snapshot:4	Epoch:0	Loss:4.619	translation_Loss:4.1	token_training_loss:0.0	distillation_Loss:0.519                                                   	MRR:6.66	Hits@10:18.01	Best:6.66
2025-01-06 22:09:47,589: Snapshot:4	Epoch:1	Loss:3.49	translation_Loss:2.749	token_training_loss:0.0	distillation_Loss:0.741                                                   	MRR:10.71	Hits@10:27.88	Best:10.71
2025-01-06 22:09:50,069: Snapshot:4	Epoch:2	Loss:2.855	translation_Loss:2.108	token_training_loss:0.0	distillation_Loss:0.747                                                   	MRR:14.67	Hits@10:33.93	Best:14.67
2025-01-06 22:09:52,538: Snapshot:4	Epoch:3	Loss:2.393	translation_Loss:1.695	token_training_loss:0.0	distillation_Loss:0.699                                                   	MRR:17.54	Hits@10:36.98	Best:17.54
2025-01-06 22:09:55,086: Snapshot:4	Epoch:4	Loss:2.091	translation_Loss:1.454	token_training_loss:0.0	distillation_Loss:0.638                                                   	MRR:19.6	Hits@10:38.74	Best:19.6
2025-01-06 22:09:57,989: Snapshot:4	Epoch:5	Loss:1.864	translation_Loss:1.265	token_training_loss:0.0	distillation_Loss:0.598                                                   	MRR:20.76	Hits@10:40.28	Best:20.76
2025-01-06 22:10:00,561: Snapshot:4	Epoch:6	Loss:1.688	translation_Loss:1.124	token_training_loss:0.0	distillation_Loss:0.564                                                   	MRR:21.66	Hits@10:41.26	Best:21.66
2025-01-06 22:10:03,181: Snapshot:4	Epoch:7	Loss:1.543	translation_Loss:1.015	token_training_loss:0.0	distillation_Loss:0.529                                                   	MRR:22.18	Hits@10:41.7	Best:22.18
2025-01-06 22:10:05,742: Snapshot:4	Epoch:8	Loss:1.427	translation_Loss:0.925	token_training_loss:0.0	distillation_Loss:0.502                                                   	MRR:22.65	Hits@10:42.29	Best:22.65
2025-01-06 22:10:08,357: Snapshot:4	Epoch:9	Loss:1.343	translation_Loss:0.864	token_training_loss:0.0	distillation_Loss:0.479                                                   	MRR:22.77	Hits@10:42.49	Best:22.77
2025-01-06 22:10:10,861: Snapshot:4	Epoch:10	Loss:1.279	translation_Loss:0.816	token_training_loss:0.0	distillation_Loss:0.463                                                   	MRR:22.83	Hits@10:42.57	Best:22.83
2025-01-06 22:10:13,271: Snapshot:4	Epoch:11	Loss:1.231	translation_Loss:0.781	token_training_loss:0.0	distillation_Loss:0.45                                                   	MRR:22.58	Hits@10:42.71	Best:22.83
2025-01-06 22:10:16,094: Snapshot:4	Epoch:12	Loss:1.184	translation_Loss:0.743	token_training_loss:0.0	distillation_Loss:0.441                                                   	MRR:22.51	Hits@10:42.58	Best:22.83
2025-01-06 22:10:18,489: Early Stopping! Snapshot: 4 Epoch: 13 Best Results: 22.83
2025-01-06 22:10:18,489: Start to training tokens! Snapshot: 4 Epoch: 13 Loss:1.166 MRR:22.66 Best Results: 22.83
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:10:18,489: Snapshot:4	Epoch:13	Loss:1.166	translation_Loss:0.733	token_training_loss:0.0	distillation_Loss:0.433                                                   	MRR:22.66	Hits@10:42.5	Best:22.83
2025-01-06 22:10:20,877: Snapshot:4	Epoch:14	Loss:15.856	translation_Loss:3.992	token_training_loss:11.864	distillation_Loss:0.0                                                   	MRR:22.66	Hits@10:42.5	Best:22.83
2025-01-06 22:10:23,253: End of token training: 4 Epoch: 15 Loss:6.668 MRR:22.66 Best Results: 22.83
2025-01-06 22:10:23,254: Snapshot:4	Epoch:15	Loss:6.668	translation_Loss:4.003	token_training_loss:2.665	distillation_Loss:0.0                                                           	MRR:22.66	Hits@10:42.5	Best:22.83
2025-01-06 22:10:23,533: => loading checkpoint './checkpoint/RELATION/4model_best.tar'
2025-01-06 22:10:39,824: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2154 | 0.1165 | 0.2711 | 0.3331 |  0.3996 |
|     1      | 0.1602 | 0.0779 | 0.1921 | 0.2464 |  0.3161 |
|     2      | 0.1962 | 0.1164 | 0.2215 | 0.2743 |  0.3535 |
|     3      | 0.2471 | 0.1663 | 0.2789 | 0.3293 |  0.3973 |
|     4      | 0.2216 | 0.1266 | 0.241  | 0.3171 |  0.4183 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 22:10:39,826: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2819 | 0.1704 | 0.3478 | 0.4177 |  0.4868 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2503 | 0.1416 | 0.3126 | 0.378  |  0.4512 |
|     1      | 0.1736 | 0.0894 | 0.2084 | 0.2641 |  0.3337 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2173 | 0.1177 | 0.274  | 0.3353 |  0.4017 |
|     1      | 0.1611 | 0.0785 | 0.1944 | 0.2477 |  0.316  |
|     2      | 0.2106 | 0.1298 | 0.2375 | 0.2929 |  0.3719 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2175 | 0.1184 | 0.2739 | 0.3359 |  0.4015 |
|     1      | 0.1612 | 0.0785 | 0.1945 | 0.2477 |  0.3175 |
|     2      | 0.207  | 0.1251 | 0.2343 | 0.2916 |  0.3704 |
|     3      | 0.2527 | 0.1744 | 0.2857 | 0.3319 |  0.3957 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2154 | 0.1165 | 0.2711 | 0.3331 |  0.3996 |
|     1      | 0.1602 | 0.0779 | 0.1921 | 0.2464 |  0.3161 |
|     2      | 0.1962 | 0.1164 | 0.2215 | 0.2743 |  0.3535 |
|     3      | 0.2471 | 0.1663 | 0.2789 | 0.3293 |  0.3973 |
|     4      | 0.2216 | 0.1266 | 0.241  | 0.3171 |  0.4183 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 22:10:39,827: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 139.37803435325623 |   0.282   |     0.17     |    0.348     |     0.487     |
|    1     | 107.50319361686707 |   0.213   |    0.116     |    0.262     |     0.394     |
|    2     |  80.9618468284607  |   0.195   |    0.107     |    0.236     |     0.363     |
|    3     | 72.00748586654663  |   0.201   |    0.113     |     0.24     |     0.367     |
|    4     | 44.79206442832947  |   0.198   |     0.11     |    0.235     |     0.366     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 22:10:39,827: Sum_Training_Time:444.6426250934601
2025-01-06 22:10:39,827: Every_Training_Time:[139.37803435325623, 107.50319361686707, 80.9618468284607, 72.00748586654663, 44.79206442832947]
2025-01-06 22:10:39,827: Forward transfer: 0.015524999999999999 Backward transfer: -0.02497499999999999
2025-01-06 22:10:59,894: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106221044/RELATION', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=2222, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATION', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[3000.0, 15000.0, 80000.0, 80000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 22:11:15,217: Snapshot:0	Epoch:0	Loss:24.085	translation_Loss:24.085	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:11.08	Hits@10:26.25	Best:11.08
2025-01-06 22:11:26,614: Snapshot:0	Epoch:1	Loss:14.914	translation_Loss:14.914	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.87	Hits@10:39.79	Best:18.87
2025-01-06 22:11:38,018: Snapshot:0	Epoch:2	Loss:8.699	translation_Loss:8.699	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.59	Hits@10:44.59	Best:23.59
2025-01-06 22:11:48,889: Snapshot:0	Epoch:3	Loss:4.949	translation_Loss:4.949	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.92	Hits@10:46.44	Best:25.92
2025-01-06 22:12:00,114: Snapshot:0	Epoch:4	Loss:2.912	translation_Loss:2.912	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.87	Hits@10:47.36	Best:26.87
2025-01-06 22:12:11,361: Snapshot:0	Epoch:5	Loss:1.938	translation_Loss:1.938	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.22	Hits@10:47.78	Best:27.22
2025-01-06 22:12:22,361: Snapshot:0	Epoch:6	Loss:1.434	translation_Loss:1.434	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.31	Hits@10:47.81	Best:27.31
2025-01-06 22:12:33,761: Snapshot:0	Epoch:7	Loss:1.158	translation_Loss:1.158	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.2	Hits@10:47.95	Best:27.31
2025-01-06 22:12:44,961: Snapshot:0	Epoch:8	Loss:0.985	translation_Loss:0.985	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.29	Hits@10:47.66	Best:27.31
2025-01-06 22:12:55,837: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 27.31
2025-01-06 22:12:55,838: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.89 MRR:27.28 Best Results: 27.31
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:12:55,838: Snapshot:0	Epoch:9	Loss:0.89	translation_Loss:0.89	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.28	Hits@10:47.52	Best:27.31
2025-01-06 22:13:07,582: Snapshot:0	Epoch:10	Loss:31.563	translation_Loss:16.561	token_training_loss:15.003	distillation_Loss:0.0                                                   	MRR:27.28	Hits@10:47.52	Best:27.31
2025-01-06 22:13:18,473: End of token training: 0 Epoch: 11 Loss:16.665 MRR:27.28 Best Results: 27.31
2025-01-06 22:13:18,473: Snapshot:0	Epoch:11	Loss:16.665	translation_Loss:16.576	token_training_loss:0.088	distillation_Loss:0.0                                                           	MRR:27.28	Hits@10:47.52	Best:27.31
2025-01-06 22:13:18,765: => loading checkpoint './checkpoint/RELATION/0model_best.tar'
2025-01-06 22:13:24,216: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2762 | 0.1643 | 0.3417 | 0.4097 |  0.4827 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:13:42,672: Snapshot:1	Epoch:0	Loss:20.199	translation_Loss:18.972	token_training_loss:0.0	distillation_Loss:1.226                                                   	MRR:10.45	Hits@10:24.93	Best:10.45
2025-01-06 22:13:53,165: Snapshot:1	Epoch:1	Loss:10.628	translation_Loss:8.384	token_training_loss:0.0	distillation_Loss:2.244                                                   	MRR:16.41	Hits@10:32.56	Best:16.41
2025-01-06 22:14:03,542: Snapshot:1	Epoch:2	Loss:6.823	translation_Loss:4.382	token_training_loss:0.0	distillation_Loss:2.441                                                   	MRR:17.25	Hits@10:33.44	Best:17.25
2025-01-06 22:14:13,576: Snapshot:1	Epoch:3	Loss:5.41	translation_Loss:3.112	token_training_loss:0.0	distillation_Loss:2.298                                                   	MRR:17.55	Hits@10:33.72	Best:17.55
2025-01-06 22:14:23,998: Snapshot:1	Epoch:4	Loss:4.868	translation_Loss:2.707	token_training_loss:0.0	distillation_Loss:2.161                                                   	MRR:17.11	Hits@10:33.06	Best:17.55
2025-01-06 22:14:34,386: Snapshot:1	Epoch:5	Loss:4.642	translation_Loss:2.568	token_training_loss:0.0	distillation_Loss:2.074                                                   	MRR:17.0	Hits@10:32.95	Best:17.55
2025-01-06 22:14:44,271: Early Stopping! Snapshot: 1 Epoch: 6 Best Results: 17.55
2025-01-06 22:14:44,272: Start to training tokens! Snapshot: 1 Epoch: 6 Loss:4.549 MRR:16.98 Best Results: 17.55
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:14:44,272: Snapshot:1	Epoch:6	Loss:4.549	translation_Loss:2.509	token_training_loss:0.0	distillation_Loss:2.04                                                   	MRR:16.98	Hits@10:32.85	Best:17.55
2025-01-06 22:14:54,448: Snapshot:1	Epoch:7	Loss:34.303	translation_Loss:19.27	token_training_loss:15.034	distillation_Loss:0.0                                                   	MRR:16.98	Hits@10:32.85	Best:17.55
2025-01-06 22:15:04,311: End of token training: 1 Epoch: 8 Loss:19.382 MRR:16.98 Best Results: 17.55
2025-01-06 22:15:04,312: Snapshot:1	Epoch:8	Loss:19.382	translation_Loss:19.276	token_training_loss:0.106	distillation_Loss:0.0                                                           	MRR:16.98	Hits@10:32.85	Best:17.55
2025-01-06 22:15:04,625: => loading checkpoint './checkpoint/RELATION/1model_best.tar'
2025-01-06 22:15:14,338: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2408 | 0.1325 | 0.3004 | 0.3682 |  0.4429 |
|     1      | 0.1743 | 0.0905 | 0.2077 | 0.2633 |  0.336  |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:15:29,428: Snapshot:2	Epoch:0	Loss:13.497	translation_Loss:11.688	token_training_loss:0.0	distillation_Loss:1.809                                                   	MRR:12.54	Hits@10:29.08	Best:12.54
2025-01-06 22:15:37,342: Snapshot:2	Epoch:1	Loss:7.535	translation_Loss:4.95	token_training_loss:0.0	distillation_Loss:2.585                                                   	MRR:19.33	Hits@10:36.17	Best:19.33
2025-01-06 22:15:44,790: Snapshot:2	Epoch:2	Loss:5.363	translation_Loss:3.39	token_training_loss:0.0	distillation_Loss:1.973                                                   	MRR:20.49	Hits@10:36.93	Best:20.49
2025-01-06 22:15:52,419: Snapshot:2	Epoch:3	Loss:4.3	translation_Loss:2.673	token_training_loss:0.0	distillation_Loss:1.627                                                   	MRR:21.26	Hits@10:37.05	Best:21.26
2025-01-06 22:16:00,284: Snapshot:2	Epoch:4	Loss:3.72	translation_Loss:2.33	token_training_loss:0.0	distillation_Loss:1.39                                                   	MRR:21.4	Hits@10:37.31	Best:21.4
2025-01-06 22:16:07,744: Snapshot:2	Epoch:5	Loss:3.438	translation_Loss:2.18	token_training_loss:0.0	distillation_Loss:1.258                                                   	MRR:21.44	Hits@10:37.14	Best:21.44
2025-01-06 22:16:15,686: Snapshot:2	Epoch:6	Loss:3.273	translation_Loss:2.089	token_training_loss:0.0	distillation_Loss:1.183                                                   	MRR:21.59	Hits@10:36.86	Best:21.59
2025-01-06 22:16:23,187: Snapshot:2	Epoch:7	Loss:3.192	translation_Loss:2.048	token_training_loss:0.0	distillation_Loss:1.144                                                   	MRR:21.62	Hits@10:36.99	Best:21.62
2025-01-06 22:16:31,030: Snapshot:2	Epoch:8	Loss:3.147	translation_Loss:2.023	token_training_loss:0.0	distillation_Loss:1.123                                                   	MRR:21.24	Hits@10:36.86	Best:21.62
2025-01-06 22:16:38,446: Snapshot:2	Epoch:9	Loss:3.131	translation_Loss:2.015	token_training_loss:0.0	distillation_Loss:1.115                                                   	MRR:21.27	Hits@10:36.72	Best:21.62
2025-01-06 22:16:46,170: Early Stopping! Snapshot: 2 Epoch: 10 Best Results: 21.62
2025-01-06 22:16:46,172: Start to training tokens! Snapshot: 2 Epoch: 10 Loss:3.093 MRR:21.11 Best Results: 21.62
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:16:46,172: Snapshot:2	Epoch:10	Loss:3.093	translation_Loss:1.989	token_training_loss:0.0	distillation_Loss:1.104                                                   	MRR:21.11	Hits@10:36.31	Best:21.62
2025-01-06 22:16:53,467: Snapshot:2	Epoch:11	Loss:30.492	translation_Loss:14.76	token_training_loss:15.731	distillation_Loss:0.0                                                   	MRR:21.11	Hits@10:36.31	Best:21.62
2025-01-06 22:17:00,765: End of token training: 2 Epoch: 12 Loss:15.06 MRR:21.11 Best Results: 21.62
2025-01-06 22:17:00,766: Snapshot:2	Epoch:12	Loss:15.06	translation_Loss:14.753	token_training_loss:0.307	distillation_Loss:0.0                                                           	MRR:21.11	Hits@10:36.31	Best:21.62
2025-01-06 22:17:01,058: => loading checkpoint './checkpoint/RELATION/2model_best.tar'
2025-01-06 22:17:14,319: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2126 | 0.1122 | 0.266  |  0.33  |  0.401  |
|     1      | 0.1659 | 0.0812 | 0.1996 | 0.2549 |  0.3279 |
|     2      | 0.2127 | 0.1348 | 0.2366 | 0.2896 |  0.3677 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:17:23,844: Snapshot:3	Epoch:0	Loss:6.844	translation_Loss:6.149	token_training_loss:0.0	distillation_Loss:0.695                                                   	MRR:6.35	Hits@10:15.5	Best:6.35
2025-01-06 22:17:27,297: Snapshot:3	Epoch:1	Loss:4.939	translation_Loss:4.225	token_training_loss:0.0	distillation_Loss:0.714                                                   	MRR:13.53	Hits@10:30.66	Best:13.53
2025-01-06 22:17:30,777: Snapshot:3	Epoch:2	Loss:3.661	translation_Loss:3.057	token_training_loss:0.0	distillation_Loss:0.604                                                   	MRR:16.6	Hits@10:34.57	Best:16.6
2025-01-06 22:17:34,272: Snapshot:3	Epoch:3	Loss:2.939	translation_Loss:2.419	token_training_loss:0.0	distillation_Loss:0.519                                                   	MRR:19.56	Hits@10:36.47	Best:19.56
2025-01-06 22:17:38,162: Snapshot:3	Epoch:4	Loss:2.505	translation_Loss:2.038	token_training_loss:0.0	distillation_Loss:0.466                                                   	MRR:21.55	Hits@10:37.94	Best:21.55
2025-01-06 22:17:41,688: Snapshot:3	Epoch:5	Loss:2.219	translation_Loss:1.794	token_training_loss:0.0	distillation_Loss:0.426                                                   	MRR:22.71	Hits@10:38.85	Best:22.71
2025-01-06 22:17:45,176: Snapshot:3	Epoch:6	Loss:2.004	translation_Loss:1.616	token_training_loss:0.0	distillation_Loss:0.388                                                   	MRR:23.52	Hits@10:39.27	Best:23.52
2025-01-06 22:17:48,617: Snapshot:3	Epoch:7	Loss:1.843	translation_Loss:1.481	token_training_loss:0.0	distillation_Loss:0.362                                                   	MRR:24.01	Hits@10:39.45	Best:24.01
2025-01-06 22:17:52,504: Snapshot:3	Epoch:8	Loss:1.728	translation_Loss:1.389	token_training_loss:0.0	distillation_Loss:0.339                                                   	MRR:24.52	Hits@10:39.24	Best:24.52
2025-01-06 22:17:55,996: Snapshot:3	Epoch:9	Loss:1.644	translation_Loss:1.322	token_training_loss:0.0	distillation_Loss:0.323                                                   	MRR:24.88	Hits@10:39.22	Best:24.88
2025-01-06 22:17:59,492: Snapshot:3	Epoch:10	Loss:1.579	translation_Loss:1.27	token_training_loss:0.0	distillation_Loss:0.308                                                   	MRR:24.95	Hits@10:39.23	Best:24.95
2025-01-06 22:18:02,901: Snapshot:3	Epoch:11	Loss:1.532	translation_Loss:1.231	token_training_loss:0.0	distillation_Loss:0.301                                                   	MRR:24.94	Hits@10:39.25	Best:24.95
2025-01-06 22:18:06,350: Snapshot:3	Epoch:12	Loss:1.498	translation_Loss:1.203	token_training_loss:0.0	distillation_Loss:0.294                                                   	MRR:25.07	Hits@10:39.13	Best:25.07
2025-01-06 22:18:09,897: Snapshot:3	Epoch:13	Loss:1.483	translation_Loss:1.191	token_training_loss:0.0	distillation_Loss:0.292                                                   	MRR:25.21	Hits@10:39.29	Best:25.21
2025-01-06 22:18:13,759: Snapshot:3	Epoch:14	Loss:1.459	translation_Loss:1.172	token_training_loss:0.0	distillation_Loss:0.288                                                   	MRR:25.36	Hits@10:39.21	Best:25.36
2025-01-06 22:18:17,246: Snapshot:3	Epoch:15	Loss:1.444	translation_Loss:1.158	token_training_loss:0.0	distillation_Loss:0.286                                                   	MRR:25.23	Hits@10:39.1	Best:25.36
2025-01-06 22:18:20,669: Snapshot:3	Epoch:16	Loss:1.431	translation_Loss:1.149	token_training_loss:0.0	distillation_Loss:0.282                                                   	MRR:25.25	Hits@10:39.19	Best:25.36
2025-01-06 22:18:24,104: Early Stopping! Snapshot: 3 Epoch: 17 Best Results: 25.36
2025-01-06 22:18:24,104: Start to training tokens! Snapshot: 3 Epoch: 17 Loss:1.422 MRR:25.03 Best Results: 25.36
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:18:24,105: Snapshot:3	Epoch:17	Loss:1.422	translation_Loss:1.142	token_training_loss:0.0	distillation_Loss:0.28                                                   	MRR:25.03	Hits@10:39.15	Best:25.36
2025-01-06 22:18:27,888: Snapshot:3	Epoch:18	Loss:18.704	translation_Loss:5.804	token_training_loss:12.9	distillation_Loss:0.0                                                   	MRR:25.03	Hits@10:39.15	Best:25.36
2025-01-06 22:18:31,237: End of token training: 3 Epoch: 19 Loss:7.258 MRR:25.03 Best Results: 25.36
2025-01-06 22:18:31,237: Snapshot:3	Epoch:19	Loss:7.258	translation_Loss:5.788	token_training_loss:1.47	distillation_Loss:0.0                                                           	MRR:25.03	Hits@10:39.15	Best:25.36
2025-01-06 22:18:31,531: => loading checkpoint './checkpoint/RELATION/3model_best.tar'
2025-01-06 22:18:46,407: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2133 | 0.1124 | 0.2667 | 0.3315 |  0.4038 |
|     1      | 0.1661 | 0.0806 | 0.2005 | 0.2576 |  0.3312 |
|     2      | 0.202  | 0.1228 | 0.2251 | 0.2799 |  0.3628 |
|     3      | 0.2529 | 0.175  | 0.2872 | 0.3325 |  0.3926 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:18:54,488: Snapshot:4	Epoch:0	Loss:4.657	translation_Loss:4.135	token_training_loss:0.0	distillation_Loss:0.522                                                   	MRR:6.09	Hits@10:17.21	Best:6.09
2025-01-06 22:18:56,989: Snapshot:4	Epoch:1	Loss:3.538	translation_Loss:2.78	token_training_loss:0.0	distillation_Loss:0.758                                                   	MRR:10.71	Hits@10:27.96	Best:10.71
2025-01-06 22:18:59,446: Snapshot:4	Epoch:2	Loss:2.909	translation_Loss:2.149	token_training_loss:0.0	distillation_Loss:0.759                                                   	MRR:14.0	Hits@10:33.97	Best:14.0
2025-01-06 22:19:01,922: Snapshot:4	Epoch:3	Loss:2.438	translation_Loss:1.736	token_training_loss:0.0	distillation_Loss:0.701                                                   	MRR:17.76	Hits@10:37.22	Best:17.76
2025-01-06 22:19:04,414: Snapshot:4	Epoch:4	Loss:2.122	translation_Loss:1.477	token_training_loss:0.0	distillation_Loss:0.645                                                   	MRR:19.51	Hits@10:39.38	Best:19.51
2025-01-06 22:19:07,248: Snapshot:4	Epoch:5	Loss:1.888	translation_Loss:1.286	token_training_loss:0.0	distillation_Loss:0.602                                                   	MRR:20.75	Hits@10:40.56	Best:20.75
2025-01-06 22:19:09,707: Snapshot:4	Epoch:6	Loss:1.713	translation_Loss:1.15	token_training_loss:0.0	distillation_Loss:0.563                                                   	MRR:21.79	Hits@10:41.56	Best:21.79
2025-01-06 22:19:12,177: Snapshot:4	Epoch:7	Loss:1.571	translation_Loss:1.039	token_training_loss:0.0	distillation_Loss:0.533                                                   	MRR:22.47	Hits@10:42.24	Best:22.47
2025-01-06 22:19:14,651: Snapshot:4	Epoch:8	Loss:1.456	translation_Loss:0.95	token_training_loss:0.0	distillation_Loss:0.506                                                   	MRR:22.86	Hits@10:42.46	Best:22.86
2025-01-06 22:19:17,112: Snapshot:4	Epoch:9	Loss:1.37	translation_Loss:0.884	token_training_loss:0.0	distillation_Loss:0.486                                                   	MRR:22.86	Hits@10:42.3	Best:22.86
2025-01-06 22:19:19,565: Snapshot:4	Epoch:10	Loss:1.309	translation_Loss:0.841	token_training_loss:0.0	distillation_Loss:0.467                                                   	MRR:23.12	Hits@10:42.67	Best:23.12
2025-01-06 22:19:21,991: Snapshot:4	Epoch:11	Loss:1.253	translation_Loss:0.798	token_training_loss:0.0	distillation_Loss:0.455                                                   	MRR:23.09	Hits@10:42.65	Best:23.12
2025-01-06 22:19:24,784: Snapshot:4	Epoch:12	Loss:1.214	translation_Loss:0.769	token_training_loss:0.0	distillation_Loss:0.445                                                   	MRR:22.7	Hits@10:42.31	Best:23.12
2025-01-06 22:19:27,160: Early Stopping! Snapshot: 4 Epoch: 13 Best Results: 23.12
2025-01-06 22:19:27,160: Start to training tokens! Snapshot: 4 Epoch: 13 Loss:1.182 MRR:22.66 Best Results: 23.12
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:19:27,161: Snapshot:4	Epoch:13	Loss:1.182	translation_Loss:0.743	token_training_loss:0.0	distillation_Loss:0.438                                                   	MRR:22.66	Hits@10:42.61	Best:23.12
2025-01-06 22:19:29,513: Snapshot:4	Epoch:14	Loss:14.807	translation_Loss:3.947	token_training_loss:10.86	distillation_Loss:0.0                                                   	MRR:22.66	Hits@10:42.61	Best:23.12
2025-01-06 22:19:31,928: End of token training: 4 Epoch: 15 Loss:6.119 MRR:22.66 Best Results: 23.12
2025-01-06 22:19:31,928: Snapshot:4	Epoch:15	Loss:6.119	translation_Loss:3.956	token_training_loss:2.163	distillation_Loss:0.0                                                           	MRR:22.66	Hits@10:42.61	Best:23.12
2025-01-06 22:19:32,246: => loading checkpoint './checkpoint/RELATION/4model_best.tar'
2025-01-06 22:19:48,600: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2098 | 0.1109 | 0.2626 | 0.3247 |  0.3962 |
|     1      | 0.1652 | 0.0807 | 0.1986 | 0.2541 |  0.3268 |
|     2      | 0.1953 |  0.12  | 0.2167 | 0.2692 |  0.3447 |
|     3      | 0.2466 | 0.169  | 0.2748 | 0.323  |  0.3924 |
|     4      | 0.2258 | 0.1282 | 0.2508 | 0.3233 |  0.4248 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 22:19:48,602: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2762 | 0.1643 | 0.3417 | 0.4097 |  0.4827 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2408 | 0.1325 | 0.3004 | 0.3682 |  0.4429 |
|     1      | 0.1743 | 0.0905 | 0.2077 | 0.2633 |  0.336  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2126 | 0.1122 | 0.266  |  0.33  |  0.401  |
|     1      | 0.1659 | 0.0812 | 0.1996 | 0.2549 |  0.3279 |
|     2      | 0.2127 | 0.1348 | 0.2366 | 0.2896 |  0.3677 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2133 | 0.1124 | 0.2667 | 0.3315 |  0.4038 |
|     1      | 0.1661 | 0.0806 | 0.2005 | 0.2576 |  0.3312 |
|     2      | 0.202  | 0.1228 | 0.2251 | 0.2799 |  0.3628 |
|     3      | 0.2529 | 0.175  | 0.2872 | 0.3325 |  0.3926 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2098 | 0.1109 | 0.2626 | 0.3247 |  0.3962 |
|     1      | 0.1652 | 0.0807 | 0.1986 | 0.2541 |  0.3268 |
|     2      | 0.1953 |  0.12  | 0.2167 | 0.2692 |  0.3447 |
|     3      | 0.2466 | 0.169  | 0.2748 | 0.323  |  0.3924 |
|     4      | 0.2258 | 0.1282 | 0.2508 | 0.3233 |  0.4248 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 22:19:48,603: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 138.57855415344238 |   0.276   |    0.164     |    0.342     |     0.483     |
|    1     | 95.85050678253174  |   0.208   |    0.112     |    0.255     |     0.391     |
|    2     | 102.95276141166687 |   0.196   |    0.107     |    0.234     |     0.366     |
|    3     | 75.34785914421082  |    0.2    |    0.111     |    0.238     |      0.37     |
|    4     | 44.054965019226074 |   0.198   |    0.111     |    0.234     |     0.366     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 22:19:48,603: Sum_Training_Time:456.7846465110779
2025-01-06 22:19:48,603: Every_Training_Time:[138.57855415344238, 95.85050678253174, 102.95276141166687, 75.34785914421082, 44.054965019226074]
2025-01-06 22:19:48,603: Forward transfer: 0.015775 Backward transfer: -0.024800000000000003
2025-01-06 22:20:09,194: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106221953/RELATION', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3333, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATION', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[3000.0, 15000.0, 80000.0, 80000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 22:20:24,489: Snapshot:0	Epoch:0	Loss:24.114	translation_Loss:24.114	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:11.15	Hits@10:26.79	Best:11.15
2025-01-06 22:20:35,721: Snapshot:0	Epoch:1	Loss:14.854	translation_Loss:14.854	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:19.07	Hits@10:40.79	Best:19.07
2025-01-06 22:20:47,026: Snapshot:0	Epoch:2	Loss:8.505	translation_Loss:8.505	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.83	Hits@10:45.2	Best:23.83
2025-01-06 22:20:57,863: Snapshot:0	Epoch:3	Loss:4.715	translation_Loss:4.715	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.08	Hits@10:46.84	Best:26.08
2025-01-06 22:21:09,047: Snapshot:0	Epoch:4	Loss:2.73	translation_Loss:2.73	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.97	Hits@10:47.73	Best:26.97
2025-01-06 22:21:20,244: Snapshot:0	Epoch:5	Loss:1.799	translation_Loss:1.799	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.32	Hits@10:47.82	Best:27.32
2025-01-06 22:21:30,985: Snapshot:0	Epoch:6	Loss:1.34	translation_Loss:1.34	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.42	Hits@10:47.83	Best:27.42
2025-01-06 22:21:42,221: Snapshot:0	Epoch:7	Loss:1.096	translation_Loss:1.096	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.4	Hits@10:47.79	Best:27.42
