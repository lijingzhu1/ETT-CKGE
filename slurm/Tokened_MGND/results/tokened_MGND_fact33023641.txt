2024-12-29 23:17:08,134: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229231635/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[500.0, 15000.0, 10000.0, 10000.0], token_num=2, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 23:17:17,288: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:6.23	Hits@10:13.26	Best:6.23
2024-12-29 23:17:23,674: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.68	Hits@10:22.6	Best:9.68
2024-12-29 23:17:29,614: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.9	Hits@10:28.89	Best:12.9
2024-12-29 23:17:35,935: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.76	Hits@10:33.12	Best:15.76
2024-12-29 23:17:41,898: Snapshot:0	Epoch:4	Loss:4.364	translation_Loss:4.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.32	Hits@10:36.0	Best:18.32
2024-12-29 23:17:47,887: Snapshot:0	Epoch:5	Loss:3.084	translation_Loss:3.084	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.44	Hits@10:37.71	Best:20.44
2024-12-29 23:17:54,311: Snapshot:0	Epoch:6	Loss:2.175	translation_Loss:2.175	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.95	Hits@10:38.75	Best:21.95
2024-12-29 23:18:00,264: Snapshot:0	Epoch:7	Loss:1.541	translation_Loss:1.541	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.99	Hits@10:39.41	Best:22.99
2024-12-29 23:18:06,629: Snapshot:0	Epoch:8	Loss:1.095	translation_Loss:1.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.75	Hits@10:39.88	Best:23.75
2024-12-29 23:18:12,532: Snapshot:0	Epoch:9	Loss:0.814	translation_Loss:0.814	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.12	Hits@10:40.1	Best:24.12
2024-12-29 23:18:18,489: Snapshot:0	Epoch:10	Loss:0.628	translation_Loss:0.628	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.29	Hits@10:40.22	Best:24.29
2024-12-29 23:18:24,875: Snapshot:0	Epoch:11	Loss:0.494	translation_Loss:0.494	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.4	Hits@10:40.14	Best:24.4
2024-12-29 23:18:30,855: Snapshot:0	Epoch:12	Loss:0.412	translation_Loss:0.412	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.55	Hits@10:40.35	Best:24.55
2024-12-29 23:18:37,187: Snapshot:0	Epoch:13	Loss:0.352	translation_Loss:0.352	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.7	Hits@10:40.29	Best:24.7
2024-12-29 23:18:43,184: Snapshot:0	Epoch:14	Loss:0.311	translation_Loss:0.311	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.74	Hits@10:40.42	Best:24.74
2024-12-29 23:18:49,194: Snapshot:0	Epoch:15	Loss:0.272	translation_Loss:0.272	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.75	Hits@10:40.42	Best:24.75
2024-12-29 23:18:55,526: Snapshot:0	Epoch:16	Loss:0.244	translation_Loss:0.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.77	Hits@10:40.29	Best:24.77
2024-12-29 23:19:01,490: Snapshot:0	Epoch:17	Loss:0.224	translation_Loss:0.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.75	Hits@10:40.44	Best:24.77
2024-12-29 23:19:07,779: Snapshot:0	Epoch:18	Loss:0.206	translation_Loss:0.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.73	Hits@10:40.32	Best:24.77
2024-12-29 23:19:13,740: Early Stopping! Snapshot: 0 Epoch: 19 Best Results: 24.77
2024-12-29 23:19:13,740: Start to training tokens! Snapshot: 0 Epoch: 19 Loss:0.193 MRR:24.75 Best Results: 24.77
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-29 23:19:13,740: Snapshot:0	Epoch:19	Loss:0.193	translation_Loss:0.193	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.75	Hits@10:40.32	Best:24.77
2024-12-29 23:19:20,604: Snapshot:0	Epoch:20	Loss:22.763	translation_Loss:12.307	multi_layer_Loss:10.456	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.75	Hits@10:40.32	Best:24.77
2024-12-29 23:19:26,542: End of token training: 0 Epoch: 21 Loss:12.577 MRR:24.75 Best Results: 24.77
2024-12-29 23:19:26,542: Snapshot:0	Epoch:21	Loss:12.577	translation_Loss:12.297	multi_layer_Loss:0.281	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.75	Hits@10:40.32	Best:24.77
2024-12-29 23:19:26,798: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2024-12-29 23:19:29,516: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2394 | 0.1537 | 0.2821 | 0.3317 |  0.3923 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:19:52,067: Snapshot:1	Epoch:0	Loss:7.287	translation_Loss:7.129	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.158                                                   	MRR:20.91	Hits@10:34.86	Best:20.91
2024-12-29 23:19:58,445: Snapshot:1	Epoch:1	Loss:3.33	translation_Loss:2.966	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.364                                                   	MRR:22.7	Hits@10:37.23	Best:22.7
2024-12-29 23:20:05,340: Snapshot:1	Epoch:2	Loss:1.83	translation_Loss:1.348	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.482                                                   	MRR:23.34	Hits@10:38.15	Best:23.34
2024-12-29 23:20:11,816: Snapshot:1	Epoch:3	Loss:1.306	translation_Loss:0.764	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.542                                                   	MRR:23.37	Hits@10:38.32	Best:23.37
2024-12-29 23:20:18,253: Snapshot:1	Epoch:4	Loss:1.135	translation_Loss:0.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.564                                                   	MRR:23.4	Hits@10:38.38	Best:23.4
2024-12-29 23:20:24,961: Snapshot:1	Epoch:5	Loss:1.055	translation_Loss:0.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.575                                                   	MRR:23.25	Hits@10:38.27	Best:23.4
2024-12-29 23:20:31,305: Snapshot:1	Epoch:6	Loss:1.014	translation_Loss:0.431	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.583                                                   	MRR:23.3	Hits@10:38.12	Best:23.4
2024-12-29 23:20:38,071: Early Stopping! Snapshot: 1 Epoch: 7 Best Results: 23.4
2024-12-29 23:20:38,071: Start to training tokens! Snapshot: 1 Epoch: 7 Loss:0.986 MRR:23.11 Best Results: 23.4
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-29 23:20:38,071: Snapshot:1	Epoch:7	Loss:0.986	translation_Loss:0.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.587                                                   	MRR:23.11	Hits@10:38.17	Best:23.4
2024-12-29 23:20:44,343: Snapshot:1	Epoch:8	Loss:23.215	translation_Loss:12.931	multi_layer_Loss:10.285	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.11	Hits@10:38.17	Best:23.4
2024-12-29 23:20:50,762: End of token training: 1 Epoch: 9 Loss:13.232 MRR:23.11 Best Results: 23.4
2024-12-29 23:20:50,762: Snapshot:1	Epoch:9	Loss:13.232	translation_Loss:12.939	multi_layer_Loss:0.293	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.11	Hits@10:38.17	Best:23.4
2024-12-29 23:20:51,090: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2024-12-29 23:20:57,337: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2396 | 0.1532 | 0.2764 | 0.3304 |  0.4045 |
|     1      | 0.2344 | 0.1531 | 0.2726 | 0.322  |  0.3822 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:21:20,289: Snapshot:2	Epoch:0	Loss:4.658	translation_Loss:3.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.943                                                   	MRR:21.85	Hits@10:37.93	Best:21.85
2024-12-29 23:21:26,812: Snapshot:2	Epoch:1	Loss:3.218	translation_Loss:1.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.232                                                   	MRR:22.25	Hits@10:38.19	Best:22.25
2024-12-29 23:21:33,351: Snapshot:2	Epoch:2	Loss:3.044	translation_Loss:1.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.123                                                   	MRR:22.37	Hits@10:38.51	Best:22.37
2024-12-29 23:21:39,898: Snapshot:2	Epoch:3	Loss:2.907	translation_Loss:1.768	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.139                                                   	MRR:22.38	Hits@10:38.48	Best:22.38
2024-12-29 23:21:46,333: Snapshot:2	Epoch:4	Loss:2.927	translation_Loss:1.792	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.135                                                   	MRR:22.4	Hits@10:38.55	Best:22.4
2024-12-29 23:21:52,793: Snapshot:2	Epoch:5	Loss:2.889	translation_Loss:1.748	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.14                                                   	MRR:22.45	Hits@10:38.43	Best:22.45
2024-12-29 23:21:59,725: Snapshot:2	Epoch:6	Loss:2.897	translation_Loss:1.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.139                                                   	MRR:22.38	Hits@10:38.44	Best:22.45
2024-12-29 23:22:06,247: Snapshot:2	Epoch:7	Loss:2.895	translation_Loss:1.748	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.147                                                   	MRR:22.37	Hits@10:38.52	Best:22.45
2024-12-29 23:22:13,102: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 22.45
2024-12-29 23:22:13,102: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:2.896 MRR:22.43 Best Results: 22.45
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-29 23:22:13,103: Snapshot:2	Epoch:8	Loss:2.896	translation_Loss:1.749	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.147                                                   	MRR:22.43	Hits@10:38.68	Best:22.45
2024-12-29 23:22:19,568: Snapshot:2	Epoch:9	Loss:24.727	translation_Loss:14.072	multi_layer_Loss:10.655	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.43	Hits@10:38.68	Best:22.45
2024-12-29 23:22:25,910: End of token training: 2 Epoch: 10 Loss:14.345 MRR:22.43 Best Results: 22.45
2024-12-29 23:22:25,911: Snapshot:2	Epoch:10	Loss:14.345	translation_Loss:14.042	multi_layer_Loss:0.302	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.43	Hits@10:38.68	Best:22.45
2024-12-29 23:22:26,162: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2024-12-29 23:22:34,937: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2396 | 0.1523 | 0.2767 | 0.3327 |  0.4052 |
|     1      | 0.2383 | 0.1551 | 0.2746 | 0.3277 |  0.3965 |
|     2      | 0.2238 | 0.1399 | 0.2597 | 0.311  |  0.384  |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:22:57,980: Snapshot:3	Epoch:0	Loss:2.721	translation_Loss:2.062	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.66                                                   	MRR:19.96	Hits@10:38.56	Best:19.96
2024-12-29 23:23:04,591: Snapshot:3	Epoch:1	Loss:1.696	translation_Loss:0.824	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.872                                                   	MRR:20.18	Hits@10:37.74	Best:20.18
2024-12-29 23:23:11,134: Snapshot:3	Epoch:2	Loss:1.629	translation_Loss:0.858	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.771                                                   	MRR:20.3	Hits@10:38.47	Best:20.3
2024-12-29 23:23:17,664: Snapshot:3	Epoch:3	Loss:1.574	translation_Loss:0.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.793                                                   	MRR:20.22	Hits@10:38.21	Best:20.3
2024-12-29 23:23:24,163: Snapshot:3	Epoch:4	Loss:1.607	translation_Loss:0.809	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.798                                                   	MRR:20.13	Hits@10:38.12	Best:20.3
2024-12-29 23:23:30,570: Early Stopping! Snapshot: 3 Epoch: 5 Best Results: 20.3
2024-12-29 23:23:30,570: Start to training tokens! Snapshot: 3 Epoch: 5 Loss:1.601 MRR:20.16 Best Results: 20.3
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-29 23:23:30,570: Snapshot:3	Epoch:5	Loss:1.601	translation_Loss:0.789	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.812                                                   	MRR:20.16	Hits@10:38.06	Best:20.3
2024-12-29 23:23:37,544: Snapshot:3	Epoch:6	Loss:22.391	translation_Loss:13.251	multi_layer_Loss:9.14	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.16	Hits@10:38.06	Best:20.3
2024-12-29 23:23:43,977: End of token training: 3 Epoch: 7 Loss:13.553 MRR:20.16 Best Results: 20.3
2024-12-29 23:23:43,978: Snapshot:3	Epoch:7	Loss:13.553	translation_Loss:13.273	multi_layer_Loss:0.28	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.16	Hits@10:38.06	Best:20.3
2024-12-29 23:23:44,228: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2024-12-29 23:23:55,945: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2271 | 0.1421 | 0.2618 | 0.315  |  0.3896 |
|     1      | 0.2277 | 0.1457 | 0.2604 | 0.3141 |  0.3851 |
|     2      | 0.2163 | 0.1302 | 0.2478 | 0.3083 |  0.3867 |
|     3      | 0.2068 | 0.1158 | 0.2395 | 0.3049 |  0.3881 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:24:19,181: Snapshot:4	Epoch:0	Loss:1.513	translation_Loss:1.121	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.392                                                   	MRR:21.19	Hits@10:45.82	Best:21.19
2024-12-29 23:24:25,736: Snapshot:4	Epoch:1	Loss:0.724	translation_Loss:0.339	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.385                                                   	MRR:21.18	Hits@10:44.49	Best:21.19
2024-12-29 23:24:32,461: Snapshot:4	Epoch:2	Loss:0.599	translation_Loss:0.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.326                                                   	MRR:21.61	Hits@10:45.26	Best:21.61
2024-12-29 23:24:38,999: Snapshot:4	Epoch:3	Loss:0.56	translation_Loss:0.233	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.328                                                   	MRR:21.23	Hits@10:44.95	Best:21.61
2024-12-29 23:24:45,521: Snapshot:4	Epoch:4	Loss:0.565	translation_Loss:0.239	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.326                                                   	MRR:21.44	Hits@10:45.08	Best:21.61
2024-12-29 23:24:52,518: Early Stopping! Snapshot: 4 Epoch: 5 Best Results: 21.61
2024-12-29 23:24:52,518: Start to training tokens! Snapshot: 4 Epoch: 5 Loss:0.563 MRR:21.51 Best Results: 21.61
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-29 23:24:52,519: Snapshot:4	Epoch:5	Loss:0.563	translation_Loss:0.229	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.334                                                   	MRR:21.51	Hits@10:44.78	Best:21.61
2024-12-29 23:24:58,966: Snapshot:4	Epoch:6	Loss:20.682	translation_Loss:11.143	multi_layer_Loss:9.539	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.51	Hits@10:44.78	Best:21.61
2024-12-29 23:25:05,889: End of token training: 4 Epoch: 7 Loss:11.428 MRR:21.51 Best Results: 21.61
2024-12-29 23:25:05,890: Snapshot:4	Epoch:7	Loss:11.428	translation_Loss:11.124	multi_layer_Loss:0.304	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.51	Hits@10:44.78	Best:21.61
2024-12-29 23:25:06,134: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2024-12-29 23:25:20,575: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2167 | 0.1351 | 0.2461 | 0.2995 |  0.3752 |
|     1      | 0.2138 | 0.1348 | 0.243  | 0.2955 |  0.3721 |
|     2      | 0.2036 | 0.1207 | 0.2314 | 0.2893 |  0.369  |
|     3      | 0.1942 | 0.1042 | 0.2218 | 0.287  |  0.379  |
|     4      | 0.2173 | 0.1027 | 0.2546 | 0.3397 |  0.453  |
+------------+--------+--------+--------+--------+---------+
2024-12-29 23:25:20,577: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2394 | 0.1537 | 0.2821 | 0.3317 |  0.3923 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2396 | 0.1532 | 0.2764 | 0.3304 |  0.4045 |
|     1      | 0.2344 | 0.1531 | 0.2726 | 0.322  |  0.3822 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2396 | 0.1523 | 0.2767 | 0.3327 |  0.4052 |
|     1      | 0.2383 | 0.1551 | 0.2746 | 0.3277 |  0.3965 |
|     2      | 0.2238 | 0.1399 | 0.2597 | 0.311  |  0.384  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2271 | 0.1421 | 0.2618 | 0.315  |  0.3896 |
|     1      | 0.2277 | 0.1457 | 0.2604 | 0.3141 |  0.3851 |
|     2      | 0.2163 | 0.1302 | 0.2478 | 0.3083 |  0.3867 |
|     3      | 0.2068 | 0.1158 | 0.2395 | 0.3049 |  0.3881 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2167 | 0.1351 | 0.2461 | 0.2995 |  0.3752 |
|     1      | 0.2138 | 0.1348 | 0.243  | 0.2955 |  0.3721 |
|     2      | 0.2036 | 0.1207 | 0.2314 | 0.2893 |  0.369  |
|     3      | 0.1942 | 0.1042 | 0.2218 | 0.287  |  0.379  |
|     4      | 0.2173 | 0.1027 | 0.2546 | 0.3397 |  0.453  |
+------------+--------+--------+--------+--------+---------+]
2024-12-29 23:25:20,578: Report Result:
+----------+-------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time       | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+-------------------+-----------+--------------+--------------+---------------+
|    0     | 138.4070065021515 |   0.239   |    0.154     |    0.282     |     0.392     |
|    1     | 78.45546245574951 |   0.237   |    0.153     |    0.274     |     0.393     |
|    2     | 85.89856266975403 |   0.234   |    0.149     |     0.27     |     0.395     |
|    3     | 66.02687740325928 |   0.219   |    0.133     |    0.252     |     0.387     |
|    4     | 66.87836956977844 |   0.209   |     0.12     |    0.239     |      0.39     |
+----------+-------------------+-----------+--------------+--------------+---------------+
2024-12-29 23:25:20,578: Sum_Training_Time:435.66627860069275
2024-12-29 23:25:20,578: Every_Training_Time:[138.4070065021515, 78.45546245574951, 85.89856266975403, 66.02687740325928, 66.87836956977844]
2024-12-29 23:25:20,578: Forward transfer: 0.17757499999999998 Backward transfer: -0.019025
2024-12-29 23:25:57,411: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229232525/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[500.0, 15000.0, 10000.0, 10000.0], token_num=3, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 23:26:06,603: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:6.23	Hits@10:13.26	Best:6.23
2024-12-29 23:26:13,089: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.68	Hits@10:22.61	Best:9.68
2024-12-29 23:26:19,117: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.9	Hits@10:28.87	Best:12.9
2024-12-29 23:26:25,546: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.78	Hits@10:33.12	Best:15.78
2024-12-29 23:26:31,563: Snapshot:0	Epoch:4	Loss:4.363	translation_Loss:4.363	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.32	Hits@10:36.01	Best:18.32
2024-12-29 23:26:37,558: Snapshot:0	Epoch:5	Loss:3.085	translation_Loss:3.085	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.44	Hits@10:37.72	Best:20.44
2024-12-29 23:26:44,024: Snapshot:0	Epoch:6	Loss:2.177	translation_Loss:2.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.95	Hits@10:38.75	Best:21.95
2024-12-29 23:26:50,063: Snapshot:0	Epoch:7	Loss:1.541	translation_Loss:1.541	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.98	Hits@10:39.47	Best:22.98
2024-12-29 23:26:56,525: Snapshot:0	Epoch:8	Loss:1.097	translation_Loss:1.097	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.72	Hits@10:39.83	Best:23.72
2024-12-29 23:27:02,528: Snapshot:0	Epoch:9	Loss:0.815	translation_Loss:0.815	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.08	Hits@10:39.98	Best:24.08
2024-12-29 23:27:08,518: Snapshot:0	Epoch:10	Loss:0.627	translation_Loss:0.627	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.3	Hits@10:40.21	Best:24.3
2024-12-29 23:27:14,874: Snapshot:0	Epoch:11	Loss:0.495	translation_Loss:0.495	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.41	Hits@10:40.14	Best:24.41
2024-12-29 23:27:20,896: Snapshot:0	Epoch:12	Loss:0.412	translation_Loss:0.412	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.5	Hits@10:40.33	Best:24.5
2024-12-29 23:27:27,260: Snapshot:0	Epoch:13	Loss:0.351	translation_Loss:0.351	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.68	Hits@10:40.44	Best:24.68
2024-12-29 23:27:33,212: Snapshot:0	Epoch:14	Loss:0.312	translation_Loss:0.312	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.71	Hits@10:40.48	Best:24.71
2024-12-29 23:27:39,255: Snapshot:0	Epoch:15	Loss:0.273	translation_Loss:0.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.68	Hits@10:40.4	Best:24.71
2024-12-29 23:27:45,714: Snapshot:0	Epoch:16	Loss:0.243	translation_Loss:0.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.67	Hits@10:40.38	Best:24.71
2024-12-29 23:27:51,712: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 24.71
2024-12-29 23:27:51,713: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.223 MRR:24.71 Best Results: 24.71
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-29 23:27:51,713: Snapshot:0	Epoch:17	Loss:0.223	translation_Loss:0.223	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.71	Hits@10:40.54	Best:24.71
2024-12-29 23:27:58,511: Snapshot:0	Epoch:18	Loss:24.665	translation_Loss:12.302	multi_layer_Loss:12.363	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.71	Hits@10:40.54	Best:24.71
2024-12-29 23:28:04,393: End of token training: 0 Epoch: 19 Loss:12.618 MRR:24.71 Best Results: 24.71
2024-12-29 23:28:04,393: Snapshot:0	Epoch:19	Loss:12.618	translation_Loss:12.315	multi_layer_Loss:0.303	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.71	Hits@10:40.54	Best:24.71
2024-12-29 23:28:04,638: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2024-12-29 23:28:07,406: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2397 | 0.1534 | 0.2824 | 0.3319 |  0.3952 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:28:29,819: Snapshot:1	Epoch:0	Loss:7.533	translation_Loss:7.323	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.21                                                   	MRR:20.83	Hits@10:34.78	Best:20.83
2024-12-29 23:28:36,600: Snapshot:1	Epoch:1	Loss:3.581	translation_Loss:3.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.48                                                   	MRR:22.43	Hits@10:37.25	Best:22.43
2024-12-29 23:28:43,161: Snapshot:1	Epoch:2	Loss:2.1	translation_Loss:1.452	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.648                                                   	MRR:23.12	Hits@10:38.34	Best:23.12
2024-12-29 23:28:50,032: Snapshot:1	Epoch:3	Loss:1.592	translation_Loss:0.868	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.724                                                   	MRR:23.33	Hits@10:38.5	Best:23.33
2024-12-29 23:28:56,440: Snapshot:1	Epoch:4	Loss:1.418	translation_Loss:0.668	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.75                                                   	MRR:23.32	Hits@10:38.57	Best:23.33
2024-12-29 23:29:03,237: Snapshot:1	Epoch:5	Loss:1.335	translation_Loss:0.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.764                                                   	MRR:23.32	Hits@10:38.37	Best:23.33
2024-12-29 23:29:09,505: Early Stopping! Snapshot: 1 Epoch: 6 Best Results: 23.33
2024-12-29 23:29:09,505: Start to training tokens! Snapshot: 1 Epoch: 6 Loss:1.298 MRR:23.3 Best Results: 23.33
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-29 23:29:09,506: Snapshot:1	Epoch:6	Loss:1.298	translation_Loss:0.526	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.772                                                   	MRR:23.3	Hits@10:38.47	Best:23.33
2024-12-29 23:29:15,950: Snapshot:1	Epoch:7	Loss:24.887	translation_Loss:13.002	multi_layer_Loss:11.885	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.3	Hits@10:38.47	Best:23.33
2024-12-29 23:29:22,743: End of token training: 1 Epoch: 8 Loss:13.32 MRR:23.3 Best Results: 23.33
2024-12-29 23:29:22,743: Snapshot:1	Epoch:8	Loss:13.32	translation_Loss:13.009	multi_layer_Loss:0.311	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.3	Hits@10:38.47	Best:23.33
2024-12-29 23:29:22,998: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2024-12-29 23:29:28,624: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2429 | 0.1554 | 0.2817 | 0.3374 |  0.4093 |
|     1      | 0.2351 | 0.1519 | 0.2759 | 0.3236 |  0.3868 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:29:51,756: Snapshot:2	Epoch:0	Loss:5.115	translation_Loss:4.006	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.109                                                   	MRR:21.53	Hits@10:37.45	Best:21.53
2024-12-29 23:29:58,361: Snapshot:2	Epoch:1	Loss:3.879	translation_Loss:2.613	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.267                                                   	MRR:21.94	Hits@10:37.79	Best:21.94
2024-12-29 23:30:04,989: Snapshot:2	Epoch:2	Loss:3.623	translation_Loss:2.499	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.124                                                   	MRR:21.99	Hits@10:37.92	Best:21.99
2024-12-29 23:30:11,604: Snapshot:2	Epoch:3	Loss:3.512	translation_Loss:2.363	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.149                                                   	MRR:22.01	Hits@10:37.98	Best:22.01
2024-12-29 23:30:18,148: Snapshot:2	Epoch:4	Loss:3.488	translation_Loss:2.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.124                                                   	MRR:21.95	Hits@10:38.0	Best:22.01
2024-12-29 23:30:25,152: Snapshot:2	Epoch:5	Loss:3.482	translation_Loss:2.333	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.149                                                   	MRR:22.01	Hits@10:37.86	Best:22.01
2024-12-29 23:30:31,753: Snapshot:2	Epoch:6	Loss:3.465	translation_Loss:2.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.132                                                   	MRR:22.12	Hits@10:38.04	Best:22.12
2024-12-29 23:30:38,281: Snapshot:2	Epoch:7	Loss:3.48	translation_Loss:2.333	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.147                                                   	MRR:22.11	Hits@10:38.1	Best:22.12
2024-12-29 23:30:45,259: Snapshot:2	Epoch:8	Loss:3.473	translation_Loss:2.325	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.148                                                   	MRR:21.97	Hits@10:37.95	Best:22.12
2024-12-29 23:30:51,766: Early Stopping! Snapshot: 2 Epoch: 9 Best Results: 22.12
2024-12-29 23:30:51,766: Start to training tokens! Snapshot: 2 Epoch: 9 Loss:3.468 MRR:21.99 Best Results: 22.12
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-29 23:30:51,767: Snapshot:2	Epoch:9	Loss:3.468	translation_Loss:2.321	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.147                                                   	MRR:21.99	Hits@10:38.01	Best:22.12
2024-12-29 23:30:58,671: Snapshot:2	Epoch:10	Loss:27.115	translation_Loss:14.273	multi_layer_Loss:12.842	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.99	Hits@10:38.01	Best:22.12
2024-12-29 23:31:05,189: End of token training: 2 Epoch: 11 Loss:14.615 MRR:21.99 Best Results: 22.12
2024-12-29 23:31:05,189: Snapshot:2	Epoch:11	Loss:14.615	translation_Loss:14.288	multi_layer_Loss:0.327	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.99	Hits@10:38.01	Best:22.12
2024-12-29 23:31:05,476: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2024-12-29 23:31:13,687: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2424 | 0.1544 | 0.2809 | 0.3362 |  0.4102 |
|     1      | 0.237  | 0.1521 | 0.2751 | 0.3293 |  0.3958 |
|     2      | 0.2227 | 0.1404 | 0.2566 | 0.3098 |  0.3813 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:31:36,474: Snapshot:3	Epoch:0	Loss:3.194	translation_Loss:2.363	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.831                                                   	MRR:19.98	Hits@10:38.23	Best:19.98
2024-12-29 23:31:43,547: Snapshot:3	Epoch:1	Loss:2.166	translation_Loss:1.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.02                                                   	MRR:20.05	Hits@10:37.72	Best:20.05
2024-12-29 23:31:50,150: Snapshot:3	Epoch:2	Loss:2.14	translation_Loss:1.216	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.924                                                   	MRR:20.13	Hits@10:38.32	Best:20.13
2024-12-29 23:31:56,634: Snapshot:3	Epoch:3	Loss:2.08	translation_Loss:1.13	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.95                                                   	MRR:20.06	Hits@10:37.98	Best:20.13
2024-12-29 23:32:03,522: Snapshot:3	Epoch:4	Loss:2.094	translation_Loss:1.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.948                                                   	MRR:20.17	Hits@10:38.13	Best:20.17
2024-12-29 23:32:10,096: Snapshot:3	Epoch:5	Loss:2.092	translation_Loss:1.135	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.957                                                   	MRR:20.07	Hits@10:38.09	Best:20.17
2024-12-29 23:32:17,058: Snapshot:3	Epoch:6	Loss:2.1	translation_Loss:1.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.963                                                   	MRR:20.13	Hits@10:38.14	Best:20.17
2024-12-29 23:32:23,653: Early Stopping! Snapshot: 3 Epoch: 7 Best Results: 20.17
2024-12-29 23:32:23,654: Start to training tokens! Snapshot: 3 Epoch: 7 Loss:2.097 MRR:19.98 Best Results: 20.17
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-29 23:32:23,654: Snapshot:3	Epoch:7	Loss:2.097	translation_Loss:1.13	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.967                                                   	MRR:19.98	Hits@10:38.02	Best:20.17
2024-12-29 23:32:30,538: Snapshot:3	Epoch:8	Loss:25.534	translation_Loss:13.478	multi_layer_Loss:12.056	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.98	Hits@10:38.02	Best:20.17
2024-12-29 23:32:37,077: End of token training: 3 Epoch: 9 Loss:13.786 MRR:19.98 Best Results: 20.17
2024-12-29 23:32:37,077: Snapshot:3	Epoch:9	Loss:13.786	translation_Loss:13.471	multi_layer_Loss:0.315	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.98	Hits@10:38.02	Best:20.17
2024-12-29 23:32:37,328: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2024-12-29 23:32:48,649: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2326 | 0.147  | 0.2678 | 0.3211 |  0.397  |
|     1      | 0.2285 | 0.1444 | 0.2634 | 0.3172 |  0.3883 |
|     2      | 0.2176 | 0.1309 | 0.2522 | 0.3105 |  0.3873 |
|     3      | 0.203  | 0.1124 | 0.2353 | 0.2979 |  0.3845 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:33:12,135: Snapshot:4	Epoch:0	Loss:1.737	translation_Loss:1.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.499                                                   	MRR:21.26	Hits@10:46.34	Best:21.26
2024-12-29 23:33:18,759: Snapshot:4	Epoch:1	Loss:0.897	translation_Loss:0.435	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.462                                                   	MRR:21.07	Hits@10:44.78	Best:21.26
2024-12-29 23:33:25,479: Snapshot:4	Epoch:2	Loss:0.784	translation_Loss:0.379	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.405                                                   	MRR:21.31	Hits@10:45.18	Best:21.31
2024-12-29 23:33:32,069: Snapshot:4	Epoch:3	Loss:0.74	translation_Loss:0.328	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.412                                                   	MRR:21.52	Hits@10:45.11	Best:21.52
2024-12-29 23:33:38,690: Snapshot:4	Epoch:4	Loss:0.739	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.408                                                   	MRR:21.65	Hits@10:45.36	Best:21.65
2024-12-29 23:33:45,296: Snapshot:4	Epoch:5	Loss:0.745	translation_Loss:0.329	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.416                                                   	MRR:21.31	Hits@10:45.22	Best:21.65
2024-12-29 23:33:51,916: Snapshot:4	Epoch:6	Loss:0.738	translation_Loss:0.327	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.411                                                   	MRR:21.51	Hits@10:45.35	Best:21.65
2024-12-29 23:33:58,937: Early Stopping! Snapshot: 4 Epoch: 7 Best Results: 21.65
2024-12-29 23:33:58,938: Start to training tokens! Snapshot: 4 Epoch: 7 Loss:0.744 MRR:21.42 Best Results: 21.65
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-29 23:33:58,938: Snapshot:4	Epoch:7	Loss:0.744	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.413                                                   	MRR:21.42	Hits@10:45.32	Best:21.65
2024-12-29 23:34:05,422: Snapshot:4	Epoch:8	Loss:22.731	translation_Loss:11.241	multi_layer_Loss:11.49	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.42	Hits@10:45.32	Best:21.65
2024-12-29 23:34:12,480: End of token training: 4 Epoch: 9 Loss:11.566 MRR:21.42 Best Results: 21.65
2024-12-29 23:34:12,480: Snapshot:4	Epoch:9	Loss:11.566	translation_Loss:11.249	multi_layer_Loss:0.318	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.42	Hits@10:45.32	Best:21.65
2024-12-29 23:34:12,731: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2024-12-29 23:34:27,253: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2232 | 0.1383 | 0.258  | 0.3112 |  0.3832 |
|     1      | 0.2173 | 0.1354 | 0.2489 | 0.3027 |  0.3759 |
|     2      | 0.2065 | 0.1228 | 0.2359 | 0.2928 |  0.3723 |
|     3      | 0.1952 | 0.1054 | 0.2218 | 0.2856 |  0.3812 |
|     4      | 0.2171 | 0.1055 | 0.2505 | 0.3372 |  0.4498 |
+------------+--------+--------+--------+--------+---------+
2024-12-29 23:34:27,255: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2397 | 0.1534 | 0.2824 | 0.3319 |  0.3952 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2429 | 0.1554 | 0.2817 | 0.3374 |  0.4093 |
|     1      | 0.2351 | 0.1519 | 0.2759 | 0.3236 |  0.3868 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2424 | 0.1544 | 0.2809 | 0.3362 |  0.4102 |
|     1      | 0.237  | 0.1521 | 0.2751 | 0.3293 |  0.3958 |
|     2      | 0.2227 | 0.1404 | 0.2566 | 0.3098 |  0.3813 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2326 | 0.147  | 0.2678 | 0.3211 |  0.397  |
|     1      | 0.2285 | 0.1444 | 0.2634 | 0.3172 |  0.3883 |
|     2      | 0.2176 | 0.1309 | 0.2522 | 0.3105 |  0.3873 |
|     3      | 0.203  | 0.1124 | 0.2353 | 0.2979 |  0.3845 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2232 | 0.1383 | 0.258  | 0.3112 |  0.3832 |
|     1      | 0.2173 | 0.1354 | 0.2489 | 0.3027 |  0.3759 |
|     2      | 0.2065 | 0.1228 | 0.2359 | 0.2928 |  0.3723 |
|     3      | 0.1952 | 0.1054 | 0.2218 | 0.2856 |  0.3812 |
|     4      | 0.2171 | 0.1055 | 0.2505 | 0.3372 |  0.4498 |
+------------+--------+--------+--------+--------+---------+]
2024-12-29 23:34:27,256: Report Result:
+----------+-------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time       | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+-------------------+-----------+--------------+--------------+---------------+
|    0     | 126.9816312789917 |    0.24   |    0.153     |    0.282     |     0.395     |
|    1     |  72.5833101272583 |   0.239   |    0.154     |    0.279     |     0.398     |
|    2     | 93.57557463645935 |   0.234   |    0.149     |    0.271     |     0.396     |
|    3     | 80.39316010475159 |    0.22   |    0.134     |    0.255     |     0.389     |
|    4     | 80.80384159088135 |   0.212   |    0.121     |    0.243     |     0.392     |
+----------+-------------------+-----------+--------------+--------------+---------------+
2024-12-29 23:34:27,256: Sum_Training_Time:454.3375177383423
2024-12-29 23:34:27,256: Every_Training_Time:[126.9816312789917, 72.5833101272583, 93.57557463645935, 80.39316010475159, 80.80384159088135]
2024-12-29 23:34:27,256: Forward transfer: 0.17670000000000002 Backward transfer: -0.014575000000000005
2024-12-29 23:35:04,566: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229233431/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[500.0, 15000.0, 10000.0, 10000.0], token_num=4, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 23:35:13,753: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:6.23	Hits@10:13.26	Best:6.23
2024-12-29 23:35:20,165: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.69	Hits@10:22.6	Best:9.69
2024-12-29 23:35:26,110: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.9	Hits@10:28.88	Best:12.9
2024-12-29 23:35:32,398: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.75	Hits@10:33.15	Best:15.75
2024-12-29 23:35:38,371: Snapshot:0	Epoch:4	Loss:4.364	translation_Loss:4.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.33	Hits@10:35.97	Best:18.33
2024-12-29 23:35:44,320: Snapshot:0	Epoch:5	Loss:3.085	translation_Loss:3.085	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.45	Hits@10:37.73	Best:20.45
2024-12-29 23:35:50,735: Snapshot:0	Epoch:6	Loss:2.174	translation_Loss:2.174	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.98	Hits@10:38.83	Best:21.98
2024-12-29 23:35:56,690: Snapshot:0	Epoch:7	Loss:1.539	translation_Loss:1.539	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.0	Hits@10:39.45	Best:23.0
2024-12-29 23:36:02,977: Snapshot:0	Epoch:8	Loss:1.095	translation_Loss:1.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.7	Hits@10:39.82	Best:23.7
2024-12-29 23:36:08,898: Snapshot:0	Epoch:9	Loss:0.817	translation_Loss:0.817	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.14	Hits@10:40.04	Best:24.14
2024-12-29 23:36:14,861: Snapshot:0	Epoch:10	Loss:0.625	translation_Loss:0.625	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.3	Hits@10:40.16	Best:24.3
2024-12-29 23:36:21,251: Snapshot:0	Epoch:11	Loss:0.497	translation_Loss:0.497	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.42	Hits@10:40.38	Best:24.42
2024-12-29 23:36:27,225: Snapshot:0	Epoch:12	Loss:0.414	translation_Loss:0.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.51	Hits@10:40.29	Best:24.51
2024-12-29 23:36:33,673: Snapshot:0	Epoch:13	Loss:0.351	translation_Loss:0.351	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.77	Hits@10:40.4	Best:24.77
2024-12-29 23:36:39,587: Snapshot:0	Epoch:14	Loss:0.31	translation_Loss:0.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:40.5	Best:24.77
2024-12-29 23:36:45,507: Snapshot:0	Epoch:15	Loss:0.273	translation_Loss:0.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.7	Hits@10:40.3	Best:24.77
2024-12-29 23:36:51,880: Early Stopping! Snapshot: 0 Epoch: 16 Best Results: 24.77
2024-12-29 23:36:51,880: Start to training tokens! Snapshot: 0 Epoch: 16 Loss:0.243 MRR:24.73 Best Results: 24.77
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-29 23:36:51,880: Snapshot:0	Epoch:16	Loss:0.243	translation_Loss:0.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.73	Hits@10:40.36	Best:24.77
2024-12-29 23:36:58,259: Snapshot:0	Epoch:17	Loss:25.814	translation_Loss:12.315	multi_layer_Loss:13.499	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.73	Hits@10:40.36	Best:24.77
2024-12-29 23:37:04,554: End of token training: 0 Epoch: 18 Loss:12.606 MRR:24.73 Best Results: 24.77
2024-12-29 23:37:04,554: Snapshot:0	Epoch:18	Loss:12.606	translation_Loss:12.313	multi_layer_Loss:0.293	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.73	Hits@10:40.36	Best:24.77
2024-12-29 23:37:04,804: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2024-12-29 23:37:07,395: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2386 | 0.1516 | 0.2825 | 0.3305 |  0.3953 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:37:30,318: Snapshot:1	Epoch:0	Loss:7.7	translation_Loss:7.445	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.255                                                   	MRR:20.63	Hits@10:34.68	Best:20.63
2024-12-29 23:37:36,724: Snapshot:1	Epoch:1	Loss:3.817	translation_Loss:3.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.582                                                   	MRR:22.46	Hits@10:37.17	Best:22.46
2024-12-29 23:37:43,098: Snapshot:1	Epoch:2	Loss:2.35	translation_Loss:1.558	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.791                                                   	MRR:23.3	Hits@10:38.07	Best:23.3
2024-12-29 23:37:49,463: Snapshot:1	Epoch:3	Loss:1.856	translation_Loss:0.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.881                                                   	MRR:23.36	Hits@10:38.36	Best:23.36
2024-12-29 23:37:55,879: Snapshot:1	Epoch:4	Loss:1.672	translation_Loss:0.761	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.912                                                   	MRR:23.3	Hits@10:38.31	Best:23.36
2024-12-29 23:38:02,329: Snapshot:1	Epoch:5	Loss:1.593	translation_Loss:0.667	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.926                                                   	MRR:23.41	Hits@10:38.65	Best:23.41
2024-12-29 23:38:08,693: Snapshot:1	Epoch:6	Loss:1.56	translation_Loss:0.622	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.938                                                   	MRR:23.39	Hits@10:38.64	Best:23.41
2024-12-29 23:38:15,415: Snapshot:1	Epoch:7	Loss:1.531	translation_Loss:0.583	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.949                                                   	MRR:23.35	Hits@10:38.57	Best:23.41
2024-12-29 23:38:21,838: Early Stopping! Snapshot: 1 Epoch: 8 Best Results: 23.41
2024-12-29 23:38:21,838: Start to training tokens! Snapshot: 1 Epoch: 8 Loss:1.521 MRR:23.22 Best Results: 23.41
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-29 23:38:21,838: Snapshot:1	Epoch:8	Loss:1.521	translation_Loss:0.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.955                                                   	MRR:23.22	Hits@10:38.6	Best:23.41
2024-12-29 23:38:28,516: Snapshot:1	Epoch:9	Loss:26.311	translation_Loss:12.954	multi_layer_Loss:13.357	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.22	Hits@10:38.6	Best:23.41
2024-12-29 23:38:34,801: End of token training: 1 Epoch: 10 Loss:13.259 MRR:23.22 Best Results: 23.41
2024-12-29 23:38:34,802: Snapshot:1	Epoch:10	Loss:13.259	translation_Loss:12.958	multi_layer_Loss:0.3	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.22	Hits@10:38.6	Best:23.41
2024-12-29 23:38:35,042: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2024-12-29 23:38:40,443: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2433 | 0.1548 | 0.2823 | 0.3397 |  0.4123 |
|     1      | 0.236  | 0.1528 | 0.2761 | 0.3229 |  0.3861 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:39:03,449: Snapshot:2	Epoch:0	Loss:5.156	translation_Loss:3.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.184                                                   	MRR:21.54	Hits@10:37.23	Best:21.54
2024-12-29 23:39:10,005: Snapshot:2	Epoch:1	Loss:4.097	translation_Loss:2.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.183                                                   	MRR:21.84	Hits@10:37.54	Best:21.84
2024-12-29 23:39:16,617: Snapshot:2	Epoch:2	Loss:3.746	translation_Loss:2.705	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.041                                                   	MRR:22.04	Hits@10:37.82	Best:22.04
2024-12-29 23:39:23,057: Snapshot:2	Epoch:3	Loss:3.675	translation_Loss:2.621	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.054                                                   	MRR:22.05	Hits@10:37.85	Best:22.05
2024-12-29 23:39:29,510: Snapshot:2	Epoch:4	Loss:3.648	translation_Loss:2.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.038                                                   	MRR:22.0	Hits@10:37.88	Best:22.05
2024-12-29 23:39:36,068: Snapshot:2	Epoch:5	Loss:3.633	translation_Loss:2.583	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.051                                                   	MRR:22.07	Hits@10:37.86	Best:22.07
2024-12-29 23:39:42,955: Snapshot:2	Epoch:6	Loss:3.628	translation_Loss:2.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.043                                                   	MRR:22.06	Hits@10:37.84	Best:22.07
2024-12-29 23:39:49,429: Snapshot:2	Epoch:7	Loss:3.628	translation_Loss:2.573	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.055                                                   	MRR:22.06	Hits@10:37.85	Best:22.07
2024-12-29 23:39:56,342: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 22.07
2024-12-29 23:39:56,342: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:3.633 MRR:21.99 Best Results: 22.07
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-29 23:39:56,342: Snapshot:2	Epoch:8	Loss:3.633	translation_Loss:2.586	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.047                                                   	MRR:21.99	Hits@10:37.84	Best:22.07
2024-12-29 23:40:02,834: Snapshot:2	Epoch:9	Loss:28.548	translation_Loss:14.308	multi_layer_Loss:14.24	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.99	Hits@10:37.84	Best:22.07
2024-12-29 23:40:09,413: End of token training: 2 Epoch: 10 Loss:14.617 MRR:21.99 Best Results: 22.07
2024-12-29 23:40:09,413: Snapshot:2	Epoch:10	Loss:14.617	translation_Loss:14.312	multi_layer_Loss:0.305	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.99	Hits@10:37.84	Best:22.07
2024-12-29 23:40:09,669: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2024-12-29 23:40:19,089: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2431 | 0.1539 | 0.2816 | 0.3397 |  0.4115 |
|     1      | 0.239  | 0.1546 | 0.2776 | 0.3288 |  0.3961 |
|     2      | 0.2205 | 0.1362 | 0.2561 | 0.3107 |  0.3811 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:40:42,412: Snapshot:3	Epoch:0	Loss:3.374	translation_Loss:2.437	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.938                                                   	MRR:19.81	Hits@10:37.91	Best:19.81
2024-12-29 23:40:49,030: Snapshot:3	Epoch:1	Loss:2.442	translation_Loss:1.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.06                                                   	MRR:19.84	Hits@10:37.63	Best:19.84
2024-12-29 23:40:55,603: Snapshot:3	Epoch:2	Loss:2.399	translation_Loss:1.441	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.958                                                   	MRR:19.98	Hits@10:38.08	Best:19.98
2024-12-29 23:41:02,197: Snapshot:3	Epoch:3	Loss:2.349	translation_Loss:1.367	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.982                                                   	MRR:20.06	Hits@10:37.94	Best:20.06
2024-12-29 23:41:08,718: Snapshot:3	Epoch:4	Loss:2.361	translation_Loss:1.383	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.977                                                   	MRR:19.95	Hits@10:38.04	Best:20.06
2024-12-29 23:41:15,263: Snapshot:3	Epoch:5	Loss:2.359	translation_Loss:1.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.994                                                   	MRR:20.01	Hits@10:38.01	Best:20.06
2024-12-29 23:41:22,283: Early Stopping! Snapshot: 3 Epoch: 6 Best Results: 20.06
2024-12-29 23:41:22,283: Start to training tokens! Snapshot: 3 Epoch: 6 Loss:2.356 MRR:19.86 Best Results: 20.06
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-29 23:41:22,284: Snapshot:3	Epoch:6	Loss:2.356	translation_Loss:1.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.988                                                   	MRR:19.86	Hits@10:37.77	Best:20.06
2024-12-29 23:41:28,663: Snapshot:3	Epoch:7	Loss:27.105	translation_Loss:13.55	multi_layer_Loss:13.555	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.86	Hits@10:37.77	Best:20.06
2024-12-29 23:41:35,498: End of token training: 3 Epoch: 8 Loss:13.864 MRR:19.86 Best Results: 20.06
2024-12-29 23:41:35,498: Snapshot:3	Epoch:8	Loss:13.864	translation_Loss:13.56	multi_layer_Loss:0.304	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.86	Hits@10:37.77	Best:20.06
2024-12-29 23:41:35,748: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2024-12-29 23:41:46,993: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2345 | 0.147  | 0.2705 | 0.3277 |  0.4042 |
|     1      | 0.2308 | 0.146  | 0.2674 | 0.3217 |  0.3919 |
|     2      | 0.2169 | 0.1299 | 0.2499 | 0.3097 |  0.387  |
|     3      | 0.203  | 0.1134 | 0.2345 | 0.2974 |  0.3809 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:42:10,374: Snapshot:4	Epoch:0	Loss:1.932	translation_Loss:1.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.586                                                   	MRR:20.58	Hits@10:45.25	Best:20.58
2024-12-29 23:42:16,972: Snapshot:4	Epoch:1	Loss:1.06	translation_Loss:0.531	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.529                                                   	MRR:20.82	Hits@10:44.51	Best:20.82
2024-12-29 23:42:23,632: Snapshot:4	Epoch:2	Loss:0.936	translation_Loss:0.461	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.474                                                   	MRR:21.05	Hits@10:44.31	Best:21.05
2024-12-29 23:42:30,177: Snapshot:4	Epoch:3	Loss:0.898	translation_Loss:0.426	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.472                                                   	MRR:20.82	Hits@10:44.42	Best:21.05
2024-12-29 23:42:36,776: Snapshot:4	Epoch:4	Loss:0.896	translation_Loss:0.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.474                                                   	MRR:21.27	Hits@10:44.82	Best:21.27
2024-12-29 23:42:43,525: Snapshot:4	Epoch:5	Loss:0.902	translation_Loss:0.421	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.481                                                   	MRR:20.93	Hits@10:44.35	Best:21.27
2024-12-29 23:42:50,603: Snapshot:4	Epoch:6	Loss:0.893	translation_Loss:0.415	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.477                                                   	MRR:21.36	Hits@10:44.84	Best:21.36
2024-12-29 23:42:57,165: Snapshot:4	Epoch:7	Loss:0.89	translation_Loss:0.412	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.478                                                   	MRR:20.99	Hits@10:44.6	Best:21.36
2024-12-29 23:43:03,965: Snapshot:4	Epoch:8	Loss:0.896	translation_Loss:0.411	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.485                                                   	MRR:20.94	Hits@10:44.39	Best:21.36
2024-12-29 23:43:10,500: Early Stopping! Snapshot: 4 Epoch: 9 Best Results: 21.36
2024-12-29 23:43:10,500: Start to training tokens! Snapshot: 4 Epoch: 9 Loss:0.901 MRR:21.0 Best Results: 21.36
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-29 23:43:10,500: Snapshot:4	Epoch:9	Loss:0.901	translation_Loss:0.416	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.485                                                   	MRR:21.0	Hits@10:44.64	Best:21.36
2024-12-29 23:43:16,946: Snapshot:4	Epoch:10	Loss:24.386	translation_Loss:11.302	multi_layer_Loss:13.084	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.0	Hits@10:44.64	Best:21.36
2024-12-29 23:43:23,890: End of token training: 4 Epoch: 11 Loss:11.609 MRR:21.0 Best Results: 21.36
2024-12-29 23:43:23,891: Snapshot:4	Epoch:11	Loss:11.609	translation_Loss:11.311	multi_layer_Loss:0.299	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.0	Hits@10:44.64	Best:21.36
2024-12-29 23:43:24,181: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2024-12-29 23:43:38,574: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2265 | 0.1411 | 0.2605 | 0.3158 |  0.3903 |
|     1      | 0.222  | 0.1406 | 0.2541 | 0.3058 |  0.3792 |
|     2      | 0.2087 | 0.1249 | 0.2393 | 0.2967 |  0.3753 |
|     3      | 0.1968 | 0.1073 | 0.2236 | 0.2906 |  0.3809 |
|     4      | 0.2136 | 0.101  | 0.2466 | 0.3338 |  0.447  |
+------------+--------+--------+--------+--------+---------+
2024-12-29 23:43:38,576: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2386 | 0.1516 | 0.2825 | 0.3305 |  0.3953 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2433 | 0.1548 | 0.2823 | 0.3397 |  0.4123 |
|     1      | 0.236  | 0.1528 | 0.2761 | 0.3229 |  0.3861 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2431 | 0.1539 | 0.2816 | 0.3397 |  0.4115 |
|     1      | 0.239  | 0.1546 | 0.2776 | 0.3288 |  0.3961 |
|     2      | 0.2205 | 0.1362 | 0.2561 | 0.3107 |  0.3811 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2345 | 0.147  | 0.2705 | 0.3277 |  0.4042 |
|     1      | 0.2308 | 0.146  | 0.2674 | 0.3217 |  0.3919 |
|     2      | 0.2169 | 0.1299 | 0.2499 | 0.3097 |  0.387  |
|     3      | 0.203  | 0.1134 | 0.2345 | 0.2974 |  0.3809 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2265 | 0.1411 | 0.2605 | 0.3158 |  0.3903 |
|     1      | 0.222  | 0.1406 | 0.2541 | 0.3058 |  0.3792 |
|     2      | 0.2087 | 0.1249 | 0.2393 | 0.2967 |  0.3753 |
|     3      | 0.1968 | 0.1073 | 0.2236 | 0.2906 |  0.3809 |
|     4      | 0.2136 | 0.101  | 0.2466 | 0.3338 |  0.447  |
+------------+--------+--------+--------+--------+---------+]
2024-12-29 23:43:38,576: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 119.98791885375977 |   0.239   |    0.152     |    0.282     |     0.395     |
|    1     | 84.57312202453613  |    0.24   |    0.154     |    0.279     |     0.399     |
|    2     | 86.03192114830017  |   0.234   |    0.148     |    0.272     |     0.396     |
|    3     | 73.36234378814697  |   0.221   |    0.134     |    0.256     |     0.391     |
|    4     | 93.55888986587524  |   0.214   |    0.123     |    0.245     |     0.395     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-29 23:43:38,576: Sum_Training_Time:457.5141956806183
2024-12-29 23:43:38,577: Every_Training_Time:[119.98791885375977, 84.57312202453613, 86.03192114830017, 73.36234378814697, 93.55888986587524]
2024-12-29 23:43:38,577: Forward transfer: 0.17595 Backward transfer: -0.011025
2024-12-29 23:44:15,432: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229234343/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[500.0, 15000.0, 10000.0, 10000.0], token_num=6, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 23:44:24,546: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:6.23	Hits@10:13.26	Best:6.23
2024-12-29 23:44:30,831: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.68	Hits@10:22.6	Best:9.68
2024-12-29 23:44:36,752: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.9	Hits@10:28.89	Best:12.9
2024-12-29 23:44:43,076: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.76	Hits@10:33.11	Best:15.76
2024-12-29 23:44:48,999: Snapshot:0	Epoch:4	Loss:4.364	translation_Loss:4.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.35	Hits@10:36.04	Best:18.35
2024-12-29 23:44:54,990: Snapshot:0	Epoch:5	Loss:3.085	translation_Loss:3.085	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.44	Hits@10:37.77	Best:20.44
2024-12-29 23:45:01,379: Snapshot:0	Epoch:6	Loss:2.173	translation_Loss:2.173	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.96	Hits@10:38.64	Best:21.96
2024-12-29 23:45:07,377: Snapshot:0	Epoch:7	Loss:1.54	translation_Loss:1.54	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.01	Hits@10:39.49	Best:23.01
2024-12-29 23:45:13,749: Snapshot:0	Epoch:8	Loss:1.095	translation_Loss:1.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.68	Hits@10:39.85	Best:23.68
2024-12-29 23:45:19,730: Snapshot:0	Epoch:9	Loss:0.817	translation_Loss:0.817	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.04	Hits@10:39.98	Best:24.04
2024-12-29 23:45:25,635: Snapshot:0	Epoch:10	Loss:0.628	translation_Loss:0.628	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.25	Hits@10:40.12	Best:24.25
2024-12-29 23:45:32,080: Snapshot:0	Epoch:11	Loss:0.496	translation_Loss:0.496	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.43	Hits@10:40.17	Best:24.43
2024-12-29 23:45:37,972: Snapshot:0	Epoch:12	Loss:0.413	translation_Loss:0.413	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.47	Hits@10:40.23	Best:24.47
2024-12-29 23:45:44,264: Snapshot:0	Epoch:13	Loss:0.352	translation_Loss:0.352	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.64	Hits@10:40.43	Best:24.64
2024-12-29 23:45:50,267: Snapshot:0	Epoch:14	Loss:0.308	translation_Loss:0.308	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.62	Hits@10:40.31	Best:24.64
2024-12-29 23:45:56,190: Snapshot:0	Epoch:15	Loss:0.273	translation_Loss:0.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.59	Hits@10:40.24	Best:24.64
2024-12-29 23:46:02,475: Early Stopping! Snapshot: 0 Epoch: 16 Best Results: 24.64
2024-12-29 23:46:02,475: Start to training tokens! Snapshot: 0 Epoch: 16 Loss:0.244 MRR:24.64 Best Results: 24.64
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-29 23:46:02,476: Snapshot:0	Epoch:16	Loss:0.244	translation_Loss:0.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.64	Hits@10:40.24	Best:24.64
2024-12-29 23:46:08,850: Snapshot:0	Epoch:17	Loss:28.119	translation_Loss:12.319	multi_layer_Loss:15.8	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.64	Hits@10:40.24	Best:24.64
2024-12-29 23:46:15,175: End of token training: 0 Epoch: 18 Loss:12.661 MRR:24.64 Best Results: 24.64
2024-12-29 23:46:15,175: Snapshot:0	Epoch:18	Loss:12.661	translation_Loss:12.316	multi_layer_Loss:0.345	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.64	Hits@10:40.24	Best:24.64
2024-12-29 23:46:15,413: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2024-12-29 23:46:17,880: 
+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.239 | 0.1524 | 0.2832 | 0.332  |  0.3946 |
+------------+-------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:46:40,487: Snapshot:1	Epoch:0	Loss:7.773	translation_Loss:7.443	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.33                                                   	MRR:20.64	Hits@10:34.78	Best:20.64
2024-12-29 23:46:46,833: Snapshot:1	Epoch:1	Loss:4.049	translation_Loss:3.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.753                                                   	MRR:22.33	Hits@10:37.23	Best:22.33
2024-12-29 23:46:53,257: Snapshot:1	Epoch:2	Loss:2.692	translation_Loss:1.679	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.012                                                   	MRR:23.12	Hits@10:38.08	Best:23.12
2024-12-29 23:46:59,663: Snapshot:1	Epoch:3	Loss:2.232	translation_Loss:1.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.109                                                   	MRR:23.38	Hits@10:38.52	Best:23.38
2024-12-29 23:47:05,851: Snapshot:1	Epoch:4	Loss:2.061	translation_Loss:0.917	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.145                                                   	MRR:23.38	Hits@10:38.7	Best:23.38
2024-12-29 23:47:12,218: Snapshot:1	Epoch:5	Loss:1.988	translation_Loss:0.823	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.165                                                   	MRR:23.51	Hits@10:38.66	Best:23.51
2024-12-29 23:47:18,589: Snapshot:1	Epoch:6	Loss:1.963	translation_Loss:0.785	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.178                                                   	MRR:23.34	Hits@10:38.72	Best:23.51
2024-12-29 23:47:25,244: Snapshot:1	Epoch:7	Loss:1.934	translation_Loss:0.738	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.196                                                   	MRR:23.5	Hits@10:38.8	Best:23.51
2024-12-29 23:47:31,513: Early Stopping! Snapshot: 1 Epoch: 8 Best Results: 23.51
2024-12-29 23:47:31,513: Start to training tokens! Snapshot: 1 Epoch: 8 Loss:1.927 MRR:23.39 Best Results: 23.51
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-29 23:47:31,513: Snapshot:1	Epoch:8	Loss:1.927	translation_Loss:0.723	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.204                                                   	MRR:23.39	Hits@10:38.79	Best:23.51
2024-12-29 23:47:38,108: Snapshot:1	Epoch:9	Loss:28.39	translation_Loss:13.052	multi_layer_Loss:15.338	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.39	Hits@10:38.79	Best:23.51
2024-12-29 23:47:44,426: End of token training: 1 Epoch: 10 Loss:13.381 MRR:23.39 Best Results: 23.51
2024-12-29 23:47:44,426: Snapshot:1	Epoch:10	Loss:13.381	translation_Loss:13.056	multi_layer_Loss:0.325	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.39	Hits@10:38.79	Best:23.51
2024-12-29 23:47:44,716: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2024-12-29 23:47:50,191: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2472 | 0.1581 | 0.2875 | 0.3425 |  0.415  |
|     1      | 0.236  | 0.1526 | 0.2749 | 0.3242 |  0.3896 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:48:13,332: Snapshot:2	Epoch:0	Loss:5.428	translation_Loss:4.148	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.279                                                   	MRR:21.46	Hits@10:36.91	Best:21.46
2024-12-29 23:48:19,803: Snapshot:2	Epoch:1	Loss:4.645	translation_Loss:3.534	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.111                                                   	MRR:21.84	Hits@10:37.45	Best:21.84
2024-12-29 23:48:26,283: Snapshot:2	Epoch:2	Loss:4.148	translation_Loss:3.173	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.975                                                   	MRR:22.1	Hits@10:37.72	Best:22.1
2024-12-29 23:48:32,792: Snapshot:2	Epoch:3	Loss:4.095	translation_Loss:3.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.977                                                   	MRR:22.0	Hits@10:37.71	Best:22.1
2024-12-29 23:48:39,246: Snapshot:2	Epoch:4	Loss:4.063	translation_Loss:3.098	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.965                                                   	MRR:22.06	Hits@10:37.58	Best:22.1
2024-12-29 23:48:45,805: Early Stopping! Snapshot: 2 Epoch: 5 Best Results: 22.1
2024-12-29 23:48:45,805: Start to training tokens! Snapshot: 2 Epoch: 5 Loss:4.043 MRR:21.96 Best Results: 22.1
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-29 23:48:45,806: Snapshot:2	Epoch:5	Loss:4.043	translation_Loss:3.072	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.972                                                   	MRR:21.96	Hits@10:37.65	Best:22.1
2024-12-29 23:48:52,638: Snapshot:2	Epoch:6	Loss:30.403	translation_Loss:14.483	multi_layer_Loss:15.92	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.96	Hits@10:37.65	Best:22.1
2024-12-29 23:48:58,935: End of token training: 2 Epoch: 7 Loss:14.846 MRR:21.96 Best Results: 22.1
2024-12-29 23:48:58,935: Snapshot:2	Epoch:7	Loss:14.846	translation_Loss:14.496	multi_layer_Loss:0.35	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.96	Hits@10:37.65	Best:22.1
2024-12-29 23:48:59,184: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2024-12-29 23:49:07,666: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.247  | 0.1578 | 0.2857 | 0.3447 |  0.417  |
|     1      | 0.2392 | 0.1553 | 0.2777 | 0.3301 |  0.3963 |
|     2      | 0.2213 | 0.1387 | 0.2558 | 0.3102 |  0.3793 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:49:30,541: Snapshot:3	Epoch:0	Loss:3.877	translation_Loss:2.759	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.118                                                   	MRR:19.41	Hits@10:37.35	Best:19.41
2024-12-29 23:49:37,062: Snapshot:3	Epoch:1	Loss:3.059	translation_Loss:1.922	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.137                                                   	MRR:19.67	Hits@10:37.36	Best:19.67
2024-12-29 23:49:43,500: Snapshot:3	Epoch:2	Loss:2.928	translation_Loss:1.905	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.023                                                   	MRR:19.72	Hits@10:37.56	Best:19.72
2024-12-29 23:49:49,998: Snapshot:3	Epoch:3	Loss:2.896	translation_Loss:1.86	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.036                                                   	MRR:19.72	Hits@10:37.64	Best:19.72
2024-12-29 23:49:56,429: Snapshot:3	Epoch:4	Loss:2.894	translation_Loss:1.864	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.031                                                   	MRR:19.83	Hits@10:37.6	Best:19.83
2024-12-29 23:50:02,927: Snapshot:3	Epoch:5	Loss:2.902	translation_Loss:1.855	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.046                                                   	MRR:19.82	Hits@10:37.38	Best:19.83
2024-12-29 23:50:10,006: Snapshot:3	Epoch:6	Loss:2.911	translation_Loss:1.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.048                                                   	MRR:19.86	Hits@10:37.74	Best:19.86
2024-12-29 23:50:16,468: Snapshot:3	Epoch:7	Loss:2.9	translation_Loss:1.844	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.057                                                   	MRR:19.63	Hits@10:37.36	Best:19.86
2024-12-29 23:50:23,331: Snapshot:3	Epoch:8	Loss:2.902	translation_Loss:1.856	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.046                                                   	MRR:19.77	Hits@10:37.47	Best:19.86
2024-12-29 23:50:29,809: Early Stopping! Snapshot: 3 Epoch: 9 Best Results: 19.86
2024-12-29 23:50:29,810: Start to training tokens! Snapshot: 3 Epoch: 9 Loss:2.899 MRR:19.75 Best Results: 19.86
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-29 23:50:29,810: Snapshot:3	Epoch:9	Loss:2.899	translation_Loss:1.849	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.05                                                   	MRR:19.75	Hits@10:37.45	Best:19.86
2024-12-29 23:50:36,227: Snapshot:3	Epoch:10	Loss:29.67	translation_Loss:13.805	multi_layer_Loss:15.865	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.75	Hits@10:37.45	Best:19.86
2024-12-29 23:50:42,939: End of token training: 3 Epoch: 11 Loss:14.141 MRR:19.75 Best Results: 19.86
2024-12-29 23:50:42,939: Snapshot:3	Epoch:11	Loss:14.141	translation_Loss:13.817	multi_layer_Loss:0.324	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.75	Hits@10:37.45	Best:19.86
2024-12-29 23:50:43,188: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2024-12-29 23:50:54,440: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2407 | 0.1529 | 0.2762 | 0.3344 |  0.4106 |
|     1      | 0.2347 | 0.1509 | 0.2695 | 0.3245 |  0.3943 |
|     2      | 0.2186 | 0.1329 | 0.2536 | 0.3116 |  0.3865 |
|     3      | 0.2002 | 0.1118 | 0.2316 | 0.2918 |  0.3755 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:51:17,883: Snapshot:4	Epoch:0	Loss:2.273	translation_Loss:1.533	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.74                                                   	MRR:20.9	Hits@10:44.74	Best:20.9
2024-12-29 23:51:24,433: Snapshot:4	Epoch:1	Loss:1.392	translation_Loss:0.75	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.643                                                   	MRR:20.78	Hits@10:44.09	Best:20.9
2024-12-29 23:51:30,965: Snapshot:4	Epoch:2	Loss:1.229	translation_Loss:0.639	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.59                                                   	MRR:20.92	Hits@10:43.83	Best:20.92
2024-12-29 23:51:37,540: Snapshot:4	Epoch:3	Loss:1.207	translation_Loss:0.613	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.594                                                   	MRR:21.01	Hits@10:43.89	Best:21.01
2024-12-29 23:51:44,121: Snapshot:4	Epoch:4	Loss:1.202	translation_Loss:0.612	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.59                                                   	MRR:21.32	Hits@10:44.33	Best:21.32
2024-12-29 23:51:50,643: Snapshot:4	Epoch:5	Loss:1.188	translation_Loss:0.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.589                                                   	MRR:21.27	Hits@10:44.2	Best:21.32
2024-12-29 23:51:57,118: Snapshot:4	Epoch:6	Loss:1.196	translation_Loss:0.602	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.594                                                   	MRR:21.12	Hits@10:44.2	Best:21.32
2024-12-29 23:52:03,949: Early Stopping! Snapshot: 4 Epoch: 7 Best Results: 21.32
2024-12-29 23:52:03,950: Start to training tokens! Snapshot: 4 Epoch: 7 Loss:1.188 MRR:21.12 Best Results: 21.32
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-29 23:52:03,950: Snapshot:4	Epoch:7	Loss:1.188	translation_Loss:0.593	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.594                                                   	MRR:21.12	Hits@10:44.04	Best:21.32
2024-12-29 23:52:10,382: Snapshot:4	Epoch:8	Loss:27.015	translation_Loss:11.51	multi_layer_Loss:15.504	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.12	Hits@10:44.04	Best:21.32
2024-12-29 23:52:17,237: End of token training: 4 Epoch: 9 Loss:11.846 MRR:21.12 Best Results: 21.32
2024-12-29 23:52:17,237: Snapshot:4	Epoch:9	Loss:11.846	translation_Loss:11.52	multi_layer_Loss:0.327	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.12	Hits@10:44.04	Best:21.32
2024-12-29 23:52:17,501: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2024-12-29 23:52:32,152: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2334 | 0.1478 | 0.2679 | 0.3237 |  0.398  |
|     1      | 0.226  | 0.1441 | 0.258  | 0.3129 |  0.384  |
|     2      | 0.2105 | 0.125  | 0.243  | 0.3018 |  0.3794 |
|     3      | 0.1946 | 0.1052 | 0.2223 | 0.2855 |  0.379  |
|     4      | 0.2151 | 0.1046 | 0.2491 | 0.3308 |  0.4446 |
+------------+--------+--------+--------+--------+---------+
2024-12-29 23:52:32,154: Final Result:
[+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.239 | 0.1524 | 0.2832 | 0.332  |  0.3946 |
+------------+-------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2472 | 0.1581 | 0.2875 | 0.3425 |  0.415  |
|     1      | 0.236  | 0.1526 | 0.2749 | 0.3242 |  0.3896 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.247  | 0.1578 | 0.2857 | 0.3447 |  0.417  |
|     1      | 0.2392 | 0.1553 | 0.2777 | 0.3301 |  0.3963 |
|     2      | 0.2213 | 0.1387 | 0.2558 | 0.3102 |  0.3793 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2407 | 0.1529 | 0.2762 | 0.3344 |  0.4106 |
|     1      | 0.2347 | 0.1509 | 0.2695 | 0.3245 |  0.3943 |
|     2      | 0.2186 | 0.1329 | 0.2536 | 0.3116 |  0.3865 |
|     3      | 0.2002 | 0.1118 | 0.2316 | 0.2918 |  0.3755 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2334 | 0.1478 | 0.2679 | 0.3237 |  0.398  |
|     1      | 0.226  | 0.1441 | 0.258  | 0.3129 |  0.384  |
|     2      | 0.2105 | 0.125  | 0.243  | 0.3018 |  0.3794 |
|     3      | 0.1946 | 0.1052 | 0.2223 | 0.2855 |  0.379  |
|     4      | 0.2151 | 0.1046 | 0.2491 | 0.3308 |  0.4446 |
+------------+--------+--------+--------+--------+---------+]
2024-12-29 23:52:32,155: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 119.74224519729614 |   0.239   |    0.152     |    0.283     |     0.395     |
|    1     | 83.70390796661377  |   0.242   |    0.155     |    0.281     |     0.402     |
|    2     | 65.78274416923523  |   0.236   |    0.151     |    0.273     |     0.398     |
|    3     | 92.56640338897705  |   0.224   |    0.137     |    0.258     |     0.392     |
|    4     | 79.72782969474792  |   0.216   |    0.125     |    0.248     |     0.397     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-29 23:52:32,155: Sum_Training_Time:441.5231304168701
2024-12-29 23:52:32,155: Every_Training_Time:[119.74224519729614, 83.70390796661377, 65.78274416923523, 92.56640338897705, 79.72782969474792]
2024-12-29 23:52:32,155: Forward transfer: 0.17645 Backward transfer: -0.007999999999999993
2024-12-29 23:53:08,815: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229235236/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[500.0, 15000.0, 10000.0, 10000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 23:53:17,990: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:6.23	Hits@10:13.26	Best:6.23
2024-12-29 23:53:24,406: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.69	Hits@10:22.61	Best:9.69
2024-12-29 23:53:30,353: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.9	Hits@10:28.89	Best:12.9
2024-12-29 23:53:36,677: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.77	Hits@10:33.14	Best:15.77
2024-12-29 23:53:42,688: Snapshot:0	Epoch:4	Loss:4.364	translation_Loss:4.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.34	Hits@10:35.94	Best:18.34
2024-12-29 23:53:48,686: Snapshot:0	Epoch:5	Loss:3.085	translation_Loss:3.085	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.43	Hits@10:37.64	Best:20.43
2024-12-29 23:53:55,198: Snapshot:0	Epoch:6	Loss:2.175	translation_Loss:2.175	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.95	Hits@10:38.83	Best:21.95
2024-12-29 23:54:01,155: Snapshot:0	Epoch:7	Loss:1.54	translation_Loss:1.54	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.0	Hits@10:39.58	Best:23.0
2024-12-29 23:54:07,430: Snapshot:0	Epoch:8	Loss:1.096	translation_Loss:1.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.74	Hits@10:39.8	Best:23.74
2024-12-29 23:54:13,380: Snapshot:0	Epoch:9	Loss:0.813	translation_Loss:0.813	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.07	Hits@10:40.04	Best:24.07
2024-12-29 23:54:19,394: Snapshot:0	Epoch:10	Loss:0.626	translation_Loss:0.626	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.27	Hits@10:40.21	Best:24.27
2024-12-29 23:54:25,704: Snapshot:0	Epoch:11	Loss:0.497	translation_Loss:0.497	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.39	Hits@10:40.1	Best:24.39
2024-12-29 23:54:31,644: Snapshot:0	Epoch:12	Loss:0.413	translation_Loss:0.413	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.52	Hits@10:40.28	Best:24.52
2024-12-29 23:54:38,025: Snapshot:0	Epoch:13	Loss:0.351	translation_Loss:0.351	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.62	Hits@10:40.26	Best:24.62
2024-12-29 23:54:44,021: Snapshot:0	Epoch:14	Loss:0.31	translation_Loss:0.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.67	Hits@10:40.37	Best:24.67
2024-12-29 23:54:50,077: Snapshot:0	Epoch:15	Loss:0.274	translation_Loss:0.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.69	Hits@10:40.34	Best:24.69
2024-12-29 23:54:56,423: Snapshot:0	Epoch:16	Loss:0.244	translation_Loss:0.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.7	Hits@10:40.41	Best:24.7
2024-12-29 23:55:02,385: Snapshot:0	Epoch:17	Loss:0.223	translation_Loss:0.223	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.75	Hits@10:40.41	Best:24.75
2024-12-29 23:55:08,810: Snapshot:0	Epoch:18	Loss:0.206	translation_Loss:0.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.76	Hits@10:40.32	Best:24.76
2024-12-29 23:55:14,642: Snapshot:0	Epoch:19	Loss:0.19	translation_Loss:0.19	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:40.2	Best:24.76
2024-12-29 23:55:20,912: Snapshot:0	Epoch:20	Loss:0.181	translation_Loss:0.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.67	Hits@10:40.31	Best:24.76
2024-12-29 23:55:26,821: Early Stopping! Snapshot: 0 Epoch: 21 Best Results: 24.76
2024-12-29 23:55:26,821: Start to training tokens! Snapshot: 0 Epoch: 21 Loss:0.167 MRR:24.66 Best Results: 24.76
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([7, 200]), requires_grad: True
 - torch.Size([7, 200]), requires_grad: True
2024-12-29 23:55:26,822: Snapshot:0	Epoch:21	Loss:0.167	translation_Loss:0.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:40.37	Best:24.76
2024-12-29 23:55:33,224: Snapshot:0	Epoch:22	Loss:28.26	translation_Loss:12.306	multi_layer_Loss:15.955	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:40.37	Best:24.76
2024-12-29 23:55:39,506: End of token training: 0 Epoch: 23 Loss:12.665 MRR:24.66 Best Results: 24.76
2024-12-29 23:55:39,506: Snapshot:0	Epoch:23	Loss:12.665	translation_Loss:12.319	multi_layer_Loss:0.346	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.66	Hits@10:40.37	Best:24.76
2024-12-29 23:55:39,749: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2024-12-29 23:55:42,222: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2401 | 0.1551 | 0.2818 | 0.3318 |  0.392  |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:56:05,103: Snapshot:1	Epoch:0	Loss:7.37	translation_Loss:7.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.358                                                   	MRR:20.75	Hits@10:34.63	Best:20.75
2024-12-29 23:56:11,411: Snapshot:1	Epoch:1	Loss:3.867	translation_Loss:3.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.803                                                   	MRR:22.43	Hits@10:37.11	Best:22.43
2024-12-29 23:56:17,817: Snapshot:1	Epoch:2	Loss:2.639	translation_Loss:1.591	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.048                                                   	MRR:23.12	Hits@10:38.03	Best:23.12
2024-12-29 23:56:24,253: Snapshot:1	Epoch:3	Loss:2.217	translation_Loss:1.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.128                                                   	MRR:23.41	Hits@10:38.43	Best:23.41
2024-12-29 23:56:30,650: Snapshot:1	Epoch:4	Loss:2.087	translation_Loss:0.927	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.16                                                   	MRR:23.44	Hits@10:38.46	Best:23.44
2024-12-29 23:56:37,498: Snapshot:1	Epoch:5	Loss:2.022	translation_Loss:0.842	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.18                                                   	MRR:23.46	Hits@10:38.54	Best:23.46
2024-12-29 23:56:43,819: Snapshot:1	Epoch:6	Loss:1.997	translation_Loss:0.804	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.193                                                   	MRR:23.4	Hits@10:38.58	Best:23.46
2024-12-29 23:56:50,196: Snapshot:1	Epoch:7	Loss:1.986	translation_Loss:0.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.205                                                   	MRR:23.4	Hits@10:38.85	Best:23.46
2024-12-29 23:56:56,865: Snapshot:1	Epoch:8	Loss:1.98	translation_Loss:0.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.22                                                   	MRR:23.48	Hits@10:38.69	Best:23.48
2024-12-29 23:57:03,220: Snapshot:1	Epoch:9	Loss:1.971	translation_Loss:0.744	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.227                                                   	MRR:23.35	Hits@10:38.65	Best:23.48
2024-12-29 23:57:09,499: Snapshot:1	Epoch:10	Loss:1.975	translation_Loss:0.742	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.233                                                   	MRR:23.36	Hits@10:38.72	Best:23.48
2024-12-29 23:57:16,263: Early Stopping! Snapshot: 1 Epoch: 11 Best Results: 23.48
2024-12-29 23:57:16,263: Start to training tokens! Snapshot: 1 Epoch: 11 Loss:1.964 MRR:23.31 Best Results: 23.48
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([7, 200]), requires_grad: True
 - torch.Size([7, 200]), requires_grad: True
2024-12-29 23:57:16,263: Snapshot:1	Epoch:11	Loss:1.964	translation_Loss:0.727	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.237                                                   	MRR:23.31	Hits@10:38.45	Best:23.48
2024-12-29 23:57:22,546: Snapshot:1	Epoch:12	Loss:28.8	translation_Loss:13.224	multi_layer_Loss:15.576	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.31	Hits@10:38.45	Best:23.48
2024-12-29 23:57:29,323: End of token training: 1 Epoch: 13 Loss:13.574 MRR:23.31 Best Results: 23.48
2024-12-29 23:57:29,323: Snapshot:1	Epoch:13	Loss:13.574	translation_Loss:13.231	multi_layer_Loss:0.342	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.31	Hits@10:38.45	Best:23.48
2024-12-29 23:57:29,578: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2024-12-29 23:57:34,881: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2501 | 0.1614 | 0.2898 | 0.3451 |  0.4178 |
|     1      | 0.2353 | 0.1525 | 0.2739 | 0.3231 |  0.3864 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:57:57,559: Snapshot:2	Epoch:0	Loss:5.167	translation_Loss:3.93	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.237                                                   	MRR:21.4	Hits@10:36.69	Best:21.4
2024-12-29 23:58:04,115: Snapshot:2	Epoch:1	Loss:4.5	translation_Loss:3.47	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.03                                                   	MRR:21.79	Hits@10:37.27	Best:21.79
2024-12-29 23:58:10,726: Snapshot:2	Epoch:2	Loss:3.987	translation_Loss:3.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.9                                                   	MRR:21.94	Hits@10:37.33	Best:21.94
2024-12-29 23:58:17,251: Snapshot:2	Epoch:3	Loss:3.928	translation_Loss:3.035	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.892                                                   	MRR:21.88	Hits@10:37.4	Best:21.94
2024-12-29 23:58:23,813: Snapshot:2	Epoch:4	Loss:3.879	translation_Loss:2.998	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.881                                                   	MRR:22.01	Hits@10:37.46	Best:22.01
2024-12-29 23:58:30,767: Snapshot:2	Epoch:5	Loss:3.857	translation_Loss:2.971	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.886                                                   	MRR:22.01	Hits@10:37.49	Best:22.01
2024-12-29 23:58:37,240: Snapshot:2	Epoch:6	Loss:3.866	translation_Loss:2.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.88                                                   	MRR:21.99	Hits@10:37.34	Best:22.01
2024-12-29 23:58:44,244: Snapshot:2	Epoch:7	Loss:3.859	translation_Loss:2.977	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.882                                                   	MRR:22.05	Hits@10:37.5	Best:22.05
2024-12-29 23:58:50,752: Snapshot:2	Epoch:8	Loss:3.859	translation_Loss:2.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.886                                                   	MRR:21.92	Hits@10:37.4	Best:22.05
2024-12-29 23:58:57,385: Snapshot:2	Epoch:9	Loss:3.855	translation_Loss:2.971	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.885                                                   	MRR:21.99	Hits@10:37.38	Best:22.05
2024-12-29 23:59:04,292: Early Stopping! Snapshot: 2 Epoch: 10 Best Results: 22.05
2024-12-29 23:59:04,292: Start to training tokens! Snapshot: 2 Epoch: 10 Loss:3.867 MRR:21.9 Best Results: 22.05
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([7, 200]), requires_grad: True
 - torch.Size([7, 200]), requires_grad: True
2024-12-29 23:59:04,292: Snapshot:2	Epoch:10	Loss:3.867	translation_Loss:2.975	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.892                                                   	MRR:21.9	Hits@10:37.3	Best:22.05
2024-12-29 23:59:10,794: Snapshot:2	Epoch:11	Loss:30.954	translation_Loss:14.522	multi_layer_Loss:16.432	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.9	Hits@10:37.3	Best:22.05
2024-12-29 23:59:17,646: End of token training: 2 Epoch: 12 Loss:14.876 MRR:21.9 Best Results: 22.05
2024-12-29 23:59:17,647: Snapshot:2	Epoch:12	Loss:14.876	translation_Loss:14.515	multi_layer_Loss:0.361	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.9	Hits@10:37.3	Best:22.05
2024-12-29 23:59:17,888: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2024-12-29 23:59:26,236: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2507 | 0.1625 | 0.289  | 0.3467 |  0.4166 |
|     1      | 0.2383 | 0.1549 | 0.2758 | 0.3282 |  0.3931 |
|     2      | 0.2188 | 0.1369 | 0.2543 | 0.3055 |  0.3735 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 23:59:49,271: Snapshot:3	Epoch:0	Loss:3.688	translation_Loss:2.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.091                                                   	MRR:19.44	Hits@10:36.41	Best:19.44
2024-12-29 23:59:55,976: Snapshot:3	Epoch:1	Loss:3.03	translation_Loss:1.996	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.034                                                   	MRR:19.57	Hits@10:36.65	Best:19.57
2024-12-30 00:00:02,451: Snapshot:3	Epoch:2	Loss:2.863	translation_Loss:1.939	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.924                                                   	MRR:19.53	Hits@10:36.61	Best:19.57
2024-12-30 00:00:09,143: Snapshot:3	Epoch:3	Loss:2.838	translation_Loss:1.894	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.943                                                   	MRR:19.67	Hits@10:36.76	Best:19.67
2024-12-30 00:00:15,754: Snapshot:3	Epoch:4	Loss:2.835	translation_Loss:1.898	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.936                                                   	MRR:19.6	Hits@10:36.66	Best:19.67
2024-12-30 00:00:22,295: Snapshot:3	Epoch:5	Loss:2.839	translation_Loss:1.894	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.945                                                   	MRR:19.71	Hits@10:36.68	Best:19.71
2024-12-30 00:00:29,244: Snapshot:3	Epoch:6	Loss:2.84	translation_Loss:1.898	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.942                                                   	MRR:19.56	Hits@10:36.59	Best:19.71
2024-12-30 00:00:35,828: Snapshot:3	Epoch:7	Loss:2.844	translation_Loss:1.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.945                                                   	MRR:19.52	Hits@10:36.61	Best:19.71
2024-12-30 00:00:42,769: Early Stopping! Snapshot: 3 Epoch: 8 Best Results: 19.71
2024-12-30 00:00:42,770: Start to training tokens! Snapshot: 3 Epoch: 8 Loss:2.834 MRR:19.69 Best Results: 19.71
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([7, 200]), requires_grad: True
 - torch.Size([7, 200]), requires_grad: True
2024-12-30 00:00:42,770: Snapshot:3	Epoch:8	Loss:2.834	translation_Loss:1.892	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.942                                                   	MRR:19.69	Hits@10:36.79	Best:19.71
2024-12-30 00:00:49,325: Snapshot:3	Epoch:9	Loss:30.639	translation_Loss:13.906	multi_layer_Loss:16.733	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.69	Hits@10:36.79	Best:19.71
2024-12-30 00:00:55,783: End of token training: 3 Epoch: 10 Loss:14.245 MRR:19.69 Best Results: 19.71
2024-12-30 00:00:55,784: Snapshot:3	Epoch:10	Loss:14.245	translation_Loss:13.897	multi_layer_Loss:0.347	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.69	Hits@10:36.79	Best:19.71
2024-12-30 00:00:56,031: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2024-12-30 00:01:07,716: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2452 | 0.1567 | 0.2827 | 0.3401 |  0.4135 |
|     1      | 0.2346 | 0.1502 | 0.2714 | 0.324  |  0.3929 |
|     2      | 0.2193 | 0.135  | 0.2533 | 0.3082 |  0.3832 |
|     3      |  0.2   | 0.1158 | 0.2275 | 0.2884 |  0.3696 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:01:30,308: Snapshot:4	Epoch:0	Loss:2.319	translation_Loss:1.552	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.768                                                   	MRR:20.0	Hits@10:42.97	Best:20.0
2024-12-30 00:01:37,436: Snapshot:4	Epoch:1	Loss:1.474	translation_Loss:0.812	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.662                                                   	MRR:20.32	Hits@10:42.52	Best:20.32
2024-12-30 00:01:44,171: Snapshot:4	Epoch:2	Loss:1.294	translation_Loss:0.693	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.601                                                   	MRR:20.7	Hits@10:43.14	Best:20.7
2024-12-30 00:01:51,101: Snapshot:4	Epoch:3	Loss:1.256	translation_Loss:0.659	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.597                                                   	MRR:20.58	Hits@10:43.04	Best:20.7
2024-12-30 00:01:57,646: Snapshot:4	Epoch:4	Loss:1.251	translation_Loss:0.654	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.597                                                   	MRR:20.47	Hits@10:42.97	Best:20.7
2024-12-30 00:02:04,254: Early Stopping! Snapshot: 4 Epoch: 5 Best Results: 20.7
2024-12-30 00:02:04,254: Start to training tokens! Snapshot: 4 Epoch: 5 Loss:1.256 MRR:20.59 Best Results: 20.7
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([7, 200]), requires_grad: True
 - torch.Size([7, 200]), requires_grad: True
2024-12-30 00:02:04,254: Snapshot:4	Epoch:5	Loss:1.256	translation_Loss:0.657	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.599                                                   	MRR:20.59	Hits@10:42.74	Best:20.7
2024-12-30 00:02:11,143: Snapshot:4	Epoch:6	Loss:27.635	translation_Loss:11.66	multi_layer_Loss:15.975	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.59	Hits@10:42.74	Best:20.7
2024-12-30 00:02:17,708: End of token training: 4 Epoch: 7 Loss:12.016 MRR:20.59 Best Results: 20.7
2024-12-30 00:02:17,709: Snapshot:4	Epoch:7	Loss:12.016	translation_Loss:11.665	multi_layer_Loss:0.351	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.59	Hits@10:42.74	Best:20.7
2024-12-30 00:02:17,990: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2024-12-30 00:02:32,640: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2399 | 0.1532 | 0.2749 | 0.3325 |  0.4049 |
|     1      | 0.2295 | 0.1482 | 0.2624 | 0.3152 |  0.3843 |
|     2      | 0.2134 | 0.1301 | 0.2444 | 0.3002 |   0.38  |
|     3      | 0.1978 | 0.111  | 0.2256 | 0.2876 |  0.3757 |
|     4      | 0.206  | 0.0992 | 0.2366 | 0.3181 |  0.4288 |
+------------+--------+--------+--------+--------+---------+
2024-12-30 00:02:32,642: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2401 | 0.1551 | 0.2818 | 0.3318 |  0.392  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2501 | 0.1614 | 0.2898 | 0.3451 |  0.4178 |
|     1      | 0.2353 | 0.1525 | 0.2739 | 0.3231 |  0.3864 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2507 | 0.1625 | 0.289  | 0.3467 |  0.4166 |
|     1      | 0.2383 | 0.1549 | 0.2758 | 0.3282 |  0.3931 |
|     2      | 0.2188 | 0.1369 | 0.2543 | 0.3055 |  0.3735 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2452 | 0.1567 | 0.2827 | 0.3401 |  0.4135 |
|     1      | 0.2346 | 0.1502 | 0.2714 | 0.324  |  0.3929 |
|     2      | 0.2193 | 0.135  | 0.2533 | 0.3082 |  0.3832 |
|     3      |  0.2   | 0.1158 | 0.2275 | 0.2884 |  0.3696 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2399 | 0.1532 | 0.2749 | 0.3325 |  0.4049 |
|     1      | 0.2295 | 0.1482 | 0.2624 | 0.3152 |  0.3843 |
|     2      | 0.2134 | 0.1301 | 0.2444 | 0.3002 |   0.38  |
|     3      | 0.1978 | 0.111  | 0.2256 | 0.2876 |  0.3757 |
|     4      | 0.206  | 0.0992 | 0.2366 | 0.3181 |  0.4288 |
+------------+--------+--------+--------+--------+---------+]
2024-12-30 00:02:32,643: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 150.69035458564758 |    0.24   |    0.155     |    0.282     |     0.392     |
|    1     | 104.29323029518127 |   0.243   |    0.157     |    0.282     |     0.402     |
|    2     | 99.82177805900574  |   0.236   |    0.151     |    0.273     |     0.394     |
|    3     | 86.54888010025024  |   0.225   |    0.139     |    0.259     |      0.39     |
|    4     | 66.90055227279663  |   0.217   |    0.128     |    0.249     |     0.395     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-30 00:02:32,643: Sum_Training_Time:508.25479531288147
2024-12-30 00:02:32,643: Every_Training_Time:[150.69035458564758, 104.29323029518127, 99.82177805900574, 86.54888010025024, 66.90055227279663]
2024-12-30 00:02:32,643: Forward transfer: 0.17405 Backward transfer: -0.0034000000000000002
2024-12-30 00:03:09,738: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241230000237/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[500.0, 15000.0, 10000.0, 10000.0], token_num=8, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-30 00:03:18,846: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:6.23	Hits@10:13.26	Best:6.23
2024-12-30 00:03:25,176: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.69	Hits@10:22.6	Best:9.69
2024-12-30 00:03:31,153: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.9	Hits@10:28.9	Best:12.9
2024-12-30 00:03:37,447: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.75	Hits@10:33.12	Best:15.75
2024-12-30 00:03:43,372: Snapshot:0	Epoch:4	Loss:4.364	translation_Loss:4.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.37	Hits@10:35.89	Best:18.37
2024-12-30 00:03:49,268: Snapshot:0	Epoch:5	Loss:3.084	translation_Loss:3.084	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.42	Hits@10:37.71	Best:20.42
2024-12-30 00:03:55,614: Snapshot:0	Epoch:6	Loss:2.174	translation_Loss:2.174	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.96	Hits@10:38.68	Best:21.96
2024-12-30 00:04:01,539: Snapshot:0	Epoch:7	Loss:1.54	translation_Loss:1.54	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.96	Hits@10:39.42	Best:22.96
2024-12-30 00:04:07,817: Snapshot:0	Epoch:8	Loss:1.097	translation_Loss:1.097	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.72	Hits@10:39.82	Best:23.72
2024-12-30 00:04:13,738: Snapshot:0	Epoch:9	Loss:0.816	translation_Loss:0.816	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.09	Hits@10:40.12	Best:24.09
2024-12-30 00:04:19,709: Snapshot:0	Epoch:10	Loss:0.628	translation_Loss:0.628	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.25	Hits@10:40.12	Best:24.25
2024-12-30 00:04:26,030: Snapshot:0	Epoch:11	Loss:0.495	translation_Loss:0.495	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.35	Hits@10:40.19	Best:24.35
2024-12-30 00:04:31,888: Snapshot:0	Epoch:12	Loss:0.41	translation_Loss:0.41	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.53	Hits@10:40.36	Best:24.53
2024-12-30 00:04:38,206: Snapshot:0	Epoch:13	Loss:0.352	translation_Loss:0.352	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.65	Hits@10:40.45	Best:24.65
2024-12-30 00:04:44,068: Snapshot:0	Epoch:14	Loss:0.31	translation_Loss:0.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.65	Hits@10:40.42	Best:24.65
2024-12-30 00:04:49,981: Snapshot:0	Epoch:15	Loss:0.272	translation_Loss:0.272	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:40.38	Best:24.66
2024-12-30 00:04:56,229: Snapshot:0	Epoch:16	Loss:0.244	translation_Loss:0.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.69	Hits@10:40.35	Best:24.69
2024-12-30 00:05:02,160: Snapshot:0	Epoch:17	Loss:0.224	translation_Loss:0.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.74	Hits@10:40.35	Best:24.74
2024-12-30 00:05:08,552: Snapshot:0	Epoch:18	Loss:0.208	translation_Loss:0.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.71	Hits@10:40.21	Best:24.74
2024-12-30 00:05:14,479: Snapshot:0	Epoch:19	Loss:0.194	translation_Loss:0.194	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.71	Hits@10:40.35	Best:24.74
2024-12-30 00:05:20,787: Snapshot:0	Epoch:20	Loss:0.183	translation_Loss:0.183	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.76	Hits@10:40.29	Best:24.76
2024-12-30 00:05:26,716: Snapshot:0	Epoch:21	Loss:0.167	translation_Loss:0.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.7	Hits@10:40.43	Best:24.76
2024-12-30 00:05:32,571: Snapshot:0	Epoch:22	Loss:0.157	translation_Loss:0.157	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.76	Hits@10:40.33	Best:24.76
2024-12-30 00:05:38,875: Snapshot:0	Epoch:23	Loss:0.152	translation_Loss:0.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.79	Hits@10:40.31	Best:24.79
2024-12-30 00:05:44,780: Snapshot:0	Epoch:24	Loss:0.144	translation_Loss:0.144	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.8	Hits@10:40.42	Best:24.8
2024-12-30 00:05:51,076: Snapshot:0	Epoch:25	Loss:0.138	translation_Loss:0.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.73	Hits@10:40.42	Best:24.8
2024-12-30 00:05:56,940: Snapshot:0	Epoch:26	Loss:0.132	translation_Loss:0.132	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.63	Hits@10:40.48	Best:24.8
2024-12-30 00:06:02,796: Early Stopping! Snapshot: 0 Epoch: 27 Best Results: 24.8
2024-12-30 00:06:02,796: Start to training tokens! Snapshot: 0 Epoch: 27 Loss:0.133 MRR:24.61 Best Results: 24.8
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-30 00:06:02,797: Snapshot:0	Epoch:27	Loss:0.133	translation_Loss:0.133	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.61	Hits@10:40.35	Best:24.8
2024-12-30 00:06:09,509: Snapshot:0	Epoch:28	Loss:28.5	translation_Loss:12.303	multi_layer_Loss:16.198	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.61	Hits@10:40.35	Best:24.8
2024-12-30 00:06:15,421: End of token training: 0 Epoch: 29 Loss:12.673 MRR:24.61 Best Results: 24.8
2024-12-30 00:06:15,422: Snapshot:0	Epoch:29	Loss:12.673	translation_Loss:12.309	multi_layer_Loss:0.365	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.61	Hits@10:40.35	Best:24.8
2024-12-30 00:06:15,684: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2024-12-30 00:06:18,306: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2404 | 0.1567 |  0.28  | 0.3282 |  0.3935 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:06:40,518: Snapshot:1	Epoch:0	Loss:7.093	translation_Loss:6.71	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.383                                                   	MRR:20.71	Hits@10:34.62	Best:20.71
2024-12-30 00:06:47,288: Snapshot:1	Epoch:1	Loss:3.768	translation_Loss:2.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.847                                                   	MRR:22.44	Hits@10:37.07	Best:22.44
2024-12-30 00:06:53,697: Snapshot:1	Epoch:2	Loss:2.633	translation_Loss:1.556	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.076                                                   	MRR:23.05	Hits@10:37.97	Best:23.05
2024-12-30 00:07:00,405: Snapshot:1	Epoch:3	Loss:2.262	translation_Loss:1.115	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.147                                                   	MRR:23.27	Hits@10:38.38	Best:23.27
2024-12-30 00:07:06,813: Snapshot:1	Epoch:4	Loss:2.144	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.176                                                   	MRR:23.38	Hits@10:38.54	Best:23.38
2024-12-30 00:07:13,340: Snapshot:1	Epoch:5	Loss:2.091	translation_Loss:0.892	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.199                                                   	MRR:23.37	Hits@10:38.45	Best:23.38
2024-12-30 00:07:20,074: Snapshot:1	Epoch:6	Loss:2.074	translation_Loss:0.86	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.214                                                   	MRR:23.45	Hits@10:38.56	Best:23.45
2024-12-30 00:07:26,424: Snapshot:1	Epoch:7	Loss:2.058	translation_Loss:0.832	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.226                                                   	MRR:23.42	Hits@10:38.39	Best:23.45
2024-12-30 00:07:33,135: Snapshot:1	Epoch:8	Loss:2.043	translation_Loss:0.809	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.234                                                   	MRR:23.32	Hits@10:38.55	Best:23.45
2024-12-30 00:07:39,438: Early Stopping! Snapshot: 1 Epoch: 9 Best Results: 23.45
2024-12-30 00:07:39,439: Start to training tokens! Snapshot: 1 Epoch: 9 Loss:2.034 MRR:23.29 Best Results: 23.45
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-30 00:07:39,439: Snapshot:1	Epoch:9	Loss:2.034	translation_Loss:0.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.241                                                   	MRR:23.29	Hits@10:38.42	Best:23.45
2024-12-30 00:07:45,729: Snapshot:1	Epoch:10	Loss:29.458	translation_Loss:13.409	multi_layer_Loss:16.049	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.29	Hits@10:38.42	Best:23.45
2024-12-30 00:07:52,430: End of token training: 1 Epoch: 11 Loss:13.757 MRR:23.29 Best Results: 23.45
2024-12-30 00:07:52,430: Snapshot:1	Epoch:11	Loss:13.757	translation_Loss:13.396	multi_layer_Loss:0.361	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.29	Hits@10:38.42	Best:23.45
2024-12-30 00:07:52,682: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2024-12-30 00:07:58,296: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2522 | 0.1636 | 0.2921 | 0.3471 |  0.4188 |
|     1      | 0.2344 | 0.1523 | 0.2712 | 0.3229 |  0.3848 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:08:21,036: Snapshot:2	Epoch:0	Loss:5.091	translation_Loss:3.88	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.211                                                   	MRR:21.07	Hits@10:36.36	Best:21.07
2024-12-30 00:08:27,637: Snapshot:2	Epoch:1	Loss:4.507	translation_Loss:3.507	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.0                                                   	MRR:21.48	Hits@10:36.67	Best:21.48
2024-12-30 00:08:34,242: Snapshot:2	Epoch:2	Loss:3.991	translation_Loss:3.121	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.87                                                   	MRR:21.54	Hits@10:37.07	Best:21.54
2024-12-30 00:08:41,205: Snapshot:2	Epoch:3	Loss:3.918	translation_Loss:3.06	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.858                                                   	MRR:21.68	Hits@10:37.04	Best:21.68
2024-12-30 00:08:47,729: Snapshot:2	Epoch:4	Loss:3.899	translation_Loss:3.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.846                                                   	MRR:21.65	Hits@10:36.98	Best:21.68
2024-12-30 00:08:54,240: Snapshot:2	Epoch:5	Loss:3.871	translation_Loss:3.022	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.849                                                   	MRR:21.7	Hits@10:37.05	Best:21.7
2024-12-30 00:09:01,154: Snapshot:2	Epoch:6	Loss:3.875	translation_Loss:3.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.851                                                   	MRR:21.64	Hits@10:36.99	Best:21.7
2024-12-30 00:09:07,588: Snapshot:2	Epoch:7	Loss:3.867	translation_Loss:3.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.856                                                   	MRR:21.64	Hits@10:36.94	Best:21.7
2024-12-30 00:09:14,442: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 21.7
2024-12-30 00:09:14,442: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:3.871 MRR:21.66 Best Results: 21.7
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-30 00:09:14,443: Snapshot:2	Epoch:8	Loss:3.871	translation_Loss:3.025	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.846                                                   	MRR:21.66	Hits@10:37.12	Best:21.7
2024-12-30 00:09:20,971: Snapshot:2	Epoch:9	Loss:31.268	translation_Loss:14.656	multi_layer_Loss:16.612	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.66	Hits@10:37.12	Best:21.7
2024-12-30 00:09:27,415: End of token training: 2 Epoch: 10 Loss:15.016 MRR:21.66 Best Results: 21.7
2024-12-30 00:09:27,415: Snapshot:2	Epoch:10	Loss:15.016	translation_Loss:14.655	multi_layer_Loss:0.362	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.66	Hits@10:37.12	Best:21.7
2024-12-30 00:09:27,675: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2024-12-30 00:09:36,119: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2516 | 0.1624 | 0.2912 | 0.3486 |  0.4187 |
|     1      | 0.2369 | 0.1537 | 0.2742 | 0.3251 |  0.3892 |
|     2      | 0.2155 | 0.1341 | 0.2518 | 0.3022 |  0.3691 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:09:59,057: Snapshot:3	Epoch:0	Loss:3.721	translation_Loss:2.616	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.104                                                   	MRR:18.93	Hits@10:35.87	Best:18.93
2024-12-30 00:10:05,827: Snapshot:3	Epoch:1	Loss:3.153	translation_Loss:2.144	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.009                                                   	MRR:19.18	Hits@10:35.92	Best:19.18
2024-12-30 00:10:12,510: Snapshot:3	Epoch:2	Loss:2.933	translation_Loss:2.033	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.901                                                   	MRR:19.03	Hits@10:36.12	Best:19.18
2024-12-30 00:10:18,946: Snapshot:3	Epoch:3	Loss:2.921	translation_Loss:2.008	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.913                                                   	MRR:19.2	Hits@10:36.17	Best:19.2
2024-12-30 00:10:25,529: Snapshot:3	Epoch:4	Loss:2.919	translation_Loss:2.017	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.902                                                   	MRR:19.3	Hits@10:36.13	Best:19.3
2024-12-30 00:10:32,063: Snapshot:3	Epoch:5	Loss:2.898	translation_Loss:1.992	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.906                                                   	MRR:19.12	Hits@10:36.01	Best:19.3
2024-12-30 00:10:38,912: Snapshot:3	Epoch:6	Loss:2.905	translation_Loss:2.0	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.905                                                   	MRR:19.23	Hits@10:36.17	Best:19.3
2024-12-30 00:10:45,394: Early Stopping! Snapshot: 3 Epoch: 7 Best Results: 19.3
2024-12-30 00:10:45,394: Start to training tokens! Snapshot: 3 Epoch: 7 Loss:2.917 MRR:19.29 Best Results: 19.3
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-30 00:10:45,395: Snapshot:3	Epoch:7	Loss:2.917	translation_Loss:2.006	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.911                                                   	MRR:19.29	Hits@10:36.16	Best:19.3
2024-12-30 00:10:52,280: Snapshot:3	Epoch:8	Loss:30.787	translation_Loss:14.08	multi_layer_Loss:16.707	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.29	Hits@10:36.16	Best:19.3
2024-12-30 00:10:58,615: End of token training: 3 Epoch: 9 Loss:14.452 MRR:19.29 Best Results: 19.3
2024-12-30 00:10:58,617: Snapshot:3	Epoch:9	Loss:14.452	translation_Loss:14.085	multi_layer_Loss:0.367	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.29	Hits@10:36.16	Best:19.3
2024-12-30 00:10:58,872: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2024-12-30 00:11:10,371: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2481 | 0.1609 | 0.2844 | 0.3401 |  0.4145 |
|     1      | 0.2359 | 0.1535 | 0.2713 | 0.3227 |  0.3912 |
|     2      | 0.2164 | 0.1328 | 0.2496 | 0.3057 |  0.3805 |
|     3      | 0.1949 | 0.1087 | 0.226  | 0.2856 |  0.3624 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:11:33,499: Snapshot:4	Epoch:0	Loss:2.408	translation_Loss:1.607	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.802                                                   	MRR:19.48	Hits@10:42.33	Best:19.48
2024-12-30 00:11:40,059: Snapshot:4	Epoch:1	Loss:1.587	translation_Loss:0.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.688                                                   	MRR:19.82	Hits@10:41.58	Best:19.82
2024-12-30 00:11:46,622: Snapshot:4	Epoch:2	Loss:1.402	translation_Loss:0.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.629                                                   	MRR:20.08	Hits@10:41.87	Best:20.08
2024-12-30 00:11:53,177: Snapshot:4	Epoch:3	Loss:1.366	translation_Loss:0.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.633                                                   	MRR:20.04	Hits@10:42.1	Best:20.08
2024-12-30 00:12:00,090: Snapshot:4	Epoch:4	Loss:1.36	translation_Loss:0.733	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.626                                                   	MRR:20.05	Hits@10:41.95	Best:20.08
2024-12-30 00:12:06,651: Snapshot:4	Epoch:5	Loss:1.371	translation_Loss:0.739	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.632                                                   	MRR:20.15	Hits@10:41.91	Best:20.15
2024-12-30 00:12:13,253: Snapshot:4	Epoch:6	Loss:1.372	translation_Loss:0.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.638                                                   	MRR:20.25	Hits@10:42.03	Best:20.25
2024-12-30 00:12:20,245: Snapshot:4	Epoch:7	Loss:1.364	translation_Loss:0.729	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.635                                                   	MRR:20.27	Hits@10:41.99	Best:20.27
2024-12-30 00:12:26,796: Snapshot:4	Epoch:8	Loss:1.366	translation_Loss:0.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.64                                                   	MRR:20.11	Hits@10:41.93	Best:20.27
2024-12-30 00:12:33,334: Snapshot:4	Epoch:9	Loss:1.359	translation_Loss:0.727	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.633                                                   	MRR:20.19	Hits@10:42.01	Best:20.27
2024-12-30 00:12:40,270: Early Stopping! Snapshot: 4 Epoch: 10 Best Results: 20.27
2024-12-30 00:12:40,270: Start to training tokens! Snapshot: 4 Epoch: 10 Loss:1.362 MRR:20.06 Best Results: 20.27
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-30 00:12:40,270: Snapshot:4	Epoch:10	Loss:1.362	translation_Loss:0.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.636                                                   	MRR:20.06	Hits@10:41.6	Best:20.27
2024-12-30 00:12:46,847: Snapshot:4	Epoch:11	Loss:28.29	translation_Loss:11.874	multi_layer_Loss:16.416	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.06	Hits@10:41.6	Best:20.27
2024-12-30 00:12:53,716: End of token training: 4 Epoch: 12 Loss:12.219 MRR:20.06 Best Results: 20.27
2024-12-30 00:12:53,717: Snapshot:4	Epoch:12	Loss:12.219	translation_Loss:11.852	multi_layer_Loss:0.368	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.06	Hits@10:41.6	Best:20.27
2024-12-30 00:12:53,963: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2024-12-30 00:13:08,193: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2421 | 0.1564 | 0.2775 | 0.3334 |  0.4059 |
|     1      | 0.2295 | 0.1485 | 0.2636 | 0.3123 |  0.3819 |
|     2      | 0.2113 | 0.1293 | 0.2412 | 0.2976 |  0.3727 |
|     3      | 0.1935 | 0.1076 |  0.22  | 0.2834 |  0.369  |
|     4      | 0.204  | 0.0993 | 0.2345 | 0.3157 |  0.4215 |
+------------+--------+--------+--------+--------+---------+
2024-12-30 00:13:08,196: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2404 | 0.1567 |  0.28  | 0.3282 |  0.3935 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2522 | 0.1636 | 0.2921 | 0.3471 |  0.4188 |
|     1      | 0.2344 | 0.1523 | 0.2712 | 0.3229 |  0.3848 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2516 | 0.1624 | 0.2912 | 0.3486 |  0.4187 |
|     1      | 0.2369 | 0.1537 | 0.2742 | 0.3251 |  0.3892 |
|     2      | 0.2155 | 0.1341 | 0.2518 | 0.3022 |  0.3691 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2481 | 0.1609 | 0.2844 | 0.3401 |  0.4145 |
|     1      | 0.2359 | 0.1535 | 0.2713 | 0.3227 |  0.3912 |
|     2      | 0.2164 | 0.1328 | 0.2496 | 0.3057 |  0.3805 |
|     3      | 0.1949 | 0.1087 | 0.226  | 0.2856 |  0.3624 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2421 | 0.1564 | 0.2775 | 0.3334 |  0.4059 |
|     1      | 0.2295 | 0.1485 | 0.2636 | 0.3123 |  0.3819 |
|     2      | 0.2113 | 0.1293 | 0.2412 | 0.2976 |  0.3727 |
|     3      | 0.1935 | 0.1076 |  0.22  | 0.2834 |  0.369  |
|     4      | 0.204  | 0.0993 | 0.2345 | 0.3157 |  0.4215 |
+------------+--------+--------+--------+--------+---------+]
2024-12-30 00:13:08,196: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 185.68328857421875 |    0.24   |    0.157     |     0.28     |     0.394     |
|    1     |  91.3144838809967  |   0.243   |    0.158     |    0.282     |     0.402     |
|    2     | 86.15858912467957  |   0.235   |     0.15     |    0.272     |     0.392     |
|    3     |  79.489919424057   |   0.224   |    0.139     |    0.258     |     0.387     |
|    4     | 100.31823253631592 |   0.216   |    0.128     |    0.247     |      0.39     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-30 00:13:08,197: Sum_Training_Time:542.964513540268
2024-12-30 00:13:08,197: Every_Training_Time:[185.68328857421875, 91.3144838809967, 86.15858912467957, 79.489919424057, 100.31823253631592]
2024-12-30 00:13:08,197: Forward transfer: 0.171725 Backward transfer: -0.0021999999999999936
2024-12-30 00:13:44,897: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241230001312/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[500.0, 15000.0, 10000.0, 10000.0], token_num=10, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-30 00:13:54,137: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:6.23	Hits@10:13.26	Best:6.23
2024-12-30 00:14:00,561: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.68	Hits@10:22.61	Best:9.68
2024-12-30 00:14:06,515: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.9	Hits@10:28.87	Best:12.9
2024-12-30 00:14:12,855: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.77	Hits@10:33.13	Best:15.77
2024-12-30 00:14:18,816: Snapshot:0	Epoch:4	Loss:4.364	translation_Loss:4.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.33	Hits@10:35.98	Best:18.33
2024-12-30 00:14:24,816: Snapshot:0	Epoch:5	Loss:3.084	translation_Loss:3.084	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.44	Hits@10:37.76	Best:20.44
2024-12-30 00:14:31,288: Snapshot:0	Epoch:6	Loss:2.176	translation_Loss:2.176	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.95	Hits@10:38.67	Best:21.95
2024-12-30 00:14:37,272: Snapshot:0	Epoch:7	Loss:1.541	translation_Loss:1.541	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.94	Hits@10:39.5	Best:22.94
2024-12-30 00:14:43,705: Snapshot:0	Epoch:8	Loss:1.097	translation_Loss:1.097	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.68	Hits@10:39.85	Best:23.68
2024-12-30 00:14:49,754: Snapshot:0	Epoch:9	Loss:0.815	translation_Loss:0.815	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.1	Hits@10:40.02	Best:24.1
2024-12-30 00:14:55,716: Snapshot:0	Epoch:10	Loss:0.628	translation_Loss:0.628	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.32	Hits@10:40.12	Best:24.32
2024-12-30 00:15:02,143: Snapshot:0	Epoch:11	Loss:0.498	translation_Loss:0.498	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.46	Hits@10:40.14	Best:24.46
2024-12-30 00:15:08,214: Snapshot:0	Epoch:12	Loss:0.41	translation_Loss:0.41	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.47	Hits@10:40.25	Best:24.47
2024-12-30 00:15:14,601: Snapshot:0	Epoch:13	Loss:0.35	translation_Loss:0.35	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.62	Hits@10:40.23	Best:24.62
2024-12-30 00:15:20,670: Snapshot:0	Epoch:14	Loss:0.31	translation_Loss:0.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.7	Hits@10:40.38	Best:24.7
2024-12-30 00:15:26,633: Snapshot:0	Epoch:15	Loss:0.273	translation_Loss:0.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.69	Hits@10:40.39	Best:24.7
2024-12-30 00:15:32,927: Snapshot:0	Epoch:16	Loss:0.244	translation_Loss:0.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.8	Hits@10:40.53	Best:24.8
2024-12-30 00:15:38,943: Snapshot:0	Epoch:17	Loss:0.223	translation_Loss:0.223	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.79	Hits@10:40.48	Best:24.8
2024-12-30 00:15:45,251: Snapshot:0	Epoch:18	Loss:0.207	translation_Loss:0.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.71	Hits@10:40.21	Best:24.8
2024-12-30 00:15:51,225: Early Stopping! Snapshot: 0 Epoch: 19 Best Results: 24.8
2024-12-30 00:15:51,225: Start to training tokens! Snapshot: 0 Epoch: 19 Loss:0.191 MRR:24.71 Best Results: 24.8
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-30 00:15:51,226: Snapshot:0	Epoch:19	Loss:0.191	translation_Loss:0.191	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.71	Hits@10:40.31	Best:24.8
2024-12-30 00:15:58,087: Snapshot:0	Epoch:20	Loss:29.545	translation_Loss:12.316	multi_layer_Loss:17.229	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.71	Hits@10:40.31	Best:24.8
2024-12-30 00:16:04,015: End of token training: 0 Epoch: 21 Loss:12.715 MRR:24.71 Best Results: 24.8
2024-12-30 00:16:04,015: Snapshot:0	Epoch:21	Loss:12.715	translation_Loss:12.307	multi_layer_Loss:0.409	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.71	Hits@10:40.31	Best:24.8
2024-12-30 00:16:04,262: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2024-12-30 00:16:06,745: 
+------------+------+--------+--------+--------+---------+
| Snapshot:0 | MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+------+--------+--------+--------+---------+
|     0      | 0.24 | 0.1537 | 0.2833 | 0.3316 |  0.3948 |
+------------+------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:16:29,062: Snapshot:1	Epoch:0	Loss:7.598	translation_Loss:7.151	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.447                                                   	MRR:20.67	Hits@10:34.57	Best:20.67
2024-12-30 00:16:35,469: Snapshot:1	Epoch:1	Loss:4.228	translation_Loss:3.233	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.995                                                   	MRR:22.25	Hits@10:37.05	Best:22.25
2024-12-30 00:16:42,243: Snapshot:1	Epoch:2	Loss:3.092	translation_Loss:1.829	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.263                                                   	MRR:22.98	Hits@10:38.37	Best:22.98
2024-12-30 00:16:48,682: Snapshot:1	Epoch:3	Loss:2.691	translation_Loss:1.342	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.349                                                   	MRR:23.25	Hits@10:38.31	Best:23.25
2024-12-30 00:16:55,031: Snapshot:1	Epoch:4	Loss:2.562	translation_Loss:1.175	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.387                                                   	MRR:23.25	Hits@10:38.59	Best:23.25
2024-12-30 00:17:01,853: Snapshot:1	Epoch:5	Loss:2.514	translation_Loss:1.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.414                                                   	MRR:23.38	Hits@10:38.61	Best:23.38
2024-12-30 00:17:08,227: Snapshot:1	Epoch:6	Loss:2.48	translation_Loss:1.048	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.431                                                   	MRR:23.31	Hits@10:38.52	Best:23.38
2024-12-30 00:17:14,885: Snapshot:1	Epoch:7	Loss:2.463	translation_Loss:1.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.447                                                   	MRR:23.21	Hits@10:38.7	Best:23.38
2024-12-30 00:17:21,282: Early Stopping! Snapshot: 1 Epoch: 8 Best Results: 23.38
2024-12-30 00:17:21,282: Start to training tokens! Snapshot: 1 Epoch: 8 Loss:2.462 MRR:23.28 Best Results: 23.38
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-30 00:17:21,282: Snapshot:1	Epoch:8	Loss:2.462	translation_Loss:1.007	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.456                                                   	MRR:23.28	Hits@10:38.64	Best:23.38
2024-12-30 00:17:27,607: Snapshot:1	Epoch:9	Loss:30.157	translation_Loss:13.35	multi_layer_Loss:16.806	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.28	Hits@10:38.64	Best:23.38
2024-12-30 00:17:34,261: End of token training: 1 Epoch: 10 Loss:13.728 MRR:23.28 Best Results: 23.38
2024-12-30 00:17:34,261: Snapshot:1	Epoch:10	Loss:13.728	translation_Loss:13.338	multi_layer_Loss:0.39	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.28	Hits@10:38.64	Best:23.38
2024-12-30 00:17:34,506: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2024-12-30 00:17:39,760: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2522 | 0.163  | 0.292  | 0.348  |  0.4218 |
|     1      | 0.234  | 0.1515 | 0.2723 | 0.3234 |  0.3867 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:18:02,496: Snapshot:2	Epoch:0	Loss:5.629	translation_Loss:4.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.335                                                   	MRR:21.11	Hits@10:36.55	Best:21.11
2024-12-30 00:18:09,010: Snapshot:2	Epoch:1	Loss:5.106	translation_Loss:4.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.09                                                   	MRR:21.52	Hits@10:37.03	Best:21.52
2024-12-30 00:18:15,721: Snapshot:2	Epoch:2	Loss:4.57	translation_Loss:3.626	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.944                                                   	MRR:21.66	Hits@10:37.19	Best:21.66
2024-12-30 00:18:22,288: Snapshot:2	Epoch:3	Loss:4.474	translation_Loss:3.554	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.92                                                   	MRR:21.65	Hits@10:37.34	Best:21.66
2024-12-30 00:18:28,819: Snapshot:2	Epoch:4	Loss:4.448	translation_Loss:3.532	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.915                                                   	MRR:21.63	Hits@10:37.36	Best:21.66
2024-12-30 00:18:35,812: Snapshot:2	Epoch:5	Loss:4.442	translation_Loss:3.527	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.915                                                   	MRR:21.75	Hits@10:37.34	Best:21.75
2024-12-30 00:18:42,338: Snapshot:2	Epoch:6	Loss:4.429	translation_Loss:3.515	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.914                                                   	MRR:21.7	Hits@10:37.29	Best:21.75
2024-12-30 00:18:49,249: Snapshot:2	Epoch:7	Loss:4.419	translation_Loss:3.504	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.915                                                   	MRR:21.68	Hits@10:37.26	Best:21.75
2024-12-30 00:18:55,808: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 21.75
2024-12-30 00:18:55,808: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:4.427 MRR:21.63 Best Results: 21.75
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-30 00:18:55,809: Snapshot:2	Epoch:8	Loss:4.427	translation_Loss:3.51	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.917                                                   	MRR:21.63	Hits@10:37.22	Best:21.75
2024-12-30 00:19:02,156: Snapshot:2	Epoch:9	Loss:32.365	translation_Loss:14.73	multi_layer_Loss:17.635	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.63	Hits@10:37.22	Best:21.75
2024-12-30 00:19:08,935: End of token training: 2 Epoch: 10 Loss:15.143 MRR:21.63 Best Results: 21.75
2024-12-30 00:19:08,935: Snapshot:2	Epoch:10	Loss:15.143	translation_Loss:14.723	multi_layer_Loss:0.42	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.63	Hits@10:37.22	Best:21.75
2024-12-30 00:19:09,165: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2024-12-30 00:19:17,283: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.252  | 0.1633 | 0.2914 | 0.3478 |  0.421  |
|     1      | 0.2366 | 0.1537 | 0.2737 | 0.3266 |  0.3927 |
|     2      | 0.2177 | 0.1357 | 0.2524 | 0.3049 |  0.3715 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:19:39,774: Snapshot:3	Epoch:0	Loss:4.242	translation_Loss:2.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.247                                                   	MRR:18.9	Hits@10:36.0	Best:18.9
2024-12-30 00:19:46,823: Snapshot:3	Epoch:1	Loss:3.726	translation_Loss:2.642	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.084                                                   	MRR:19.21	Hits@10:36.33	Best:19.21
2024-12-30 00:19:53,425: Snapshot:3	Epoch:2	Loss:3.46	translation_Loss:2.484	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.976                                                   	MRR:19.18	Hits@10:36.41	Best:19.21
2024-12-30 00:19:59,992: Snapshot:3	Epoch:3	Loss:3.429	translation_Loss:2.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.976                                                   	MRR:19.29	Hits@10:36.55	Best:19.29
2024-12-30 00:20:06,916: Snapshot:3	Epoch:4	Loss:3.425	translation_Loss:2.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.972                                                   	MRR:19.26	Hits@10:36.3	Best:19.29
2024-12-30 00:20:13,646: Snapshot:3	Epoch:5	Loss:3.432	translation_Loss:2.45	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.982                                                   	MRR:19.25	Hits@10:36.39	Best:19.29
2024-12-30 00:20:20,678: Early Stopping! Snapshot: 3 Epoch: 6 Best Results: 19.29
2024-12-30 00:20:20,679: Start to training tokens! Snapshot: 3 Epoch: 6 Loss:3.435 MRR:19.22 Best Results: 19.29
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-30 00:20:20,679: Snapshot:3	Epoch:6	Loss:3.435	translation_Loss:2.457	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.978                                                   	MRR:19.22	Hits@10:36.32	Best:19.29
2024-12-30 00:20:27,159: Snapshot:3	Epoch:7	Loss:31.551	translation_Loss:14.176	multi_layer_Loss:17.375	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.22	Hits@10:36.32	Best:19.29
2024-12-30 00:20:33,578: End of token training: 3 Epoch: 8 Loss:14.576 MRR:19.22 Best Results: 19.29
2024-12-30 00:20:33,578: Snapshot:3	Epoch:8	Loss:14.576	translation_Loss:14.179	multi_layer_Loss:0.397	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.22	Hits@10:36.32	Best:19.29
2024-12-30 00:20:33,816: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2024-12-30 00:20:45,424: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2478 | 0.1591 | 0.2864 | 0.3429 |  0.4173 |
|     1      | 0.2345 | 0.1505 | 0.2724 | 0.3256 |  0.3917 |
|     2      | 0.2183 | 0.1347 | 0.2525 | 0.3085 |  0.3813 |
|     3      | 0.1962 | 0.1099 | 0.2265 | 0.2867 |  0.3649 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:21:08,369: Snapshot:4	Epoch:0	Loss:2.798	translation_Loss:1.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.955                                                   	MRR:19.72	Hits@10:42.06	Best:19.72
2024-12-30 00:21:15,006: Snapshot:4	Epoch:1	Loss:1.957	translation_Loss:1.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.819                                                   	MRR:20.14	Hits@10:42.36	Best:20.14
2024-12-30 00:21:21,741: Snapshot:4	Epoch:2	Loss:1.726	translation_Loss:0.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.747                                                   	MRR:20.28	Hits@10:42.39	Best:20.28
2024-12-30 00:21:28,431: Snapshot:4	Epoch:3	Loss:1.71	translation_Loss:0.957	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.753                                                   	MRR:20.37	Hits@10:42.35	Best:20.37
2024-12-30 00:21:34,971: Snapshot:4	Epoch:4	Loss:1.703	translation_Loss:0.958	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.745                                                   	MRR:20.43	Hits@10:42.52	Best:20.43
2024-12-30 00:21:41,629: Snapshot:4	Epoch:5	Loss:1.701	translation_Loss:0.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.75                                                   	MRR:20.5	Hits@10:42.55	Best:20.5
2024-12-30 00:21:48,545: Snapshot:4	Epoch:6	Loss:1.692	translation_Loss:0.942	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.75                                                   	MRR:20.44	Hits@10:42.36	Best:20.5
2024-12-30 00:21:55,176: Snapshot:4	Epoch:7	Loss:1.689	translation_Loss:0.942	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.747                                                   	MRR:20.44	Hits@10:42.45	Best:20.5
2024-12-30 00:22:02,088: Early Stopping! Snapshot: 4 Epoch: 8 Best Results: 20.5
2024-12-30 00:22:02,088: Start to training tokens! Snapshot: 4 Epoch: 8 Loss:1.688 MRR:20.41 Best Results: 20.5
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([10, 200]), requires_grad: True
 - torch.Size([10, 200]), requires_grad: True
2024-12-30 00:22:02,089: Snapshot:4	Epoch:8	Loss:1.688	translation_Loss:0.942	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.746                                                   	MRR:20.41	Hits@10:42.18	Best:20.5
2024-12-30 00:22:08,608: Snapshot:4	Epoch:9	Loss:28.898	translation_Loss:11.897	multi_layer_Loss:17.001	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.41	Hits@10:42.18	Best:20.5
2024-12-30 00:22:15,231: End of token training: 4 Epoch: 10 Loss:12.288 MRR:20.41 Best Results: 20.5
2024-12-30 00:22:15,231: Snapshot:4	Epoch:10	Loss:12.288	translation_Loss:11.894	multi_layer_Loss:0.394	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.41	Hits@10:42.18	Best:20.5
2024-12-30 00:22:15,506: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2024-12-30 00:22:29,883: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.242  | 0.1548 | 0.2799 | 0.3342 |  0.4085 |
|     1      | 0.2275 | 0.1449 | 0.263  | 0.3144 |  0.3833 |
|     2      | 0.2126 | 0.129  | 0.2455 | 0.3005 |  0.3768 |
|     3      | 0.1954 | 0.1087 | 0.2229 | 0.2831 |  0.3719 |
|     4      | 0.2075 | 0.1017 | 0.2401 | 0.3193 |  0.4269 |
+------------+--------+--------+--------+--------+---------+
2024-12-30 00:22:29,886: Final Result:
[+------------+------+--------+--------+--------+---------+
| Snapshot:0 | MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+------+--------+--------+--------+---------+
|     0      | 0.24 | 0.1537 | 0.2833 | 0.3316 |  0.3948 |
+------------+------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2522 | 0.163  | 0.292  | 0.348  |  0.4218 |
|     1      | 0.234  | 0.1515 | 0.2723 | 0.3234 |  0.3867 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.252  | 0.1633 | 0.2914 | 0.3478 |  0.421  |
|     1      | 0.2366 | 0.1537 | 0.2737 | 0.3266 |  0.3927 |
|     2      | 0.2177 | 0.1357 | 0.2524 | 0.3049 |  0.3715 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2478 | 0.1591 | 0.2864 | 0.3429 |  0.4173 |
|     1      | 0.2345 | 0.1505 | 0.2724 | 0.3256 |  0.3917 |
|     2      | 0.2183 | 0.1347 | 0.2525 | 0.3085 |  0.3813 |
|     3      | 0.1962 | 0.1099 | 0.2265 | 0.2867 |  0.3649 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.242  | 0.1548 | 0.2799 | 0.3342 |  0.4085 |
|     1      | 0.2275 | 0.1449 | 0.263  | 0.3144 |  0.3833 |
|     2      | 0.2126 | 0.129  | 0.2455 | 0.3005 |  0.3768 |
|     3      | 0.1954 | 0.1087 | 0.2229 | 0.2831 |  0.3719 |
|     4      | 0.2075 | 0.1017 | 0.2401 | 0.3193 |  0.4269 |
+------------+--------+--------+--------+--------+---------+]
2024-12-30 00:22:29,886: Report Result:
+----------+-------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time       | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+-------------------+-----------+--------------+--------------+---------------+
|    0     | 139.1174714565277 |    0.24   |    0.154     |    0.283     |     0.395     |
|    1     | 84.73337817192078 |   0.243   |    0.157     |    0.282     |     0.404     |
|    2     | 86.23669672012329 |   0.235   |    0.151     |    0.273     |     0.395     |
|    3     | 73.33984136581421 |   0.224   |    0.139     |    0.259     |     0.389     |
|    4     |  87.0605788230896 |   0.217   |    0.128     |     0.25     |     0.393     |
+----------+-------------------+-----------+--------------+--------------+---------------+
2024-12-30 00:22:29,886: Sum_Training_Time:470.4879665374756
2024-12-30 00:22:29,886: Every_Training_Time:[139.1174714565277, 84.73337817192078, 86.23669672012329, 73.33984136581421, 87.0605788230896]
2024-12-30 00:22:29,886: Forward transfer: 0.173725 Backward transfer: -0.002600000000000005
2024-12-30 00:23:06,802: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241230002234/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[500.0, 15000.0, 10000.0, 10000.0], token_num=13, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-30 00:23:15,957: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:6.23	Hits@10:13.26	Best:6.23
2024-12-30 00:23:22,294: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.68	Hits@10:22.61	Best:9.68
2024-12-30 00:23:28,321: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.91	Hits@10:28.88	Best:12.91
2024-12-30 00:23:34,589: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.78	Hits@10:33.13	Best:15.78
2024-12-30 00:23:40,693: Snapshot:0	Epoch:4	Loss:4.364	translation_Loss:4.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.38	Hits@10:35.99	Best:18.38
2024-12-30 00:23:46,603: Snapshot:0	Epoch:5	Loss:3.085	translation_Loss:3.085	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.45	Hits@10:37.68	Best:20.45
2024-12-30 00:23:52,999: Snapshot:0	Epoch:6	Loss:2.176	translation_Loss:2.176	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.91	Hits@10:38.76	Best:21.91
2024-12-30 00:23:58,938: Snapshot:0	Epoch:7	Loss:1.54	translation_Loss:1.54	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.01	Hits@10:39.56	Best:23.01
2024-12-30 00:24:05,282: Snapshot:0	Epoch:8	Loss:1.096	translation_Loss:1.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.74	Hits@10:39.83	Best:23.74
2024-12-30 00:24:11,234: Snapshot:0	Epoch:9	Loss:0.816	translation_Loss:0.816	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.07	Hits@10:40.05	Best:24.07
2024-12-30 00:24:17,199: Snapshot:0	Epoch:10	Loss:0.626	translation_Loss:0.626	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.27	Hits@10:40.09	Best:24.27
2024-12-30 00:24:23,569: Snapshot:0	Epoch:11	Loss:0.495	translation_Loss:0.495	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.36	Hits@10:40.05	Best:24.36
2024-12-30 00:24:29,434: Snapshot:0	Epoch:12	Loss:0.411	translation_Loss:0.411	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.47	Hits@10:40.21	Best:24.47
2024-12-30 00:24:35,743: Snapshot:0	Epoch:13	Loss:0.353	translation_Loss:0.353	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.65	Hits@10:40.29	Best:24.65
2024-12-30 00:24:41,674: Snapshot:0	Epoch:14	Loss:0.311	translation_Loss:0.311	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.69	Hits@10:40.34	Best:24.69
2024-12-30 00:24:47,466: Snapshot:0	Epoch:15	Loss:0.275	translation_Loss:0.275	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.72	Hits@10:40.36	Best:24.72
2024-12-30 00:24:53,725: Snapshot:0	Epoch:16	Loss:0.244	translation_Loss:0.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.64	Hits@10:40.36	Best:24.72
2024-12-30 00:24:59,608: Snapshot:0	Epoch:17	Loss:0.224	translation_Loss:0.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.77	Hits@10:40.46	Best:24.77
2024-12-30 00:25:05,991: Snapshot:0	Epoch:18	Loss:0.207	translation_Loss:0.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.77	Hits@10:40.27	Best:24.77
2024-12-30 00:25:11,839: Snapshot:0	Epoch:19	Loss:0.19	translation_Loss:0.19	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:40.24	Best:24.77
2024-12-30 00:25:18,108: Snapshot:0	Epoch:20	Loss:0.181	translation_Loss:0.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.79	Hits@10:40.33	Best:24.79
2024-12-30 00:25:24,033: Snapshot:0	Epoch:21	Loss:0.167	translation_Loss:0.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.71	Hits@10:40.37	Best:24.79
2024-12-30 00:25:29,892: Snapshot:0	Epoch:22	Loss:0.155	translation_Loss:0.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.68	Hits@10:40.38	Best:24.79
2024-12-30 00:25:36,042: Early Stopping! Snapshot: 0 Epoch: 23 Best Results: 24.79
2024-12-30 00:25:36,042: Start to training tokens! Snapshot: 0 Epoch: 23 Loss:0.151 MRR:24.76 Best Results: 24.79
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([13, 200]), requires_grad: True
 - torch.Size([13, 200]), requires_grad: True
2024-12-30 00:25:36,042: Snapshot:0	Epoch:23	Loss:0.151	translation_Loss:0.151	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.76	Hits@10:40.45	Best:24.79
2024-12-30 00:25:42,517: Snapshot:0	Epoch:24	Loss:30.348	translation_Loss:12.305	multi_layer_Loss:18.044	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.76	Hits@10:40.45	Best:24.79
2024-12-30 00:25:48,727: End of token training: 0 Epoch: 25 Loss:12.776 MRR:24.76 Best Results: 24.79
2024-12-30 00:25:48,727: Snapshot:0	Epoch:25	Loss:12.776	translation_Loss:12.32	multi_layer_Loss:0.456	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.76	Hits@10:40.45	Best:24.79
2024-12-30 00:25:48,976: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2024-12-30 00:25:51,111: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2393 | 0.1544 | 0.2797 | 0.331  |  0.3943 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:26:13,858: Snapshot:1	Epoch:0	Loss:7.409	translation_Loss:6.897	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.512                                                   	MRR:20.51	Hits@10:34.62	Best:20.51
2024-12-30 00:26:20,430: Snapshot:1	Epoch:1	Loss:4.266	translation_Loss:3.16	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.106                                                   	MRR:22.28	Hits@10:36.96	Best:22.28
2024-12-30 00:26:26,953: Snapshot:1	Epoch:2	Loss:3.267	translation_Loss:1.93	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.336                                                   	MRR:22.86	Hits@10:37.8	Best:22.86
2024-12-30 00:26:33,327: Snapshot:1	Epoch:3	Loss:2.932	translation_Loss:1.52	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.412                                                   	MRR:23.15	Hits@10:38.25	Best:23.15
2024-12-30 00:26:40,208: Snapshot:1	Epoch:4	Loss:2.814	translation_Loss:1.367	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.447                                                   	MRR:23.14	Hits@10:38.24	Best:23.15
2024-12-30 00:26:46,575: Snapshot:1	Epoch:5	Loss:2.758	translation_Loss:1.287	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.471                                                   	MRR:23.12	Hits@10:38.45	Best:23.15
2024-12-30 00:26:52,828: Early Stopping! Snapshot: 1 Epoch: 6 Best Results: 23.15
2024-12-30 00:26:52,828: Start to training tokens! Snapshot: 1 Epoch: 6 Loss:2.739 MRR:23.09 Best Results: 23.15
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([13, 200]), requires_grad: True
 - torch.Size([13, 200]), requires_grad: True
2024-12-30 00:26:52,828: Snapshot:1	Epoch:6	Loss:2.739	translation_Loss:1.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.485                                                   	MRR:23.09	Hits@10:38.34	Best:23.15
2024-12-30 00:26:59,436: Snapshot:1	Epoch:7	Loss:31.55	translation_Loss:13.626	multi_layer_Loss:17.924	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.09	Hits@10:38.34	Best:23.15
2024-12-30 00:27:05,671: End of token training: 1 Epoch: 8 Loss:14.092 MRR:23.09 Best Results: 23.15
2024-12-30 00:27:05,671: Snapshot:1	Epoch:8	Loss:14.092	translation_Loss:13.621	multi_layer_Loss:0.471	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.09	Hits@10:38.34	Best:23.15
2024-12-30 00:27:05,860: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2024-12-30 00:27:11,086: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2526 | 0.1633 | 0.2931 | 0.3483 |  0.4195 |
|     1      | 0.231  | 0.1477 | 0.2707 | 0.3204 |  0.3844 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:27:34,243: Snapshot:2	Epoch:0	Loss:5.846	translation_Loss:4.476	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.37                                                   	MRR:20.57	Hits@10:35.36	Best:20.57
2024-12-30 00:27:40,739: Snapshot:2	Epoch:1	Loss:5.324	translation_Loss:4.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.126                                                   	MRR:21.02	Hits@10:35.86	Best:21.02
2024-12-30 00:27:47,243: Snapshot:2	Epoch:2	Loss:4.872	translation_Loss:3.891	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.98                                                   	MRR:21.14	Hits@10:36.11	Best:21.14
2024-12-30 00:27:53,812: Snapshot:2	Epoch:3	Loss:4.761	translation_Loss:3.813	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.948                                                   	MRR:21.2	Hits@10:36.23	Best:21.2
2024-12-30 00:28:00,304: Snapshot:2	Epoch:4	Loss:4.718	translation_Loss:3.778	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.94                                                   	MRR:21.14	Hits@10:36.13	Best:21.2
2024-12-30 00:28:06,822: Snapshot:2	Epoch:5	Loss:4.706	translation_Loss:3.768	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.938                                                   	MRR:21.21	Hits@10:36.14	Best:21.21
2024-12-30 00:28:13,575: Snapshot:2	Epoch:6	Loss:4.703	translation_Loss:3.764	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.939                                                   	MRR:21.28	Hits@10:36.1	Best:21.28
2024-12-30 00:28:20,417: Snapshot:2	Epoch:7	Loss:4.698	translation_Loss:3.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.938                                                   	MRR:21.17	Hits@10:36.13	Best:21.28
2024-12-30 00:28:26,932: Snapshot:2	Epoch:8	Loss:4.695	translation_Loss:3.757	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.939                                                   	MRR:21.18	Hits@10:36.09	Best:21.28
2024-12-30 00:28:33,437: Early Stopping! Snapshot: 2 Epoch: 9 Best Results: 21.28
2024-12-30 00:28:33,437: Start to training tokens! Snapshot: 2 Epoch: 9 Loss:4.694 MRR:21.22 Best Results: 21.28
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([13, 200]), requires_grad: True
 - torch.Size([13, 200]), requires_grad: True
2024-12-30 00:28:33,438: Snapshot:2	Epoch:9	Loss:4.694	translation_Loss:3.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.936                                                   	MRR:21.22	Hits@10:36.15	Best:21.28
2024-12-30 00:28:40,288: Snapshot:2	Epoch:10	Loss:33.068	translation_Loss:14.966	multi_layer_Loss:18.102	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.22	Hits@10:36.15	Best:21.28
2024-12-30 00:28:46,609: End of token training: 2 Epoch: 11 Loss:15.405 MRR:21.22 Best Results: 21.28
2024-12-30 00:28:46,609: Snapshot:2	Epoch:11	Loss:15.405	translation_Loss:14.956	multi_layer_Loss:0.449	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.22	Hits@10:36.15	Best:21.28
2024-12-30 00:28:46,846: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2024-12-30 00:28:55,188: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2524 | 0.1636 | 0.2923 | 0.3475 |  0.4202 |
|     1      | 0.2331 | 0.1503 | 0.2728 | 0.3221 |  0.3877 |
|     2      | 0.2098 | 0.1275 | 0.2474 | 0.2978 |  0.3619 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:29:18,018: Snapshot:3	Epoch:0	Loss:4.562	translation_Loss:3.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.307                                                   	MRR:18.3	Hits@10:34.58	Best:18.3
2024-12-30 00:29:24,741: Snapshot:3	Epoch:1	Loss:4.174	translation_Loss:3.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.082                                                   	MRR:18.71	Hits@10:35.05	Best:18.71
2024-12-30 00:29:31,354: Snapshot:3	Epoch:2	Loss:3.853	translation_Loss:2.881	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.972                                                   	MRR:18.68	Hits@10:35.21	Best:18.71
2024-12-30 00:29:37,924: Snapshot:3	Epoch:3	Loss:3.834	translation_Loss:2.877	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.957                                                   	MRR:18.79	Hits@10:35.27	Best:18.79
2024-12-30 00:29:45,008: Snapshot:3	Epoch:4	Loss:3.809	translation_Loss:2.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.958                                                   	MRR:18.8	Hits@10:35.25	Best:18.8
2024-12-30 00:29:51,555: Snapshot:3	Epoch:5	Loss:3.819	translation_Loss:2.862	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.957                                                   	MRR:18.69	Hits@10:35.14	Best:18.8
2024-12-30 00:29:58,091: Snapshot:3	Epoch:6	Loss:3.827	translation_Loss:2.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.964                                                   	MRR:18.73	Hits@10:35.14	Best:18.8
2024-12-30 00:30:05,118: Early Stopping! Snapshot: 3 Epoch: 7 Best Results: 18.8
2024-12-30 00:30:05,120: Start to training tokens! Snapshot: 3 Epoch: 7 Loss:3.816 MRR:18.8 Best Results: 18.8
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([13, 200]), requires_grad: True
 - torch.Size([13, 200]), requires_grad: True
2024-12-30 00:30:05,120: Snapshot:3	Epoch:7	Loss:3.816	translation_Loss:2.852	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.964                                                   	MRR:18.8	Hits@10:35.23	Best:18.8
2024-12-30 00:30:11,790: Snapshot:3	Epoch:8	Loss:32.739	translation_Loss:14.469	multi_layer_Loss:18.27	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.8	Hits@10:35.23	Best:18.8
2024-12-30 00:30:18,585: End of token training: 3 Epoch: 9 Loss:14.951 MRR:18.8 Best Results: 18.8
2024-12-30 00:30:18,585: Snapshot:3	Epoch:9	Loss:14.951	translation_Loss:14.488	multi_layer_Loss:0.463	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:18.8	Hits@10:35.23	Best:18.8
2024-12-30 00:30:18,808: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2024-12-30 00:30:30,056: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2492 | 0.1607 | 0.2865 | 0.3436 |  0.4173 |
|     1      | 0.2313 | 0.1475 | 0.2692 | 0.3213 |  0.3868 |
|     2      | 0.2122 | 0.1292 | 0.2476 | 0.3019 |  0.3715 |
|     3      | 0.1897 | 0.1056 | 0.2223 | 0.2776 |  0.3533 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-30 00:30:52,885: Snapshot:4	Epoch:0	Loss:3.167	translation_Loss:2.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.073                                                   	MRR:18.52	Hits@10:40.12	Best:18.52
2024-12-30 00:30:59,588: Snapshot:4	Epoch:1	Loss:2.357	translation_Loss:1.446	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.911                                                   	MRR:19.29	Hits@10:40.59	Best:19.29
2024-12-30 00:31:06,200: Snapshot:4	Epoch:2	Loss:2.098	translation_Loss:1.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.83                                                   	MRR:19.61	Hits@10:40.93	Best:19.61
2024-12-30 00:31:12,731: Snapshot:4	Epoch:3	Loss:2.074	translation_Loss:1.24	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.834                                                   	MRR:19.45	Hits@10:40.74	Best:19.61
2024-12-30 00:31:19,195: Snapshot:4	Epoch:4	Loss:2.071	translation_Loss:1.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.835                                                   	MRR:19.53	Hits@10:40.87	Best:19.61
2024-12-30 00:31:25,765: Early Stopping! Snapshot: 4 Epoch: 5 Best Results: 19.61
2024-12-30 00:31:25,766: Start to training tokens! Snapshot: 4 Epoch: 5 Loss:2.076 MRR:19.51 Best Results: 19.61
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([13, 200]), requires_grad: True
 - torch.Size([13, 200]), requires_grad: True
2024-12-30 00:31:25,766: Snapshot:4	Epoch:5	Loss:2.076	translation_Loss:1.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.84                                                   	MRR:19.51	Hits@10:40.85	Best:19.61
2024-12-30 00:31:32,763: Snapshot:4	Epoch:6	Loss:30.358	translation_Loss:12.217	multi_layer_Loss:18.141	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.51	Hits@10:40.85	Best:19.61
2024-12-30 00:31:39,334: End of token training: 4 Epoch: 7 Loss:12.688 MRR:19.51 Best Results: 19.61
2024-12-30 00:31:39,335: Snapshot:4	Epoch:7	Loss:12.688	translation_Loss:12.222	multi_layer_Loss:0.466	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.51	Hits@10:40.85	Best:19.61
2024-12-30 00:31:39,565: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2024-12-30 00:31:53,879: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2452 | 0.1584 |  0.28  | 0.3365 |  0.4098 |
|     1      | 0.2274 | 0.145  | 0.2646 | 0.314  |  0.3814 |
|     2      | 0.2089 | 0.1264 | 0.2405 | 0.2951 |  0.3702 |
|     3      | 0.1899 | 0.1049 | 0.2189 | 0.2775 |  0.3602 |
|     4      | 0.1974 | 0.0953 | 0.2276 | 0.3044 |  0.4071 |
+------------+--------+--------+--------+--------+---------+
2024-12-30 00:31:53,881: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2393 | 0.1544 | 0.2797 | 0.331  |  0.3943 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2526 | 0.1633 | 0.2931 | 0.3483 |  0.4195 |
|     1      | 0.231  | 0.1477 | 0.2707 | 0.3204 |  0.3844 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2524 | 0.1636 | 0.2923 | 0.3475 |  0.4202 |
|     1      | 0.2331 | 0.1503 | 0.2728 | 0.3221 |  0.3877 |
|     2      | 0.2098 | 0.1275 | 0.2474 | 0.2978 |  0.3619 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2492 | 0.1607 | 0.2865 | 0.3436 |  0.4173 |
|     1      | 0.2313 | 0.1475 | 0.2692 | 0.3213 |  0.3868 |
|     2      | 0.2122 | 0.1292 | 0.2476 | 0.3019 |  0.3715 |
|     3      | 0.1897 | 0.1056 | 0.2223 | 0.2776 |  0.3533 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2452 | 0.1584 |  0.28  | 0.3365 |  0.4098 |
|     1      | 0.2274 | 0.145  | 0.2646 | 0.314  |  0.3814 |
|     2      | 0.2089 | 0.1264 | 0.2405 | 0.2951 |  0.3702 |
|     3      | 0.1899 | 0.1049 | 0.2189 | 0.2775 |  0.3602 |
|     4      | 0.1974 | 0.0953 | 0.2276 | 0.3044 |  0.4071 |
+------------+--------+--------+--------+--------+---------+]
2024-12-30 00:31:53,882: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 161.92463183403015 |   0.239   |    0.154     |     0.28     |     0.394     |
|    1     | 71.50413918495178  |   0.242   |    0.155     |    0.282     |     0.402     |
|    2     | 92.59885716438293  |   0.232   |    0.147     |    0.271     |      0.39     |
|    3     | 80.42690062522888  |   0.221   |    0.136     |    0.256     |     0.382     |
|    4     | 66.26845288276672  |   0.214   |    0.126     |    0.246     |     0.386     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-30 00:31:53,882: Sum_Training_Time:472.7229816913605
2024-12-30 00:31:53,882: Every_Training_Time:[161.92463183403015, 71.50413918495178, 92.59885716438293, 80.42690062522888, 66.26845288276672]
2024-12-30 00:31:53,882: Forward transfer: 0.168575 Backward transfer: 0.0003999999999999976
