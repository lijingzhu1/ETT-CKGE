2025-01-05 20:47:28,788: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250105204709/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 3000.0, 800.0, 180000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-05 20:47:37,858: Snapshot:0	Epoch:0	Loss:15.399	translation_Loss:15.399	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.3	Hits@10:18.01	Best:7.3
2025-01-05 20:47:43,854: Snapshot:0	Epoch:1	Loss:10.741	translation_Loss:10.741	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.4	Hits@10:31.06	Best:12.4
2025-01-05 20:47:49,493: Snapshot:0	Epoch:2	Loss:7.011	translation_Loss:7.011	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.93	Hits@10:39.68	Best:18.93
2025-01-05 20:47:55,194: Snapshot:0	Epoch:3	Loss:4.123	translation_Loss:4.123	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.68	Hits@10:43.52	Best:22.68
2025-01-05 20:48:01,176: Snapshot:0	Epoch:4	Loss:2.463	translation_Loss:2.463	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.23	Hits@10:45.28	Best:24.23
2025-01-05 20:48:06,924: Snapshot:0	Epoch:5	Loss:1.562	translation_Loss:1.562	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.98	Hits@10:46.0	Best:24.98
2025-01-05 20:48:12,978: Snapshot:0	Epoch:6	Loss:1.067	translation_Loss:1.067	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.23	Hits@10:46.28	Best:25.23
2025-01-05 20:48:18,625: Snapshot:0	Epoch:7	Loss:0.8	translation_Loss:0.8	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.5	Hits@10:46.36	Best:25.5
2025-01-05 20:48:24,637: Snapshot:0	Epoch:8	Loss:0.631	translation_Loss:0.631	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.7	Hits@10:46.54	Best:25.7
2025-01-05 20:48:30,231: Snapshot:0	Epoch:9	Loss:0.536	translation_Loss:0.536	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:46.53	Best:25.79
2025-01-05 20:48:36,066: Snapshot:0	Epoch:10	Loss:0.455	translation_Loss:0.455	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.77	Hits@10:46.31	Best:25.79
2025-01-05 20:48:41,540: Snapshot:0	Epoch:11	Loss:0.402	translation_Loss:0.402	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:46.32	Best:25.79
2025-01-05 20:48:47,310: Snapshot:0	Epoch:12	Loss:0.356	translation_Loss:0.356	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.85	Hits@10:46.34	Best:25.85
2025-01-05 20:48:52,893: Snapshot:0	Epoch:13	Loss:0.319	translation_Loss:0.319	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.73	Hits@10:45.94	Best:25.85
2025-01-05 20:48:58,388: Snapshot:0	Epoch:14	Loss:0.293	translation_Loss:0.293	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.86	Hits@10:46.15	Best:25.86
2025-01-05 20:49:04,275: Snapshot:0	Epoch:15	Loss:0.27	translation_Loss:0.27	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.77	Hits@10:45.93	Best:25.86
2025-01-05 20:49:09,832: Snapshot:0	Epoch:16	Loss:0.253	translation_Loss:0.253	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.75	Hits@10:46.06	Best:25.86
2025-01-05 20:49:15,771: Snapshot:0	Epoch:17	Loss:0.237	translation_Loss:0.237	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.69	Hits@10:45.87	Best:25.86
2025-01-05 20:49:21,297: Snapshot:0	Epoch:18	Loss:0.223	translation_Loss:0.223	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.62	Hits@10:45.87	Best:25.86
2025-01-05 20:49:27,260: Early Stopping! Snapshot: 0 Epoch: 19 Best Results: 25.86
2025-01-05 20:49:27,260: Start to training tokens! Snapshot: 0 Epoch: 19 Loss:0.219 MRR:25.56 Best Results: 25.86
Token added to optimizer, embeddings excluded successfully.
2025-01-05 20:49:27,260: Snapshot:0	Epoch:19	Loss:0.219	translation_Loss:0.219	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.56	Hits@10:45.66	Best:25.86
2025-01-05 20:49:33,345: Snapshot:0	Epoch:20	Loss:26.529	translation_Loss:11.531	token_training_loss:14.999	distillation_Loss:0.0                                                   	MRR:25.56	Hits@10:45.66	Best:25.86
2025-01-05 20:49:39,181: End of token training: 0 Epoch: 21 Loss:11.892 MRR:25.56 Best Results: 25.86
2025-01-05 20:49:39,181: Snapshot:0	Epoch:21	Loss:11.892	translation_Loss:11.52	token_training_loss:0.373	distillation_Loss:0.0                                                           	MRR:25.56	Hits@10:45.66	Best:25.86
2025-01-05 20:49:39,430: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2025-01-05 20:49:41,811: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2584 | 0.153  | 0.3123 | 0.3772 |  0.4523 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 20:49:48,508: Snapshot:1	Epoch:0	Loss:4.973	translation_Loss:4.756	token_training_loss:0.0	distillation_Loss:0.218                                                   	MRR:9.54	Hits@10:16.84	Best:9.54
2025-01-05 20:49:51,017: Snapshot:1	Epoch:1	Loss:3.069	translation_Loss:2.669	token_training_loss:0.0	distillation_Loss:0.399                                                   	MRR:16.38	Hits@10:30.02	Best:16.38
2025-01-05 20:49:53,315: Snapshot:1	Epoch:2	Loss:1.984	translation_Loss:1.535	token_training_loss:0.0	distillation_Loss:0.45                                                   	MRR:20.66	Hits@10:35.95	Best:20.66
2025-01-05 20:49:55,470: Snapshot:1	Epoch:3	Loss:1.41	translation_Loss:0.998	token_training_loss:0.0	distillation_Loss:0.412                                                   	MRR:23.17	Hits@10:39.81	Best:23.17
2025-01-05 20:49:57,630: Snapshot:1	Epoch:4	Loss:1.103	translation_Loss:0.758	token_training_loss:0.0	distillation_Loss:0.345                                                   	MRR:24.38	Hits@10:43.21	Best:24.38
2025-01-05 20:49:59,694: Snapshot:1	Epoch:5	Loss:0.912	translation_Loss:0.617	token_training_loss:0.0	distillation_Loss:0.295                                                   	MRR:25.54	Hits@10:45.39	Best:25.54
2025-01-05 20:50:01,870: Snapshot:1	Epoch:6	Loss:0.802	translation_Loss:0.539	token_training_loss:0.0	distillation_Loss:0.262                                                   	MRR:26.34	Hits@10:46.84	Best:26.34
2025-01-05 20:50:04,374: Snapshot:1	Epoch:7	Loss:0.728	translation_Loss:0.483	token_training_loss:0.0	distillation_Loss:0.244                                                   	MRR:27.13	Hits@10:47.87	Best:27.13
2025-01-05 20:50:06,560: Snapshot:1	Epoch:8	Loss:0.679	translation_Loss:0.448	token_training_loss:0.0	distillation_Loss:0.231                                                   	MRR:27.52	Hits@10:48.46	Best:27.52
2025-01-05 20:50:08,811: Snapshot:1	Epoch:9	Loss:0.641	translation_Loss:0.421	token_training_loss:0.0	distillation_Loss:0.219                                                   	MRR:27.81	Hits@10:48.77	Best:27.81
2025-01-05 20:50:11,015: Snapshot:1	Epoch:10	Loss:0.606	translation_Loss:0.395	token_training_loss:0.0	distillation_Loss:0.211                                                   	MRR:28.51	Hits@10:49.47	Best:28.51
2025-01-05 20:50:13,135: Snapshot:1	Epoch:11	Loss:0.582	translation_Loss:0.378	token_training_loss:0.0	distillation_Loss:0.204                                                   	MRR:29.05	Hits@10:49.63	Best:29.05
2025-01-05 20:50:15,282: Snapshot:1	Epoch:12	Loss:0.561	translation_Loss:0.364	token_training_loss:0.0	distillation_Loss:0.197                                                   	MRR:29.2	Hits@10:49.86	Best:29.2
2025-01-05 20:50:17,783: Snapshot:1	Epoch:13	Loss:0.537	translation_Loss:0.346	token_training_loss:0.0	distillation_Loss:0.191                                                   	MRR:29.32	Hits@10:49.83	Best:29.32
2025-01-05 20:50:19,903: Snapshot:1	Epoch:14	Loss:0.522	translation_Loss:0.335	token_training_loss:0.0	distillation_Loss:0.187                                                   	MRR:29.2	Hits@10:50.12	Best:29.32
2025-01-05 20:50:22,073: Snapshot:1	Epoch:15	Loss:0.513	translation_Loss:0.329	token_training_loss:0.0	distillation_Loss:0.183                                                   	MRR:29.03	Hits@10:50.12	Best:29.32
2025-01-05 20:50:24,237: Snapshot:1	Epoch:16	Loss:0.5	translation_Loss:0.321	token_training_loss:0.0	distillation_Loss:0.179                                                   	MRR:29.27	Hits@10:49.98	Best:29.32
2025-01-05 20:50:26,460: Snapshot:1	Epoch:17	Loss:0.491	translation_Loss:0.314	token_training_loss:0.0	distillation_Loss:0.177                                                   	MRR:29.52	Hits@10:50.1	Best:29.52
2025-01-05 20:50:28,690: Snapshot:1	Epoch:18	Loss:0.478	translation_Loss:0.303	token_training_loss:0.0	distillation_Loss:0.175                                                   	MRR:29.47	Hits@10:50.06	Best:29.52
2025-01-05 20:50:31,229: Snapshot:1	Epoch:19	Loss:0.47	translation_Loss:0.298	token_training_loss:0.0	distillation_Loss:0.172                                                   	MRR:29.54	Hits@10:50.04	Best:29.54
2025-01-05 20:50:33,375: Snapshot:1	Epoch:20	Loss:0.461	translation_Loss:0.293	token_training_loss:0.0	distillation_Loss:0.168                                                   	MRR:29.51	Hits@10:50.38	Best:29.54
2025-01-05 20:50:35,604: Snapshot:1	Epoch:21	Loss:0.458	translation_Loss:0.291	token_training_loss:0.0	distillation_Loss:0.167                                                   	MRR:29.55	Hits@10:50.28	Best:29.55
2025-01-05 20:50:37,849: Snapshot:1	Epoch:22	Loss:0.46	translation_Loss:0.292	token_training_loss:0.0	distillation_Loss:0.167                                                   	MRR:29.7	Hits@10:50.54	Best:29.7
2025-01-05 20:50:40,026: Snapshot:1	Epoch:23	Loss:0.446	translation_Loss:0.281	token_training_loss:0.0	distillation_Loss:0.166                                                   	MRR:29.76	Hits@10:50.36	Best:29.76
2025-01-05 20:50:42,279: Snapshot:1	Epoch:24	Loss:0.444	translation_Loss:0.281	token_training_loss:0.0	distillation_Loss:0.163                                                   	MRR:29.55	Hits@10:50.3	Best:29.76
2025-01-05 20:50:44,874: Snapshot:1	Epoch:25	Loss:0.441	translation_Loss:0.278	token_training_loss:0.0	distillation_Loss:0.163                                                   	MRR:29.8	Hits@10:50.51	Best:29.8
2025-01-05 20:50:47,162: Snapshot:1	Epoch:26	Loss:0.439	translation_Loss:0.276	token_training_loss:0.0	distillation_Loss:0.163                                                   	MRR:29.81	Hits@10:50.54	Best:29.81
2025-01-05 20:50:49,439: Snapshot:1	Epoch:27	Loss:0.436	translation_Loss:0.276	token_training_loss:0.0	distillation_Loss:0.16                                                   	MRR:29.84	Hits@10:50.62	Best:29.84
2025-01-05 20:50:51,596: Snapshot:1	Epoch:28	Loss:0.43	translation_Loss:0.27	token_training_loss:0.0	distillation_Loss:0.16                                                   	MRR:29.76	Hits@10:50.56	Best:29.84
2025-01-05 20:50:53,828: Snapshot:1	Epoch:29	Loss:0.433	translation_Loss:0.274	token_training_loss:0.0	distillation_Loss:0.159                                                   	MRR:29.61	Hits@10:50.75	Best:29.84
2025-01-05 20:50:55,976: Snapshot:1	Epoch:30	Loss:0.427	translation_Loss:0.269	token_training_loss:0.0	distillation_Loss:0.159                                                   	MRR:29.74	Hits@10:50.73	Best:29.84
2025-01-05 20:50:58,550: Snapshot:1	Epoch:31	Loss:0.424	translation_Loss:0.268	token_training_loss:0.0	distillation_Loss:0.156                                                   	MRR:29.77	Hits@10:50.61	Best:29.84
2025-01-05 20:51:00,751: Snapshot:1	Epoch:32	Loss:0.426	translation_Loss:0.27	token_training_loss:0.0	distillation_Loss:0.156                                                   	MRR:29.94	Hits@10:50.46	Best:29.94
2025-01-05 20:51:02,908: Snapshot:1	Epoch:33	Loss:0.423	translation_Loss:0.266	token_training_loss:0.0	distillation_Loss:0.157                                                   	MRR:29.71	Hits@10:50.48	Best:29.94
2025-01-05 20:51:05,182: Snapshot:1	Epoch:34	Loss:0.423	translation_Loss:0.267	token_training_loss:0.0	distillation_Loss:0.156                                                   	MRR:29.83	Hits@10:50.36	Best:29.94
2025-01-05 20:51:07,331: Snapshot:1	Epoch:35	Loss:0.423	translation_Loss:0.266	token_training_loss:0.0	distillation_Loss:0.157                                                   	MRR:29.87	Hits@10:50.19	Best:29.94
2025-01-05 20:51:09,601: Snapshot:1	Epoch:36	Loss:0.42	translation_Loss:0.262	token_training_loss:0.0	distillation_Loss:0.158                                                   	MRR:30.04	Hits@10:50.35	Best:30.04
2025-01-05 20:51:12,070: Snapshot:1	Epoch:37	Loss:0.417	translation_Loss:0.259	token_training_loss:0.0	distillation_Loss:0.158                                                   	MRR:29.97	Hits@10:50.55	Best:30.04
2025-01-05 20:51:14,297: Snapshot:1	Epoch:38	Loss:0.417	translation_Loss:0.261	token_training_loss:0.0	distillation_Loss:0.156                                                   	MRR:29.83	Hits@10:50.65	Best:30.04
2025-01-05 20:51:16,376: Snapshot:1	Epoch:39	Loss:0.412	translation_Loss:0.258	token_training_loss:0.0	distillation_Loss:0.155                                                   	MRR:29.92	Hits@10:50.47	Best:30.04
2025-01-05 20:51:18,569: Snapshot:1	Epoch:40	Loss:0.414	translation_Loss:0.259	token_training_loss:0.0	distillation_Loss:0.155                                                   	MRR:29.94	Hits@10:50.71	Best:30.04
2025-01-05 20:51:20,720: Early Stopping! Snapshot: 1 Epoch: 41 Best Results: 30.04
2025-01-05 20:51:20,720: Start to training tokens! Snapshot: 1 Epoch: 41 Loss:0.413 MRR:29.71 Best Results: 30.04
Token added to optimizer, embeddings excluded successfully.
2025-01-05 20:51:20,721: Snapshot:1	Epoch:41	Loss:0.413	translation_Loss:0.257	token_training_loss:0.0	distillation_Loss:0.156                                                   	MRR:29.71	Hits@10:50.49	Best:30.04
2025-01-05 20:51:22,769: Snapshot:1	Epoch:42	Loss:16.252	translation_Loss:4.463	token_training_loss:11.789	distillation_Loss:0.0                                                   	MRR:29.71	Hits@10:50.49	Best:30.04
2025-01-05 20:51:25,304: End of token training: 1 Epoch: 43 Loss:7.095 MRR:29.71 Best Results: 30.04
2025-01-05 20:51:25,304: Snapshot:1	Epoch:43	Loss:7.095	translation_Loss:4.457	token_training_loss:2.638	distillation_Loss:0.0                                                           	MRR:29.71	Hits@10:50.49	Best:30.04
2025-01-05 20:51:25,570: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2025-01-05 20:51:29,099: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2583 | 0.1528 | 0.3133 | 0.3776 |  0.4525 |
|     1      | 0.2922 | 0.1863 | 0.3396 | 0.4117 |  0.5044 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 20:51:45,594: Snapshot:2	Epoch:0	Loss:15.723	translation_Loss:14.687	token_training_loss:0.0	distillation_Loss:1.036                                                   	MRR:14.29	Hits@10:28.87	Best:14.29
2025-01-05 20:51:54,936: Snapshot:2	Epoch:1	Loss:6.888	translation_Loss:5.437	token_training_loss:0.0	distillation_Loss:1.45                                                   	MRR:19.02	Hits@10:36.06	Best:19.02
2025-01-05 20:52:04,372: Snapshot:2	Epoch:2	Loss:4.448	translation_Loss:3.209	token_training_loss:0.0	distillation_Loss:1.239                                                   	MRR:20.65	Hits@10:37.4	Best:20.65
2025-01-05 20:52:13,397: Snapshot:2	Epoch:3	Loss:3.617	translation_Loss:2.524	token_training_loss:0.0	distillation_Loss:1.093                                                   	MRR:21.11	Hits@10:38.12	Best:21.11
2025-01-05 20:52:22,707: Snapshot:2	Epoch:4	Loss:3.273	translation_Loss:2.249	token_training_loss:0.0	distillation_Loss:1.024                                                   	MRR:21.39	Hits@10:38.04	Best:21.39
2025-01-05 20:52:32,116: Snapshot:2	Epoch:5	Loss:3.134	translation_Loss:2.143	token_training_loss:0.0	distillation_Loss:0.991                                                   	MRR:21.45	Hits@10:38.24	Best:21.45
2025-01-05 20:52:41,263: Snapshot:2	Epoch:6	Loss:3.034	translation_Loss:2.062	token_training_loss:0.0	distillation_Loss:0.972                                                   	MRR:21.51	Hits@10:38.33	Best:21.51
2025-01-05 20:52:50,643: Snapshot:2	Epoch:7	Loss:2.98	translation_Loss:2.019	token_training_loss:0.0	distillation_Loss:0.961                                                   	MRR:21.46	Hits@10:38.32	Best:21.51
2025-01-05 20:52:59,962: Snapshot:2	Epoch:8	Loss:2.934	translation_Loss:1.979	token_training_loss:0.0	distillation_Loss:0.955                                                   	MRR:21.67	Hits@10:38.21	Best:21.67
2025-01-05 20:53:09,163: Snapshot:2	Epoch:9	Loss:2.911	translation_Loss:1.96	token_training_loss:0.0	distillation_Loss:0.951                                                   	MRR:21.66	Hits@10:38.1	Best:21.67
2025-01-05 20:53:18,547: Snapshot:2	Epoch:10	Loss:2.894	translation_Loss:1.937	token_training_loss:0.0	distillation_Loss:0.957                                                   	MRR:21.62	Hits@10:38.23	Best:21.67
2025-01-05 20:53:28,006: Snapshot:2	Epoch:11	Loss:2.876	translation_Loss:1.926	token_training_loss:0.0	distillation_Loss:0.95                                                   	MRR:21.58	Hits@10:38.34	Best:21.67
2025-01-05 20:53:37,366: Snapshot:2	Epoch:12	Loss:2.851	translation_Loss:1.905	token_training_loss:0.0	distillation_Loss:0.947                                                   	MRR:21.43	Hits@10:38.2	Best:21.67
2025-01-05 20:53:46,342: Early Stopping! Snapshot: 2 Epoch: 13 Best Results: 21.67
2025-01-05 20:53:46,343: Start to training tokens! Snapshot: 2 Epoch: 13 Loss:2.844 MRR:21.62 Best Results: 21.67
Token added to optimizer, embeddings excluded successfully.
2025-01-05 20:53:46,343: Snapshot:2	Epoch:13	Loss:2.844	translation_Loss:1.899	token_training_loss:0.0	distillation_Loss:0.945                                                   	MRR:21.62	Hits@10:38.19	Best:21.67
2025-01-05 20:53:55,690: Snapshot:2	Epoch:14	Loss:32.344	translation_Loss:17.906	token_training_loss:14.438	distillation_Loss:0.0                                                   	MRR:21.62	Hits@10:38.19	Best:21.67
2025-01-05 20:54:04,951: End of token training: 2 Epoch: 15 Loss:18.04 MRR:21.62 Best Results: 21.67
2025-01-05 20:54:04,951: Snapshot:2	Epoch:15	Loss:18.04	translation_Loss:17.913	token_training_loss:0.127	distillation_Loss:0.0                                                           	MRR:21.62	Hits@10:38.19	Best:21.67
2025-01-05 20:54:05,187: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2025-01-05 20:54:12,965: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.253  | 0.1414 | 0.3105 | 0.3791 |  0.4591 |
|     1      | 0.2781 | 0.1741 | 0.3224 | 0.3891 |  0.4793 |
|     2      | 0.2163 | 0.1297 | 0.2484 | 0.3052 |  0.3839 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 20:54:32,208: Snapshot:3	Epoch:0	Loss:14.143	translation_Loss:13.368	token_training_loss:0.0	distillation_Loss:0.775                                                   	MRR:16.01	Hits@10:32.11	Best:16.01
2025-01-05 20:54:43,560: Snapshot:3	Epoch:1	Loss:5.023	translation_Loss:3.673	token_training_loss:0.0	distillation_Loss:1.35                                                   	MRR:20.21	Hits@10:37.87	Best:20.21
2025-01-05 20:54:54,859: Snapshot:3	Epoch:2	Loss:3.256	translation_Loss:1.925	token_training_loss:0.0	distillation_Loss:1.331                                                   	MRR:21.07	Hits@10:38.72	Best:21.07
2025-01-05 20:55:06,267: Snapshot:3	Epoch:3	Loss:2.733	translation_Loss:1.477	token_training_loss:0.0	distillation_Loss:1.255                                                   	MRR:21.35	Hits@10:39.31	Best:21.35
2025-01-05 20:55:17,302: Snapshot:3	Epoch:4	Loss:2.534	translation_Loss:1.311	token_training_loss:0.0	distillation_Loss:1.223                                                   	MRR:21.74	Hits@10:39.82	Best:21.74
2025-01-05 20:55:28,671: Snapshot:3	Epoch:5	Loss:2.414	translation_Loss:1.216	token_training_loss:0.0	distillation_Loss:1.197                                                   	MRR:21.66	Hits@10:39.63	Best:21.74
2025-01-05 20:55:39,937: Snapshot:3	Epoch:6	Loss:2.342	translation_Loss:1.157	token_training_loss:0.0	distillation_Loss:1.185                                                   	MRR:21.82	Hits@10:39.92	Best:21.82
2025-01-05 20:55:51,116: Snapshot:3	Epoch:7	Loss:2.307	translation_Loss:1.133	token_training_loss:0.0	distillation_Loss:1.174                                                   	MRR:21.78	Hits@10:39.87	Best:21.82
2025-01-05 20:56:02,392: Snapshot:3	Epoch:8	Loss:2.264	translation_Loss:1.095	token_training_loss:0.0	distillation_Loss:1.169                                                   	MRR:21.98	Hits@10:39.77	Best:21.98
2025-01-05 20:56:13,330: Snapshot:3	Epoch:9	Loss:2.244	translation_Loss:1.086	token_training_loss:0.0	distillation_Loss:1.158                                                   	MRR:21.9	Hits@10:39.92	Best:21.98
2025-01-05 20:56:24,709: Snapshot:3	Epoch:10	Loss:2.236	translation_Loss:1.082	token_training_loss:0.0	distillation_Loss:1.155                                                   	MRR:21.69	Hits@10:39.57	Best:21.98
2025-01-05 20:56:36,000: Snapshot:3	Epoch:11	Loss:2.239	translation_Loss:1.08	token_training_loss:0.0	distillation_Loss:1.159                                                   	MRR:21.81	Hits@10:39.82	Best:21.98
2025-01-05 20:56:47,157: Snapshot:3	Epoch:12	Loss:2.227	translation_Loss:1.064	token_training_loss:0.0	distillation_Loss:1.163                                                   	MRR:21.86	Hits@10:39.74	Best:21.98
2025-01-05 20:56:58,410: Early Stopping! Snapshot: 3 Epoch: 13 Best Results: 21.98
2025-01-05 20:56:58,410: Start to training tokens! Snapshot: 3 Epoch: 13 Loss:2.234 MRR:21.68 Best Results: 21.98
Token added to optimizer, embeddings excluded successfully.
2025-01-05 20:56:58,411: Snapshot:3	Epoch:13	Loss:2.234	translation_Loss:1.066	token_training_loss:0.0	distillation_Loss:1.168                                                   	MRR:21.68	Hits@10:39.74	Best:21.98
2025-01-05 20:57:09,231: Snapshot:3	Epoch:14	Loss:33.52	translation_Loss:18.173	token_training_loss:15.348	distillation_Loss:0.0                                                   	MRR:21.68	Hits@10:39.74	Best:21.98
2025-01-05 20:57:20,481: End of token training: 3 Epoch: 15 Loss:18.23 MRR:21.68 Best Results: 21.98
2025-01-05 20:57:20,481: Snapshot:3	Epoch:15	Loss:18.23	translation_Loss:18.16	token_training_loss:0.071	distillation_Loss:0.0                                                           	MRR:21.68	Hits@10:39.74	Best:21.98
2025-01-05 20:57:20,796: => loading checkpoint './checkpoint/HYBRID/3model_best.tar'
2025-01-05 20:57:32,924: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2572 | 0.1546 | 0.303  | 0.3694 |  0.4532 |
|     1      | 0.2755 | 0.1777 | 0.3093 | 0.3714 |  0.4734 |
|     2      | 0.2084 | 0.1232 | 0.2356 | 0.2949 |  0.3782 |
|     3      | 0.2193 | 0.1255 | 0.2555 | 0.3187 |  0.3967 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 20:57:43,299: Snapshot:4	Epoch:0	Loss:7.648	translation_Loss:6.312	token_training_loss:0.0	distillation_Loss:1.337                                                   	MRR:8.23	Hits@10:16.81	Best:8.23
2025-01-05 20:57:47,772: Snapshot:4	Epoch:1	Loss:5.548	translation_Loss:4.675	token_training_loss:0.0	distillation_Loss:0.873                                                   	MRR:14.09	Hits@10:27.17	Best:14.09
2025-01-05 20:57:52,662: Snapshot:4	Epoch:2	Loss:4.525	translation_Loss:3.705	token_training_loss:0.0	distillation_Loss:0.82                                                   	MRR:18.12	Hits@10:32.25	Best:18.12
2025-01-05 20:57:57,177: Snapshot:4	Epoch:3	Loss:3.822	translation_Loss:3.086	token_training_loss:0.0	distillation_Loss:0.736                                                   	MRR:20.85	Hits@10:34.78	Best:20.85
2025-01-05 20:58:01,779: Snapshot:4	Epoch:4	Loss:3.299	translation_Loss:2.638	token_training_loss:0.0	distillation_Loss:0.661                                                   	MRR:22.1	Hits@10:35.58	Best:22.1
2025-01-05 20:58:06,661: Snapshot:4	Epoch:5	Loss:2.969	translation_Loss:2.353	token_training_loss:0.0	distillation_Loss:0.615                                                   	MRR:22.36	Hits@10:35.62	Best:22.36
2025-01-05 20:58:11,114: Snapshot:4	Epoch:6	Loss:2.789	translation_Loss:2.204	token_training_loss:0.0	distillation_Loss:0.585                                                   	MRR:22.43	Hits@10:35.54	Best:22.43
2025-01-05 20:58:15,721: Snapshot:4	Epoch:7	Loss:2.692	translation_Loss:2.122	token_training_loss:0.0	distillation_Loss:0.569                                                   	MRR:22.41	Hits@10:35.56	Best:22.43
2025-01-05 20:58:20,570: Snapshot:4	Epoch:8	Loss:2.628	translation_Loss:2.07	token_training_loss:0.0	distillation_Loss:0.558                                                   	MRR:22.37	Hits@10:35.57	Best:22.43
2025-01-05 20:58:25,134: Snapshot:4	Epoch:9	Loss:2.594	translation_Loss:2.045	token_training_loss:0.0	distillation_Loss:0.549                                                   	MRR:22.35	Hits@10:35.58	Best:22.43
2025-01-05 20:58:29,572: Snapshot:4	Epoch:10	Loss:2.577	translation_Loss:2.035	token_training_loss:0.0	distillation_Loss:0.543                                                   	MRR:22.22	Hits@10:35.54	Best:22.43
2025-01-05 20:58:34,499: Early Stopping! Snapshot: 4 Epoch: 11 Best Results: 22.43
2025-01-05 20:58:34,500: Start to training tokens! Snapshot: 4 Epoch: 11 Loss:2.563 MRR:22.21 Best Results: 22.43
Token added to optimizer, embeddings excluded successfully.
2025-01-05 20:58:34,500: Snapshot:4	Epoch:11	Loss:2.563	translation_Loss:2.028	token_training_loss:0.0	distillation_Loss:0.535                                                   	MRR:22.21	Hits@10:35.51	Best:22.43
2025-01-05 20:58:39,008: Snapshot:4	Epoch:12	Loss:24.874	translation_Loss:9.81	token_training_loss:15.063	distillation_Loss:0.0                                                   	MRR:22.21	Hits@10:35.51	Best:22.43
2025-01-05 20:58:43,437: End of token training: 4 Epoch: 13 Loss:10.729 MRR:22.21 Best Results: 22.43
2025-01-05 20:58:43,437: Snapshot:4	Epoch:13	Loss:10.729	translation_Loss:9.814	token_training_loss:0.916	distillation_Loss:0.0                                                           	MRR:22.21	Hits@10:35.51	Best:22.43
2025-01-05 20:58:43,699: => loading checkpoint './checkpoint/HYBRID/4model_best.tar'
2025-01-05 20:58:57,997: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.241  | 0.1355 | 0.2874 | 0.3564 |  0.4445 |
|     1      | 0.2727 | 0.1744 | 0.3079 | 0.3696 |  0.4723 |
|     2      | 0.206  | 0.1202 | 0.233  | 0.2925 |  0.3778 |
|     3      | 0.2144 | 0.1198 | 0.2509 | 0.3159 |  0.3938 |
|     4      | 0.2255 | 0.1582 | 0.2496 | 0.2959 |  0.3571 |
+------------+--------+--------+--------+--------+---------+
2025-01-05 20:58:58,000: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2584 | 0.153  | 0.3123 | 0.3772 |  0.4523 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2583 | 0.1528 | 0.3133 | 0.3776 |  0.4525 |
|     1      | 0.2922 | 0.1863 | 0.3396 | 0.4117 |  0.5044 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.253  | 0.1414 | 0.3105 | 0.3791 |  0.4591 |
|     1      | 0.2781 | 0.1741 | 0.3224 | 0.3891 |  0.4793 |
|     2      | 0.2163 | 0.1297 | 0.2484 | 0.3052 |  0.3839 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2572 | 0.1546 | 0.303  | 0.3694 |  0.4532 |
|     1      | 0.2755 | 0.1777 | 0.3093 | 0.3714 |  0.4734 |
|     2      | 0.2084 | 0.1232 | 0.2356 | 0.2949 |  0.3782 |
|     3      | 0.2193 | 0.1255 | 0.2555 | 0.3187 |  0.3967 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.241  | 0.1355 | 0.2874 | 0.3564 |  0.4445 |
|     1      | 0.2727 | 0.1744 | 0.3079 | 0.3696 |  0.4723 |
|     2      | 0.206  | 0.1202 | 0.233  | 0.2925 |  0.3778 |
|     3      | 0.2144 | 0.1198 | 0.2509 | 0.3159 |  0.3938 |
|     4      | 0.2255 | 0.1582 | 0.2496 | 0.2959 |  0.3571 |
+------------+--------+--------+--------+--------+---------+]
2025-01-05 20:58:58,000: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 130.39291644096375 |   0.258   |    0.153     |    0.312     |     0.452     |
|    1     | 102.32638192176819 |   0.267   |    0.162     |     0.32     |     0.466     |
|    2     | 152.10285544395447 |   0.237   |    0.139     |    0.279     |     0.422     |
|    3     | 182.85658168792725 |   0.228   |    0.135     |    0.263     |     0.409     |
|    4     | 67.99478149414062  |   0.222   |    0.131     |    0.256     |     0.399     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-05 20:58:58,000: Sum_Training_Time:635.6735169887543
2025-01-05 20:58:58,000: Every_Training_Time:[130.39291644096375, 102.32638192176819, 152.10285544395447, 182.85658168792725, 67.99478149414062]
2025-01-05 20:58:58,000: Forward transfer: 0.0437 Backward transfer: -0.013025000000000009
2025-01-05 20:59:15,821: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250105205902/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 3000.0, 800.0, 200000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-05 20:59:24,686: Snapshot:0	Epoch:0	Loss:15.399	translation_Loss:15.399	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.3	Hits@10:18.01	Best:7.3
2025-01-05 20:59:30,539: Snapshot:0	Epoch:1	Loss:10.741	translation_Loss:10.741	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.4	Hits@10:31.06	Best:12.4
2025-01-05 20:59:35,996: Snapshot:0	Epoch:2	Loss:7.011	translation_Loss:7.011	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.94	Hits@10:39.68	Best:18.94
2025-01-05 20:59:41,427: Snapshot:0	Epoch:3	Loss:4.123	translation_Loss:4.123	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.69	Hits@10:43.57	Best:22.69
2025-01-05 20:59:47,283: Snapshot:0	Epoch:4	Loss:2.463	translation_Loss:2.463	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.23	Hits@10:45.22	Best:24.23
2025-01-05 20:59:52,754: Snapshot:0	Epoch:5	Loss:1.561	translation_Loss:1.561	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.02	Hits@10:46.04	Best:25.02
2025-01-05 20:59:58,544: Snapshot:0	Epoch:6	Loss:1.067	translation_Loss:1.067	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.26	Hits@10:46.2	Best:25.26
2025-01-05 21:00:04,195: Snapshot:0	Epoch:7	Loss:0.799	translation_Loss:0.799	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.63	Hits@10:46.55	Best:25.63
2025-01-05 21:00:10,296: Snapshot:0	Epoch:8	Loss:0.631	translation_Loss:0.631	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.68	Hits@10:46.68	Best:25.68
2025-01-05 21:00:15,811: Snapshot:0	Epoch:9	Loss:0.535	translation_Loss:0.535	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.66	Hits@10:46.49	Best:25.68
2025-01-05 21:00:21,527: Snapshot:0	Epoch:10	Loss:0.455	translation_Loss:0.455	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.66	Hits@10:46.4	Best:25.68
2025-01-05 21:00:27,049: Snapshot:0	Epoch:11	Loss:0.402	translation_Loss:0.402	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:46.48	Best:25.79
2025-01-05 21:00:32,814: Snapshot:0	Epoch:12	Loss:0.356	translation_Loss:0.356	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.76	Hits@10:46.28	Best:25.79
2025-01-05 21:00:38,260: Snapshot:0	Epoch:13	Loss:0.318	translation_Loss:0.318	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.85	Hits@10:46.1	Best:25.85
2025-01-05 21:00:43,780: Snapshot:0	Epoch:14	Loss:0.294	translation_Loss:0.294	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.77	Hits@10:46.12	Best:25.85
2025-01-05 21:00:49,626: Snapshot:0	Epoch:15	Loss:0.271	translation_Loss:0.271	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.76	Hits@10:46.0	Best:25.85
2025-01-05 21:00:55,120: Snapshot:0	Epoch:16	Loss:0.252	translation_Loss:0.252	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.68	Hits@10:45.9	Best:25.85
2025-01-05 21:01:00,949: Snapshot:0	Epoch:17	Loss:0.236	translation_Loss:0.236	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.49	Hits@10:45.85	Best:25.85
2025-01-05 21:01:06,574: Early Stopping! Snapshot: 0 Epoch: 18 Best Results: 25.85
2025-01-05 21:01:06,574: Start to training tokens! Snapshot: 0 Epoch: 18 Loss:0.223 MRR:25.48 Best Results: 25.85
Token added to optimizer, embeddings excluded successfully.
2025-01-05 21:01:06,575: Snapshot:0	Epoch:18	Loss:0.223	translation_Loss:0.223	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.48	Hits@10:45.63	Best:25.85
2025-01-05 21:01:12,886: Snapshot:0	Epoch:19	Loss:26.507	translation_Loss:11.508	token_training_loss:14.999	distillation_Loss:0.0                                                   	MRR:25.48	Hits@10:45.63	Best:25.85
2025-01-05 21:01:18,372: End of token training: 0 Epoch: 20 Loss:11.874 MRR:25.48 Best Results: 25.85
2025-01-05 21:01:18,372: Snapshot:0	Epoch:20	Loss:11.874	translation_Loss:11.501	token_training_loss:0.373	distillation_Loss:0.0                                                           	MRR:25.48	Hits@10:45.63	Best:25.85
2025-01-05 21:01:18,612: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2025-01-05 21:01:20,916: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2573 | 0.1502 | 0.314  | 0.3778 |  0.4518 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 21:01:27,819: Snapshot:1	Epoch:0	Loss:4.975	translation_Loss:4.756	token_training_loss:0.0	distillation_Loss:0.218                                                   	MRR:9.63	Hits@10:16.84	Best:9.63
2025-01-05 21:01:30,231: Snapshot:1	Epoch:1	Loss:3.085	translation_Loss:2.685	token_training_loss:0.0	distillation_Loss:0.4                                                   	MRR:16.45	Hits@10:30.2	Best:16.45
2025-01-05 21:01:32,409: Snapshot:1	Epoch:2	Loss:2.005	translation_Loss:1.554	token_training_loss:0.0	distillation_Loss:0.451                                                   	MRR:20.73	Hits@10:35.9	Best:20.73
2025-01-05 21:01:34,506: Snapshot:1	Epoch:3	Loss:1.434	translation_Loss:1.02	token_training_loss:0.0	distillation_Loss:0.414                                                   	MRR:23.37	Hits@10:39.94	Best:23.37
2025-01-05 21:01:36,577: Snapshot:1	Epoch:4	Loss:1.11	translation_Loss:0.76	token_training_loss:0.0	distillation_Loss:0.35                                                   	MRR:24.56	Hits@10:43.47	Best:24.56
2025-01-05 21:01:38,744: Snapshot:1	Epoch:5	Loss:0.926	translation_Loss:0.627	token_training_loss:0.0	distillation_Loss:0.298                                                   	MRR:25.5	Hits@10:45.65	Best:25.5
2025-01-05 21:01:40,872: Snapshot:1	Epoch:6	Loss:0.813	translation_Loss:0.547	token_training_loss:0.0	distillation_Loss:0.266                                                   	MRR:26.4	Hits@10:47.29	Best:26.4
2025-01-05 21:01:43,281: Snapshot:1	Epoch:7	Loss:0.741	translation_Loss:0.494	token_training_loss:0.0	distillation_Loss:0.247                                                   	MRR:27.09	Hits@10:47.96	Best:27.09
2025-01-05 21:01:45,395: Snapshot:1	Epoch:8	Loss:0.688	translation_Loss:0.452	token_training_loss:0.0	distillation_Loss:0.236                                                   	MRR:27.68	Hits@10:48.49	Best:27.68
2025-01-05 21:01:47,468: Snapshot:1	Epoch:9	Loss:0.653	translation_Loss:0.428	token_training_loss:0.0	distillation_Loss:0.225                                                   	MRR:28.21	Hits@10:48.95	Best:28.21
2025-01-05 21:01:49,629: Snapshot:1	Epoch:10	Loss:0.626	translation_Loss:0.41	token_training_loss:0.0	distillation_Loss:0.216                                                   	MRR:28.58	Hits@10:49.31	Best:28.58
2025-01-05 21:01:51,756: Snapshot:1	Epoch:11	Loss:0.594	translation_Loss:0.385	token_training_loss:0.0	distillation_Loss:0.209                                                   	MRR:28.85	Hits@10:49.87	Best:28.85
2025-01-05 21:01:53,865: Snapshot:1	Epoch:12	Loss:0.569	translation_Loss:0.367	token_training_loss:0.0	distillation_Loss:0.202                                                   	MRR:29.06	Hits@10:50.0	Best:29.06
2025-01-05 21:01:56,087: Snapshot:1	Epoch:13	Loss:0.553	translation_Loss:0.356	token_training_loss:0.0	distillation_Loss:0.197                                                   	MRR:29.32	Hits@10:50.02	Best:29.32
2025-01-05 21:01:58,488: Snapshot:1	Epoch:14	Loss:0.537	translation_Loss:0.344	token_training_loss:0.0	distillation_Loss:0.193                                                   	MRR:29.23	Hits@10:50.11	Best:29.32
2025-01-05 21:02:00,532: Snapshot:1	Epoch:15	Loss:0.526	translation_Loss:0.339	token_training_loss:0.0	distillation_Loss:0.187                                                   	MRR:29.34	Hits@10:50.29	Best:29.34
2025-01-05 21:02:02,605: Snapshot:1	Epoch:16	Loss:0.505	translation_Loss:0.321	token_training_loss:0.0	distillation_Loss:0.184                                                   	MRR:29.48	Hits@10:50.38	Best:29.48
2025-01-05 21:02:04,760: Snapshot:1	Epoch:17	Loss:0.502	translation_Loss:0.322	token_training_loss:0.0	distillation_Loss:0.18                                                   	MRR:29.73	Hits@10:50.35	Best:29.73
2025-01-05 21:02:06,858: Snapshot:1	Epoch:18	Loss:0.49	translation_Loss:0.312	token_training_loss:0.0	distillation_Loss:0.178                                                   	MRR:30.07	Hits@10:50.3	Best:30.07
2025-01-05 21:02:09,402: Snapshot:1	Epoch:19	Loss:0.488	translation_Loss:0.313	token_training_loss:0.0	distillation_Loss:0.175                                                   	MRR:30.24	Hits@10:50.66	Best:30.24
2025-01-05 21:02:11,458: Snapshot:1	Epoch:20	Loss:0.476	translation_Loss:0.302	token_training_loss:0.0	distillation_Loss:0.174                                                   	MRR:29.95	Hits@10:50.65	Best:30.24
2025-01-05 21:02:13,461: Snapshot:1	Epoch:21	Loss:0.474	translation_Loss:0.301	token_training_loss:0.0	distillation_Loss:0.174                                                   	MRR:30.05	Hits@10:50.72	Best:30.24
2025-01-05 21:02:15,560: Snapshot:1	Epoch:22	Loss:0.47	translation_Loss:0.298	token_training_loss:0.0	distillation_Loss:0.172                                                   	MRR:30.08	Hits@10:50.74	Best:30.24
2025-01-05 21:02:17,694: Snapshot:1	Epoch:23	Loss:0.459	translation_Loss:0.29	token_training_loss:0.0	distillation_Loss:0.17                                                   	MRR:30.02	Hits@10:50.68	Best:30.24
2025-01-05 21:02:19,854: Early Stopping! Snapshot: 1 Epoch: 24 Best Results: 30.24
2025-01-05 21:02:19,854: Start to training tokens! Snapshot: 1 Epoch: 24 Loss:0.457 MRR:30.04 Best Results: 30.24
Token added to optimizer, embeddings excluded successfully.
2025-01-05 21:02:19,854: Snapshot:1	Epoch:24	Loss:0.457	translation_Loss:0.289	token_training_loss:0.0	distillation_Loss:0.168                                                   	MRR:30.04	Hits@10:50.54	Best:30.24
2025-01-05 21:02:21,972: Snapshot:1	Epoch:25	Loss:16.236	translation_Loss:4.447	token_training_loss:11.789	distillation_Loss:0.0                                                   	MRR:30.04	Hits@10:50.54	Best:30.24
2025-01-05 21:02:24,340: End of token training: 1 Epoch: 26 Loss:7.077 MRR:30.04 Best Results: 30.24
2025-01-05 21:02:24,340: Snapshot:1	Epoch:26	Loss:7.077	translation_Loss:4.438	token_training_loss:2.638	distillation_Loss:0.0                                                           	MRR:30.04	Hits@10:50.54	Best:30.24
2025-01-05 21:02:24,582: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2025-01-05 21:02:27,971: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.258  | 0.1506 | 0.3149 |  0.38  |  0.4545 |
|     1      | 0.2932 | 0.1885 | 0.3387 | 0.4098 |  0.5054 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 21:02:44,472: Snapshot:2	Epoch:0	Loss:15.815	translation_Loss:14.774	token_training_loss:0.0	distillation_Loss:1.04                                                   	MRR:14.15	Hits@10:28.78	Best:14.15
2025-01-05 21:02:53,371: Snapshot:2	Epoch:1	Loss:7.023	translation_Loss:5.56	token_training_loss:0.0	distillation_Loss:1.463                                                   	MRR:19.02	Hits@10:36.19	Best:19.02
2025-01-05 21:03:02,580: Snapshot:2	Epoch:2	Loss:4.569	translation_Loss:3.309	token_training_loss:0.0	distillation_Loss:1.261                                                   	MRR:20.57	Hits@10:37.46	Best:20.57
2025-01-05 21:03:11,816: Snapshot:2	Epoch:3	Loss:3.74	translation_Loss:2.624	token_training_loss:0.0	distillation_Loss:1.116                                                   	MRR:21.12	Hits@10:37.91	Best:21.12
2025-01-05 21:03:21,148: Snapshot:2	Epoch:4	Loss:3.409	translation_Loss:2.359	token_training_loss:0.0	distillation_Loss:1.05                                                   	MRR:21.51	Hits@10:38.18	Best:21.51
2025-01-05 21:03:30,262: Snapshot:2	Epoch:5	Loss:3.237	translation_Loss:2.226	token_training_loss:0.0	distillation_Loss:1.012                                                   	MRR:21.49	Hits@10:38.31	Best:21.51
2025-01-05 21:03:39,533: Snapshot:2	Epoch:6	Loss:3.156	translation_Loss:2.156	token_training_loss:0.0	distillation_Loss:1.0                                                   	MRR:21.37	Hits@10:38.24	Best:21.51
2025-01-05 21:03:48,890: Snapshot:2	Epoch:7	Loss:3.083	translation_Loss:2.094	token_training_loss:0.0	distillation_Loss:0.989                                                   	MRR:21.58	Hits@10:38.53	Best:21.58
2025-01-05 21:03:57,988: Snapshot:2	Epoch:8	Loss:3.058	translation_Loss:2.075	token_training_loss:0.0	distillation_Loss:0.983                                                   	MRR:21.72	Hits@10:38.41	Best:21.72
2025-01-05 21:04:07,180: Snapshot:2	Epoch:9	Loss:3.026	translation_Loss:2.047	token_training_loss:0.0	distillation_Loss:0.979                                                   	MRR:21.48	Hits@10:38.22	Best:21.72
2025-01-05 21:04:16,402: Snapshot:2	Epoch:10	Loss:2.992	translation_Loss:2.017	token_training_loss:0.0	distillation_Loss:0.975                                                   	MRR:21.48	Hits@10:38.39	Best:21.72
2025-01-05 21:04:25,261: Snapshot:2	Epoch:11	Loss:2.983	translation_Loss:2.01	token_training_loss:0.0	distillation_Loss:0.973                                                   	MRR:21.65	Hits@10:38.42	Best:21.72
2025-01-05 21:04:34,469: Snapshot:2	Epoch:12	Loss:2.962	translation_Loss:1.99	token_training_loss:0.0	distillation_Loss:0.973                                                   	MRR:21.65	Hits@10:38.54	Best:21.72
2025-01-05 21:04:43,588: Early Stopping! Snapshot: 2 Epoch: 13 Best Results: 21.72
2025-01-05 21:04:43,589: Start to training tokens! Snapshot: 2 Epoch: 13 Loss:2.947 MRR:21.67 Best Results: 21.72
Token added to optimizer, embeddings excluded successfully.
2025-01-05 21:04:43,589: Snapshot:2	Epoch:13	Loss:2.947	translation_Loss:1.978	token_training_loss:0.0	distillation_Loss:0.97                                                   	MRR:21.67	Hits@10:38.41	Best:21.72
2025-01-05 21:04:52,350: Snapshot:2	Epoch:14	Loss:32.339	translation_Loss:17.901	token_training_loss:14.438	distillation_Loss:0.0                                                   	MRR:21.67	Hits@10:38.41	Best:21.72
2025-01-05 21:05:01,488: End of token training: 2 Epoch: 15 Loss:18.014 MRR:21.67 Best Results: 21.72
2025-01-05 21:05:01,488: Snapshot:2	Epoch:15	Loss:18.014	translation_Loss:17.887	token_training_loss:0.127	distillation_Loss:0.0                                                           	MRR:21.67	Hits@10:38.41	Best:21.72
2025-01-05 21:05:01,730: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2025-01-05 21:05:09,120: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2543 | 0.1438 | 0.3117 | 0.3785 |  0.4567 |
|     1      | 0.275  | 0.1707 | 0.3201 | 0.3844 |  0.4721 |
|     2      | 0.2172 | 0.1311 | 0.2465 | 0.3053 |  0.3857 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 21:05:28,621: Snapshot:3	Epoch:0	Loss:14.205	translation_Loss:13.428	token_training_loss:0.0	distillation_Loss:0.777                                                   	MRR:16.04	Hits@10:32.29	Best:16.04
2025-01-05 21:05:39,847: Snapshot:3	Epoch:1	Loss:5.086	translation_Loss:3.726	token_training_loss:0.0	distillation_Loss:1.359                                                   	MRR:20.23	Hits@10:38.13	Best:20.23
2025-01-05 21:05:50,768: Snapshot:3	Epoch:2	Loss:3.309	translation_Loss:1.964	token_training_loss:0.0	distillation_Loss:1.345                                                   	MRR:21.06	Hits@10:38.99	Best:21.06
2025-01-05 21:06:01,975: Snapshot:3	Epoch:3	Loss:2.779	translation_Loss:1.5	token_training_loss:0.0	distillation_Loss:1.279                                                   	MRR:21.42	Hits@10:39.65	Best:21.42
2025-01-05 21:06:13,247: Snapshot:3	Epoch:4	Loss:2.575	translation_Loss:1.332	token_training_loss:0.0	distillation_Loss:1.242                                                   	MRR:21.64	Hits@10:40.01	Best:21.64
2025-01-05 21:06:24,500: Snapshot:3	Epoch:5	Loss:2.455	translation_Loss:1.232	token_training_loss:0.0	distillation_Loss:1.223                                                   	MRR:21.78	Hits@10:39.97	Best:21.78
2025-01-05 21:06:35,718: Snapshot:3	Epoch:6	Loss:2.389	translation_Loss:1.192	token_training_loss:0.0	distillation_Loss:1.197                                                   	MRR:21.7	Hits@10:39.81	Best:21.78
2025-01-05 21:06:46,602: Snapshot:3	Epoch:7	Loss:2.343	translation_Loss:1.149	token_training_loss:0.0	distillation_Loss:1.194                                                   	MRR:21.98	Hits@10:40.07	Best:21.98
2025-01-05 21:06:57,714: Snapshot:3	Epoch:8	Loss:2.322	translation_Loss:1.138	token_training_loss:0.0	distillation_Loss:1.184                                                   	MRR:22.1	Hits@10:40.1	Best:22.1
2025-01-05 21:07:08,903: Snapshot:3	Epoch:9	Loss:2.297	translation_Loss:1.114	token_training_loss:0.0	distillation_Loss:1.183                                                   	MRR:21.85	Hits@10:39.86	Best:22.1
2025-01-05 21:07:20,121: Snapshot:3	Epoch:10	Loss:2.284	translation_Loss:1.103	token_training_loss:0.0	distillation_Loss:1.181                                                   	MRR:21.86	Hits@10:40.24	Best:22.1
2025-01-05 21:07:31,265: Snapshot:3	Epoch:11	Loss:2.268	translation_Loss:1.086	token_training_loss:0.0	distillation_Loss:1.183                                                   	MRR:21.8	Hits@10:40.05	Best:22.1
2025-01-05 21:07:42,331: Snapshot:3	Epoch:12	Loss:2.259	translation_Loss:1.081	token_training_loss:0.0	distillation_Loss:1.178                                                   	MRR:21.84	Hits@10:40.02	Best:22.1
2025-01-05 21:07:53,014: Early Stopping! Snapshot: 3 Epoch: 13 Best Results: 22.1
2025-01-05 21:07:53,015: Start to training tokens! Snapshot: 3 Epoch: 13 Loss:2.263 MRR:21.85 Best Results: 22.1
Token added to optimizer, embeddings excluded successfully.
2025-01-05 21:07:53,015: Snapshot:3	Epoch:13	Loss:2.263	translation_Loss:1.083	token_training_loss:0.0	distillation_Loss:1.181                                                   	MRR:21.85	Hits@10:39.91	Best:22.1
2025-01-05 21:08:04,091: Snapshot:3	Epoch:14	Loss:33.474	translation_Loss:18.127	token_training_loss:15.348	distillation_Loss:0.0                                                   	MRR:21.85	Hits@10:39.91	Best:22.1
2025-01-05 21:08:15,278: End of token training: 3 Epoch: 15 Loss:18.2 MRR:21.85 Best Results: 22.1
2025-01-05 21:08:15,279: Snapshot:3	Epoch:15	Loss:18.2	translation_Loss:18.129	token_training_loss:0.071	distillation_Loss:0.0                                                           	MRR:21.85	Hits@10:39.91	Best:22.1
2025-01-05 21:08:15,557: => loading checkpoint './checkpoint/HYBRID/3model_best.tar'
2025-01-05 21:08:28,053: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2587 | 0.1547 | 0.3078 | 0.3727 |  0.4554 |
|     1      | 0.2688 | 0.1696 | 0.3044 | 0.3727 |  0.466  |
|     2      | 0.2079 | 0.1224 | 0.2364 | 0.2924 |  0.3765 |
|     3      | 0.2201 | 0.1254 | 0.2586 | 0.3199 |  0.4014 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 21:08:38,691: Snapshot:4	Epoch:0	Loss:7.748	translation_Loss:6.329	token_training_loss:0.0	distillation_Loss:1.419                                                   	MRR:8.06	Hits@10:16.86	Best:8.06
2025-01-05 21:08:43,228: Snapshot:4	Epoch:1	Loss:5.577	translation_Loss:4.701	token_training_loss:0.0	distillation_Loss:0.877                                                   	MRR:13.96	Hits@10:27.11	Best:13.96
2025-01-05 21:08:47,833: Snapshot:4	Epoch:2	Loss:4.556	translation_Loss:3.735	token_training_loss:0.0	distillation_Loss:0.822                                                   	MRR:17.93	Hits@10:31.81	Best:17.93
2025-01-05 21:08:52,793: Snapshot:4	Epoch:3	Loss:3.837	translation_Loss:3.107	token_training_loss:0.0	distillation_Loss:0.731                                                   	MRR:20.63	Hits@10:34.33	Best:20.63
2025-01-05 21:08:57,385: Snapshot:4	Epoch:4	Loss:3.325	translation_Loss:2.667	token_training_loss:0.0	distillation_Loss:0.658                                                   	MRR:21.72	Hits@10:35.09	Best:21.72
2025-01-05 21:09:02,096: Snapshot:4	Epoch:5	Loss:3.0	translation_Loss:2.386	token_training_loss:0.0	distillation_Loss:0.614                                                   	MRR:22.0	Hits@10:35.15	Best:22.0
2025-01-05 21:09:07,080: Snapshot:4	Epoch:6	Loss:2.812	translation_Loss:2.228	token_training_loss:0.0	distillation_Loss:0.584                                                   	MRR:21.97	Hits@10:35.12	Best:22.0
2025-01-05 21:09:11,786: Snapshot:4	Epoch:7	Loss:2.714	translation_Loss:2.146	token_training_loss:0.0	distillation_Loss:0.569                                                   	MRR:21.94	Hits@10:35.09	Best:22.0
2025-01-05 21:09:16,430: Snapshot:4	Epoch:8	Loss:2.655	translation_Loss:2.097	token_training_loss:0.0	distillation_Loss:0.558                                                   	MRR:21.87	Hits@10:35.18	Best:22.0
2025-01-05 21:09:21,459: Snapshot:4	Epoch:9	Loss:2.615	translation_Loss:2.067	token_training_loss:0.0	distillation_Loss:0.548                                                   	MRR:21.88	Hits@10:35.13	Best:22.0
2025-01-05 21:09:26,106: Early Stopping! Snapshot: 4 Epoch: 10 Best Results: 22.0
2025-01-05 21:09:26,106: Start to training tokens! Snapshot: 4 Epoch: 10 Loss:2.592 MRR:21.78 Best Results: 22.0
Token added to optimizer, embeddings excluded successfully.
2025-01-05 21:09:26,107: Snapshot:4	Epoch:10	Loss:2.592	translation_Loss:2.052	token_training_loss:0.0	distillation_Loss:0.541                                                   	MRR:21.78	Hits@10:35.17	Best:22.0
2025-01-05 21:09:30,568: Snapshot:4	Epoch:11	Loss:24.866	translation_Loss:9.803	token_training_loss:15.063	distillation_Loss:0.0                                                   	MRR:21.78	Hits@10:35.17	Best:22.0
2025-01-05 21:09:34,997: End of token training: 4 Epoch: 12 Loss:10.72 MRR:21.78 Best Results: 22.0
2025-01-05 21:09:34,997: Snapshot:4	Epoch:12	Loss:10.72	translation_Loss:9.804	token_training_loss:0.916	distillation_Loss:0.0                                                           	MRR:21.78	Hits@10:35.17	Best:22.0
2025-01-05 21:09:35,287: => loading checkpoint './checkpoint/HYBRID/4model_best.tar'
2025-01-05 21:09:49,697: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2441 | 0.1368 | 0.2941 | 0.3624 |  0.4497 |
|     1      | 0.2651 | 0.1649 | 0.302  | 0.3685 |  0.464  |
|     2      | 0.2051 | 0.1192 | 0.2336 | 0.2908 |  0.3752 |
|     3      | 0.2148 | 0.1189 | 0.253  | 0.3163 |  0.3992 |
|     4      | 0.2196 | 0.151  | 0.2443 | 0.2926 |  0.3529 |
+------------+--------+--------+--------+--------+---------+
2025-01-05 21:09:49,699: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2573 | 0.1502 | 0.314  | 0.3778 |  0.4518 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.258  | 0.1506 | 0.3149 |  0.38  |  0.4545 |
|     1      | 0.2932 | 0.1885 | 0.3387 | 0.4098 |  0.5054 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2543 | 0.1438 | 0.3117 | 0.3785 |  0.4567 |
|     1      | 0.275  | 0.1707 | 0.3201 | 0.3844 |  0.4721 |
|     2      | 0.2172 | 0.1311 | 0.2465 | 0.3053 |  0.3857 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2587 | 0.1547 | 0.3078 | 0.3727 |  0.4554 |
|     1      | 0.2688 | 0.1696 | 0.3044 | 0.3727 |  0.466  |
|     2      | 0.2079 | 0.1224 | 0.2364 | 0.2924 |  0.3765 |
|     3      | 0.2201 | 0.1254 | 0.2586 | 0.3199 |  0.4014 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2441 | 0.1368 | 0.2941 | 0.3624 |  0.4497 |
|     1      | 0.2651 | 0.1649 | 0.302  | 0.3685 |  0.464  |
|     2      | 0.2051 | 0.1192 | 0.2336 | 0.2908 |  0.3752 |
|     3      | 0.2148 | 0.1189 | 0.253  | 0.3163 |  0.3992 |
|     4      | 0.2196 | 0.151  | 0.2443 | 0.2926 |  0.3529 |
+------------+--------+--------+--------+--------+---------+]
2025-01-05 21:09:49,699: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 122.5509181022644  |   0.257   |     0.15     |    0.314     |     0.452     |
|    1     | 62.037505865097046 |   0.267   |    0.161     |    0.321     |     0.468     |
|    2     | 149.79681825637817 |   0.237   |     0.14     |    0.278     |     0.421     |
|    3     | 181.24428153038025 |   0.228   |    0.134     |    0.265     |      0.41     |
|    4     |  64.4668779373169  |   0.221   |     0.13     |    0.257     |      0.4      |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-05 21:09:49,699: Sum_Training_Time:580.0964016914368
2025-01-05 21:09:49,699: Every_Training_Time:[122.5509181022644, 62.037505865097046, 149.79681825637817, 181.24428153038025, 64.4668779373169]
2025-01-05 21:09:49,699: Forward transfer: 0.043524999999999994 Backward transfer: -0.014674999999999994
