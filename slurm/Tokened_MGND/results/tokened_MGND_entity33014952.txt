2024-12-28 15:30:52,696: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241228153017/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=100000.0, token_num=2, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-28 15:31:00,535: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-28 15:31:04,443: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.11	Best:9.49
2024-12-28 15:31:08,527: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.7	Best:14.08
2024-12-28 15:31:12,297: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.75	Best:19.63
2024-12-28 15:31:16,063: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.65	Hits@10:48.72	Best:24.65
2024-12-28 15:31:20,107: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.3	Hits@10:52.05	Best:28.3
2024-12-28 15:31:23,856: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.41	Hits@10:53.89	Best:30.41
2024-12-28 15:31:28,030: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.79	Hits@10:55.44	Best:31.79
2024-12-28 15:31:31,728: Snapshot:0	Epoch:8	Loss:1.3	translation_Loss:1.3	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.69	Hits@10:56.14	Best:32.69
2024-12-28 15:31:35,411: Snapshot:0	Epoch:9	Loss:0.968	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.12	Hits@10:56.52	Best:33.12
2024-12-28 15:31:39,695: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.46	Hits@10:57.08	Best:33.46
2024-12-28 15:31:43,589: Snapshot:0	Epoch:11	Loss:0.608	translation_Loss:0.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.49	Hits@10:57.08	Best:33.49
2024-12-28 15:31:47,487: Snapshot:0	Epoch:12	Loss:0.499	translation_Loss:0.499	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:57.17	Best:33.68
2024-12-28 15:31:51,632: Snapshot:0	Epoch:13	Loss:0.422	translation_Loss:0.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.64	Hits@10:57.01	Best:33.68
2024-12-28 15:31:55,389: Snapshot:0	Epoch:14	Loss:0.373	translation_Loss:0.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:56.95	Best:33.68
2024-12-28 15:31:59,141: Snapshot:0	Epoch:15	Loss:0.33	translation_Loss:0.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.62	Hits@10:56.91	Best:33.68
2024-12-28 15:32:03,249: Snapshot:0	Epoch:16	Loss:0.302	translation_Loss:0.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.66	Hits@10:56.82	Best:33.68
2024-12-28 15:32:06,998: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 33.68
2024-12-28 15:32:06,998: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.278 MRR:33.65 Best Results: 33.68
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-28 15:32:06,998: Snapshot:0	Epoch:17	Loss:0.278	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.65	Hits@10:56.75	Best:33.68
2024-12-28 15:32:11,153: Snapshot:0	Epoch:18	Loss:18.216	translation_Loss:9.722	multi_layer_Loss:8.495	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.65	Hits@10:56.75	Best:33.68
2024-12-28 15:32:15,197: End of token training: 0 Epoch: 19 Loss:10.171 MRR:33.65 Best Results: 33.68
2024-12-28 15:32:15,198: Snapshot:0	Epoch:19	Loss:10.171	translation_Loss:9.716	multi_layer_Loss:0.456	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.65	Hits@10:56.75	Best:33.68
2024-12-28 15:32:15,447: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-28 15:32:16,783: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3405 | 0.2198 | 0.3963 | 0.4716 |  0.5722 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 15:32:41,461: Snapshot:1	Epoch:0	Loss:13.537	translation_Loss:12.934	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.602                                                   	MRR:14.66	Hits@10:25.55	Best:14.66
2024-12-28 15:32:48,058: Snapshot:1	Epoch:1	Loss:5.477	translation_Loss:5.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.242                                                   	MRR:20.63	Hits@10:36.94	Best:20.63
2024-12-28 15:32:54,544: Snapshot:1	Epoch:2	Loss:2.925	translation_Loss:2.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:23.13	Hits@10:41.22	Best:23.13
2024-12-28 15:33:01,163: Snapshot:1	Epoch:3	Loss:2.08	translation_Loss:1.942	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.138                                                   	MRR:24.03	Hits@10:42.72	Best:24.03
2024-12-28 15:33:07,727: Snapshot:1	Epoch:4	Loss:1.71	translation_Loss:1.586	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.124                                                   	MRR:24.43	Hits@10:43.29	Best:24.43
2024-12-28 15:33:14,633: Snapshot:1	Epoch:5	Loss:1.502	translation_Loss:1.384	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.118                                                   	MRR:24.65	Hits@10:43.91	Best:24.65
2024-12-28 15:33:21,283: Snapshot:1	Epoch:6	Loss:1.386	translation_Loss:1.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.115                                                   	MRR:25.0	Hits@10:43.98	Best:25.0
2024-12-28 15:33:28,152: Snapshot:1	Epoch:7	Loss:1.308	translation_Loss:1.194	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:24.87	Hits@10:44.07	Best:25.0
2024-12-28 15:33:34,731: Snapshot:1	Epoch:8	Loss:1.242	translation_Loss:1.128	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:24.91	Hits@10:44.09	Best:25.0
2024-12-28 15:33:41,698: Snapshot:1	Epoch:9	Loss:1.21	translation_Loss:1.098	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:25.05	Hits@10:44.17	Best:25.05
2024-12-28 15:33:48,268: Snapshot:1	Epoch:10	Loss:1.166	translation_Loss:1.054	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:25.17	Hits@10:44.49	Best:25.17
2024-12-28 15:33:55,158: Snapshot:1	Epoch:11	Loss:1.141	translation_Loss:1.028	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:25.14	Hits@10:44.51	Best:25.17
2024-12-28 15:34:01,662: Snapshot:1	Epoch:12	Loss:1.124	translation_Loss:1.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:25.14	Hits@10:44.61	Best:25.17
2024-12-28 15:34:08,391: Snapshot:1	Epoch:13	Loss:1.099	translation_Loss:0.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:25.15	Hits@10:44.38	Best:25.17
2024-12-28 15:34:14,887: Snapshot:1	Epoch:14	Loss:1.082	translation_Loss:0.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:25.19	Hits@10:44.55	Best:25.19
2024-12-28 15:34:21,617: Snapshot:1	Epoch:15	Loss:1.066	translation_Loss:0.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.115                                                   	MRR:25.09	Hits@10:44.43	Best:25.19
2024-12-28 15:34:28,428: Snapshot:1	Epoch:16	Loss:1.046	translation_Loss:0.934	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.112                                                   	MRR:25.21	Hits@10:44.45	Best:25.21
2024-12-28 15:34:34,896: Snapshot:1	Epoch:17	Loss:1.04	translation_Loss:0.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.112                                                   	MRR:25.18	Hits@10:44.55	Best:25.21
2024-12-28 15:34:41,692: Snapshot:1	Epoch:18	Loss:1.025	translation_Loss:0.911	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:25.14	Hits@10:44.49	Best:25.21
2024-12-28 15:34:48,166: Snapshot:1	Epoch:19	Loss:1.025	translation_Loss:0.912	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:25.2	Hits@10:44.47	Best:25.21
2024-12-28 15:34:54,943: Snapshot:1	Epoch:20	Loss:1.018	translation_Loss:0.905	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:25.2	Hits@10:44.58	Best:25.21
2024-12-28 15:35:01,495: Early Stopping! Snapshot: 1 Epoch: 21 Best Results: 25.21
2024-12-28 15:35:01,495: Start to training tokens! Snapshot: 1 Epoch: 21 Loss:1.009 MRR:25.21 Best Results: 25.21
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-28 15:35:01,496: Snapshot:1	Epoch:21	Loss:1.009	translation_Loss:0.894	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.115                                                   	MRR:25.21	Hits@10:44.46	Best:25.21
2024-12-28 15:35:08,419: Snapshot:1	Epoch:22	Loss:24.917	translation_Loss:15.784	multi_layer_Loss:9.133	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.21	Hits@10:44.46	Best:25.21
2024-12-28 15:35:14,908: End of token training: 1 Epoch: 23 Loss:15.969 MRR:25.21 Best Results: 25.21
2024-12-28 15:35:14,908: Snapshot:1	Epoch:23	Loss:15.969	translation_Loss:15.779	multi_layer_Loss:0.19	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.21	Hits@10:44.46	Best:25.21
2024-12-28 15:35:15,158: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-28 15:35:19,061: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3405 |  0.22  | 0.3952 | 0.471  |  0.573  |
|     1      | 0.2534 | 0.1539 | 0.2903 | 0.3554 |  0.4445 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 15:35:44,964: Snapshot:2	Epoch:0	Loss:12.208	translation_Loss:11.43	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.777                                                   	MRR:14.29	Hits@10:24.31	Best:14.29
2024-12-28 15:35:52,100: Snapshot:2	Epoch:1	Loss:4.362	translation_Loss:4.02	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.342                                                   	MRR:18.25	Hits@10:32.41	Best:18.25
2024-12-28 15:35:59,413: Snapshot:2	Epoch:2	Loss:2.49	translation_Loss:2.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.232                                                   	MRR:20.53	Hits@10:36.23	Best:20.53
2024-12-28 15:36:07,166: Snapshot:2	Epoch:3	Loss:1.9	translation_Loss:1.705	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:21.55	Hits@10:38.09	Best:21.55
2024-12-28 15:36:14,611: Snapshot:2	Epoch:4	Loss:1.644	translation_Loss:1.464	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.18                                                   	MRR:22.08	Hits@10:38.71	Best:22.08
2024-12-28 15:36:22,327: Snapshot:2	Epoch:5	Loss:1.517	translation_Loss:1.342	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.176                                                   	MRR:22.44	Hits@10:39.27	Best:22.44
2024-12-28 15:36:29,671: Snapshot:2	Epoch:6	Loss:1.425	translation_Loss:1.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:22.59	Hits@10:39.72	Best:22.59
2024-12-28 15:36:37,246: Snapshot:2	Epoch:7	Loss:1.361	translation_Loss:1.19	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:22.8	Hits@10:40.22	Best:22.8
2024-12-28 15:36:44,447: Snapshot:2	Epoch:8	Loss:1.315	translation_Loss:1.144	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:22.94	Hits@10:40.31	Best:22.94
2024-12-28 15:36:52,177: Snapshot:2	Epoch:9	Loss:1.291	translation_Loss:1.119	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:22.95	Hits@10:40.55	Best:22.95
2024-12-28 15:36:59,683: Snapshot:2	Epoch:10	Loss:1.255	translation_Loss:1.084	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:22.91	Hits@10:40.55	Best:22.95
2024-12-28 15:37:06,805: Snapshot:2	Epoch:11	Loss:1.23	translation_Loss:1.06	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:23.11	Hits@10:40.65	Best:23.11
2024-12-28 15:37:14,573: Snapshot:2	Epoch:12	Loss:1.212	translation_Loss:1.042	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:23.05	Hits@10:40.52	Best:23.11
2024-12-28 15:37:21,731: Snapshot:2	Epoch:13	Loss:1.198	translation_Loss:1.026	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:23.03	Hits@10:40.69	Best:23.11
2024-12-28 15:37:29,156: Snapshot:2	Epoch:14	Loss:1.174	translation_Loss:1.003	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:23.17	Hits@10:40.55	Best:23.17
2024-12-28 15:37:36,329: Snapshot:2	Epoch:15	Loss:1.18	translation_Loss:1.008	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:23.26	Hits@10:40.83	Best:23.26
2024-12-28 15:37:43,798: Snapshot:2	Epoch:16	Loss:1.161	translation_Loss:0.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:23.17	Hits@10:40.82	Best:23.26
2024-12-28 15:37:50,833: Snapshot:2	Epoch:17	Loss:1.14	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:23.15	Hits@10:40.8	Best:23.26
2024-12-28 15:37:58,251: Snapshot:2	Epoch:18	Loss:1.153	translation_Loss:0.98	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.174                                                   	MRR:23.32	Hits@10:41.12	Best:23.32
2024-12-28 15:38:05,765: Snapshot:2	Epoch:19	Loss:1.127	translation_Loss:0.955	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:23.28	Hits@10:41.1	Best:23.32
2024-12-28 15:38:12,894: Snapshot:2	Epoch:20	Loss:1.129	translation_Loss:0.957	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:23.32	Hits@10:41.08	Best:23.32
2024-12-28 15:38:20,475: Snapshot:2	Epoch:21	Loss:1.117	translation_Loss:0.943	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.174                                                   	MRR:23.35	Hits@10:41.1	Best:23.35
2024-12-28 15:38:27,774: Snapshot:2	Epoch:22	Loss:1.116	translation_Loss:0.943	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:23.33	Hits@10:41.05	Best:23.35
2024-12-28 15:38:35,448: Snapshot:2	Epoch:23	Loss:1.108	translation_Loss:0.934	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:23.26	Hits@10:41.05	Best:23.35
2024-12-28 15:38:42,540: Snapshot:2	Epoch:24	Loss:1.101	translation_Loss:0.928	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:23.31	Hits@10:41.12	Best:23.35
2024-12-28 15:38:50,203: Snapshot:2	Epoch:25	Loss:1.104	translation_Loss:0.931	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.174                                                   	MRR:23.42	Hits@10:41.2	Best:23.42
2024-12-28 15:38:57,255: Snapshot:2	Epoch:26	Loss:1.089	translation_Loss:0.916	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:23.3	Hits@10:41.17	Best:23.42
2024-12-28 15:39:04,912: Snapshot:2	Epoch:27	Loss:1.09	translation_Loss:0.916	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:23.36	Hits@10:41.21	Best:23.42
2024-12-28 15:39:12,397: Snapshot:2	Epoch:28	Loss:1.086	translation_Loss:0.911	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.175                                                   	MRR:23.37	Hits@10:41.24	Best:23.42
2024-12-28 15:39:19,511: Snapshot:2	Epoch:29	Loss:1.073	translation_Loss:0.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.174                                                   	MRR:23.51	Hits@10:41.37	Best:23.51
2024-12-28 15:39:27,179: Snapshot:2	Epoch:30	Loss:1.08	translation_Loss:0.906	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.174                                                   	MRR:23.37	Hits@10:41.33	Best:23.51
2024-12-28 15:39:34,250: Snapshot:2	Epoch:31	Loss:1.075	translation_Loss:0.902	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.174                                                   	MRR:23.45	Hits@10:41.34	Best:23.51
2024-12-28 15:39:41,676: Snapshot:2	Epoch:32	Loss:1.067	translation_Loss:0.894	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.174                                                   	MRR:23.46	Hits@10:41.38	Best:23.51
2024-12-28 15:39:48,746: Snapshot:2	Epoch:33	Loss:1.061	translation_Loss:0.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:23.4	Hits@10:41.28	Best:23.51
2024-12-28 15:39:56,129: Early Stopping! Snapshot: 2 Epoch: 34 Best Results: 23.51
2024-12-28 15:39:56,130: Start to training tokens! Snapshot: 2 Epoch: 34 Loss:1.055 MRR:23.45 Best Results: 23.51
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-28 15:39:56,130: Snapshot:2	Epoch:34	Loss:1.055	translation_Loss:0.882	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:23.45	Hits@10:41.28	Best:23.51
2024-12-28 15:40:03,244: Snapshot:2	Epoch:35	Loss:25.432	translation_Loss:15.643	multi_layer_Loss:9.788	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.45	Hits@10:41.28	Best:23.51
2024-12-28 15:40:10,941: End of token training: 2 Epoch: 36 Loss:15.838 MRR:23.45 Best Results: 23.51
2024-12-28 15:40:10,942: Snapshot:2	Epoch:36	Loss:15.838	translation_Loss:15.644	multi_layer_Loss:0.194	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.45	Hits@10:41.28	Best:23.51
2024-12-28 15:40:11,197: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-28 15:40:18,081: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3396 | 0.2186 | 0.3946 | 0.4698 |  0.5726 |
|     1      | 0.254  | 0.155  | 0.289  | 0.3556 |  0.4444 |
|     2      | 0.236  | 0.1404 | 0.2736 | 0.3328 |  0.4177 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 15:40:43,547: Snapshot:3	Epoch:0	Loss:11.207	translation_Loss:10.363	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.844                                                   	MRR:14.04	Hits@10:24.82	Best:14.04
2024-12-28 15:40:51,292: Snapshot:3	Epoch:1	Loss:3.57	translation_Loss:3.169	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.401                                                   	MRR:17.75	Hits@10:32.01	Best:17.75
2024-12-28 15:40:58,640: Snapshot:3	Epoch:2	Loss:2.037	translation_Loss:1.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.264                                                   	MRR:19.65	Hits@10:35.4	Best:19.65
2024-12-28 15:41:06,514: Snapshot:3	Epoch:3	Loss:1.576	translation_Loss:1.358	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:20.44	Hits@10:37.01	Best:20.44
2024-12-28 15:41:13,925: Snapshot:3	Epoch:4	Loss:1.378	translation_Loss:1.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:20.92	Hits@10:37.98	Best:20.92
2024-12-28 15:41:21,848: Snapshot:3	Epoch:5	Loss:1.266	translation_Loss:1.074	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.192                                                   	MRR:21.18	Hits@10:38.5	Best:21.18
2024-12-28 15:41:29,381: Snapshot:3	Epoch:6	Loss:1.191	translation_Loss:1.003	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:21.43	Hits@10:38.82	Best:21.43
2024-12-28 15:41:36,984: Snapshot:3	Epoch:7	Loss:1.151	translation_Loss:0.965	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.186                                                   	MRR:21.53	Hits@10:39.04	Best:21.53
2024-12-28 15:41:44,420: Snapshot:3	Epoch:8	Loss:1.119	translation_Loss:0.932	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:21.62	Hits@10:39.24	Best:21.62
2024-12-28 15:41:52,239: Snapshot:3	Epoch:9	Loss:1.085	translation_Loss:0.898	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:21.78	Hits@10:39.35	Best:21.78
2024-12-28 15:41:59,993: Snapshot:3	Epoch:10	Loss:1.071	translation_Loss:0.886	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.185                                                   	MRR:21.91	Hits@10:39.55	Best:21.91
2024-12-28 15:42:07,335: Snapshot:3	Epoch:11	Loss:1.049	translation_Loss:0.865	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.185                                                   	MRR:21.92	Hits@10:39.55	Best:21.92
2024-12-28 15:42:15,239: Snapshot:3	Epoch:12	Loss:1.041	translation_Loss:0.854	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:21.87	Hits@10:39.69	Best:21.92
2024-12-28 15:42:22,488: Snapshot:3	Epoch:13	Loss:1.023	translation_Loss:0.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.186                                                   	MRR:21.94	Hits@10:39.66	Best:21.94
2024-12-28 15:42:30,298: Snapshot:3	Epoch:14	Loss:1.008	translation_Loss:0.824	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.184                                                   	MRR:21.86	Hits@10:39.64	Best:21.94
2024-12-28 15:42:37,736: Snapshot:3	Epoch:15	Loss:0.997	translation_Loss:0.811	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.186                                                   	MRR:21.98	Hits@10:39.58	Best:21.98
2024-12-28 15:42:45,487: Snapshot:3	Epoch:16	Loss:0.989	translation_Loss:0.804	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.185                                                   	MRR:22.03	Hits@10:39.82	Best:22.03
2024-12-28 15:42:53,093: Snapshot:3	Epoch:17	Loss:0.985	translation_Loss:0.798	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:21.96	Hits@10:39.89	Best:22.03
2024-12-28 15:43:01,001: Snapshot:3	Epoch:18	Loss:0.971	translation_Loss:0.783	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:22.19	Hits@10:40.01	Best:22.19
2024-12-28 15:43:08,661: Snapshot:3	Epoch:19	Loss:0.968	translation_Loss:0.781	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:22.3	Hits@10:39.93	Best:22.3
2024-12-28 15:43:16,430: Snapshot:3	Epoch:20	Loss:0.962	translation_Loss:0.777	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.186                                                   	MRR:22.23	Hits@10:40.21	Best:22.3
2024-12-28 15:43:23,819: Snapshot:3	Epoch:21	Loss:0.961	translation_Loss:0.772	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:22.11	Hits@10:40.13	Best:22.3
2024-12-28 15:43:31,429: Snapshot:3	Epoch:22	Loss:0.949	translation_Loss:0.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:22.15	Hits@10:40.08	Best:22.3
2024-12-28 15:43:38,679: Snapshot:3	Epoch:23	Loss:0.94	translation_Loss:0.755	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.185                                                   	MRR:22.03	Hits@10:40.22	Best:22.3
2024-12-28 15:43:46,255: Early Stopping! Snapshot: 3 Epoch: 24 Best Results: 22.3
2024-12-28 15:43:46,255: Start to training tokens! Snapshot: 3 Epoch: 24 Loss:0.943 MRR:22.19 Best Results: 22.3
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-28 15:43:46,255: Snapshot:3	Epoch:24	Loss:0.943	translation_Loss:0.757	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.186                                                   	MRR:22.19	Hits@10:40.23	Best:22.3
2024-12-28 15:43:53,665: Snapshot:3	Epoch:25	Loss:24.745	translation_Loss:14.194	multi_layer_Loss:10.551	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.19	Hits@10:40.23	Best:22.3
2024-12-28 15:44:01,263: End of token training: 3 Epoch: 26 Loss:14.406 MRR:22.19 Best Results: 22.3
2024-12-28 15:44:01,264: Snapshot:3	Epoch:26	Loss:14.406	translation_Loss:14.185	multi_layer_Loss:0.222	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.19	Hits@10:40.23	Best:22.3
2024-12-28 15:44:01,513: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-28 15:44:11,736: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3405 | 0.2204 | 0.3959 | 0.4694 |  0.5715 |
|     1      | 0.2547 | 0.1557 | 0.2899 | 0.3563 |  0.4456 |
|     2      | 0.2373 | 0.1423 | 0.274  | 0.3332 |  0.418  |
|     3      | 0.2237 | 0.1314 | 0.259  | 0.3153 |  0.3987 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 15:44:31,006: Snapshot:4	Epoch:0	Loss:8.462	translation_Loss:7.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.654                                                   	MRR:15.99	Hits@10:30.34	Best:15.99
2024-12-28 15:44:36,771: Snapshot:4	Epoch:1	Loss:2.78	translation_Loss:2.394	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.386                                                   	MRR:21.09	Hits@10:38.87	Best:21.09
2024-12-28 15:44:42,076: Snapshot:4	Epoch:2	Loss:1.288	translation_Loss:1.074	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:23.86	Hits@10:42.64	Best:23.86
2024-12-28 15:44:47,410: Snapshot:4	Epoch:3	Loss:0.857	translation_Loss:0.708	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:24.73	Hits@10:44.34	Best:24.73
2024-12-28 15:44:53,253: Snapshot:4	Epoch:4	Loss:0.686	translation_Loss:0.565	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.121                                                   	MRR:25.41	Hits@10:45.25	Best:25.41
2024-12-28 15:44:58,618: Snapshot:4	Epoch:5	Loss:0.604	translation_Loss:0.496	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:25.77	Hits@10:45.56	Best:25.77
2024-12-28 15:45:04,109: Snapshot:4	Epoch:6	Loss:0.55	translation_Loss:0.447	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.104                                                   	MRR:25.89	Hits@10:45.8	Best:25.89
2024-12-28 15:45:09,910: Snapshot:4	Epoch:7	Loss:0.52	translation_Loss:0.419	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:26.01	Hits@10:45.84	Best:26.01
2024-12-28 15:45:15,405: Snapshot:4	Epoch:8	Loss:0.502	translation_Loss:0.401	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:26.11	Hits@10:46.3	Best:26.11
2024-12-28 15:45:21,295: Snapshot:4	Epoch:9	Loss:0.486	translation_Loss:0.387	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:26.12	Hits@10:46.31	Best:26.12
2024-12-28 15:45:26,802: Snapshot:4	Epoch:10	Loss:0.476	translation_Loss:0.376	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:26.32	Hits@10:46.74	Best:26.32
2024-12-28 15:45:32,139: Snapshot:4	Epoch:11	Loss:0.461	translation_Loss:0.361	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:26.29	Hits@10:46.45	Best:26.32
2024-12-28 15:45:37,895: Snapshot:4	Epoch:12	Loss:0.452	translation_Loss:0.352	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:26.41	Hits@10:46.67	Best:26.41
2024-12-28 15:45:43,388: Snapshot:4	Epoch:13	Loss:0.447	translation_Loss:0.347	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:26.57	Hits@10:46.76	Best:26.57
2024-12-28 15:45:48,737: Snapshot:4	Epoch:14	Loss:0.442	translation_Loss:0.341	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:26.61	Hits@10:46.85	Best:26.61
2024-12-28 15:45:54,001: Snapshot:4	Epoch:15	Loss:0.434	translation_Loss:0.334	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:26.59	Hits@10:46.67	Best:26.61
2024-12-28 15:45:59,611: Snapshot:4	Epoch:16	Loss:0.432	translation_Loss:0.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:26.59	Hits@10:46.75	Best:26.61
2024-12-28 15:46:04,890: Snapshot:4	Epoch:17	Loss:0.426	translation_Loss:0.323	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:26.68	Hits@10:47.23	Best:26.68
2024-12-28 15:46:10,190: Snapshot:4	Epoch:18	Loss:0.421	translation_Loss:0.319	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:26.65	Hits@10:47.26	Best:26.68
2024-12-28 15:46:15,800: Snapshot:4	Epoch:19	Loss:0.416	translation_Loss:0.315	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:26.61	Hits@10:47.04	Best:26.68
2024-12-28 15:46:21,021: Snapshot:4	Epoch:20	Loss:0.415	translation_Loss:0.313	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:26.6	Hits@10:46.99	Best:26.68
2024-12-28 15:46:26,665: Snapshot:4	Epoch:21	Loss:0.416	translation_Loss:0.314	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:26.58	Hits@10:47.27	Best:26.68
2024-12-28 15:46:31,984: Snapshot:4	Epoch:22	Loss:0.408	translation_Loss:0.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:26.75	Hits@10:47.3	Best:26.75
2024-12-28 15:46:37,370: Snapshot:4	Epoch:23	Loss:0.405	translation_Loss:0.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:26.9	Hits@10:47.13	Best:26.9
2024-12-28 15:46:43,109: Snapshot:4	Epoch:24	Loss:0.402	translation_Loss:0.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:26.78	Hits@10:47.24	Best:26.9
2024-12-28 15:46:48,421: Snapshot:4	Epoch:25	Loss:0.405	translation_Loss:0.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:26.82	Hits@10:47.39	Best:26.9
2024-12-28 15:46:53,705: Snapshot:4	Epoch:26	Loss:0.401	translation_Loss:0.298	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:26.64	Hits@10:47.15	Best:26.9
2024-12-28 15:46:59,299: Snapshot:4	Epoch:27	Loss:0.399	translation_Loss:0.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:26.84	Hits@10:47.62	Best:26.9
2024-12-28 15:47:04,547: Early Stopping! Snapshot: 4 Epoch: 28 Best Results: 26.9
2024-12-28 15:47:04,547: Start to training tokens! Snapshot: 4 Epoch: 28 Loss:0.4 MRR:26.86 Best Results: 26.9
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-28 15:47:04,547: Snapshot:4	Epoch:28	Loss:0.4	translation_Loss:0.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:26.86	Hits@10:47.55	Best:26.9
2024-12-28 15:47:09,800: Snapshot:4	Epoch:29	Loss:17.324	translation_Loss:7.794	multi_layer_Loss:9.531	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.86	Hits@10:47.55	Best:26.9
2024-12-28 15:47:15,543: End of token training: 4 Epoch: 30 Loss:8.215 MRR:26.86 Best Results: 26.9
2024-12-28 15:47:15,543: Snapshot:4	Epoch:30	Loss:8.215	translation_Loss:7.798	multi_layer_Loss:0.417	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.86	Hits@10:47.55	Best:26.9
2024-12-28 15:47:15,798: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-28 15:47:28,894: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3389 | 0.218  | 0.3943 | 0.4692 |  0.5707 |
|     1      | 0.2544 | 0.1552 | 0.2901 | 0.3564 |  0.4452 |
|     2      | 0.2377 | 0.1425 | 0.274  | 0.3336 |  0.4186 |
|     3      | 0.2252 | 0.1331 | 0.2604 | 0.3158 |  0.4014 |
|     4      | 0.2692 | 0.1594 | 0.3225 | 0.394  |  0.4812 |
+------------+--------+--------+--------+--------+---------+
2024-12-28 15:47:28,896: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3405 | 0.2198 | 0.3963 | 0.4716 |  0.5722 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3405 |  0.22  | 0.3952 | 0.471  |  0.573  |
|     1      | 0.2534 | 0.1539 | 0.2903 | 0.3554 |  0.4445 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3396 | 0.2186 | 0.3946 | 0.4698 |  0.5726 |
|     1      | 0.254  | 0.155  | 0.289  | 0.3556 |  0.4444 |
|     2      | 0.236  | 0.1404 | 0.2736 | 0.3328 |  0.4177 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3405 | 0.2204 | 0.3959 | 0.4694 |  0.5715 |
|     1      | 0.2547 | 0.1557 | 0.2899 | 0.3563 |  0.4456 |
|     2      | 0.2373 | 0.1423 | 0.274  | 0.3332 |  0.418  |
|     3      | 0.2237 | 0.1314 | 0.259  | 0.3153 |  0.3987 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3389 | 0.218  | 0.3943 | 0.4692 |  0.5707 |
|     1      | 0.2544 | 0.1552 | 0.2901 | 0.3564 |  0.4452 |
|     2      | 0.2377 | 0.1425 | 0.274  | 0.3336 |  0.4186 |
|     3      | 0.2252 | 0.1331 | 0.2604 | 0.3158 |  0.4014 |
|     4      | 0.2692 | 0.1594 | 0.3225 | 0.394  |  0.4812 |
+------------+--------+--------+--------+--------+---------+]
2024-12-28 15:47:28,897: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 82.50041818618774  |   0.341   |     0.22     |    0.396     |     0.572     |
|    1     | 175.72704076766968 |   0.287   |     0.18     |    0.331     |     0.495     |
|    2     | 289.0101532936096  |   0.268   |    0.165     |    0.309     |     0.465     |
|    3     | 219.87766337394714 |   0.257   |    0.157     |    0.296     |     0.447     |
|    4     | 181.0762870311737  |   0.259   |    0.157     |     0.3      |     0.453     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-28 15:47:28,897: Sum_Training_Time:948.1915626525879
2024-12-28 15:47:28,897: Every_Training_Time:[82.50041818618774, 175.72704076766968, 289.0101532936096, 219.87766337394714, 181.0762870311737]
2024-12-28 15:47:28,897: Forward transfer: 0.048025 Backward transfer: 0.0006499999999999909
2024-12-28 15:48:03,463: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241228154733/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=2, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-28 15:48:11,165: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-28 15:48:15,007: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.12	Best:9.49
2024-12-28 15:48:19,199: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.7	Best:14.08
2024-12-28 15:48:22,946: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.74	Best:19.63
2024-12-28 15:48:26,788: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:48.72	Best:24.66
2024-12-28 15:48:30,834: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.3	Hits@10:52.0	Best:28.3
2024-12-28 15:48:34,713: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.32	Hits@10:53.92	Best:30.32
2024-12-28 15:48:38,791: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.8	Hits@10:55.63	Best:31.8
2024-12-28 15:48:42,637: Snapshot:0	Epoch:8	Loss:1.299	translation_Loss:1.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.57	Hits@10:56.13	Best:32.57
2024-12-28 15:48:46,299: Snapshot:0	Epoch:9	Loss:0.968	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.18	Hits@10:56.6	Best:33.18
2024-12-28 15:48:50,475: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.51	Hits@10:57.01	Best:33.51
2024-12-28 15:48:54,325: Snapshot:0	Epoch:11	Loss:0.607	translation_Loss:0.607	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.56	Hits@10:57.16	Best:33.56
2024-12-28 15:48:58,039: Snapshot:0	Epoch:12	Loss:0.5	translation_Loss:0.5	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.75	Hits@10:57.11	Best:33.75
2024-12-28 15:49:02,108: Snapshot:0	Epoch:13	Loss:0.422	translation_Loss:0.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.65	Hits@10:57.05	Best:33.75
2024-12-28 15:49:05,809: Snapshot:0	Epoch:14	Loss:0.374	translation_Loss:0.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:56.95	Best:33.75
2024-12-28 15:49:09,513: Snapshot:0	Epoch:15	Loss:0.331	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.62	Hits@10:56.98	Best:33.75
2024-12-28 15:49:13,700: Snapshot:0	Epoch:16	Loss:0.303	translation_Loss:0.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.64	Hits@10:56.68	Best:33.75
2024-12-28 15:49:17,391: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 33.75
2024-12-28 15:49:17,392: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.278 MRR:33.63 Best Results: 33.75
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-28 15:49:17,392: Snapshot:0	Epoch:17	Loss:0.278	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.63	Hits@10:56.83	Best:33.75
2024-12-28 15:49:21,512: Snapshot:0	Epoch:18	Loss:18.212	translation_Loss:9.717	multi_layer_Loss:8.495	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.63	Hits@10:56.83	Best:33.75
2024-12-28 15:49:25,541: End of token training: 0 Epoch: 19 Loss:10.167 MRR:33.63 Best Results: 33.75
2024-12-28 15:49:25,541: Snapshot:0	Epoch:19	Loss:10.167	translation_Loss:9.711	multi_layer_Loss:0.456	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.63	Hits@10:56.83	Best:33.75
2024-12-28 15:49:25,790: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-28 15:49:27,106: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3412 | 0.2213 | 0.395  | 0.4703 |  0.5727 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 15:49:51,826: Snapshot:1	Epoch:0	Loss:13.207	translation_Loss:12.729	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.477                                                   	MRR:15.26	Hits@10:25.99	Best:15.26
2024-12-28 15:49:58,241: Snapshot:1	Epoch:1	Loss:5.576	translation_Loss:5.189	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.387                                                   	MRR:20.64	Hits@10:36.7	Best:20.64
2024-12-28 15:50:04,830: Snapshot:1	Epoch:2	Loss:3.009	translation_Loss:2.761	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.248                                                   	MRR:23.11	Hits@10:41.13	Best:23.11
2024-12-28 15:50:11,453: Snapshot:1	Epoch:3	Loss:2.145	translation_Loss:1.944	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:23.98	Hits@10:42.7	Best:23.98
2024-12-28 15:50:18,009: Snapshot:1	Epoch:4	Loss:1.766	translation_Loss:1.586	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.18                                                   	MRR:24.5	Hits@10:43.39	Best:24.5
2024-12-28 15:50:24,818: Snapshot:1	Epoch:5	Loss:1.547	translation_Loss:1.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:24.72	Hits@10:43.75	Best:24.72
2024-12-28 15:50:31,328: Snapshot:1	Epoch:6	Loss:1.426	translation_Loss:1.263	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.163                                                   	MRR:25.06	Hits@10:44.09	Best:25.06
2024-12-28 15:50:38,156: Snapshot:1	Epoch:7	Loss:1.34	translation_Loss:1.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.159                                                   	MRR:24.97	Hits@10:44.2	Best:25.06
2024-12-28 15:50:44,604: Snapshot:1	Epoch:8	Loss:1.271	translation_Loss:1.114	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.158                                                   	MRR:24.89	Hits@10:44.39	Best:25.06
2024-12-28 15:50:51,309: Snapshot:1	Epoch:9	Loss:1.236	translation_Loss:1.081	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:25.09	Hits@10:44.46	Best:25.09
2024-12-28 15:50:57,671: Snapshot:1	Epoch:10	Loss:1.192	translation_Loss:1.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:25.26	Hits@10:44.63	Best:25.26
2024-12-28 15:51:04,494: Snapshot:1	Epoch:11	Loss:1.166	translation_Loss:1.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:25.26	Hits@10:44.56	Best:25.26
2024-12-28 15:51:10,961: Snapshot:1	Epoch:12	Loss:1.147	translation_Loss:0.993	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:25.32	Hits@10:44.61	Best:25.32
2024-12-28 15:51:17,837: Snapshot:1	Epoch:13	Loss:1.122	translation_Loss:0.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:25.23	Hits@10:44.47	Best:25.32
2024-12-28 15:51:24,280: Snapshot:1	Epoch:14	Loss:1.105	translation_Loss:0.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:25.31	Hits@10:44.56	Best:25.32
2024-12-28 15:51:31,284: Snapshot:1	Epoch:15	Loss:1.09	translation_Loss:0.935	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:25.26	Hits@10:44.53	Best:25.32
2024-12-28 15:51:38,167: Snapshot:1	Epoch:16	Loss:1.07	translation_Loss:0.917	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:25.37	Hits@10:44.69	Best:25.37
2024-12-28 15:51:44,521: Snapshot:1	Epoch:17	Loss:1.063	translation_Loss:0.912	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.151                                                   	MRR:25.29	Hits@10:44.85	Best:25.37
2024-12-28 15:51:51,404: Snapshot:1	Epoch:18	Loss:1.048	translation_Loss:0.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:25.18	Hits@10:44.78	Best:25.37
2024-12-28 15:51:57,850: Snapshot:1	Epoch:19	Loss:1.047	translation_Loss:0.895	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:25.26	Hits@10:44.93	Best:25.37
2024-12-28 15:52:04,759: Snapshot:1	Epoch:20	Loss:1.042	translation_Loss:0.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:25.44	Hits@10:45.01	Best:25.44
2024-12-28 15:52:11,263: Snapshot:1	Epoch:21	Loss:1.031	translation_Loss:0.876	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:25.37	Hits@10:44.81	Best:25.44
2024-12-28 15:52:18,018: Snapshot:1	Epoch:22	Loss:1.01	translation_Loss:0.857	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:25.44	Hits@10:44.55	Best:25.44
2024-12-28 15:52:24,409: Snapshot:1	Epoch:23	Loss:1.016	translation_Loss:0.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:25.45	Hits@10:44.71	Best:25.45
2024-12-28 15:52:31,324: Snapshot:1	Epoch:24	Loss:1.0	translation_Loss:0.848	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:25.3	Hits@10:44.53	Best:25.45
2024-12-28 15:52:37,854: Snapshot:1	Epoch:25	Loss:0.991	translation_Loss:0.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:25.28	Hits@10:44.8	Best:25.45
2024-12-28 15:52:44,584: Snapshot:1	Epoch:26	Loss:0.993	translation_Loss:0.842	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:25.24	Hits@10:44.81	Best:25.45
2024-12-28 15:52:50,945: Snapshot:1	Epoch:27	Loss:0.983	translation_Loss:0.83	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:25.28	Hits@10:44.8	Best:25.45
2024-12-28 15:52:57,679: Early Stopping! Snapshot: 1 Epoch: 28 Best Results: 25.45
2024-12-28 15:52:57,679: Start to training tokens! Snapshot: 1 Epoch: 28 Loss:0.985 MRR:25.2 Best Results: 25.45
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-28 15:52:57,679: Snapshot:1	Epoch:28	Loss:0.985	translation_Loss:0.834	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:25.2	Hits@10:44.63	Best:25.45
2024-12-28 15:53:04,446: Snapshot:1	Epoch:29	Loss:24.812	translation_Loss:15.679	multi_layer_Loss:9.133	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.2	Hits@10:44.63	Best:25.45
2024-12-28 15:53:10,846: End of token training: 1 Epoch: 30 Loss:15.898 MRR:25.2 Best Results: 25.45
2024-12-28 15:53:10,846: Snapshot:1	Epoch:30	Loss:15.898	translation_Loss:15.707	multi_layer_Loss:0.19	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.2	Hits@10:44.63	Best:25.45
2024-12-28 15:53:11,095: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-28 15:53:15,033: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3396 | 0.2184 | 0.3946 | 0.4685 |  0.573  |
|     1      | 0.2545 | 0.1545 | 0.2909 | 0.3584 |  0.4488 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 15:53:40,748: Snapshot:2	Epoch:0	Loss:11.825	translation_Loss:11.209	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.616                                                   	MRR:15.09	Hits@10:25.55	Best:15.09
2024-12-28 15:53:48,034: Snapshot:2	Epoch:1	Loss:4.371	translation_Loss:3.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.497                                                   	MRR:18.67	Hits@10:32.66	Best:18.67
2024-12-28 15:53:55,372: Snapshot:2	Epoch:2	Loss:2.467	translation_Loss:2.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.31                                                   	MRR:20.46	Hits@10:36.12	Best:20.46
2024-12-28 15:54:02,530: Snapshot:2	Epoch:3	Loss:1.887	translation_Loss:1.634	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.253                                                   	MRR:21.55	Hits@10:37.9	Best:21.55
2024-12-28 15:54:10,102: Snapshot:2	Epoch:4	Loss:1.615	translation_Loss:1.386	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.229                                                   	MRR:22.15	Hits@10:39.28	Best:22.15
2024-12-28 15:54:17,229: Snapshot:2	Epoch:5	Loss:1.477	translation_Loss:1.259	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:22.55	Hits@10:39.92	Best:22.55
2024-12-28 15:54:24,790: Snapshot:2	Epoch:6	Loss:1.387	translation_Loss:1.174	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:22.81	Hits@10:39.98	Best:22.81
2024-12-28 15:54:32,360: Snapshot:2	Epoch:7	Loss:1.317	translation_Loss:1.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:22.9	Hits@10:40.41	Best:22.9
2024-12-28 15:54:39,563: Snapshot:2	Epoch:8	Loss:1.27	translation_Loss:1.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:23.0	Hits@10:40.64	Best:23.0
2024-12-28 15:54:47,089: Snapshot:2	Epoch:9	Loss:1.236	translation_Loss:1.032	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:23.13	Hits@10:40.72	Best:23.13
2024-12-28 15:54:54,274: Snapshot:2	Epoch:10	Loss:1.211	translation_Loss:1.008	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.203                                                   	MRR:23.22	Hits@10:40.73	Best:23.22
2024-12-28 15:55:02,066: Snapshot:2	Epoch:11	Loss:1.186	translation_Loss:0.983	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.203                                                   	MRR:23.26	Hits@10:41.12	Best:23.26
2024-12-28 15:55:09,445: Snapshot:2	Epoch:12	Loss:1.162	translation_Loss:0.959	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.203                                                   	MRR:23.31	Hits@10:41.19	Best:23.31
2024-12-28 15:55:17,119: Snapshot:2	Epoch:13	Loss:1.148	translation_Loss:0.946	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:23.54	Hits@10:41.3	Best:23.54
2024-12-28 15:55:24,438: Snapshot:2	Epoch:14	Loss:1.13	translation_Loss:0.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:23.27	Hits@10:41.45	Best:23.54
2024-12-28 15:55:31,956: Snapshot:2	Epoch:15	Loss:1.123	translation_Loss:0.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:23.45	Hits@10:41.41	Best:23.54
2024-12-28 15:55:39,295: Snapshot:2	Epoch:16	Loss:1.105	translation_Loss:0.904	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:23.35	Hits@10:41.5	Best:23.54
2024-12-28 15:55:46,379: Snapshot:2	Epoch:17	Loss:1.102	translation_Loss:0.9	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:23.53	Hits@10:41.59	Best:23.54
2024-12-28 15:55:53,808: Early Stopping! Snapshot: 2 Epoch: 18 Best Results: 23.54
2024-12-28 15:55:53,809: Start to training tokens! Snapshot: 2 Epoch: 18 Loss:1.094 MRR:23.46 Best Results: 23.54
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-28 15:55:53,809: Snapshot:2	Epoch:18	Loss:1.094	translation_Loss:0.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:23.46	Hits@10:41.47	Best:23.54
2024-12-28 15:56:00,862: Snapshot:2	Epoch:19	Loss:25.307	translation_Loss:15.519	multi_layer_Loss:9.788	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.46	Hits@10:41.47	Best:23.54
2024-12-28 15:56:08,320: End of token training: 2 Epoch: 20 Loss:15.698 MRR:23.46 Best Results: 23.54
2024-12-28 15:56:08,320: Snapshot:2	Epoch:20	Loss:15.698	translation_Loss:15.504	multi_layer_Loss:0.194	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.46	Hits@10:41.47	Best:23.54
2024-12-28 15:56:08,587: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-28 15:56:15,141: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3372 | 0.2163 | 0.3929 | 0.4673 |  0.5725 |
|     1      | 0.2561 | 0.1556 | 0.2935 | 0.3606 |  0.4511 |
|     2      | 0.2368 | 0.1412 | 0.2742 | 0.3338 |  0.4169 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 15:56:41,502: Snapshot:3	Epoch:0	Loss:10.753	translation_Loss:10.091	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.662                                                   	MRR:15.22	Hits@10:26.97	Best:15.22
2024-12-28 15:56:48,808: Snapshot:3	Epoch:1	Loss:3.458	translation_Loss:2.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.584                                                   	MRR:18.86	Hits@10:33.84	Best:18.86
2024-12-28 15:56:56,214: Snapshot:3	Epoch:2	Loss:1.917	translation_Loss:1.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.347                                                   	MRR:20.23	Hits@10:36.59	Best:20.23
2024-12-28 15:57:03,713: Snapshot:3	Epoch:3	Loss:1.444	translation_Loss:1.176	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.268                                                   	MRR:20.86	Hits@10:38.2	Best:20.86
2024-12-28 15:57:11,281: Snapshot:3	Epoch:4	Loss:1.273	translation_Loss:1.027	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.246                                                   	MRR:21.53	Hits@10:39.04	Best:21.53
2024-12-28 15:57:18,754: Snapshot:3	Epoch:5	Loss:1.16	translation_Loss:0.924	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.236                                                   	MRR:21.99	Hits@10:39.82	Best:21.99
2024-12-28 15:57:26,657: Snapshot:3	Epoch:6	Loss:1.088	translation_Loss:0.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.227                                                   	MRR:22.3	Hits@10:40.32	Best:22.3
2024-12-28 15:57:34,051: Snapshot:3	Epoch:7	Loss:1.04	translation_Loss:0.816	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.224                                                   	MRR:22.41	Hits@10:40.63	Best:22.41
2024-12-28 15:57:41,735: Snapshot:3	Epoch:8	Loss:1.008	translation_Loss:0.787	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:22.61	Hits@10:40.61	Best:22.61
2024-12-28 15:57:49,150: Snapshot:3	Epoch:9	Loss:0.98	translation_Loss:0.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:22.72	Hits@10:41.05	Best:22.72
2024-12-28 15:57:57,020: Snapshot:3	Epoch:10	Loss:0.95	translation_Loss:0.735	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.215                                                   	MRR:22.74	Hits@10:41.04	Best:22.74
2024-12-28 15:58:04,351: Snapshot:3	Epoch:11	Loss:0.947	translation_Loss:0.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.217                                                   	MRR:22.72	Hits@10:41.19	Best:22.74
2024-12-28 15:58:11,974: Snapshot:3	Epoch:12	Loss:0.923	translation_Loss:0.705	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:22.77	Hits@10:41.36	Best:22.77
2024-12-28 15:58:19,254: Snapshot:3	Epoch:13	Loss:0.911	translation_Loss:0.695	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.216                                                   	MRR:22.82	Hits@10:41.27	Best:22.82
2024-12-28 15:58:26,841: Snapshot:3	Epoch:14	Loss:0.895	translation_Loss:0.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.215                                                   	MRR:23.1	Hits@10:41.62	Best:23.1
2024-12-28 15:58:34,225: Snapshot:3	Epoch:15	Loss:0.891	translation_Loss:0.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:23.01	Hits@10:41.63	Best:23.1
2024-12-28 15:58:41,836: Snapshot:3	Epoch:16	Loss:0.879	translation_Loss:0.665	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:23.15	Hits@10:41.6	Best:23.15
2024-12-28 15:58:49,145: Snapshot:3	Epoch:17	Loss:0.886	translation_Loss:0.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.217                                                   	MRR:22.89	Hits@10:41.44	Best:23.15
2024-12-28 15:58:56,696: Snapshot:3	Epoch:18	Loss:0.869	translation_Loss:0.653	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.216                                                   	MRR:23.02	Hits@10:41.58	Best:23.15
2024-12-28 15:59:03,938: Snapshot:3	Epoch:19	Loss:0.87	translation_Loss:0.655	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.216                                                   	MRR:23.09	Hits@10:41.83	Best:23.15
2024-12-28 15:59:11,431: Snapshot:3	Epoch:20	Loss:0.858	translation_Loss:0.642	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.216                                                   	MRR:23.14	Hits@10:41.68	Best:23.15
2024-12-28 15:59:18,696: Early Stopping! Snapshot: 3 Epoch: 21 Best Results: 23.15
2024-12-28 15:59:18,696: Start to training tokens! Snapshot: 3 Epoch: 21 Loss:0.862 MRR:23.1 Best Results: 23.15
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-28 15:59:18,697: Snapshot:3	Epoch:21	Loss:0.862	translation_Loss:0.647	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.216                                                   	MRR:23.1	Hits@10:41.8	Best:23.15
2024-12-28 15:59:26,232: Snapshot:3	Epoch:22	Loss:24.483	translation_Loss:13.932	multi_layer_Loss:10.551	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.1	Hits@10:41.8	Best:23.15
2024-12-28 15:59:33,770: End of token training: 3 Epoch: 23 Loss:14.16 MRR:23.1 Best Results: 23.15
2024-12-28 15:59:33,770: Snapshot:3	Epoch:23	Loss:14.16	translation_Loss:13.938	multi_layer_Loss:0.222	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.1	Hits@10:41.8	Best:23.15
2024-12-28 15:59:34,008: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-28 15:59:43,779: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3357 | 0.2151 | 0.3908 | 0.4658 |  0.5691 |
|     1      | 0.2558 | 0.1548 | 0.2943 |  0.36  |  0.4513 |
|     2      | 0.2378 | 0.1412 | 0.2754 | 0.3354 |  0.4213 |
|     3      | 0.2318 | 0.1363 |  0.27  | 0.3309 |  0.413  |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:00:03,251: Snapshot:4	Epoch:0	Loss:7.96	translation_Loss:7.538	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.422                                                   	MRR:17.55	Hits@10:33.1	Best:17.55
2024-12-28 16:00:08,702: Snapshot:4	Epoch:1	Loss:2.466	translation_Loss:1.961	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.504                                                   	MRR:23.49	Hits@10:42.63	Best:23.49
2024-12-28 16:00:14,145: Snapshot:4	Epoch:2	Loss:1.095	translation_Loss:0.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.322                                                   	MRR:25.01	Hits@10:44.57	Best:25.01
2024-12-28 16:00:19,470: Snapshot:4	Epoch:3	Loss:0.7	translation_Loss:0.497	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:25.49	Hits@10:45.38	Best:25.49
2024-12-28 16:00:24,799: Snapshot:4	Epoch:4	Loss:0.556	translation_Loss:0.401	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:26.11	Hits@10:46.15	Best:26.11
2024-12-28 16:00:30,604: Snapshot:4	Epoch:5	Loss:0.482	translation_Loss:0.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.136                                                   	MRR:26.57	Hits@10:46.65	Best:26.57
2024-12-28 16:00:36,014: Snapshot:4	Epoch:6	Loss:0.446	translation_Loss:0.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:26.86	Hits@10:47.15	Best:26.86
2024-12-28 16:00:41,390: Snapshot:4	Epoch:7	Loss:0.412	translation_Loss:0.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.119                                                   	MRR:26.74	Hits@10:47.25	Best:26.86
2024-12-28 16:00:47,041: Snapshot:4	Epoch:8	Loss:0.395	translation_Loss:0.28	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.116                                                   	MRR:26.92	Hits@10:47.67	Best:26.92
2024-12-28 16:00:52,339: Snapshot:4	Epoch:9	Loss:0.378	translation_Loss:0.265	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:27.14	Hits@10:47.88	Best:27.14
2024-12-28 16:00:57,573: Snapshot:4	Epoch:10	Loss:0.365	translation_Loss:0.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.112                                                   	MRR:27.28	Hits@10:48.12	Best:27.28
2024-12-28 16:01:03,215: Snapshot:4	Epoch:11	Loss:0.355	translation_Loss:0.246	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:27.27	Hits@10:48.45	Best:27.28
2024-12-28 16:01:08,598: Snapshot:4	Epoch:12	Loss:0.344	translation_Loss:0.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:27.51	Hits@10:48.49	Best:27.51
2024-12-28 16:01:13,994: Snapshot:4	Epoch:13	Loss:0.338	translation_Loss:0.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:27.52	Hits@10:48.53	Best:27.52
2024-12-28 16:01:19,683: Snapshot:4	Epoch:14	Loss:0.331	translation_Loss:0.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:27.76	Hits@10:48.98	Best:27.76
2024-12-28 16:01:25,077: Snapshot:4	Epoch:15	Loss:0.328	translation_Loss:0.222	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.106                                                   	MRR:27.86	Hits@10:48.74	Best:27.86
2024-12-28 16:01:30,616: Snapshot:4	Epoch:16	Loss:0.328	translation_Loss:0.221	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:27.74	Hits@10:49.14	Best:27.86
2024-12-28 16:01:35,921: Snapshot:4	Epoch:17	Loss:0.321	translation_Loss:0.213	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:27.87	Hits@10:49.0	Best:27.87
2024-12-28 16:01:41,321: Snapshot:4	Epoch:18	Loss:0.321	translation_Loss:0.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:27.75	Hits@10:48.95	Best:27.87
2024-12-28 16:01:46,916: Snapshot:4	Epoch:19	Loss:0.319	translation_Loss:0.212	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.106                                                   	MRR:27.62	Hits@10:48.78	Best:27.87
2024-12-28 16:01:52,114: Snapshot:4	Epoch:20	Loss:0.315	translation_Loss:0.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:27.81	Hits@10:49.11	Best:27.87
2024-12-28 16:01:57,350: Snapshot:4	Epoch:21	Loss:0.316	translation_Loss:0.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:27.82	Hits@10:48.98	Best:27.87
2024-12-28 16:02:02,613: Snapshot:4	Epoch:22	Loss:0.309	translation_Loss:0.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:27.98	Hits@10:49.36	Best:27.98
2024-12-28 16:02:08,221: Snapshot:4	Epoch:23	Loss:0.307	translation_Loss:0.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:27.78	Hits@10:49.16	Best:27.98
2024-12-28 16:02:13,384: Snapshot:4	Epoch:24	Loss:0.308	translation_Loss:0.2	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:27.78	Hits@10:49.62	Best:27.98
2024-12-28 16:02:18,907: Snapshot:4	Epoch:25	Loss:0.306	translation_Loss:0.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:27.7	Hits@10:49.47	Best:27.98
2024-12-28 16:02:24,094: Snapshot:4	Epoch:26	Loss:0.301	translation_Loss:0.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.106                                                   	MRR:27.81	Hits@10:49.52	Best:27.98
2024-12-28 16:02:29,324: Early Stopping! Snapshot: 4 Epoch: 27 Best Results: 27.98
2024-12-28 16:02:29,324: Start to training tokens! Snapshot: 4 Epoch: 27 Loss:0.302 MRR:27.89 Best Results: 27.98
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-28 16:02:29,325: Snapshot:4	Epoch:27	Loss:0.302	translation_Loss:0.196	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.106                                                   	MRR:27.89	Hits@10:49.6	Best:27.98
2024-12-28 16:02:34,921: Snapshot:4	Epoch:28	Loss:17.066	translation_Loss:7.535	multi_layer_Loss:9.531	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.89	Hits@10:49.6	Best:27.98
2024-12-28 16:02:40,087: End of token training: 4 Epoch: 29 Loss:7.955 MRR:27.89 Best Results: 27.98
2024-12-28 16:02:40,088: Snapshot:4	Epoch:29	Loss:7.955	translation_Loss:7.537	multi_layer_Loss:0.417	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.89	Hits@10:49.6	Best:27.98
2024-12-28 16:02:40,324: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-28 16:02:52,959: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3312 | 0.2092 | 0.3875 | 0.4615 |  0.5661 |
|     1      | 0.2532 | 0.1514 | 0.2909 | 0.3576 |  0.4488 |
|     2      | 0.2358 | 0.1387 | 0.2749 | 0.3354 |  0.4211 |
|     3      | 0.2325 | 0.1354 | 0.2722 | 0.3335 |  0.4161 |
|     4      | 0.2854 | 0.1726 | 0.3419 | 0.4133 |  0.5011 |
+------------+--------+--------+--------+--------+---------+
2024-12-28 16:02:52,961: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3412 | 0.2213 | 0.395  | 0.4703 |  0.5727 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3396 | 0.2184 | 0.3946 | 0.4685 |  0.573  |
|     1      | 0.2545 | 0.1545 | 0.2909 | 0.3584 |  0.4488 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3372 | 0.2163 | 0.3929 | 0.4673 |  0.5725 |
|     1      | 0.2561 | 0.1556 | 0.2935 | 0.3606 |  0.4511 |
|     2      | 0.2368 | 0.1412 | 0.2742 | 0.3338 |  0.4169 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3357 | 0.2151 | 0.3908 | 0.4658 |  0.5691 |
|     1      | 0.2558 | 0.1548 | 0.2943 |  0.36  |  0.4513 |
|     2      | 0.2378 | 0.1412 | 0.2754 | 0.3354 |  0.4213 |
|     3      | 0.2318 | 0.1363 |  0.27  | 0.3309 |  0.413  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3312 | 0.2092 | 0.3875 | 0.4615 |  0.5661 |
|     1      | 0.2532 | 0.1514 | 0.2909 | 0.3576 |  0.4488 |
|     2      | 0.2358 | 0.1387 | 0.2749 | 0.3354 |  0.4211 |
|     3      | 0.2325 | 0.1354 | 0.2722 | 0.3335 |  0.4161 |
|     4      | 0.2854 | 0.1726 | 0.3419 | 0.4133 |  0.5011 |
+------------+--------+--------+--------+--------+---------+]
2024-12-28 16:02:52,962: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 82.07711744308472  |   0.341   |    0.221     |    0.395     |     0.573     |
|    1     | 221.34837245941162 |   0.288   |     0.18     |    0.331     |     0.497     |
|    2     | 170.4047462940216  |   0.268   |    0.165     |     0.31     |     0.467     |
|    3     | 195.10685229301453 |   0.258   |    0.157     |     0.3      |     0.453     |
|    4     | 173.37489342689514 |   0.261   |    0.157     |    0.305     |      0.46     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-28 16:02:52,962: Sum_Training_Time:842.3119819164276
2024-12-28 16:02:52,962: Every_Training_Time:[82.07711744308472, 221.34837245941162, 170.4047462940216, 195.10685229301453, 173.37489342689514]
2024-12-28 16:02:52,962: Forward transfer: 0.046575 Backward transfer: -0.0029000000000000067
2024-12-28 16:03:27,515: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241228160257/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=50000.0, token_num=3, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-28 16:03:35,136: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-28 16:03:38,992: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.11	Best:9.49
2024-12-28 16:03:43,205: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.71	Best:14.08
2024-12-28 16:03:46,917: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.75	Best:19.63
2024-12-28 16:03:50,706: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.68	Hits@10:48.73	Best:24.68
2024-12-28 16:03:54,885: Snapshot:0	Epoch:5	Loss:3.609	translation_Loss:3.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.29	Hits@10:51.98	Best:28.29
2024-12-28 16:03:58,793: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.39	Hits@10:53.92	Best:30.39
2024-12-28 16:04:03,024: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.74	Hits@10:55.52	Best:31.74
2024-12-28 16:04:06,762: Snapshot:0	Epoch:8	Loss:1.299	translation_Loss:1.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.55	Hits@10:56.06	Best:32.55
2024-12-28 16:04:10,552: Snapshot:0	Epoch:9	Loss:0.968	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.06	Hits@10:56.49	Best:33.06
2024-12-28 16:04:14,705: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.38	Hits@10:57.07	Best:33.38
2024-12-28 16:04:18,445: Snapshot:0	Epoch:11	Loss:0.608	translation_Loss:0.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.51	Hits@10:57.03	Best:33.51
2024-12-28 16:04:22,213: Snapshot:0	Epoch:12	Loss:0.5	translation_Loss:0.5	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.66	Hits@10:57.07	Best:33.66
2024-12-28 16:04:26,451: Snapshot:0	Epoch:13	Loss:0.421	translation_Loss:0.421	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.53	Hits@10:57.15	Best:33.66
2024-12-28 16:04:30,220: Snapshot:0	Epoch:14	Loss:0.374	translation_Loss:0.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.61	Hits@10:56.92	Best:33.66
2024-12-28 16:04:33,869: Snapshot:0	Epoch:15	Loss:0.331	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.59	Hits@10:56.72	Best:33.66
2024-12-28 16:04:37,885: Snapshot:0	Epoch:16	Loss:0.302	translation_Loss:0.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.66	Hits@10:56.7	Best:33.66
2024-12-28 16:04:41,630: Snapshot:0	Epoch:17	Loss:0.278	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:56.91	Best:33.68
2024-12-28 16:04:45,460: Snapshot:0	Epoch:18	Loss:0.257	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.46	Hits@10:57.01	Best:33.68
2024-12-28 16:04:49,512: Snapshot:0	Epoch:19	Loss:0.241	translation_Loss:0.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.52	Hits@10:56.96	Best:33.68
2024-12-28 16:04:53,178: Snapshot:0	Epoch:20	Loss:0.225	translation_Loss:0.225	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.47	Hits@10:56.69	Best:33.68
2024-12-28 16:04:56,823: Snapshot:0	Epoch:21	Loss:0.214	translation_Loss:0.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.46	Hits@10:56.43	Best:33.68
2024-12-28 16:05:00,945: Early Stopping! Snapshot: 0 Epoch: 22 Best Results: 33.68
2024-12-28 16:05:00,945: Start to training tokens! Snapshot: 0 Epoch: 22 Loss:0.202 MRR:33.49 Best Results: 33.68
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-28 16:05:00,946: Snapshot:0	Epoch:22	Loss:0.202	translation_Loss:0.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.49	Hits@10:56.38	Best:33.68
2024-12-28 16:05:05,253: Snapshot:0	Epoch:23	Loss:20.966	translation_Loss:9.734	multi_layer_Loss:11.233	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.49	Hits@10:56.38	Best:33.68
2024-12-28 16:05:09,011: End of token training: 0 Epoch: 24 Loss:10.167 MRR:33.49 Best Results: 33.68
2024-12-28 16:05:09,011: Snapshot:0	Epoch:24	Loss:10.167	translation_Loss:9.725	multi_layer_Loss:0.442	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.49	Hits@10:56.38	Best:33.68
2024-12-28 16:05:09,296: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-28 16:05:10,857: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3406 | 0.2212 | 0.3953 | 0.4681 |  0.5706 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:05:35,241: Snapshot:1	Epoch:0	Loss:13.277	translation_Loss:12.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.547                                                   	MRR:14.5	Hits@10:25.15	Best:14.5
2024-12-28 16:05:41,769: Snapshot:1	Epoch:1	Loss:5.046	translation_Loss:4.796	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.25                                                   	MRR:20.12	Hits@10:35.81	Best:20.12
2024-12-28 16:05:48,201: Snapshot:1	Epoch:2	Loss:2.494	translation_Loss:2.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.162                                                   	MRR:22.89	Hits@10:40.57	Best:22.89
2024-12-28 16:05:54,820: Snapshot:1	Epoch:3	Loss:1.696	translation_Loss:1.57	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:23.9	Hits@10:42.17	Best:23.9
2024-12-28 16:06:01,270: Snapshot:1	Epoch:4	Loss:1.374	translation_Loss:1.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:24.41	Hits@10:43.03	Best:24.41
2024-12-28 16:06:08,072: Snapshot:1	Epoch:5	Loss:1.199	translation_Loss:1.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:24.62	Hits@10:43.32	Best:24.62
2024-12-28 16:06:14,646: Snapshot:1	Epoch:6	Loss:1.097	translation_Loss:0.991	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.106                                                   	MRR:24.71	Hits@10:43.69	Best:24.71
2024-12-28 16:06:21,592: Snapshot:1	Epoch:7	Loss:1.021	translation_Loss:0.92	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:24.84	Hits@10:43.76	Best:24.84
2024-12-28 16:06:28,062: Snapshot:1	Epoch:8	Loss:0.96	translation_Loss:0.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:24.83	Hits@10:43.76	Best:24.84
2024-12-28 16:06:34,884: Snapshot:1	Epoch:9	Loss:0.936	translation_Loss:0.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:24.89	Hits@10:43.99	Best:24.89
2024-12-28 16:06:41,241: Snapshot:1	Epoch:10	Loss:0.907	translation_Loss:0.806	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:24.8	Hits@10:43.85	Best:24.89
2024-12-28 16:06:48,003: Snapshot:1	Epoch:11	Loss:0.882	translation_Loss:0.781	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:25.01	Hits@10:44.22	Best:25.01
2024-12-28 16:06:54,499: Snapshot:1	Epoch:12	Loss:0.862	translation_Loss:0.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:24.9	Hits@10:44.18	Best:25.01
2024-12-28 16:07:01,260: Snapshot:1	Epoch:13	Loss:0.845	translation_Loss:0.746	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:24.86	Hits@10:44.05	Best:25.01
2024-12-28 16:07:08,040: Snapshot:1	Epoch:14	Loss:0.829	translation_Loss:0.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:24.89	Hits@10:44.07	Best:25.01
2024-12-28 16:07:14,461: Snapshot:1	Epoch:15	Loss:0.823	translation_Loss:0.721	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:24.85	Hits@10:44.05	Best:25.01
2024-12-28 16:07:21,231: Snapshot:1	Epoch:16	Loss:0.812	translation_Loss:0.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:25.06	Hits@10:44.1	Best:25.06
2024-12-28 16:07:27,662: Snapshot:1	Epoch:17	Loss:0.796	translation_Loss:0.695	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:24.84	Hits@10:44.09	Best:25.06
2024-12-28 16:07:34,395: Snapshot:1	Epoch:18	Loss:0.78	translation_Loss:0.682	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:24.89	Hits@10:43.99	Best:25.06
2024-12-28 16:07:40,801: Snapshot:1	Epoch:19	Loss:0.782	translation_Loss:0.684	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:24.94	Hits@10:44.18	Best:25.06
2024-12-28 16:07:47,563: Snapshot:1	Epoch:20	Loss:0.776	translation_Loss:0.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:25.11	Hits@10:44.07	Best:25.11
2024-12-28 16:07:53,994: Snapshot:1	Epoch:21	Loss:0.765	translation_Loss:0.664	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:24.93	Hits@10:44.27	Best:25.11
2024-12-28 16:08:00,760: Snapshot:1	Epoch:22	Loss:0.76	translation_Loss:0.659	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:24.92	Hits@10:44.37	Best:25.11
2024-12-28 16:08:07,171: Snapshot:1	Epoch:23	Loss:0.751	translation_Loss:0.65	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:24.95	Hits@10:44.37	Best:25.11
2024-12-28 16:08:13,899: Snapshot:1	Epoch:24	Loss:0.748	translation_Loss:0.648	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:25.11	Hits@10:44.45	Best:25.11
2024-12-28 16:08:20,600: Early Stopping! Snapshot: 1 Epoch: 25 Best Results: 25.11
2024-12-28 16:08:20,600: Start to training tokens! Snapshot: 1 Epoch: 25 Loss:0.744 MRR:25.08 Best Results: 25.11
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-28 16:08:20,601: Snapshot:1	Epoch:25	Loss:0.744	translation_Loss:0.642	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:25.08	Hits@10:44.39	Best:25.11
2024-12-28 16:08:26,967: Snapshot:1	Epoch:26	Loss:27.359	translation_Loss:15.82	multi_layer_Loss:11.539	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.08	Hits@10:44.39	Best:25.11
2024-12-28 16:08:33,755: End of token training: 1 Epoch: 27 Loss:16.029 MRR:25.08 Best Results: 25.11
2024-12-28 16:08:33,756: Snapshot:1	Epoch:27	Loss:16.029	translation_Loss:15.822	multi_layer_Loss:0.207	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.08	Hits@10:44.39	Best:25.11
2024-12-28 16:08:33,990: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-28 16:08:37,798: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      |  0.34  | 0.2208 | 0.3944 | 0.4679 |  0.5707 |
|     1      | 0.2553 | 0.1588 | 0.2888 | 0.3548 |  0.4452 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:09:03,230: Snapshot:2	Epoch:0	Loss:11.923	translation_Loss:11.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.721                                                   	MRR:14.38	Hits@10:24.24	Best:14.38
2024-12-28 16:09:10,377: Snapshot:2	Epoch:1	Loss:3.959	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.35                                                   	MRR:18.12	Hits@10:31.65	Best:18.12
2024-12-28 16:09:17,585: Snapshot:2	Epoch:2	Loss:2.098	translation_Loss:1.87	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.228                                                   	MRR:20.32	Hits@10:35.83	Best:20.32
2024-12-28 16:09:25,310: Snapshot:2	Epoch:3	Loss:1.561	translation_Loss:1.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.183                                                   	MRR:21.44	Hits@10:37.53	Best:21.44
2024-12-28 16:09:32,447: Snapshot:2	Epoch:4	Loss:1.327	translation_Loss:1.16	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:21.77	Hits@10:38.28	Best:21.77
2024-12-28 16:09:39,829: Snapshot:2	Epoch:5	Loss:1.205	translation_Loss:1.046	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.159                                                   	MRR:22.03	Hits@10:38.82	Best:22.03
2024-12-28 16:09:47,123: Snapshot:2	Epoch:6	Loss:1.138	translation_Loss:0.982	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:22.34	Hits@10:39.22	Best:22.34
2024-12-28 16:09:54,796: Snapshot:2	Epoch:7	Loss:1.085	translation_Loss:0.931	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:22.46	Hits@10:39.7	Best:22.46
2024-12-28 16:10:01,949: Snapshot:2	Epoch:8	Loss:1.047	translation_Loss:0.894	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:22.71	Hits@10:39.99	Best:22.71
2024-12-28 16:10:09,588: Snapshot:2	Epoch:9	Loss:1.016	translation_Loss:0.864	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:22.81	Hits@10:40.0	Best:22.81
2024-12-28 16:10:17,009: Snapshot:2	Epoch:10	Loss:0.987	translation_Loss:0.835	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:22.74	Hits@10:40.32	Best:22.81
2024-12-28 16:10:24,254: Snapshot:2	Epoch:11	Loss:0.969	translation_Loss:0.817	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:22.92	Hits@10:40.21	Best:22.92
2024-12-28 16:10:31,883: Snapshot:2	Epoch:12	Loss:0.947	translation_Loss:0.796	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.151                                                   	MRR:23.02	Hits@10:40.42	Best:23.02
2024-12-28 16:10:39,012: Snapshot:2	Epoch:13	Loss:0.942	translation_Loss:0.79	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:23.03	Hits@10:40.44	Best:23.03
2024-12-28 16:10:46,518: Snapshot:2	Epoch:14	Loss:0.931	translation_Loss:0.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.151                                                   	MRR:23.13	Hits@10:40.65	Best:23.13
2024-12-28 16:10:53,710: Snapshot:2	Epoch:15	Loss:0.914	translation_Loss:0.761	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:23.08	Hits@10:40.57	Best:23.13
2024-12-28 16:11:01,346: Snapshot:2	Epoch:16	Loss:0.901	translation_Loss:0.749	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:23.18	Hits@10:40.44	Best:23.18
2024-12-28 16:11:08,646: Snapshot:2	Epoch:17	Loss:0.895	translation_Loss:0.742	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:22.99	Hits@10:40.46	Best:23.18
2024-12-28 16:11:16,109: Snapshot:2	Epoch:18	Loss:0.891	translation_Loss:0.738	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:23.15	Hits@10:40.69	Best:23.18
2024-12-28 16:11:23,558: Snapshot:2	Epoch:19	Loss:0.893	translation_Loss:0.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:23.17	Hits@10:40.72	Best:23.18
2024-12-28 16:11:30,800: Snapshot:2	Epoch:20	Loss:0.884	translation_Loss:0.729	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:23.3	Hits@10:40.7	Best:23.3
2024-12-28 16:11:38,358: Snapshot:2	Epoch:21	Loss:0.869	translation_Loss:0.717	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:23.29	Hits@10:40.75	Best:23.3
2024-12-28 16:11:45,434: Snapshot:2	Epoch:22	Loss:0.868	translation_Loss:0.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:23.21	Hits@10:40.77	Best:23.3
2024-12-28 16:11:53,003: Snapshot:2	Epoch:23	Loss:0.866	translation_Loss:0.714	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:23.25	Hits@10:40.71	Best:23.3
2024-12-28 16:12:00,106: Snapshot:2	Epoch:24	Loss:0.858	translation_Loss:0.705	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:23.33	Hits@10:40.87	Best:23.33
2024-12-28 16:12:07,585: Snapshot:2	Epoch:25	Loss:0.855	translation_Loss:0.701	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:23.28	Hits@10:40.76	Best:23.33
2024-12-28 16:12:14,582: Snapshot:2	Epoch:26	Loss:0.856	translation_Loss:0.702	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:23.22	Hits@10:40.87	Best:23.33
2024-12-28 16:12:22,062: Snapshot:2	Epoch:27	Loss:0.849	translation_Loss:0.695	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:23.32	Hits@10:41.1	Best:23.33
2024-12-28 16:12:29,695: Snapshot:2	Epoch:28	Loss:0.838	translation_Loss:0.685	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:23.25	Hits@10:40.88	Best:23.33
2024-12-28 16:12:36,871: Snapshot:2	Epoch:29	Loss:0.834	translation_Loss:0.681	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:23.38	Hits@10:41.0	Best:23.38
2024-12-28 16:12:44,613: Snapshot:2	Epoch:30	Loss:0.83	translation_Loss:0.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:23.32	Hits@10:40.98	Best:23.38
2024-12-28 16:12:51,630: Snapshot:2	Epoch:31	Loss:0.834	translation_Loss:0.681	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:23.31	Hits@10:40.92	Best:23.38
2024-12-28 16:12:59,031: Snapshot:2	Epoch:32	Loss:0.827	translation_Loss:0.675	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:23.41	Hits@10:40.93	Best:23.41
2024-12-28 16:13:06,336: Snapshot:2	Epoch:33	Loss:0.833	translation_Loss:0.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:23.31	Hits@10:40.98	Best:23.41
2024-12-28 16:13:13,748: Snapshot:2	Epoch:34	Loss:0.825	translation_Loss:0.67	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:23.32	Hits@10:40.96	Best:23.41
2024-12-28 16:13:20,769: Snapshot:2	Epoch:35	Loss:0.821	translation_Loss:0.666	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:23.25	Hits@10:41.0	Best:23.41
2024-12-28 16:13:28,278: Snapshot:2	Epoch:36	Loss:0.815	translation_Loss:0.663	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:23.31	Hits@10:41.08	Best:23.41
2024-12-28 16:13:35,654: Early Stopping! Snapshot: 2 Epoch: 37 Best Results: 23.41
2024-12-28 16:13:35,654: Start to training tokens! Snapshot: 2 Epoch: 37 Loss:0.81 MRR:23.24 Best Results: 23.41
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-28 16:13:35,655: Snapshot:2	Epoch:37	Loss:0.81	translation_Loss:0.658	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:23.24	Hits@10:40.92	Best:23.41
2024-12-28 16:13:42,900: Snapshot:2	Epoch:38	Loss:28.27	translation_Loss:15.727	multi_layer_Loss:12.542	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.24	Hits@10:40.92	Best:23.41
2024-12-28 16:13:50,309: End of token training: 2 Epoch: 39 Loss:15.942 MRR:23.24 Best Results: 23.41
2024-12-28 16:13:50,309: Snapshot:2	Epoch:39	Loss:15.942	translation_Loss:15.71	multi_layer_Loss:0.232	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.24	Hits@10:40.92	Best:23.41
2024-12-28 16:13:50,564: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-28 16:13:57,121: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.339  | 0.2196 | 0.3928 | 0.4677 |  0.5696 |
|     1      | 0.2555 | 0.1585 | 0.2894 | 0.3558 |  0.4458 |
|     2      | 0.2365 | 0.1427 | 0.2712 | 0.3292 |  0.4136 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:14:22,438: Snapshot:3	Epoch:0	Loss:10.892	translation_Loss:10.108	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.784                                                   	MRR:14.22	Hits@10:25.04	Best:14.22
2024-12-28 16:14:29,790: Snapshot:3	Epoch:1	Loss:3.219	translation_Loss:2.812	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.407                                                   	MRR:17.52	Hits@10:31.77	Best:17.52
2024-12-28 16:14:37,545: Snapshot:3	Epoch:2	Loss:1.728	translation_Loss:1.469	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.259                                                   	MRR:19.46	Hits@10:35.22	Best:19.46
2024-12-28 16:14:45,320: Snapshot:3	Epoch:3	Loss:1.308	translation_Loss:1.097	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.211                                                   	MRR:20.34	Hits@10:36.8	Best:20.34
2024-12-28 16:14:52,536: Snapshot:3	Epoch:4	Loss:1.123	translation_Loss:0.935	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:20.86	Hits@10:37.66	Best:20.86
2024-12-28 16:14:59,885: Snapshot:3	Epoch:5	Loss:1.031	translation_Loss:0.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.18                                                   	MRR:21.11	Hits@10:38.24	Best:21.11
2024-12-28 16:15:07,745: Snapshot:3	Epoch:6	Loss:0.964	translation_Loss:0.788	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.176                                                   	MRR:21.27	Hits@10:38.66	Best:21.27
2024-12-28 16:15:15,549: Snapshot:3	Epoch:7	Loss:0.924	translation_Loss:0.752	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:21.43	Hits@10:38.77	Best:21.43
2024-12-28 16:15:22,971: Snapshot:3	Epoch:8	Loss:0.897	translation_Loss:0.728	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:21.71	Hits@10:39.04	Best:21.71
2024-12-28 16:15:30,592: Snapshot:3	Epoch:9	Loss:0.866	translation_Loss:0.696	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:21.67	Hits@10:39.24	Best:21.71
2024-12-28 16:15:37,868: Snapshot:3	Epoch:10	Loss:0.851	translation_Loss:0.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:21.68	Hits@10:39.25	Best:21.71
2024-12-28 16:15:45,480: Snapshot:3	Epoch:11	Loss:0.838	translation_Loss:0.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:21.84	Hits@10:39.49	Best:21.84
2024-12-28 16:15:52,913: Snapshot:3	Epoch:12	Loss:0.82	translation_Loss:0.653	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:21.83	Hits@10:39.47	Best:21.84
2024-12-28 16:16:00,601: Snapshot:3	Epoch:13	Loss:0.809	translation_Loss:0.64	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:21.86	Hits@10:39.8	Best:21.86
2024-12-28 16:16:07,972: Snapshot:3	Epoch:14	Loss:0.802	translation_Loss:0.635	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:21.77	Hits@10:39.7	Best:21.86
2024-12-28 16:16:15,705: Snapshot:3	Epoch:15	Loss:0.794	translation_Loss:0.624	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:21.91	Hits@10:39.77	Best:21.91
2024-12-28 16:16:23,011: Snapshot:3	Epoch:16	Loss:0.787	translation_Loss:0.619	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:21.77	Hits@10:39.82	Best:21.91
2024-12-28 16:16:30,579: Snapshot:3	Epoch:17	Loss:0.782	translation_Loss:0.615	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:21.9	Hits@10:39.71	Best:21.91
2024-12-28 16:16:37,970: Snapshot:3	Epoch:18	Loss:0.776	translation_Loss:0.607	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:21.9	Hits@10:40.02	Best:21.91
2024-12-28 16:16:45,488: Snapshot:3	Epoch:19	Loss:0.767	translation_Loss:0.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:21.89	Hits@10:39.87	Best:21.91
2024-12-28 16:16:52,719: Early Stopping! Snapshot: 3 Epoch: 20 Best Results: 21.91
2024-12-28 16:16:52,719: Start to training tokens! Snapshot: 3 Epoch: 20 Loss:0.768 MRR:21.84 Best Results: 21.91
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-28 16:16:52,720: Snapshot:3	Epoch:20	Loss:0.768	translation_Loss:0.6	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:21.84	Hits@10:39.77	Best:21.91
2024-12-28 16:17:00,193: Snapshot:3	Epoch:21	Loss:25.988	translation_Loss:14.228	multi_layer_Loss:11.76	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.84	Hits@10:39.77	Best:21.91
2024-12-28 16:17:07,515: End of token training: 3 Epoch: 22 Loss:14.482 MRR:21.84 Best Results: 21.91
2024-12-28 16:17:07,515: Snapshot:3	Epoch:22	Loss:14.482	translation_Loss:14.236	multi_layer_Loss:0.247	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.84	Hits@10:39.77	Best:21.91
2024-12-28 16:17:07,769: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-28 16:17:17,765: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3394 | 0.2201 | 0.3942 | 0.4672 |  0.5691 |
|     1      | 0.2559 | 0.1586 | 0.2908 | 0.3565 |  0.4461 |
|     2      | 0.238  | 0.1445 | 0.2739 | 0.3305 |  0.4143 |
|     3      | 0.221  | 0.1289 | 0.258  | 0.3146 |  0.3958 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:17:37,119: Snapshot:4	Epoch:0	Loss:8.252	translation_Loss:7.656	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.596                                                   	MRR:16.15	Hits@10:30.42	Best:16.15
2024-12-28 16:17:42,478: Snapshot:4	Epoch:1	Loss:2.552	translation_Loss:2.164	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.388                                                   	MRR:21.09	Hits@10:38.66	Best:21.09
2024-12-28 16:17:47,733: Snapshot:4	Epoch:2	Loss:1.096	translation_Loss:0.897	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:23.63	Hits@10:42.24	Best:23.63
2024-12-28 16:17:53,047: Snapshot:4	Epoch:3	Loss:0.701	translation_Loss:0.572	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.13                                                   	MRR:24.6	Hits@10:43.96	Best:24.6
2024-12-28 16:17:58,773: Snapshot:4	Epoch:4	Loss:0.555	translation_Loss:0.451	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.105                                                   	MRR:25.06	Hits@10:44.64	Best:25.06
2024-12-28 16:18:04,074: Snapshot:4	Epoch:5	Loss:0.485	translation_Loss:0.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:25.38	Hits@10:45.1	Best:25.38
2024-12-28 16:18:09,486: Snapshot:4	Epoch:6	Loss:0.447	translation_Loss:0.358	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:25.76	Hits@10:45.83	Best:25.76
2024-12-28 16:18:15,233: Snapshot:4	Epoch:7	Loss:0.413	translation_Loss:0.327	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:25.89	Hits@10:46.09	Best:25.89
2024-12-28 16:18:20,660: Snapshot:4	Epoch:8	Loss:0.393	translation_Loss:0.308	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:25.97	Hits@10:46.21	Best:25.97
2024-12-28 16:18:26,066: Snapshot:4	Epoch:9	Loss:0.378	translation_Loss:0.294	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.084                                                   	MRR:26.08	Hits@10:46.21	Best:26.08
2024-12-28 16:18:31,820: Snapshot:4	Epoch:10	Loss:0.375	translation_Loss:0.291	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:26.2	Hits@10:46.65	Best:26.2
2024-12-28 16:18:37,083: Snapshot:4	Epoch:11	Loss:0.361	translation_Loss:0.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:26.33	Hits@10:46.9	Best:26.33
2024-12-28 16:18:42,335: Snapshot:4	Epoch:12	Loss:0.358	translation_Loss:0.272	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:26.29	Hits@10:46.88	Best:26.33
2024-12-28 16:18:47,856: Snapshot:4	Epoch:13	Loss:0.352	translation_Loss:0.266	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:26.31	Hits@10:47.05	Best:26.33
2024-12-28 16:18:53,122: Snapshot:4	Epoch:14	Loss:0.347	translation_Loss:0.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:26.42	Hits@10:47.33	Best:26.42
2024-12-28 16:18:58,430: Snapshot:4	Epoch:15	Loss:0.341	translation_Loss:0.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:26.49	Hits@10:47.3	Best:26.49
2024-12-28 16:19:04,100: Snapshot:4	Epoch:16	Loss:0.337	translation_Loss:0.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:26.56	Hits@10:47.37	Best:26.56
2024-12-28 16:19:09,407: Snapshot:4	Epoch:17	Loss:0.334	translation_Loss:0.248	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:26.72	Hits@10:47.3	Best:26.72
2024-12-28 16:19:15,080: Snapshot:4	Epoch:18	Loss:0.336	translation_Loss:0.249	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:26.79	Hits@10:47.3	Best:26.79
2024-12-28 16:19:20,360: Snapshot:4	Epoch:19	Loss:0.327	translation_Loss:0.239	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:26.71	Hits@10:47.17	Best:26.79
2024-12-28 16:19:25,710: Snapshot:4	Epoch:20	Loss:0.331	translation_Loss:0.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.62	Hits@10:47.33	Best:26.79
2024-12-28 16:19:31,375: Snapshot:4	Epoch:21	Loss:0.326	translation_Loss:0.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:26.55	Hits@10:47.22	Best:26.79
2024-12-28 16:19:36,626: Snapshot:4	Epoch:22	Loss:0.326	translation_Loss:0.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.54	Hits@10:47.37	Best:26.79
2024-12-28 16:19:41,948: Early Stopping! Snapshot: 4 Epoch: 23 Best Results: 26.79
2024-12-28 16:19:41,948: Start to training tokens! Snapshot: 4 Epoch: 23 Loss:0.324 MRR:26.71 Best Results: 26.79
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-28 16:19:41,948: Snapshot:4	Epoch:23	Loss:0.324	translation_Loss:0.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.71	Hits@10:47.57	Best:26.79
2024-12-28 16:19:47,175: Snapshot:4	Epoch:24	Loss:19.533	translation_Loss:7.796	multi_layer_Loss:11.738	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.71	Hits@10:47.57	Best:26.79
2024-12-28 16:19:52,733: End of token training: 4 Epoch: 25 Loss:8.261 MRR:26.71 Best Results: 26.79
2024-12-28 16:19:52,733: Snapshot:4	Epoch:25	Loss:8.261	translation_Loss:7.805	multi_layer_Loss:0.455	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.71	Hits@10:47.57	Best:26.79
2024-12-28 16:19:52,972: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-28 16:20:05,673: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3383 | 0.2186 | 0.3932 | 0.466  |  0.5677 |
|     1      | 0.2558 | 0.1583 | 0.2913 | 0.3551 |  0.4457 |
|     2      | 0.2391 | 0.1456 | 0.2746 | 0.3317 |  0.4152 |
|     3      | 0.223  | 0.1316 | 0.258  | 0.3166 |  0.3975 |
|     4      | 0.2695 | 0.1594 | 0.321  | 0.3943 |  0.4816 |
+------------+--------+--------+--------+--------+---------+
2024-12-28 16:20:05,675: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3406 | 0.2212 | 0.3953 | 0.4681 |  0.5706 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      |  0.34  | 0.2208 | 0.3944 | 0.4679 |  0.5707 |
|     1      | 0.2553 | 0.1588 | 0.2888 | 0.3548 |  0.4452 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.339  | 0.2196 | 0.3928 | 0.4677 |  0.5696 |
|     1      | 0.2555 | 0.1585 | 0.2894 | 0.3558 |  0.4458 |
|     2      | 0.2365 | 0.1427 | 0.2712 | 0.3292 |  0.4136 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3394 | 0.2201 | 0.3942 | 0.4672 |  0.5691 |
|     1      | 0.2559 | 0.1586 | 0.2908 | 0.3565 |  0.4461 |
|     2      | 0.238  | 0.1445 | 0.2739 | 0.3305 |  0.4143 |
|     3      | 0.221  | 0.1289 | 0.258  | 0.3146 |  0.3958 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3383 | 0.2186 | 0.3932 | 0.466  |  0.5677 |
|     1      | 0.2558 | 0.1583 | 0.2913 | 0.3551 |  0.4457 |
|     2      | 0.2391 | 0.1456 | 0.2746 | 0.3317 |  0.4152 |
|     3      | 0.223  | 0.1316 | 0.258  | 0.3166 |  0.3975 |
|     4      | 0.2695 | 0.1594 | 0.321  | 0.3943 |  0.4816 |
+------------+--------+--------+--------+--------+---------+]
2024-12-28 16:20:05,676: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 101.49528503417969 |   0.341   |    0.221     |    0.395     |     0.571     |
|    1     | 200.5492696762085  |   0.288   |    0.183     |     0.33     |     0.494     |
|    2     | 309.6800241470337  |   0.268   |    0.167     |    0.307     |     0.463     |
|    3     | 186.9220814704895  |   0.256   |    0.158     |    0.296     |     0.445     |
|    4     | 152.30075025558472 |   0.259   |    0.158     |     0.3      |     0.451     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-28 16:20:05,676: Sum_Training_Time:950.9474105834961
2024-12-28 16:20:05,676: Every_Training_Time:[101.49528503417969, 200.5492696762085, 309.6800241470337, 186.9220814704895, 152.30075025558472]
2024-12-28 16:20:05,676: Forward transfer: 0.045575000000000004 Backward transfer: 0.0006999999999999992
2024-12-28 16:20:41,668: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241228162012/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=50000.0, token_num=4, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-28 16:20:49,393: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-28 16:20:53,052: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.11	Best:9.49
2024-12-28 16:20:57,312: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.7	Best:14.08
2024-12-28 16:21:01,117: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.64	Hits@10:43.74	Best:19.64
2024-12-28 16:21:04,990: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:48.71	Best:24.66
2024-12-28 16:21:09,159: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.29	Hits@10:52.03	Best:28.29
2024-12-28 16:21:12,965: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.37	Hits@10:53.87	Best:30.37
2024-12-28 16:21:16,996: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.79	Hits@10:55.41	Best:31.79
2024-12-28 16:21:20,781: Snapshot:0	Epoch:8	Loss:1.299	translation_Loss:1.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.68	Hits@10:56.11	Best:32.68
2024-12-28 16:21:24,657: Snapshot:0	Epoch:9	Loss:0.968	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.17	Hits@10:56.54	Best:33.17
2024-12-28 16:21:28,923: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.49	Hits@10:57.09	Best:33.49
2024-12-28 16:21:32,760: Snapshot:0	Epoch:11	Loss:0.607	translation_Loss:0.607	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.48	Hits@10:57.01	Best:33.49
2024-12-28 16:21:36,534: Snapshot:0	Epoch:12	Loss:0.5	translation_Loss:0.5	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:56.97	Best:33.68
2024-12-28 16:21:40,687: Snapshot:0	Epoch:13	Loss:0.422	translation_Loss:0.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.56	Hits@10:57.11	Best:33.68
2024-12-28 16:21:44,426: Snapshot:0	Epoch:14	Loss:0.374	translation_Loss:0.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.64	Hits@10:57.0	Best:33.68
2024-12-28 16:21:48,124: Snapshot:0	Epoch:15	Loss:0.331	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.61	Hits@10:56.96	Best:33.68
2024-12-28 16:21:52,206: Snapshot:0	Epoch:16	Loss:0.302	translation_Loss:0.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.62	Hits@10:56.84	Best:33.68
2024-12-28 16:21:55,922: Snapshot:0	Epoch:17	Loss:0.278	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.69	Hits@10:56.81	Best:33.69
2024-12-28 16:21:59,649: Snapshot:0	Epoch:18	Loss:0.257	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.51	Hits@10:57.1	Best:33.69
2024-12-28 16:22:03,755: Snapshot:0	Epoch:19	Loss:0.241	translation_Loss:0.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.52	Hits@10:56.85	Best:33.69
2024-12-28 16:22:07,424: Snapshot:0	Epoch:20	Loss:0.223	translation_Loss:0.223	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.57	Hits@10:56.7	Best:33.69
2024-12-28 16:22:11,149: Snapshot:0	Epoch:21	Loss:0.213	translation_Loss:0.213	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.63	Hits@10:56.76	Best:33.69
2024-12-28 16:22:15,286: Early Stopping! Snapshot: 0 Epoch: 22 Best Results: 33.69
2024-12-28 16:22:15,286: Start to training tokens! Snapshot: 0 Epoch: 22 Loss:0.202 MRR:33.64 Best Results: 33.69
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-28 16:22:15,286: Snapshot:0	Epoch:22	Loss:0.202	translation_Loss:0.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.64	Hits@10:56.59	Best:33.69
2024-12-28 16:22:19,484: Snapshot:0	Epoch:23	Loss:22.945	translation_Loss:9.737	multi_layer_Loss:13.208	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.64	Hits@10:56.59	Best:33.69
2024-12-28 16:22:23,240: End of token training: 0 Epoch: 24 Loss:10.203 MRR:33.64 Best Results: 33.69
2024-12-28 16:22:23,240: Snapshot:0	Epoch:24	Loss:10.203	translation_Loss:9.729	multi_layer_Loss:0.474	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.64	Hits@10:56.59	Best:33.69
2024-12-28 16:22:23,495: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-28 16:22:25,054: 
+------------+------+--------+--------+--------+---------+
| Snapshot:0 | MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+------+--------+--------+--------+---------+
|     0      | 0.34 | 0.2198 | 0.3943 | 0.4682 |  0.5716 |
+------------+------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:22:49,439: Snapshot:1	Epoch:0	Loss:13.354	translation_Loss:12.75	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.604                                                   	MRR:14.42	Hits@10:25.19	Best:14.42
2024-12-28 16:22:55,801: Snapshot:1	Epoch:1	Loss:5.038	translation_Loss:4.801	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.237                                                   	MRR:20.08	Hits@10:35.77	Best:20.08
2024-12-28 16:23:02,367: Snapshot:1	Epoch:2	Loss:2.486	translation_Loss:2.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:22.89	Hits@10:40.54	Best:22.89
2024-12-28 16:23:08,867: Snapshot:1	Epoch:3	Loss:1.691	translation_Loss:1.57	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.121                                                   	MRR:23.86	Hits@10:42.15	Best:23.86
2024-12-28 16:23:15,380: Snapshot:1	Epoch:4	Loss:1.37	translation_Loss:1.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:24.38	Hits@10:42.9	Best:24.38
2024-12-28 16:23:22,127: Snapshot:1	Epoch:5	Loss:1.195	translation_Loss:1.092	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:24.49	Hits@10:43.21	Best:24.49
2024-12-28 16:23:28,640: Snapshot:1	Epoch:6	Loss:1.091	translation_Loss:0.99	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:24.74	Hits@10:43.49	Best:24.74
2024-12-28 16:23:35,541: Snapshot:1	Epoch:7	Loss:1.017	translation_Loss:0.919	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:24.7	Hits@10:43.52	Best:24.74
2024-12-28 16:23:41,915: Snapshot:1	Epoch:8	Loss:0.954	translation_Loss:0.859	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:24.65	Hits@10:43.58	Best:24.74
2024-12-28 16:23:48,790: Snapshot:1	Epoch:9	Loss:0.932	translation_Loss:0.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:24.8	Hits@10:43.94	Best:24.8
2024-12-28 16:23:55,117: Snapshot:1	Epoch:10	Loss:0.902	translation_Loss:0.806	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:24.75	Hits@10:43.85	Best:24.8
2024-12-28 16:24:01,871: Snapshot:1	Epoch:11	Loss:0.875	translation_Loss:0.779	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.096                                                   	MRR:24.94	Hits@10:43.97	Best:24.94
2024-12-28 16:24:08,234: Snapshot:1	Epoch:12	Loss:0.855	translation_Loss:0.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:24.95	Hits@10:43.89	Best:24.95
2024-12-28 16:24:14,933: Snapshot:1	Epoch:13	Loss:0.841	translation_Loss:0.745	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:24.86	Hits@10:43.95	Best:24.95
2024-12-28 16:24:21,861: Snapshot:1	Epoch:14	Loss:0.826	translation_Loss:0.731	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:24.86	Hits@10:44.03	Best:24.95
2024-12-28 16:24:28,387: Snapshot:1	Epoch:15	Loss:0.818	translation_Loss:0.721	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:24.84	Hits@10:44.08	Best:24.95
2024-12-28 16:24:35,097: Snapshot:1	Epoch:16	Loss:0.806	translation_Loss:0.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:25.01	Hits@10:44.16	Best:25.01
2024-12-28 16:24:41,698: Snapshot:1	Epoch:17	Loss:0.791	translation_Loss:0.695	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:24.82	Hits@10:44.06	Best:25.01
2024-12-28 16:24:48,467: Snapshot:1	Epoch:18	Loss:0.778	translation_Loss:0.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:24.91	Hits@10:44.16	Best:25.01
2024-12-28 16:24:54,858: Snapshot:1	Epoch:19	Loss:0.778	translation_Loss:0.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:24.95	Hits@10:44.08	Best:25.01
2024-12-28 16:25:01,663: Snapshot:1	Epoch:20	Loss:0.771	translation_Loss:0.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.096                                                   	MRR:25.15	Hits@10:44.3	Best:25.15
2024-12-28 16:25:08,203: Snapshot:1	Epoch:21	Loss:0.759	translation_Loss:0.663	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.096                                                   	MRR:24.98	Hits@10:44.21	Best:25.15
2024-12-28 16:25:15,005: Snapshot:1	Epoch:22	Loss:0.753	translation_Loss:0.659	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:24.93	Hits@10:44.26	Best:25.15
2024-12-28 16:25:21,360: Snapshot:1	Epoch:23	Loss:0.746	translation_Loss:0.65	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.096                                                   	MRR:24.99	Hits@10:44.44	Best:25.15
2024-12-28 16:25:28,117: Snapshot:1	Epoch:24	Loss:0.744	translation_Loss:0.648	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:25.05	Hits@10:44.5	Best:25.15
2024-12-28 16:25:34,894: Early Stopping! Snapshot: 1 Epoch: 25 Best Results: 25.15
2024-12-28 16:25:34,895: Start to training tokens! Snapshot: 1 Epoch: 25 Loss:0.735 MRR:25.03 Best Results: 25.15
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-28 16:25:34,895: Snapshot:1	Epoch:25	Loss:0.735	translation_Loss:0.64	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:25.03	Hits@10:44.35	Best:25.15
2024-12-28 16:25:41,294: Snapshot:1	Epoch:26	Loss:29.992	translation_Loss:15.821	multi_layer_Loss:14.171	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.03	Hits@10:44.35	Best:25.15
2024-12-28 16:25:48,010: End of token training: 1 Epoch: 27 Loss:16.041 MRR:25.03 Best Results: 25.15
2024-12-28 16:25:48,010: Snapshot:1	Epoch:27	Loss:16.041	translation_Loss:15.823	multi_layer_Loss:0.218	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.03	Hits@10:44.35	Best:25.15
2024-12-28 16:25:48,279: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-28 16:25:51,920: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3392 | 0.2193 | 0.3924 | 0.4678 |  0.5722 |
|     1      | 0.2539 | 0.1559 | 0.2892 | 0.3535 |  0.4456 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:26:17,407: Snapshot:2	Epoch:0	Loss:12.003	translation_Loss:11.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.776                                                   	MRR:14.27	Hits@10:24.21	Best:14.27
2024-12-28 16:26:24,490: Snapshot:2	Epoch:1	Loss:3.945	translation_Loss:3.618	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.326                                                   	MRR:18.13	Hits@10:31.68	Best:18.13
2024-12-28 16:26:31,695: Snapshot:2	Epoch:2	Loss:2.085	translation_Loss:1.876	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:20.3	Hits@10:35.83	Best:20.3
2024-12-28 16:26:39,214: Snapshot:2	Epoch:3	Loss:1.557	translation_Loss:1.387	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:21.37	Hits@10:37.61	Best:21.37
2024-12-28 16:26:46,355: Snapshot:2	Epoch:4	Loss:1.326	translation_Loss:1.169	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.157                                                   	MRR:21.88	Hits@10:38.45	Best:21.88
2024-12-28 16:26:53,796: Snapshot:2	Epoch:5	Loss:1.204	translation_Loss:1.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.151                                                   	MRR:22.1	Hits@10:38.89	Best:22.1
2024-12-28 16:27:01,018: Snapshot:2	Epoch:6	Loss:1.141	translation_Loss:0.991	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:22.46	Hits@10:39.42	Best:22.46
2024-12-28 16:27:08,808: Snapshot:2	Epoch:7	Loss:1.086	translation_Loss:0.938	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:22.41	Hits@10:39.71	Best:22.46
2024-12-28 16:27:16,008: Snapshot:2	Epoch:8	Loss:1.05	translation_Loss:0.902	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:22.7	Hits@10:39.88	Best:22.7
2024-12-28 16:27:23,509: Snapshot:2	Epoch:9	Loss:1.019	translation_Loss:0.872	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.147                                                   	MRR:22.76	Hits@10:40.03	Best:22.76
2024-12-28 16:27:31,263: Snapshot:2	Epoch:10	Loss:0.989	translation_Loss:0.842	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.147                                                   	MRR:22.81	Hits@10:40.24	Best:22.81
2024-12-28 16:27:38,414: Snapshot:2	Epoch:11	Loss:0.972	translation_Loss:0.823	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:22.91	Hits@10:40.24	Best:22.91
2024-12-28 16:27:45,948: Snapshot:2	Epoch:12	Loss:0.95	translation_Loss:0.803	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.147                                                   	MRR:22.97	Hits@10:40.29	Best:22.97
2024-12-28 16:27:53,089: Snapshot:2	Epoch:13	Loss:0.942	translation_Loss:0.795	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:22.94	Hits@10:40.4	Best:22.97
2024-12-28 16:28:00,568: Snapshot:2	Epoch:14	Loss:0.933	translation_Loss:0.785	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:23.1	Hits@10:40.7	Best:23.1
2024-12-28 16:28:07,899: Snapshot:2	Epoch:15	Loss:0.917	translation_Loss:0.769	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:23.03	Hits@10:40.56	Best:23.1
2024-12-28 16:28:15,438: Snapshot:2	Epoch:16	Loss:0.903	translation_Loss:0.754	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:23.11	Hits@10:40.67	Best:23.11
2024-12-28 16:28:22,630: Snapshot:2	Epoch:17	Loss:0.897	translation_Loss:0.748	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:23.05	Hits@10:40.76	Best:23.11
2024-12-28 16:28:30,023: Snapshot:2	Epoch:18	Loss:0.893	translation_Loss:0.744	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:23.06	Hits@10:40.68	Best:23.11
2024-12-28 16:28:37,441: Snapshot:2	Epoch:19	Loss:0.896	translation_Loss:0.746	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.15                                                   	MRR:23.2	Hits@10:40.64	Best:23.2
2024-12-28 16:28:44,725: Snapshot:2	Epoch:20	Loss:0.886	translation_Loss:0.736	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.15                                                   	MRR:23.27	Hits@10:40.9	Best:23.27
2024-12-28 16:28:52,300: Snapshot:2	Epoch:21	Loss:0.873	translation_Loss:0.724	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:23.22	Hits@10:40.69	Best:23.27
2024-12-28 16:28:59,333: Snapshot:2	Epoch:22	Loss:0.87	translation_Loss:0.721	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:23.2	Hits@10:40.75	Best:23.27
2024-12-28 16:29:06,884: Snapshot:2	Epoch:23	Loss:0.87	translation_Loss:0.721	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:23.2	Hits@10:40.7	Best:23.27
2024-12-28 16:29:14,017: Snapshot:2	Epoch:24	Loss:0.861	translation_Loss:0.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.15                                                   	MRR:23.24	Hits@10:40.88	Best:23.27
2024-12-28 16:29:21,568: Early Stopping! Snapshot: 2 Epoch: 25 Best Results: 23.27
2024-12-28 16:29:21,569: Start to training tokens! Snapshot: 2 Epoch: 25 Loss:0.858 MRR:23.16 Best Results: 23.27
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-28 16:29:21,569: Snapshot:2	Epoch:25	Loss:0.858	translation_Loss:0.708	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.15                                                   	MRR:23.16	Hits@10:40.84	Best:23.27
2024-12-28 16:29:28,765: Snapshot:2	Epoch:26	Loss:29.629	translation_Loss:15.712	multi_layer_Loss:13.917	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.16	Hits@10:40.84	Best:23.27
2024-12-28 16:29:36,119: End of token training: 2 Epoch: 27 Loss:15.934 MRR:23.16 Best Results: 23.27
2024-12-28 16:29:36,120: Snapshot:2	Epoch:27	Loss:15.934	translation_Loss:15.708	multi_layer_Loss:0.226	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.16	Hits@10:40.84	Best:23.27
2024-12-28 16:29:36,377: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-28 16:29:43,282: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3397 | 0.2203 | 0.3922 | 0.4683 |  0.572  |
|     1      | 0.2551 | 0.1574 | 0.291  | 0.3549 |  0.4464 |
|     2      | 0.2343 | 0.1408 | 0.2694 | 0.3285 |  0.4131 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:30:09,492: Snapshot:3	Epoch:0	Loss:10.982	translation_Loss:10.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.859                                                   	MRR:14.03	Hits@10:24.99	Best:14.03
2024-12-28 16:30:16,778: Snapshot:3	Epoch:1	Loss:3.205	translation_Loss:2.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.397                                                   	MRR:17.6	Hits@10:31.89	Best:17.6
2024-12-28 16:30:24,177: Snapshot:3	Epoch:2	Loss:1.719	translation_Loss:1.472	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.247                                                   	MRR:19.46	Hits@10:35.37	Best:19.46
2024-12-28 16:30:31,610: Snapshot:3	Epoch:3	Loss:1.298	translation_Loss:1.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:20.42	Hits@10:36.96	Best:20.42
2024-12-28 16:30:38,894: Snapshot:3	Epoch:4	Loss:1.117	translation_Loss:0.939	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.179                                                   	MRR:20.88	Hits@10:38.0	Best:20.88
2024-12-28 16:30:46,420: Snapshot:3	Epoch:5	Loss:1.03	translation_Loss:0.857	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:21.16	Hits@10:38.74	Best:21.16
2024-12-28 16:30:54,209: Snapshot:3	Epoch:6	Loss:0.971	translation_Loss:0.803	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:21.45	Hits@10:39.02	Best:21.45
2024-12-28 16:31:01,651: Snapshot:3	Epoch:7	Loss:0.928	translation_Loss:0.761	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:21.56	Hits@10:39.13	Best:21.56
2024-12-28 16:31:09,307: Snapshot:3	Epoch:8	Loss:0.898	translation_Loss:0.731	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:21.67	Hits@10:39.41	Best:21.67
2024-12-28 16:31:16,712: Snapshot:3	Epoch:9	Loss:0.875	translation_Loss:0.709	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:21.85	Hits@10:39.55	Best:21.85
2024-12-28 16:31:24,536: Snapshot:3	Epoch:10	Loss:0.849	translation_Loss:0.686	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.163                                                   	MRR:21.88	Hits@10:39.69	Best:21.88
2024-12-28 16:31:32,091: Snapshot:3	Epoch:11	Loss:0.837	translation_Loss:0.672	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:21.85	Hits@10:39.78	Best:21.88
2024-12-28 16:31:39,777: Snapshot:3	Epoch:12	Loss:0.832	translation_Loss:0.665	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:21.93	Hits@10:39.95	Best:21.93
2024-12-28 16:31:47,071: Snapshot:3	Epoch:13	Loss:0.809	translation_Loss:0.645	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.164                                                   	MRR:22.05	Hits@10:40.05	Best:22.05
2024-12-28 16:31:54,636: Snapshot:3	Epoch:14	Loss:0.816	translation_Loss:0.65	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:21.99	Hits@10:39.72	Best:22.05
2024-12-28 16:32:01,964: Snapshot:3	Epoch:15	Loss:0.799	translation_Loss:0.633	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:22.03	Hits@10:40.02	Best:22.05
2024-12-28 16:32:09,620: Snapshot:3	Epoch:16	Loss:0.797	translation_Loss:0.632	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:22.16	Hits@10:40.33	Best:22.16
2024-12-28 16:32:17,057: Snapshot:3	Epoch:17	Loss:0.784	translation_Loss:0.618	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:22.29	Hits@10:40.27	Best:22.29
2024-12-28 16:32:24,662: Snapshot:3	Epoch:18	Loss:0.783	translation_Loss:0.616	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:22.19	Hits@10:40.16	Best:22.29
2024-12-28 16:32:32,162: Snapshot:3	Epoch:19	Loss:0.774	translation_Loss:0.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:22.32	Hits@10:40.21	Best:22.32
2024-12-28 16:32:39,960: Snapshot:3	Epoch:20	Loss:0.767	translation_Loss:0.601	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:22.16	Hits@10:40.35	Best:22.32
2024-12-28 16:32:47,215: Snapshot:3	Epoch:21	Loss:0.763	translation_Loss:0.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:22.21	Hits@10:40.24	Best:22.32
2024-12-28 16:32:54,932: Snapshot:3	Epoch:22	Loss:0.753	translation_Loss:0.587	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:22.17	Hits@10:40.29	Best:22.32
2024-12-28 16:33:02,566: Snapshot:3	Epoch:23	Loss:0.752	translation_Loss:0.587	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:22.29	Hits@10:40.26	Best:22.32
2024-12-28 16:33:09,826: Snapshot:3	Epoch:24	Loss:0.749	translation_Loss:0.584	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:22.42	Hits@10:40.44	Best:22.42
2024-12-28 16:33:17,206: Snapshot:3	Epoch:25	Loss:0.746	translation_Loss:0.581	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:22.21	Hits@10:40.27	Best:22.42
2024-12-28 16:33:24,790: Snapshot:3	Epoch:26	Loss:0.743	translation_Loss:0.578	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:22.32	Hits@10:40.31	Best:22.42
2024-12-28 16:33:32,391: Snapshot:3	Epoch:27	Loss:0.741	translation_Loss:0.576	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.164                                                   	MRR:22.38	Hits@10:40.42	Best:22.42
2024-12-28 16:33:39,624: Snapshot:3	Epoch:28	Loss:0.739	translation_Loss:0.573	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:22.13	Hits@10:40.33	Best:22.42
2024-12-28 16:33:47,266: Early Stopping! Snapshot: 3 Epoch: 29 Best Results: 22.42
2024-12-28 16:33:47,266: Start to training tokens! Snapshot: 3 Epoch: 29 Loss:0.738 MRR:22.23 Best Results: 22.42
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-28 16:33:47,267: Snapshot:3	Epoch:29	Loss:0.738	translation_Loss:0.573	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:22.23	Hits@10:40.46	Best:22.42
2024-12-28 16:33:54,593: Snapshot:3	Epoch:30	Loss:27.635	translation_Loss:14.23	multi_layer_Loss:13.406	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.23	Hits@10:40.46	Best:22.42
2024-12-28 16:34:02,377: End of token training: 3 Epoch: 31 Loss:14.469 MRR:22.23 Best Results: 22.42
2024-12-28 16:34:02,378: Snapshot:3	Epoch:31	Loss:14.469	translation_Loss:14.235	multi_layer_Loss:0.234	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.23	Hits@10:40.46	Best:22.42
2024-12-28 16:34:02,634: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-28 16:34:12,415: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3391 | 0.2193 | 0.3921 | 0.469  |  0.5708 |
|     1      | 0.2555 | 0.1575 | 0.2904 | 0.3554 |  0.4459 |
|     2      | 0.2353 | 0.142  | 0.2702 | 0.3292 |  0.4136 |
|     3      | 0.2241 | 0.1326 | 0.2579 | 0.3168 |  0.399  |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:34:31,870: Snapshot:4	Epoch:0	Loss:8.34	translation_Loss:7.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.657                                                   	MRR:15.94	Hits@10:30.04	Best:15.94
2024-12-28 16:34:37,340: Snapshot:4	Epoch:1	Loss:2.571	translation_Loss:2.19	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.381                                                   	MRR:21.05	Hits@10:38.74	Best:21.05
2024-12-28 16:34:43,045: Snapshot:4	Epoch:2	Loss:1.103	translation_Loss:0.902	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:23.59	Hits@10:42.28	Best:23.59
2024-12-28 16:34:48,431: Snapshot:4	Epoch:3	Loss:0.708	translation_Loss:0.575	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.133                                                   	MRR:24.48	Hits@10:43.97	Best:24.48
2024-12-28 16:34:53,744: Snapshot:4	Epoch:4	Loss:0.564	translation_Loss:0.456	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:25.02	Hits@10:44.64	Best:25.02
2024-12-28 16:34:59,455: Snapshot:4	Epoch:5	Loss:0.494	translation_Loss:0.397	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:25.57	Hits@10:45.43	Best:25.57
2024-12-28 16:35:04,778: Snapshot:4	Epoch:6	Loss:0.445	translation_Loss:0.353	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:25.74	Hits@10:45.92	Best:25.74
2024-12-28 16:35:10,547: Snapshot:4	Epoch:7	Loss:0.422	translation_Loss:0.333	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:25.85	Hits@10:46.14	Best:25.85
2024-12-28 16:35:15,920: Snapshot:4	Epoch:8	Loss:0.403	translation_Loss:0.315	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:25.9	Hits@10:46.19	Best:25.9
2024-12-28 16:35:21,395: Snapshot:4	Epoch:9	Loss:0.387	translation_Loss:0.301	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:26.02	Hits@10:46.32	Best:26.02
2024-12-28 16:35:27,216: Snapshot:4	Epoch:10	Loss:0.376	translation_Loss:0.29	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:26.18	Hits@10:46.47	Best:26.18
2024-12-28 16:35:32,655: Snapshot:4	Epoch:11	Loss:0.361	translation_Loss:0.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:26.24	Hits@10:46.7	Best:26.24
2024-12-28 16:35:37,985: Snapshot:4	Epoch:12	Loss:0.362	translation_Loss:0.275	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:26.26	Hits@10:46.94	Best:26.26
2024-12-28 16:35:43,660: Snapshot:4	Epoch:13	Loss:0.353	translation_Loss:0.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:26.35	Hits@10:46.93	Best:26.35
2024-12-28 16:35:49,068: Snapshot:4	Epoch:14	Loss:0.349	translation_Loss:0.263	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:26.36	Hits@10:46.95	Best:26.36
2024-12-28 16:35:54,355: Snapshot:4	Epoch:15	Loss:0.344	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:26.51	Hits@10:47.25	Best:26.51
2024-12-28 16:36:00,144: Snapshot:4	Epoch:16	Loss:0.34	translation_Loss:0.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:26.61	Hits@10:47.21	Best:26.61
2024-12-28 16:36:05,546: Snapshot:4	Epoch:17	Loss:0.335	translation_Loss:0.248	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:26.45	Hits@10:47.47	Best:26.61
2024-12-28 16:36:10,876: Snapshot:4	Epoch:18	Loss:0.335	translation_Loss:0.247	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.55	Hits@10:47.19	Best:26.61
2024-12-28 16:36:16,714: Snapshot:4	Epoch:19	Loss:0.333	translation_Loss:0.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:26.62	Hits@10:47.36	Best:26.62
2024-12-28 16:36:22,038: Snapshot:4	Epoch:20	Loss:0.328	translation_Loss:0.24	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.74	Hits@10:47.4	Best:26.74
2024-12-28 16:36:27,330: Snapshot:4	Epoch:21	Loss:0.322	translation_Loss:0.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:26.74	Hits@10:47.4	Best:26.74
2024-12-28 16:36:32,977: Snapshot:4	Epoch:22	Loss:0.324	translation_Loss:0.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.84	Hits@10:47.35	Best:26.84
2024-12-28 16:36:38,394: Snapshot:4	Epoch:23	Loss:0.32	translation_Loss:0.232	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.85	Hits@10:47.62	Best:26.85
2024-12-28 16:36:43,694: Snapshot:4	Epoch:24	Loss:0.321	translation_Loss:0.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:26.76	Hits@10:47.31	Best:26.85
2024-12-28 16:36:49,303: Snapshot:4	Epoch:25	Loss:0.321	translation_Loss:0.232	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.84	Hits@10:47.39	Best:26.85
2024-12-28 16:36:54,528: Snapshot:4	Epoch:26	Loss:0.319	translation_Loss:0.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:26.84	Hits@10:47.69	Best:26.85
2024-12-28 16:37:00,170: Snapshot:4	Epoch:27	Loss:0.313	translation_Loss:0.225	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.61	Hits@10:47.45	Best:26.85
2024-12-28 16:37:05,490: Early Stopping! Snapshot: 4 Epoch: 28 Best Results: 26.85
2024-12-28 16:37:05,490: Start to training tokens! Snapshot: 4 Epoch: 28 Loss:0.315 MRR:26.46 Best Results: 26.85
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-28 16:37:05,490: Snapshot:4	Epoch:28	Loss:0.315	translation_Loss:0.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.46	Hits@10:47.49	Best:26.85
2024-12-28 16:37:10,681: Snapshot:4	Epoch:29	Loss:21.701	translation_Loss:7.823	multi_layer_Loss:13.878	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.46	Hits@10:47.49	Best:26.85
2024-12-28 16:37:16,405: End of token training: 4 Epoch: 30 Loss:8.294 MRR:26.46 Best Results: 26.85
2024-12-28 16:37:16,406: Snapshot:4	Epoch:30	Loss:8.294	translation_Loss:7.808	multi_layer_Loss:0.486	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.46	Hits@10:47.49	Best:26.85
2024-12-28 16:37:16,688: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-28 16:37:29,270: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3384 | 0.2184 | 0.3916 | 0.468  |  0.5701 |
|     1      | 0.2554 | 0.1574 | 0.2904 | 0.3557 |  0.446  |
|     2      | 0.2362 | 0.1429 | 0.2719 | 0.3299 |  0.4141 |
|     3      | 0.2249 | 0.1338 | 0.2584 | 0.3172 |  0.399  |
|     4      | 0.2683 | 0.1593 | 0.3194 | 0.3906 |  0.4795 |
+------------+--------+--------+--------+--------+---------+
2024-12-28 16:37:29,271: Final Result:
[+------------+------+--------+--------+--------+---------+
| Snapshot:0 | MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+------+--------+--------+--------+---------+
|     0      | 0.34 | 0.2198 | 0.3943 | 0.4682 |  0.5716 |
+------------+------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3392 | 0.2193 | 0.3924 | 0.4678 |  0.5722 |
|     1      | 0.2539 | 0.1559 | 0.2892 | 0.3535 |  0.4456 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3397 | 0.2203 | 0.3922 | 0.4683 |  0.572  |
|     1      | 0.2551 | 0.1574 | 0.291  | 0.3549 |  0.4464 |
|     2      | 0.2343 | 0.1408 | 0.2694 | 0.3285 |  0.4131 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3391 | 0.2193 | 0.3921 | 0.469  |  0.5708 |
|     1      | 0.2555 | 0.1575 | 0.2904 | 0.3554 |  0.4459 |
|     2      | 0.2353 | 0.142  | 0.2702 | 0.3292 |  0.4136 |
|     3      | 0.2241 | 0.1326 | 0.2579 | 0.3168 |  0.399  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3384 | 0.2184 | 0.3916 | 0.468  |  0.5701 |
|     1      | 0.2554 | 0.1574 | 0.2904 | 0.3557 |  0.446  |
|     2      | 0.2362 | 0.1429 | 0.2719 | 0.3299 |  0.4141 |
|     3      | 0.2249 | 0.1338 | 0.2584 | 0.3172 |  0.399  |
|     4      | 0.2683 | 0.1593 | 0.3194 | 0.3906 |  0.4795 |
+------------+--------+--------+--------+--------+---------+]
2024-12-28 16:37:29,272: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 101.57124948501587 |    0.34   |     0.22     |    0.394     |     0.572     |
|    1     | 200.62299585342407 |   0.287   |    0.181     |     0.33     |     0.495     |
|    2     | 221.33604264259338 |   0.268   |    0.166     |    0.307     |     0.464     |
|    3     | 255.83394694328308 |   0.256   |    0.157     |    0.294     |     0.446     |
|    4     | 181.04558300971985 |   0.258   |    0.158     |    0.298     |     0.451     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-28 16:37:29,272: Sum_Training_Time:960.4098179340363
2024-12-28 16:37:29,272: Every_Training_Time:[101.57124948501587, 200.62299585342407, 221.33604264259338, 255.83394694328308, 181.04558300971985]
2024-12-28 16:37:29,272: Forward transfer: 0.045675 Backward transfer: 0.0006499999999999839
2024-12-28 16:38:03,179: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241228163733/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=50000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-28 16:38:10,821: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-28 16:38:14,683: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.11	Best:9.49
2024-12-28 16:38:18,749: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.7	Best:14.08
2024-12-28 16:38:22,440: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.75	Best:19.63
2024-12-28 16:38:26,303: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.64	Hits@10:48.72	Best:24.64
2024-12-28 16:38:30,334: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.28	Hits@10:52.01	Best:28.28
2024-12-28 16:38:34,151: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.37	Hits@10:53.9	Best:30.37
2024-12-28 16:38:38,380: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.8	Hits@10:55.48	Best:31.8
2024-12-28 16:38:42,133: Snapshot:0	Epoch:8	Loss:1.299	translation_Loss:1.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.66	Hits@10:56.14	Best:32.66
2024-12-28 16:38:45,923: Snapshot:0	Epoch:9	Loss:0.968	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.15	Hits@10:56.57	Best:33.15
2024-12-28 16:38:50,043: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.49	Hits@10:56.9	Best:33.49
2024-12-28 16:38:53,800: Snapshot:0	Epoch:11	Loss:0.608	translation_Loss:0.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.5	Hits@10:57.03	Best:33.5
2024-12-28 16:38:57,569: Snapshot:0	Epoch:12	Loss:0.499	translation_Loss:0.499	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:57.2	Best:33.68
2024-12-28 16:39:01,702: Snapshot:0	Epoch:13	Loss:0.422	translation_Loss:0.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.6	Hits@10:57.07	Best:33.68
2024-12-28 16:39:05,365: Snapshot:0	Epoch:14	Loss:0.373	translation_Loss:0.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.72	Hits@10:56.98	Best:33.72
2024-12-28 16:39:09,115: Snapshot:0	Epoch:15	Loss:0.33	translation_Loss:0.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.66	Hits@10:56.73	Best:33.72
2024-12-28 16:39:13,229: Snapshot:0	Epoch:16	Loss:0.302	translation_Loss:0.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.7	Hits@10:56.61	Best:33.72
2024-12-28 16:39:16,892: Snapshot:0	Epoch:17	Loss:0.277	translation_Loss:0.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.66	Hits@10:56.8	Best:33.72
2024-12-28 16:39:20,578: Snapshot:0	Epoch:18	Loss:0.257	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.48	Hits@10:56.97	Best:33.72
2024-12-28 16:39:24,641: Early Stopping! Snapshot: 0 Epoch: 19 Best Results: 33.72
2024-12-28 16:39:24,641: Start to training tokens! Snapshot: 0 Epoch: 19 Loss:0.241 MRR:33.52 Best Results: 33.72
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 16:39:24,641: Snapshot:0	Epoch:19	Loss:0.241	translation_Loss:0.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.52	Hits@10:56.78	Best:33.72
2024-12-28 16:39:28,982: Snapshot:0	Epoch:20	Loss:24.559	translation_Loss:9.728	multi_layer_Loss:14.831	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.52	Hits@10:56.78	Best:33.72
2024-12-28 16:39:32,820: End of token training: 0 Epoch: 21 Loss:10.273 MRR:33.52 Best Results: 33.72
2024-12-28 16:39:32,820: Snapshot:0	Epoch:21	Loss:10.273	translation_Loss:9.721	multi_layer_Loss:0.552	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.52	Hits@10:56.78	Best:33.72
2024-12-28 16:39:33,074: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-28 16:39:34,642: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3405 | 0.2208 | 0.3943 | 0.4696 |  0.5685 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:39:59,229: Snapshot:1	Epoch:0	Loss:13.518	translation_Loss:12.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.667                                                   	MRR:14.49	Hits@10:25.24	Best:14.49
2024-12-28 16:40:05,871: Snapshot:1	Epoch:1	Loss:5.246	translation_Loss:5.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.23                                                   	MRR:20.28	Hits@10:36.04	Best:20.28
2024-12-28 16:40:12,464: Snapshot:1	Epoch:2	Loss:2.688	translation_Loss:2.537	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.151                                                   	MRR:22.99	Hits@10:40.8	Best:22.99
2024-12-28 16:40:18,843: Snapshot:1	Epoch:3	Loss:1.866	translation_Loss:1.743	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.123                                                   	MRR:23.87	Hits@10:42.22	Best:23.87
2024-12-28 16:40:25,287: Snapshot:1	Epoch:4	Loss:1.531	translation_Loss:1.42	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.111                                                   	MRR:24.21	Hits@10:43.05	Best:24.21
2024-12-28 16:40:31,709: Snapshot:1	Epoch:5	Loss:1.344	translation_Loss:1.237	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:24.44	Hits@10:43.25	Best:24.44
2024-12-28 16:40:38,663: Snapshot:1	Epoch:6	Loss:1.231	translation_Loss:1.128	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:24.58	Hits@10:43.57	Best:24.58
2024-12-28 16:40:45,048: Snapshot:1	Epoch:7	Loss:1.15	translation_Loss:1.05	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:24.66	Hits@10:43.48	Best:24.66
2024-12-28 16:40:51,870: Snapshot:1	Epoch:8	Loss:1.101	translation_Loss:1.002	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:24.74	Hits@10:43.84	Best:24.74
2024-12-28 16:40:58,595: Snapshot:1	Epoch:9	Loss:1.059	translation_Loss:0.957	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:24.85	Hits@10:43.94	Best:24.85
2024-12-28 16:41:05,004: Snapshot:1	Epoch:10	Loss:1.018	translation_Loss:0.92	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:24.99	Hits@10:44.39	Best:24.99
2024-12-28 16:41:11,769: Snapshot:1	Epoch:11	Loss:0.997	translation_Loss:0.898	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:24.95	Hits@10:44.13	Best:24.99
2024-12-28 16:41:18,191: Snapshot:1	Epoch:12	Loss:0.97	translation_Loss:0.872	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:24.96	Hits@10:43.95	Best:24.99
2024-12-28 16:41:25,016: Snapshot:1	Epoch:13	Loss:0.95	translation_Loss:0.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:25.05	Hits@10:44.19	Best:25.05
2024-12-28 16:41:31,576: Snapshot:1	Epoch:14	Loss:0.939	translation_Loss:0.841	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:25.1	Hits@10:44.11	Best:25.1
2024-12-28 16:41:38,484: Snapshot:1	Epoch:15	Loss:0.919	translation_Loss:0.822	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:25.08	Hits@10:44.23	Best:25.1
2024-12-28 16:41:44,958: Snapshot:1	Epoch:16	Loss:0.913	translation_Loss:0.814	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:25.12	Hits@10:44.35	Best:25.12
2024-12-28 16:41:51,792: Snapshot:1	Epoch:17	Loss:0.898	translation_Loss:0.799	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:25.16	Hits@10:44.19	Best:25.16
2024-12-28 16:41:58,165: Snapshot:1	Epoch:18	Loss:0.899	translation_Loss:0.799	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:25.05	Hits@10:44.18	Best:25.16
2024-12-28 16:42:04,916: Snapshot:1	Epoch:19	Loss:0.889	translation_Loss:0.79	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:25.17	Hits@10:44.23	Best:25.17
2024-12-28 16:42:11,609: Snapshot:1	Epoch:20	Loss:0.875	translation_Loss:0.775	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:25.12	Hits@10:44.23	Best:25.17
2024-12-28 16:42:17,963: Snapshot:1	Epoch:21	Loss:0.872	translation_Loss:0.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:25.16	Hits@10:44.4	Best:25.17
2024-12-28 16:42:24,734: Snapshot:1	Epoch:22	Loss:0.858	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:25.17	Hits@10:44.33	Best:25.17
2024-12-28 16:42:31,164: Snapshot:1	Epoch:23	Loss:0.857	translation_Loss:0.759	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:25.29	Hits@10:44.4	Best:25.29
2024-12-28 16:42:37,966: Snapshot:1	Epoch:24	Loss:0.847	translation_Loss:0.747	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:25.16	Hits@10:44.4	Best:25.29
2024-12-28 16:42:44,327: Snapshot:1	Epoch:25	Loss:0.845	translation_Loss:0.746	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:25.26	Hits@10:44.44	Best:25.29
2024-12-28 16:42:51,119: Snapshot:1	Epoch:26	Loss:0.843	translation_Loss:0.743	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:25.27	Hits@10:44.52	Best:25.29
2024-12-28 16:42:57,481: Snapshot:1	Epoch:27	Loss:0.836	translation_Loss:0.739	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:25.24	Hits@10:44.47	Best:25.29
2024-12-28 16:43:04,188: Early Stopping! Snapshot: 1 Epoch: 28 Best Results: 25.29
2024-12-28 16:43:04,188: Start to training tokens! Snapshot: 1 Epoch: 28 Loss:0.828 MRR:25.25 Best Results: 25.29
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 16:43:04,188: Snapshot:1	Epoch:28	Loss:0.828	translation_Loss:0.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:25.25	Hits@10:44.53	Best:25.29
2024-12-28 16:43:10,580: Snapshot:1	Epoch:29	Loss:31.741	translation_Loss:15.786	multi_layer_Loss:15.955	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.25	Hits@10:44.53	Best:25.29
2024-12-28 16:43:17,315: End of token training: 1 Epoch: 30 Loss:16.031 MRR:25.25 Best Results: 25.29
2024-12-28 16:43:17,316: Snapshot:1	Epoch:30	Loss:16.031	translation_Loss:15.812	multi_layer_Loss:0.219	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.25	Hits@10:44.53	Best:25.29
2024-12-28 16:43:17,567: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-28 16:43:21,219: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3402 | 0.2205 | 0.3943 | 0.4682 |  0.5697 |
|     1      | 0.2536 | 0.1555 | 0.2878 | 0.3541 |  0.4451 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:43:47,332: Snapshot:2	Epoch:0	Loss:12.164	translation_Loss:11.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.829                                                   	MRR:14.13	Hits@10:24.22	Best:14.13
2024-12-28 16:43:54,495: Snapshot:2	Epoch:1	Loss:4.106	translation_Loss:3.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.313                                                   	MRR:18.21	Hits@10:32.01	Best:18.21
2024-12-28 16:44:01,813: Snapshot:2	Epoch:2	Loss:2.269	translation_Loss:2.063	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.206                                                   	MRR:20.38	Hits@10:35.93	Best:20.38
2024-12-28 16:44:09,059: Snapshot:2	Epoch:3	Loss:1.712	translation_Loss:1.539	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:21.33	Hits@10:37.67	Best:21.33
2024-12-28 16:44:16,321: Snapshot:2	Epoch:4	Loss:1.474	translation_Loss:1.312	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.162                                                   	MRR:21.92	Hits@10:38.44	Best:21.92
2024-12-28 16:44:23,594: Snapshot:2	Epoch:5	Loss:1.344	translation_Loss:1.187	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.157                                                   	MRR:22.2	Hits@10:39.17	Best:22.2
2024-12-28 16:44:31,151: Snapshot:2	Epoch:6	Loss:1.274	translation_Loss:1.12	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:22.49	Hits@10:39.7	Best:22.49
2024-12-28 16:44:38,850: Snapshot:2	Epoch:7	Loss:1.213	translation_Loss:1.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:22.72	Hits@10:39.77	Best:22.72
2024-12-28 16:44:45,986: Snapshot:2	Epoch:8	Loss:1.158	translation_Loss:1.004	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:22.84	Hits@10:39.9	Best:22.84
2024-12-28 16:44:53,591: Snapshot:2	Epoch:9	Loss:1.136	translation_Loss:0.984	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:22.81	Hits@10:40.15	Best:22.84
2024-12-28 16:45:00,779: Snapshot:2	Epoch:10	Loss:1.111	translation_Loss:0.958	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:22.84	Hits@10:40.28	Best:22.84
2024-12-28 16:45:08,544: Snapshot:2	Epoch:11	Loss:1.086	translation_Loss:0.934	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:22.9	Hits@10:40.34	Best:22.9
2024-12-28 16:45:15,871: Snapshot:2	Epoch:12	Loss:1.078	translation_Loss:0.925	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:23.17	Hits@10:40.39	Best:23.17
2024-12-28 16:45:23,574: Snapshot:2	Epoch:13	Loss:1.059	translation_Loss:0.905	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:23.13	Hits@10:40.45	Best:23.17
2024-12-28 16:45:30,630: Snapshot:2	Epoch:14	Loss:1.041	translation_Loss:0.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:23.06	Hits@10:40.69	Best:23.17
2024-12-28 16:45:38,244: Snapshot:2	Epoch:15	Loss:1.031	translation_Loss:0.877	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:23.13	Hits@10:40.89	Best:23.17
2024-12-28 16:45:45,682: Snapshot:2	Epoch:16	Loss:1.029	translation_Loss:0.873	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:23.19	Hits@10:40.72	Best:23.19
2024-12-28 16:45:52,800: Snapshot:2	Epoch:17	Loss:1.014	translation_Loss:0.86	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:23.36	Hits@10:40.77	Best:23.36
2024-12-28 16:46:00,475: Snapshot:2	Epoch:18	Loss:1.003	translation_Loss:0.848	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:23.37	Hits@10:40.67	Best:23.37
2024-12-28 16:46:07,556: Snapshot:2	Epoch:19	Loss:0.992	translation_Loss:0.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:23.27	Hits@10:40.91	Best:23.37
2024-12-28 16:46:15,156: Snapshot:2	Epoch:20	Loss:0.987	translation_Loss:0.833	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:23.27	Hits@10:40.87	Best:23.37
2024-12-28 16:46:22,296: Snapshot:2	Epoch:21	Loss:0.98	translation_Loss:0.825	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:23.41	Hits@10:40.99	Best:23.41
2024-12-28 16:46:29,812: Snapshot:2	Epoch:22	Loss:0.977	translation_Loss:0.82	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:23.33	Hits@10:41.02	Best:23.41
2024-12-28 16:46:36,911: Snapshot:2	Epoch:23	Loss:0.964	translation_Loss:0.809	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:23.34	Hits@10:41.14	Best:23.41
2024-12-28 16:46:44,325: Snapshot:2	Epoch:24	Loss:0.964	translation_Loss:0.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:23.35	Hits@10:41.11	Best:23.41
2024-12-28 16:46:51,771: Snapshot:2	Epoch:25	Loss:0.967	translation_Loss:0.81	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.157                                                   	MRR:23.4	Hits@10:41.25	Best:23.41
2024-12-28 16:46:58,851: Early Stopping! Snapshot: 2 Epoch: 26 Best Results: 23.41
2024-12-28 16:46:58,852: Start to training tokens! Snapshot: 2 Epoch: 26 Loss:0.962 MRR:23.31 Best Results: 23.41
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 16:46:58,852: Snapshot:2	Epoch:26	Loss:0.962	translation_Loss:0.806	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:23.31	Hits@10:41.24	Best:23.41
2024-12-28 16:47:06,328: Snapshot:2	Epoch:27	Loss:30.907	translation_Loss:15.686	multi_layer_Loss:15.221	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.31	Hits@10:41.24	Best:23.41
2024-12-28 16:47:13,489: End of token training: 2 Epoch: 28 Loss:15.906 MRR:23.31 Best Results: 23.41
2024-12-28 16:47:13,489: Snapshot:2	Epoch:28	Loss:15.906	translation_Loss:15.686	multi_layer_Loss:0.22	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.31	Hits@10:41.24	Best:23.41
2024-12-28 16:47:13,784: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-28 16:47:20,720: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3391 | 0.2193 | 0.3926 | 0.4676 |  0.5683 |
|     1      | 0.2537 | 0.1551 | 0.2882 | 0.3541 |  0.4446 |
|     2      | 0.2349 | 0.1419 | 0.2694 | 0.329  |  0.4116 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:47:46,738: Snapshot:3	Epoch:0	Loss:11.171	translation_Loss:10.26	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.911                                                   	MRR:14.02	Hits@10:24.76	Best:14.02
2024-12-28 16:47:54,148: Snapshot:3	Epoch:1	Loss:3.38	translation_Loss:3.004	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.377                                                   	MRR:17.92	Hits@10:32.0	Best:17.92
2024-12-28 16:48:01,930: Snapshot:3	Epoch:2	Loss:1.857	translation_Loss:1.622	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.235                                                   	MRR:19.7	Hits@10:35.26	Best:19.7
2024-12-28 16:48:09,376: Snapshot:3	Epoch:3	Loss:1.41	translation_Loss:1.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.191                                                   	MRR:20.57	Hits@10:36.97	Best:20.57
2024-12-28 16:48:17,108: Snapshot:3	Epoch:4	Loss:1.235	translation_Loss:1.06	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.175                                                   	MRR:21.09	Hits@10:37.82	Best:21.09
2024-12-28 16:48:24,671: Snapshot:3	Epoch:5	Loss:1.14	translation_Loss:0.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:21.36	Hits@10:38.43	Best:21.36
2024-12-28 16:48:32,608: Snapshot:3	Epoch:6	Loss:1.072	translation_Loss:0.904	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:21.54	Hits@10:38.75	Best:21.54
2024-12-28 16:48:40,010: Snapshot:3	Epoch:7	Loss:1.023	translation_Loss:0.857	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:21.77	Hits@10:39.18	Best:21.77
2024-12-28 16:48:47,867: Snapshot:3	Epoch:8	Loss:0.994	translation_Loss:0.827	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:21.9	Hits@10:39.42	Best:21.9
2024-12-28 16:48:55,252: Snapshot:3	Epoch:9	Loss:0.972	translation_Loss:0.805	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:21.93	Hits@10:39.58	Best:21.93
2024-12-28 16:49:02,989: Snapshot:3	Epoch:10	Loss:0.95	translation_Loss:0.783	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:21.95	Hits@10:39.52	Best:21.95
2024-12-28 16:49:10,905: Snapshot:3	Epoch:11	Loss:0.937	translation_Loss:0.769	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:22.01	Hits@10:39.68	Best:22.01
2024-12-28 16:49:18,424: Snapshot:3	Epoch:12	Loss:0.928	translation_Loss:0.759	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:22.2	Hits@10:39.82	Best:22.2
2024-12-28 16:49:25,740: Snapshot:3	Epoch:13	Loss:0.912	translation_Loss:0.743	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:22.22	Hits@10:39.93	Best:22.22
2024-12-28 16:49:33,509: Snapshot:3	Epoch:14	Loss:0.902	translation_Loss:0.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:22.25	Hits@10:40.01	Best:22.25
2024-12-28 16:49:41,399: Snapshot:3	Epoch:15	Loss:0.887	translation_Loss:0.721	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:22.3	Hits@10:39.93	Best:22.3
2024-12-28 16:49:48,764: Snapshot:3	Epoch:16	Loss:0.879	translation_Loss:0.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:22.41	Hits@10:40.06	Best:22.41
2024-12-28 16:49:56,555: Snapshot:3	Epoch:17	Loss:0.87	translation_Loss:0.701	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:22.34	Hits@10:40.2	Best:22.41
2024-12-28 16:50:03,923: Snapshot:3	Epoch:18	Loss:0.872	translation_Loss:0.702	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:22.42	Hits@10:40.28	Best:22.42
2024-12-28 16:50:11,779: Snapshot:3	Epoch:19	Loss:0.85	translation_Loss:0.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:22.46	Hits@10:40.21	Best:22.46
2024-12-28 16:50:19,193: Snapshot:3	Epoch:20	Loss:0.857	translation_Loss:0.688	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:22.5	Hits@10:40.39	Best:22.5
2024-12-28 16:50:26,875: Snapshot:3	Epoch:21	Loss:0.846	translation_Loss:0.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:22.45	Hits@10:40.49	Best:22.5
2024-12-28 16:50:34,178: Snapshot:3	Epoch:22	Loss:0.839	translation_Loss:0.671	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:22.52	Hits@10:40.34	Best:22.52
2024-12-28 16:50:41,870: Snapshot:3	Epoch:23	Loss:0.84	translation_Loss:0.671	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:22.37	Hits@10:40.59	Best:22.52
2024-12-28 16:50:49,120: Snapshot:3	Epoch:24	Loss:0.848	translation_Loss:0.677	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:22.52	Hits@10:40.44	Best:22.52
2024-12-28 16:50:56,870: Snapshot:3	Epoch:25	Loss:0.842	translation_Loss:0.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:22.42	Hits@10:40.41	Best:22.52
2024-12-28 16:51:04,115: Snapshot:3	Epoch:26	Loss:0.834	translation_Loss:0.661	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:22.51	Hits@10:40.42	Best:22.52
2024-12-28 16:51:11,710: Early Stopping! Snapshot: 3 Epoch: 27 Best Results: 22.52
2024-12-28 16:51:11,710: Start to training tokens! Snapshot: 3 Epoch: 27 Loss:0.835 MRR:22.49 Best Results: 22.52
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 16:51:11,711: Snapshot:3	Epoch:27	Loss:0.835	translation_Loss:0.664	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:22.49	Hits@10:40.23	Best:22.52
2024-12-28 16:51:19,016: Snapshot:3	Epoch:28	Loss:28.679	translation_Loss:14.216	multi_layer_Loss:14.463	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.49	Hits@10:40.23	Best:22.52
2024-12-28 16:51:26,712: End of token training: 3 Epoch: 29 Loss:14.451 MRR:22.49 Best Results: 22.52
2024-12-28 16:51:26,713: Snapshot:3	Epoch:29	Loss:14.451	translation_Loss:14.209	multi_layer_Loss:0.241	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.49	Hits@10:40.23	Best:22.52
2024-12-28 16:51:26,967: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-28 16:51:37,136: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3392 | 0.2193 | 0.3932 | 0.4673 |  0.5688 |
|     1      | 0.254  | 0.1557 | 0.2886 | 0.3546 |  0.445  |
|     2      | 0.2356 | 0.1422 | 0.2709 |  0.33  |  0.4129 |
|     3      | 0.2255 | 0.1336 | 0.2599 | 0.3194 |  0.4008 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 16:51:56,426: Snapshot:4	Epoch:0	Loss:8.468	translation_Loss:7.747	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.721                                                   	MRR:15.88	Hits@10:30.2	Best:15.88
2024-12-28 16:52:02,198: Snapshot:4	Epoch:1	Loss:2.669	translation_Loss:2.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.379                                                   	MRR:21.09	Hits@10:38.77	Best:21.09
2024-12-28 16:52:07,605: Snapshot:4	Epoch:2	Loss:1.187	translation_Loss:0.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:23.94	Hits@10:42.74	Best:23.94
2024-12-28 16:52:12,995: Snapshot:4	Epoch:3	Loss:0.777	translation_Loss:0.634	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.143                                                   	MRR:24.76	Hits@10:44.08	Best:24.76
2024-12-28 16:52:18,806: Snapshot:4	Epoch:4	Loss:0.615	translation_Loss:0.501	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:25.3	Hits@10:44.88	Best:25.3
2024-12-28 16:52:24,169: Snapshot:4	Epoch:5	Loss:0.543	translation_Loss:0.438	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.105                                                   	MRR:25.64	Hits@10:45.35	Best:25.64
2024-12-28 16:52:29,530: Snapshot:4	Epoch:6	Loss:0.495	translation_Loss:0.397	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:25.83	Hits@10:45.81	Best:25.83
2024-12-28 16:52:35,354: Snapshot:4	Epoch:7	Loss:0.47	translation_Loss:0.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:26.12	Hits@10:46.18	Best:26.12
2024-12-28 16:52:40,697: Snapshot:4	Epoch:8	Loss:0.449	translation_Loss:0.354	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:26.41	Hits@10:46.28	Best:26.41
2024-12-28 16:52:45,981: Snapshot:4	Epoch:9	Loss:0.434	translation_Loss:0.34	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.36	Hits@10:46.22	Best:26.41
2024-12-28 16:52:51,625: Snapshot:4	Epoch:10	Loss:0.422	translation_Loss:0.329	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:26.5	Hits@10:46.46	Best:26.5
2024-12-28 16:52:56,890: Snapshot:4	Epoch:11	Loss:0.411	translation_Loss:0.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:26.42	Hits@10:46.66	Best:26.5
2024-12-28 16:53:02,239: Snapshot:4	Epoch:12	Loss:0.402	translation_Loss:0.309	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:26.45	Hits@10:46.56	Best:26.5
2024-12-28 16:53:07,849: Snapshot:4	Epoch:13	Loss:0.395	translation_Loss:0.304	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:26.43	Hits@10:46.7	Best:26.5
2024-12-28 16:53:13,268: Snapshot:4	Epoch:14	Loss:0.389	translation_Loss:0.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:26.32	Hits@10:46.95	Best:26.5
2024-12-28 16:53:18,553: Snapshot:4	Epoch:15	Loss:0.392	translation_Loss:0.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:26.64	Hits@10:46.93	Best:26.64
2024-12-28 16:53:24,337: Snapshot:4	Epoch:16	Loss:0.382	translation_Loss:0.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:26.75	Hits@10:47.02	Best:26.75
2024-12-28 16:53:29,668: Snapshot:4	Epoch:17	Loss:0.376	translation_Loss:0.283	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:26.72	Hits@10:47.08	Best:26.75
2024-12-28 16:53:35,304: Snapshot:4	Epoch:18	Loss:0.37	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:26.79	Hits@10:47.46	Best:26.79
2024-12-28 16:53:40,693: Snapshot:4	Epoch:19	Loss:0.367	translation_Loss:0.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:26.81	Hits@10:47.32	Best:26.81
2024-12-28 16:53:46,013: Snapshot:4	Epoch:20	Loss:0.368	translation_Loss:0.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.75	Hits@10:47.27	Best:26.81
2024-12-28 16:53:51,655: Snapshot:4	Epoch:21	Loss:0.367	translation_Loss:0.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.75	Hits@10:47.28	Best:26.81
2024-12-28 16:53:56,878: Snapshot:4	Epoch:22	Loss:0.358	translation_Loss:0.266	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:26.72	Hits@10:47.29	Best:26.81
2024-12-28 16:54:02,102: Snapshot:4	Epoch:23	Loss:0.363	translation_Loss:0.27	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.62	Hits@10:47.35	Best:26.81
2024-12-28 16:54:07,385: Early Stopping! Snapshot: 4 Epoch: 24 Best Results: 26.81
2024-12-28 16:54:07,386: Start to training tokens! Snapshot: 4 Epoch: 24 Loss:0.358 MRR:26.68 Best Results: 26.81
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 16:54:07,386: Snapshot:4	Epoch:24	Loss:0.358	translation_Loss:0.263	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.68	Hits@10:47.42	Best:26.81
2024-12-28 16:54:12,993: Snapshot:4	Epoch:25	Loss:22.662	translation_Loss:7.819	multi_layer_Loss:14.843	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.68	Hits@10:47.42	Best:26.81
2024-12-28 16:54:18,180: End of token training: 4 Epoch: 26 Loss:8.421 MRR:26.68 Best Results: 26.81
2024-12-28 16:54:18,180: Snapshot:4	Epoch:26	Loss:8.421	translation_Loss:7.813	multi_layer_Loss:0.607	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.68	Hits@10:47.42	Best:26.81
2024-12-28 16:54:18,473: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-28 16:54:31,995: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3389 | 0.219  | 0.393  | 0.4664 |  0.5684 |
|     1      | 0.254  | 0.1557 | 0.288  | 0.3543 |  0.4448 |
|     2      | 0.2364 | 0.1433 | 0.2711 | 0.331  |  0.4133 |
|     3      | 0.2265 | 0.1346 | 0.2609 | 0.3205 |  0.4019 |
|     4      | 0.2678 | 0.1569 | 0.3213 | 0.3916 |  0.4783 |
+------------+--------+--------+--------+--------+---------+
2024-12-28 16:54:31,997: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3405 | 0.2208 | 0.3943 | 0.4696 |  0.5685 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3402 | 0.2205 | 0.3943 | 0.4682 |  0.5697 |
|     1      | 0.2536 | 0.1555 | 0.2878 | 0.3541 |  0.4451 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3391 | 0.2193 | 0.3926 | 0.4676 |  0.5683 |
|     1      | 0.2537 | 0.1551 | 0.2882 | 0.3541 |  0.4446 |
|     2      | 0.2349 | 0.1419 | 0.2694 | 0.329  |  0.4116 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3392 | 0.2193 | 0.3932 | 0.4673 |  0.5688 |
|     1      | 0.254  | 0.1557 | 0.2886 | 0.3546 |  0.445  |
|     2      | 0.2356 | 0.1422 | 0.2709 |  0.33  |  0.4129 |
|     3      | 0.2255 | 0.1336 | 0.2599 | 0.3194 |  0.4008 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3389 | 0.219  | 0.393  | 0.4664 |  0.5684 |
|     1      | 0.254  | 0.1557 | 0.288  | 0.3543 |  0.4448 |
|     2      | 0.2364 | 0.1433 | 0.2711 | 0.331  |  0.4133 |
|     3      | 0.2265 | 0.1346 | 0.2609 | 0.3205 |  0.4019 |
|     4      | 0.2678 | 0.1569 | 0.3213 | 0.3916 |  0.4783 |
+------------+--------+--------+--------+--------+---------+]
2024-12-28 16:54:31,998: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 89.63976883888245  |   0.341   |    0.221     |    0.394     |     0.569     |
|    1     | 220.31241273880005 |   0.288   |    0.181     |    0.329     |     0.494     |
|    2     | 229.1198925971985  |   0.267   |    0.166     |    0.306     |     0.462     |
|    3     | 242.71841025352478 |   0.256   |    0.157     |    0.294     |     0.446     |
|    4     | 158.30011796951294 |   0.258   |    0.158     |    0.299     |     0.451     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-28 16:54:31,998: Sum_Training_Time:940.0906023979187
2024-12-28 16:54:31,998: Every_Training_Time:[89.63976883888245, 220.31241273880005, 229.1198925971985, 242.71841025352478, 158.30011796951294]
2024-12-28 16:54:31,998: Forward transfer: 0.046825 Backward transfer: 0.00032499999999999196
