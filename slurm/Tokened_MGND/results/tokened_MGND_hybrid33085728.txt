2025-01-06 22:01:05,503: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106220050/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=1111, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 3000.0, 800.0, 200000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 22:01:15,971: Snapshot:0	Epoch:0	Loss:15.427	translation_Loss:15.427	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.31	Hits@10:17.42	Best:7.31
2025-01-06 22:01:23,063: Snapshot:0	Epoch:1	Loss:10.818	translation_Loss:10.818	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.44	Hits@10:30.71	Best:12.44
2025-01-06 22:01:29,763: Snapshot:0	Epoch:2	Loss:7.131	translation_Loss:7.131	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.49	Hits@10:38.92	Best:18.49
2025-01-06 22:01:36,467: Snapshot:0	Epoch:3	Loss:4.228	translation_Loss:4.228	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.71	Hits@10:42.87	Best:22.71
2025-01-06 22:01:43,581: Snapshot:0	Epoch:4	Loss:2.555	translation_Loss:2.555	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.26	Hits@10:44.49	Best:24.26
2025-01-06 22:01:50,305: Snapshot:0	Epoch:5	Loss:1.622	translation_Loss:1.622	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.89	Hits@10:45.41	Best:24.89
2025-01-06 22:01:57,343: Snapshot:0	Epoch:6	Loss:1.11	translation_Loss:1.11	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.48	Hits@10:45.95	Best:25.48
2025-01-06 22:02:03,998: Snapshot:0	Epoch:7	Loss:0.826	translation_Loss:0.826	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.7	Hits@10:46.17	Best:25.7
2025-01-06 22:02:11,026: Snapshot:0	Epoch:8	Loss:0.645	translation_Loss:0.645	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.67	Hits@10:46.19	Best:25.7
2025-01-06 22:02:17,652: Snapshot:0	Epoch:9	Loss:0.53	translation_Loss:0.53	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.66	Hits@10:46.24	Best:25.7
2025-01-06 22:02:24,675: Snapshot:0	Epoch:10	Loss:0.459	translation_Loss:0.459	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.54	Hits@10:46.07	Best:25.7
2025-01-06 22:02:31,295: Snapshot:0	Epoch:11	Loss:0.393	translation_Loss:0.393	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.55	Hits@10:45.98	Best:25.7
2025-01-06 22:02:38,272: Early Stopping! Snapshot: 0 Epoch: 12 Best Results: 25.7
2025-01-06 22:02:38,272: Start to training tokens! Snapshot: 0 Epoch: 12 Loss:0.354 MRR:25.58 Best Results: 25.7
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:02:38,272: Snapshot:0	Epoch:12	Loss:0.354	translation_Loss:0.354	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.58	Hits@10:45.96	Best:25.7
2025-01-06 22:02:45,515: Snapshot:0	Epoch:13	Loss:27.557	translation_Loss:11.904	token_training_loss:15.654	distillation_Loss:0.0                                                   	MRR:25.58	Hits@10:45.96	Best:25.7
2025-01-06 22:02:52,174: End of token training: 0 Epoch: 14 Loss:12.301 MRR:25.58 Best Results: 25.7
2025-01-06 22:02:52,174: Snapshot:0	Epoch:14	Loss:12.301	translation_Loss:11.9	token_training_loss:0.402	distillation_Loss:0.0                                                           	MRR:25.58	Hits@10:45.96	Best:25.7
2025-01-06 22:02:52,427: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2025-01-06 22:02:55,421: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2573 | 0.1475 | 0.3161 | 0.3817 |  0.4559 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:03:03,129: Snapshot:1	Epoch:0	Loss:5.07	translation_Loss:4.849	token_training_loss:0.0	distillation_Loss:0.222                                                   	MRR:9.84	Hits@10:17.14	Best:9.84
2025-01-06 22:03:05,707: Snapshot:1	Epoch:1	Loss:3.26	translation_Loss:2.854	token_training_loss:0.0	distillation_Loss:0.407                                                   	MRR:16.42	Hits@10:31.26	Best:16.42
2025-01-06 22:03:08,290: Snapshot:1	Epoch:2	Loss:2.218	translation_Loss:1.753	token_training_loss:0.0	distillation_Loss:0.465                                                   	MRR:20.88	Hits@10:37.41	Best:20.88
2025-01-06 22:03:10,920: Snapshot:1	Epoch:3	Loss:1.636	translation_Loss:1.196	token_training_loss:0.0	distillation_Loss:0.44                                                   	MRR:23.37	Hits@10:41.35	Best:23.37
2025-01-06 22:03:13,476: Snapshot:1	Epoch:4	Loss:1.309	translation_Loss:0.924	token_training_loss:0.0	distillation_Loss:0.385                                                   	MRR:24.79	Hits@10:45.04	Best:24.79
2025-01-06 22:03:16,063: Snapshot:1	Epoch:5	Loss:1.11	translation_Loss:0.772	token_training_loss:0.0	distillation_Loss:0.337                                                   	MRR:25.88	Hits@10:47.29	Best:25.88
2025-01-06 22:03:18,983: Snapshot:1	Epoch:6	Loss:0.993	translation_Loss:0.686	token_training_loss:0.0	distillation_Loss:0.307                                                   	MRR:26.94	Hits@10:48.11	Best:26.94
2025-01-06 22:03:21,549: Snapshot:1	Epoch:7	Loss:0.913	translation_Loss:0.626	token_training_loss:0.0	distillation_Loss:0.287                                                   	MRR:27.67	Hits@10:48.71	Best:27.67
2025-01-06 22:03:24,194: Snapshot:1	Epoch:8	Loss:0.849	translation_Loss:0.574	token_training_loss:0.0	distillation_Loss:0.275                                                   	MRR:28.02	Hits@10:49.51	Best:28.02
2025-01-06 22:03:26,775: Snapshot:1	Epoch:9	Loss:0.806	translation_Loss:0.542	token_training_loss:0.0	distillation_Loss:0.264                                                   	MRR:28.53	Hits@10:49.86	Best:28.53
2025-01-06 22:03:29,328: Snapshot:1	Epoch:10	Loss:0.774	translation_Loss:0.518	token_training_loss:0.0	distillation_Loss:0.256                                                   	MRR:28.74	Hits@10:50.26	Best:28.74
2025-01-06 22:03:31,913: Snapshot:1	Epoch:11	Loss:0.746	translation_Loss:0.497	token_training_loss:0.0	distillation_Loss:0.249                                                   	MRR:29.15	Hits@10:50.84	Best:29.15
2025-01-06 22:03:34,788: Snapshot:1	Epoch:12	Loss:0.718	translation_Loss:0.475	token_training_loss:0.0	distillation_Loss:0.244                                                   	MRR:29.48	Hits@10:50.92	Best:29.48
2025-01-06 22:03:37,342: Snapshot:1	Epoch:13	Loss:0.696	translation_Loss:0.459	token_training_loss:0.0	distillation_Loss:0.237                                                   	MRR:29.74	Hits@10:51.22	Best:29.74
2025-01-06 22:03:39,958: Snapshot:1	Epoch:14	Loss:0.678	translation_Loss:0.447	token_training_loss:0.0	distillation_Loss:0.231                                                   	MRR:29.94	Hits@10:51.09	Best:29.94
2025-01-06 22:03:42,520: Snapshot:1	Epoch:15	Loss:0.67	translation_Loss:0.441	token_training_loss:0.0	distillation_Loss:0.228                                                   	MRR:29.94	Hits@10:51.25	Best:29.94
2025-01-06 22:03:45,043: Snapshot:1	Epoch:16	Loss:0.65	translation_Loss:0.424	token_training_loss:0.0	distillation_Loss:0.226                                                   	MRR:29.85	Hits@10:51.21	Best:29.94
2025-01-06 22:03:47,643: Snapshot:1	Epoch:17	Loss:0.644	translation_Loss:0.421	token_training_loss:0.0	distillation_Loss:0.224                                                   	MRR:30.01	Hits@10:51.34	Best:30.01
2025-01-06 22:03:50,655: Snapshot:1	Epoch:18	Loss:0.63	translation_Loss:0.409	token_training_loss:0.0	distillation_Loss:0.221                                                   	MRR:30.17	Hits@10:51.75	Best:30.17
2025-01-06 22:03:53,229: Snapshot:1	Epoch:19	Loss:0.625	translation_Loss:0.406	token_training_loss:0.0	distillation_Loss:0.219                                                   	MRR:30.33	Hits@10:51.87	Best:30.33
2025-01-06 22:03:55,814: Snapshot:1	Epoch:20	Loss:0.616	translation_Loss:0.399	token_training_loss:0.0	distillation_Loss:0.218                                                   	MRR:30.42	Hits@10:51.86	Best:30.42
2025-01-06 22:03:58,429: Snapshot:1	Epoch:21	Loss:0.613	translation_Loss:0.398	token_training_loss:0.0	distillation_Loss:0.215                                                   	MRR:30.27	Hits@10:51.45	Best:30.42
2025-01-06 22:04:00,943: Snapshot:1	Epoch:22	Loss:0.604	translation_Loss:0.391	token_training_loss:0.0	distillation_Loss:0.213                                                   	MRR:30.29	Hits@10:51.78	Best:30.42
2025-01-06 22:04:03,492: Snapshot:1	Epoch:23	Loss:0.598	translation_Loss:0.387	token_training_loss:0.0	distillation_Loss:0.211                                                   	MRR:30.45	Hits@10:51.89	Best:30.45
2025-01-06 22:04:06,445: Snapshot:1	Epoch:24	Loss:0.595	translation_Loss:0.385	token_training_loss:0.0	distillation_Loss:0.21                                                   	MRR:30.64	Hits@10:52.11	Best:30.64
2025-01-06 22:04:09,010: Snapshot:1	Epoch:25	Loss:0.592	translation_Loss:0.381	token_training_loss:0.0	distillation_Loss:0.211                                                   	MRR:30.72	Hits@10:52.14	Best:30.72
2025-01-06 22:04:11,612: Snapshot:1	Epoch:26	Loss:0.584	translation_Loss:0.374	token_training_loss:0.0	distillation_Loss:0.21                                                   	MRR:30.59	Hits@10:51.99	Best:30.72
2025-01-06 22:04:14,182: Snapshot:1	Epoch:27	Loss:0.579	translation_Loss:0.37	token_training_loss:0.0	distillation_Loss:0.209                                                   	MRR:30.42	Hits@10:51.93	Best:30.72
2025-01-06 22:04:16,694: Snapshot:1	Epoch:28	Loss:0.578	translation_Loss:0.37	token_training_loss:0.0	distillation_Loss:0.208                                                   	MRR:30.3	Hits@10:52.01	Best:30.72
2025-01-06 22:04:19,235: Snapshot:1	Epoch:29	Loss:0.582	translation_Loss:0.376	token_training_loss:0.0	distillation_Loss:0.206                                                   	MRR:30.37	Hits@10:51.81	Best:30.72
2025-01-06 22:04:22,097: Early Stopping! Snapshot: 1 Epoch: 30 Best Results: 30.72
2025-01-06 22:04:22,097: Start to training tokens! Snapshot: 1 Epoch: 30 Loss:0.574 MRR:30.46 Best Results: 30.72
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:04:22,098: Snapshot:1	Epoch:30	Loss:0.574	translation_Loss:0.368	token_training_loss:0.0	distillation_Loss:0.206                                                   	MRR:30.46	Hits@10:51.76	Best:30.72
2025-01-06 22:04:24,633: Snapshot:1	Epoch:31	Loss:16.375	translation_Loss:4.58	token_training_loss:11.795	distillation_Loss:0.0                                                   	MRR:30.46	Hits@10:51.76	Best:30.72
2025-01-06 22:04:27,118: End of token training: 1 Epoch: 32 Loss:7.179 MRR:30.46 Best Results: 30.72
2025-01-06 22:04:27,118: Snapshot:1	Epoch:32	Loss:7.179	translation_Loss:4.583	token_training_loss:2.596	distillation_Loss:0.0                                                           	MRR:30.46	Hits@10:51.76	Best:30.72
2025-01-06 22:04:27,383: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2025-01-06 22:04:31,339: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2555 | 0.1456 | 0.3145 | 0.3803 |  0.4563 |
|     1      | 0.3014 | 0.192  | 0.3562 | 0.4249 |  0.5083 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:04:51,036: Snapshot:2	Epoch:0	Loss:16.61	translation_Loss:15.559	token_training_loss:0.0	distillation_Loss:1.051                                                   	MRR:14.13	Hits@10:29.43	Best:14.13
2025-01-06 22:05:02,604: Snapshot:2	Epoch:1	Loss:8.011	translation_Loss:6.472	token_training_loss:0.0	distillation_Loss:1.539                                                   	MRR:19.24	Hits@10:36.7	Best:19.24
2025-01-06 22:05:13,868: Snapshot:2	Epoch:2	Loss:5.441	translation_Loss:4.016	token_training_loss:0.0	distillation_Loss:1.425                                                   	MRR:20.7	Hits@10:38.15	Best:20.7
2025-01-06 22:05:25,424: Snapshot:2	Epoch:3	Loss:4.505	translation_Loss:3.194	token_training_loss:0.0	distillation_Loss:1.31                                                   	MRR:21.24	Hits@10:38.6	Best:21.24
2025-01-06 22:05:36,921: Snapshot:2	Epoch:4	Loss:4.126	translation_Loss:2.875	token_training_loss:0.0	distillation_Loss:1.251                                                   	MRR:21.7	Hits@10:38.87	Best:21.7
2025-01-06 22:05:48,108: Snapshot:2	Epoch:5	Loss:3.94	translation_Loss:2.722	token_training_loss:0.0	distillation_Loss:1.218                                                   	MRR:21.78	Hits@10:38.86	Best:21.78
2025-01-06 22:05:59,528: Snapshot:2	Epoch:6	Loss:3.837	translation_Loss:2.634	token_training_loss:0.0	distillation_Loss:1.204                                                   	MRR:21.82	Hits@10:39.1	Best:21.82
2025-01-06 22:06:11,076: Snapshot:2	Epoch:7	Loss:3.756	translation_Loss:2.566	token_training_loss:0.0	distillation_Loss:1.19                                                   	MRR:21.66	Hits@10:38.88	Best:21.82
2025-01-06 22:06:22,234: Snapshot:2	Epoch:8	Loss:3.71	translation_Loss:2.527	token_training_loss:0.0	distillation_Loss:1.183                                                   	MRR:21.88	Hits@10:38.91	Best:21.88
2025-01-06 22:06:33,701: Snapshot:2	Epoch:9	Loss:3.678	translation_Loss:2.497	token_training_loss:0.0	distillation_Loss:1.181                                                   	MRR:21.83	Hits@10:39.17	Best:21.88
2025-01-06 22:06:45,112: Snapshot:2	Epoch:10	Loss:3.654	translation_Loss:2.474	token_training_loss:0.0	distillation_Loss:1.181                                                   	MRR:21.86	Hits@10:39.26	Best:21.88
2025-01-06 22:06:56,281: Snapshot:2	Epoch:11	Loss:3.631	translation_Loss:2.455	token_training_loss:0.0	distillation_Loss:1.176                                                   	MRR:21.92	Hits@10:39.24	Best:21.92
2025-01-06 22:07:07,683: Snapshot:2	Epoch:12	Loss:3.607	translation_Loss:2.432	token_training_loss:0.0	distillation_Loss:1.175                                                   	MRR:21.9	Hits@10:39.32	Best:21.92
2025-01-06 22:07:19,144: Snapshot:2	Epoch:13	Loss:3.584	translation_Loss:2.415	token_training_loss:0.0	distillation_Loss:1.168                                                   	MRR:21.92	Hits@10:39.05	Best:21.92
2025-01-06 22:07:30,740: Snapshot:2	Epoch:14	Loss:3.583	translation_Loss:2.409	token_training_loss:0.0	distillation_Loss:1.174                                                   	MRR:21.97	Hits@10:39.2	Best:21.97
2025-01-06 22:07:41,855: Snapshot:2	Epoch:15	Loss:3.562	translation_Loss:2.389	token_training_loss:0.0	distillation_Loss:1.174                                                   	MRR:21.81	Hits@10:39.04	Best:21.97
2025-01-06 22:07:53,310: Snapshot:2	Epoch:16	Loss:3.558	translation_Loss:2.389	token_training_loss:0.0	distillation_Loss:1.169                                                   	MRR:21.87	Hits@10:39.16	Best:21.97
2025-01-06 22:08:04,793: Snapshot:2	Epoch:17	Loss:3.538	translation_Loss:2.368	token_training_loss:0.0	distillation_Loss:1.17                                                   	MRR:22.06	Hits@10:39.06	Best:22.06
2025-01-06 22:08:15,955: Snapshot:2	Epoch:18	Loss:3.526	translation_Loss:2.359	token_training_loss:0.0	distillation_Loss:1.167                                                   	MRR:21.88	Hits@10:39.09	Best:22.06
2025-01-06 22:08:27,348: Snapshot:2	Epoch:19	Loss:3.521	translation_Loss:2.352	token_training_loss:0.0	distillation_Loss:1.169                                                   	MRR:21.91	Hits@10:39.14	Best:22.06
2025-01-06 22:08:38,866: Snapshot:2	Epoch:20	Loss:3.521	translation_Loss:2.352	token_training_loss:0.0	distillation_Loss:1.168                                                   	MRR:21.85	Hits@10:39.21	Best:22.06
2025-01-06 22:08:50,007: Snapshot:2	Epoch:21	Loss:3.506	translation_Loss:2.338	token_training_loss:0.0	distillation_Loss:1.167                                                   	MRR:21.82	Hits@10:39.16	Best:22.06
2025-01-06 22:09:01,501: Early Stopping! Snapshot: 2 Epoch: 22 Best Results: 22.06
2025-01-06 22:09:01,503: Start to training tokens! Snapshot: 2 Epoch: 22 Loss:3.499 MRR:21.82 Best Results: 22.06
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:09:01,503: Snapshot:2	Epoch:22	Loss:3.499	translation_Loss:2.334	token_training_loss:0.0	distillation_Loss:1.165                                                   	MRR:21.82	Hits@10:39.21	Best:22.06
2025-01-06 22:09:12,763: Snapshot:2	Epoch:23	Loss:33.431	translation_Loss:18.229	token_training_loss:15.203	distillation_Loss:0.0                                                   	MRR:21.82	Hits@10:39.21	Best:22.06
2025-01-06 22:09:23,694: End of token training: 2 Epoch: 24 Loss:18.336 MRR:21.82 Best Results: 22.06
2025-01-06 22:09:23,694: Snapshot:2	Epoch:24	Loss:18.336	translation_Loss:18.21	token_training_loss:0.126	distillation_Loss:0.0                                                           	MRR:21.82	Hits@10:39.21	Best:22.06
2025-01-06 22:09:23,947: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2025-01-06 22:09:32,611: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      |  0.25  | 0.1358 | 0.3104 | 0.3787 |  0.4602 |
|     1      | 0.2875 | 0.183  | 0.3325 | 0.4011 |  0.492  |
|     2      | 0.2183 | 0.1291 | 0.2522 | 0.3116 |  0.3897 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:09:55,843: Snapshot:3	Epoch:0	Loss:14.847	translation_Loss:14.074	token_training_loss:0.0	distillation_Loss:0.773                                                   	MRR:15.96	Hits@10:32.78	Best:15.96
2025-01-06 22:10:09,849: Snapshot:3	Epoch:1	Loss:5.63	translation_Loss:4.218	token_training_loss:0.0	distillation_Loss:1.412                                                   	MRR:20.51	Hits@10:38.52	Best:20.51
2025-01-06 22:10:23,687: Snapshot:3	Epoch:2	Loss:3.754	translation_Loss:2.28	token_training_loss:0.0	distillation_Loss:1.474                                                   	MRR:21.46	Hits@10:39.7	Best:21.46
2025-01-06 22:10:37,508: Snapshot:3	Epoch:3	Loss:3.19	translation_Loss:1.758	token_training_loss:0.0	distillation_Loss:1.432                                                   	MRR:21.79	Hits@10:40.0	Best:21.79
2025-01-06 22:10:51,001: Snapshot:3	Epoch:4	Loss:2.965	translation_Loss:1.555	token_training_loss:0.0	distillation_Loss:1.41                                                   	MRR:21.89	Hits@10:40.53	Best:21.89
2025-01-06 22:11:04,839: Snapshot:3	Epoch:5	Loss:2.838	translation_Loss:1.442	token_training_loss:0.0	distillation_Loss:1.395                                                   	MRR:22.0	Hits@10:40.3	Best:22.0
2025-01-06 22:11:18,890: Snapshot:3	Epoch:6	Loss:2.759	translation_Loss:1.377	token_training_loss:0.0	distillation_Loss:1.382                                                   	MRR:22.09	Hits@10:40.44	Best:22.09
2025-01-06 22:11:32,782: Snapshot:3	Epoch:7	Loss:2.706	translation_Loss:1.335	token_training_loss:0.0	distillation_Loss:1.372                                                   	MRR:22.09	Hits@10:40.69	Best:22.09
2025-01-06 22:11:46,701: Snapshot:3	Epoch:8	Loss:2.676	translation_Loss:1.308	token_training_loss:0.0	distillation_Loss:1.368                                                   	MRR:22.1	Hits@10:40.64	Best:22.1
2025-01-06 22:12:00,196: Snapshot:3	Epoch:9	Loss:2.656	translation_Loss:1.29	token_training_loss:0.0	distillation_Loss:1.367                                                   	MRR:22.14	Hits@10:40.57	Best:22.14
2025-01-06 22:12:14,020: Snapshot:3	Epoch:10	Loss:2.627	translation_Loss:1.27	token_training_loss:0.0	distillation_Loss:1.357                                                   	MRR:22.17	Hits@10:40.66	Best:22.17
2025-01-06 22:12:27,928: Snapshot:3	Epoch:11	Loss:2.618	translation_Loss:1.257	token_training_loss:0.0	distillation_Loss:1.361                                                   	MRR:21.99	Hits@10:40.64	Best:22.17
2025-01-06 22:12:41,773: Snapshot:3	Epoch:12	Loss:2.606	translation_Loss:1.251	token_training_loss:0.0	distillation_Loss:1.355                                                   	MRR:22.11	Hits@10:40.43	Best:22.17
2025-01-06 22:12:55,589: Snapshot:3	Epoch:13	Loss:2.608	translation_Loss:1.249	token_training_loss:0.0	distillation_Loss:1.359                                                   	MRR:22.2	Hits@10:40.72	Best:22.2
2025-01-06 22:13:09,346: Snapshot:3	Epoch:14	Loss:2.581	translation_Loss:1.229	token_training_loss:0.0	distillation_Loss:1.353                                                   	MRR:22.14	Hits@10:40.82	Best:22.2
2025-01-06 22:13:22,831: Snapshot:3	Epoch:15	Loss:2.584	translation_Loss:1.226	token_training_loss:0.0	distillation_Loss:1.359                                                   	MRR:22.11	Hits@10:40.6	Best:22.2
2025-01-06 22:13:36,611: Snapshot:3	Epoch:16	Loss:2.572	translation_Loss:1.221	token_training_loss:0.0	distillation_Loss:1.351                                                   	MRR:22.07	Hits@10:40.5	Best:22.2
2025-01-06 22:13:50,562: Snapshot:3	Epoch:17	Loss:2.569	translation_Loss:1.212	token_training_loss:0.0	distillation_Loss:1.357                                                   	MRR:22.31	Hits@10:40.89	Best:22.31
2025-01-06 22:14:04,364: Snapshot:3	Epoch:18	Loss:2.566	translation_Loss:1.207	token_training_loss:0.0	distillation_Loss:1.358                                                   	MRR:22.04	Hits@10:40.66	Best:22.31
2025-01-06 22:14:18,195: Snapshot:3	Epoch:19	Loss:2.551	translation_Loss:1.201	token_training_loss:0.0	distillation_Loss:1.35                                                   	MRR:21.95	Hits@10:40.7	Best:22.31
2025-01-06 22:14:31,910: Snapshot:3	Epoch:20	Loss:2.566	translation_Loss:1.211	token_training_loss:0.0	distillation_Loss:1.355                                                   	MRR:22.23	Hits@10:40.96	Best:22.31
2025-01-06 22:14:45,337: Snapshot:3	Epoch:21	Loss:2.565	translation_Loss:1.206	token_training_loss:0.0	distillation_Loss:1.359                                                   	MRR:22.12	Hits@10:40.85	Best:22.31
2025-01-06 22:14:59,202: Early Stopping! Snapshot: 3 Epoch: 22 Best Results: 22.31
2025-01-06 22:14:59,203: Start to training tokens! Snapshot: 3 Epoch: 22 Loss:2.562 MRR:22.16 Best Results: 22.31
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:14:59,203: Snapshot:3	Epoch:22	Loss:2.562	translation_Loss:1.206	token_training_loss:0.0	distillation_Loss:1.356                                                   	MRR:22.16	Hits@10:40.98	Best:22.31
2025-01-06 22:15:13,046: Snapshot:3	Epoch:23	Loss:33.134	translation_Loss:18.255	token_training_loss:14.879	distillation_Loss:0.0                                                   	MRR:22.16	Hits@10:40.98	Best:22.31
2025-01-06 22:15:26,619: End of token training: 3 Epoch: 24 Loss:18.328 MRR:22.16 Best Results: 22.31
2025-01-06 22:15:26,619: Snapshot:3	Epoch:24	Loss:18.328	translation_Loss:18.256	token_training_loss:0.073	distillation_Loss:0.0                                                           	MRR:22.16	Hits@10:40.98	Best:22.31
2025-01-06 22:15:26,876: => loading checkpoint './checkpoint/HYBRID/3model_best.tar'
2025-01-06 22:15:41,346: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2512 | 0.1458 | 0.3017 | 0.3657 |  0.4484 |
|     1      | 0.2719 | 0.172  | 0.3051 | 0.375  |  0.4747 |
|     2      | 0.2122 | 0.1238 | 0.2426 | 0.3018 |  0.3839 |
|     3      | 0.2224 | 0.1246 | 0.2613 | 0.3274 |  0.4089 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:15:53,324: Snapshot:4	Epoch:0	Loss:7.801	translation_Loss:6.37	token_training_loss:0.0	distillation_Loss:1.43                                                   	MRR:8.58	Hits@10:17.85	Best:8.58
2025-01-06 22:15:59,252: Snapshot:4	Epoch:1	Loss:5.713	translation_Loss:4.85	token_training_loss:0.0	distillation_Loss:0.863                                                   	MRR:14.52	Hits@10:28.27	Best:14.52
2025-01-06 22:16:04,762: Snapshot:4	Epoch:2	Loss:4.698	translation_Loss:3.898	token_training_loss:0.0	distillation_Loss:0.801                                                   	MRR:18.43	Hits@10:32.28	Best:18.43
2025-01-06 22:16:10,337: Snapshot:4	Epoch:3	Loss:3.986	translation_Loss:3.267	token_training_loss:0.0	distillation_Loss:0.719                                                   	MRR:20.77	Hits@10:34.86	Best:20.77
2025-01-06 22:16:16,336: Snapshot:4	Epoch:4	Loss:3.481	translation_Loss:2.831	token_training_loss:0.0	distillation_Loss:0.649                                                   	MRR:21.86	Hits@10:35.44	Best:21.86
2025-01-06 22:16:21,883: Snapshot:4	Epoch:5	Loss:3.175	translation_Loss:2.563	token_training_loss:0.0	distillation_Loss:0.611                                                   	MRR:22.27	Hits@10:35.53	Best:22.27
2025-01-06 22:16:27,437: Snapshot:4	Epoch:6	Loss:2.983	translation_Loss:2.397	token_training_loss:0.0	distillation_Loss:0.587                                                   	MRR:22.3	Hits@10:35.57	Best:22.3
2025-01-06 22:16:33,283: Snapshot:4	Epoch:7	Loss:2.883	translation_Loss:2.317	token_training_loss:0.0	distillation_Loss:0.566                                                   	MRR:22.36	Hits@10:35.67	Best:22.36
2025-01-06 22:16:38,764: Snapshot:4	Epoch:8	Loss:2.831	translation_Loss:2.276	token_training_loss:0.0	distillation_Loss:0.555                                                   	MRR:22.41	Hits@10:35.69	Best:22.41
2025-01-06 22:16:44,230: Snapshot:4	Epoch:9	Loss:2.785	translation_Loss:2.245	token_training_loss:0.0	distillation_Loss:0.541                                                   	MRR:22.37	Hits@10:35.69	Best:22.41
2025-01-06 22:16:49,972: Snapshot:4	Epoch:10	Loss:2.764	translation_Loss:2.231	token_training_loss:0.0	distillation_Loss:0.533                                                   	MRR:22.37	Hits@10:35.76	Best:22.41
2025-01-06 22:16:55,433: Snapshot:4	Epoch:11	Loss:2.76	translation_Loss:2.23	token_training_loss:0.0	distillation_Loss:0.53                                                   	MRR:22.42	Hits@10:35.85	Best:22.42
2025-01-06 22:17:00,893: Snapshot:4	Epoch:12	Loss:2.746	translation_Loss:2.223	token_training_loss:0.0	distillation_Loss:0.523                                                   	MRR:22.41	Hits@10:35.69	Best:22.42
2025-01-06 22:17:06,321: Snapshot:4	Epoch:13	Loss:2.745	translation_Loss:2.224	token_training_loss:0.0	distillation_Loss:0.521                                                   	MRR:22.31	Hits@10:35.69	Best:22.42
2025-01-06 22:17:12,191: Snapshot:4	Epoch:14	Loss:2.732	translation_Loss:2.214	token_training_loss:0.0	distillation_Loss:0.518                                                   	MRR:22.23	Hits@10:35.77	Best:22.42
2025-01-06 22:17:17,609: Snapshot:4	Epoch:15	Loss:2.742	translation_Loss:2.225	token_training_loss:0.0	distillation_Loss:0.516                                                   	MRR:22.17	Hits@10:35.66	Best:22.42
2025-01-06 22:17:23,119: Early Stopping! Snapshot: 4 Epoch: 16 Best Results: 22.42
2025-01-06 22:17:23,119: Start to training tokens! Snapshot: 4 Epoch: 16 Loss:2.728 MRR:22.27 Best Results: 22.42
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:17:23,120: Snapshot:4	Epoch:16	Loss:2.728	translation_Loss:2.214	token_training_loss:0.0	distillation_Loss:0.514                                                   	MRR:22.27	Hits@10:35.72	Best:22.42
2025-01-06 22:17:28,930: Snapshot:4	Epoch:17	Loss:24.749	translation_Loss:9.906	token_training_loss:14.843	distillation_Loss:0.0                                                   	MRR:22.27	Hits@10:35.72	Best:22.42
2025-01-06 22:17:34,287: End of token training: 4 Epoch: 18 Loss:10.863 MRR:22.27 Best Results: 22.42
2025-01-06 22:17:34,287: Snapshot:4	Epoch:18	Loss:10.863	translation_Loss:9.912	token_training_loss:0.95	distillation_Loss:0.0                                                           	MRR:22.27	Hits@10:35.72	Best:22.42
2025-01-06 22:17:34,542: => loading checkpoint './checkpoint/HYBRID/4model_best.tar'
2025-01-06 22:17:51,865: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2426 | 0.1342 | 0.295  | 0.362  |  0.4471 |
|     1      | 0.2711 | 0.1707 | 0.3056 | 0.3752 |  0.4745 |
|     2      | 0.2101 | 0.1212 | 0.2394 | 0.302  |  0.3837 |
|     3      | 0.2204 | 0.1217 | 0.2596 | 0.3257 |  0.4091 |
|     4      | 0.2208 | 0.1504 | 0.2487 | 0.2968 |  0.3552 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 22:17:51,867: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2573 | 0.1475 | 0.3161 | 0.3817 |  0.4559 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2555 | 0.1456 | 0.3145 | 0.3803 |  0.4563 |
|     1      | 0.3014 | 0.192  | 0.3562 | 0.4249 |  0.5083 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      |  0.25  | 0.1358 | 0.3104 | 0.3787 |  0.4602 |
|     1      | 0.2875 | 0.183  | 0.3325 | 0.4011 |  0.492  |
|     2      | 0.2183 | 0.1291 | 0.2522 | 0.3116 |  0.3897 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2512 | 0.1458 | 0.3017 | 0.3657 |  0.4484 |
|     1      | 0.2719 | 0.172  | 0.3051 | 0.375  |  0.4747 |
|     2      | 0.2122 | 0.1238 | 0.2426 | 0.3018 |  0.3839 |
|     3      | 0.2224 | 0.1246 | 0.2613 | 0.3274 |  0.4089 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2426 | 0.1342 | 0.295  | 0.362  |  0.4471 |
|     1      | 0.2711 | 0.1707 | 0.3056 | 0.3752 |  0.4745 |
|     2      | 0.2101 | 0.1212 | 0.2394 | 0.302  |  0.3837 |
|     3      | 0.2204 | 0.1217 | 0.2596 | 0.3257 |  0.4091 |
|     4      | 0.2208 | 0.1504 | 0.2487 | 0.2968 |  0.3552 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 22:17:51,868: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 106.6699755191803  |   0.257   |    0.147     |    0.316     |     0.456     |
|    1     | 90.36417961120605  |   0.268   |    0.158     |    0.326     |      0.47     |
|    2     | 287.6342213153839  |   0.238   |    0.138     |    0.282     |     0.427     |
|    3     | 348.1679537296295  |   0.229   |    0.133     |    0.267     |     0.414     |
|    4     | 110.01712584495544 |   0.225   |    0.131     |    0.262     |     0.406     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 22:17:51,868: Sum_Training_Time:942.8534560203552
2025-01-06 22:17:51,868: Every_Training_Time:[106.6699755191803, 90.36417961120605, 287.6342213153839, 348.1679537296295, 110.01712584495544]
2025-01-06 22:17:51,868: Forward transfer: 0.045675 Backward transfer: -0.013799999999999979
2025-01-06 22:18:15,828: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106221801/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3333, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 3000.0, 800.0, 200000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 22:18:26,030: Snapshot:0	Epoch:0	Loss:15.465	translation_Loss:15.465	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.06	Hits@10:17.02	Best:7.06
2025-01-06 22:18:33,024: Snapshot:0	Epoch:1	Loss:10.872	translation_Loss:10.872	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.29	Hits@10:31.02	Best:12.29
2025-01-06 22:18:39,690: Snapshot:0	Epoch:2	Loss:7.171	translation_Loss:7.171	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.62	Hits@10:39.2	Best:18.62
2025-01-06 22:18:46,345: Snapshot:0	Epoch:3	Loss:4.228	translation_Loss:4.228	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.8	Hits@10:43.23	Best:22.8
2025-01-06 22:18:53,394: Snapshot:0	Epoch:4	Loss:2.511	translation_Loss:2.511	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.24	Hits@10:44.77	Best:24.24
