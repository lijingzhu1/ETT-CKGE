2025-01-06 18:16:49,860: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106181632/RELATION', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=11, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATION', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[3000.0, 15000.0, 80000.0, 80000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:17:07,113: Snapshot:0	Epoch:0	Loss:24.073	translation_Loss:24.073	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:11.11	Hits@10:26.88	Best:11.11
2025-01-06 18:17:20,219: Snapshot:0	Epoch:1	Loss:14.92	translation_Loss:14.92	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.96	Hits@10:40.39	Best:18.96
2025-01-06 18:17:33,289: Snapshot:0	Epoch:2	Loss:8.639	translation_Loss:8.639	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.91	Hits@10:44.96	Best:23.91
2025-01-06 18:17:45,903: Snapshot:0	Epoch:3	Loss:4.85	translation_Loss:4.85	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.94	Hits@10:46.79	Best:25.94
2025-01-06 18:17:58,913: Snapshot:0	Epoch:4	Loss:2.831	translation_Loss:2.831	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.95	Hits@10:47.83	Best:26.95
2025-01-06 18:18:11,934: Snapshot:0	Epoch:5	Loss:1.859	translation_Loss:1.859	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.27	Hits@10:48.14	Best:27.27
2025-01-06 18:18:24,539: Snapshot:0	Epoch:6	Loss:1.378	translation_Loss:1.378	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.5	Hits@10:48.28	Best:27.5
2025-01-06 18:18:37,559: Snapshot:0	Epoch:7	Loss:1.128	translation_Loss:1.128	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.43	Hits@10:48.26	Best:27.5
2025-01-06 18:18:50,468: Snapshot:0	Epoch:8	Loss:0.959	translation_Loss:0.959	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.46	Hits@10:47.95	Best:27.5
2025-01-06 18:19:03,152: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 27.5
2025-01-06 18:19:03,153: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.865 MRR:27.36 Best Results: 27.5
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:19:03,153: Snapshot:0	Epoch:9	Loss:0.865	translation_Loss:0.865	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.36	Hits@10:47.85	Best:27.5
2025-01-06 18:19:16,668: Snapshot:0	Epoch:10	Loss:31.848	translation_Loss:16.573	token_training_loss:15.274	distillation_Loss:0.0                                                   	MRR:27.36	Hits@10:47.85	Best:27.5
2025-01-06 18:19:29,273: End of token training: 0 Epoch: 11 Loss:16.651 MRR:27.36 Best Results: 27.5
2025-01-06 18:19:29,274: Snapshot:0	Epoch:11	Loss:16.651	translation_Loss:16.563	token_training_loss:0.088	distillation_Loss:0.0                                                           	MRR:27.36	Hits@10:47.85	Best:27.5
2025-01-06 18:19:29,613: => loading checkpoint './checkpoint/RELATION/0model_best.tar'
2025-01-06 18:19:35,519: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2775 | 0.1649 | 0.3452 | 0.4124 |  0.4856 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:19:55,922: Snapshot:1	Epoch:0	Loss:19.996	translation_Loss:18.773	token_training_loss:0.0	distillation_Loss:1.224                                                   	MRR:10.79	Hits@10:25.66	Best:10.79
2025-01-06 18:20:07,984: Snapshot:1	Epoch:1	Loss:10.438	translation_Loss:8.195	token_training_loss:0.0	distillation_Loss:2.243                                                   	MRR:16.3	Hits@10:33.03	Best:16.3
2025-01-06 18:20:20,066: Snapshot:1	Epoch:2	Loss:6.768	translation_Loss:4.341	token_training_loss:0.0	distillation_Loss:2.427                                                   	MRR:17.24	Hits@10:33.91	Best:17.24
2025-01-06 18:20:31,732: Snapshot:1	Epoch:3	Loss:5.432	translation_Loss:3.151	token_training_loss:0.0	distillation_Loss:2.282                                                   	MRR:17.29	Hits@10:33.8	Best:17.29
2025-01-06 18:20:43,782: Snapshot:1	Epoch:4	Loss:4.925	translation_Loss:2.762	token_training_loss:0.0	distillation_Loss:2.163                                                   	MRR:17.26	Hits@10:33.65	Best:17.29
2025-01-06 18:20:55,815: Snapshot:1	Epoch:5	Loss:4.703	translation_Loss:2.615	token_training_loss:0.0	distillation_Loss:2.088                                                   	MRR:17.21	Hits@10:33.58	Best:17.29
2025-01-06 18:21:07,411: Snapshot:1	Epoch:6	Loss:4.598	translation_Loss:2.541	token_training_loss:0.0	distillation_Loss:2.057                                                   	MRR:17.33	Hits@10:33.51	Best:17.33
2025-01-06 18:21:19,354: Snapshot:1	Epoch:7	Loss:4.524	translation_Loss:2.492	token_training_loss:0.0	distillation_Loss:2.032                                                   	MRR:16.82	Hits@10:33.21	Best:17.33
2025-01-06 18:21:31,007: Snapshot:1	Epoch:8	Loss:4.486	translation_Loss:2.465	token_training_loss:0.0	distillation_Loss:2.021                                                   	MRR:16.93	Hits@10:33.04	Best:17.33
2025-01-06 18:21:43,034: Early Stopping! Snapshot: 1 Epoch: 9 Best Results: 17.33
2025-01-06 18:21:43,034: Start to training tokens! Snapshot: 1 Epoch: 9 Loss:4.447 MRR:16.78 Best Results: 17.33
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:21:43,035: Snapshot:1	Epoch:9	Loss:4.447	translation_Loss:2.438	token_training_loss:0.0	distillation_Loss:2.01                                                   	MRR:16.78	Hits@10:32.83	Best:17.33
2025-01-06 18:21:54,957: Snapshot:1	Epoch:10	Loss:35.035	translation_Loss:19.328	token_training_loss:15.707	distillation_Loss:0.0                                                   	MRR:16.78	Hits@10:32.83	Best:17.33
2025-01-06 18:22:06,330: End of token training: 1 Epoch: 11 Loss:19.451 MRR:16.78 Best Results: 17.33
2025-01-06 18:22:06,331: Snapshot:1	Epoch:11	Loss:19.451	translation_Loss:19.343	token_training_loss:0.108	distillation_Loss:0.0                                                           	MRR:16.78	Hits@10:32.83	Best:17.33
2025-01-06 18:22:06,641: => loading checkpoint './checkpoint/RELATION/1model_best.tar'
2025-01-06 18:22:17,149: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2453 | 0.1329 | 0.3075 | 0.3775 |  0.4576 |
|     1      | 0.1733 |  0.09  | 0.2057 | 0.2623 |  0.3318 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:22:33,681: Snapshot:2	Epoch:0	Loss:13.769	translation_Loss:11.984	token_training_loss:0.0	distillation_Loss:1.785                                                   	MRR:10.57	Hits@10:25.07	Best:10.57
2025-01-06 18:22:42,694: Snapshot:2	Epoch:1	Loss:7.824	translation_Loss:5.238	token_training_loss:0.0	distillation_Loss:2.585                                                   	MRR:17.69	Hits@10:34.09	Best:17.69
2025-01-06 18:22:51,306: Snapshot:2	Epoch:2	Loss:5.504	translation_Loss:3.514	token_training_loss:0.0	distillation_Loss:1.99                                                   	MRR:19.32	Hits@10:35.53	Best:19.32
2025-01-06 18:22:59,948: Snapshot:2	Epoch:3	Loss:4.365	translation_Loss:2.736	token_training_loss:0.0	distillation_Loss:1.629                                                   	MRR:20.04	Hits@10:35.81	Best:20.04
2025-01-06 18:23:09,017: Snapshot:2	Epoch:4	Loss:3.781	translation_Loss:2.375	token_training_loss:0.0	distillation_Loss:1.405                                                   	MRR:20.94	Hits@10:36.76	Best:20.94
2025-01-06 18:23:17,579: Snapshot:2	Epoch:5	Loss:3.491	translation_Loss:2.215	token_training_loss:0.0	distillation_Loss:1.276                                                   	MRR:21.34	Hits@10:36.98	Best:21.34
2025-01-06 18:23:26,594: Snapshot:2	Epoch:6	Loss:3.332	translation_Loss:2.126	token_training_loss:0.0	distillation_Loss:1.205                                                   	MRR:21.42	Hits@10:36.89	Best:21.42
2025-01-06 18:23:35,117: Snapshot:2	Epoch:7	Loss:3.244	translation_Loss:2.079	token_training_loss:0.0	distillation_Loss:1.165                                                   	MRR:21.4	Hits@10:36.9	Best:21.42
2025-01-06 18:23:44,128: Snapshot:2	Epoch:8	Loss:3.196	translation_Loss:2.05	token_training_loss:0.0	distillation_Loss:1.146                                                   	MRR:21.51	Hits@10:36.92	Best:21.51
2025-01-06 18:23:52,620: Snapshot:2	Epoch:9	Loss:3.153	translation_Loss:2.028	token_training_loss:0.0	distillation_Loss:1.125                                                   	MRR:21.38	Hits@10:36.63	Best:21.51
2025-01-06 18:24:01,733: Snapshot:2	Epoch:10	Loss:3.137	translation_Loss:2.018	token_training_loss:0.0	distillation_Loss:1.118                                                   	MRR:21.29	Hits@10:36.3	Best:21.51
2025-01-06 18:24:10,230: Early Stopping! Snapshot: 2 Epoch: 11 Best Results: 21.51
2025-01-06 18:24:10,230: Start to training tokens! Snapshot: 2 Epoch: 11 Loss:3.129 MRR:21.19 Best Results: 21.51
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:24:10,230: Snapshot:2	Epoch:11	Loss:3.129	translation_Loss:2.012	token_training_loss:0.0	distillation_Loss:1.117                                                   	MRR:21.19	Hits@10:36.46	Best:21.51
2025-01-06 18:24:18,591: Snapshot:2	Epoch:12	Loss:29.453	translation_Loss:14.671	token_training_loss:14.782	distillation_Loss:0.0                                                   	MRR:21.19	Hits@10:36.46	Best:21.51
2025-01-06 18:24:27,484: End of token training: 2 Epoch: 13 Loss:14.958 MRR:21.19 Best Results: 21.51
2025-01-06 18:24:27,485: Snapshot:2	Epoch:13	Loss:14.958	translation_Loss:14.677	token_training_loss:0.281	distillation_Loss:0.0                                                           	MRR:21.19	Hits@10:36.46	Best:21.51
2025-01-06 18:24:27,772: => loading checkpoint './checkpoint/RELATION/2model_best.tar'
2025-01-06 18:24:41,483: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2146 | 0.1108 | 0.2714 | 0.3364 |  0.4081 |
|     1      | 0.1678 | 0.0849 | 0.1998 | 0.2551 |  0.3244 |
|     2      | 0.2119 | 0.1359 | 0.2324 | 0.2856 |  0.3662 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:24:51,573: Snapshot:3	Epoch:0	Loss:6.889	translation_Loss:6.204	token_training_loss:0.0	distillation_Loss:0.684                                                   	MRR:5.45	Hits@10:12.79	Best:5.45
2025-01-06 18:24:55,978: Snapshot:3	Epoch:1	Loss:4.952	translation_Loss:4.267	token_training_loss:0.0	distillation_Loss:0.685                                                   	MRR:12.52	Hits@10:28.25	Best:12.52
2025-01-06 18:24:59,943: Snapshot:3	Epoch:2	Loss:3.648	translation_Loss:3.066	token_training_loss:0.0	distillation_Loss:0.581                                                   	MRR:16.05	Hits@10:32.82	Best:16.05
2025-01-06 18:25:03,930: Snapshot:3	Epoch:3	Loss:2.927	translation_Loss:2.427	token_training_loss:0.0	distillation_Loss:0.5                                                   	MRR:19.4	Hits@10:36.13	Best:19.4
2025-01-06 18:25:08,001: Snapshot:3	Epoch:4	Loss:2.492	translation_Loss:2.037	token_training_loss:0.0	distillation_Loss:0.456                                                   	MRR:21.13	Hits@10:37.2	Best:21.13
2025-01-06 18:25:11,977: Snapshot:3	Epoch:5	Loss:2.202	translation_Loss:1.786	token_training_loss:0.0	distillation_Loss:0.415                                                   	MRR:22.27	Hits@10:38.27	Best:22.27
2025-01-06 18:25:16,352: Snapshot:3	Epoch:6	Loss:1.981	translation_Loss:1.601	token_training_loss:0.0	distillation_Loss:0.38                                                   	MRR:23.11	Hits@10:38.69	Best:23.11
2025-01-06 18:25:20,311: Snapshot:3	Epoch:7	Loss:1.817	translation_Loss:1.465	token_training_loss:0.0	distillation_Loss:0.352                                                   	MRR:23.58	Hits@10:38.87	Best:23.58
2025-01-06 18:25:24,339: Snapshot:3	Epoch:8	Loss:1.704	translation_Loss:1.376	token_training_loss:0.0	distillation_Loss:0.327                                                   	MRR:23.77	Hits@10:39.02	Best:23.77
2025-01-06 18:25:28,415: Snapshot:3	Epoch:9	Loss:1.619	translation_Loss:1.305	token_training_loss:0.0	distillation_Loss:0.314                                                   	MRR:24.02	Hits@10:38.97	Best:24.02
2025-01-06 18:25:32,366: Snapshot:3	Epoch:10	Loss:1.56	translation_Loss:1.259	token_training_loss:0.0	distillation_Loss:0.301                                                   	MRR:24.43	Hits@10:39.04	Best:24.43
2025-01-06 18:25:36,834: Snapshot:3	Epoch:11	Loss:1.512	translation_Loss:1.22	token_training_loss:0.0	distillation_Loss:0.291                                                   	MRR:24.48	Hits@10:38.99	Best:24.48
2025-01-06 18:25:40,827: Snapshot:3	Epoch:12	Loss:1.479	translation_Loss:1.192	token_training_loss:0.0	distillation_Loss:0.287                                                   	MRR:24.85	Hits@10:38.94	Best:24.85
2025-01-06 18:25:44,798: Snapshot:3	Epoch:13	Loss:1.446	translation_Loss:1.165	token_training_loss:0.0	distillation_Loss:0.28                                                   	MRR:25.11	Hits@10:39.1	Best:25.11
2025-01-06 18:25:48,758: Snapshot:3	Epoch:14	Loss:1.43	translation_Loss:1.153	token_training_loss:0.0	distillation_Loss:0.276                                                   	MRR:25.27	Hits@10:39.08	Best:25.27
2025-01-06 18:25:52,793: Snapshot:3	Epoch:15	Loss:1.424	translation_Loss:1.149	token_training_loss:0.0	distillation_Loss:0.275                                                   	MRR:25.48	Hits@10:39.11	Best:25.48
2025-01-06 18:25:57,217: Snapshot:3	Epoch:16	Loss:1.408	translation_Loss:1.134	token_training_loss:0.0	distillation_Loss:0.274                                                   	MRR:25.54	Hits@10:39.19	Best:25.54
2025-01-06 18:26:01,154: Snapshot:3	Epoch:17	Loss:1.393	translation_Loss:1.123	token_training_loss:0.0	distillation_Loss:0.271                                                   	MRR:25.25	Hits@10:39.25	Best:25.54
2025-01-06 18:26:05,044: Snapshot:3	Epoch:18	Loss:1.395	translation_Loss:1.124	token_training_loss:0.0	distillation_Loss:0.271                                                   	MRR:25.53	Hits@10:39.48	Best:25.54
2025-01-06 18:26:08,968: Early Stopping! Snapshot: 3 Epoch: 19 Best Results: 25.54
2025-01-06 18:26:08,968: Start to training tokens! Snapshot: 3 Epoch: 19 Loss:1.386 MRR:25.52 Best Results: 25.54
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:26:08,968: Snapshot:3	Epoch:19	Loss:1.386	translation_Loss:1.115	token_training_loss:0.0	distillation_Loss:0.271                                                   	MRR:25.52	Hits@10:39.17	Best:25.54
2025-01-06 18:26:12,823: Snapshot:3	Epoch:20	Loss:18.631	translation_Loss:5.856	token_training_loss:12.774	distillation_Loss:0.0                                                   	MRR:25.52	Hits@10:39.17	Best:25.54
2025-01-06 18:26:17,074: End of token training: 3 Epoch: 21 Loss:7.282 MRR:25.52 Best Results: 25.54
2025-01-06 18:26:17,074: Snapshot:3	Epoch:21	Loss:7.282	translation_Loss:5.858	token_training_loss:1.424	distillation_Loss:0.0                                                           	MRR:25.52	Hits@10:39.17	Best:25.54
2025-01-06 18:26:17,362: => loading checkpoint './checkpoint/RELATION/3model_best.tar'
2025-01-06 18:26:33,223: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2154 | 0.1115 | 0.2724 | 0.3378 |  0.4098 |
|     1      | 0.1674 | 0.0838 |  0.2   | 0.2565 |  0.3267 |
|     2      | 0.2023 | 0.1264 | 0.2212 | 0.2746 |  0.3573 |
|     3      | 0.2503 | 0.1744 | 0.2817 | 0.3275 |  0.3855 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:26:41,832: Snapshot:4	Epoch:0	Loss:4.609	translation_Loss:4.089	token_training_loss:0.0	distillation_Loss:0.52                                                   	MRR:6.53	Hits@10:17.18	Best:6.53
2025-01-06 18:26:44,650: Snapshot:4	Epoch:1	Loss:3.499	translation_Loss:2.76	token_training_loss:0.0	distillation_Loss:0.739                                                   	MRR:10.89	Hits@10:27.56	Best:10.89
2025-01-06 18:26:47,540: Snapshot:4	Epoch:2	Loss:2.878	translation_Loss:2.151	token_training_loss:0.0	distillation_Loss:0.727                                                   	MRR:14.32	Hits@10:32.91	Best:14.32
2025-01-06 18:26:50,403: Snapshot:4	Epoch:3	Loss:2.4	translation_Loss:1.725	token_training_loss:0.0	distillation_Loss:0.676                                                   	MRR:17.56	Hits@10:36.2	Best:17.56
2025-01-06 18:26:53,286: Snapshot:4	Epoch:4	Loss:2.076	translation_Loss:1.46	token_training_loss:0.0	distillation_Loss:0.616                                                   	MRR:19.57	Hits@10:37.98	Best:19.57
2025-01-06 18:26:56,183: Snapshot:4	Epoch:5	Loss:1.846	translation_Loss:1.273	token_training_loss:0.0	distillation_Loss:0.573                                                   	MRR:20.73	Hits@10:38.91	Best:20.73
2025-01-06 18:26:59,391: Snapshot:4	Epoch:6	Loss:1.657	translation_Loss:1.12	token_training_loss:0.0	distillation_Loss:0.537                                                   	MRR:21.63	Hits@10:40.18	Best:21.63
2025-01-06 18:27:02,279: Snapshot:4	Epoch:7	Loss:1.511	translation_Loss:1.007	token_training_loss:0.0	distillation_Loss:0.503                                                   	MRR:21.87	Hits@10:40.61	Best:21.87
2025-01-06 18:27:05,237: Snapshot:4	Epoch:8	Loss:1.4	translation_Loss:0.925	token_training_loss:0.0	distillation_Loss:0.475                                                   	MRR:22.38	Hits@10:41.2	Best:22.38
2025-01-06 18:27:08,096: Snapshot:4	Epoch:9	Loss:1.311	translation_Loss:0.858	token_training_loss:0.0	distillation_Loss:0.453                                                   	MRR:22.6	Hits@10:41.56	Best:22.6
2025-01-06 18:27:10,866: Snapshot:4	Epoch:10	Loss:1.246	translation_Loss:0.808	token_training_loss:0.0	distillation_Loss:0.438                                                   	MRR:22.53	Hits@10:41.63	Best:22.6
2025-01-06 18:27:13,685: Snapshot:4	Epoch:11	Loss:1.193	translation_Loss:0.769	token_training_loss:0.0	distillation_Loss:0.423                                                   	MRR:22.95	Hits@10:41.85	Best:22.95
2025-01-06 18:27:16,852: Snapshot:4	Epoch:12	Loss:1.16	translation_Loss:0.747	token_training_loss:0.0	distillation_Loss:0.413                                                   	MRR:22.91	Hits@10:41.93	Best:22.95
2025-01-06 18:27:19,636: Snapshot:4	Epoch:13	Loss:1.131	translation_Loss:0.725	token_training_loss:0.0	distillation_Loss:0.406                                                   	MRR:22.81	Hits@10:41.97	Best:22.95
2025-01-06 18:27:22,438: Early Stopping! Snapshot: 4 Epoch: 14 Best Results: 22.95
2025-01-06 18:27:22,438: Start to training tokens! Snapshot: 4 Epoch: 14 Loss:1.103 MRR:22.59 Best Results: 22.95
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:27:22,439: Snapshot:4	Epoch:14	Loss:1.103	translation_Loss:0.706	token_training_loss:0.0	distillation_Loss:0.397                                                   	MRR:22.59	Hits@10:41.66	Best:22.95
2025-01-06 18:27:25,229: Snapshot:4	Epoch:15	Loss:15.459	translation_Loss:4.048	token_training_loss:11.411	distillation_Loss:0.0                                                   	MRR:22.59	Hits@10:41.66	Best:22.95
2025-01-06 18:27:27,988: End of token training: 4 Epoch: 16 Loss:6.518 MRR:22.59 Best Results: 22.95
2025-01-06 18:27:27,988: Snapshot:4	Epoch:16	Loss:6.518	translation_Loss:4.051	token_training_loss:2.467	distillation_Loss:0.0                                                           	MRR:22.59	Hits@10:41.66	Best:22.95
2025-01-06 18:27:28,265: => loading checkpoint './checkpoint/RELATION/4model_best.tar'
2025-01-06 18:27:45,916: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2133 | 0.1099 | 0.2695 | 0.3345 |  0.4069 |
|     1      | 0.1668 | 0.0838 | 0.1988 | 0.2547 |  0.3253 |
|     2      | 0.1968 | 0.1234 | 0.215  | 0.2662 |  0.3441 |
|     3      | 0.2445 | 0.1674 | 0.2728 | 0.3235 |  0.3873 |
|     4      | 0.2249 | 0.1294 | 0.2523 | 0.3126 |  0.4144 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 18:27:45,918: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2775 | 0.1649 | 0.3452 | 0.4124 |  0.4856 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2453 | 0.1329 | 0.3075 | 0.3775 |  0.4576 |
|     1      | 0.1733 |  0.09  | 0.2057 | 0.2623 |  0.3318 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2146 | 0.1108 | 0.2714 | 0.3364 |  0.4081 |
|     1      | 0.1678 | 0.0849 | 0.1998 | 0.2551 |  0.3244 |
|     2      | 0.2119 | 0.1359 | 0.2324 | 0.2856 |  0.3662 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2154 | 0.1115 | 0.2724 | 0.3378 |  0.4098 |
|     1      | 0.1674 | 0.0838 |  0.2   | 0.2565 |  0.3267 |
|     2      | 0.2023 | 0.1264 | 0.2212 | 0.2746 |  0.3573 |
|     3      | 0.2503 | 0.1744 | 0.2817 | 0.3275 |  0.3855 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2133 | 0.1099 | 0.2695 | 0.3345 |  0.4069 |
|     1      | 0.1668 | 0.0838 | 0.1988 | 0.2547 |  0.3253 |
|     2      | 0.1968 | 0.1234 | 0.215  | 0.2662 |  0.3441 |
|     3      | 0.2445 | 0.1674 | 0.2728 | 0.3235 |  0.3873 |
|     4      | 0.2249 | 0.1294 | 0.2523 | 0.3126 |  0.4144 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 18:27:45,919: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 159.41337943077087 |   0.278   |    0.165     |    0.345     |     0.486     |
|    1     | 146.17848420143127 |    0.21   |    0.112     |    0.258     |     0.396     |
|    2     | 126.59822535514832 |   0.197   |    0.108     |    0.236     |     0.367     |
|    3     | 93.60003066062927  |    0.2    |    0.112     |    0.238     |     0.368     |
|    4     | 53.19608283042908  |    0.2    |    0.112     |    0.236     |     0.368     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 18:27:45,919: Sum_Training_Time:578.9862024784088
2025-01-06 18:27:45,919: Every_Training_Time:[159.41337943077087, 146.17848420143127, 126.59822535514832, 93.60003066062927, 53.19608283042908]
2025-01-06 18:27:45,919: Forward transfer: 0.015275 Backward transfer: -0.022900000000000018
2025-01-06 18:28:07,135: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106182751/RELATION', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=22, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATION', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[3000.0, 15000.0, 80000.0, 80000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:28:24,200: Snapshot:0	Epoch:0	Loss:24.153	translation_Loss:24.153	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:10.98	Hits@10:26.42	Best:10.98
2025-01-06 18:28:37,292: Snapshot:0	Epoch:1	Loss:14.954	translation_Loss:14.954	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.75	Hits@10:40.05	Best:18.75
2025-01-06 18:28:50,327: Snapshot:0	Epoch:2	Loss:8.641	translation_Loss:8.641	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.85	Hits@10:44.95	Best:23.85
2025-01-06 18:29:03,024: Snapshot:0	Epoch:3	Loss:4.846	translation_Loss:4.846	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.14	Hits@10:46.85	Best:26.14
2025-01-06 18:29:15,948: Snapshot:0	Epoch:4	Loss:2.832	translation_Loss:2.832	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.04	Hits@10:48.01	Best:27.04
2025-01-06 18:29:28,970: Snapshot:0	Epoch:5	Loss:1.858	translation_Loss:1.858	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.42	Hits@10:47.95	Best:27.42
2025-01-06 18:29:41,615: Snapshot:0	Epoch:6	Loss:1.398	translation_Loss:1.398	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.45	Hits@10:48.19	Best:27.45
2025-01-06 18:29:54,643: Snapshot:0	Epoch:7	Loss:1.126	translation_Loss:1.126	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.49	Hits@10:48.26	Best:27.49
2025-01-06 18:30:07,697: Snapshot:0	Epoch:8	Loss:0.968	translation_Loss:0.968	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.55	Hits@10:48.18	Best:27.55
2025-01-06 18:30:20,272: Snapshot:0	Epoch:9	Loss:0.86	translation_Loss:0.86	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.43	Hits@10:48.03	Best:27.55
2025-01-06 18:30:33,296: Snapshot:0	Epoch:10	Loss:0.793	translation_Loss:0.793	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.54	Hits@10:47.72	Best:27.55
2025-01-06 18:30:45,844: Early Stopping! Snapshot: 0 Epoch: 11 Best Results: 27.55
2025-01-06 18:30:45,844: Start to training tokens! Snapshot: 0 Epoch: 11 Loss:0.725 MRR:27.4 Best Results: 27.55
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:30:45,844: Snapshot:0	Epoch:11	Loss:0.725	translation_Loss:0.725	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.4	Hits@10:47.75	Best:27.55
2025-01-06 18:30:59,381: Snapshot:0	Epoch:12	Loss:31.854	translation_Loss:16.563	token_training_loss:15.291	distillation_Loss:0.0                                                   	MRR:27.4	Hits@10:47.75	Best:27.55
2025-01-06 18:31:12,357: End of token training: 0 Epoch: 13 Loss:16.666 MRR:27.4 Best Results: 27.55
2025-01-06 18:31:12,357: Snapshot:0	Epoch:13	Loss:16.666	translation_Loss:16.577	token_training_loss:0.089	distillation_Loss:0.0                                                           	MRR:27.4	Hits@10:47.75	Best:27.55
2025-01-06 18:31:12,643: => loading checkpoint './checkpoint/RELATION/0model_best.tar'
2025-01-06 18:31:18,209: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2795 | 0.1681 | 0.3456 | 0.4137 |  0.4871 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:31:39,071: Snapshot:1	Epoch:0	Loss:20.033	translation_Loss:18.809	token_training_loss:0.0	distillation_Loss:1.224                                                   	MRR:10.21	Hits@10:24.83	Best:10.21
2025-01-06 18:31:50,726: Snapshot:1	Epoch:1	Loss:10.242	translation_Loss:8.018	token_training_loss:0.0	distillation_Loss:2.224                                                   	MRR:16.15	Hits@10:32.21	Best:16.15
2025-01-06 18:32:02,963: Snapshot:1	Epoch:2	Loss:6.493	translation_Loss:4.126	token_training_loss:0.0	distillation_Loss:2.367                                                   	MRR:16.57	Hits@10:33.3	Best:16.57
2025-01-06 18:32:14,582: Snapshot:1	Epoch:3	Loss:5.152	translation_Loss:2.953	token_training_loss:0.0	distillation_Loss:2.199                                                   	MRR:16.83	Hits@10:33.06	Best:16.83
2025-01-06 18:32:26,620: Snapshot:1	Epoch:4	Loss:4.644	translation_Loss:2.575	token_training_loss:0.0	distillation_Loss:2.069                                                   	MRR:16.83	Hits@10:33.09	Best:16.83
2025-01-06 18:32:38,585: Snapshot:1	Epoch:5	Loss:4.432	translation_Loss:2.443	token_training_loss:0.0	distillation_Loss:1.989                                                   	MRR:16.95	Hits@10:32.97	Best:16.95
2025-01-06 18:32:50,262: Snapshot:1	Epoch:6	Loss:4.316	translation_Loss:2.361	token_training_loss:0.0	distillation_Loss:1.955                                                   	MRR:16.6	Hits@10:32.74	Best:16.95
2025-01-06 18:33:02,331: Snapshot:1	Epoch:7	Loss:4.24	translation_Loss:2.317	token_training_loss:0.0	distillation_Loss:1.924                                                   	MRR:16.53	Hits@10:32.68	Best:16.95
2025-01-06 18:33:13,903: Early Stopping! Snapshot: 1 Epoch: 8 Best Results: 16.95
2025-01-06 18:33:13,903: Start to training tokens! Snapshot: 1 Epoch: 8 Loss:4.182 MRR:16.52 Best Results: 16.95
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:33:13,904: Snapshot:1	Epoch:8	Loss:4.182	translation_Loss:2.276	token_training_loss:0.0	distillation_Loss:1.906                                                   	MRR:16.52	Hits@10:32.72	Best:16.95
2025-01-06 18:33:25,847: Snapshot:1	Epoch:9	Loss:34.645	translation_Loss:19.493	token_training_loss:15.151	distillation_Loss:0.0                                                   	MRR:16.52	Hits@10:32.72	Best:16.95
2025-01-06 18:33:37,723: End of token training: 1 Epoch: 10 Loss:19.604 MRR:16.52 Best Results: 16.95
2025-01-06 18:33:37,723: Snapshot:1	Epoch:10	Loss:19.604	translation_Loss:19.496	token_training_loss:0.108	distillation_Loss:0.0                                                           	MRR:16.52	Hits@10:32.72	Best:16.95
2025-01-06 18:33:38,023: => loading checkpoint './checkpoint/RELATION/1model_best.tar'
2025-01-06 18:33:48,042: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2489 | 0.1375 | 0.3098 | 0.3817 |  0.4584 |
|     1      | 0.1714 | 0.0887 | 0.2035 | 0.2584 |  0.3287 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:34:04,963: Snapshot:2	Epoch:0	Loss:13.636	translation_Loss:11.834	token_training_loss:0.0	distillation_Loss:1.802                                                   	MRR:12.06	Hits@10:27.09	Best:12.06
2025-01-06 18:34:14,072: Snapshot:2	Epoch:1	Loss:7.563	translation_Loss:4.992	token_training_loss:0.0	distillation_Loss:2.572                                                   	MRR:18.94	Hits@10:35.42	Best:18.94
2025-01-06 18:34:22,649: Snapshot:2	Epoch:2	Loss:5.271	translation_Loss:3.322	token_training_loss:0.0	distillation_Loss:1.949                                                   	MRR:20.51	Hits@10:36.85	Best:20.51
2025-01-06 18:34:31,702: Snapshot:2	Epoch:3	Loss:4.176	translation_Loss:2.584	token_training_loss:0.0	distillation_Loss:1.592                                                   	MRR:21.47	Hits@10:37.08	Best:21.47
2025-01-06 18:34:40,221: Snapshot:2	Epoch:4	Loss:3.592	translation_Loss:2.232	token_training_loss:0.0	distillation_Loss:1.36                                                   	MRR:21.55	Hits@10:37.09	Best:21.55
2025-01-06 18:34:48,773: Snapshot:2	Epoch:5	Loss:3.298	translation_Loss:2.068	token_training_loss:0.0	distillation_Loss:1.23                                                   	MRR:21.43	Hits@10:37.02	Best:21.55
2025-01-06 18:34:57,790: Snapshot:2	Epoch:6	Loss:3.17	translation_Loss:2.001	token_training_loss:0.0	distillation_Loss:1.169                                                   	MRR:21.18	Hits@10:36.81	Best:21.55
2025-01-06 18:35:06,436: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 21.55
2025-01-06 18:35:06,437: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:3.086 MRR:21.02 Best Results: 21.55
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:35:06,437: Snapshot:2	Epoch:7	Loss:3.086	translation_Loss:1.957	token_training_loss:0.0	distillation_Loss:1.13                                                   	MRR:21.02	Hits@10:36.32	Best:21.55
2025-01-06 18:35:15,277: Snapshot:2	Epoch:8	Loss:29.92	translation_Loss:14.966	token_training_loss:14.954	distillation_Loss:0.0                                                   	MRR:21.02	Hits@10:36.32	Best:21.55
2025-01-06 18:35:23,678: End of token training: 2 Epoch: 9 Loss:15.266 MRR:21.02 Best Results: 21.55
2025-01-06 18:35:23,679: Snapshot:2	Epoch:9	Loss:15.266	translation_Loss:14.968	token_training_loss:0.297	distillation_Loss:0.0                                                           	MRR:21.02	Hits@10:36.32	Best:21.55
2025-01-06 18:35:23,991: => loading checkpoint './checkpoint/RELATION/2model_best.tar'
2025-01-06 18:35:44,933: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106183529/RELATION', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=33, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATION', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[3000.0, 15000.0, 80000.0, 80000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:36:02,147: Snapshot:0	Epoch:0	Loss:24.103	translation_Loss:24.103	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:10.85	Hits@10:26.16	Best:10.85
2025-01-06 18:36:15,236: Snapshot:0	Epoch:1	Loss:14.893	translation_Loss:14.893	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:19.17	Hits@10:40.27	Best:19.17
2025-01-06 18:36:28,416: Snapshot:0	Epoch:2	Loss:8.557	translation_Loss:8.557	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.94	Hits@10:44.88	Best:23.94
2025-01-06 18:36:41,182: Snapshot:0	Epoch:3	Loss:4.752	translation_Loss:4.752	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.43	Hits@10:46.99	Best:26.43
2025-01-06 18:36:54,262: Snapshot:0	Epoch:4	Loss:2.752	translation_Loss:2.752	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.41	Hits@10:47.82	Best:27.41
2025-01-06 18:37:07,385: Snapshot:0	Epoch:5	Loss:1.815	translation_Loss:1.815	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.57	Hits@10:48.02	Best:27.57
2025-01-06 18:37:20,074: Snapshot:0	Epoch:6	Loss:1.342	translation_Loss:1.342	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.62	Hits@10:48.23	Best:27.62
2025-01-06 18:37:33,236: Snapshot:0	Epoch:7	Loss:1.095	translation_Loss:1.095	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.45	Hits@10:48.15	Best:27.62
2025-01-06 18:37:46,243: Snapshot:0	Epoch:8	Loss:0.949	translation_Loss:0.949	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.52	Hits@10:48.16	Best:27.62
2025-01-06 18:37:58,838: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 27.62
2025-01-06 18:37:58,839: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.844 MRR:27.58 Best Results: 27.62
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:37:58,839: Snapshot:0	Epoch:9	Loss:0.844	translation_Loss:0.844	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.58	Hits@10:48.2	Best:27.62
2025-01-06 18:38:12,387: Snapshot:0	Epoch:10	Loss:32.212	translation_Loss:16.511	token_training_loss:15.701	distillation_Loss:0.0                                                   	MRR:27.58	Hits@10:48.2	Best:27.62
2025-01-06 18:38:25,051: End of token training: 0 Epoch: 11 Loss:16.588 MRR:27.58 Best Results: 27.62
2025-01-06 18:38:25,051: Snapshot:0	Epoch:11	Loss:16.588	translation_Loss:16.499	token_training_loss:0.09	distillation_Loss:0.0                                                           	MRR:27.58	Hits@10:48.2	Best:27.62
2025-01-06 18:38:25,342: => loading checkpoint './checkpoint/RELATION/0model_best.tar'
2025-01-06 18:38:31,211: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2792 | 0.1671 | 0.346  | 0.4151 |  0.4849 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:38:51,819: Snapshot:1	Epoch:0	Loss:20.234	translation_Loss:18.998	token_training_loss:0.0	distillation_Loss:1.235                                                   	MRR:10.74	Hits@10:25.18	Best:10.74
2025-01-06 18:39:04,160: Snapshot:1	Epoch:1	Loss:10.515	translation_Loss:8.263	token_training_loss:0.0	distillation_Loss:2.252                                                   	MRR:16.3	Hits@10:32.57	Best:16.3
2025-01-06 18:39:16,299: Snapshot:1	Epoch:2	Loss:6.712	translation_Loss:4.279	token_training_loss:0.0	distillation_Loss:2.433                                                   	MRR:17.18	Hits@10:33.87	Best:17.18
2025-01-06 18:39:28,034: Snapshot:1	Epoch:3	Loss:5.352	translation_Loss:3.053	token_training_loss:0.0	distillation_Loss:2.299                                                   	MRR:17.16	Hits@10:33.62	Best:17.18
2025-01-06 18:39:40,164: Snapshot:1	Epoch:4	Loss:4.854	translation_Loss:2.681	token_training_loss:0.0	distillation_Loss:2.173                                                   	MRR:17.23	Hits@10:33.49	Best:17.23
2025-01-06 18:39:52,376: Snapshot:1	Epoch:5	Loss:4.653	translation_Loss:2.546	token_training_loss:0.0	distillation_Loss:2.107                                                   	MRR:17.24	Hits@10:33.53	Best:17.24
2025-01-06 18:40:04,105: Snapshot:1	Epoch:6	Loss:4.536	translation_Loss:2.469	token_training_loss:0.0	distillation_Loss:2.067                                                   	MRR:17.0	Hits@10:33.2	Best:17.24
2025-01-06 18:40:16,172: Snapshot:1	Epoch:7	Loss:4.475	translation_Loss:2.432	token_training_loss:0.0	distillation_Loss:2.043                                                   	MRR:16.9	Hits@10:33.08	Best:17.24
2025-01-06 18:40:27,891: Early Stopping! Snapshot: 1 Epoch: 8 Best Results: 17.24
2025-01-06 18:40:27,891: Start to training tokens! Snapshot: 1 Epoch: 8 Loss:4.42 MRR:16.95 Best Results: 17.24
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:40:27,892: Snapshot:1	Epoch:8	Loss:4.42	translation_Loss:2.397	token_training_loss:0.0	distillation_Loss:2.024                                                   	MRR:16.95	Hits@10:33.08	Best:17.24
2025-01-06 18:40:40,037: Snapshot:1	Epoch:9	Loss:35.766	translation_Loss:19.271	token_training_loss:16.495	distillation_Loss:0.0                                                   	MRR:16.95	Hits@10:33.08	Best:17.24
2025-01-06 18:40:51,969: End of token training: 1 Epoch: 10 Loss:19.381 MRR:16.95 Best Results: 17.24
2025-01-06 18:40:51,969: Snapshot:1	Epoch:10	Loss:19.381	translation_Loss:19.269	token_training_loss:0.112	distillation_Loss:0.0                                                           	MRR:16.95	Hits@10:33.08	Best:17.24
2025-01-06 18:40:52,334: => loading checkpoint './checkpoint/RELATION/1model_best.tar'
2025-01-06 18:41:02,730: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2464 | 0.1355 | 0.3062 | 0.3766 |  0.455  |
|     1      | 0.1728 | 0.0896 | 0.2039 | 0.2606 |  0.3339 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:41:19,326: Snapshot:2	Epoch:0	Loss:13.836	translation_Loss:12.016	token_training_loss:0.0	distillation_Loss:1.82                                                   	MRR:12.42	Hits@10:27.95	Best:12.42
2025-01-06 18:41:28,045: Snapshot:2	Epoch:1	Loss:7.818	translation_Loss:5.179	token_training_loss:0.0	distillation_Loss:2.639                                                   	MRR:18.53	Hits@10:35.76	Best:18.53
2025-01-06 18:41:37,185: Snapshot:2	Epoch:2	Loss:5.495	translation_Loss:3.499	token_training_loss:0.0	distillation_Loss:1.996                                                   	MRR:20.84	Hits@10:37.42	Best:20.84
2025-01-06 18:41:46,111: Snapshot:2	Epoch:3	Loss:4.322	translation_Loss:2.687	token_training_loss:0.0	distillation_Loss:1.634                                                   	MRR:21.49	Hits@10:37.55	Best:21.49
2025-01-06 18:41:55,245: Snapshot:2	Epoch:4	Loss:3.716	translation_Loss:2.321	token_training_loss:0.0	distillation_Loss:1.395                                                   	MRR:21.67	Hits@10:37.52	Best:21.67
2025-01-06 18:42:03,938: Snapshot:2	Epoch:5	Loss:3.407	translation_Loss:2.142	token_training_loss:0.0	distillation_Loss:1.265                                                   	MRR:21.57	Hits@10:37.33	Best:21.67
2025-01-06 18:42:12,524: Snapshot:2	Epoch:6	Loss:3.269	translation_Loss:2.076	token_training_loss:0.0	distillation_Loss:1.192                                                   	MRR:21.21	Hits@10:36.99	Best:21.67
2025-01-06 18:42:21,575: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 21.67
2025-01-06 18:42:21,575: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:3.198 MRR:21.36 Best Results: 21.67
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:42:21,575: Snapshot:2	Epoch:7	Loss:3.198	translation_Loss:2.038	token_training_loss:0.0	distillation_Loss:1.159                                                   	MRR:21.36	Hits@10:37.05	Best:21.67
2025-01-06 18:42:30,054: Snapshot:2	Epoch:8	Loss:29.091	translation_Loss:14.717	token_training_loss:14.374	distillation_Loss:0.0                                                   	MRR:21.36	Hits@10:37.05	Best:21.67
2025-01-06 18:42:38,944: End of token training: 2 Epoch: 9 Loss:14.997 MRR:21.36 Best Results: 21.67
2025-01-06 18:42:38,944: Snapshot:2	Epoch:9	Loss:14.997	translation_Loss:14.719	token_training_loss:0.278	distillation_Loss:0.0                                                           	MRR:21.36	Hits@10:37.05	Best:21.67
2025-01-06 18:42:39,246: => loading checkpoint './checkpoint/RELATION/2model_best.tar'
2025-01-06 18:42:53,911: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2147 | 0.1138 | 0.2704 | 0.3333 |  0.4034 |
|     1      | 0.1615 |  0.08  | 0.1915 | 0.2477 |  0.318  |
|     2      | 0.2139 | 0.1337 | 0.237  | 0.2963 |  0.3724 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:43:04,069: Snapshot:3	Epoch:0	Loss:6.725	translation_Loss:6.033	token_training_loss:0.0	distillation_Loss:0.692                                                   	MRR:6.73	Hits@10:16.24	Best:6.73
2025-01-06 18:43:08,508: Snapshot:3	Epoch:1	Loss:4.763	translation_Loss:4.073	token_training_loss:0.0	distillation_Loss:0.689                                                   	MRR:13.57	Hits@10:30.7	Best:13.57
2025-01-06 18:43:12,589: Snapshot:3	Epoch:2	Loss:3.494	translation_Loss:2.925	token_training_loss:0.0	distillation_Loss:0.569                                                   	MRR:16.72	Hits@10:34.29	Best:16.72
2025-01-06 18:43:16,676: Snapshot:3	Epoch:3	Loss:2.794	translation_Loss:2.31	token_training_loss:0.0	distillation_Loss:0.485                                                   	MRR:19.65	Hits@10:36.01	Best:19.65
2025-01-06 18:43:20,748: Snapshot:3	Epoch:4	Loss:2.388	translation_Loss:1.949	token_training_loss:0.0	distillation_Loss:0.439                                                   	MRR:21.79	Hits@10:37.82	Best:21.79
2025-01-06 18:43:24,795: Snapshot:3	Epoch:5	Loss:2.112	translation_Loss:1.711	token_training_loss:0.0	distillation_Loss:0.401                                                   	MRR:23.08	Hits@10:38.56	Best:23.08
2025-01-06 18:43:29,354: Snapshot:3	Epoch:6	Loss:1.905	translation_Loss:1.537	token_training_loss:0.0	distillation_Loss:0.368                                                   	MRR:23.78	Hits@10:38.85	Best:23.78
2025-01-06 18:43:33,362: Snapshot:3	Epoch:7	Loss:1.754	translation_Loss:1.411	token_training_loss:0.0	distillation_Loss:0.343                                                   	MRR:24.22	Hits@10:39.13	Best:24.22
2025-01-06 18:43:37,349: Snapshot:3	Epoch:8	Loss:1.642	translation_Loss:1.318	token_training_loss:0.0	distillation_Loss:0.323                                                   	MRR:24.55	Hits@10:39.08	Best:24.55
2025-01-06 18:43:41,384: Snapshot:3	Epoch:9	Loss:1.565	translation_Loss:1.254	token_training_loss:0.0	distillation_Loss:0.31                                                   	MRR:24.62	Hits@10:38.95	Best:24.62
2025-01-06 18:43:45,386: Snapshot:3	Epoch:10	Loss:1.504	translation_Loss:1.207	token_training_loss:0.0	distillation_Loss:0.297                                                   	MRR:24.87	Hits@10:39.19	Best:24.87
2025-01-06 18:43:49,848: Snapshot:3	Epoch:11	Loss:1.474	translation_Loss:1.185	token_training_loss:0.0	distillation_Loss:0.289                                                   	MRR:25.26	Hits@10:39.09	Best:25.26
2025-01-06 18:43:53,945: Snapshot:3	Epoch:12	Loss:1.446	translation_Loss:1.162	token_training_loss:0.0	distillation_Loss:0.283                                                   	MRR:25.34	Hits@10:39.38	Best:25.34
2025-01-06 18:43:58,160: Snapshot:3	Epoch:13	Loss:1.422	translation_Loss:1.139	token_training_loss:0.0	distillation_Loss:0.283                                                   	MRR:25.27	Hits@10:39.12	Best:25.34
2025-01-06 18:44:02,208: Snapshot:3	Epoch:14	Loss:1.401	translation_Loss:1.125	token_training_loss:0.0	distillation_Loss:0.276                                                   	MRR:25.4	Hits@10:39.07	Best:25.4
2025-01-06 18:44:06,371: Snapshot:3	Epoch:15	Loss:1.381	translation_Loss:1.106	token_training_loss:0.0	distillation_Loss:0.275                                                   	MRR:25.46	Hits@10:39.17	Best:25.46
2025-01-06 18:44:10,372: Snapshot:3	Epoch:16	Loss:1.374	translation_Loss:1.101	token_training_loss:0.0	distillation_Loss:0.273                                                   	MRR:25.49	Hits@10:39.27	Best:25.49
2025-01-06 18:44:14,724: Snapshot:3	Epoch:17	Loss:1.364	translation_Loss:1.094	token_training_loss:0.0	distillation_Loss:0.271                                                   	MRR:25.48	Hits@10:39.15	Best:25.49
2025-01-06 18:44:18,680: Snapshot:3	Epoch:18	Loss:1.355	translation_Loss:1.086	token_training_loss:0.0	distillation_Loss:0.269                                                   	MRR:25.44	Hits@10:39.25	Best:25.49
2025-01-06 18:44:22,685: Snapshot:3	Epoch:19	Loss:1.351	translation_Loss:1.082	token_training_loss:0.0	distillation_Loss:0.269                                                   	MRR:25.68	Hits@10:39.44	Best:25.68
2025-01-06 18:44:26,647: Snapshot:3	Epoch:20	Loss:1.34	translation_Loss:1.073	token_training_loss:0.0	distillation_Loss:0.267                                                   	MRR:25.56	Hits@10:39.5	Best:25.68
2025-01-06 18:44:30,648: Snapshot:3	Epoch:21	Loss:1.337	translation_Loss:1.071	token_training_loss:0.0	distillation_Loss:0.266                                                   	MRR:25.55	Hits@10:39.68	Best:25.68
2025-01-06 18:44:35,046: Early Stopping! Snapshot: 3 Epoch: 22 Best Results: 25.68
2025-01-06 18:44:35,046: Start to training tokens! Snapshot: 3 Epoch: 22 Loss:1.329 MRR:25.65 Best Results: 25.68
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:44:35,047: Snapshot:3	Epoch:22	Loss:1.329	translation_Loss:1.064	token_training_loss:0.0	distillation_Loss:0.265                                                   	MRR:25.65	Hits@10:39.67	Best:25.68
2025-01-06 18:44:38,947: Snapshot:3	Epoch:23	Loss:19.064	translation_Loss:5.812	token_training_loss:13.251	distillation_Loss:0.0                                                   	MRR:25.65	Hits@10:39.67	Best:25.68
2025-01-06 18:44:42,893: End of token training: 3 Epoch: 24 Loss:7.542 MRR:25.65 Best Results: 25.68
2025-01-06 18:44:42,893: Snapshot:3	Epoch:24	Loss:7.542	translation_Loss:5.798	token_training_loss:1.743	distillation_Loss:0.0                                                           	MRR:25.65	Hits@10:39.67	Best:25.68
2025-01-06 18:44:43,251: => loading checkpoint './checkpoint/RELATION/3model_best.tar'
2025-01-06 18:44:59,068: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.215  | 0.1138 | 0.2704 | 0.3331 |  0.405  |
|     1      | 0.1619 |  0.08  | 0.1914 | 0.2482 |  0.3191 |
|     2      | 0.208  | 0.1258 | 0.2326 | 0.2931 |  0.3726 |
|     3      | 0.2538 | 0.1789 | 0.2816 | 0.327  |  0.3925 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:45:07,954: Snapshot:4	Epoch:0	Loss:4.616	translation_Loss:4.094	token_training_loss:0.0	distillation_Loss:0.522                                                   	MRR:6.13	Hits@10:16.51	Best:6.13
2025-01-06 18:45:10,827: Snapshot:4	Epoch:1	Loss:3.503	translation_Loss:2.756	token_training_loss:0.0	distillation_Loss:0.748                                                   	MRR:10.67	Hits@10:26.58	Best:10.67
2025-01-06 18:45:13,688: Snapshot:4	Epoch:2	Loss:2.868	translation_Loss:2.129	token_training_loss:0.0	distillation_Loss:0.739                                                   	MRR:14.17	Hits@10:32.74	Best:14.17
2025-01-06 18:45:16,589: Snapshot:4	Epoch:3	Loss:2.405	translation_Loss:1.711	token_training_loss:0.0	distillation_Loss:0.694                                                   	MRR:17.66	Hits@10:36.77	Best:17.66
2025-01-06 18:45:19,489: Snapshot:4	Epoch:4	Loss:2.079	translation_Loss:1.444	token_training_loss:0.0	distillation_Loss:0.635                                                   	MRR:19.47	Hits@10:39.08	Best:19.47
2025-01-06 18:45:22,751: Snapshot:4	Epoch:5	Loss:1.845	translation_Loss:1.259	token_training_loss:0.0	distillation_Loss:0.587                                                   	MRR:20.75	Hits@10:40.06	Best:20.75
2025-01-06 18:45:25,692: Snapshot:4	Epoch:6	Loss:1.656	translation_Loss:1.109	token_training_loss:0.0	distillation_Loss:0.546                                                   	MRR:21.5	Hits@10:41.38	Best:21.5
2025-01-06 18:45:28,564: Snapshot:4	Epoch:7	Loss:1.51	translation_Loss:0.992	token_training_loss:0.0	distillation_Loss:0.518                                                   	MRR:22.16	Hits@10:41.87	Best:22.16
2025-01-06 18:45:31,516: Snapshot:4	Epoch:8	Loss:1.398	translation_Loss:0.91	token_training_loss:0.0	distillation_Loss:0.488                                                   	MRR:22.88	Hits@10:42.43	Best:22.88
2025-01-06 18:45:34,426: Snapshot:4	Epoch:9	Loss:1.314	translation_Loss:0.847	token_training_loss:0.0	distillation_Loss:0.467                                                   	MRR:23.09	Hits@10:42.21	Best:23.09
2025-01-06 18:45:37,290: Snapshot:4	Epoch:10	Loss:1.238	translation_Loss:0.791	token_training_loss:0.0	distillation_Loss:0.448                                                   	MRR:23.02	Hits@10:42.65	Best:23.09
2025-01-06 18:45:40,116: Snapshot:4	Epoch:11	Loss:1.191	translation_Loss:0.754	token_training_loss:0.0	distillation_Loss:0.436                                                   	MRR:22.97	Hits@10:42.53	Best:23.09
2025-01-06 18:45:43,387: Snapshot:4	Epoch:12	Loss:1.154	translation_Loss:0.728	token_training_loss:0.0	distillation_Loss:0.426                                                   	MRR:23.14	Hits@10:42.56	Best:23.14
2025-01-06 18:45:46,191: Snapshot:4	Epoch:13	Loss:1.127	translation_Loss:0.71	token_training_loss:0.0	distillation_Loss:0.418                                                   	MRR:22.99	Hits@10:42.19	Best:23.14
2025-01-06 18:45:49,090: Snapshot:4	Epoch:14	Loss:1.099	translation_Loss:0.689	token_training_loss:0.0	distillation_Loss:0.41                                                   	MRR:23.24	Hits@10:41.92	Best:23.24
2025-01-06 18:45:52,004: Snapshot:4	Epoch:15	Loss:1.083	translation_Loss:0.678	token_training_loss:0.0	distillation_Loss:0.405                                                   	MRR:23.12	Hits@10:42.08	Best:23.24
2025-01-06 18:45:54,865: Snapshot:4	Epoch:16	Loss:1.074	translation_Loss:0.673	token_training_loss:0.0	distillation_Loss:0.4                                                   	MRR:22.99	Hits@10:42.23	Best:23.24
2025-01-06 18:45:57,723: Early Stopping! Snapshot: 4 Epoch: 17 Best Results: 23.24
2025-01-06 18:45:57,723: Start to training tokens! Snapshot: 4 Epoch: 17 Loss:1.063 MRR:22.83 Best Results: 23.24
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:45:57,723: Snapshot:4	Epoch:17	Loss:1.063	translation_Loss:0.666	token_training_loss:0.0	distillation_Loss:0.397                                                   	MRR:22.83	Hits@10:42.1	Best:23.24
2025-01-06 18:46:00,485: Snapshot:4	Epoch:18	Loss:16.001	translation_Loss:3.98	token_training_loss:12.022	distillation_Loss:0.0                                                   	MRR:22.83	Hits@10:42.1	Best:23.24
2025-01-06 18:46:03,692: End of token training: 4 Epoch: 19 Loss:6.83 MRR:22.83 Best Results: 23.24
2025-01-06 18:46:03,692: Snapshot:4	Epoch:19	Loss:6.83	translation_Loss:3.99	token_training_loss:2.84	distillation_Loss:0.0                                                           	MRR:22.83	Hits@10:42.1	Best:23.24
2025-01-06 18:46:03,991: => loading checkpoint './checkpoint/RELATION/4model_best.tar'
2025-01-06 18:46:21,308: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.214  | 0.1137 | 0.2697 | 0.3311 |  0.4023 |
|     1      | 0.1614 | 0.0798 | 0.1913 | 0.2472 |  0.3181 |
|     2      | 0.2005 | 0.1201 | 0.2214 | 0.2818 |  0.3629 |
|     3      | 0.2498 | 0.1728 | 0.2755 | 0.3249 |  0.3958 |
|     4      | 0.2257 | 0.1312 | 0.248  | 0.3182 |  0.4156 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 18:46:21,310: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2792 | 0.1671 | 0.346  | 0.4151 |  0.4849 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2464 | 0.1355 | 0.3062 | 0.3766 |  0.455  |
|     1      | 0.1728 | 0.0896 | 0.2039 | 0.2606 |  0.3339 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2147 | 0.1138 | 0.2704 | 0.3333 |  0.4034 |
|     1      | 0.1615 |  0.08  | 0.1915 | 0.2477 |  0.318  |
|     2      | 0.2139 | 0.1337 | 0.237  | 0.2963 |  0.3724 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.215  | 0.1138 | 0.2704 | 0.3331 |  0.405  |
|     1      | 0.1619 |  0.08  | 0.1914 | 0.2482 |  0.3191 |
|     2      | 0.208  | 0.1258 | 0.2326 | 0.2931 |  0.3726 |
|     3      | 0.2538 | 0.1789 | 0.2816 | 0.327  |  0.3925 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.214  | 0.1137 | 0.2697 | 0.3311 |  0.4023 |
|     1      | 0.1614 | 0.0798 | 0.1913 | 0.2472 |  0.3181 |
|     2      | 0.2005 | 0.1201 | 0.2214 | 0.2818 |  0.3629 |
|     3      | 0.2498 | 0.1728 | 0.2755 | 0.3249 |  0.3958 |
|     4      | 0.2257 | 0.1312 | 0.248  | 0.3182 |  0.4156 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 18:46:21,311: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 160.11772441864014 |   0.279   |    0.167     |    0.346     |     0.485     |
|    1     | 136.11192846298218 |   0.211   |    0.113     |    0.256     |     0.396     |
|    2     | 92.46597027778625  |   0.195   |    0.107     |    0.233     |     0.365     |
|    3     | 106.96155500411987 |    0.2    |    0.112     |    0.237     |     0.368     |
|    4     | 62.79177951812744  |    0.2    |    0.112     |    0.235     |     0.369     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 18:46:21,311: Sum_Training_Time:558.4489576816559
2025-01-06 18:46:21,311: Every_Training_Time:[160.11772441864014, 136.11192846298218, 92.46597027778625, 106.96155500411987, 62.79177951812744]
2025-01-06 18:46:21,311: Forward transfer: 0.015725 Backward transfer: -0.023500000000000014
2025-01-06 18:46:42,318: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106184626/RELATION', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=44, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATION', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[3000.0, 15000.0, 80000.0, 80000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:46:59,454: Snapshot:0	Epoch:0	Loss:24.181	translation_Loss:24.181	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:10.92	Hits@10:26.82	Best:10.92
2025-01-06 18:47:12,618: Snapshot:0	Epoch:1	Loss:14.97	translation_Loss:14.97	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.55	Hits@10:40.41	Best:18.55
2025-01-06 18:47:25,747: Snapshot:0	Epoch:2	Loss:8.544	translation_Loss:8.544	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.48	Hits@10:44.94	Best:23.48
2025-01-06 18:47:38,326: Snapshot:0	Epoch:3	Loss:4.721	translation_Loss:4.721	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.78	Hits@10:46.58	Best:25.78
2025-01-06 18:47:51,419: Snapshot:0	Epoch:4	Loss:2.74	translation_Loss:2.74	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.0	Hits@10:47.54	Best:27.0
2025-01-06 18:48:04,465: Snapshot:0	Epoch:5	Loss:1.807	translation_Loss:1.807	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.38	Hits@10:47.93	Best:27.38
2025-01-06 18:48:17,033: Snapshot:0	Epoch:6	Loss:1.357	translation_Loss:1.357	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.48	Hits@10:47.97	Best:27.48
2025-01-06 18:48:30,259: Snapshot:0	Epoch:7	Loss:1.106	translation_Loss:1.106	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.42	Hits@10:47.98	Best:27.48
2025-01-06 18:48:43,226: Snapshot:0	Epoch:8	Loss:0.943	translation_Loss:0.943	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.47	Hits@10:47.89	Best:27.48
2025-01-06 18:48:55,833: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 27.48
2025-01-06 18:48:55,833: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:0.849 MRR:27.34 Best Results: 27.48
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:48:55,833: Snapshot:0	Epoch:9	Loss:0.849	translation_Loss:0.849	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:27.34	Hits@10:47.75	Best:27.48
2025-01-06 18:49:09,473: Snapshot:0	Epoch:10	Loss:32.942	translation_Loss:16.406	token_training_loss:16.536	distillation_Loss:0.0                                                   	MRR:27.34	Hits@10:47.75	Best:27.48
2025-01-06 18:49:22,139: End of token training: 0 Epoch: 11 Loss:16.486 MRR:27.34 Best Results: 27.48
2025-01-06 18:49:22,139: Snapshot:0	Epoch:11	Loss:16.486	translation_Loss:16.392	token_training_loss:0.094	distillation_Loss:0.0                                                           	MRR:27.34	Hits@10:47.75	Best:27.48
2025-01-06 18:49:22,426: => loading checkpoint './checkpoint/RELATION/0model_best.tar'
2025-01-06 18:49:28,270: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2771 | 0.1669 | 0.3408 | 0.4101 |  0.4828 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:49:48,821: Snapshot:1	Epoch:0	Loss:20.11	translation_Loss:18.869	token_training_loss:0.0	distillation_Loss:1.241                                                   	MRR:10.53	Hits@10:25.4	Best:10.53
2025-01-06 18:50:01,002: Snapshot:1	Epoch:1	Loss:10.327	translation_Loss:8.069	token_training_loss:0.0	distillation_Loss:2.258                                                   	MRR:16.25	Hits@10:32.69	Best:16.25
2025-01-06 18:50:13,203: Snapshot:1	Epoch:2	Loss:6.649	translation_Loss:4.205	token_training_loss:0.0	distillation_Loss:2.444                                                   	MRR:17.27	Hits@10:33.79	Best:17.27
2025-01-06 18:50:25,033: Snapshot:1	Epoch:3	Loss:5.366	translation_Loss:3.051	token_training_loss:0.0	distillation_Loss:2.316                                                   	MRR:17.31	Hits@10:33.74	Best:17.31
2025-01-06 18:50:37,156: Snapshot:1	Epoch:4	Loss:4.871	translation_Loss:2.688	token_training_loss:0.0	distillation_Loss:2.183                                                   	MRR:17.32	Hits@10:33.4	Best:17.32
2025-01-06 18:50:49,404: Snapshot:1	Epoch:5	Loss:4.664	translation_Loss:2.543	token_training_loss:0.0	distillation_Loss:2.121                                                   	MRR:17.3	Hits@10:33.33	Best:17.32
2025-01-06 18:51:01,146: Snapshot:1	Epoch:6	Loss:4.553	translation_Loss:2.476	token_training_loss:0.0	distillation_Loss:2.077                                                   	MRR:17.05	Hits@10:33.25	Best:17.32
2025-01-06 18:51:13,320: Early Stopping! Snapshot: 1 Epoch: 7 Best Results: 17.32
2025-01-06 18:51:13,320: Start to training tokens! Snapshot: 1 Epoch: 7 Loss:4.488 MRR:17.17 Best Results: 17.32
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:51:13,320: Snapshot:1	Epoch:7	Loss:4.488	translation_Loss:2.435	token_training_loss:0.0	distillation_Loss:2.053                                                   	MRR:17.17	Hits@10:33.42	Best:17.32
2025-01-06 18:51:24,892: Snapshot:1	Epoch:8	Loss:34.741	translation_Loss:19.494	token_training_loss:15.246	distillation_Loss:0.0                                                   	MRR:17.17	Hits@10:33.42	Best:17.32
2025-01-06 18:51:36,782: End of token training: 1 Epoch: 9 Loss:19.586 MRR:17.17 Best Results: 17.32
2025-01-06 18:51:36,782: Snapshot:1	Epoch:9	Loss:19.586	translation_Loss:19.481	token_training_loss:0.106	distillation_Loss:0.0                                                           	MRR:17.17	Hits@10:33.42	Best:17.32
2025-01-06 18:51:37,071: => loading checkpoint './checkpoint/RELATION/1model_best.tar'
2025-01-06 18:51:47,641: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2464 | 0.1372 | 0.3083 | 0.3757 |  0.4476 |
|     1      | 0.1727 | 0.0896 | 0.2055 | 0.2591 |  0.3321 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:52:04,515: Snapshot:2	Epoch:0	Loss:13.845	translation_Loss:12.031	token_training_loss:0.0	distillation_Loss:1.815                                                   	MRR:11.7	Hits@10:26.8	Best:11.7
2025-01-06 18:52:13,126: Snapshot:2	Epoch:1	Loss:7.812	translation_Loss:5.207	token_training_loss:0.0	distillation_Loss:2.605                                                   	MRR:18.88	Hits@10:36.04	Best:18.88
2025-01-06 18:52:22,200: Snapshot:2	Epoch:2	Loss:5.469	translation_Loss:3.477	token_training_loss:0.0	distillation_Loss:1.992                                                   	MRR:20.29	Hits@10:37.25	Best:20.29
2025-01-06 18:52:30,906: Snapshot:2	Epoch:3	Loss:4.304	translation_Loss:2.677	token_training_loss:0.0	distillation_Loss:1.628                                                   	MRR:21.05	Hits@10:37.58	Best:21.05
2025-01-06 18:52:40,014: Snapshot:2	Epoch:4	Loss:3.696	translation_Loss:2.307	token_training_loss:0.0	distillation_Loss:1.39                                                   	MRR:21.64	Hits@10:37.51	Best:21.64
2025-01-06 18:52:48,618: Snapshot:2	Epoch:5	Loss:3.395	translation_Loss:2.152	token_training_loss:0.0	distillation_Loss:1.243                                                   	MRR:21.64	Hits@10:37.59	Best:21.64
2025-01-06 18:52:57,721: Snapshot:2	Epoch:6	Loss:3.244	translation_Loss:2.073	token_training_loss:0.0	distillation_Loss:1.171                                                   	MRR:21.63	Hits@10:37.18	Best:21.64
2025-01-06 18:53:06,303: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 21.64
2025-01-06 18:53:06,303: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:3.177 MRR:21.44 Best Results: 21.64
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:53:06,303: Snapshot:2	Epoch:7	Loss:3.177	translation_Loss:2.04	token_training_loss:0.0	distillation_Loss:1.137                                                   	MRR:21.44	Hits@10:37.16	Best:21.64
2025-01-06 18:53:14,737: Snapshot:2	Epoch:8	Loss:29.581	translation_Loss:14.931	token_training_loss:14.65	distillation_Loss:0.0                                                   	MRR:21.44	Hits@10:37.16	Best:21.64
2025-01-06 18:53:23,608: End of token training: 2 Epoch: 9 Loss:15.228 MRR:21.44 Best Results: 21.64
2025-01-06 18:53:23,608: Snapshot:2	Epoch:9	Loss:15.228	translation_Loss:14.94	token_training_loss:0.288	distillation_Loss:0.0                                                           	MRR:21.44	Hits@10:37.16	Best:21.64
2025-01-06 18:53:23,901: => loading checkpoint './checkpoint/RELATION/2model_best.tar'
2025-01-06 18:53:38,251: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2146 | 0.1146 | 0.2709 | 0.3331 |  0.3991 |
|     1      | 0.1604 | 0.0787 | 0.1902 | 0.2445 |  0.3184 |
|     2      | 0.2138 | 0.1334 | 0.239  | 0.2925 |  0.372  |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:53:48,787: Snapshot:3	Epoch:0	Loss:6.851	translation_Loss:6.153	token_training_loss:0.0	distillation_Loss:0.698                                                   	MRR:6.01	Hits@10:13.96	Best:6.01
2025-01-06 18:53:52,835: Snapshot:3	Epoch:1	Loss:4.915	translation_Loss:4.196	token_training_loss:0.0	distillation_Loss:0.719                                                   	MRR:13.37	Hits@10:29.27	Best:13.37
2025-01-06 18:53:56,982: Snapshot:3	Epoch:2	Loss:3.634	translation_Loss:3.024	token_training_loss:0.0	distillation_Loss:0.609                                                   	MRR:16.98	Hits@10:34.61	Best:16.98
2025-01-06 18:54:01,018: Snapshot:3	Epoch:3	Loss:2.894	translation_Loss:2.373	token_training_loss:0.0	distillation_Loss:0.521                                                   	MRR:20.36	Hits@10:36.87	Best:20.36
2025-01-06 18:54:05,091: Snapshot:3	Epoch:4	Loss:2.466	translation_Loss:1.994	token_training_loss:0.0	distillation_Loss:0.472                                                   	MRR:22.17	Hits@10:37.73	Best:22.17
2025-01-06 18:54:09,169: Snapshot:3	Epoch:5	Loss:2.171	translation_Loss:1.744	token_training_loss:0.0	distillation_Loss:0.428                                                   	MRR:23.53	Hits@10:38.58	Best:23.53
2025-01-06 18:54:13,683: Snapshot:3	Epoch:6	Loss:1.955	translation_Loss:1.567	token_training_loss:0.0	distillation_Loss:0.388                                                   	MRR:24.27	Hits@10:38.86	Best:24.27
2025-01-06 18:54:17,709: Snapshot:3	Epoch:7	Loss:1.801	translation_Loss:1.442	token_training_loss:0.0	distillation_Loss:0.359                                                   	MRR:24.59	Hits@10:39.06	Best:24.59
2025-01-06 18:54:21,712: Snapshot:3	Epoch:8	Loss:1.688	translation_Loss:1.352	token_training_loss:0.0	distillation_Loss:0.336                                                   	MRR:24.9	Hits@10:38.98	Best:24.9
2025-01-06 18:54:25,737: Snapshot:3	Epoch:9	Loss:1.608	translation_Loss:1.289	token_training_loss:0.0	distillation_Loss:0.319                                                   	MRR:25.16	Hits@10:39.23	Best:25.16
2025-01-06 18:54:29,796: Snapshot:3	Epoch:10	Loss:1.541	translation_Loss:1.236	token_training_loss:0.0	distillation_Loss:0.306                                                   	MRR:25.18	Hits@10:39.27	Best:25.18
2025-01-06 18:54:34,169: Snapshot:3	Epoch:11	Loss:1.501	translation_Loss:1.204	token_training_loss:0.0	distillation_Loss:0.297                                                   	MRR:25.37	Hits@10:39.43	Best:25.37
2025-01-06 18:54:38,229: Snapshot:3	Epoch:12	Loss:1.469	translation_Loss:1.179	token_training_loss:0.0	distillation_Loss:0.29                                                   	MRR:25.57	Hits@10:39.63	Best:25.57
2025-01-06 18:54:42,366: Snapshot:3	Epoch:13	Loss:1.45	translation_Loss:1.164	token_training_loss:0.0	distillation_Loss:0.286                                                   	MRR:25.61	Hits@10:39.73	Best:25.61
2025-01-06 18:54:46,488: Snapshot:3	Epoch:14	Loss:1.429	translation_Loss:1.146	token_training_loss:0.0	distillation_Loss:0.282                                                   	MRR:25.76	Hits@10:39.6	Best:25.76
2025-01-06 18:54:50,593: Snapshot:3	Epoch:15	Loss:1.403	translation_Loss:1.126	token_training_loss:0.0	distillation_Loss:0.277                                                   	MRR:25.76	Hits@10:39.35	Best:25.76
2025-01-06 18:54:55,049: Snapshot:3	Epoch:16	Loss:1.395	translation_Loss:1.118	token_training_loss:0.0	distillation_Loss:0.278                                                   	MRR:25.75	Hits@10:39.44	Best:25.76
2025-01-06 18:54:59,136: Snapshot:3	Epoch:17	Loss:1.395	translation_Loss:1.117	token_training_loss:0.0	distillation_Loss:0.277                                                   	MRR:25.85	Hits@10:39.45	Best:25.85
2025-01-06 18:55:03,140: Snapshot:3	Epoch:18	Loss:1.382	translation_Loss:1.107	token_training_loss:0.0	distillation_Loss:0.275                                                   	MRR:25.9	Hits@10:39.45	Best:25.9
2025-01-06 18:55:07,168: Snapshot:3	Epoch:19	Loss:1.37	translation_Loss:1.096	token_training_loss:0.0	distillation_Loss:0.274                                                   	MRR:25.96	Hits@10:39.63	Best:25.96
2025-01-06 18:55:11,190: Snapshot:3	Epoch:20	Loss:1.36	translation_Loss:1.088	token_training_loss:0.0	distillation_Loss:0.272                                                   	MRR:25.99	Hits@10:39.57	Best:25.99
2025-01-06 18:55:15,629: Snapshot:3	Epoch:21	Loss:1.358	translation_Loss:1.089	token_training_loss:0.0	distillation_Loss:0.27                                                   	MRR:26.09	Hits@10:39.64	Best:26.09
2025-01-06 18:55:19,659: Snapshot:3	Epoch:22	Loss:1.348	translation_Loss:1.079	token_training_loss:0.0	distillation_Loss:0.269                                                   	MRR:26.11	Hits@10:39.59	Best:26.11
2025-01-06 18:55:23,701: Snapshot:3	Epoch:23	Loss:1.355	translation_Loss:1.084	token_training_loss:0.0	distillation_Loss:0.271                                                   	MRR:25.91	Hits@10:39.73	Best:26.11
2025-01-06 18:55:27,698: Snapshot:3	Epoch:24	Loss:1.34	translation_Loss:1.071	token_training_loss:0.0	distillation_Loss:0.269                                                   	MRR:26.08	Hits@10:39.6	Best:26.11
2025-01-06 18:55:31,628: Early Stopping! Snapshot: 3 Epoch: 25 Best Results: 26.11
2025-01-06 18:55:31,628: Start to training tokens! Snapshot: 3 Epoch: 25 Loss:1.344 MRR:25.86 Best Results: 26.11
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:55:31,628: Snapshot:3	Epoch:25	Loss:1.344	translation_Loss:1.075	token_training_loss:0.0	distillation_Loss:0.269                                                   	MRR:25.86	Hits@10:39.5	Best:26.11
2025-01-06 18:55:35,998: Snapshot:3	Epoch:26	Loss:18.965	translation_Loss:5.902	token_training_loss:13.063	distillation_Loss:0.0                                                   	MRR:25.86	Hits@10:39.5	Best:26.11
2025-01-06 18:55:39,876: End of token training: 3 Epoch: 27 Loss:7.49 MRR:25.86 Best Results: 26.11
2025-01-06 18:55:39,877: Snapshot:3	Epoch:27	Loss:7.49	translation_Loss:5.901	token_training_loss:1.588	distillation_Loss:0.0                                                           	MRR:25.86	Hits@10:39.5	Best:26.11
2025-01-06 18:55:40,171: => loading checkpoint './checkpoint/RELATION/3model_best.tar'
2025-01-06 18:55:56,035: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2151 | 0.1155 | 0.2708 | 0.3331 |  0.3996 |
|     1      | 0.1606 | 0.0785 | 0.191  | 0.244  |  0.3193 |
|     2      | 0.208  | 0.1258 | 0.2338 |  0.29  |  0.3712 |
|     3      | 0.2564 | 0.181  | 0.2869 | 0.3314 |  0.3893 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:56:04,664: Snapshot:4	Epoch:0	Loss:4.598	translation_Loss:4.079	token_training_loss:0.0	distillation_Loss:0.518                                                   	MRR:5.89	Hits@10:16.21	Best:5.89
2025-01-06 18:56:07,570: Snapshot:4	Epoch:1	Loss:3.482	translation_Loss:2.74	token_training_loss:0.0	distillation_Loss:0.742                                                   	MRR:10.56	Hits@10:27.08	Best:10.56
2025-01-06 18:56:10,537: Snapshot:4	Epoch:2	Loss:2.864	translation_Loss:2.123	token_training_loss:0.0	distillation_Loss:0.741                                                   	MRR:14.28	Hits@10:33.87	Best:14.28
2025-01-06 18:56:13,422: Snapshot:4	Epoch:3	Loss:2.397	translation_Loss:1.71	token_training_loss:0.0	distillation_Loss:0.687                                                   	MRR:17.15	Hits@10:36.41	Best:17.15
2025-01-06 18:56:16,656: Snapshot:4	Epoch:4	Loss:2.075	translation_Loss:1.446	token_training_loss:0.0	distillation_Loss:0.629                                                   	MRR:19.27	Hits@10:38.13	Best:19.27
2025-01-06 18:56:19,503: Snapshot:4	Epoch:5	Loss:1.844	translation_Loss:1.258	token_training_loss:0.0	distillation_Loss:0.586                                                   	MRR:20.68	Hits@10:39.73	Best:20.68
2025-01-06 18:56:22,432: Snapshot:4	Epoch:6	Loss:1.664	translation_Loss:1.117	token_training_loss:0.0	distillation_Loss:0.547                                                   	MRR:21.59	Hits@10:40.75	Best:21.59
2025-01-06 18:56:25,332: Snapshot:4	Epoch:7	Loss:1.519	translation_Loss:1.002	token_training_loss:0.0	distillation_Loss:0.517                                                   	MRR:22.3	Hits@10:41.22	Best:22.3
2025-01-06 18:56:28,244: Snapshot:4	Epoch:8	Loss:1.405	translation_Loss:0.916	token_training_loss:0.0	distillation_Loss:0.489                                                   	MRR:22.57	Hits@10:41.79	Best:22.57
2025-01-06 18:56:31,060: Snapshot:4	Epoch:9	Loss:1.322	translation_Loss:0.856	token_training_loss:0.0	distillation_Loss:0.467                                                   	MRR:22.56	Hits@10:42.37	Best:22.57
2025-01-06 18:56:33,859: Snapshot:4	Epoch:10	Loss:1.255	translation_Loss:0.803	token_training_loss:0.0	distillation_Loss:0.452                                                   	MRR:22.46	Hits@10:42.17	Best:22.57
2025-01-06 18:56:37,190: Snapshot:4	Epoch:11	Loss:1.204	translation_Loss:0.764	token_training_loss:0.0	distillation_Loss:0.439                                                   	MRR:22.65	Hits@10:42.2	Best:22.65
2025-01-06 18:56:40,068: Snapshot:4	Epoch:12	Loss:1.166	translation_Loss:0.738	token_training_loss:0.0	distillation_Loss:0.428                                                   	MRR:22.63	Hits@10:42.26	Best:22.65
2025-01-06 18:56:42,886: Snapshot:4	Epoch:13	Loss:1.137	translation_Loss:0.718	token_training_loss:0.0	distillation_Loss:0.419                                                   	MRR:22.65	Hits@10:42.59	Best:22.65
2025-01-06 18:56:45,728: Early Stopping! Snapshot: 4 Epoch: 14 Best Results: 22.65
2025-01-06 18:56:45,728: Start to training tokens! Snapshot: 4 Epoch: 14 Loss:1.118 MRR:22.48 Best Results: 22.65
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:56:45,728: Snapshot:4	Epoch:14	Loss:1.118	translation_Loss:0.707	token_training_loss:0.0	distillation_Loss:0.411                                                   	MRR:22.48	Hits@10:42.53	Best:22.65
2025-01-06 18:56:48,498: Snapshot:4	Epoch:15	Loss:15.943	translation_Loss:4.027	token_training_loss:11.916	distillation_Loss:0.0                                                   	MRR:22.48	Hits@10:42.53	Best:22.65
2025-01-06 18:56:51,259: End of token training: 4 Epoch: 16 Loss:6.807 MRR:22.48 Best Results: 22.65
2025-01-06 18:56:51,259: Snapshot:4	Epoch:16	Loss:6.807	translation_Loss:4.027	token_training_loss:2.78	distillation_Loss:0.0                                                           	MRR:22.48	Hits@10:42.53	Best:22.65
2025-01-06 18:56:51,580: => loading checkpoint './checkpoint/RELATION/4model_best.tar'
2025-01-06 18:57:09,207: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.213  | 0.1132 | 0.2683 | 0.3311 |  0.3978 |
|     1      | 0.1599 | 0.0779 | 0.1899 | 0.2438 |  0.3181 |
|     2      | 0.1992 | 0.1213 | 0.2212 | 0.274  |  0.353  |
|     3      | 0.2497 | 0.173  | 0.2753 | 0.324  |  0.3921 |
|     4      | 0.2252 | 0.1297 | 0.2473 | 0.3206 |  0.423  |
+------------+--------+--------+--------+--------+---------+
2025-01-06 18:57:09,209: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2771 | 0.1669 | 0.3408 | 0.4101 |  0.4828 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2464 | 0.1372 | 0.3083 | 0.3757 |  0.4476 |
|     1      | 0.1727 | 0.0896 | 0.2055 | 0.2591 |  0.3321 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2146 | 0.1146 | 0.2709 | 0.3331 |  0.3991 |
|     1      | 0.1604 | 0.0787 | 0.1902 | 0.2445 |  0.3184 |
|     2      | 0.2138 | 0.1334 | 0.239  | 0.2925 |  0.372  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2151 | 0.1155 | 0.2708 | 0.3331 |  0.3996 |
|     1      | 0.1606 | 0.0785 | 0.191  | 0.244  |  0.3193 |
|     2      | 0.208  | 0.1258 | 0.2338 |  0.29  |  0.3712 |
|     3      | 0.2564 | 0.181  | 0.2869 | 0.3314 |  0.3893 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.213  | 0.1132 | 0.2683 | 0.3311 |  0.3978 |
|     1      | 0.1599 | 0.0779 | 0.1899 | 0.2438 |  0.3181 |
|     2      | 0.1992 | 0.1213 | 0.2212 | 0.274  |  0.353  |
|     3      | 0.2497 | 0.173  | 0.2753 | 0.324  |  0.3921 |
|     4      | 0.2252 | 0.1297 | 0.2473 | 0.3206 |  0.423  |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 18:57:09,210: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 159.82006978988647 |   0.277   |    0.167     |    0.341     |     0.483     |
|    1     | 123.87949323654175 |   0.211   |    0.114     |    0.258     |     0.391     |
|    2     | 92.24971294403076  |   0.195   |    0.106     |    0.234     |     0.363     |
|    3     | 119.61842703819275 |    0.2    |    0.113     |    0.238     |     0.366     |
|    4     | 53.66348886489868  |   0.198   |    0.111     |    0.234     |     0.365     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 18:57:09,210: Sum_Training_Time:549.2311918735504
2025-01-06 18:57:09,210: Every_Training_Time:[159.82006978988647, 123.87949323654175, 92.24971294403076, 119.61842703819275, 53.66348886489868]
2025-01-06 18:57:09,210: Forward transfer: 0.015775 Backward transfer: -0.02455000000000001
