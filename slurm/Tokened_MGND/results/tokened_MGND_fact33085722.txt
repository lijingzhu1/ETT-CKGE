2025-01-06 22:00:42,592: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106220021/FACT', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=1111, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[1000.0, 10000.0, 10000.0, 10000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 22:00:53,435: Snapshot:0	Epoch:0	Loss:17.018	translation_Loss:17.018	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.36	Hits@10:13.57	Best:6.36
2025-01-06 22:01:01,088: Snapshot:0	Epoch:1	Loss:11.931	translation_Loss:11.931	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:9.86	Hits@10:23.24	Best:9.86
2025-01-06 22:01:08,386: Snapshot:0	Epoch:2	Loss:8.593	translation_Loss:8.593	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:13.06	Hits@10:29.27	Best:13.06
2025-01-06 22:01:16,154: Snapshot:0	Epoch:3	Loss:6.15	translation_Loss:6.15	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.83	Hits@10:33.32	Best:15.83
2025-01-06 22:01:23,337: Snapshot:0	Epoch:4	Loss:4.359	translation_Loss:4.359	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.34	Hits@10:36.07	Best:18.34
2025-01-06 22:01:30,528: Snapshot:0	Epoch:5	Loss:3.101	translation_Loss:3.101	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:20.39	Hits@10:37.81	Best:20.39
2025-01-06 22:01:38,098: Snapshot:0	Epoch:6	Loss:2.206	translation_Loss:2.206	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:21.88	Hits@10:38.91	Best:21.88
2025-01-06 22:01:45,312: Snapshot:0	Epoch:7	Loss:1.563	translation_Loss:1.563	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.01	Hits@10:39.39	Best:23.01
2025-01-06 22:01:52,868: Snapshot:0	Epoch:8	Loss:1.123	translation_Loss:1.123	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.59	Hits@10:39.77	Best:23.59
2025-01-06 22:02:00,058: Snapshot:0	Epoch:9	Loss:0.839	translation_Loss:0.839	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.1	Hits@10:40.0	Best:24.1
2025-01-06 22:02:07,298: Snapshot:0	Epoch:10	Loss:0.643	translation_Loss:0.643	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.36	Hits@10:40.09	Best:24.36
2025-01-06 22:02:14,973: Snapshot:0	Epoch:11	Loss:0.52	translation_Loss:0.52	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.52	Hits@10:40.17	Best:24.52
2025-01-06 22:02:22,145: Snapshot:0	Epoch:12	Loss:0.424	translation_Loss:0.424	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.55	Hits@10:40.18	Best:24.55
2025-01-06 22:02:29,697: Snapshot:0	Epoch:13	Loss:0.36	translation_Loss:0.36	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.67	Hits@10:40.33	Best:24.67
2025-01-06 22:02:36,910: Snapshot:0	Epoch:14	Loss:0.317	translation_Loss:0.317	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.75	Hits@10:40.37	Best:24.75
2025-01-06 22:02:44,079: Snapshot:0	Epoch:15	Loss:0.279	translation_Loss:0.279	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.77	Hits@10:40.33	Best:24.77
2025-01-06 22:02:51,650: Snapshot:0	Epoch:16	Loss:0.254	translation_Loss:0.254	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.79	Hits@10:40.24	Best:24.79
2025-01-06 22:02:58,807: Snapshot:0	Epoch:17	Loss:0.229	translation_Loss:0.229	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.78	Hits@10:40.15	Best:24.79
2025-01-06 22:03:06,397: Snapshot:0	Epoch:18	Loss:0.209	translation_Loss:0.209	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.73	Hits@10:40.08	Best:24.79
2025-01-06 22:03:13,541: Early Stopping! Snapshot: 0 Epoch: 19 Best Results: 24.79
2025-01-06 22:03:13,541: Start to training tokens! Snapshot: 0 Epoch: 19 Loss:0.196 MRR:24.76 Best Results: 24.79
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:03:13,541: Snapshot:0	Epoch:19	Loss:0.196	translation_Loss:0.196	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.76	Hits@10:40.27	Best:24.79
2025-01-06 22:03:21,261: Snapshot:0	Epoch:20	Loss:28.243	translation_Loss:12.295	token_training_loss:15.948	distillation_Loss:0.0                                                   	MRR:24.76	Hits@10:40.27	Best:24.79
2025-01-06 22:03:28,902: End of token training: 0 Epoch: 21 Loss:12.654 MRR:24.76 Best Results: 24.79
2025-01-06 22:03:28,902: Snapshot:0	Epoch:21	Loss:12.654	translation_Loss:12.3	token_training_loss:0.354	distillation_Loss:0.0                                                           	MRR:24.76	Hits@10:40.27	Best:24.79
2025-01-06 22:03:29,166: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2025-01-06 22:03:32,252: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2401 | 0.1559 | 0.2806 | 0.3293 |  0.392  |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:03:47,083: Snapshot:1	Epoch:0	Loss:7.709	translation_Loss:7.17	token_training_loss:0.0	distillation_Loss:0.539                                                   	MRR:20.51	Hits@10:34.49	Best:20.51
2025-01-06 22:03:54,940: Snapshot:1	Epoch:1	Loss:4.538	translation_Loss:3.369	token_training_loss:0.0	distillation_Loss:1.168                                                   	MRR:22.05	Hits@10:36.51	Best:22.05
2025-01-06 22:04:03,170: Snapshot:1	Epoch:2	Loss:3.52	translation_Loss:2.104	token_training_loss:0.0	distillation_Loss:1.416                                                   	MRR:22.72	Hits@10:37.42	Best:22.72
2025-01-06 22:04:11,003: Snapshot:1	Epoch:3	Loss:3.164	translation_Loss:1.661	token_training_loss:0.0	distillation_Loss:1.503                                                   	MRR:22.86	Hits@10:37.91	Best:22.86
2025-01-06 22:04:18,883: Snapshot:1	Epoch:4	Loss:3.046	translation_Loss:1.505	token_training_loss:0.0	distillation_Loss:1.541                                                   	MRR:23.04	Hits@10:38.04	Best:23.04
2025-01-06 22:04:27,065: Snapshot:1	Epoch:5	Loss:2.985	translation_Loss:1.413	token_training_loss:0.0	distillation_Loss:1.572                                                   	MRR:23.03	Hits@10:38.08	Best:23.04
2025-01-06 22:04:34,904: Snapshot:1	Epoch:6	Loss:2.966	translation_Loss:1.374	token_training_loss:0.0	distillation_Loss:1.592                                                   	MRR:23.08	Hits@10:38.12	Best:23.08
2025-01-06 22:04:43,157: Snapshot:1	Epoch:7	Loss:2.946	translation_Loss:1.346	token_training_loss:0.0	distillation_Loss:1.6                                                   	MRR:23.03	Hits@10:38.01	Best:23.08
2025-01-06 22:04:50,924: Snapshot:1	Epoch:8	Loss:2.946	translation_Loss:1.338	token_training_loss:0.0	distillation_Loss:1.609                                                   	MRR:22.99	Hits@10:38.16	Best:23.08
2025-01-06 22:04:58,687: Early Stopping! Snapshot: 1 Epoch: 9 Best Results: 23.08
2025-01-06 22:04:58,687: Start to training tokens! Snapshot: 1 Epoch: 9 Loss:2.946 MRR:22.98 Best Results: 23.08
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:04:58,687: Snapshot:1	Epoch:9	Loss:2.946	translation_Loss:1.327	token_training_loss:0.0	distillation_Loss:1.619                                                   	MRR:22.98	Hits@10:38.2	Best:23.08
2025-01-06 22:05:06,761: Snapshot:1	Epoch:10	Loss:29.515	translation_Loss:13.491	token_training_loss:16.024	distillation_Loss:0.0                                                   	MRR:22.98	Hits@10:38.2	Best:23.08
2025-01-06 22:05:14,422: End of token training: 1 Epoch: 11 Loss:13.848 MRR:22.98 Best Results: 23.08
2025-01-06 22:05:14,423: Snapshot:1	Epoch:11	Loss:13.848	translation_Loss:13.502	token_training_loss:0.347	distillation_Loss:0.0                                                           	MRR:22.98	Hits@10:38.2	Best:23.08
2025-01-06 22:05:14,685: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2025-01-06 22:05:21,131: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.253  | 0.165  | 0.2936 | 0.3483 |  0.4199 |
|     1      | 0.2323 | 0.1488 | 0.2717 | 0.3212 |  0.3864 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:05:36,573: Snapshot:2	Epoch:0	Loss:5.459	translation_Loss:4.234	token_training_loss:0.0	distillation_Loss:1.225                                                   	MRR:21.37	Hits@10:37.08	Best:21.37
2025-01-06 22:05:44,607: Snapshot:2	Epoch:1	Loss:4.504	translation_Loss:3.356	token_training_loss:0.0	distillation_Loss:1.148                                                   	MRR:21.65	Hits@10:37.42	Best:21.65
2025-01-06 22:05:52,587: Snapshot:2	Epoch:2	Loss:4.102	translation_Loss:3.092	token_training_loss:0.0	distillation_Loss:1.01                                                   	MRR:21.85	Hits@10:37.59	Best:21.85
2025-01-06 22:06:00,997: Snapshot:2	Epoch:3	Loss:4.02	translation_Loss:3.0	token_training_loss:0.0	distillation_Loss:1.02                                                   	MRR:21.9	Hits@10:37.64	Best:21.9
2025-01-06 22:06:08,933: Snapshot:2	Epoch:4	Loss:3.997	translation_Loss:2.992	token_training_loss:0.0	distillation_Loss:1.005                                                   	MRR:21.86	Hits@10:37.82	Best:21.9
2025-01-06 22:06:17,423: Snapshot:2	Epoch:5	Loss:3.98	translation_Loss:2.964	token_training_loss:0.0	distillation_Loss:1.015                                                   	MRR:21.94	Hits@10:37.66	Best:21.94
2025-01-06 22:06:25,343: Snapshot:2	Epoch:6	Loss:3.978	translation_Loss:2.968	token_training_loss:0.0	distillation_Loss:1.01                                                   	MRR:21.92	Hits@10:37.64	Best:21.94
2025-01-06 22:06:33,250: Snapshot:2	Epoch:7	Loss:3.972	translation_Loss:2.955	token_training_loss:0.0	distillation_Loss:1.017                                                   	MRR:21.86	Hits@10:37.66	Best:21.94
2025-01-06 22:06:41,537: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 21.94
2025-01-06 22:06:41,538: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:3.977 MRR:21.93 Best Results: 21.94
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:06:41,538: Snapshot:2	Epoch:8	Loss:3.977	translation_Loss:2.967	token_training_loss:0.0	distillation_Loss:1.01                                                   	MRR:21.93	Hits@10:37.72	Best:21.94
2025-01-06 22:06:49,350: Snapshot:2	Epoch:9	Loss:30.249	translation_Loss:14.413	token_training_loss:15.836	distillation_Loss:0.0                                                   	MRR:21.93	Hits@10:37.72	Best:21.94
2025-01-06 22:06:57,553: End of token training: 2 Epoch: 10 Loss:14.744 MRR:21.93 Best Results: 21.94
2025-01-06 22:06:57,553: Snapshot:2	Epoch:10	Loss:14.744	translation_Loss:14.399	token_training_loss:0.345	distillation_Loss:0.0                                                           	MRR:21.93	Hits@10:37.72	Best:21.94
2025-01-06 22:06:57,829: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2025-01-06 22:07:07,616: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2516 | 0.1632 | 0.2901 | 0.3459 |  0.4197 |
|     1      | 0.2351 | 0.1511 | 0.2721 | 0.3263 |  0.3921 |
|     2      | 0.2184 | 0.1356 | 0.2537 | 0.3056 |  0.3732 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:07:22,917: Snapshot:3	Epoch:0	Loss:3.902	translation_Loss:2.774	token_training_loss:0.0	distillation_Loss:1.127                                                   	MRR:19.44	Hits@10:36.74	Best:19.44
2025-01-06 22:07:30,989: Snapshot:3	Epoch:1	Loss:3.206	translation_Loss:2.131	token_training_loss:0.0	distillation_Loss:1.075                                                   	MRR:19.71	Hits@10:36.91	Best:19.71
2025-01-06 22:07:39,062: Snapshot:3	Epoch:2	Loss:3.045	translation_Loss:2.082	token_training_loss:0.0	distillation_Loss:0.963                                                   	MRR:19.81	Hits@10:37.04	Best:19.81
2025-01-06 22:07:47,512: Snapshot:3	Epoch:3	Loss:3.016	translation_Loss:2.033	token_training_loss:0.0	distillation_Loss:0.983                                                   	MRR:19.74	Hits@10:37.23	Best:19.81
2025-01-06 22:07:55,560: Snapshot:3	Epoch:4	Loss:3.016	translation_Loss:2.039	token_training_loss:0.0	distillation_Loss:0.977                                                   	MRR:19.91	Hits@10:36.88	Best:19.91
2025-01-06 22:08:03,556: Snapshot:3	Epoch:5	Loss:3.011	translation_Loss:2.031	token_training_loss:0.0	distillation_Loss:0.98                                                   	MRR:19.84	Hits@10:37.17	Best:19.91
2025-01-06 22:08:11,994: Snapshot:3	Epoch:6	Loss:3.013	translation_Loss:2.031	token_training_loss:0.0	distillation_Loss:0.982                                                   	MRR:19.87	Hits@10:36.92	Best:19.91
2025-01-06 22:08:20,044: Early Stopping! Snapshot: 3 Epoch: 7 Best Results: 19.91
2025-01-06 22:08:20,045: Start to training tokens! Snapshot: 3 Epoch: 7 Loss:3.016 MRR:19.9 Best Results: 19.91
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:08:20,045: Snapshot:3	Epoch:7	Loss:3.016	translation_Loss:2.032	token_training_loss:0.0	distillation_Loss:0.985                                                   	MRR:19.9	Hits@10:36.92	Best:19.91
2025-01-06 22:08:28,327: Snapshot:3	Epoch:8	Loss:30.26	translation_Loss:13.844	token_training_loss:16.416	distillation_Loss:0.0                                                   	MRR:19.9	Hits@10:36.92	Best:19.91
2025-01-06 22:08:36,169: End of token training: 3 Epoch: 9 Loss:14.196 MRR:19.9 Best Results: 19.91
2025-01-06 22:08:36,170: Snapshot:3	Epoch:9	Loss:14.196	translation_Loss:13.842	token_training_loss:0.354	distillation_Loss:0.0                                                           	MRR:19.9	Hits@10:36.92	Best:19.91
2025-01-06 22:08:36,434: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2025-01-06 22:08:49,878: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2456 | 0.1574 | 0.2834 | 0.3384 |  0.4156 |
|     1      | 0.2311 | 0.147  | 0.2671 | 0.323  |  0.3913 |
|     2      | 0.2187 | 0.1339 | 0.2541 | 0.3093 |  0.3832 |
|     3      | 0.1988 | 0.1114 | 0.2305 | 0.289  |  0.3725 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:09:05,234: Snapshot:4	Epoch:0	Loss:2.405	translation_Loss:1.619	token_training_loss:0.0	distillation_Loss:0.786                                                   	MRR:20.56	Hits@10:43.74	Best:20.56
2025-01-06 22:09:13,352: Snapshot:4	Epoch:1	Loss:1.548	translation_Loss:0.86	token_training_loss:0.0	distillation_Loss:0.688                                                   	MRR:20.72	Hits@10:43.15	Best:20.72
2025-01-06 22:09:21,506: Snapshot:4	Epoch:2	Loss:1.37	translation_Loss:0.75	token_training_loss:0.0	distillation_Loss:0.62                                                   	MRR:20.78	Hits@10:43.25	Best:20.78
2025-01-06 22:09:30,073: Snapshot:4	Epoch:3	Loss:1.335	translation_Loss:0.706	token_training_loss:0.0	distillation_Loss:0.63                                                   	MRR:20.89	Hits@10:43.32	Best:20.89
2025-01-06 22:09:38,150: Snapshot:4	Epoch:4	Loss:1.336	translation_Loss:0.714	token_training_loss:0.0	distillation_Loss:0.622                                                   	MRR:20.79	Hits@10:43.33	Best:20.89
2025-01-06 22:09:46,587: Snapshot:4	Epoch:5	Loss:1.329	translation_Loss:0.705	token_training_loss:0.0	distillation_Loss:0.624                                                   	MRR:20.74	Hits@10:43.48	Best:20.89
2025-01-06 22:09:54,694: Early Stopping! Snapshot: 4 Epoch: 6 Best Results: 20.89
2025-01-06 22:09:54,695: Start to training tokens! Snapshot: 4 Epoch: 6 Loss:1.328 MRR:20.69 Best Results: 20.89
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:09:54,695: Snapshot:4	Epoch:6	Loss:1.328	translation_Loss:0.706	token_training_loss:0.0	distillation_Loss:0.622                                                   	MRR:20.69	Hits@10:43.13	Best:20.89
2025-01-06 22:10:02,592: Snapshot:4	Epoch:7	Loss:27.411	translation_Loss:11.47	token_training_loss:15.941	distillation_Loss:0.0                                                   	MRR:20.69	Hits@10:43.13	Best:20.89
2025-01-06 22:10:11,134: End of token training: 4 Epoch: 8 Loss:11.825 MRR:20.69 Best Results: 20.89
2025-01-06 22:10:11,134: Snapshot:4	Epoch:8	Loss:11.825	translation_Loss:11.475	token_training_loss:0.349	distillation_Loss:0.0                                                           	MRR:20.69	Hits@10:43.13	Best:20.89
2025-01-06 22:10:11,400: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2025-01-06 22:10:28,248: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      |  0.24  | 0.1536 | 0.2752 | 0.3291 |  0.4058 |
|     1      | 0.2228 | 0.1409 | 0.2565 | 0.3095 |  0.3808 |
|     2      | 0.2114 | 0.1274 | 0.2445 | 0.3012 |  0.3767 |
|     3      | 0.1967 | 0.1084 | 0.2254 | 0.2869 |  0.3771 |
|     4      |  0.21  | 0.1019 | 0.2437 | 0.3263 |  0.4343 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 22:10:28,269: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2401 | 0.1559 | 0.2806 | 0.3293 |  0.392  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.253  | 0.165  | 0.2936 | 0.3483 |  0.4199 |
|     1      | 0.2323 | 0.1488 | 0.2717 | 0.3212 |  0.3864 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2516 | 0.1632 | 0.2901 | 0.3459 |  0.4197 |
|     1      | 0.2351 | 0.1511 | 0.2721 | 0.3263 |  0.3921 |
|     2      | 0.2184 | 0.1356 | 0.2537 | 0.3056 |  0.3732 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2456 | 0.1574 | 0.2834 | 0.3384 |  0.4156 |
|     1      | 0.2311 | 0.147  | 0.2671 | 0.323  |  0.3913 |
|     2      | 0.2187 | 0.1339 | 0.2541 | 0.3093 |  0.3832 |
|     3      | 0.1988 | 0.1114 | 0.2305 | 0.289  |  0.3725 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      |  0.24  | 0.1536 | 0.2752 | 0.3291 |  0.4058 |
|     1      | 0.2228 | 0.1409 | 0.2565 | 0.3095 |  0.3808 |
|     2      | 0.2114 | 0.1274 | 0.2445 | 0.3012 |  0.3767 |
|     3      | 0.1967 | 0.1084 | 0.2254 | 0.2869 |  0.3771 |
|     4      |  0.21  | 0.1019 | 0.2437 | 0.3263 |  0.4343 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 22:10:28,270: Report Result:
+----------+-------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time       | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+-------------------+-----------+--------------+--------------+---------------+
|    0     | 166.3098647594452 |    0.24   |    0.156     |    0.281     |     0.392     |
|    1     | 98.84136962890625 |   0.243   |    0.157     |    0.283     |     0.403     |
|    2     |  92.9601788520813 |   0.235   |     0.15     |    0.272     |     0.395     |
|    3     | 85.33660364151001 |   0.224   |    0.137     |    0.259     |     0.391     |
|    4     | 77.95638179779053 |   0.216   |    0.126     |    0.249     |     0.395     |
+----------+-------------------+-----------+--------------+--------------+---------------+
2025-01-06 22:10:28,270: Sum_Training_Time:521.4043986797333
2025-01-06 22:10:28,270: Every_Training_Time:[166.3098647594452, 98.84136962890625, 92.9601788520813, 85.33660364151001, 77.95638179779053]
2025-01-06 22:10:28,270: Forward transfer: 0.174175 Backward transfer: -0.0046750000000000055
2025-01-06 22:10:50,085: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106221033/FACT', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=2222, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[1000.0, 10000.0, 10000.0, 10000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 22:11:00,943: Snapshot:0	Epoch:0	Loss:17.026	translation_Loss:17.026	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.15	Hits@10:12.86	Best:6.15
2025-01-06 22:11:08,606: Snapshot:0	Epoch:1	Loss:11.984	translation_Loss:11.984	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:9.71	Hits@10:22.79	Best:9.71
2025-01-06 22:11:15,903: Snapshot:0	Epoch:2	Loss:8.664	translation_Loss:8.664	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.95	Hits@10:29.17	Best:12.95
2025-01-06 22:11:23,617: Snapshot:0	Epoch:3	Loss:6.189	translation_Loss:6.189	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.74	Hits@10:33.3	Best:15.74
2025-01-06 22:11:30,879: Snapshot:0	Epoch:4	Loss:4.39	translation_Loss:4.39	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.32	Hits@10:36.0	Best:18.32
2025-01-06 22:11:38,091: Snapshot:0	Epoch:5	Loss:3.113	translation_Loss:3.113	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:20.34	Hits@10:37.86	Best:20.34
2025-01-06 22:11:45,722: Snapshot:0	Epoch:6	Loss:2.227	translation_Loss:2.227	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:21.75	Hits@10:38.92	Best:21.75
2025-01-06 22:11:52,945: Snapshot:0	Epoch:7	Loss:1.577	translation_Loss:1.577	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.88	Hits@10:39.63	Best:22.88
2025-01-06 22:12:00,548: Snapshot:0	Epoch:8	Loss:1.133	translation_Loss:1.133	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.55	Hits@10:39.98	Best:23.55
2025-01-06 22:12:07,847: Snapshot:0	Epoch:9	Loss:0.835	translation_Loss:0.835	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.04	Hits@10:40.29	Best:24.04
2025-01-06 22:12:15,085: Snapshot:0	Epoch:10	Loss:0.645	translation_Loss:0.645	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.33	Hits@10:40.34	Best:24.33
2025-01-06 22:12:22,788: Snapshot:0	Epoch:11	Loss:0.519	translation_Loss:0.519	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.44	Hits@10:40.33	Best:24.44
2025-01-06 22:12:29,987: Snapshot:0	Epoch:12	Loss:0.427	translation_Loss:0.427	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.59	Hits@10:40.4	Best:24.59
2025-01-06 22:12:37,575: Snapshot:0	Epoch:13	Loss:0.359	translation_Loss:0.359	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.71	Hits@10:40.42	Best:24.71
2025-01-06 22:12:44,839: Snapshot:0	Epoch:14	Loss:0.314	translation_Loss:0.314	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.79	Hits@10:40.45	Best:24.79
2025-01-06 22:12:52,056: Snapshot:0	Epoch:15	Loss:0.281	translation_Loss:0.281	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.78	Hits@10:40.48	Best:24.79
2025-01-06 22:12:59,655: Snapshot:0	Epoch:16	Loss:0.256	translation_Loss:0.256	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.83	Hits@10:40.42	Best:24.83
2025-01-06 22:13:06,925: Snapshot:0	Epoch:17	Loss:0.229	translation_Loss:0.229	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.86	Hits@10:40.44	Best:24.86
2025-01-06 22:13:14,536: Snapshot:0	Epoch:18	Loss:0.213	translation_Loss:0.213	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.74	Hits@10:40.52	Best:24.86
2025-01-06 22:13:21,764: Snapshot:0	Epoch:19	Loss:0.201	translation_Loss:0.201	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.78	Hits@10:40.5	Best:24.86
2025-01-06 22:13:28,963: Early Stopping! Snapshot: 0 Epoch: 20 Best Results: 24.86
2025-01-06 22:13:28,964: Start to training tokens! Snapshot: 0 Epoch: 20 Loss:0.181 MRR:24.73 Best Results: 24.86
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:13:28,964: Snapshot:0	Epoch:20	Loss:0.181	translation_Loss:0.181	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.73	Hits@10:40.48	Best:24.86
2025-01-06 22:13:37,162: Snapshot:0	Epoch:21	Loss:28.181	translation_Loss:12.301	token_training_loss:15.88	distillation_Loss:0.0                                                   	MRR:24.73	Hits@10:40.48	Best:24.86
2025-01-06 22:13:44,462: End of token training: 0 Epoch: 22 Loss:12.633 MRR:24.73 Best Results: 24.86
2025-01-06 22:13:44,463: Snapshot:0	Epoch:22	Loss:12.633	translation_Loss:12.292	token_training_loss:0.341	distillation_Loss:0.0                                                           	MRR:24.73	Hits@10:40.48	Best:24.86
2025-01-06 22:13:44,725: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2025-01-06 22:13:47,614: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2433 | 0.1597 | 0.2832 | 0.3325 |  0.3957 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:14:02,340: Snapshot:1	Epoch:0	Loss:7.655	translation_Loss:7.116	token_training_loss:0.0	distillation_Loss:0.538                                                   	MRR:20.82	Hits@10:34.89	Best:20.82
2025-01-06 22:14:10,622: Snapshot:1	Epoch:1	Loss:4.525	translation_Loss:3.363	token_training_loss:0.0	distillation_Loss:1.162                                                   	MRR:22.36	Hits@10:37.03	Best:22.36
2025-01-06 22:14:18,618: Snapshot:1	Epoch:2	Loss:3.508	translation_Loss:2.1	token_training_loss:0.0	distillation_Loss:1.407                                                   	MRR:23.07	Hits@10:38.0	Best:23.07
2025-01-06 22:14:26,859: Snapshot:1	Epoch:3	Loss:3.153	translation_Loss:1.655	token_training_loss:0.0	distillation_Loss:1.498                                                   	MRR:23.24	Hits@10:38.33	Best:23.24
2025-01-06 22:14:34,790: Snapshot:1	Epoch:4	Loss:3.027	translation_Loss:1.49	token_training_loss:0.0	distillation_Loss:1.537                                                   	MRR:23.38	Hits@10:38.37	Best:23.38
2025-01-06 22:14:43,021: Snapshot:1	Epoch:5	Loss:2.977	translation_Loss:1.417	token_training_loss:0.0	distillation_Loss:1.56                                                   	MRR:23.35	Hits@10:38.46	Best:23.38
2025-01-06 22:14:50,923: Snapshot:1	Epoch:6	Loss:2.955	translation_Loss:1.376	token_training_loss:0.0	distillation_Loss:1.578                                                   	MRR:23.42	Hits@10:38.38	Best:23.42
2025-01-06 22:14:58,880: Snapshot:1	Epoch:7	Loss:2.934	translation_Loss:1.344	token_training_loss:0.0	distillation_Loss:1.589                                                   	MRR:23.44	Hits@10:38.46	Best:23.44
2025-01-06 22:15:07,369: Snapshot:1	Epoch:8	Loss:2.94	translation_Loss:1.341	token_training_loss:0.0	distillation_Loss:1.6                                                   	MRR:23.59	Hits@10:38.47	Best:23.59
2025-01-06 22:15:15,248: Snapshot:1	Epoch:9	Loss:2.928	translation_Loss:1.317	token_training_loss:0.0	distillation_Loss:1.611                                                   	MRR:23.47	Hits@10:38.56	Best:23.59
2025-01-06 22:15:23,459: Snapshot:1	Epoch:10	Loss:2.932	translation_Loss:1.317	token_training_loss:0.0	distillation_Loss:1.615                                                   	MRR:23.53	Hits@10:38.52	Best:23.59
2025-01-06 22:15:31,239: Early Stopping! Snapshot: 1 Epoch: 11 Best Results: 23.59
2025-01-06 22:15:31,239: Start to training tokens! Snapshot: 1 Epoch: 11 Loss:2.921 MRR:23.41 Best Results: 23.59
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:15:31,240: Snapshot:1	Epoch:11	Loss:2.921	translation_Loss:1.299	token_training_loss:0.0	distillation_Loss:1.622                                                   	MRR:23.41	Hits@10:38.37	Best:23.59
2025-01-06 22:15:38,926: Snapshot:1	Epoch:12	Loss:29.836	translation_Loss:13.542	token_training_loss:16.294	distillation_Loss:0.0                                                   	MRR:23.41	Hits@10:38.37	Best:23.59
2025-01-06 22:15:47,066: End of token training: 1 Epoch: 13 Loss:13.889 MRR:23.41 Best Results: 23.59
2025-01-06 22:15:47,067: Snapshot:1	Epoch:13	Loss:13.889	translation_Loss:13.525	token_training_loss:0.365	distillation_Loss:0.0                                                           	MRR:23.41	Hits@10:38.37	Best:23.59
2025-01-06 22:15:47,350: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2025-01-06 22:15:53,675: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2552 | 0.1653 | 0.2958 | 0.3529 |  0.4237 |
|     1      | 0.232  | 0.1497 | 0.2701 | 0.3211 |  0.3831 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:16:08,933: Snapshot:2	Epoch:0	Loss:5.46	translation_Loss:4.245	token_training_loss:0.0	distillation_Loss:1.216                                                   	MRR:21.37	Hits@10:36.98	Best:21.37
2025-01-06 22:16:17,045: Snapshot:2	Epoch:1	Loss:4.502	translation_Loss:3.373	token_training_loss:0.0	distillation_Loss:1.129                                                   	MRR:21.64	Hits@10:37.34	Best:21.64
2025-01-06 22:16:25,090: Snapshot:2	Epoch:2	Loss:4.113	translation_Loss:3.119	token_training_loss:0.0	distillation_Loss:0.995                                                   	MRR:21.84	Hits@10:37.67	Best:21.84
2025-01-06 22:16:33,454: Snapshot:2	Epoch:3	Loss:4.034	translation_Loss:3.029	token_training_loss:0.0	distillation_Loss:1.005                                                   	MRR:21.8	Hits@10:37.66	Best:21.84
2025-01-06 22:16:41,458: Snapshot:2	Epoch:4	Loss:4.003	translation_Loss:3.013	token_training_loss:0.0	distillation_Loss:0.99                                                   	MRR:21.88	Hits@10:37.76	Best:21.88
2025-01-06 22:16:49,928: Snapshot:2	Epoch:5	Loss:3.99	translation_Loss:2.99	token_training_loss:0.0	distillation_Loss:1.0                                                   	MRR:21.85	Hits@10:37.86	Best:21.88
2025-01-06 22:16:57,947: Snapshot:2	Epoch:6	Loss:3.985	translation_Loss:2.993	token_training_loss:0.0	distillation_Loss:0.992                                                   	MRR:21.94	Hits@10:37.69	Best:21.94
2025-01-06 22:17:06,034: Snapshot:2	Epoch:7	Loss:3.979	translation_Loss:2.977	token_training_loss:0.0	distillation_Loss:1.002                                                   	MRR:21.83	Hits@10:37.73	Best:21.94
2025-01-06 22:17:14,460: Snapshot:2	Epoch:8	Loss:3.975	translation_Loss:2.983	token_training_loss:0.0	distillation_Loss:0.992                                                   	MRR:21.89	Hits@10:37.71	Best:21.94
2025-01-06 22:17:22,514: Early Stopping! Snapshot: 2 Epoch: 9 Best Results: 21.94
2025-01-06 22:17:22,514: Start to training tokens! Snapshot: 2 Epoch: 9 Loss:3.982 MRR:21.86 Best Results: 21.94
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:17:22,514: Snapshot:2	Epoch:9	Loss:3.982	translation_Loss:2.979	token_training_loss:0.0	distillation_Loss:1.004                                                   	MRR:21.86	Hits@10:37.67	Best:21.94
2025-01-06 22:17:30,755: Snapshot:2	Epoch:10	Loss:31.339	translation_Loss:14.537	token_training_loss:16.802	distillation_Loss:0.0                                                   	MRR:21.86	Hits@10:37.67	Best:21.94
2025-01-06 22:17:38,599: End of token training: 2 Epoch: 11 Loss:14.887 MRR:21.86 Best Results: 21.94
2025-01-06 22:17:38,600: Snapshot:2	Epoch:11	Loss:14.887	translation_Loss:14.531	token_training_loss:0.356	distillation_Loss:0.0                                                           	MRR:21.86	Hits@10:37.67	Best:21.94
2025-01-06 22:17:38,862: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2025-01-06 22:17:48,765: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2549 | 0.1644 | 0.2973 | 0.3532 |  0.424  |
|     1      | 0.2343 | 0.1506 | 0.2718 | 0.3243 |  0.391  |
|     2      | 0.2183 | 0.1356 | 0.255  | 0.3057 |  0.3747 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:18:04,012: Snapshot:3	Epoch:0	Loss:3.951	translation_Loss:2.835	token_training_loss:0.0	distillation_Loss:1.117                                                   	MRR:19.43	Hits@10:37.04	Best:19.43
2025-01-06 22:18:12,148: Snapshot:3	Epoch:1	Loss:3.252	translation_Loss:2.18	token_training_loss:0.0	distillation_Loss:1.072                                                   	MRR:19.84	Hits@10:37.23	Best:19.84
2025-01-06 22:18:20,767: Snapshot:3	Epoch:2	Loss:3.077	translation_Loss:2.12	token_training_loss:0.0	distillation_Loss:0.956                                                   	MRR:19.76	Hits@10:37.21	Best:19.84
2025-01-06 22:18:28,846: Snapshot:3	Epoch:3	Loss:3.059	translation_Loss:2.085	token_training_loss:0.0	distillation_Loss:0.974                                                   	MRR:19.9	Hits@10:37.36	Best:19.9
2025-01-06 22:18:37,284: Snapshot:3	Epoch:4	Loss:3.047	translation_Loss:2.092	token_training_loss:0.0	distillation_Loss:0.954                                                   	MRR:19.86	Hits@10:37.19	Best:19.9
2025-01-06 22:18:45,327: Snapshot:3	Epoch:5	Loss:3.06	translation_Loss:2.088	token_training_loss:0.0	distillation_Loss:0.973                                                   	MRR:19.81	Hits@10:37.36	Best:19.9
2025-01-06 22:18:53,336: Early Stopping! Snapshot: 3 Epoch: 6 Best Results: 19.9
2025-01-06 22:18:53,337: Start to training tokens! Snapshot: 3 Epoch: 6 Loss:3.046 MRR:19.87 Best Results: 19.9
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:18:53,337: Snapshot:3	Epoch:6	Loss:3.046	translation_Loss:2.073	token_training_loss:0.0	distillation_Loss:0.973                                                   	MRR:19.87	Hits@10:37.05	Best:19.9
2025-01-06 22:19:01,576: Snapshot:3	Epoch:7	Loss:29.97	translation_Loss:14.017	token_training_loss:15.953	distillation_Loss:0.0                                                   	MRR:19.87	Hits@10:37.05	Best:19.9
2025-01-06 22:19:09,496: End of token training: 3 Epoch: 8 Loss:14.369 MRR:19.87 Best Results: 19.9
2025-01-06 22:19:09,497: Snapshot:3	Epoch:8	Loss:14.369	translation_Loss:14.019	token_training_loss:0.35	distillation_Loss:0.0                                                           	MRR:19.87	Hits@10:37.05	Best:19.9
2025-01-06 22:19:09,759: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2025-01-06 22:19:23,464: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2511 | 0.1628 | 0.2894 | 0.3444 |  0.4177 |
|     1      | 0.2318 | 0.1483 | 0.2678 | 0.3224 |  0.3915 |
|     2      | 0.2175 | 0.1323 | 0.252  | 0.3072 |  0.3834 |
|     3      | 0.2012 | 0.1133 | 0.232  | 0.2938 |  0.3784 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 22:19:38,533: Snapshot:4	Epoch:0	Loss:2.439	translation_Loss:1.647	token_training_loss:0.0	distillation_Loss:0.792                                                   	MRR:20.62	Hits@10:44.86	Best:20.62
2025-01-06 22:19:47,116: Snapshot:4	Epoch:1	Loss:1.586	translation_Loss:0.892	token_training_loss:0.0	distillation_Loss:0.694                                                   	MRR:21.12	Hits@10:44.62	Best:21.12
2025-01-06 22:19:55,194: Snapshot:4	Epoch:2	Loss:1.405	translation_Loss:0.77	token_training_loss:0.0	distillation_Loss:0.635                                                   	MRR:21.09	Hits@10:44.58	Best:21.12
2025-01-06 22:20:03,707: Snapshot:4	Epoch:3	Loss:1.366	translation_Loss:0.734	token_training_loss:0.0	distillation_Loss:0.632                                                   	MRR:21.27	Hits@10:44.45	Best:21.27
2025-01-06 22:20:11,956: Snapshot:4	Epoch:4	Loss:1.374	translation_Loss:0.742	token_training_loss:0.0	distillation_Loss:0.632                                                   	MRR:21.36	Hits@10:45.0	Best:21.36
2025-01-06 22:20:20,600: Snapshot:4	Epoch:5	Loss:1.372	translation_Loss:0.736	token_training_loss:0.0	distillation_Loss:0.636                                                   	MRR:21.39	Hits@10:44.47	Best:21.39
2025-01-06 22:20:28,768: Snapshot:4	Epoch:6	Loss:1.356	translation_Loss:0.723	token_training_loss:0.0	distillation_Loss:0.632                                                   	MRR:21.14	Hits@10:44.33	Best:21.39
2025-01-06 22:20:36,870: Snapshot:4	Epoch:7	Loss:1.365	translation_Loss:0.727	token_training_loss:0.0	distillation_Loss:0.638                                                   	MRR:21.08	Hits@10:44.47	Best:21.39
2025-01-06 22:20:45,442: Early Stopping! Snapshot: 4 Epoch: 8 Best Results: 21.39
2025-01-06 22:20:45,442: Start to training tokens! Snapshot: 4 Epoch: 8 Loss:1.367 MRR:21.13 Best Results: 21.39
Token added to optimizer, embeddings excluded successfully.
2025-01-06 22:20:45,442: Snapshot:4	Epoch:8	Loss:1.367	translation_Loss:0.727	token_training_loss:0.0	distillation_Loss:0.64                                                   	MRR:21.13	Hits@10:44.69	Best:21.39
2025-01-06 22:20:53,422: Snapshot:4	Epoch:9	Loss:28.262	translation_Loss:11.799	token_training_loss:16.463	distillation_Loss:0.0                                                   	MRR:21.13	Hits@10:44.69	Best:21.39
2025-01-06 22:21:01,788: End of token training: 4 Epoch: 10 Loss:12.181 MRR:21.13 Best Results: 21.39
2025-01-06 22:21:01,788: Snapshot:4	Epoch:10	Loss:12.181	translation_Loss:11.823	token_training_loss:0.357	distillation_Loss:0.0                                                           	MRR:21.13	Hits@10:44.69	Best:21.39
2025-01-06 22:21:02,045: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2025-01-06 22:21:19,048: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2429 | 0.1561 | 0.2786 | 0.3345 |  0.4077 |
|     1      | 0.2247 | 0.1432 | 0.2565 | 0.3114 |  0.3812 |
|     2      | 0.2114 | 0.1269 | 0.2442 | 0.3001 |  0.3785 |
|     3      | 0.1987 | 0.1101 | 0.2266 | 0.2883 |  0.3809 |
|     4      | 0.2143 | 0.1058 | 0.2451 | 0.3304 |  0.4426 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 22:21:19,050: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2433 | 0.1597 | 0.2832 | 0.3325 |  0.3957 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2552 | 0.1653 | 0.2958 | 0.3529 |  0.4237 |
|     1      | 0.232  | 0.1497 | 0.2701 | 0.3211 |  0.3831 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2549 | 0.1644 | 0.2973 | 0.3532 |  0.424  |
|     1      | 0.2343 | 0.1506 | 0.2718 | 0.3243 |  0.391  |
|     2      | 0.2183 | 0.1356 | 0.255  | 0.3057 |  0.3747 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2511 | 0.1628 | 0.2894 | 0.3444 |  0.4177 |
|     1      | 0.2318 | 0.1483 | 0.2678 | 0.3224 |  0.3915 |
|     2      | 0.2175 | 0.1323 | 0.252  | 0.3072 |  0.3834 |
|     3      | 0.2012 | 0.1133 | 0.232  | 0.2938 |  0.3784 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2429 | 0.1561 | 0.2786 | 0.3345 |  0.4077 |
|     1      | 0.2247 | 0.1432 | 0.2565 | 0.3114 |  0.3812 |
|     2      | 0.2114 | 0.1269 | 0.2442 | 0.3001 |  0.3785 |
|     3      | 0.1987 | 0.1101 | 0.2266 | 0.2883 |  0.3809 |
|     4      | 0.2143 | 0.1058 | 0.2451 | 0.3304 |  0.4426 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 22:21:19,051: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 174.37755489349365 |   0.243   |     0.16     |    0.283     |     0.396     |
|    1     | 116.16735172271729 |   0.244   |    0.158     |    0.283     |     0.403     |
|    2     | 101.43472814559937 |   0.236   |     0.15     |    0.275     |     0.397     |
|    3     | 77.20928835868835  |   0.225   |    0.139     |     0.26     |     0.393     |
|    4     | 94.71999430656433  |   0.218   |    0.128     |     0.25     |     0.398     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 22:21:19,051: Sum_Training_Time:563.908917427063
2025-01-06 22:21:19,051: Every_Training_Time:[174.37755489349365, 116.16735172271729, 101.43472814559937, 77.20928835868835, 94.71999430656433]
2025-01-06 22:21:19,051: Forward transfer: 0.1753 Backward transfer: -0.004274999999999994
2025-01-06 22:21:40,725: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106222124/FACT', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3333, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[1000.0, 10000.0, 10000.0, 10000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 22:21:51,696: Snapshot:0	Epoch:0	Loss:17.027	translation_Loss:17.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.27	Hits@10:13.28	Best:6.27
