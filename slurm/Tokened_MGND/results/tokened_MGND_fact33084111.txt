2025-01-06 18:16:36,722: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106181617/FACT', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=11, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[1000.0, 10000.0, 10000.0, 10000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:16:47,782: Snapshot:0	Epoch:0	Loss:17.05	translation_Loss:17.05	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.19	Hits@10:13.05	Best:6.19
2025-01-06 18:16:55,429: Snapshot:0	Epoch:1	Loss:12.019	translation_Loss:12.019	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:9.46	Hits@10:22.42	Best:9.46
2025-01-06 18:17:02,651: Snapshot:0	Epoch:2	Loss:8.678	translation_Loss:8.678	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.42	Hits@10:28.8	Best:12.42
2025-01-06 18:17:10,401: Snapshot:0	Epoch:3	Loss:6.192	translation_Loss:6.192	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.42	Hits@10:32.99	Best:15.42
2025-01-06 18:17:17,670: Snapshot:0	Epoch:4	Loss:4.366	translation_Loss:4.366	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.01	Hits@10:35.93	Best:18.01
2025-01-06 18:17:24,920: Snapshot:0	Epoch:5	Loss:3.086	translation_Loss:3.086	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:20.11	Hits@10:37.66	Best:20.11
2025-01-06 18:17:32,547: Snapshot:0	Epoch:6	Loss:2.168	translation_Loss:2.168	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:21.68	Hits@10:38.71	Best:21.68
2025-01-06 18:17:39,967: Snapshot:0	Epoch:7	Loss:1.537	translation_Loss:1.537	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.92	Hits@10:39.28	Best:22.92
2025-01-06 18:17:47,661: Snapshot:0	Epoch:8	Loss:1.098	translation_Loss:1.098	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.65	Hits@10:39.86	Best:23.65
2025-01-06 18:17:54,870: Snapshot:0	Epoch:9	Loss:0.816	translation_Loss:0.816	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.07	Hits@10:40.04	Best:24.07
2025-01-06 18:18:02,095: Snapshot:0	Epoch:10	Loss:0.631	translation_Loss:0.631	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.32	Hits@10:40.05	Best:24.32
2025-01-06 18:18:09,859: Snapshot:0	Epoch:11	Loss:0.507	translation_Loss:0.507	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.55	Hits@10:40.26	Best:24.55
2025-01-06 18:18:17,057: Snapshot:0	Epoch:12	Loss:0.417	translation_Loss:0.417	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.61	Hits@10:40.25	Best:24.61
2025-01-06 18:18:24,639: Snapshot:0	Epoch:13	Loss:0.358	translation_Loss:0.358	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.7	Hits@10:40.21	Best:24.7
2025-01-06 18:18:31,831: Snapshot:0	Epoch:14	Loss:0.315	translation_Loss:0.315	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.76	Hits@10:40.36	Best:24.76
2025-01-06 18:18:39,093: Snapshot:0	Epoch:15	Loss:0.271	translation_Loss:0.271	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.74	Hits@10:40.29	Best:24.76
2025-01-06 18:18:46,779: Snapshot:0	Epoch:16	Loss:0.25	translation_Loss:0.25	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.74	Hits@10:40.32	Best:24.76
2025-01-06 18:18:53,973: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 24.76
2025-01-06 18:18:53,973: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.23 MRR:24.76 Best Results: 24.76
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:18:53,973: Snapshot:0	Epoch:17	Loss:0.23	translation_Loss:0.23	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.76	Hits@10:40.29	Best:24.76
2025-01-06 18:19:02,157: Snapshot:0	Epoch:18	Loss:28.112	translation_Loss:12.254	token_training_loss:15.858	distillation_Loss:0.0                                                   	MRR:24.76	Hits@10:40.29	Best:24.76
2025-01-06 18:19:09,485: End of token training: 0 Epoch: 19 Loss:12.595 MRR:24.76 Best Results: 24.76
2025-01-06 18:19:09,485: Snapshot:0	Epoch:19	Loss:12.595	translation_Loss:12.249	token_training_loss:0.346	distillation_Loss:0.0                                                           	MRR:24.76	Hits@10:40.29	Best:24.76
2025-01-06 18:19:09,754: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2025-01-06 18:19:12,652: 
+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.239 | 0.1539 | 0.2808 | 0.3308 |  0.3921 |
+------------+-------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:19:27,520: Snapshot:1	Epoch:0	Loss:7.883	translation_Loss:7.339	token_training_loss:0.0	distillation_Loss:0.544                                                   	MRR:20.47	Hits@10:34.25	Best:20.47
2025-01-06 18:19:35,779: Snapshot:1	Epoch:1	Loss:4.686	translation_Loss:3.499	token_training_loss:0.0	distillation_Loss:1.187                                                   	MRR:22.03	Hits@10:36.67	Best:22.03
2025-01-06 18:19:43,833: Snapshot:1	Epoch:2	Loss:3.641	translation_Loss:2.185	token_training_loss:0.0	distillation_Loss:1.456                                                   	MRR:22.88	Hits@10:37.7	Best:22.88
2025-01-06 18:19:51,679: Snapshot:1	Epoch:3	Loss:3.27	translation_Loss:1.717	token_training_loss:0.0	distillation_Loss:1.552                                                   	MRR:23.12	Hits@10:38.06	Best:23.12
2025-01-06 18:19:59,923: Snapshot:1	Epoch:4	Loss:3.15	translation_Loss:1.554	token_training_loss:0.0	distillation_Loss:1.596                                                   	MRR:23.09	Hits@10:37.98	Best:23.12
2025-01-06 18:20:08,180: Snapshot:1	Epoch:5	Loss:3.095	translation_Loss:1.466	token_training_loss:0.0	distillation_Loss:1.629                                                   	MRR:23.14	Hits@10:38.07	Best:23.14
2025-01-06 18:20:16,518: Snapshot:1	Epoch:6	Loss:3.058	translation_Loss:1.408	token_training_loss:0.0	distillation_Loss:1.65                                                   	MRR:23.11	Hits@10:38.08	Best:23.14
2025-01-06 18:20:24,377: Snapshot:1	Epoch:7	Loss:3.048	translation_Loss:1.385	token_training_loss:0.0	distillation_Loss:1.663                                                   	MRR:23.14	Hits@10:37.98	Best:23.14
2025-01-06 18:20:32,155: Early Stopping! Snapshot: 1 Epoch: 8 Best Results: 23.14
2025-01-06 18:20:32,155: Start to training tokens! Snapshot: 1 Epoch: 8 Loss:3.031 MRR:23.11 Best Results: 23.14
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:20:32,156: Snapshot:1	Epoch:8	Loss:3.031	translation_Loss:1.359	token_training_loss:0.0	distillation_Loss:1.672                                                   	MRR:23.11	Hits@10:38.08	Best:23.14
2025-01-06 18:20:40,355: Snapshot:1	Epoch:9	Loss:29.632	translation_Loss:13.435	token_training_loss:16.197	distillation_Loss:0.0                                                   	MRR:23.11	Hits@10:38.08	Best:23.14
2025-01-06 18:20:48,069: End of token training: 1 Epoch: 10 Loss:13.785 MRR:23.11 Best Results: 23.14
2025-01-06 18:20:48,069: Snapshot:1	Epoch:10	Loss:13.785	translation_Loss:13.432	token_training_loss:0.353	distillation_Loss:0.0                                                           	MRR:23.11	Hits@10:38.08	Best:23.14
2025-01-06 18:20:48,341: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2025-01-06 18:20:54,766: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2514 | 0.1622 | 0.2922 | 0.3485 |  0.4187 |
|     1      | 0.2322 | 0.1489 | 0.272  | 0.3208 |  0.3841 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:21:10,095: Snapshot:2	Epoch:0	Loss:5.645	translation_Loss:4.387	token_training_loss:0.0	distillation_Loss:1.258                                                   	MRR:21.41	Hits@10:36.94	Best:21.41
2025-01-06 18:21:18,517: Snapshot:2	Epoch:1	Loss:4.669	translation_Loss:3.474	token_training_loss:0.0	distillation_Loss:1.195                                                   	MRR:21.77	Hits@10:37.48	Best:21.77
2025-01-06 18:21:26,559: Snapshot:2	Epoch:2	Loss:4.268	translation_Loss:3.218	token_training_loss:0.0	distillation_Loss:1.051                                                   	MRR:21.91	Hits@10:37.7	Best:21.91
2025-01-06 18:21:35,042: Snapshot:2	Epoch:3	Loss:4.178	translation_Loss:3.118	token_training_loss:0.0	distillation_Loss:1.06                                                   	MRR:21.98	Hits@10:37.75	Best:21.98
2025-01-06 18:21:43,077: Snapshot:2	Epoch:4	Loss:4.154	translation_Loss:3.11	token_training_loss:0.0	distillation_Loss:1.044                                                   	MRR:21.93	Hits@10:37.81	Best:21.98
2025-01-06 18:21:51,040: Snapshot:2	Epoch:5	Loss:4.137	translation_Loss:3.077	token_training_loss:0.0	distillation_Loss:1.061                                                   	MRR:21.93	Hits@10:37.71	Best:21.98
2025-01-06 18:21:59,384: Early Stopping! Snapshot: 2 Epoch: 6 Best Results: 21.98
2025-01-06 18:21:59,385: Start to training tokens! Snapshot: 2 Epoch: 6 Loss:4.12 MRR:21.92 Best Results: 21.98
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:21:59,385: Snapshot:2	Epoch:6	Loss:4.12	translation_Loss:3.073	token_training_loss:0.0	distillation_Loss:1.047                                                   	MRR:21.92	Hits@10:37.7	Best:21.98
2025-01-06 18:22:07,277: Snapshot:2	Epoch:7	Loss:30.046	translation_Loss:14.402	token_training_loss:15.644	distillation_Loss:0.0                                                   	MRR:21.92	Hits@10:37.7	Best:21.98
2025-01-06 18:22:15,549: End of token training: 2 Epoch: 8 Loss:14.715 MRR:21.92 Best Results: 21.98
2025-01-06 18:22:15,550: Snapshot:2	Epoch:8	Loss:14.715	translation_Loss:14.393	token_training_loss:0.321	distillation_Loss:0.0                                                           	MRR:21.92	Hits@10:37.7	Best:21.98
2025-01-06 18:22:15,817: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2025-01-06 18:22:25,651: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2502 | 0.1613 | 0.2896 | 0.3447 |  0.4192 |
|     1      | 0.2349 | 0.1508 | 0.2734 | 0.3249 |  0.3909 |
|     2      | 0.2184 | 0.1353 | 0.2527 | 0.3079 |  0.3762 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:22:41,018: Snapshot:3	Epoch:0	Loss:4.086	translation_Loss:2.927	token_training_loss:0.0	distillation_Loss:1.159                                                   	MRR:19.66	Hits@10:36.76	Best:19.66
2025-01-06 18:22:49,522: Snapshot:3	Epoch:1	Loss:3.357	translation_Loss:2.234	token_training_loss:0.0	distillation_Loss:1.123                                                   	MRR:19.77	Hits@10:36.96	Best:19.77
2025-01-06 18:22:57,586: Snapshot:3	Epoch:2	Loss:3.177	translation_Loss:2.173	token_training_loss:0.0	distillation_Loss:1.004                                                   	MRR:19.72	Hits@10:37.34	Best:19.77
2025-01-06 18:23:05,982: Snapshot:3	Epoch:3	Loss:3.166	translation_Loss:2.133	token_training_loss:0.0	distillation_Loss:1.033                                                   	MRR:19.73	Hits@10:37.28	Best:19.77
2025-01-06 18:23:14,104: Snapshot:3	Epoch:4	Loss:3.158	translation_Loss:2.137	token_training_loss:0.0	distillation_Loss:1.022                                                   	MRR:19.83	Hits@10:37.2	Best:19.83
2025-01-06 18:23:22,118: Snapshot:3	Epoch:5	Loss:3.152	translation_Loss:2.124	token_training_loss:0.0	distillation_Loss:1.028                                                   	MRR:19.79	Hits@10:37.3	Best:19.83
2025-01-06 18:23:30,598: Snapshot:3	Epoch:6	Loss:3.156	translation_Loss:2.127	token_training_loss:0.0	distillation_Loss:1.029                                                   	MRR:19.93	Hits@10:37.44	Best:19.93
2025-01-06 18:23:38,708: Snapshot:3	Epoch:7	Loss:3.149	translation_Loss:2.118	token_training_loss:0.0	distillation_Loss:1.032                                                   	MRR:19.85	Hits@10:37.23	Best:19.93
2025-01-06 18:23:47,225: Snapshot:3	Epoch:8	Loss:3.158	translation_Loss:2.125	token_training_loss:0.0	distillation_Loss:1.033                                                   	MRR:19.86	Hits@10:37.27	Best:19.93
2025-01-06 18:23:55,269: Early Stopping! Snapshot: 3 Epoch: 9 Best Results: 19.93
2025-01-06 18:23:55,270: Start to training tokens! Snapshot: 3 Epoch: 9 Loss:3.162 MRR:19.77 Best Results: 19.93
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:23:55,270: Snapshot:3	Epoch:9	Loss:3.162	translation_Loss:2.122	token_training_loss:0.0	distillation_Loss:1.04                                                   	MRR:19.77	Hits@10:37.19	Best:19.93
2025-01-06 18:24:03,142: Snapshot:3	Epoch:10	Loss:29.644	translation_Loss:13.835	token_training_loss:15.809	distillation_Loss:0.0                                                   	MRR:19.77	Hits@10:37.19	Best:19.93
2025-01-06 18:24:11,508: End of token training: 3 Epoch: 11 Loss:14.175 MRR:19.77 Best Results: 19.93
2025-01-06 18:24:11,508: Snapshot:3	Epoch:11	Loss:14.175	translation_Loss:13.841	token_training_loss:0.334	distillation_Loss:0.0                                                           	MRR:19.77	Hits@10:37.19	Best:19.93
2025-01-06 18:24:11,774: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2025-01-06 18:24:25,337: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.244  | 0.1557 | 0.2833 | 0.3367 |  0.4121 |
|     1      | 0.2318 | 0.148  | 0.2672 | 0.322  |  0.3917 |
|     2      | 0.2174 | 0.1317 | 0.2529 | 0.3101 |  0.3824 |
|     3      | 0.1995 | 0.1128 | 0.2301 | 0.2893 |  0.3721 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:24:40,990: Snapshot:4	Epoch:0	Loss:2.45	translation_Loss:1.651	token_training_loss:0.0	distillation_Loss:0.799                                                   	MRR:20.74	Hits@10:44.72	Best:20.74
2025-01-06 18:24:49,114: Snapshot:4	Epoch:1	Loss:1.583	translation_Loss:0.887	token_training_loss:0.0	distillation_Loss:0.696                                                   	MRR:20.87	Hits@10:44.06	Best:20.87
2025-01-06 18:24:57,258: Snapshot:4	Epoch:2	Loss:1.405	translation_Loss:0.768	token_training_loss:0.0	distillation_Loss:0.637                                                   	MRR:21.16	Hits@10:44.01	Best:21.16
2025-01-06 18:25:05,896: Snapshot:4	Epoch:3	Loss:1.372	translation_Loss:0.735	token_training_loss:0.0	distillation_Loss:0.636                                                   	MRR:21.06	Hits@10:44.39	Best:21.16
2025-01-06 18:25:14,039: Snapshot:4	Epoch:4	Loss:1.364	translation_Loss:0.726	token_training_loss:0.0	distillation_Loss:0.638                                                   	MRR:20.99	Hits@10:44.31	Best:21.16
2025-01-06 18:25:22,493: Early Stopping! Snapshot: 4 Epoch: 5 Best Results: 21.16
2025-01-06 18:25:22,493: Start to training tokens! Snapshot: 4 Epoch: 5 Loss:1.358 MRR:20.9 Best Results: 21.16
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:25:22,493: Snapshot:4	Epoch:5	Loss:1.358	translation_Loss:0.723	token_training_loss:0.0	distillation_Loss:0.635                                                   	MRR:20.9	Hits@10:43.87	Best:21.16
2025-01-06 18:25:30,463: Snapshot:4	Epoch:6	Loss:27.801	translation_Loss:11.577	token_training_loss:16.224	distillation_Loss:0.0                                                   	MRR:20.9	Hits@10:43.87	Best:21.16
2025-01-06 18:25:38,477: End of token training: 4 Epoch: 7 Loss:11.911 MRR:20.9 Best Results: 21.16
2025-01-06 18:25:38,477: Snapshot:4	Epoch:7	Loss:11.911	translation_Loss:11.566	token_training_loss:0.345	distillation_Loss:0.0                                                           	MRR:20.9	Hits@10:43.87	Best:21.16
2025-01-06 18:25:38,742: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2025-01-06 18:25:56,208: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2394 | 0.1534 | 0.2765 | 0.3295 |  0.404  |
|     1      | 0.2241 | 0.142  | 0.2576 | 0.3101 |  0.3814 |
|     2      | 0.2107 | 0.1267 | 0.2421 | 0.2994 |  0.3771 |
|     3      | 0.1958 | 0.1074 | 0.225  | 0.2869 |  0.3753 |
|     4      | 0.2146 | 0.105  | 0.2486 | 0.3342 |  0.4428 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 18:25:56,210: Final Result:
[+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.239 | 0.1539 | 0.2808 | 0.3308 |  0.3921 |
+------------+-------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2514 | 0.1622 | 0.2922 | 0.3485 |  0.4187 |
|     1      | 0.2322 | 0.1489 | 0.272  | 0.3208 |  0.3841 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2502 | 0.1613 | 0.2896 | 0.3447 |  0.4192 |
|     1      | 0.2349 | 0.1508 | 0.2734 | 0.3249 |  0.3909 |
|     2      | 0.2184 | 0.1353 | 0.2527 | 0.3079 |  0.3762 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.244  | 0.1557 | 0.2833 | 0.3367 |  0.4121 |
|     1      | 0.2318 | 0.148  | 0.2672 | 0.322  |  0.3917 |
|     2      | 0.2174 | 0.1317 | 0.2529 | 0.3101 |  0.3824 |
|     3      | 0.1995 | 0.1128 | 0.2301 | 0.2893 |  0.3721 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2394 | 0.1534 | 0.2765 | 0.3295 |  0.404  |
|     1      | 0.2241 | 0.142  | 0.2576 | 0.3101 |  0.3814 |
|     2      | 0.2107 | 0.1267 | 0.2421 | 0.2994 |  0.3771 |
|     3      | 0.1958 | 0.1074 | 0.225  | 0.2869 |  0.3753 |
|     4      | 0.2146 | 0.105  | 0.2486 | 0.3342 |  0.4428 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 18:25:56,211: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 152.76269006729126 |   0.239   |    0.154     |    0.281     |     0.392     |
|    1     | 92.12000155448914  |   0.242   |    0.156     |    0.282     |     0.401     |
|    2     | 76.99070239067078  |   0.234   |    0.149     |    0.272     |     0.395     |
|    3     | 102.29408431053162 |   0.223   |    0.137     |    0.258     |      0.39     |
|    4     | 69.53147888183594  |   0.217   |    0.127     |     0.25     |     0.396     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 18:25:56,211: Sum_Training_Time:493.6989572048187
2025-01-06 18:25:56,211: Every_Training_Time:[152.76269006729126, 92.12000155448914, 76.99070239067078, 102.29408431053162, 69.53147888183594]
2025-01-06 18:25:56,211: Forward transfer: 0.17475000000000002 Backward transfer: -0.0047750000000000015
2025-01-06 18:26:18,177: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106182601/FACT', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=22, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[1000.0, 10000.0, 10000.0, 10000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:26:29,201: Snapshot:0	Epoch:0	Loss:17.054	translation_Loss:17.054	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.28	Hits@10:13.12	Best:6.28
2025-01-06 18:26:36,816: Snapshot:0	Epoch:1	Loss:11.98	translation_Loss:11.98	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:9.61	Hits@10:22.41	Best:9.61
2025-01-06 18:26:44,144: Snapshot:0	Epoch:2	Loss:8.647	translation_Loss:8.647	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.88	Hits@10:28.74	Best:12.88
2025-01-06 18:26:51,902: Snapshot:0	Epoch:3	Loss:6.189	translation_Loss:6.189	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.79	Hits@10:32.87	Best:15.79
2025-01-06 18:26:59,148: Snapshot:0	Epoch:4	Loss:4.403	translation_Loss:4.403	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.33	Hits@10:35.73	Best:18.33
2025-01-06 18:27:06,366: Snapshot:0	Epoch:5	Loss:3.115	translation_Loss:3.115	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:20.3	Hits@10:37.46	Best:20.3
2025-01-06 18:27:14,047: Snapshot:0	Epoch:6	Loss:2.201	translation_Loss:2.201	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:21.9	Hits@10:38.59	Best:21.9
2025-01-06 18:27:21,316: Snapshot:0	Epoch:7	Loss:1.547	translation_Loss:1.547	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.05	Hits@10:39.2	Best:23.05
2025-01-06 18:27:28,961: Snapshot:0	Epoch:8	Loss:1.107	translation_Loss:1.107	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.83	Hits@10:39.66	Best:23.83
2025-01-06 18:27:36,150: Snapshot:0	Epoch:9	Loss:0.813	translation_Loss:0.813	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.3	Hits@10:39.89	Best:24.3
2025-01-06 18:27:43,578: Snapshot:0	Epoch:10	Loss:0.629	translation_Loss:0.629	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.52	Hits@10:40.06	Best:24.52
2025-01-06 18:27:51,265: Snapshot:0	Epoch:11	Loss:0.498	translation_Loss:0.498	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.6	Hits@10:40.1	Best:24.6
2025-01-06 18:27:58,481: Snapshot:0	Epoch:12	Loss:0.414	translation_Loss:0.414	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.74	Hits@10:40.25	Best:24.74
2025-01-06 18:28:06,099: Snapshot:0	Epoch:13	Loss:0.356	translation_Loss:0.356	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.79	Hits@10:40.16	Best:24.79
2025-01-06 18:28:13,385: Snapshot:0	Epoch:14	Loss:0.305	translation_Loss:0.305	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.83	Hits@10:40.24	Best:24.83
2025-01-06 18:28:20,654: Snapshot:0	Epoch:15	Loss:0.27	translation_Loss:0.27	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.96	Hits@10:40.28	Best:24.96
2025-01-06 18:28:28,312: Snapshot:0	Epoch:16	Loss:0.246	translation_Loss:0.246	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.99	Hits@10:40.21	Best:24.99
2025-01-06 18:28:35,550: Snapshot:0	Epoch:17	Loss:0.223	translation_Loss:0.223	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.93	Hits@10:40.27	Best:24.99
2025-01-06 18:28:43,330: Snapshot:0	Epoch:18	Loss:0.207	translation_Loss:0.207	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.95	Hits@10:40.3	Best:24.99
2025-01-06 18:28:50,497: Early Stopping! Snapshot: 0 Epoch: 19 Best Results: 24.99
2025-01-06 18:28:50,497: Start to training tokens! Snapshot: 0 Epoch: 19 Loss:0.188 MRR:24.93 Best Results: 24.99
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:28:50,498: Snapshot:0	Epoch:19	Loss:0.188	translation_Loss:0.188	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.93	Hits@10:40.21	Best:24.99
2025-01-06 18:28:58,218: Snapshot:0	Epoch:20	Loss:29.092	translation_Loss:12.352	token_training_loss:16.739	distillation_Loss:0.0                                                   	MRR:24.93	Hits@10:40.21	Best:24.99
2025-01-06 18:29:05,834: End of token training: 0 Epoch: 21 Loss:12.698 MRR:24.93 Best Results: 24.99
2025-01-06 18:29:05,835: Snapshot:0	Epoch:21	Loss:12.698	translation_Loss:12.344	token_training_loss:0.354	distillation_Loss:0.0                                                           	MRR:24.93	Hits@10:40.21	Best:24.99
2025-01-06 18:29:06,105: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2025-01-06 18:29:09,180: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2413 | 0.157  | 0.2824 | 0.3323 |  0.3932 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:29:24,195: Snapshot:1	Epoch:0	Loss:7.72	translation_Loss:7.178	token_training_loss:0.0	distillation_Loss:0.542                                                   	MRR:20.64	Hits@10:34.49	Best:20.64
2025-01-06 18:29:32,060: Snapshot:1	Epoch:1	Loss:4.564	translation_Loss:3.392	token_training_loss:0.0	distillation_Loss:1.172                                                   	MRR:22.12	Hits@10:36.74	Best:22.12
2025-01-06 18:29:40,408: Snapshot:1	Epoch:2	Loss:3.536	translation_Loss:2.114	token_training_loss:0.0	distillation_Loss:1.422                                                   	MRR:22.83	Hits@10:37.51	Best:22.83
2025-01-06 18:29:48,297: Snapshot:1	Epoch:3	Loss:3.177	translation_Loss:1.665	token_training_loss:0.0	distillation_Loss:1.512                                                   	MRR:23.06	Hits@10:37.96	Best:23.06
2025-01-06 18:29:56,234: Snapshot:1	Epoch:4	Loss:3.053	translation_Loss:1.502	token_training_loss:0.0	distillation_Loss:1.551                                                   	MRR:23.19	Hits@10:38.0	Best:23.19
2025-01-06 18:30:04,661: Snapshot:1	Epoch:5	Loss:3.003	translation_Loss:1.422	token_training_loss:0.0	distillation_Loss:1.581                                                   	MRR:23.21	Hits@10:37.96	Best:23.21
2025-01-06 18:30:12,711: Snapshot:1	Epoch:6	Loss:2.972	translation_Loss:1.377	token_training_loss:0.0	distillation_Loss:1.595                                                   	MRR:23.36	Hits@10:38.35	Best:23.36
2025-01-06 18:30:20,919: Snapshot:1	Epoch:7	Loss:2.964	translation_Loss:1.354	token_training_loss:0.0	distillation_Loss:1.61                                                   	MRR:23.23	Hits@10:38.08	Best:23.36
2025-01-06 18:30:28,725: Snapshot:1	Epoch:8	Loss:2.955	translation_Loss:1.334	token_training_loss:0.0	distillation_Loss:1.621                                                   	MRR:23.15	Hits@10:37.98	Best:23.36
2025-01-06 18:30:36,602: Early Stopping! Snapshot: 1 Epoch: 9 Best Results: 23.36
2025-01-06 18:30:36,602: Start to training tokens! Snapshot: 1 Epoch: 9 Loss:2.955 MRR:23.21 Best Results: 23.36
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:30:36,602: Snapshot:1	Epoch:9	Loss:2.955	translation_Loss:1.324	token_training_loss:0.0	distillation_Loss:1.631                                                   	MRR:23.21	Hits@10:38.05	Best:23.36
2025-01-06 18:30:44,872: Snapshot:1	Epoch:10	Loss:29.905	translation_Loss:13.558	token_training_loss:16.347	distillation_Loss:0.0                                                   	MRR:23.21	Hits@10:38.05	Best:23.36
2025-01-06 18:30:52,603: End of token training: 1 Epoch: 11 Loss:13.927 MRR:23.21 Best Results: 23.36
2025-01-06 18:30:52,603: Snapshot:1	Epoch:11	Loss:13.927	translation_Loss:13.573	token_training_loss:0.354	distillation_Loss:0.0                                                           	MRR:23.21	Hits@10:38.05	Best:23.36
2025-01-06 18:30:52,873: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2025-01-06 18:30:59,145: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2529 | 0.1638 | 0.2946 | 0.348  |  0.4187 |
|     1      | 0.2322 | 0.1496 | 0.2715 | 0.3208 |  0.3865 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:31:14,842: Snapshot:2	Epoch:0	Loss:5.5	translation_Loss:4.268	token_training_loss:0.0	distillation_Loss:1.232                                                   	MRR:21.43	Hits@10:37.15	Best:21.43
2025-01-06 18:31:22,861: Snapshot:2	Epoch:1	Loss:4.531	translation_Loss:3.371	token_training_loss:0.0	distillation_Loss:1.16                                                   	MRR:21.75	Hits@10:37.49	Best:21.75
2025-01-06 18:31:30,938: Snapshot:2	Epoch:2	Loss:4.119	translation_Loss:3.113	token_training_loss:0.0	distillation_Loss:1.007                                                   	MRR:21.79	Hits@10:37.59	Best:21.79
2025-01-06 18:31:39,456: Snapshot:2	Epoch:3	Loss:4.055	translation_Loss:3.024	token_training_loss:0.0	distillation_Loss:1.031                                                   	MRR:21.82	Hits@10:37.65	Best:21.82
2025-01-06 18:31:47,497: Snapshot:2	Epoch:4	Loss:4.019	translation_Loss:3.01	token_training_loss:0.0	distillation_Loss:1.009                                                   	MRR:21.87	Hits@10:37.65	Best:21.87
2025-01-06 18:31:55,883: Snapshot:2	Epoch:5	Loss:4.012	translation_Loss:2.988	token_training_loss:0.0	distillation_Loss:1.023                                                   	MRR:21.84	Hits@10:37.63	Best:21.87
2025-01-06 18:32:03,872: Snapshot:2	Epoch:6	Loss:4.001	translation_Loss:2.989	token_training_loss:0.0	distillation_Loss:1.012                                                   	MRR:21.86	Hits@10:37.72	Best:21.87
2025-01-06 18:32:11,982: Snapshot:2	Epoch:7	Loss:3.996	translation_Loss:2.976	token_training_loss:0.0	distillation_Loss:1.02                                                   	MRR:21.89	Hits@10:37.6	Best:21.89
2025-01-06 18:32:20,473: Snapshot:2	Epoch:8	Loss:4.0	translation_Loss:2.986	token_training_loss:0.0	distillation_Loss:1.015                                                   	MRR:21.83	Hits@10:37.69	Best:21.89
2025-01-06 18:32:28,512: Snapshot:2	Epoch:9	Loss:3.991	translation_Loss:2.964	token_training_loss:0.0	distillation_Loss:1.027                                                   	MRR:21.89	Hits@10:37.72	Best:21.89
2025-01-06 18:32:36,891: Early Stopping! Snapshot: 2 Epoch: 10 Best Results: 21.89
2025-01-06 18:32:36,891: Start to training tokens! Snapshot: 2 Epoch: 10 Loss:3.992 MRR:21.79 Best Results: 21.89
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:32:36,892: Snapshot:2	Epoch:10	Loss:3.992	translation_Loss:2.971	token_training_loss:0.0	distillation_Loss:1.021                                                   	MRR:21.79	Hits@10:37.78	Best:21.89
2025-01-06 18:32:44,950: Snapshot:2	Epoch:11	Loss:30.693	translation_Loss:14.497	token_training_loss:16.196	distillation_Loss:0.0                                                   	MRR:21.79	Hits@10:37.78	Best:21.89
2025-01-06 18:32:52,814: End of token training: 2 Epoch: 12 Loss:14.818 MRR:21.79 Best Results: 21.89
2025-01-06 18:32:52,814: Snapshot:2	Epoch:12	Loss:14.818	translation_Loss:14.479	token_training_loss:0.339	distillation_Loss:0.0                                                           	MRR:21.79	Hits@10:37.78	Best:21.89
2025-01-06 18:32:53,087: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2025-01-06 18:33:03,211: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.253  | 0.1643 | 0.2927 | 0.3494 |  0.4203 |
|     1      | 0.2356 | 0.1515 | 0.2735 | 0.3265 |  0.3948 |
|     2      | 0.2188 | 0.136  | 0.2543 | 0.3083 |  0.3741 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:33:18,687: Snapshot:3	Epoch:0	Loss:3.939	translation_Loss:2.809	token_training_loss:0.0	distillation_Loss:1.13                                                   	MRR:19.38	Hits@10:36.62	Best:19.38
2025-01-06 18:33:26,808: Snapshot:3	Epoch:1	Loss:3.256	translation_Loss:2.168	token_training_loss:0.0	distillation_Loss:1.088                                                   	MRR:19.8	Hits@10:36.87	Best:19.8
2025-01-06 18:33:34,906: Snapshot:3	Epoch:2	Loss:3.068	translation_Loss:2.101	token_training_loss:0.0	distillation_Loss:0.968                                                   	MRR:19.72	Hits@10:36.88	Best:19.8
2025-01-06 18:33:43,595: Snapshot:3	Epoch:3	Loss:3.047	translation_Loss:2.067	token_training_loss:0.0	distillation_Loss:0.979                                                   	MRR:19.81	Hits@10:37.09	Best:19.81
2025-01-06 18:33:51,645: Snapshot:3	Epoch:4	Loss:3.043	translation_Loss:2.069	token_training_loss:0.0	distillation_Loss:0.974                                                   	MRR:19.69	Hits@10:36.87	Best:19.81
2025-01-06 18:34:00,150: Snapshot:3	Epoch:5	Loss:3.042	translation_Loss:2.057	token_training_loss:0.0	distillation_Loss:0.985                                                   	MRR:19.86	Hits@10:36.88	Best:19.86
2025-01-06 18:34:08,263: Snapshot:3	Epoch:6	Loss:3.043	translation_Loss:2.066	token_training_loss:0.0	distillation_Loss:0.977                                                   	MRR:19.81	Hits@10:36.97	Best:19.86
2025-01-06 18:34:16,362: Snapshot:3	Epoch:7	Loss:3.051	translation_Loss:2.059	token_training_loss:0.0	distillation_Loss:0.992                                                   	MRR:19.9	Hits@10:36.87	Best:19.9
2025-01-06 18:34:24,789: Snapshot:3	Epoch:8	Loss:3.053	translation_Loss:2.065	token_training_loss:0.0	distillation_Loss:0.988                                                   	MRR:19.9	Hits@10:36.99	Best:19.9
2025-01-06 18:34:32,871: Snapshot:3	Epoch:9	Loss:3.053	translation_Loss:2.065	token_training_loss:0.0	distillation_Loss:0.989                                                   	MRR:19.77	Hits@10:36.88	Best:19.9
2025-01-06 18:34:41,433: Early Stopping! Snapshot: 3 Epoch: 10 Best Results: 19.9
2025-01-06 18:34:41,433: Start to training tokens! Snapshot: 3 Epoch: 10 Loss:3.054 MRR:19.85 Best Results: 19.9
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:34:41,434: Snapshot:3	Epoch:10	Loss:3.054	translation_Loss:2.062	token_training_loss:0.0	distillation_Loss:0.992                                                   	MRR:19.85	Hits@10:36.84	Best:19.9
2025-01-06 18:34:49,364: Snapshot:3	Epoch:11	Loss:29.131	translation_Loss:13.951	token_training_loss:15.18	distillation_Loss:0.0                                                   	MRR:19.85	Hits@10:36.84	Best:19.9
2025-01-06 18:34:57,797: End of token training: 3 Epoch: 12 Loss:14.253 MRR:19.85 Best Results: 19.9
2025-01-06 18:34:57,797: Snapshot:3	Epoch:12	Loss:14.253	translation_Loss:13.929	token_training_loss:0.325	distillation_Loss:0.0                                                           	MRR:19.85	Hits@10:36.84	Best:19.9
2025-01-06 18:34:58,070: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2025-01-06 18:35:11,545: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2469 | 0.1588 | 0.2844 | 0.342  |  0.4137 |
|     1      | 0.2323 | 0.1484 | 0.2692 | 0.3221 |  0.3914 |
|     2      | 0.2182 | 0.1328 | 0.2547 | 0.3089 |  0.3809 |
|     3      | 0.2003 | 0.1136 | 0.2308 | 0.291  |  0.3726 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:35:26,807: Snapshot:4	Epoch:0	Loss:2.445	translation_Loss:1.648	token_training_loss:0.0	distillation_Loss:0.797                                                   	MRR:20.6	Hits@10:44.59	Best:20.6
2025-01-06 18:35:35,371: Snapshot:4	Epoch:1	Loss:1.568	translation_Loss:0.877	token_training_loss:0.0	distillation_Loss:0.692                                                   	MRR:20.84	Hits@10:43.75	Best:20.84
2025-01-06 18:35:43,602: Snapshot:4	Epoch:2	Loss:1.389	translation_Loss:0.755	token_training_loss:0.0	distillation_Loss:0.635                                                   	MRR:21.06	Hits@10:43.99	Best:21.06
2025-01-06 18:35:52,141: Snapshot:4	Epoch:3	Loss:1.362	translation_Loss:0.727	token_training_loss:0.0	distillation_Loss:0.634                                                   	MRR:20.79	Hits@10:43.86	Best:21.06
2025-01-06 18:36:00,239: Snapshot:4	Epoch:4	Loss:1.352	translation_Loss:0.722	token_training_loss:0.0	distillation_Loss:0.63                                                   	MRR:20.85	Hits@10:43.97	Best:21.06
2025-01-06 18:36:08,434: Snapshot:4	Epoch:5	Loss:1.355	translation_Loss:0.713	token_training_loss:0.0	distillation_Loss:0.642                                                   	MRR:21.17	Hits@10:44.0	Best:21.17
2025-01-06 18:36:16,974: Snapshot:4	Epoch:6	Loss:1.351	translation_Loss:0.714	token_training_loss:0.0	distillation_Loss:0.637                                                   	MRR:20.94	Hits@10:43.77	Best:21.17
2025-01-06 18:36:25,060: Snapshot:4	Epoch:7	Loss:1.36	translation_Loss:0.718	token_training_loss:0.0	distillation_Loss:0.642                                                   	MRR:20.87	Hits@10:43.95	Best:21.17
2025-01-06 18:36:33,573: Early Stopping! Snapshot: 4 Epoch: 8 Best Results: 21.17
2025-01-06 18:36:33,574: Start to training tokens! Snapshot: 4 Epoch: 8 Loss:1.346 MRR:21.15 Best Results: 21.17
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:36:33,574: Snapshot:4	Epoch:8	Loss:1.346	translation_Loss:0.711	token_training_loss:0.0	distillation_Loss:0.636                                                   	MRR:21.15	Hits@10:44.18	Best:21.17
2025-01-06 18:36:41,670: Snapshot:4	Epoch:9	Loss:27.438	translation_Loss:11.626	token_training_loss:15.811	distillation_Loss:0.0                                                   	MRR:21.15	Hits@10:44.18	Best:21.17
2025-01-06 18:36:49,626: End of token training: 4 Epoch: 10 Loss:11.991 MRR:21.15 Best Results: 21.17
2025-01-06 18:36:49,626: Snapshot:4	Epoch:10	Loss:11.991	translation_Loss:11.639	token_training_loss:0.352	distillation_Loss:0.0                                                           	MRR:21.15	Hits@10:44.18	Best:21.17
2025-01-06 18:36:49,901: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2025-01-06 18:37:07,398: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2415 | 0.1554 | 0.2765 | 0.3318 |  0.4033 |
|     1      | 0.2254 | 0.1434 | 0.259  | 0.3108 |  0.3819 |
|     2      | 0.2134 | 0.1299 | 0.2462 | 0.3027 |  0.375  |
|     3      | 0.1985 | 0.111  | 0.2253 | 0.289  |  0.3766 |
|     4      | 0.2127 | 0.1033 | 0.2491 | 0.3287 |  0.4375 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 18:37:07,400: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2413 | 0.157  | 0.2824 | 0.3323 |  0.3932 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2529 | 0.1638 | 0.2946 | 0.348  |  0.4187 |
|     1      | 0.2322 | 0.1496 | 0.2715 | 0.3208 |  0.3865 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.253  | 0.1643 | 0.2927 | 0.3494 |  0.4203 |
|     1      | 0.2356 | 0.1515 | 0.2735 | 0.3265 |  0.3948 |
|     2      | 0.2188 | 0.136  | 0.2543 | 0.3083 |  0.3741 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2469 | 0.1588 | 0.2844 | 0.342  |  0.4137 |
|     1      | 0.2323 | 0.1484 | 0.2692 | 0.3221 |  0.3914 |
|     2      | 0.2182 | 0.1328 | 0.2547 | 0.3089 |  0.3809 |
|     3      | 0.2003 | 0.1136 | 0.2308 | 0.291  |  0.3726 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2415 | 0.1554 | 0.2765 | 0.3318 |  0.4033 |
|     1      | 0.2254 | 0.1434 | 0.259  | 0.3108 |  0.3819 |
|     2      | 0.2134 | 0.1299 | 0.2462 | 0.3027 |  0.375  |
|     3      | 0.1985 | 0.111  | 0.2253 | 0.289  |  0.3766 |
|     4      | 0.2127 | 0.1033 | 0.2491 | 0.3287 |  0.4375 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 18:37:07,401: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 167.65643739700317 |   0.241   |    0.157     |    0.282     |     0.393     |
|    1     | 100.08109283447266 |   0.243   |    0.157     |    0.283     |     0.403     |
|    2     | 110.16312670707703 |   0.236   |    0.151     |    0.274     |     0.396     |
|    3     | 111.34434747695923 |   0.224   |    0.138     |     0.26     |      0.39     |
|    4     | 94.42702341079712  |   0.218   |    0.129     |    0.251     |     0.395     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 18:37:07,401: Sum_Training_Time:583.6720278263092
2025-01-06 18:37:07,401: Every_Training_Time:[167.65643739700317, 100.08109283447266, 110.16312670707703, 111.34434747695923, 94.42702341079712]
2025-01-06 18:37:07,401: Forward transfer: 0.17495 Backward transfer: -0.0034499999999999947
2025-01-06 18:37:29,599: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106183712/FACT', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=33, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[1000.0, 10000.0, 10000.0, 10000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:37:40,809: Snapshot:0	Epoch:0	Loss:17.025	translation_Loss:17.025	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.18	Hits@10:13.12	Best:6.18
2025-01-06 18:37:48,503: Snapshot:0	Epoch:1	Loss:11.955	translation_Loss:11.955	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:9.81	Hits@10:22.66	Best:9.81
2025-01-06 18:37:55,787: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:13.09	Hits@10:29.23	Best:13.09
2025-01-06 18:38:03,564: Snapshot:0	Epoch:3	Loss:6.146	translation_Loss:6.146	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.89	Hits@10:33.36	Best:15.89
2025-01-06 18:38:10,873: Snapshot:0	Epoch:4	Loss:4.353	translation_Loss:4.353	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.35	Hits@10:36.18	Best:18.35
2025-01-06 18:38:18,141: Snapshot:0	Epoch:5	Loss:3.063	translation_Loss:3.063	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:20.54	Hits@10:37.96	Best:20.54
2025-01-06 18:38:25,787: Snapshot:0	Epoch:6	Loss:2.148	translation_Loss:2.148	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:21.99	Hits@10:39.15	Best:21.99
2025-01-06 18:38:33,096: Snapshot:0	Epoch:7	Loss:1.501	translation_Loss:1.501	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.09	Hits@10:39.79	Best:23.09
2025-01-06 18:38:40,894: Snapshot:0	Epoch:8	Loss:1.08	translation_Loss:1.08	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.84	Hits@10:40.27	Best:23.84
2025-01-06 18:38:48,180: Snapshot:0	Epoch:9	Loss:0.787	translation_Loss:0.787	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.15	Hits@10:40.37	Best:24.15
2025-01-06 18:38:55,449: Snapshot:0	Epoch:10	Loss:0.601	translation_Loss:0.601	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.46	Hits@10:40.48	Best:24.46
2025-01-06 18:39:03,202: Snapshot:0	Epoch:11	Loss:0.487	translation_Loss:0.487	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.61	Hits@10:40.5	Best:24.61
2025-01-06 18:39:10,557: Snapshot:0	Epoch:12	Loss:0.409	translation_Loss:0.409	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.75	Hits@10:40.53	Best:24.75
2025-01-06 18:39:18,188: Snapshot:0	Epoch:13	Loss:0.338	translation_Loss:0.338	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.75	Hits@10:40.62	Best:24.75
2025-01-06 18:39:25,406: Snapshot:0	Epoch:14	Loss:0.3	translation_Loss:0.3	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.74	Hits@10:40.67	Best:24.75
2025-01-06 18:39:32,656: Snapshot:0	Epoch:15	Loss:0.262	translation_Loss:0.262	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.92	Hits@10:40.77	Best:24.92
2025-01-06 18:39:40,389: Snapshot:0	Epoch:16	Loss:0.244	translation_Loss:0.244	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.94	Hits@10:40.73	Best:24.94
2025-01-06 18:39:47,629: Snapshot:0	Epoch:17	Loss:0.22	translation_Loss:0.22	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.86	Hits@10:40.57	Best:24.94
2025-01-06 18:39:55,329: Snapshot:0	Epoch:18	Loss:0.206	translation_Loss:0.206	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.81	Hits@10:40.35	Best:24.94
2025-01-06 18:40:02,587: Early Stopping! Snapshot: 0 Epoch: 19 Best Results: 24.94
2025-01-06 18:40:02,587: Start to training tokens! Snapshot: 0 Epoch: 19 Loss:0.188 MRR:24.83 Best Results: 24.94
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:40:02,588: Snapshot:0	Epoch:19	Loss:0.188	translation_Loss:0.188	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.83	Hits@10:40.51	Best:24.94
2025-01-06 18:40:10,553: Snapshot:0	Epoch:20	Loss:28.972	translation_Loss:12.248	token_training_loss:16.725	distillation_Loss:0.0                                                   	MRR:24.83	Hits@10:40.51	Best:24.94
2025-01-06 18:40:18,316: End of token training: 0 Epoch: 21 Loss:12.636 MRR:24.83 Best Results: 24.94
2025-01-06 18:40:18,316: Snapshot:0	Epoch:21	Loss:12.636	translation_Loss:12.259	token_training_loss:0.376	distillation_Loss:0.0                                                           	MRR:24.83	Hits@10:40.51	Best:24.94
2025-01-06 18:40:18,583: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2025-01-06 18:40:21,806: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2391 | 0.1545 | 0.2788 | 0.3296 |  0.3917 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:40:36,941: Snapshot:1	Epoch:0	Loss:7.663	translation_Loss:7.123	token_training_loss:0.0	distillation_Loss:0.54                                                   	MRR:20.5	Hits@10:34.6	Best:20.5
2025-01-06 18:40:44,991: Snapshot:1	Epoch:1	Loss:4.501	translation_Loss:3.332	token_training_loss:0.0	distillation_Loss:1.169                                                   	MRR:22.19	Hits@10:36.69	Best:22.19
2025-01-06 18:40:53,319: Snapshot:1	Epoch:2	Loss:3.478	translation_Loss:2.066	token_training_loss:0.0	distillation_Loss:1.412                                                   	MRR:22.78	Hits@10:37.54	Best:22.78
2025-01-06 18:41:01,336: Snapshot:1	Epoch:3	Loss:3.146	translation_Loss:1.646	token_training_loss:0.0	distillation_Loss:1.5                                                   	MRR:23.09	Hits@10:37.94	Best:23.09
2025-01-06 18:41:09,296: Snapshot:1	Epoch:4	Loss:3.008	translation_Loss:1.473	token_training_loss:0.0	distillation_Loss:1.535                                                   	MRR:23.13	Hits@10:38.08	Best:23.13
2025-01-06 18:41:17,714: Snapshot:1	Epoch:5	Loss:2.962	translation_Loss:1.398	token_training_loss:0.0	distillation_Loss:1.564                                                   	MRR:23.15	Hits@10:38.03	Best:23.15
2025-01-06 18:41:25,640: Snapshot:1	Epoch:6	Loss:2.932	translation_Loss:1.35	token_training_loss:0.0	distillation_Loss:1.582                                                   	MRR:23.29	Hits@10:38.28	Best:23.29
2025-01-06 18:41:33,963: Snapshot:1	Epoch:7	Loss:2.919	translation_Loss:1.328	token_training_loss:0.0	distillation_Loss:1.591                                                   	MRR:23.19	Hits@10:38.36	Best:23.29
2025-01-06 18:41:41,924: Snapshot:1	Epoch:8	Loss:2.909	translation_Loss:1.312	token_training_loss:0.0	distillation_Loss:1.597                                                   	MRR:23.24	Hits@10:38.32	Best:23.29
2025-01-06 18:41:49,844: Early Stopping! Snapshot: 1 Epoch: 9 Best Results: 23.29
2025-01-06 18:41:49,844: Start to training tokens! Snapshot: 1 Epoch: 9 Loss:2.908 MRR:23.16 Best Results: 23.29
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:41:49,844: Snapshot:1	Epoch:9	Loss:2.908	translation_Loss:1.295	token_training_loss:0.0	distillation_Loss:1.612                                                   	MRR:23.16	Hits@10:38.32	Best:23.29
2025-01-06 18:41:57,986: Snapshot:1	Epoch:10	Loss:30.046	translation_Loss:13.473	token_training_loss:16.573	distillation_Loss:0.0                                                   	MRR:23.16	Hits@10:38.32	Best:23.29
2025-01-06 18:42:05,745: End of token training: 1 Epoch: 11 Loss:13.815 MRR:23.16 Best Results: 23.29
2025-01-06 18:42:05,746: Snapshot:1	Epoch:11	Loss:13.815	translation_Loss:13.451	token_training_loss:0.364	distillation_Loss:0.0                                                           	MRR:23.16	Hits@10:38.32	Best:23.29
2025-01-06 18:42:06,013: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2025-01-06 18:42:12,919: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2518 | 0.1618 | 0.2927 | 0.3493 |  0.4192 |
|     1      | 0.2317 | 0.1482 | 0.2708 | 0.321  |  0.3859 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:42:28,660: Snapshot:2	Epoch:0	Loss:5.457	translation_Loss:4.231	token_training_loss:0.0	distillation_Loss:1.227                                                   	MRR:21.36	Hits@10:37.03	Best:21.36
2025-01-06 18:42:36,740: Snapshot:2	Epoch:1	Loss:4.509	translation_Loss:3.357	token_training_loss:0.0	distillation_Loss:1.152                                                   	MRR:21.73	Hits@10:37.35	Best:21.73
2025-01-06 18:42:45,103: Snapshot:2	Epoch:2	Loss:4.109	translation_Loss:3.097	token_training_loss:0.0	distillation_Loss:1.013                                                   	MRR:21.85	Hits@10:37.63	Best:21.85
2025-01-06 18:42:53,667: Snapshot:2	Epoch:3	Loss:4.016	translation_Loss:2.988	token_training_loss:0.0	distillation_Loss:1.028                                                   	MRR:21.86	Hits@10:37.55	Best:21.86
2025-01-06 18:43:01,744: Snapshot:2	Epoch:4	Loss:3.987	translation_Loss:2.984	token_training_loss:0.0	distillation_Loss:1.003                                                   	MRR:21.88	Hits@10:37.52	Best:21.88
2025-01-06 18:43:10,237: Snapshot:2	Epoch:5	Loss:3.965	translation_Loss:2.948	token_training_loss:0.0	distillation_Loss:1.018                                                   	MRR:21.86	Hits@10:37.48	Best:21.88
2025-01-06 18:43:18,320: Snapshot:2	Epoch:6	Loss:3.958	translation_Loss:2.951	token_training_loss:0.0	distillation_Loss:1.008                                                   	MRR:21.91	Hits@10:37.55	Best:21.91
2025-01-06 18:43:26,380: Snapshot:2	Epoch:7	Loss:3.963	translation_Loss:2.941	token_training_loss:0.0	distillation_Loss:1.022                                                   	MRR:21.86	Hits@10:37.51	Best:21.91
2025-01-06 18:43:34,914: Snapshot:2	Epoch:8	Loss:3.971	translation_Loss:2.956	token_training_loss:0.0	distillation_Loss:1.016                                                   	MRR:21.92	Hits@10:37.61	Best:21.92
2025-01-06 18:43:43,035: Snapshot:2	Epoch:9	Loss:3.962	translation_Loss:2.942	token_training_loss:0.0	distillation_Loss:1.02                                                   	MRR:21.84	Hits@10:37.51	Best:21.92
2025-01-06 18:43:51,518: Snapshot:2	Epoch:10	Loss:3.964	translation_Loss:2.947	token_training_loss:0.0	distillation_Loss:1.017                                                   	MRR:21.81	Hits@10:37.56	Best:21.92
2025-01-06 18:43:59,530: Early Stopping! Snapshot: 2 Epoch: 11 Best Results: 21.92
2025-01-06 18:43:59,530: Start to training tokens! Snapshot: 2 Epoch: 11 Loss:3.948 MRR:21.92 Best Results: 21.92
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:43:59,530: Snapshot:2	Epoch:11	Loss:3.948	translation_Loss:2.925	token_training_loss:0.0	distillation_Loss:1.023                                                   	MRR:21.92	Hits@10:37.37	Best:21.92
2025-01-06 18:44:07,538: Snapshot:2	Epoch:12	Loss:29.764	translation_Loss:14.392	token_training_loss:15.372	distillation_Loss:0.0                                                   	MRR:21.92	Hits@10:37.37	Best:21.92
2025-01-06 18:44:15,991: End of token training: 2 Epoch: 13 Loss:14.709 MRR:21.92 Best Results: 21.92
2025-01-06 18:44:15,992: Snapshot:2	Epoch:13	Loss:14.709	translation_Loss:14.39	token_training_loss:0.319	distillation_Loss:0.0                                                           	MRR:21.92	Hits@10:37.37	Best:21.92
2025-01-06 18:44:16,267: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2025-01-06 18:44:25,991: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2513 | 0.1615 | 0.2917 | 0.3471 |  0.4182 |
|     1      | 0.2346 |  0.15  | 0.2731 | 0.3252 |  0.3915 |
|     2      | 0.2171 | 0.1335 | 0.253  | 0.3082 |  0.3741 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:44:41,635: Snapshot:3	Epoch:0	Loss:3.891	translation_Loss:2.772	token_training_loss:0.0	distillation_Loss:1.12                                                   	MRR:19.39	Hits@10:36.69	Best:19.39
2025-01-06 18:44:49,824: Snapshot:3	Epoch:1	Loss:3.191	translation_Loss:2.118	token_training_loss:0.0	distillation_Loss:1.073                                                   	MRR:19.57	Hits@10:36.86	Best:19.57
2025-01-06 18:44:58,424: Snapshot:3	Epoch:2	Loss:3.031	translation_Loss:2.077	token_training_loss:0.0	distillation_Loss:0.954                                                   	MRR:19.6	Hits@10:36.93	Best:19.6
2025-01-06 18:45:06,635: Snapshot:3	Epoch:3	Loss:3.001	translation_Loss:2.028	token_training_loss:0.0	distillation_Loss:0.974                                                   	MRR:19.64	Hits@10:36.9	Best:19.64
2025-01-06 18:45:14,836: Snapshot:3	Epoch:4	Loss:3.002	translation_Loss:2.035	token_training_loss:0.0	distillation_Loss:0.967                                                   	MRR:19.75	Hits@10:36.94	Best:19.75
2025-01-06 18:45:23,311: Snapshot:3	Epoch:5	Loss:3.001	translation_Loss:2.029	token_training_loss:0.0	distillation_Loss:0.972                                                   	MRR:19.7	Hits@10:36.94	Best:19.75
2025-01-06 18:45:31,472: Snapshot:3	Epoch:6	Loss:3.005	translation_Loss:2.033	token_training_loss:0.0	distillation_Loss:0.972                                                   	MRR:19.64	Hits@10:36.95	Best:19.75
2025-01-06 18:45:40,007: Early Stopping! Snapshot: 3 Epoch: 7 Best Results: 19.75
2025-01-06 18:45:40,007: Start to training tokens! Snapshot: 3 Epoch: 7 Loss:2.997 MRR:19.63 Best Results: 19.75
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:45:40,008: Snapshot:3	Epoch:7	Loss:2.997	translation_Loss:2.013	token_training_loss:0.0	distillation_Loss:0.983                                                   	MRR:19.63	Hits@10:36.83	Best:19.75
2025-01-06 18:45:48,116: Snapshot:3	Epoch:8	Loss:30.567	translation_Loss:13.852	token_training_loss:16.715	distillation_Loss:0.0                                                   	MRR:19.63	Hits@10:36.83	Best:19.75
2025-01-06 18:45:56,533: End of token training: 3 Epoch: 9 Loss:14.229 MRR:19.63 Best Results: 19.75
2025-01-06 18:45:56,534: Snapshot:3	Epoch:9	Loss:14.229	translation_Loss:13.858	token_training_loss:0.372	distillation_Loss:0.0                                                           	MRR:19.63	Hits@10:36.83	Best:19.75
2025-01-06 18:45:56,809: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2025-01-06 18:46:10,298: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2462 | 0.1582 | 0.2836 | 0.3384 |  0.4129 |
|     1      | 0.2309 | 0.1463 | 0.267  | 0.3207 |  0.3911 |
|     2      | 0.2172 | 0.1313 | 0.252  | 0.3101 |  0.3803 |
|     3      | 0.1986 | 0.1127 | 0.2293 | 0.2882 |  0.3714 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:46:25,571: Snapshot:4	Epoch:0	Loss:2.389	translation_Loss:1.606	token_training_loss:0.0	distillation_Loss:0.783                                                   	MRR:20.4	Hits@10:44.12	Best:20.4
2025-01-06 18:46:34,162: Snapshot:4	Epoch:1	Loss:1.533	translation_Loss:0.848	token_training_loss:0.0	distillation_Loss:0.685                                                   	MRR:20.72	Hits@10:43.77	Best:20.72
2025-01-06 18:46:42,463: Snapshot:4	Epoch:2	Loss:1.354	translation_Loss:0.739	token_training_loss:0.0	distillation_Loss:0.615                                                   	MRR:21.03	Hits@10:44.08	Best:21.03
2025-01-06 18:46:51,038: Snapshot:4	Epoch:3	Loss:1.328	translation_Loss:0.702	token_training_loss:0.0	distillation_Loss:0.625                                                   	MRR:20.97	Hits@10:44.1	Best:21.03
2025-01-06 18:46:59,181: Snapshot:4	Epoch:4	Loss:1.32	translation_Loss:0.708	token_training_loss:0.0	distillation_Loss:0.611                                                   	MRR:20.93	Hits@10:43.91	Best:21.03
2025-01-06 18:47:07,367: Early Stopping! Snapshot: 4 Epoch: 5 Best Results: 21.03
2025-01-06 18:47:07,368: Start to training tokens! Snapshot: 4 Epoch: 5 Loss:1.32 MRR:20.86 Best Results: 21.03
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:47:07,368: Snapshot:4	Epoch:5	Loss:1.32	translation_Loss:0.698	token_training_loss:0.0	distillation_Loss:0.622                                                   	MRR:20.86	Hits@10:43.91	Best:21.03
2025-01-06 18:47:15,924: Snapshot:4	Epoch:6	Loss:27.496	translation_Loss:11.543	token_training_loss:15.953	distillation_Loss:0.0                                                   	MRR:20.86	Hits@10:43.91	Best:21.03
2025-01-06 18:47:24,036: End of token training: 4 Epoch: 7 Loss:11.883 MRR:20.86 Best Results: 21.03
2025-01-06 18:47:24,036: Snapshot:4	Epoch:7	Loss:11.883	translation_Loss:11.529	token_training_loss:0.354	distillation_Loss:0.0                                                           	MRR:20.86	Hits@10:43.91	Best:21.03
2025-01-06 18:47:24,309: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2025-01-06 18:47:41,815: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2407 | 0.1543 | 0.2764 | 0.3306 |  0.4057 |
|     1      | 0.2233 | 0.1403 | 0.2568 | 0.3096 |  0.3827 |
|     2      | 0.2114 | 0.1277 | 0.2416 | 0.2992 |  0.3767 |
|     3      | 0.1948 | 0.1067 | 0.2229 | 0.2853 |  0.3767 |
|     4      | 0.2087 | 0.0998 | 0.243  | 0.3265 |  0.4368 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 18:47:41,818: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2391 | 0.1545 | 0.2788 | 0.3296 |  0.3917 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2518 | 0.1618 | 0.2927 | 0.3493 |  0.4192 |
|     1      | 0.2317 | 0.1482 | 0.2708 | 0.321  |  0.3859 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2513 | 0.1615 | 0.2917 | 0.3471 |  0.4182 |
|     1      | 0.2346 |  0.15  | 0.2731 | 0.3252 |  0.3915 |
|     2      | 0.2171 | 0.1335 | 0.253  | 0.3082 |  0.3741 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2462 | 0.1582 | 0.2836 | 0.3384 |  0.4129 |
|     1      | 0.2309 | 0.1463 | 0.267  | 0.3207 |  0.3911 |
|     2      | 0.2172 | 0.1313 | 0.252  | 0.3101 |  0.3803 |
|     3      | 0.1986 | 0.1127 | 0.2293 | 0.2882 |  0.3714 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2407 | 0.1543 | 0.2764 | 0.3306 |  0.4057 |
|     1      | 0.2233 | 0.1403 | 0.2568 | 0.3096 |  0.3827 |
|     2      | 0.2114 | 0.1277 | 0.2416 | 0.2992 |  0.3767 |
|     3      | 0.1948 | 0.1067 | 0.2229 | 0.2853 |  0.3767 |
|     4      | 0.2087 | 0.0998 | 0.243  | 0.3265 |  0.4368 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 18:47:41,818: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 168.71599411964417 |   0.239   |    0.154     |    0.279     |     0.392     |
|    1     | 100.60620713233948 |   0.242   |    0.155     |    0.282     |     0.403     |
|    2     | 119.58752632141113 |   0.234   |    0.148     |    0.273     |     0.395     |
|    3     | 86.97007918357849  |   0.223   |    0.137     |    0.258     |     0.389     |
|    4     | 70.09529447555542  |   0.216   |    0.126     |    0.248     |     0.396     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 18:47:41,818: Sum_Training_Time:545.9751012325287
2025-01-06 18:47:41,818: Every_Training_Time:[168.71599411964417, 100.60620713233948, 119.58752632141113, 86.97007918357849, 70.09529447555542]
2025-01-06 18:47:41,819: Forward transfer: 0.173875 Backward transfer: -0.004074999999999995
2025-01-06 18:48:03,862: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106184747/FACT', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=44, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[1000.0, 10000.0, 10000.0, 10000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:48:14,937: Snapshot:0	Epoch:0	Loss:17.035	translation_Loss:17.035	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.25	Hits@10:13.24	Best:6.25
2025-01-06 18:48:22,578: Snapshot:0	Epoch:1	Loss:11.987	translation_Loss:11.987	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:9.73	Hits@10:22.72	Best:9.73
2025-01-06 18:48:29,874: Snapshot:0	Epoch:2	Loss:8.681	translation_Loss:8.681	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.9	Hits@10:29.14	Best:12.9
2025-01-06 18:48:37,608: Snapshot:0	Epoch:3	Loss:6.215	translation_Loss:6.215	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.96	Hits@10:33.54	Best:15.96
2025-01-06 18:48:44,914: Snapshot:0	Epoch:4	Loss:4.422	translation_Loss:4.422	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.49	Hits@10:36.42	Best:18.49
2025-01-06 18:48:52,213: Snapshot:0	Epoch:5	Loss:3.15	translation_Loss:3.15	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:20.54	Hits@10:38.05	Best:20.54
2025-01-06 18:48:59,841: Snapshot:0	Epoch:6	Loss:2.234	translation_Loss:2.234	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.2	Hits@10:39.13	Best:22.2
2025-01-06 18:49:07,094: Snapshot:0	Epoch:7	Loss:1.579	translation_Loss:1.579	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.22	Hits@10:39.69	Best:23.22
2025-01-06 18:49:14,821: Snapshot:0	Epoch:8	Loss:1.132	translation_Loss:1.132	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.98	Hits@10:40.35	Best:23.98
2025-01-06 18:49:22,082: Snapshot:0	Epoch:9	Loss:0.833	translation_Loss:0.833	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.48	Hits@10:40.59	Best:24.48
2025-01-06 18:49:29,289: Snapshot:0	Epoch:10	Loss:0.633	translation_Loss:0.633	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.65	Hits@10:40.47	Best:24.65
2025-01-06 18:49:37,018: Snapshot:0	Epoch:11	Loss:0.507	translation_Loss:0.507	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.86	Hits@10:40.6	Best:24.86
2025-01-06 18:49:44,301: Snapshot:0	Epoch:12	Loss:0.427	translation_Loss:0.427	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.8	Hits@10:40.5	Best:24.86
2025-01-06 18:49:51,901: Snapshot:0	Epoch:13	Loss:0.356	translation_Loss:0.356	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.9	Hits@10:40.46	Best:24.9
2025-01-06 18:49:59,085: Snapshot:0	Epoch:14	Loss:0.316	translation_Loss:0.316	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.89	Hits@10:40.43	Best:24.9
2025-01-06 18:50:06,402: Snapshot:0	Epoch:15	Loss:0.273	translation_Loss:0.273	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.9	Hits@10:40.52	Best:24.9
2025-01-06 18:50:14,255: Snapshot:0	Epoch:16	Loss:0.248	translation_Loss:0.248	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.93	Hits@10:40.52	Best:24.93
2025-01-06 18:50:21,499: Snapshot:0	Epoch:17	Loss:0.227	translation_Loss:0.227	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.94	Hits@10:40.57	Best:24.94
2025-01-06 18:50:29,148: Snapshot:0	Epoch:18	Loss:0.206	translation_Loss:0.206	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.93	Hits@10:40.52	Best:24.94
2025-01-06 18:50:36,348: Snapshot:0	Epoch:19	Loss:0.193	translation_Loss:0.193	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.91	Hits@10:40.56	Best:24.94
2025-01-06 18:50:43,633: Early Stopping! Snapshot: 0 Epoch: 20 Best Results: 24.94
2025-01-06 18:50:43,633: Start to training tokens! Snapshot: 0 Epoch: 20 Loss:0.179 MRR:24.93 Best Results: 24.94
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:50:43,634: Snapshot:0	Epoch:20	Loss:0.179	translation_Loss:0.179	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.93	Hits@10:40.46	Best:24.94
2025-01-06 18:50:51,874: Snapshot:0	Epoch:21	Loss:30.09	translation_Loss:12.282	token_training_loss:17.808	distillation_Loss:0.0                                                   	MRR:24.93	Hits@10:40.46	Best:24.94
2025-01-06 18:50:59,138: End of token training: 0 Epoch: 22 Loss:12.676 MRR:24.93 Best Results: 24.94
2025-01-06 18:50:59,138: Snapshot:0	Epoch:22	Loss:12.676	translation_Loss:12.285	token_training_loss:0.392	distillation_Loss:0.0                                                           	MRR:24.93	Hits@10:40.46	Best:24.94
2025-01-06 18:50:59,408: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2025-01-06 18:51:02,299: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2426 | 0.1582 | 0.2836 | 0.3306 |  0.394  |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:51:17,221: Snapshot:1	Epoch:0	Loss:7.64	translation_Loss:7.102	token_training_loss:0.0	distillation_Loss:0.538                                                   	MRR:20.61	Hits@10:34.69	Best:20.61
2025-01-06 18:51:25,501: Snapshot:1	Epoch:1	Loss:4.496	translation_Loss:3.333	token_training_loss:0.0	distillation_Loss:1.162                                                   	MRR:22.2	Hits@10:36.91	Best:22.2
2025-01-06 18:51:33,388: Snapshot:1	Epoch:2	Loss:3.481	translation_Loss:2.078	token_training_loss:0.0	distillation_Loss:1.403                                                   	MRR:22.79	Hits@10:37.64	Best:22.79
2025-01-06 18:51:41,747: Snapshot:1	Epoch:3	Loss:3.129	translation_Loss:1.639	token_training_loss:0.0	distillation_Loss:1.49                                                   	MRR:22.97	Hits@10:37.91	Best:22.97
2025-01-06 18:51:49,639: Snapshot:1	Epoch:4	Loss:3.005	translation_Loss:1.478	token_training_loss:0.0	distillation_Loss:1.527                                                   	MRR:23.03	Hits@10:37.94	Best:23.03
2025-01-06 18:51:58,000: Snapshot:1	Epoch:5	Loss:2.956	translation_Loss:1.404	token_training_loss:0.0	distillation_Loss:1.552                                                   	MRR:23.12	Hits@10:38.01	Best:23.12
2025-01-06 18:52:05,815: Snapshot:1	Epoch:6	Loss:2.924	translation_Loss:1.352	token_training_loss:0.0	distillation_Loss:1.572                                                   	MRR:23.07	Hits@10:38.15	Best:23.12
2025-01-06 18:52:13,705: Snapshot:1	Epoch:7	Loss:2.923	translation_Loss:1.339	token_training_loss:0.0	distillation_Loss:1.585                                                   	MRR:23.03	Hits@10:38.05	Best:23.12
2025-01-06 18:52:21,920: Early Stopping! Snapshot: 1 Epoch: 8 Best Results: 23.12
2025-01-06 18:52:21,920: Start to training tokens! Snapshot: 1 Epoch: 8 Loss:2.913 MRR:23.12 Best Results: 23.12
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:52:21,921: Snapshot:1	Epoch:8	Loss:2.913	translation_Loss:1.319	token_training_loss:0.0	distillation_Loss:1.594                                                   	MRR:23.12	Hits@10:38.08	Best:23.12
2025-01-06 18:52:29,643: Snapshot:1	Epoch:9	Loss:28.748	translation_Loss:13.512	token_training_loss:15.236	distillation_Loss:0.0                                                   	MRR:23.12	Hits@10:38.08	Best:23.12
2025-01-06 18:52:37,764: End of token training: 1 Epoch: 10 Loss:13.838 MRR:23.12 Best Results: 23.12
2025-01-06 18:52:37,764: Snapshot:1	Epoch:10	Loss:13.838	translation_Loss:13.515	token_training_loss:0.323	distillation_Loss:0.0                                                           	MRR:23.12	Hits@10:38.08	Best:23.12
2025-01-06 18:52:38,039: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2025-01-06 18:52:44,482: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2544 | 0.1648 | 0.2958 | 0.3516 |  0.4209 |
|     1      | 0.231  | 0.1485 | 0.2686 | 0.3184 |  0.3844 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:52:59,915: Snapshot:2	Epoch:0	Loss:5.474	translation_Loss:4.253	token_training_loss:0.0	distillation_Loss:1.221                                                   	MRR:21.27	Hits@10:36.88	Best:21.27
2025-01-06 18:53:07,975: Snapshot:2	Epoch:1	Loss:4.505	translation_Loss:3.35	token_training_loss:0.0	distillation_Loss:1.156                                                   	MRR:21.66	Hits@10:37.19	Best:21.66
2025-01-06 18:53:16,080: Snapshot:2	Epoch:2	Loss:4.113	translation_Loss:3.101	token_training_loss:0.0	distillation_Loss:1.012                                                   	MRR:21.77	Hits@10:37.38	Best:21.77
2025-01-06 18:53:24,626: Snapshot:2	Epoch:3	Loss:4.028	translation_Loss:3.001	token_training_loss:0.0	distillation_Loss:1.027                                                   	MRR:21.91	Hits@10:37.45	Best:21.91
2025-01-06 18:53:32,653: Snapshot:2	Epoch:4	Loss:3.996	translation_Loss:2.988	token_training_loss:0.0	distillation_Loss:1.008                                                   	MRR:21.85	Hits@10:37.46	Best:21.91
2025-01-06 18:53:41,084: Snapshot:2	Epoch:5	Loss:3.979	translation_Loss:2.961	token_training_loss:0.0	distillation_Loss:1.018                                                   	MRR:21.85	Hits@10:37.36	Best:21.91
2025-01-06 18:53:49,082: Early Stopping! Snapshot: 2 Epoch: 6 Best Results: 21.91
2025-01-06 18:53:49,082: Start to training tokens! Snapshot: 2 Epoch: 6 Loss:3.969 MRR:21.73 Best Results: 21.91
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:53:49,082: Snapshot:2	Epoch:6	Loss:3.969	translation_Loss:2.957	token_training_loss:0.0	distillation_Loss:1.013                                                   	MRR:21.73	Hits@10:37.45	Best:21.91
2025-01-06 18:53:56,957: Snapshot:2	Epoch:7	Loss:29.951	translation_Loss:14.439	token_training_loss:15.512	distillation_Loss:0.0                                                   	MRR:21.73	Hits@10:37.45	Best:21.91
2025-01-06 18:54:05,214: End of token training: 2 Epoch: 8 Loss:14.777 MRR:21.73 Best Results: 21.91
2025-01-06 18:54:05,214: Snapshot:2	Epoch:8	Loss:14.777	translation_Loss:14.442	token_training_loss:0.335	distillation_Loss:0.0                                                           	MRR:21.73	Hits@10:37.45	Best:21.91
2025-01-06 18:54:05,486: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2025-01-06 18:54:15,966: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2541 | 0.1649 | 0.2943 | 0.3486 |  0.4213 |
|     1      | 0.2335 | 0.1493 |  0.27  | 0.3243 |  0.3923 |
|     2      | 0.2182 | 0.136  | 0.2523 | 0.3048 |  0.3752 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:54:31,508: Snapshot:3	Epoch:0	Loss:3.911	translation_Loss:2.781	token_training_loss:0.0	distillation_Loss:1.13                                                   	MRR:19.51	Hits@10:37.32	Best:19.51
2025-01-06 18:54:39,689: Snapshot:3	Epoch:1	Loss:3.216	translation_Loss:2.127	token_training_loss:0.0	distillation_Loss:1.089                                                   	MRR:19.64	Hits@10:37.42	Best:19.64
2025-01-06 18:54:48,210: Snapshot:3	Epoch:2	Loss:3.06	translation_Loss:2.085	token_training_loss:0.0	distillation_Loss:0.976                                                   	MRR:19.76	Hits@10:37.42	Best:19.76
2025-01-06 18:54:56,393: Snapshot:3	Epoch:3	Loss:3.03	translation_Loss:2.034	token_training_loss:0.0	distillation_Loss:0.997                                                   	MRR:19.79	Hits@10:37.42	Best:19.79
2025-01-06 18:55:04,504: Snapshot:3	Epoch:4	Loss:3.019	translation_Loss:2.037	token_training_loss:0.0	distillation_Loss:0.982                                                   	MRR:19.79	Hits@10:37.41	Best:19.79
2025-01-06 18:55:13,098: Snapshot:3	Epoch:5	Loss:3.01	translation_Loss:2.019	token_training_loss:0.0	distillation_Loss:0.991                                                   	MRR:19.79	Hits@10:37.53	Best:19.79
2025-01-06 18:55:21,151: Early Stopping! Snapshot: 3 Epoch: 6 Best Results: 19.79
2025-01-06 18:55:21,151: Start to training tokens! Snapshot: 3 Epoch: 6 Loss:3.024 MRR:19.75 Best Results: 19.79
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:55:21,152: Snapshot:3	Epoch:6	Loss:3.024	translation_Loss:2.035	token_training_loss:0.0	distillation_Loss:0.988                                                   	MRR:19.75	Hits@10:37.5	Best:19.79
2025-01-06 18:55:29,528: Snapshot:3	Epoch:7	Loss:29.708	translation_Loss:13.849	token_training_loss:15.86	distillation_Loss:0.0                                                   	MRR:19.75	Hits@10:37.5	Best:19.79
2025-01-06 18:55:37,493: End of token training: 3 Epoch: 8 Loss:14.219 MRR:19.75 Best Results: 19.79
2025-01-06 18:55:37,494: Snapshot:3	Epoch:8	Loss:14.219	translation_Loss:13.88	token_training_loss:0.339	distillation_Loss:0.0                                                           	MRR:19.75	Hits@10:37.5	Best:19.79
2025-01-06 18:55:37,798: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2025-01-06 18:55:51,442: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2483 | 0.1601 | 0.2856 | 0.3416 |  0.4159 |
|     1      | 0.2295 | 0.1455 | 0.2638 | 0.3195 |  0.3913 |
|     2      | 0.2175 | 0.1331 | 0.2498 | 0.3083 |  0.3834 |
|     3      | 0.1997 | 0.1124 | 0.2313 | 0.2898 |  0.3732 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:56:06,881: Snapshot:4	Epoch:0	Loss:2.429	translation_Loss:1.63	token_training_loss:0.0	distillation_Loss:0.799                                                   	MRR:20.3	Hits@10:44.04	Best:20.3
2025-01-06 18:56:15,472: Snapshot:4	Epoch:1	Loss:1.546	translation_Loss:0.846	token_training_loss:0.0	distillation_Loss:0.701                                                   	MRR:20.49	Hits@10:43.57	Best:20.49
2025-01-06 18:56:23,653: Snapshot:4	Epoch:2	Loss:1.377	translation_Loss:0.736	token_training_loss:0.0	distillation_Loss:0.641                                                   	MRR:20.74	Hits@10:44.25	Best:20.74
2025-01-06 18:56:32,220: Snapshot:4	Epoch:3	Loss:1.339	translation_Loss:0.706	token_training_loss:0.0	distillation_Loss:0.633                                                   	MRR:20.81	Hits@10:44.16	Best:20.81
2025-01-06 18:56:40,357: Snapshot:4	Epoch:4	Loss:1.332	translation_Loss:0.7	token_training_loss:0.0	distillation_Loss:0.632                                                   	MRR:20.51	Hits@10:43.93	Best:20.81
2025-01-06 18:56:48,462: Snapshot:4	Epoch:5	Loss:1.329	translation_Loss:0.692	token_training_loss:0.0	distillation_Loss:0.636                                                   	MRR:20.57	Hits@10:43.78	Best:20.81
2025-01-06 18:56:57,065: Snapshot:4	Epoch:6	Loss:1.343	translation_Loss:0.707	token_training_loss:0.0	distillation_Loss:0.637                                                   	MRR:20.85	Hits@10:44.01	Best:20.85
2025-01-06 18:57:05,185: Snapshot:4	Epoch:7	Loss:1.331	translation_Loss:0.691	token_training_loss:0.0	distillation_Loss:0.64                                                   	MRR:20.83	Hits@10:43.97	Best:20.85
2025-01-06 18:57:13,731: Snapshot:4	Epoch:8	Loss:1.333	translation_Loss:0.691	token_training_loss:0.0	distillation_Loss:0.642                                                   	MRR:20.49	Hits@10:43.76	Best:20.85
2025-01-06 18:57:21,859: Early Stopping! Snapshot: 4 Epoch: 9 Best Results: 20.85
2025-01-06 18:57:21,859: Start to training tokens! Snapshot: 4 Epoch: 9 Loss:1.333 MRR:20.73 Best Results: 20.85
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:57:21,860: Snapshot:4	Epoch:9	Loss:1.333	translation_Loss:0.697	token_training_loss:0.0	distillation_Loss:0.637                                                   	MRR:20.73	Hits@10:43.95	Best:20.85
2025-01-06 18:57:29,848: Snapshot:4	Epoch:10	Loss:28.201	translation_Loss:11.61	token_training_loss:16.591	distillation_Loss:0.0                                                   	MRR:20.73	Hits@10:43.95	Best:20.85
2025-01-06 18:57:38,217: End of token training: 4 Epoch: 11 Loss:11.966 MRR:20.73 Best Results: 20.85
2025-01-06 18:57:38,217: Snapshot:4	Epoch:11	Loss:11.966	translation_Loss:11.61	token_training_loss:0.356	distillation_Loss:0.0                                                           	MRR:20.73	Hits@10:43.95	Best:20.85
2025-01-06 18:57:38,486: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2025-01-06 18:57:56,089: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2422 | 0.1561 | 0.2784 | 0.3327 |  0.4054 |
|     1      | 0.223  | 0.1414 | 0.2543 | 0.3093 |  0.3818 |
|     2      | 0.2112 | 0.1285 | 0.2418 | 0.2971 |  0.3764 |
|     3      | 0.1958 | 0.1075 | 0.2233 | 0.287  |  0.3766 |
|     4      | 0.2097 | 0.1008 | 0.241  | 0.326  |  0.4397 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 18:57:56,091: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2426 | 0.1582 | 0.2836 | 0.3306 |  0.394  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2544 | 0.1648 | 0.2958 | 0.3516 |  0.4209 |
|     1      | 0.231  | 0.1485 | 0.2686 | 0.3184 |  0.3844 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2541 | 0.1649 | 0.2943 | 0.3486 |  0.4213 |
|     1      | 0.2335 | 0.1493 |  0.27  | 0.3243 |  0.3923 |
|     2      | 0.2182 | 0.136  | 0.2523 | 0.3048 |  0.3752 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2483 | 0.1601 | 0.2856 | 0.3416 |  0.4159 |
|     1      | 0.2295 | 0.1455 | 0.2638 | 0.3195 |  0.3913 |
|     2      | 0.2175 | 0.1331 | 0.2498 | 0.3083 |  0.3834 |
|     3      | 0.1997 | 0.1124 | 0.2313 | 0.2898 |  0.3732 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2422 | 0.1561 | 0.2784 | 0.3327 |  0.4054 |
|     1      | 0.223  | 0.1414 | 0.2543 | 0.3093 |  0.3818 |
|     2      | 0.2112 | 0.1285 | 0.2418 | 0.2971 |  0.3764 |
|     3      | 0.1958 | 0.1075 | 0.2233 | 0.287  |  0.3766 |
|     4      | 0.2097 | 0.1008 | 0.241  | 0.326  |  0.4397 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 18:57:56,092: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 175.27478218078613 |   0.243   |    0.158     |    0.284     |     0.394     |
|    1     | 92.16488671302795  |   0.243   |    0.157     |    0.282     |     0.403     |
|    2     | 77.21633887290955  |   0.235   |     0.15     |    0.272     |     0.396     |
|    3     | 77.95197820663452  |   0.224   |    0.138     |    0.258     |     0.391     |
|    4     | 103.19809889793396 |   0.216   |    0.127     |    0.248     |     0.396     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 18:57:56,092: Sum_Training_Time:525.8060848712921
2025-01-06 18:57:56,092: Every_Training_Time:[175.27478218078613, 92.16488671302795, 77.21633887290955, 77.95197820663452, 103.19809889793396]
2025-01-06 18:57:56,092: Forward transfer: 0.17427499999999999 Backward transfer: -0.004825000000000003
