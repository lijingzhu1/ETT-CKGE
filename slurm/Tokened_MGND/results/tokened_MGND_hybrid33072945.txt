2025-01-05 22:57:19,764: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250105225700/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 3000.0, 500.0, 200000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-05 22:57:28,652: Snapshot:0	Epoch:0	Loss:15.399	translation_Loss:15.399	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.3	Hits@10:18.01	Best:7.3
2025-01-05 22:57:34,470: Snapshot:0	Epoch:1	Loss:10.741	translation_Loss:10.741	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.4	Hits@10:31.07	Best:12.4
2025-01-05 22:57:39,965: Snapshot:0	Epoch:2	Loss:7.011	translation_Loss:7.011	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.94	Hits@10:39.69	Best:18.94
2025-01-05 22:57:45,507: Snapshot:0	Epoch:3	Loss:4.123	translation_Loss:4.123	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.69	Hits@10:43.52	Best:22.69
2025-01-05 22:57:51,478: Snapshot:0	Epoch:4	Loss:2.462	translation_Loss:2.462	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.22	Hits@10:45.29	Best:24.22
2025-01-05 22:57:57,053: Snapshot:0	Epoch:5	Loss:1.562	translation_Loss:1.562	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.02	Hits@10:45.94	Best:25.02
2025-01-05 22:58:02,841: Snapshot:0	Epoch:6	Loss:1.067	translation_Loss:1.067	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.33	Hits@10:46.24	Best:25.33
2025-01-05 22:58:08,214: Snapshot:0	Epoch:7	Loss:0.8	translation_Loss:0.8	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.65	Hits@10:46.58	Best:25.65
2025-01-05 22:58:13,938: Snapshot:0	Epoch:8	Loss:0.632	translation_Loss:0.632	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.74	Hits@10:46.57	Best:25.74
2025-01-05 22:58:19,471: Snapshot:0	Epoch:9	Loss:0.535	translation_Loss:0.535	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.8	Hits@10:46.5	Best:25.8
2025-01-05 22:58:25,275: Snapshot:0	Epoch:10	Loss:0.454	translation_Loss:0.454	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.76	Hits@10:46.26	Best:25.8
2025-01-05 22:58:30,741: Snapshot:0	Epoch:11	Loss:0.401	translation_Loss:0.401	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.74	Hits@10:46.25	Best:25.8
2025-01-05 22:58:36,423: Snapshot:0	Epoch:12	Loss:0.355	translation_Loss:0.355	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:46.21	Best:25.8
2025-01-05 22:58:41,798: Snapshot:0	Epoch:13	Loss:0.318	translation_Loss:0.318	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.8	Hits@10:46.2	Best:25.8
2025-01-05 22:58:47,318: Snapshot:0	Epoch:14	Loss:0.292	translation_Loss:0.292	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.83	Hits@10:46.05	Best:25.83
2025-01-05 22:58:53,105: Snapshot:0	Epoch:15	Loss:0.271	translation_Loss:0.271	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:46.0	Best:25.83
2025-01-05 22:58:58,521: Snapshot:0	Epoch:16	Loss:0.252	translation_Loss:0.252	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.78	Hits@10:45.9	Best:25.83
2025-01-05 22:59:04,342: Snapshot:0	Epoch:17	Loss:0.238	translation_Loss:0.238	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.56	Hits@10:46.04	Best:25.83
2025-01-05 22:59:09,731: Snapshot:0	Epoch:18	Loss:0.221	translation_Loss:0.221	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.71	Hits@10:45.97	Best:25.83
2025-01-05 22:59:15,624: Early Stopping! Snapshot: 0 Epoch: 19 Best Results: 25.83
2025-01-05 22:59:15,625: Start to training tokens! Snapshot: 0 Epoch: 19 Loss:0.218 MRR:25.5 Best Results: 25.83
Token added to optimizer, embeddings excluded successfully.
2025-01-05 22:59:15,625: Snapshot:0	Epoch:19	Loss:0.218	translation_Loss:0.218	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.5	Hits@10:45.85	Best:25.83
2025-01-05 22:59:21,588: Snapshot:0	Epoch:20	Loss:26.494	translation_Loss:11.495	token_training_loss:14.999	distillation_Loss:0.0                                                   	MRR:25.5	Hits@10:45.85	Best:25.83
2025-01-05 22:59:27,316: End of token training: 0 Epoch: 21 Loss:11.856 MRR:25.5 Best Results: 25.83
2025-01-05 22:59:27,316: Snapshot:0	Epoch:21	Loss:11.856	translation_Loss:11.483	token_training_loss:0.373	distillation_Loss:0.0                                                           	MRR:25.5	Hits@10:45.85	Best:25.83
2025-01-05 22:59:27,548: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2025-01-05 22:59:29,842: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2573 |  0.15  | 0.3135 | 0.3779 |  0.4529 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 22:59:36,314: Snapshot:1	Epoch:0	Loss:4.97	translation_Loss:4.752	token_training_loss:0.0	distillation_Loss:0.218                                                   	MRR:9.54	Hits@10:16.75	Best:9.54
2025-01-05 22:59:38,676: Snapshot:1	Epoch:1	Loss:3.067	translation_Loss:2.667	token_training_loss:0.0	distillation_Loss:0.4                                                   	MRR:16.31	Hits@10:30.11	Best:16.31
2025-01-05 22:59:40,720: Snapshot:1	Epoch:2	Loss:1.984	translation_Loss:1.535	token_training_loss:0.0	distillation_Loss:0.45                                                   	MRR:20.44	Hits@10:36.17	Best:20.44
2025-01-05 22:59:42,820: Snapshot:1	Epoch:3	Loss:1.41	translation_Loss:0.999	token_training_loss:0.0	distillation_Loss:0.411                                                   	MRR:22.89	Hits@10:40.04	Best:22.89
2025-01-05 22:59:44,901: Snapshot:1	Epoch:4	Loss:1.102	translation_Loss:0.757	token_training_loss:0.0	distillation_Loss:0.344                                                   	MRR:24.35	Hits@10:43.31	Best:24.35
2025-01-05 22:59:47,084: Snapshot:1	Epoch:5	Loss:0.911	translation_Loss:0.617	token_training_loss:0.0	distillation_Loss:0.294                                                   	MRR:25.34	Hits@10:45.59	Best:25.34
2025-01-05 22:59:49,150: Snapshot:1	Epoch:6	Loss:0.801	translation_Loss:0.539	token_training_loss:0.0	distillation_Loss:0.262                                                   	MRR:26.26	Hits@10:46.86	Best:26.26
2025-01-05 22:59:51,658: Snapshot:1	Epoch:7	Loss:0.727	translation_Loss:0.483	token_training_loss:0.0	distillation_Loss:0.244                                                   	MRR:26.92	Hits@10:48.0	Best:26.92
2025-01-05 22:59:53,814: Snapshot:1	Epoch:8	Loss:0.679	translation_Loss:0.449	token_training_loss:0.0	distillation_Loss:0.23                                                   	MRR:27.47	Hits@10:48.41	Best:27.47
2025-01-05 22:59:55,995: Snapshot:1	Epoch:9	Loss:0.64	translation_Loss:0.421	token_training_loss:0.0	distillation_Loss:0.219                                                   	MRR:27.89	Hits@10:48.93	Best:27.89
2025-01-05 22:59:58,133: Snapshot:1	Epoch:10	Loss:0.604	translation_Loss:0.394	token_training_loss:0.0	distillation_Loss:0.21                                                   	MRR:28.35	Hits@10:49.17	Best:28.35
2025-01-05 23:00:00,290: Snapshot:1	Epoch:11	Loss:0.581	translation_Loss:0.378	token_training_loss:0.0	distillation_Loss:0.203                                                   	MRR:28.81	Hits@10:49.77	Best:28.81
2025-01-05 23:00:02,422: Snapshot:1	Epoch:12	Loss:0.561	translation_Loss:0.364	token_training_loss:0.0	distillation_Loss:0.197                                                   	MRR:28.99	Hits@10:49.9	Best:28.99
2025-01-05 23:00:04,980: Snapshot:1	Epoch:13	Loss:0.537	translation_Loss:0.345	token_training_loss:0.0	distillation_Loss:0.192                                                   	MRR:29.17	Hits@10:49.63	Best:29.17
2025-01-05 23:00:07,197: Snapshot:1	Epoch:14	Loss:0.522	translation_Loss:0.335	token_training_loss:0.0	distillation_Loss:0.187                                                   	MRR:29.05	Hits@10:49.82	Best:29.17
2025-01-05 23:00:09,293: Snapshot:1	Epoch:15	Loss:0.512	translation_Loss:0.33	token_training_loss:0.0	distillation_Loss:0.183                                                   	MRR:29.07	Hits@10:49.95	Best:29.17
2025-01-05 23:00:11,351: Snapshot:1	Epoch:16	Loss:0.5	translation_Loss:0.322	token_training_loss:0.0	distillation_Loss:0.179                                                   	MRR:29.3	Hits@10:49.9	Best:29.3
2025-01-05 23:00:13,474: Snapshot:1	Epoch:17	Loss:0.491	translation_Loss:0.315	token_training_loss:0.0	distillation_Loss:0.176                                                   	MRR:29.43	Hits@10:50.06	Best:29.43
2025-01-05 23:00:15,634: Snapshot:1	Epoch:18	Loss:0.479	translation_Loss:0.304	token_training_loss:0.0	distillation_Loss:0.175                                                   	MRR:29.45	Hits@10:50.17	Best:29.45
2025-01-05 23:00:18,072: Snapshot:1	Epoch:19	Loss:0.471	translation_Loss:0.298	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:29.38	Hits@10:50.13	Best:29.45
2025-01-05 23:00:20,211: Snapshot:1	Epoch:20	Loss:0.463	translation_Loss:0.295	token_training_loss:0.0	distillation_Loss:0.169                                                   	MRR:29.37	Hits@10:50.36	Best:29.45
2025-01-05 23:00:22,369: Snapshot:1	Epoch:21	Loss:0.458	translation_Loss:0.29	token_training_loss:0.0	distillation_Loss:0.167                                                   	MRR:29.65	Hits@10:50.48	Best:29.65
2025-01-05 23:00:24,527: Snapshot:1	Epoch:22	Loss:0.459	translation_Loss:0.292	token_training_loss:0.0	distillation_Loss:0.168                                                   	MRR:29.86	Hits@10:50.38	Best:29.86
2025-01-05 23:00:26,676: Snapshot:1	Epoch:23	Loss:0.446	translation_Loss:0.28	token_training_loss:0.0	distillation_Loss:0.166                                                   	MRR:29.72	Hits@10:50.3	Best:29.86
2025-01-05 23:00:28,793: Snapshot:1	Epoch:24	Loss:0.445	translation_Loss:0.282	token_training_loss:0.0	distillation_Loss:0.163                                                   	MRR:29.49	Hits@10:50.19	Best:29.86
2025-01-05 23:00:31,187: Snapshot:1	Epoch:25	Loss:0.441	translation_Loss:0.278	token_training_loss:0.0	distillation_Loss:0.162                                                   	MRR:29.78	Hits@10:50.28	Best:29.86
2025-01-05 23:00:33,231: Snapshot:1	Epoch:26	Loss:0.439	translation_Loss:0.277	token_training_loss:0.0	distillation_Loss:0.162                                                   	MRR:29.74	Hits@10:50.28	Best:29.86
2025-01-05 23:00:35,368: Early Stopping! Snapshot: 1 Epoch: 27 Best Results: 29.86
2025-01-05 23:00:35,369: Start to training tokens! Snapshot: 1 Epoch: 27 Loss:0.436 MRR:29.82 Best Results: 29.86
Token added to optimizer, embeddings excluded successfully.
2025-01-05 23:00:35,369: Snapshot:1	Epoch:27	Loss:0.436	translation_Loss:0.276	token_training_loss:0.0	distillation_Loss:0.16                                                   	MRR:29.82	Hits@10:50.65	Best:29.86
2025-01-05 23:00:37,398: Snapshot:1	Epoch:28	Loss:16.238	translation_Loss:4.45	token_training_loss:11.789	distillation_Loss:0.0                                                   	MRR:29.82	Hits@10:50.65	Best:29.86
2025-01-05 23:00:39,451: End of token training: 1 Epoch: 29 Loss:7.095 MRR:29.82 Best Results: 29.86
2025-01-05 23:00:39,451: Snapshot:1	Epoch:29	Loss:7.095	translation_Loss:4.457	token_training_loss:2.638	distillation_Loss:0.0                                                           	MRR:29.82	Hits@10:50.65	Best:29.86
2025-01-05 23:00:39,722: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2025-01-05 23:00:43,433: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2588 | 0.1524 | 0.3146 | 0.3798 |  0.4533 |
|     1      | 0.2925 | 0.1896 | 0.3341 | 0.4097 |  0.5028 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 23:00:59,721: Snapshot:2	Epoch:0	Loss:15.744	translation_Loss:14.706	token_training_loss:0.0	distillation_Loss:1.039                                                   	MRR:14.19	Hits@10:28.84	Best:14.19
2025-01-05 23:01:08,982: Snapshot:2	Epoch:1	Loss:6.919	translation_Loss:5.463	token_training_loss:0.0	distillation_Loss:1.456                                                   	MRR:19.16	Hits@10:36.05	Best:19.16
2025-01-05 23:01:17,971: Snapshot:2	Epoch:2	Loss:4.491	translation_Loss:3.243	token_training_loss:0.0	distillation_Loss:1.247                                                   	MRR:20.58	Hits@10:37.62	Best:20.58
2025-01-05 23:01:27,228: Snapshot:2	Epoch:3	Loss:3.663	translation_Loss:2.564	token_training_loss:0.0	distillation_Loss:1.1                                                   	MRR:21.0	Hits@10:37.58	Best:21.0
2025-01-05 23:01:36,442: Snapshot:2	Epoch:4	Loss:3.32	translation_Loss:2.291	token_training_loss:0.0	distillation_Loss:1.029                                                   	MRR:21.41	Hits@10:38.05	Best:21.41
2025-01-05 23:01:45,737: Snapshot:2	Epoch:5	Loss:3.153	translation_Loss:2.16	token_training_loss:0.0	distillation_Loss:0.993                                                   	MRR:21.54	Hits@10:38.19	Best:21.54
2025-01-05 23:01:54,537: Snapshot:2	Epoch:6	Loss:3.086	translation_Loss:2.107	token_training_loss:0.0	distillation_Loss:0.978                                                   	MRR:21.51	Hits@10:38.36	Best:21.54
2025-01-05 23:02:03,737: Snapshot:2	Epoch:7	Loss:3.017	translation_Loss:2.045	token_training_loss:0.0	distillation_Loss:0.972                                                   	MRR:21.69	Hits@10:38.28	Best:21.69
2025-01-05 23:02:12,909: Snapshot:2	Epoch:8	Loss:2.978	translation_Loss:2.014	token_training_loss:0.0	distillation_Loss:0.964                                                   	MRR:21.49	Hits@10:38.15	Best:21.69
2025-01-05 23:02:21,677: Snapshot:2	Epoch:9	Loss:2.954	translation_Loss:1.991	token_training_loss:0.0	distillation_Loss:0.962                                                   	MRR:21.6	Hits@10:38.34	Best:21.69
2025-01-05 23:02:30,822: Snapshot:2	Epoch:10	Loss:2.92	translation_Loss:1.963	token_training_loss:0.0	distillation_Loss:0.957                                                   	MRR:21.56	Hits@10:38.19	Best:21.69
2025-01-05 23:02:40,051: Snapshot:2	Epoch:11	Loss:2.913	translation_Loss:1.957	token_training_loss:0.0	distillation_Loss:0.957                                                   	MRR:21.55	Hits@10:38.42	Best:21.69
2025-01-05 23:02:49,338: Early Stopping! Snapshot: 2 Epoch: 12 Best Results: 21.69
2025-01-05 23:02:49,338: Start to training tokens! Snapshot: 2 Epoch: 12 Loss:2.903 MRR:21.68 Best Results: 21.69
Token added to optimizer, embeddings excluded successfully.
2025-01-05 23:02:49,338: Snapshot:2	Epoch:12	Loss:2.903	translation_Loss:1.949	token_training_loss:0.0	distillation_Loss:0.954                                                   	MRR:21.68	Hits@10:38.24	Best:21.69
2025-01-05 23:02:58,144: Snapshot:2	Epoch:13	Loss:32.345	translation_Loss:17.907	token_training_loss:14.438	distillation_Loss:0.0                                                   	MRR:21.68	Hits@10:38.24	Best:21.69
2025-01-05 23:03:07,294: End of token training: 2 Epoch: 14 Loss:18.036 MRR:21.68 Best Results: 21.69
2025-01-05 23:03:07,294: Snapshot:2	Epoch:14	Loss:18.036	translation_Loss:17.908	token_training_loss:0.127	distillation_Loss:0.0                                                           	MRR:21.68	Hits@10:38.24	Best:21.69
2025-01-05 23:03:07,526: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2025-01-05 23:03:14,843: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2542 | 0.1427 | 0.3122 | 0.3795 |  0.4587 |
|     1      | 0.2737 | 0.1715 | 0.3174 | 0.3824 |  0.4747 |
|     2      | 0.2165 | 0.1306 | 0.2459 | 0.3054 |  0.3846 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 23:03:34,187: Snapshot:3	Epoch:0	Loss:13.939	translation_Loss:13.354	token_training_loss:0.0	distillation_Loss:0.584                                                   	MRR:16.15	Hits@10:32.5	Best:16.15
2025-01-05 23:03:45,237: Snapshot:3	Epoch:1	Loss:4.629	translation_Loss:3.55	token_training_loss:0.0	distillation_Loss:1.079                                                   	MRR:20.57	Hits@10:38.26	Best:20.57
2025-01-05 23:03:56,064: Snapshot:3	Epoch:2	Loss:2.854	translation_Loss:1.713	token_training_loss:0.0	distillation_Loss:1.141                                                   	MRR:21.23	Hits@10:39.22	Best:21.23
2025-01-05 23:04:07,282: Snapshot:3	Epoch:3	Loss:2.317	translation_Loss:1.223	token_training_loss:0.0	distillation_Loss:1.094                                                   	MRR:21.42	Hits@10:39.45	Best:21.42
2025-01-05 23:04:18,537: Snapshot:3	Epoch:4	Loss:2.108	translation_Loss:1.037	token_training_loss:0.0	distillation_Loss:1.071                                                   	MRR:21.6	Hits@10:39.98	Best:21.6
2025-01-05 23:04:29,601: Snapshot:3	Epoch:5	Loss:2.014	translation_Loss:0.958	token_training_loss:0.0	distillation_Loss:1.056                                                   	MRR:21.71	Hits@10:40.06	Best:21.71
2025-01-05 23:04:40,706: Snapshot:3	Epoch:6	Loss:1.946	translation_Loss:0.9	token_training_loss:0.0	distillation_Loss:1.046                                                   	MRR:21.85	Hits@10:40.2	Best:21.85
2025-01-05 23:04:51,634: Snapshot:3	Epoch:7	Loss:1.901	translation_Loss:0.865	token_training_loss:0.0	distillation_Loss:1.036                                                   	MRR:21.97	Hits@10:40.21	Best:21.97
2025-01-05 23:05:02,735: Snapshot:3	Epoch:8	Loss:1.884	translation_Loss:0.847	token_training_loss:0.0	distillation_Loss:1.037                                                   	MRR:22.01	Hits@10:40.23	Best:22.01
2025-01-05 23:05:13,820: Snapshot:3	Epoch:9	Loss:1.857	translation_Loss:0.821	token_training_loss:0.0	distillation_Loss:1.036                                                   	MRR:21.92	Hits@10:40.14	Best:22.01
2025-01-05 23:05:24,891: Snapshot:3	Epoch:10	Loss:1.846	translation_Loss:0.813	token_training_loss:0.0	distillation_Loss:1.033                                                   	MRR:21.95	Hits@10:40.14	Best:22.01
2025-01-05 23:05:36,050: Snapshot:3	Epoch:11	Loss:1.846	translation_Loss:0.812	token_training_loss:0.0	distillation_Loss:1.033                                                   	MRR:21.89	Hits@10:40.48	Best:22.01
2025-01-05 23:05:47,043: Snapshot:3	Epoch:12	Loss:1.833	translation_Loss:0.795	token_training_loss:0.0	distillation_Loss:1.037                                                   	MRR:21.87	Hits@10:40.17	Best:22.01
2025-01-05 23:05:57,824: Snapshot:3	Epoch:13	Loss:1.824	translation_Loss:0.793	token_training_loss:0.0	distillation_Loss:1.03                                                   	MRR:22.14	Hits@10:40.49	Best:22.14
2025-01-05 23:06:08,945: Snapshot:3	Epoch:14	Loss:1.824	translation_Loss:0.791	token_training_loss:0.0	distillation_Loss:1.033                                                   	MRR:21.89	Hits@10:40.28	Best:22.14
2025-01-05 23:06:19,956: Snapshot:3	Epoch:15	Loss:1.83	translation_Loss:0.792	token_training_loss:0.0	distillation_Loss:1.037                                                   	MRR:22.0	Hits@10:40.25	Best:22.14
2025-01-05 23:06:31,027: Snapshot:3	Epoch:16	Loss:1.824	translation_Loss:0.782	token_training_loss:0.0	distillation_Loss:1.042                                                   	MRR:22.12	Hits@10:40.34	Best:22.14
2025-01-05 23:06:42,111: Snapshot:3	Epoch:17	Loss:1.812	translation_Loss:0.771	token_training_loss:0.0	distillation_Loss:1.041                                                   	MRR:21.96	Hits@10:40.12	Best:22.14
2025-01-05 23:06:52,919: Early Stopping! Snapshot: 3 Epoch: 18 Best Results: 22.14
2025-01-05 23:06:52,919: Start to training tokens! Snapshot: 3 Epoch: 18 Loss:1.822 MRR:22.05 Best Results: 22.14
Token added to optimizer, embeddings excluded successfully.
2025-01-05 23:06:52,920: Snapshot:3	Epoch:18	Loss:1.822	translation_Loss:0.781	token_training_loss:0.0	distillation_Loss:1.041                                                   	MRR:22.05	Hits@10:40.19	Best:22.14
2025-01-05 23:07:04,004: Snapshot:3	Epoch:19	Loss:33.197	translation_Loss:17.85	token_training_loss:15.348	distillation_Loss:0.0                                                   	MRR:22.05	Hits@10:40.19	Best:22.14
2025-01-05 23:07:15,010: End of token training: 3 Epoch: 20 Loss:17.908 MRR:22.05 Best Results: 22.14
2025-01-05 23:07:15,010: Snapshot:3	Epoch:20	Loss:17.908	translation_Loss:17.837	token_training_loss:0.071	distillation_Loss:0.0                                                           	MRR:22.05	Hits@10:40.19	Best:22.14
2025-01-05 23:07:15,239: => loading checkpoint './checkpoint/HYBRID/3model_best.tar'
2025-01-05 23:07:27,437: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2527 | 0.1505 | 0.2983 | 0.3638 |  0.446  |
|     1      | 0.2665 | 0.1698 | 0.2965 | 0.3596 |  0.4697 |
|     2      | 0.2053 | 0.1206 | 0.2315 | 0.2902 |  0.3736 |
|     3      |  0.22  | 0.1242 | 0.2573 | 0.3194 |  0.4021 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 23:07:37,799: Snapshot:4	Epoch:0	Loss:7.712	translation_Loss:6.302	token_training_loss:0.0	distillation_Loss:1.409                                                   	MRR:7.99	Hits@10:16.55	Best:7.99
2025-01-05 23:07:42,676: Snapshot:4	Epoch:1	Loss:5.549	translation_Loss:4.688	token_training_loss:0.0	distillation_Loss:0.861                                                   	MRR:13.92	Hits@10:26.98	Best:13.92
2025-01-05 23:07:47,169: Snapshot:4	Epoch:2	Loss:4.502	translation_Loss:3.69	token_training_loss:0.0	distillation_Loss:0.811                                                   	MRR:18.13	Hits@10:31.51	Best:18.13
2025-01-05 23:07:51,589: Snapshot:4	Epoch:3	Loss:3.787	translation_Loss:3.06	token_training_loss:0.0	distillation_Loss:0.728                                                   	MRR:20.65	Hits@10:34.28	Best:20.65
2025-01-05 23:07:55,984: Snapshot:4	Epoch:4	Loss:3.271	translation_Loss:2.619	token_training_loss:0.0	distillation_Loss:0.652                                                   	MRR:21.84	Hits@10:35.18	Best:21.84
2025-01-05 23:08:00,828: Snapshot:4	Epoch:5	Loss:2.93	translation_Loss:2.321	token_training_loss:0.0	distillation_Loss:0.609                                                   	MRR:22.23	Hits@10:35.3	Best:22.23
2025-01-05 23:08:05,340: Snapshot:4	Epoch:6	Loss:2.738	translation_Loss:2.159	token_training_loss:0.0	distillation_Loss:0.578                                                   	MRR:22.26	Hits@10:35.3	Best:22.26
2025-01-05 23:08:09,749: Snapshot:4	Epoch:7	Loss:2.64	translation_Loss:2.08	token_training_loss:0.0	distillation_Loss:0.559                                                   	MRR:22.24	Hits@10:35.46	Best:22.26
2025-01-05 23:08:14,491: Snapshot:4	Epoch:8	Loss:2.576	translation_Loss:2.027	token_training_loss:0.0	distillation_Loss:0.549                                                   	MRR:22.17	Hits@10:35.43	Best:22.26
2025-01-05 23:08:18,855: Snapshot:4	Epoch:9	Loss:2.541	translation_Loss:2.0	token_training_loss:0.0	distillation_Loss:0.54                                                   	MRR:22.21	Hits@10:35.23	Best:22.26
2025-01-05 23:08:23,286: Snapshot:4	Epoch:10	Loss:2.521	translation_Loss:1.99	token_training_loss:0.0	distillation_Loss:0.531                                                   	MRR:22.19	Hits@10:35.32	Best:22.26
2025-01-05 23:08:28,060: Early Stopping! Snapshot: 4 Epoch: 11 Best Results: 22.26
2025-01-05 23:08:28,061: Start to training tokens! Snapshot: 4 Epoch: 11 Loss:2.509 MRR:22.18 Best Results: 22.26
Token added to optimizer, embeddings excluded successfully.
2025-01-05 23:08:28,061: Snapshot:4	Epoch:11	Loss:2.509	translation_Loss:1.981	token_training_loss:0.0	distillation_Loss:0.528                                                   	MRR:22.18	Hits@10:35.4	Best:22.26
2025-01-05 23:08:32,507: Snapshot:4	Epoch:12	Loss:24.958	translation_Loss:9.894	token_training_loss:15.063	distillation_Loss:0.0                                                   	MRR:22.18	Hits@10:35.4	Best:22.26
2025-01-05 23:08:36,849: End of token training: 4 Epoch: 13 Loss:10.819 MRR:22.18 Best Results: 22.26
2025-01-05 23:08:36,850: Snapshot:4	Epoch:13	Loss:10.819	translation_Loss:9.903	token_training_loss:0.916	distillation_Loss:0.0                                                           	MRR:22.18	Hits@10:35.4	Best:22.26
2025-01-05 23:08:37,077: => loading checkpoint './checkpoint/HYBRID/4model_best.tar'
2025-01-05 23:08:51,822: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2385 | 0.1335 | 0.2835 | 0.3522 |  0.4404 |
|     1      | 0.2634 | 0.1662 | 0.2928 | 0.358  |  0.4678 |
|     2      | 0.2022 | 0.1166 | 0.2295 | 0.2873 |  0.3722 |
|     3      | 0.2163 | 0.1197 | 0.2534 | 0.3173 |  0.401  |
|     4      | 0.2205 | 0.1549 | 0.2411 | 0.2886 |  0.3511 |
+------------+--------+--------+--------+--------+---------+
2025-01-05 23:08:51,824: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2573 |  0.15  | 0.3135 | 0.3779 |  0.4529 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2588 | 0.1524 | 0.3146 | 0.3798 |  0.4533 |
|     1      | 0.2925 | 0.1896 | 0.3341 | 0.4097 |  0.5028 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2542 | 0.1427 | 0.3122 | 0.3795 |  0.4587 |
|     1      | 0.2737 | 0.1715 | 0.3174 | 0.3824 |  0.4747 |
|     2      | 0.2165 | 0.1306 | 0.2459 | 0.3054 |  0.3846 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2527 | 0.1505 | 0.2983 | 0.3638 |  0.446  |
|     1      | 0.2665 | 0.1698 | 0.2965 | 0.3596 |  0.4697 |
|     2      | 0.2053 | 0.1206 | 0.2315 | 0.2902 |  0.3736 |
|     3      |  0.22  | 0.1242 | 0.2573 | 0.3194 |  0.4021 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2385 | 0.1335 | 0.2835 | 0.3522 |  0.4404 |
|     1      | 0.2634 | 0.1662 | 0.2928 | 0.358  |  0.4678 |
|     2      | 0.2022 | 0.1166 | 0.2295 | 0.2873 |  0.3722 |
|     3      | 0.2163 | 0.1197 | 0.2534 | 0.3173 |  0.401  |
|     4      | 0.2205 | 0.1549 | 0.2411 | 0.2886 |  0.3511 |
+------------+--------+--------+--------+--------+---------+]
2025-01-05 23:08:51,825: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 127.5509352684021  |   0.257   |     0.15     |    0.314     |     0.453     |
|    1     | 68.46128940582275  |   0.268   |    0.162     |     0.32     |     0.466     |
|    2     | 140.10801076889038 |   0.237   |     0.14     |    0.278     |     0.422     |
|    3     | 235.54352593421936 |   0.226   |    0.132     |    0.261     |     0.407     |
|    4     | 67.16361951828003  |    0.22   |    0.129     |    0.253     |     0.398     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-05 23:08:51,825: Sum_Training_Time:638.8273808956146
2025-01-05 23:08:51,825: Every_Training_Time:[127.5509352684021, 68.46128940582275, 140.10801076889038, 235.54352593421936, 67.16361951828003]
2025-01-05 23:08:51,825: Forward transfer: 0.04355 Backward transfer: -0.01647499999999999
2025-01-05 23:09:09,979: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250105230856/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 3000.0, 1000.0, 200000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-05 23:09:18,726: Snapshot:0	Epoch:0	Loss:15.399	translation_Loss:15.399	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.3	Hits@10:18.01	Best:7.3
2025-01-05 23:09:24,531: Snapshot:0	Epoch:1	Loss:10.741	translation_Loss:10.741	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.4	Hits@10:31.06	Best:12.4
2025-01-05 23:09:29,945: Snapshot:0	Epoch:2	Loss:7.011	translation_Loss:7.011	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.93	Hits@10:39.68	Best:18.93
2025-01-05 23:09:35,395: Snapshot:0	Epoch:3	Loss:4.124	translation_Loss:4.124	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.67	Hits@10:43.54	Best:22.67
2025-01-05 23:09:41,191: Snapshot:0	Epoch:4	Loss:2.462	translation_Loss:2.462	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.2	Hits@10:45.28	Best:24.2
2025-01-05 23:09:46,619: Snapshot:0	Epoch:5	Loss:1.562	translation_Loss:1.562	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.97	Hits@10:45.96	Best:24.97
2025-01-05 23:09:52,431: Snapshot:0	Epoch:6	Loss:1.067	translation_Loss:1.067	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.33	Hits@10:46.17	Best:25.33
2025-01-05 23:09:57,967: Snapshot:0	Epoch:7	Loss:0.799	translation_Loss:0.799	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.53	Hits@10:46.5	Best:25.53
2025-01-05 23:10:03,906: Snapshot:0	Epoch:8	Loss:0.631	translation_Loss:0.631	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.66	Hits@10:46.51	Best:25.66
2025-01-05 23:10:09,549: Snapshot:0	Epoch:9	Loss:0.534	translation_Loss:0.534	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.8	Hits@10:46.36	Best:25.8
2025-01-05 23:10:15,331: Snapshot:0	Epoch:10	Loss:0.454	translation_Loss:0.454	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.77	Hits@10:46.31	Best:25.8
2025-01-05 23:10:20,775: Snapshot:0	Epoch:11	Loss:0.402	translation_Loss:0.402	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.77	Hits@10:46.2	Best:25.8
2025-01-05 23:10:26,470: Snapshot:0	Epoch:12	Loss:0.355	translation_Loss:0.355	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.01	Hits@10:46.12	Best:26.01
2025-01-05 23:10:31,824: Snapshot:0	Epoch:13	Loss:0.319	translation_Loss:0.319	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.85	Hits@10:46.22	Best:26.01
2025-01-05 23:10:37,285: Snapshot:0	Epoch:14	Loss:0.293	translation_Loss:0.293	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.82	Hits@10:46.15	Best:26.01
2025-01-05 23:10:43,011: Snapshot:0	Epoch:15	Loss:0.272	translation_Loss:0.272	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.8	Hits@10:46.08	Best:26.01
2025-01-05 23:10:48,499: Snapshot:0	Epoch:16	Loss:0.251	translation_Loss:0.251	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.68	Hits@10:46.18	Best:26.01
2025-01-05 23:10:54,311: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 26.01
2025-01-05 23:10:54,311: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.238 MRR:25.65 Best Results: 26.01
Token added to optimizer, embeddings excluded successfully.
2025-01-05 23:10:54,312: Snapshot:0	Epoch:17	Loss:0.238	translation_Loss:0.238	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.65	Hits@10:45.91	Best:26.01
2025-01-05 23:11:00,252: Snapshot:0	Epoch:18	Loss:26.538	translation_Loss:11.54	token_training_loss:14.999	distillation_Loss:0.0                                                   	MRR:25.65	Hits@10:45.91	Best:26.01
2025-01-05 23:11:06,003: End of token training: 0 Epoch: 19 Loss:11.919 MRR:25.65 Best Results: 26.01
2025-01-05 23:11:06,003: Snapshot:0	Epoch:19	Loss:11.919	translation_Loss:11.547	token_training_loss:0.373	distillation_Loss:0.0                                                           	MRR:25.65	Hits@10:45.91	Best:26.01
2025-01-05 23:11:06,236: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2025-01-05 23:11:08,924: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2592 | 0.1528 | 0.3148 | 0.378  |  0.453  |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 23:11:15,725: Snapshot:1	Epoch:0	Loss:4.99	translation_Loss:4.771	token_training_loss:0.0	distillation_Loss:0.219                                                   	MRR:9.72	Hits@10:17.04	Best:9.72
2025-01-05 23:11:17,891: Snapshot:1	Epoch:1	Loss:3.099	translation_Loss:2.698	token_training_loss:0.0	distillation_Loss:0.402                                                   	MRR:16.4	Hits@10:30.22	Best:16.4
2025-01-05 23:11:20,040: Snapshot:1	Epoch:2	Loss:2.022	translation_Loss:1.569	token_training_loss:0.0	distillation_Loss:0.453                                                   	MRR:20.74	Hits@10:36.19	Best:20.74
2025-01-05 23:11:22,098: Snapshot:1	Epoch:3	Loss:1.443	translation_Loss:1.026	token_training_loss:0.0	distillation_Loss:0.416                                                   	MRR:23.44	Hits@10:40.42	Best:23.44
2025-01-05 23:11:24,188: Snapshot:1	Epoch:4	Loss:1.132	translation_Loss:0.78	token_training_loss:0.0	distillation_Loss:0.352                                                   	MRR:24.5	Hits@10:43.8	Best:24.5
2025-01-05 23:11:26,242: Snapshot:1	Epoch:5	Loss:0.952	translation_Loss:0.651	token_training_loss:0.0	distillation_Loss:0.302                                                   	MRR:25.51	Hits@10:45.68	Best:25.51
2025-01-05 23:11:28,634: Snapshot:1	Epoch:6	Loss:0.833	translation_Loss:0.563	token_training_loss:0.0	distillation_Loss:0.27                                                   	MRR:26.39	Hits@10:47.05	Best:26.39
2025-01-05 23:11:30,809: Snapshot:1	Epoch:7	Loss:0.754	translation_Loss:0.503	token_training_loss:0.0	distillation_Loss:0.251                                                   	MRR:27.18	Hits@10:48.35	Best:27.18
2025-01-05 23:11:32,873: Snapshot:1	Epoch:8	Loss:0.705	translation_Loss:0.465	token_training_loss:0.0	distillation_Loss:0.239                                                   	MRR:27.85	Hits@10:49.13	Best:27.85
2025-01-05 23:11:34,968: Snapshot:1	Epoch:9	Loss:0.67	translation_Loss:0.441	token_training_loss:0.0	distillation_Loss:0.229                                                   	MRR:28.42	Hits@10:49.59	Best:28.42
2025-01-05 23:11:37,054: Snapshot:1	Epoch:10	Loss:0.632	translation_Loss:0.411	token_training_loss:0.0	distillation_Loss:0.222                                                   	MRR:28.69	Hits@10:49.77	Best:28.69
2025-01-05 23:11:39,144: Snapshot:1	Epoch:11	Loss:0.604	translation_Loss:0.393	token_training_loss:0.0	distillation_Loss:0.211                                                   	MRR:28.94	Hits@10:49.8	Best:28.94
2025-01-05 23:11:41,594: Snapshot:1	Epoch:12	Loss:0.583	translation_Loss:0.378	token_training_loss:0.0	distillation_Loss:0.205                                                   	MRR:29.1	Hits@10:50.06	Best:29.1
2025-01-05 23:11:43,629: Snapshot:1	Epoch:13	Loss:0.569	translation_Loss:0.368	token_training_loss:0.0	distillation_Loss:0.201                                                   	MRR:29.5	Hits@10:50.35	Best:29.5
2025-01-05 23:11:45,659: Snapshot:1	Epoch:14	Loss:0.548	translation_Loss:0.352	token_training_loss:0.0	distillation_Loss:0.196                                                   	MRR:29.68	Hits@10:50.4	Best:29.68
2025-01-05 23:11:47,806: Snapshot:1	Epoch:15	Loss:0.538	translation_Loss:0.346	token_training_loss:0.0	distillation_Loss:0.192                                                   	MRR:29.81	Hits@10:50.72	Best:29.81
2025-01-05 23:11:49,903: Snapshot:1	Epoch:16	Loss:0.524	translation_Loss:0.336	token_training_loss:0.0	distillation_Loss:0.188                                                   	MRR:29.57	Hits@10:50.62	Best:29.81
2025-01-05 23:11:51,934: Snapshot:1	Epoch:17	Loss:0.514	translation_Loss:0.326	token_training_loss:0.0	distillation_Loss:0.187                                                   	MRR:29.65	Hits@10:50.72	Best:29.81
2025-01-05 23:11:54,093: Snapshot:1	Epoch:18	Loss:0.503	translation_Loss:0.319	token_training_loss:0.0	distillation_Loss:0.184                                                   	MRR:29.74	Hits@10:50.79	Best:29.81
2025-01-05 23:11:56,539: Snapshot:1	Epoch:19	Loss:0.494	translation_Loss:0.313	token_training_loss:0.0	distillation_Loss:0.181                                                   	MRR:29.81	Hits@10:50.75	Best:29.81
2025-01-05 23:11:58,689: Snapshot:1	Epoch:20	Loss:0.487	translation_Loss:0.309	token_training_loss:0.0	distillation_Loss:0.178                                                   	MRR:29.82	Hits@10:50.89	Best:29.82
2025-01-05 23:12:00,795: Snapshot:1	Epoch:21	Loss:0.486	translation_Loss:0.312	token_training_loss:0.0	distillation_Loss:0.174                                                   	MRR:29.75	Hits@10:50.73	Best:29.82
2025-01-05 23:12:02,812: Snapshot:1	Epoch:22	Loss:0.481	translation_Loss:0.307	token_training_loss:0.0	distillation_Loss:0.174                                                   	MRR:29.73	Hits@10:50.85	Best:29.82
2025-01-05 23:12:04,873: Snapshot:1	Epoch:23	Loss:0.474	translation_Loss:0.301	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:29.97	Hits@10:51.05	Best:29.97
2025-01-05 23:12:07,062: Snapshot:1	Epoch:24	Loss:0.464	translation_Loss:0.291	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:30.08	Hits@10:51.26	Best:30.08
2025-01-05 23:12:09,437: Snapshot:1	Epoch:25	Loss:0.467	translation_Loss:0.296	token_training_loss:0.0	distillation_Loss:0.171                                                   	MRR:30.26	Hits@10:51.08	Best:30.26
2025-01-05 23:12:11,573: Snapshot:1	Epoch:26	Loss:0.46	translation_Loss:0.289	token_training_loss:0.0	distillation_Loss:0.17                                                   	MRR:30.19	Hits@10:51.21	Best:30.26
2025-01-05 23:12:13,700: Snapshot:1	Epoch:27	Loss:0.459	translation_Loss:0.29	token_training_loss:0.0	distillation_Loss:0.169                                                   	MRR:30.13	Hits@10:50.98	Best:30.26
2025-01-05 23:12:15,843: Snapshot:1	Epoch:28	Loss:0.453	translation_Loss:0.286	token_training_loss:0.0	distillation_Loss:0.167                                                   	MRR:29.94	Hits@10:51.03	Best:30.26
2025-01-05 23:12:17,856: Snapshot:1	Epoch:29	Loss:0.449	translation_Loss:0.282	token_training_loss:0.0	distillation_Loss:0.168                                                   	MRR:29.95	Hits@10:51.01	Best:30.26
2025-01-05 23:12:19,883: Early Stopping! Snapshot: 1 Epoch: 30 Best Results: 30.26
2025-01-05 23:12:19,883: Start to training tokens! Snapshot: 1 Epoch: 30 Loss:0.453 MRR:29.98 Best Results: 30.26
Token added to optimizer, embeddings excluded successfully.
2025-01-05 23:12:19,883: Snapshot:1	Epoch:30	Loss:0.453	translation_Loss:0.286	token_training_loss:0.0	distillation_Loss:0.168                                                   	MRR:29.98	Hits@10:50.97	Best:30.26
2025-01-05 23:12:22,361: Snapshot:1	Epoch:31	Loss:16.25	translation_Loss:4.462	token_training_loss:11.789	distillation_Loss:0.0                                                   	MRR:29.98	Hits@10:50.97	Best:30.26
2025-01-05 23:12:24,479: End of token training: 1 Epoch: 32 Loss:7.101 MRR:29.98 Best Results: 30.26
2025-01-05 23:12:24,479: Snapshot:1	Epoch:32	Loss:7.101	translation_Loss:4.463	token_training_loss:2.638	distillation_Loss:0.0                                                           	MRR:29.98	Hits@10:50.97	Best:30.26
2025-01-05 23:12:24,714: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2025-01-05 23:12:28,089: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2595 | 0.1531 | 0.3157 | 0.379  |  0.4547 |
|     1      | 0.293  | 0.1862 | 0.3376 | 0.4158 |  0.5074 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 23:12:44,474: Snapshot:2	Epoch:0	Loss:15.885	translation_Loss:14.844	token_training_loss:0.0	distillation_Loss:1.042                                                   	MRR:14.26	Hits@10:28.95	Best:14.26
2025-01-05 23:12:53,771: Snapshot:2	Epoch:1	Loss:7.095	translation_Loss:5.62	token_training_loss:0.0	distillation_Loss:1.474                                                   	MRR:19.08	Hits@10:36.28	Best:19.08
2025-01-05 23:13:02,644: Snapshot:2	Epoch:2	Loss:4.63	translation_Loss:3.35	token_training_loss:0.0	distillation_Loss:1.279                                                   	MRR:20.66	Hits@10:37.63	Best:20.66
2025-01-05 23:13:11,921: Snapshot:2	Epoch:3	Loss:3.783	translation_Loss:2.652	token_training_loss:0.0	distillation_Loss:1.131                                                   	MRR:21.21	Hits@10:37.92	Best:21.21
2025-01-05 23:13:21,058: Snapshot:2	Epoch:4	Loss:3.442	translation_Loss:2.373	token_training_loss:0.0	distillation_Loss:1.069                                                   	MRR:21.36	Hits@10:38.21	Best:21.36
2025-01-05 23:13:29,917: Snapshot:2	Epoch:5	Loss:3.285	translation_Loss:2.252	token_training_loss:0.0	distillation_Loss:1.033                                                   	MRR:21.43	Hits@10:38.18	Best:21.43
2025-01-05 23:13:39,049: Snapshot:2	Epoch:6	Loss:3.19	translation_Loss:2.169	token_training_loss:0.0	distillation_Loss:1.021                                                   	MRR:21.48	Hits@10:38.37	Best:21.48
2025-01-05 23:13:48,446: Snapshot:2	Epoch:7	Loss:3.121	translation_Loss:2.118	token_training_loss:0.0	distillation_Loss:1.004                                                   	MRR:21.62	Hits@10:38.3	Best:21.62
2025-01-05 23:13:57,371: Snapshot:2	Epoch:8	Loss:3.091	translation_Loss:2.092	token_training_loss:0.0	distillation_Loss:0.999                                                   	MRR:21.51	Hits@10:38.3	Best:21.62
2025-01-05 23:14:06,636: Snapshot:2	Epoch:9	Loss:3.062	translation_Loss:2.063	token_training_loss:0.0	distillation_Loss:0.999                                                   	MRR:21.49	Hits@10:38.43	Best:21.62
2025-01-05 23:14:15,967: Snapshot:2	Epoch:10	Loss:3.03	translation_Loss:2.031	token_training_loss:0.0	distillation_Loss:0.999                                                   	MRR:21.39	Hits@10:38.4	Best:21.62
2025-01-05 23:14:24,863: Snapshot:2	Epoch:11	Loss:3.025	translation_Loss:2.031	token_training_loss:0.0	distillation_Loss:0.995                                                   	MRR:21.63	Hits@10:38.29	Best:21.63
2025-01-05 23:14:34,122: Snapshot:2	Epoch:12	Loss:3.001	translation_Loss:2.007	token_training_loss:0.0	distillation_Loss:0.994                                                   	MRR:21.36	Hits@10:38.47	Best:21.63
2025-01-05 23:14:43,178: Snapshot:2	Epoch:13	Loss:2.983	translation_Loss:1.993	token_training_loss:0.0	distillation_Loss:0.991                                                   	MRR:21.49	Hits@10:38.41	Best:21.63
2025-01-05 23:14:52,294: Snapshot:2	Epoch:14	Loss:2.976	translation_Loss:1.984	token_training_loss:0.0	distillation_Loss:0.992                                                   	MRR:21.39	Hits@10:38.4	Best:21.63
2025-01-05 23:15:01,077: Snapshot:2	Epoch:15	Loss:2.971	translation_Loss:1.978	token_training_loss:0.0	distillation_Loss:0.993                                                   	MRR:21.4	Hits@10:38.62	Best:21.63
2025-01-05 23:15:10,292: Early Stopping! Snapshot: 2 Epoch: 16 Best Results: 21.63
2025-01-05 23:15:10,292: Start to training tokens! Snapshot: 2 Epoch: 16 Loss:2.964 MRR:21.46 Best Results: 21.63
Token added to optimizer, embeddings excluded successfully.
2025-01-05 23:15:10,293: Snapshot:2	Epoch:16	Loss:2.964	translation_Loss:1.973	token_training_loss:0.0	distillation_Loss:0.991                                                   	MRR:21.46	Hits@10:38.41	Best:21.63
2025-01-05 23:15:19,462: Snapshot:2	Epoch:17	Loss:32.359	translation_Loss:17.921	token_training_loss:14.438	distillation_Loss:0.0                                                   	MRR:21.46	Hits@10:38.41	Best:21.63
2025-01-05 23:15:28,275: End of token training: 2 Epoch: 18 Loss:18.043 MRR:21.46 Best Results: 21.63
2025-01-05 23:15:28,276: Snapshot:2	Epoch:18	Loss:18.043	translation_Loss:17.916	token_training_loss:0.127	distillation_Loss:0.0                                                           	MRR:21.46	Hits@10:38.41	Best:21.63
2025-01-05 23:15:28,552: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2025-01-05 23:15:35,856: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2525 | 0.1398 | 0.3132 | 0.3814 |  0.4594 |
|     1      | 0.2779 | 0.1725 | 0.3202 | 0.3904 |  0.4853 |
|     2      | 0.2166 | 0.1297 | 0.2482 | 0.3069 |  0.3879 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 23:15:55,111: Snapshot:3	Epoch:0	Loss:14.359	translation_Loss:13.479	token_training_loss:0.0	distillation_Loss:0.88                                                   	MRR:16.13	Hits@10:32.15	Best:16.13
2025-01-05 23:16:06,301: Snapshot:3	Epoch:1	Loss:5.326	translation_Loss:3.835	token_training_loss:0.0	distillation_Loss:1.49                                                   	MRR:20.22	Hits@10:37.72	Best:20.22
2025-01-05 23:16:17,332: Snapshot:3	Epoch:2	Loss:3.567	translation_Loss:2.136	token_training_loss:0.0	distillation_Loss:1.431                                                   	MRR:21.14	Hits@10:39.02	Best:21.14
2025-01-05 23:16:28,436: Snapshot:3	Epoch:3	Loss:3.03	translation_Loss:1.676	token_training_loss:0.0	distillation_Loss:1.354                                                   	MRR:21.47	Hits@10:39.56	Best:21.47
2025-01-05 23:16:39,346: Snapshot:3	Epoch:4	Loss:2.808	translation_Loss:1.5	token_training_loss:0.0	distillation_Loss:1.309                                                   	MRR:21.68	Hits@10:39.73	Best:21.68
2025-01-05 23:16:50,598: Snapshot:3	Epoch:5	Loss:2.686	translation_Loss:1.404	token_training_loss:0.0	distillation_Loss:1.281                                                   	MRR:21.77	Hits@10:39.84	Best:21.77
2025-01-05 23:17:01,623: Snapshot:3	Epoch:6	Loss:2.618	translation_Loss:1.356	token_training_loss:0.0	distillation_Loss:1.262                                                   	MRR:21.87	Hits@10:39.92	Best:21.87
2025-01-05 23:17:12,695: Snapshot:3	Epoch:7	Loss:2.569	translation_Loss:1.314	token_training_loss:0.0	distillation_Loss:1.254                                                   	MRR:21.88	Hits@10:40.05	Best:21.88
2025-01-05 23:17:23,729: Snapshot:3	Epoch:8	Loss:2.537	translation_Loss:1.295	token_training_loss:0.0	distillation_Loss:1.242                                                   	MRR:21.87	Hits@10:39.73	Best:21.88
2025-01-05 23:17:34,365: Snapshot:3	Epoch:9	Loss:2.519	translation_Loss:1.276	token_training_loss:0.0	distillation_Loss:1.243                                                   	MRR:21.86	Hits@10:39.71	Best:21.88
2025-01-05 23:17:45,312: Snapshot:3	Epoch:10	Loss:2.5	translation_Loss:1.26	token_training_loss:0.0	distillation_Loss:1.241                                                   	MRR:21.96	Hits@10:40.12	Best:21.96
2025-01-05 23:17:56,299: Snapshot:3	Epoch:11	Loss:2.493	translation_Loss:1.26	token_training_loss:0.0	distillation_Loss:1.233                                                   	MRR:21.82	Hits@10:39.87	Best:21.96
2025-01-05 23:18:07,533: Snapshot:3	Epoch:12	Loss:2.489	translation_Loss:1.253	token_training_loss:0.0	distillation_Loss:1.236                                                   	MRR:21.88	Hits@10:40.15	Best:21.96
2025-01-05 23:18:18,519: Snapshot:3	Epoch:13	Loss:2.49	translation_Loss:1.254	token_training_loss:0.0	distillation_Loss:1.236                                                   	MRR:21.84	Hits@10:39.8	Best:21.96
2025-01-05 23:18:29,593: Snapshot:3	Epoch:14	Loss:2.471	translation_Loss:1.232	token_training_loss:0.0	distillation_Loss:1.239                                                   	MRR:21.95	Hits@10:39.6	Best:21.96
2025-01-05 23:18:40,339: Early Stopping! Snapshot: 3 Epoch: 15 Best Results: 21.96
2025-01-05 23:18:40,339: Start to training tokens! Snapshot: 3 Epoch: 15 Loss:2.465 MRR:21.86 Best Results: 21.96
Token added to optimizer, embeddings excluded successfully.
2025-01-05 23:18:40,340: Snapshot:3	Epoch:15	Loss:2.465	translation_Loss:1.229	token_training_loss:0.0	distillation_Loss:1.236                                                   	MRR:21.86	Hits@10:39.74	Best:21.96
2025-01-05 23:18:51,505: Snapshot:3	Epoch:16	Loss:33.778	translation_Loss:18.43	token_training_loss:15.348	distillation_Loss:0.0                                                   	MRR:21.86	Hits@10:39.74	Best:21.96
2025-01-05 23:19:02,530: End of token training: 3 Epoch: 17 Loss:18.524 MRR:21.86 Best Results: 21.96
2025-01-05 23:19:02,530: Snapshot:3	Epoch:17	Loss:18.524	translation_Loss:18.453	token_training_loss:0.071	distillation_Loss:0.0                                                           	MRR:21.86	Hits@10:39.74	Best:21.96
2025-01-05 23:19:02,766: => loading checkpoint './checkpoint/HYBRID/3model_best.tar'
2025-01-05 23:19:14,887: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2569 | 0.1513 | 0.3083 | 0.3739 |  0.455  |
|     1      | 0.2732 | 0.1746 | 0.3069 | 0.3717 |  0.4691 |
|     2      | 0.2069 | 0.1211 | 0.2342 | 0.293  |  0.3774 |
|     3      | 0.2172 | 0.1218 | 0.2547 | 0.3185 |  0.3983 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-05 23:19:25,081: Snapshot:4	Epoch:0	Loss:7.788	translation_Loss:6.375	token_training_loss:0.0	distillation_Loss:1.414                                                   	MRR:8.2	Hits@10:16.53	Best:8.2
2025-01-05 23:19:29,823: Snapshot:4	Epoch:1	Loss:5.645	translation_Loss:4.782	token_training_loss:0.0	distillation_Loss:0.863                                                   	MRR:13.9	Hits@10:26.77	Best:13.9
2025-01-05 23:19:34,223: Snapshot:4	Epoch:2	Loss:4.617	translation_Loss:3.803	token_training_loss:0.0	distillation_Loss:0.814                                                   	MRR:18.08	Hits@10:31.84	Best:18.08
2025-01-05 23:19:38,682: Snapshot:4	Epoch:3	Loss:3.901	translation_Loss:3.167	token_training_loss:0.0	distillation_Loss:0.734                                                   	MRR:20.57	Hits@10:34.34	Best:20.57
2025-01-05 23:19:43,099: Snapshot:4	Epoch:4	Loss:3.379	translation_Loss:2.718	token_training_loss:0.0	distillation_Loss:0.661                                                   	MRR:21.69	Hits@10:34.96	Best:21.69
2025-01-05 23:19:47,855: Snapshot:4	Epoch:5	Loss:3.044	translation_Loss:2.423	token_training_loss:0.0	distillation_Loss:0.62                                                   	MRR:22.12	Hits@10:34.96	Best:22.12
2025-01-05 23:19:52,280: Snapshot:4	Epoch:6	Loss:2.854	translation_Loss:2.263	token_training_loss:0.0	distillation_Loss:0.591                                                   	MRR:22.07	Hits@10:34.76	Best:22.12
2025-01-05 23:19:56,608: Snapshot:4	Epoch:7	Loss:2.751	translation_Loss:2.177	token_training_loss:0.0	distillation_Loss:0.574                                                   	MRR:22.04	Hits@10:34.71	Best:22.12
2025-01-05 23:20:01,293: Snapshot:4	Epoch:8	Loss:2.69	translation_Loss:2.128	token_training_loss:0.0	distillation_Loss:0.562                                                   	MRR:22.09	Hits@10:34.72	Best:22.12
2025-01-05 23:20:05,805: Snapshot:4	Epoch:9	Loss:2.669	translation_Loss:2.116	token_training_loss:0.0	distillation_Loss:0.553                                                   	MRR:22.04	Hits@10:34.7	Best:22.12
2025-01-05 23:20:10,361: Early Stopping! Snapshot: 4 Epoch: 10 Best Results: 22.12
2025-01-05 23:20:10,362: Start to training tokens! Snapshot: 4 Epoch: 10 Loss:2.636 MRR:21.99 Best Results: 22.12
Token added to optimizer, embeddings excluded successfully.
2025-01-05 23:20:10,362: Snapshot:4	Epoch:10	Loss:2.636	translation_Loss:2.092	token_training_loss:0.0	distillation_Loss:0.544                                                   	MRR:21.99	Hits@10:34.79	Best:22.12
2025-01-05 23:20:15,133: Snapshot:4	Epoch:11	Loss:25.041	translation_Loss:9.978	token_training_loss:15.063	distillation_Loss:0.0                                                   	MRR:21.99	Hits@10:34.79	Best:22.12
2025-01-05 23:20:19,567: End of token training: 4 Epoch: 12 Loss:10.901 MRR:21.99 Best Results: 22.12
2025-01-05 23:20:19,567: Snapshot:4	Epoch:12	Loss:10.901	translation_Loss:9.985	token_training_loss:0.916	distillation_Loss:0.0                                                           	MRR:21.99	Hits@10:34.79	Best:22.12
2025-01-05 23:20:19,828: => loading checkpoint './checkpoint/HYBRID/4model_best.tar'
2025-01-05 23:20:34,037: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2423 | 0.134  | 0.2929 | 0.3617 |  0.448  |
|     1      | 0.2697 | 0.1703 | 0.3063 | 0.369  |  0.4692 |
|     2      | 0.204  | 0.1174 | 0.2315 | 0.2904 |  0.3769 |
|     3      | 0.2115 | 0.1152 | 0.2487 | 0.3137 |  0.3952 |
|     4      | 0.2216 | 0.1527 | 0.248  | 0.2931 |  0.3541 |
+------------+--------+--------+--------+--------+---------+
2025-01-05 23:20:34,039: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2592 | 0.1528 | 0.3148 | 0.378  |  0.453  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2595 | 0.1531 | 0.3157 | 0.379  |  0.4547 |
|     1      | 0.293  | 0.1862 | 0.3376 | 0.4158 |  0.5074 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2525 | 0.1398 | 0.3132 | 0.3814 |  0.4594 |
|     1      | 0.2779 | 0.1725 | 0.3202 | 0.3904 |  0.4853 |
|     2      | 0.2166 | 0.1297 | 0.2482 | 0.3069 |  0.3879 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2569 | 0.1513 | 0.3083 | 0.3739 |  0.455  |
|     1      | 0.2732 | 0.1746 | 0.3069 | 0.3717 |  0.4691 |
|     2      | 0.2069 | 0.1211 | 0.2342 | 0.293  |  0.3774 |
|     3      | 0.2172 | 0.1218 | 0.2547 | 0.3185 |  0.3983 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2423 | 0.134  | 0.2929 | 0.3617 |  0.448  |
|     1      | 0.2697 | 0.1703 | 0.3063 | 0.369  |  0.4692 |
|     2      | 0.204  | 0.1174 | 0.2315 | 0.2904 |  0.3769 |
|     3      | 0.2115 | 0.1152 | 0.2487 | 0.3137 |  0.3952 |
|     4      | 0.2216 | 0.1527 | 0.248  | 0.2931 |  0.3541 |
+------------+--------+--------+--------+--------+---------+]
2025-01-05 23:20:34,040: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 116.02291941642761 |   0.259   |    0.153     |    0.315     |     0.453     |
|    1     | 74.40711784362793  |   0.268   |    0.162     |    0.322     |     0.469     |
|    2     | 176.24404978752136 |   0.237   |    0.139     |     0.28     |     0.425     |
|    3     | 201.80387163162231 |   0.227   |    0.132     |    0.263     |     0.409     |
|    4     | 62.47437620162964  |    0.22   |    0.128     |    0.256     |     0.399     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-05 23:20:34,040: Sum_Training_Time:630.9523348808289
2025-01-05 23:20:34,040: Every_Training_Time:[116.02291941642761, 74.40711784362793, 176.24404978752136, 201.80387163162231, 62.47437620162964]
2025-01-05 23:20:34,040: Forward transfer: 0.044325 Backward transfer: -0.014624999999999999
