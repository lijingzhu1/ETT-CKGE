2025-01-06 12:42:24,451: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/WN_CKGE/', dataset='WN_CKGE', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106124216/WN_CKGE', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/WN_CKGE', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[20000.0, 5000.0, 10000.0, 20000.0], token_num=3, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 12:42:32,428: Snapshot:0	Epoch:0	Loss:15.314	translation_Loss:15.314	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:1.68	Hits@10:4.8	Best:1.68
2025-01-06 12:42:39,438: Snapshot:0	Epoch:1	Loss:8.263	translation_Loss:8.263	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.17	Hits@10:16.63	Best:6.17
2025-01-06 12:42:46,156: Snapshot:0	Epoch:2	Loss:3.796	translation_Loss:3.796	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:10.92	Hits@10:27.94	Best:10.92
2025-01-06 12:42:53,291: Snapshot:0	Epoch:3	Loss:1.587	translation_Loss:1.587	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:13.18	Hits@10:33.2	Best:13.18
2025-01-06 12:42:59,996: Snapshot:0	Epoch:4	Loss:0.854	translation_Loss:0.854	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.04	Hits@10:35.51	Best:14.04
2025-01-06 12:43:06,992: Snapshot:0	Epoch:5	Loss:0.533	translation_Loss:0.533	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:14.63	Hits@10:36.64	Best:14.63
2025-01-06 12:43:13,666: Snapshot:0	Epoch:6	Loss:0.349	translation_Loss:0.349	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.0	Hits@10:37.43	Best:15.0
2025-01-06 12:43:20,569: Snapshot:0	Epoch:7	Loss:0.245	translation_Loss:0.245	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.19	Hits@10:37.95	Best:15.19
2025-01-06 12:43:27,432: Snapshot:0	Epoch:8	Loss:0.179	translation_Loss:0.179	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.36	Hits@10:38.19	Best:15.36
2025-01-06 12:43:34,180: Snapshot:0	Epoch:9	Loss:0.138	translation_Loss:0.138	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.47	Hits@10:38.46	Best:15.47
2025-01-06 12:43:41,165: Snapshot:0	Epoch:10	Loss:0.113	translation_Loss:0.113	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.59	Hits@10:38.68	Best:15.59
2025-01-06 12:43:47,799: Snapshot:0	Epoch:11	Loss:0.094	translation_Loss:0.094	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.66	Hits@10:38.96	Best:15.66
2025-01-06 12:43:54,780: Snapshot:0	Epoch:12	Loss:0.078	translation_Loss:0.078	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.69	Hits@10:39.12	Best:15.69
2025-01-06 12:44:01,643: Snapshot:0	Epoch:13	Loss:0.071	translation_Loss:0.071	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.8	Hits@10:39.27	Best:15.8
2025-01-06 12:44:08,269: Snapshot:0	Epoch:14	Loss:0.06	translation_Loss:0.06	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.84	Hits@10:39.37	Best:15.84
2025-01-06 12:44:15,101: Snapshot:0	Epoch:15	Loss:0.052	translation_Loss:0.052	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.87	Hits@10:39.44	Best:15.87
2025-01-06 12:44:21,797: Snapshot:0	Epoch:16	Loss:0.047	translation_Loss:0.047	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.9	Hits@10:39.53	Best:15.9
2025-01-06 12:44:28,788: Snapshot:0	Epoch:17	Loss:0.045	translation_Loss:0.045	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.94	Hits@10:39.69	Best:15.94
2025-01-06 12:44:35,414: Snapshot:0	Epoch:18	Loss:0.042	translation_Loss:0.042	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.96	Hits@10:39.78	Best:15.96
2025-01-06 12:44:42,361: Snapshot:0	Epoch:19	Loss:0.04	translation_Loss:0.04	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.97	Hits@10:39.88	Best:15.97
2025-01-06 12:44:49,130: Snapshot:0	Epoch:20	Loss:0.037	translation_Loss:0.037	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.96	Hits@10:39.75	Best:15.97
2025-01-06 12:44:55,895: Snapshot:0	Epoch:21	Loss:0.035	translation_Loss:0.035	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.97	Hits@10:39.97	Best:15.97
2025-01-06 12:45:02,848: Snapshot:0	Epoch:22	Loss:0.031	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.01	Hits@10:40.06	Best:16.01
2025-01-06 12:45:09,620: Snapshot:0	Epoch:23	Loss:0.031	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.02	Hits@10:40.24	Best:16.02
2025-01-06 12:45:16,582: Snapshot:0	Epoch:24	Loss:0.031	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.09	Hits@10:40.36	Best:16.09
2025-01-06 12:45:23,432: Snapshot:0	Epoch:25	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.09	Hits@10:40.39	Best:16.09
2025-01-06 12:45:30,379: Snapshot:0	Epoch:26	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.08	Hits@10:40.38	Best:16.09
2025-01-06 12:45:37,184: Snapshot:0	Epoch:27	Loss:0.029	translation_Loss:0.029	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.11	Hits@10:40.51	Best:16.11
2025-01-06 12:45:43,812: Snapshot:0	Epoch:28	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.14	Hits@10:40.52	Best:16.14
2025-01-06 12:45:50,630: Snapshot:0	Epoch:29	Loss:0.027	translation_Loss:0.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.17	Hits@10:40.52	Best:16.17
2025-01-06 12:45:57,277: Snapshot:0	Epoch:30	Loss:0.027	translation_Loss:0.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.15	Hits@10:40.56	Best:16.17
2025-01-06 12:46:04,121: Snapshot:0	Epoch:31	Loss:0.027	translation_Loss:0.027	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.12	Hits@10:40.53	Best:16.17
2025-01-06 12:46:10,918: Early Stopping! Snapshot: 0 Epoch: 32 Best Results: 16.17
2025-01-06 12:46:10,918: Start to training tokens! Snapshot: 0 Epoch: 32 Loss:0.028 MRR:16.1 Best Results: 16.17
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:46:10,919: Snapshot:0	Epoch:32	Loss:0.028	translation_Loss:0.028	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:16.1	Hits@10:40.55	Best:16.17
2025-01-06 12:46:18,155: Snapshot:0	Epoch:33	Loss:17.364	translation_Loss:5.553	token_training_loss:11.811	distillation_Loss:0.0                                                   	MRR:16.1	Hits@10:40.55	Best:16.17
2025-01-06 12:46:25,056: End of token training: 0 Epoch: 34 Loss:5.928 MRR:16.1 Best Results: 16.17
2025-01-06 12:46:25,056: Snapshot:0	Epoch:34	Loss:5.928	translation_Loss:5.549	token_training_loss:0.38	distillation_Loss:0.0                                                           	MRR:16.1	Hits@10:40.55	Best:16.17
2025-01-06 12:46:25,148: => loading checkpoint './checkpoint/WN_CKGE/0model_best.tar'
2025-01-06 12:46:28,522: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1639 | 0.0069 | 0.2929 | 0.3547 |  0.4083 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:46:31,820: Snapshot:1	Epoch:0	Loss:2.723	translation_Loss:2.648	token_training_loss:0.0	distillation_Loss:0.075                                                   	MRR:2.52	Hits@10:6.59	Best:2.52
2025-01-06 12:46:33,334: Snapshot:1	Epoch:1	Loss:1.755	translation_Loss:1.612	token_training_loss:0.0	distillation_Loss:0.142                                                   	MRR:7.51	Hits@10:19.7	Best:7.51
2025-01-06 12:46:34,743: Snapshot:1	Epoch:2	Loss:0.976	translation_Loss:0.8	token_training_loss:0.0	distillation_Loss:0.176                                                   	MRR:10.75	Hits@10:27.18	Best:10.75
2025-01-06 12:46:36,216: Snapshot:1	Epoch:3	Loss:0.527	translation_Loss:0.305	token_training_loss:0.0	distillation_Loss:0.222                                                   	MRR:12.55	Hits@10:30.11	Best:12.55
2025-01-06 12:46:37,680: Snapshot:1	Epoch:4	Loss:0.367	translation_Loss:0.115	token_training_loss:0.0	distillation_Loss:0.252                                                   	MRR:13.35	Hits@10:31.72	Best:13.35
2025-01-06 12:46:39,039: Snapshot:1	Epoch:5	Loss:0.3	translation_Loss:0.049	token_training_loss:0.0	distillation_Loss:0.252                                                   	MRR:13.75	Hits@10:32.63	Best:13.75
2025-01-06 12:46:40,429: Snapshot:1	Epoch:6	Loss:0.251	translation_Loss:0.024	token_training_loss:0.0	distillation_Loss:0.227                                                   	MRR:13.87	Hits@10:33.01	Best:13.87
2025-01-06 12:46:42,054: Snapshot:1	Epoch:7	Loss:0.208	translation_Loss:0.016	token_training_loss:0.0	distillation_Loss:0.192                                                   	MRR:13.89	Hits@10:33.15	Best:13.89
2025-01-06 12:46:43,394: Snapshot:1	Epoch:8	Loss:0.168	translation_Loss:0.013	token_training_loss:0.0	distillation_Loss:0.155                                                   	MRR:13.82	Hits@10:33.17	Best:13.89
2025-01-06 12:46:44,679: Snapshot:1	Epoch:9	Loss:0.134	translation_Loss:0.013	token_training_loss:0.0	distillation_Loss:0.121                                                   	MRR:13.73	Hits@10:33.12	Best:13.89
2025-01-06 12:46:45,937: Early Stopping! Snapshot: 1 Epoch: 10 Best Results: 13.89
2025-01-06 12:46:45,937: Start to training tokens! Snapshot: 1 Epoch: 10 Loss:0.108 MRR:13.73 Best Results: 13.89
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:46:45,938: Snapshot:1	Epoch:10	Loss:0.108	translation_Loss:0.013	token_training_loss:0.0	distillation_Loss:0.095                                                   	MRR:13.73	Hits@10:33.17	Best:13.89
2025-01-06 12:46:47,317: Snapshot:1	Epoch:11	Loss:8.055	translation_Loss:1.189	token_training_loss:6.867	distillation_Loss:0.0                                                   	MRR:13.73	Hits@10:33.17	Best:13.89
2025-01-06 12:46:48,685: End of token training: 1 Epoch: 12 Loss:4.707 MRR:13.73 Best Results: 13.89
2025-01-06 12:46:48,685: Snapshot:1	Epoch:12	Loss:4.707	translation_Loss:1.19	token_training_loss:3.517	distillation_Loss:0.0                                                           	MRR:13.73	Hits@10:33.17	Best:13.89
2025-01-06 12:46:48,761: => loading checkpoint './checkpoint/WN_CKGE/1model_best.tar'
2025-01-06 12:46:52,734: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1646 | 0.008  | 0.2916 | 0.3575 |  0.415  |
|     1      | 0.1398 | 0.0067 | 0.2532 | 0.2882 |  0.3331 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:46:56,257: Snapshot:2	Epoch:0	Loss:2.621	translation_Loss:2.598	token_training_loss:0.0	distillation_Loss:0.024                                                   	MRR:2.87	Hits@10:7.63	Best:2.87
2025-01-06 12:46:57,736: Snapshot:2	Epoch:1	Loss:1.599	translation_Loss:1.517	token_training_loss:0.0	distillation_Loss:0.082                                                   	MRR:7.93	Hits@10:20.13	Best:7.93
2025-01-06 12:46:59,250: Snapshot:2	Epoch:2	Loss:0.799	translation_Loss:0.678	token_training_loss:0.0	distillation_Loss:0.121                                                   	MRR:10.88	Hits@10:25.91	Best:10.88
2025-01-06 12:47:00,796: Snapshot:2	Epoch:3	Loss:0.354	translation_Loss:0.217	token_training_loss:0.0	distillation_Loss:0.137                                                   	MRR:12.39	Hits@10:28.25	Best:12.39
2025-01-06 12:47:02,313: Snapshot:2	Epoch:4	Loss:0.215	translation_Loss:0.074	token_training_loss:0.0	distillation_Loss:0.141                                                   	MRR:13.11	Hits@10:29.25	Best:13.11
2025-01-06 12:47:03,876: Snapshot:2	Epoch:5	Loss:0.166	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.136                                                   	MRR:13.48	Hits@10:30.24	Best:13.48
2025-01-06 12:47:05,379: Snapshot:2	Epoch:6	Loss:0.143	translation_Loss:0.017	token_training_loss:0.0	distillation_Loss:0.126                                                   	MRR:13.57	Hits@10:30.89	Best:13.57
2025-01-06 12:47:06,862: Snapshot:2	Epoch:7	Loss:0.127	translation_Loss:0.012	token_training_loss:0.0	distillation_Loss:0.115                                                   	MRR:13.7	Hits@10:31.16	Best:13.7
2025-01-06 12:47:08,370: Snapshot:2	Epoch:8	Loss:0.113	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.105                                                   	MRR:13.79	Hits@10:31.18	Best:13.79
2025-01-06 12:47:09,864: Snapshot:2	Epoch:9	Loss:0.101	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.095                                                   	MRR:13.84	Hits@10:31.32	Best:13.84
2025-01-06 12:47:11,584: Snapshot:2	Epoch:10	Loss:0.09	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.086                                                   	MRR:13.86	Hits@10:31.42	Best:13.86
2025-01-06 12:47:12,965: Snapshot:2	Epoch:11	Loss:0.081	translation_Loss:0.004	token_training_loss:0.0	distillation_Loss:0.077                                                   	MRR:13.8	Hits@10:31.51	Best:13.86
2025-01-06 12:47:14,399: Snapshot:2	Epoch:12	Loss:0.071	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.068                                                   	MRR:13.74	Hits@10:31.59	Best:13.86
2025-01-06 12:47:15,811: Early Stopping! Snapshot: 2 Epoch: 13 Best Results: 13.86
2025-01-06 12:47:15,811: Start to training tokens! Snapshot: 2 Epoch: 13 Loss:0.063 MRR:13.68 Best Results: 13.86
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:47:15,811: Snapshot:2	Epoch:13	Loss:0.063	translation_Loss:0.003	token_training_loss:0.0	distillation_Loss:0.061                                                   	MRR:13.68	Hits@10:31.56	Best:13.86
2025-01-06 12:47:17,298: Snapshot:2	Epoch:14	Loss:7.757	translation_Loss:1.132	token_training_loss:6.625	distillation_Loss:0.0                                                   	MRR:13.68	Hits@10:31.56	Best:13.86
2025-01-06 12:47:18,686: End of token training: 2 Epoch: 15 Loss:4.458 MRR:13.68 Best Results: 13.86
2025-01-06 12:47:18,686: Snapshot:2	Epoch:15	Loss:4.458	translation_Loss:1.133	token_training_loss:3.325	distillation_Loss:0.0                                                           	MRR:13.68	Hits@10:31.56	Best:13.86
2025-01-06 12:47:18,763: => loading checkpoint './checkpoint/WN_CKGE/2model_best.tar'
2025-01-06 12:47:23,548: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1599 | 0.0074 | 0.2791 | 0.3491 |  0.413  |
|     1      | 0.1356 | 0.0073 | 0.2398 | 0.2849 |  0.3306 |
|     2      | 0.1404 | 0.0078 | 0.2519 | 0.2849 |  0.3258 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:47:27,171: Snapshot:3	Epoch:0	Loss:2.601	translation_Loss:2.559	token_training_loss:0.0	distillation_Loss:0.042                                                   	MRR:3.03	Hits@10:7.34	Best:3.03
2025-01-06 12:47:28,726: Snapshot:3	Epoch:1	Loss:1.57	translation_Loss:1.445	token_training_loss:0.0	distillation_Loss:0.125                                                   	MRR:7.63	Hits@10:19.17	Best:7.63
2025-01-06 12:47:30,310: Snapshot:3	Epoch:2	Loss:0.779	translation_Loss:0.616	token_training_loss:0.0	distillation_Loss:0.163                                                   	MRR:10.73	Hits@10:25.05	Best:10.73
2025-01-06 12:47:31,978: Snapshot:3	Epoch:3	Loss:0.362	translation_Loss:0.187	token_training_loss:0.0	distillation_Loss:0.175                                                   	MRR:12.2	Hits@10:27.34	Best:12.2
2025-01-06 12:47:33,536: Snapshot:3	Epoch:4	Loss:0.245	translation_Loss:0.067	token_training_loss:0.0	distillation_Loss:0.177                                                   	MRR:12.91	Hits@10:28.68	Best:12.91
2025-01-06 12:47:35,171: Snapshot:3	Epoch:5	Loss:0.204	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:13.2	Hits@10:29.27	Best:13.2
2025-01-06 12:47:36,970: Snapshot:3	Epoch:6	Loss:0.182	translation_Loss:0.021	token_training_loss:0.0	distillation_Loss:0.161                                                   	MRR:13.31	Hits@10:29.57	Best:13.31
2025-01-06 12:47:38,581: Snapshot:3	Epoch:7	Loss:0.16	translation_Loss:0.013	token_training_loss:0.0	distillation_Loss:0.147                                                   	MRR:13.37	Hits@10:29.7	Best:13.37
2025-01-06 12:47:40,041: Snapshot:3	Epoch:8	Loss:0.14	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.131                                                   	MRR:13.37	Hits@10:29.95	Best:13.37
2025-01-06 12:47:41,716: Snapshot:3	Epoch:9	Loss:0.122	translation_Loss:0.007	token_training_loss:0.0	distillation_Loss:0.114                                                   	MRR:13.41	Hits@10:30.3	Best:13.41
2025-01-06 12:47:43,301: Snapshot:3	Epoch:10	Loss:0.104	translation_Loss:0.006	token_training_loss:0.0	distillation_Loss:0.098                                                   	MRR:13.48	Hits@10:30.38	Best:13.48
2025-01-06 12:47:44,875: Snapshot:3	Epoch:11	Loss:0.089	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.083                                                   	MRR:13.52	Hits@10:30.56	Best:13.52
2025-01-06 12:47:46,480: Snapshot:3	Epoch:12	Loss:0.076	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.07                                                   	MRR:13.54	Hits@10:30.62	Best:13.54
2025-01-06 12:47:48,003: Snapshot:3	Epoch:13	Loss:0.065	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.06                                                   	MRR:13.49	Hits@10:30.75	Best:13.54
2025-01-06 12:47:49,517: Snapshot:3	Epoch:14	Loss:0.057	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.052                                                   	MRR:13.48	Hits@10:30.91	Best:13.54
2025-01-06 12:47:50,971: Early Stopping! Snapshot: 3 Epoch: 15 Best Results: 13.54
2025-01-06 12:47:50,971: Start to training tokens! Snapshot: 3 Epoch: 15 Loss:0.05 MRR:13.52 Best Results: 13.54
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:47:50,972: Snapshot:3	Epoch:15	Loss:0.05	translation_Loss:0.005	token_training_loss:0.0	distillation_Loss:0.045                                                   	MRR:13.52	Hits@10:30.86	Best:13.54
2025-01-06 12:47:52,478: Snapshot:3	Epoch:16	Loss:7.694	translation_Loss:1.137	token_training_loss:6.557	distillation_Loss:0.0                                                   	MRR:13.52	Hits@10:30.86	Best:13.54
2025-01-06 12:47:53,880: End of token training: 3 Epoch: 17 Loss:4.324 MRR:13.52 Best Results: 13.54
2025-01-06 12:47:53,880: Snapshot:3	Epoch:17	Loss:4.324	translation_Loss:1.138	token_training_loss:3.186	distillation_Loss:0.0                                                           	MRR:13.52	Hits@10:30.86	Best:13.54
2025-01-06 12:47:54,005: => loading checkpoint './checkpoint/WN_CKGE/3model_best.tar'
2025-01-06 12:47:59,774: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1582 | 0.0073 | 0.2749 | 0.3481 |  0.4091 |
|     1      | 0.1331 | 0.0059 | 0.2355 | 0.2809 |  0.3261 |
|     2      | 0.1373 | 0.007  | 0.247  | 0.2849 |  0.3237 |
|     3      | 0.137  | 0.0078 | 0.2441 | 0.2849 |  0.3207 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 12:48:03,611: Snapshot:4	Epoch:0	Loss:2.567	translation_Loss:2.495	token_training_loss:0.0	distillation_Loss:0.072                                                   	MRR:10.11	Hits@10:24.41	Best:10.11
2025-01-06 12:48:05,328: Snapshot:4	Epoch:1	Loss:1.548	translation_Loss:1.375	token_training_loss:0.0	distillation_Loss:0.172                                                   	MRR:11.72	Hits@10:28.17	Best:11.72
2025-01-06 12:48:07,007: Snapshot:4	Epoch:2	Loss:0.755	translation_Loss:0.557	token_training_loss:0.0	distillation_Loss:0.198                                                   	MRR:12.93	Hits@10:30.51	Best:12.93
2025-01-06 12:48:08,816: Snapshot:4	Epoch:3	Loss:0.374	translation_Loss:0.161	token_training_loss:0.0	distillation_Loss:0.212                                                   	MRR:13.53	Hits@10:31.26	Best:13.53
2025-01-06 12:48:10,733: Snapshot:4	Epoch:4	Loss:0.282	translation_Loss:0.062	token_training_loss:0.0	distillation_Loss:0.221                                                   	MRR:13.82	Hits@10:31.61	Best:13.82
2025-01-06 12:48:12,441: Snapshot:4	Epoch:5	Loss:0.243	translation_Loss:0.031	token_training_loss:0.0	distillation_Loss:0.212                                                   	MRR:13.97	Hits@10:31.91	Best:13.97
2025-01-06 12:48:14,129: Snapshot:4	Epoch:6	Loss:0.211	translation_Loss:0.02	token_training_loss:0.0	distillation_Loss:0.19                                                   	MRR:14.06	Hits@10:32.07	Best:14.06
2025-01-06 12:48:15,772: Snapshot:4	Epoch:7	Loss:0.179	translation_Loss:0.014	token_training_loss:0.0	distillation_Loss:0.164                                                   	MRR:14.01	Hits@10:32.37	Best:14.06
2025-01-06 12:48:17,419: Snapshot:4	Epoch:8	Loss:0.15	translation_Loss:0.012	token_training_loss:0.0	distillation_Loss:0.138                                                   	MRR:13.89	Hits@10:32.45	Best:14.06
2025-01-06 12:48:19,036: Early Stopping! Snapshot: 4 Epoch: 9 Best Results: 14.06
2025-01-06 12:48:19,037: Start to training tokens! Snapshot: 4 Epoch: 9 Loss:0.121 MRR:13.87 Best Results: 14.06
Token added to optimizer, embeddings excluded successfully.
2025-01-06 12:48:19,037: Snapshot:4	Epoch:9	Loss:0.121	translation_Loss:0.009	token_training_loss:0.0	distillation_Loss:0.112                                                   	MRR:13.87	Hits@10:32.5	Best:14.06
2025-01-06 12:48:20,679: Snapshot:4	Epoch:10	Loss:7.736	translation_Loss:1.157	token_training_loss:6.58	distillation_Loss:0.0                                                   	MRR:13.87	Hits@10:32.5	Best:14.06
2025-01-06 12:48:22,218: End of token training: 4 Epoch: 11 Loss:4.437 MRR:13.87 Best Results: 14.06
2025-01-06 12:48:22,218: Snapshot:4	Epoch:11	Loss:4.437	translation_Loss:1.153	token_training_loss:3.284	distillation_Loss:0.0                                                           	MRR:13.87	Hits@10:32.5	Best:14.06
2025-01-06 12:48:22,309: => loading checkpoint './checkpoint/WN_CKGE/4model_best.tar'
2025-01-06 12:48:29,174: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1559 | 0.0074 | 0.2706 | 0.3412 |  0.4043 |
|     1      | 0.1295 | 0.0065 | 0.2261 | 0.2715 |  0.3164 |
|     2      | 0.1362 | 0.0078 | 0.2444 | 0.2804 |  0.3194 |
|     3      | 0.1373 | 0.0099 | 0.2414 | 0.2828 |  0.3218 |
|     4      | 0.133  | 0.0081 |  0.23  | 0.2875 |  0.3267 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 12:48:29,176: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1639 | 0.0069 | 0.2929 | 0.3547 |  0.4083 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1646 | 0.008  | 0.2916 | 0.3575 |  0.415  |
|     1      | 0.1398 | 0.0067 | 0.2532 | 0.2882 |  0.3331 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1599 | 0.0074 | 0.2791 | 0.3491 |  0.413  |
|     1      | 0.1356 | 0.0073 | 0.2398 | 0.2849 |  0.3306 |
|     2      | 0.1404 | 0.0078 | 0.2519 | 0.2849 |  0.3258 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1582 | 0.0073 | 0.2749 | 0.3481 |  0.4091 |
|     1      | 0.1331 | 0.0059 | 0.2355 | 0.2809 |  0.3261 |
|     2      | 0.1373 | 0.007  | 0.247  | 0.2849 |  0.3237 |
|     3      | 0.137  | 0.0078 | 0.2441 | 0.2849 |  0.3207 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1559 | 0.0074 | 0.2706 | 0.3412 |  0.4043 |
|     1      | 0.1295 | 0.0065 | 0.2261 | 0.2715 |  0.3164 |
|     2      | 0.1362 | 0.0078 | 0.2444 | 0.2804 |  0.3194 |
|     3      | 0.1373 | 0.0099 | 0.2414 | 0.2828 |  0.3218 |
|     4      | 0.133  | 0.0081 |  0.23  | 0.2875 |  0.3267 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 12:48:29,177: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 240.6048891544342  |   0.164   |    0.007     |    0.293     |     0.408     |
|    1     | 19.268535137176514 |   0.161   |    0.008     |    0.286     |     0.403     |
|    2     | 25.161583423614502 |   0.154   |    0.007     |    0.271     |     0.392     |
|    3     |  29.3131422996521  |   0.151   |    0.007     |    0.264     |     0.381     |
|    4     | 21.328745365142822 |   0.147   |    0.008     |    0.257     |     0.371     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 12:48:29,177: Sum_Training_Time:335.67689538002014
2025-01-06 12:48:29,177: Every_Training_Time:[240.6048891544342, 19.268535137176514, 25.161583423614502, 29.3131422996521, 21.328745365142822]
2025-01-06 12:48:29,177: Forward transfer: 0.059275 Backward transfer: -0.005549999999999999