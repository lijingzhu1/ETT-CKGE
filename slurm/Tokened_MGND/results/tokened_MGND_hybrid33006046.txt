2024-12-26 23:27:57,720: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241226232727/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-26 23:28:07,510: Snapshot:0	Epoch:0	Loss:22.251	translation_Loss:22.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.47	Hits@10:21.0	Best:8.47
2024-12-26 23:28:12,956: Snapshot:0	Epoch:1	Loss:14.345	translation_Loss:14.345	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.18	Hits@10:35.97	Best:16.18
2024-12-26 23:28:18,855: Snapshot:0	Epoch:2	Loss:8.169	translation_Loss:8.169	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.17	Hits@10:42.56	Best:22.17
2024-12-26 23:28:24,950: Snapshot:0	Epoch:3	Loss:4.491	translation_Loss:4.491	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.4	Hits@10:45.04	Best:24.4
2024-12-26 23:28:31,455: Snapshot:0	Epoch:4	Loss:2.637	translation_Loss:2.637	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.23	Hits@10:45.82	Best:25.23
2024-12-26 23:28:37,888: Snapshot:0	Epoch:5	Loss:1.728	translation_Loss:1.728	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.64	Hits@10:46.42	Best:25.64
2024-12-26 23:28:43,938: Snapshot:0	Epoch:6	Loss:1.238	translation_Loss:1.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.63	Hits@10:46.52	Best:25.64
2024-12-26 23:28:49,752: Snapshot:0	Epoch:7	Loss:0.965	translation_Loss:0.965	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.74	Hits@10:46.43	Best:25.74
2024-12-26 23:28:55,236: Snapshot:0	Epoch:8	Loss:0.794	translation_Loss:0.794	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.74	Hits@10:46.28	Best:25.74
2024-12-26 23:29:00,727: Snapshot:0	Epoch:9	Loss:0.692	translation_Loss:0.692	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.59	Hits@10:46.3	Best:25.74
2024-12-26 23:29:06,514: Snapshot:0	Epoch:10	Loss:0.603	translation_Loss:0.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.83	Hits@10:46.05	Best:25.83
2024-12-26 23:29:13,309: Snapshot:0	Epoch:11	Loss:0.542	translation_Loss:0.542	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.95	Hits@10:45.94	Best:25.95
2024-12-26 23:29:19,617: Snapshot:0	Epoch:12	Loss:0.487	translation_Loss:0.487	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.92	Hits@10:45.9	Best:25.95
2024-12-26 23:29:25,966: Snapshot:0	Epoch:13	Loss:0.44	translation_Loss:0.44	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.75	Hits@10:45.85	Best:25.95
2024-12-26 23:29:31,773: Early Stopping! Snapshot: 0 Epoch: 14 Best Results: 25.95
2024-12-26 23:29:31,773: Start to training tokens! Snapshot: 0 Epoch: 14 Loss:0.411 MRR:25.66 Best Results: 25.95
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-26 23:29:31,773: Snapshot:0	Epoch:14	Loss:0.411	translation_Loss:0.411	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.66	Hits@10:45.63	Best:25.95
2024-12-26 23:29:37,724: Snapshot:0	Epoch:15	Loss:32.442	translation_Loss:17.171	multi_layer_Loss:15.271	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.66	Hits@10:45.63	Best:25.95
2024-12-26 23:29:43,566: End of token training: 0 Epoch: 16 Loss:17.287 MRR:25.66 Best Results: 25.95
2024-12-26 23:29:43,566: Snapshot:0	Epoch:16	Loss:17.287	translation_Loss:17.144	multi_layer_Loss:0.143	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.66	Hits@10:45.63	Best:25.95
2024-12-26 23:29:43,807: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2024-12-26 23:29:46,101: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2568 | 0.1507 | 0.3117 | 0.3756 |  0.4521 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-26 23:29:56,567: Snapshot:1	Epoch:0	Loss:6.61	translation_Loss:6.477	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.132                                                   	MRR:12.07	Hits@10:22.62	Best:12.07
2024-12-26 23:29:58,733: Snapshot:1	Epoch:1	Loss:3.114	translation_Loss:2.81	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.304                                                   	MRR:20.4	Hits@10:36.35	Best:20.4
2024-12-26 23:30:00,875: Snapshot:1	Epoch:2	Loss:1.624	translation_Loss:1.222	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.402                                                   	MRR:25.04	Hits@10:42.75	Best:25.04
2024-12-26 23:30:03,058: Snapshot:1	Epoch:3	Loss:1.048	translation_Loss:0.614	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.434                                                   	MRR:26.13	Hits@10:44.89	Best:26.13
2024-12-26 23:30:05,237: Snapshot:1	Epoch:4	Loss:0.775	translation_Loss:0.36	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.415                                                   	MRR:26.79	Hits@10:45.46	Best:26.79
2024-12-26 23:30:07,336: Snapshot:1	Epoch:5	Loss:0.63	translation_Loss:0.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.375                                                   	MRR:27.18	Hits@10:45.87	Best:27.18
2024-12-26 23:30:09,498: Snapshot:1	Epoch:6	Loss:0.544	translation_Loss:0.203	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.341                                                   	MRR:27.3	Hits@10:46.42	Best:27.3
2024-12-26 23:30:11,677: Snapshot:1	Epoch:7	Loss:0.495	translation_Loss:0.179	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.316                                                   	MRR:27.96	Hits@10:47.38	Best:27.96
2024-12-26 23:30:13,837: Snapshot:1	Epoch:8	Loss:0.456	translation_Loss:0.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.298                                                   	MRR:28.25	Hits@10:47.76	Best:28.25
2024-12-26 23:30:15,972: Snapshot:1	Epoch:9	Loss:0.434	translation_Loss:0.15	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.284                                                   	MRR:28.8	Hits@10:48.91	Best:28.8
2024-12-26 23:30:18,102: Snapshot:1	Epoch:10	Loss:0.412	translation_Loss:0.14	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.272                                                   	MRR:28.99	Hits@10:49.11	Best:28.99
2024-12-26 23:30:20,257: Snapshot:1	Epoch:11	Loss:0.397	translation_Loss:0.134	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.262                                                   	MRR:29.31	Hits@10:49.43	Best:29.31
2024-12-26 23:30:22,341: Snapshot:1	Epoch:12	Loss:0.38	translation_Loss:0.125	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.254                                                   	MRR:29.54	Hits@10:50.04	Best:29.54
2024-12-26 23:30:24,412: Snapshot:1	Epoch:13	Loss:0.37	translation_Loss:0.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.247                                                   	MRR:29.76	Hits@10:50.47	Best:29.76
2024-12-26 23:30:26,510: Snapshot:1	Epoch:14	Loss:0.36	translation_Loss:0.119	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.241                                                   	MRR:30.37	Hits@10:50.55	Best:30.37
2024-12-26 23:30:28,614: Snapshot:1	Epoch:15	Loss:0.355	translation_Loss:0.119	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.236                                                   	MRR:30.25	Hits@10:50.69	Best:30.37
2024-12-26 23:30:30,723: Snapshot:1	Epoch:16	Loss:0.346	translation_Loss:0.115	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.231                                                   	MRR:30.27	Hits@10:50.78	Best:30.37
2024-12-26 23:30:32,845: Early Stopping! Snapshot: 1 Epoch: 17 Best Results: 30.37
2024-12-26 23:30:32,845: Start to training tokens! Snapshot: 1 Epoch: 17 Loss:0.336 MRR:29.98 Best Results: 30.37
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-26 23:30:32,845: Snapshot:1	Epoch:17	Loss:0.336	translation_Loss:0.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.227                                                   	MRR:29.98	Hits@10:50.72	Best:30.37
2024-12-26 23:30:35,006: Snapshot:1	Epoch:18	Loss:19.498	translation_Loss:5.97	multi_layer_Loss:13.527	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:29.98	Hits@10:50.72	Best:30.37
2024-12-26 23:30:37,151: End of token training: 1 Epoch: 19 Loss:7.342 MRR:29.98 Best Results: 30.37
2024-12-26 23:30:37,151: Snapshot:1	Epoch:19	Loss:7.342	translation_Loss:5.979	multi_layer_Loss:1.363	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:29.98	Hits@10:50.72	Best:30.37
2024-12-26 23:30:37,363: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2024-12-26 23:30:41,037: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2535 | 0.1485 | 0.3063 | 0.3718 |  0.4472 |
|     1      | 0.2992 | 0.1931 | 0.3495 | 0.4188 |  0.5041 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-26 23:31:11,848: Snapshot:2	Epoch:0	Loss:20.503	translation_Loss:19.353	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.15                                                   	MRR:17.39	Hits@10:32.96	Best:17.39
2024-12-26 23:31:20,977: Snapshot:2	Epoch:1	Loss:7.405	translation_Loss:5.59	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.815                                                   	MRR:20.39	Hits@10:37.44	Best:20.39
2024-12-26 23:31:30,748: Snapshot:2	Epoch:2	Loss:4.78	translation_Loss:3.056	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.725                                                   	MRR:21.12	Hits@10:38.24	Best:21.12
2024-12-26 23:31:41,244: Snapshot:2	Epoch:3	Loss:4.047	translation_Loss:2.406	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.641                                                   	MRR:21.59	Hits@10:38.57	Best:21.59
2024-12-26 23:31:51,810: Snapshot:2	Epoch:4	Loss:3.782	translation_Loss:2.169	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.613                                                   	MRR:21.67	Hits@10:38.44	Best:21.67
2024-12-26 23:32:02,271: Snapshot:2	Epoch:5	Loss:3.662	translation_Loss:2.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.591                                                   	MRR:21.84	Hits@10:38.83	Best:21.84
2024-12-26 23:32:13,222: Snapshot:2	Epoch:6	Loss:3.546	translation_Loss:1.965	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.581                                                   	MRR:21.6	Hits@10:38.53	Best:21.84
2024-12-26 23:32:23,723: Snapshot:2	Epoch:7	Loss:3.503	translation_Loss:1.936	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.567                                                   	MRR:21.74	Hits@10:38.59	Best:21.84
2024-12-26 23:32:34,133: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 21.84
2024-12-26 23:32:34,133: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:3.471 MRR:21.75 Best Results: 21.84
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-26 23:32:34,134: Snapshot:2	Epoch:8	Loss:3.471	translation_Loss:1.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.572                                                   	MRR:21.75	Hits@10:38.95	Best:21.84
2024-12-26 23:32:44,931: Snapshot:2	Epoch:9	Loss:39.713	translation_Loss:25.166	multi_layer_Loss:14.546	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.75	Hits@10:38.95	Best:21.84
2024-12-26 23:32:55,366: End of token training: 2 Epoch: 10 Loss:25.153 MRR:21.75 Best Results: 21.84
2024-12-26 23:32:55,366: Snapshot:2	Epoch:10	Loss:25.153	translation_Loss:25.13	multi_layer_Loss:0.023	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.75	Hits@10:38.95	Best:21.84
2024-12-26 23:32:55,660: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2024-12-26 23:33:03,690: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2468 | 0.1395 | 0.2958 | 0.3682 |  0.4524 |
|     1      | 0.2674 | 0.1655 | 0.3096 | 0.3783 |  0.4592 |
|     2      | 0.2187 | 0.1318 | 0.2469 | 0.3091 |  0.3906 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-26 23:33:43,224: Snapshot:3	Epoch:0	Loss:18.409	translation_Loss:16.857	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.552                                                   	MRR:18.02	Hits@10:35.01	Best:18.02
2024-12-26 23:33:55,856: Snapshot:3	Epoch:1	Loss:6.456	translation_Loss:4.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.135                                                   	MRR:20.31	Hits@10:38.07	Best:20.31
2024-12-26 23:34:08,631: Snapshot:3	Epoch:2	Loss:4.667	translation_Loss:2.723	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.944                                                   	MRR:21.06	Hits@10:38.96	Best:21.06
2024-12-26 23:34:19,731: Snapshot:3	Epoch:3	Loss:4.198	translation_Loss:2.324	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.874                                                   	MRR:21.18	Hits@10:38.67	Best:21.18
2024-12-26 23:34:30,848: Snapshot:3	Epoch:4	Loss:4.02	translation_Loss:2.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.851                                                   	MRR:21.34	Hits@10:38.92	Best:21.34
2024-12-26 23:34:42,242: Snapshot:3	Epoch:5	Loss:3.927	translation_Loss:2.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.846                                                   	MRR:21.39	Hits@10:38.92	Best:21.39
2024-12-26 23:34:53,178: Snapshot:3	Epoch:6	Loss:3.871	translation_Loss:2.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.841                                                   	MRR:21.26	Hits@10:38.84	Best:21.39
2024-12-26 23:35:04,466: Snapshot:3	Epoch:7	Loss:3.857	translation_Loss:2.005	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.852                                                   	MRR:21.24	Hits@10:39.1	Best:21.39
2024-12-26 23:35:15,403: Early Stopping! Snapshot: 3 Epoch: 8 Best Results: 21.39
2024-12-26 23:35:15,404: Start to training tokens! Snapshot: 3 Epoch: 8 Loss:3.838 MRR:21.29 Best Results: 21.39
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-26 23:35:15,404: Snapshot:3	Epoch:8	Loss:3.838	translation_Loss:1.983	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.855                                                   	MRR:21.29	Hits@10:39.08	Best:21.39
2024-12-26 23:35:26,316: Snapshot:3	Epoch:9	Loss:42.298	translation_Loss:26.888	multi_layer_Loss:15.41	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.29	Hits@10:39.08	Best:21.39
2024-12-26 23:35:37,791: End of token training: 3 Epoch: 10 Loss:26.872 MRR:21.29 Best Results: 21.39
2024-12-26 23:35:37,791: Snapshot:3	Epoch:10	Loss:26.872	translation_Loss:26.863	multi_layer_Loss:0.009	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.29	Hits@10:39.08	Best:21.39
2024-12-26 23:35:38,030: => loading checkpoint './checkpoint/HYBRID/3model_best.tar'
2024-12-26 23:35:50,123: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2531 | 0.1515 | 0.2986 | 0.3645 |  0.444  |
|     1      | 0.2612 | 0.1662 | 0.2919 | 0.3551 |  0.4473 |
|     2      | 0.2083 | 0.1213 | 0.2372 | 0.2969 |  0.3786 |
|     3      | 0.2134 | 0.1211 | 0.2477 | 0.3088 |  0.3902 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-26 23:36:06,829: Snapshot:4	Epoch:0	Loss:8.478	translation_Loss:8.143	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.335                                                   	MRR:12.48	Hits@10:28.6	Best:12.48
2024-12-26 23:36:11,741: Snapshot:4	Epoch:1	Loss:3.737	translation_Loss:3.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.707                                                   	MRR:18.73	Hits@10:35.17	Best:18.73
2024-12-26 23:36:16,257: Snapshot:4	Epoch:2	Loss:2.146	translation_Loss:1.25	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.896                                                   	MRR:20.81	Hits@10:36.83	Best:20.81
2024-12-26 23:36:20,821: Snapshot:4	Epoch:3	Loss:1.559	translation_Loss:0.646	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.913                                                   	MRR:21.9	Hits@10:37.23	Best:21.9
2024-12-26 23:36:25,378: Snapshot:4	Epoch:4	Loss:1.328	translation_Loss:0.471	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.857                                                   	MRR:22.03	Hits@10:36.78	Best:22.03
2024-12-26 23:36:29,839: Snapshot:4	Epoch:5	Loss:1.21	translation_Loss:0.397	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.814                                                   	MRR:22.04	Hits@10:36.85	Best:22.04
2024-12-26 23:36:35,071: Snapshot:4	Epoch:6	Loss:1.156	translation_Loss:0.376	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.78                                                   	MRR:22.73	Hits@10:37.06	Best:22.73
2024-12-26 23:36:40,208: Snapshot:4	Epoch:7	Loss:1.116	translation_Loss:0.363	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.753                                                   	MRR:22.72	Hits@10:37.0	Best:22.73
2024-12-26 23:36:45,872: Snapshot:4	Epoch:8	Loss:1.09	translation_Loss:0.351	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.738                                                   	MRR:22.17	Hits@10:37.17	Best:22.73
2024-12-26 23:36:50,935: Early Stopping! Snapshot: 4 Epoch: 9 Best Results: 22.73
2024-12-26 23:36:50,935: Start to training tokens! Snapshot: 4 Epoch: 9 Loss:1.074 MRR:22.42 Best Results: 22.73
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-26 23:36:50,936: Snapshot:4	Epoch:9	Loss:1.074	translation_Loss:0.344	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.729                                                   	MRR:22.42	Hits@10:37.18	Best:22.73
2024-12-26 23:36:56,041: Snapshot:4	Epoch:10	Loss:27.94	translation_Loss:12.168	multi_layer_Loss:15.772	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.42	Hits@10:37.18	Best:22.73
2024-12-26 23:37:01,186: End of token training: 4 Epoch: 11 Loss:12.492 MRR:22.42 Best Results: 22.73
2024-12-26 23:37:01,187: Snapshot:4	Epoch:11	Loss:12.492	translation_Loss:12.142	multi_layer_Loss:0.349	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.42	Hits@10:37.18	Best:22.73
2024-12-26 23:37:01,430: => loading checkpoint './checkpoint/HYBRID/4model_best.tar'
2024-12-26 23:37:17,275: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2051 | 0.1139 | 0.2422 | 0.3014 |  0.3764 |
|     1      | 0.2363 | 0.1485 | 0.2614 | 0.3198 |  0.4164 |
|     2      | 0.185  | 0.1066 | 0.2084 | 0.2599 |  0.3379 |
|     3      | 0.1767 | 0.0941 | 0.2036 | 0.2589 |  0.3333 |
|     4      | 0.2233 | 0.144  | 0.2529 | 0.3027 |  0.3696 |
+------------+--------+--------+--------+--------+---------+
2024-12-26 23:37:17,276: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2568 | 0.1507 | 0.3117 | 0.3756 |  0.4521 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2535 | 0.1485 | 0.3063 | 0.3718 |  0.4472 |
|     1      | 0.2992 | 0.1931 | 0.3495 | 0.4188 |  0.5041 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2468 | 0.1395 | 0.2958 | 0.3682 |  0.4524 |
|     1      | 0.2674 | 0.1655 | 0.3096 | 0.3783 |  0.4592 |
|     2      | 0.2187 | 0.1318 | 0.2469 | 0.3091 |  0.3906 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2531 | 0.1515 | 0.2986 | 0.3645 |  0.444  |
|     1      | 0.2612 | 0.1662 | 0.2919 | 0.3551 |  0.4473 |
|     2      | 0.2083 | 0.1213 | 0.2372 | 0.2969 |  0.3786 |
|     3      | 0.2134 | 0.1211 | 0.2477 | 0.3088 |  0.3902 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2051 | 0.1139 | 0.2422 | 0.3014 |  0.3764 |
|     1      | 0.2363 | 0.1485 | 0.2614 | 0.3198 |  0.4164 |
|     2      | 0.185  | 0.1066 | 0.2084 | 0.2599 |  0.3379 |
|     3      | 0.1767 | 0.0941 | 0.2036 | 0.2589 |  0.3333 |
|     4      | 0.2233 | 0.144  | 0.2529 | 0.3027 |  0.3696 |
+------------+--------+--------+--------+--------+---------+]
2024-12-26 23:37:17,277: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 105.84533429145813 |   0.257   |    0.151     |    0.312     |     0.452     |
|    1     | 49.866180658340454 |   0.266   |     0.16     |    0.318     |     0.462     |
|    2     | 130.2826132774353  |   0.235   |    0.139     |    0.272     |     0.421     |
|    3     | 149.0721402168274  |   0.224   |    0.131     |    0.259     |     0.402     |
|    4     | 68.81027913093567  |   0.194   |    0.111     |    0.222     |     0.353     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-26 23:37:17,277: Sum_Training_Time:503.87654757499695
2024-12-26 23:37:17,277: Every_Training_Time:[105.84533429145813, 49.866180658340454, 130.2826132774353, 149.0721402168274, 68.81027913093567]
2024-12-26 23:37:17,277: Forward transfer: 0.04345 Backward transfer: -0.04625
2024-12-26 23:37:49,154: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241226233721/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=2, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-26 23:37:58,019: Snapshot:0	Epoch:0	Loss:22.251	translation_Loss:22.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.47	Hits@10:21.0	Best:8.47
2024-12-26 23:38:03,513: Snapshot:0	Epoch:1	Loss:14.345	translation_Loss:14.345	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.18	Hits@10:35.97	Best:16.18
2024-12-26 23:38:09,306: Snapshot:0	Epoch:2	Loss:8.169	translation_Loss:8.169	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.17	Hits@10:42.62	Best:22.17
2024-12-26 23:38:14,822: Snapshot:0	Epoch:3	Loss:4.491	translation_Loss:4.491	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.42	Hits@10:44.99	Best:24.42
2024-12-26 23:38:20,306: Snapshot:0	Epoch:4	Loss:2.638	translation_Loss:2.638	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.17	Hits@10:45.85	Best:25.17
2024-12-26 23:38:25,775: Snapshot:0	Epoch:5	Loss:1.73	translation_Loss:1.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.64	Hits@10:46.5	Best:25.64
2024-12-26 23:38:31,152: Snapshot:0	Epoch:6	Loss:1.237	translation_Loss:1.237	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.73	Hits@10:46.4	Best:25.73
2024-12-26 23:38:37,095: Snapshot:0	Epoch:7	Loss:0.967	translation_Loss:0.967	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.78	Hits@10:46.42	Best:25.78
2024-12-26 23:38:43,657: Snapshot:0	Epoch:8	Loss:0.793	translation_Loss:0.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.79	Hits@10:46.3	Best:25.79
2024-12-26 23:38:50,136: Snapshot:0	Epoch:9	Loss:0.692	translation_Loss:0.692	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.71	Hits@10:46.13	Best:25.79
2024-12-26 23:38:56,453: Snapshot:0	Epoch:10	Loss:0.604	translation_Loss:0.604	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.82	Hits@10:45.89	Best:25.82
2024-12-26 23:39:03,221: Snapshot:0	Epoch:11	Loss:0.542	translation_Loss:0.542	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.83	Hits@10:45.71	Best:25.83
2024-12-26 23:39:09,554: Snapshot:0	Epoch:12	Loss:0.488	translation_Loss:0.488	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.86	Hits@10:45.89	Best:25.86
2024-12-26 23:39:15,867: Snapshot:0	Epoch:13	Loss:0.442	translation_Loss:0.442	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.83	Hits@10:45.7	Best:25.86
2024-12-26 23:39:22,144: Snapshot:0	Epoch:14	Loss:0.409	translation_Loss:0.409	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.75	Hits@10:45.65	Best:25.86
2024-12-26 23:39:28,412: Early Stopping! Snapshot: 0 Epoch: 15 Best Results: 25.86
2024-12-26 23:39:28,412: Start to training tokens! Snapshot: 0 Epoch: 15 Loss:0.38 MRR:25.62 Best Results: 25.86
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-26 23:39:28,413: Snapshot:0	Epoch:15	Loss:0.38	translation_Loss:0.38	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.62	Hits@10:45.65	Best:25.86
2024-12-26 23:39:35,557: Snapshot:0	Epoch:16	Loss:27.032	translation_Loss:17.135	multi_layer_Loss:9.897	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.62	Hits@10:45.65	Best:25.86
2024-12-26 23:39:41,903: End of token training: 0 Epoch: 17 Loss:17.284 MRR:25.62 Best Results: 25.86
2024-12-26 23:39:41,903: Snapshot:0	Epoch:17	Loss:17.284	translation_Loss:17.169	multi_layer_Loss:0.115	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.62	Hits@10:45.65	Best:25.86
2024-12-26 23:39:42,148: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2024-12-26 23:39:44,664: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2594 | 0.1536 | 0.3138 | 0.3763 |  0.4528 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-26 23:39:55,681: Snapshot:1	Epoch:0	Loss:6.531	translation_Loss:6.457	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.074                                                   	MRR:12.14	Hits@10:22.99	Best:12.14
2024-12-26 23:39:58,209: Snapshot:1	Epoch:1	Loss:2.939	translation_Loss:2.751	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:20.65	Hits@10:36.71	Best:20.65
2024-12-26 23:40:00,735: Snapshot:1	Epoch:2	Loss:1.4	translation_Loss:1.149	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.251                                                   	MRR:25.34	Hits@10:43.65	Best:25.34
2024-12-26 23:40:03,271: Snapshot:1	Epoch:3	Loss:0.82	translation_Loss:0.542	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.278                                                   	MRR:26.79	Hits@10:45.5	Best:26.79
2024-12-26 23:40:05,804: Snapshot:1	Epoch:4	Loss:0.563	translation_Loss:0.286	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.277                                                   	MRR:27.15	Hits@10:45.74	Best:27.15
2024-12-26 23:40:08,263: Snapshot:1	Epoch:5	Loss:0.443	translation_Loss:0.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.262                                                   	MRR:27.06	Hits@10:45.92	Best:27.15
2024-12-26 23:40:10,709: Snapshot:1	Epoch:6	Loss:0.374	translation_Loss:0.133	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.241                                                   	MRR:27.12	Hits@10:45.82	Best:27.15
2024-12-26 23:40:13,214: Snapshot:1	Epoch:7	Loss:0.336	translation_Loss:0.113	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.223                                                   	MRR:27.28	Hits@10:46.29	Best:27.28
2024-12-26 23:40:15,705: Snapshot:1	Epoch:8	Loss:0.307	translation_Loss:0.098	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:27.68	Hits@10:46.36	Best:27.68
2024-12-26 23:40:18,234: Snapshot:1	Epoch:9	Loss:0.289	translation_Loss:0.091	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:27.94	Hits@10:46.63	Best:27.94
2024-12-26 23:40:21,141: Snapshot:1	Epoch:10	Loss:0.276	translation_Loss:0.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.19                                                   	MRR:27.93	Hits@10:46.92	Best:27.94
2024-12-26 23:40:23,639: Snapshot:1	Epoch:11	Loss:0.264	translation_Loss:0.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.184                                                   	MRR:28.3	Hits@10:47.68	Best:28.3
2024-12-26 23:40:26,061: Snapshot:1	Epoch:12	Loss:0.254	translation_Loss:0.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.178                                                   	MRR:28.34	Hits@10:47.83	Best:28.34
2024-12-26 23:40:28,516: Snapshot:1	Epoch:13	Loss:0.248	translation_Loss:0.074	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.174                                                   	MRR:28.64	Hits@10:48.32	Best:28.64
2024-12-26 23:40:31,011: Snapshot:1	Epoch:14	Loss:0.239	translation_Loss:0.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:28.93	Hits@10:48.73	Best:28.93
2024-12-26 23:40:33,538: Snapshot:1	Epoch:15	Loss:0.236	translation_Loss:0.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:29.02	Hits@10:49.43	Best:29.02
2024-12-26 23:40:35,936: Snapshot:1	Epoch:16	Loss:0.227	translation_Loss:0.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.163                                                   	MRR:29.09	Hits@10:49.52	Best:29.09
2024-12-26 23:40:38,413: Snapshot:1	Epoch:17	Loss:0.225	translation_Loss:0.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.16                                                   	MRR:29.26	Hits@10:49.53	Best:29.26
2024-12-26 23:40:40,916: Snapshot:1	Epoch:18	Loss:0.221	translation_Loss:0.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.157                                                   	MRR:29.58	Hits@10:49.95	Best:29.58
2024-12-26 23:40:43,320: Snapshot:1	Epoch:19	Loss:0.218	translation_Loss:0.063	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:29.39	Hits@10:49.99	Best:29.58
2024-12-26 23:40:45,802: Snapshot:1	Epoch:20	Loss:0.213	translation_Loss:0.061	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:29.6	Hits@10:50.01	Best:29.6
2024-12-26 23:40:48,264: Snapshot:1	Epoch:21	Loss:0.209	translation_Loss:0.058	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.151                                                   	MRR:29.66	Hits@10:49.84	Best:29.66
2024-12-26 23:40:50,717: Snapshot:1	Epoch:22	Loss:0.209	translation_Loss:0.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:29.92	Hits@10:50.24	Best:29.92
2024-12-26 23:40:53,501: Snapshot:1	Epoch:23	Loss:0.206	translation_Loss:0.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.147                                                   	MRR:30.05	Hits@10:50.37	Best:30.05
2024-12-26 23:40:55,973: Snapshot:1	Epoch:24	Loss:0.205	translation_Loss:0.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.146                                                   	MRR:29.95	Hits@10:50.99	Best:30.05
2024-12-26 23:40:58,468: Snapshot:1	Epoch:25	Loss:0.201	translation_Loss:0.056	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.145                                                   	MRR:30.27	Hits@10:51.05	Best:30.27
2024-12-26 23:41:00,950: Snapshot:1	Epoch:26	Loss:0.2	translation_Loss:0.057	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.144                                                   	MRR:30.3	Hits@10:50.9	Best:30.3
2024-12-26 23:41:03,366: Snapshot:1	Epoch:27	Loss:0.197	translation_Loss:0.054	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.143                                                   	MRR:30.24	Hits@10:51.04	Best:30.3
2024-12-26 23:41:05,770: Snapshot:1	Epoch:28	Loss:0.194	translation_Loss:0.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.141                                                   	MRR:30.16	Hits@10:51.02	Best:30.3
2024-12-26 23:41:08,194: Snapshot:1	Epoch:29	Loss:0.195	translation_Loss:0.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.14                                                   	MRR:30.32	Hits@10:51.29	Best:30.32
2024-12-26 23:41:10,646: Snapshot:1	Epoch:30	Loss:0.194	translation_Loss:0.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.14                                                   	MRR:30.41	Hits@10:51.07	Best:30.41
2024-12-26 23:41:13,044: Snapshot:1	Epoch:31	Loss:0.193	translation_Loss:0.054	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.139                                                   	MRR:30.11	Hits@10:50.95	Best:30.41
2024-12-26 23:41:15,481: Snapshot:1	Epoch:32	Loss:0.191	translation_Loss:0.054	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.138                                                   	MRR:30.67	Hits@10:51.31	Best:30.67
2024-12-26 23:41:17,926: Snapshot:1	Epoch:33	Loss:0.192	translation_Loss:0.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.137                                                   	MRR:30.82	Hits@10:51.32	Best:30.82
2024-12-26 23:41:20,372: Snapshot:1	Epoch:34	Loss:0.191	translation_Loss:0.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.137                                                   	MRR:30.9	Hits@10:51.39	Best:30.9
2024-12-26 23:41:22,756: Snapshot:1	Epoch:35	Loss:0.188	translation_Loss:0.051	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.136                                                   	MRR:30.64	Hits@10:51.02	Best:30.9
2024-12-26 23:41:25,232: Snapshot:1	Epoch:36	Loss:0.192	translation_Loss:0.056	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.136                                                   	MRR:30.51	Hits@10:50.86	Best:30.9
2024-12-26 23:41:28,041: Early Stopping! Snapshot: 1 Epoch: 37 Best Results: 30.9
2024-12-26 23:41:28,041: Start to training tokens! Snapshot: 1 Epoch: 37 Loss:0.187 MRR:30.67 Best Results: 30.9
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-26 23:41:28,041: Snapshot:1	Epoch:37	Loss:0.187	translation_Loss:0.051	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.136                                                   	MRR:30.67	Hits@10:51.23	Best:30.9
2024-12-26 23:41:30,420: Snapshot:1	Epoch:38	Loss:15.561	translation_Loss:5.844	multi_layer_Loss:9.718	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.67	Hits@10:51.23	Best:30.9
2024-12-26 23:41:32,861: End of token training: 1 Epoch: 39 Loss:6.419 MRR:30.67 Best Results: 30.9
2024-12-26 23:41:32,861: Snapshot:1	Epoch:39	Loss:6.419	translation_Loss:5.852	multi_layer_Loss:0.566	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.67	Hits@10:51.23	Best:30.9
2024-12-26 23:41:33,116: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2024-12-26 23:41:36,828: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2458 | 0.1414 | 0.2971 | 0.3628 |  0.4428 |
|     1      | 0.3011 | 0.1945 | 0.3521 | 0.4162 |  0.5063 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-26 23:42:10,584: Snapshot:2	Epoch:0	Loss:19.793	translation_Loss:19.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.693                                                   	MRR:17.67	Hits@10:33.18	Best:17.67
2024-12-26 23:42:20,971: Snapshot:2	Epoch:1	Loss:6.184	translation_Loss:4.924	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.26                                                   	MRR:20.62	Hits@10:37.59	Best:20.62
2024-12-26 23:42:31,441: Snapshot:2	Epoch:2	Loss:3.591	translation_Loss:2.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.348                                                   	MRR:20.98	Hits@10:38.07	Best:20.98
2024-12-26 23:42:42,100: Snapshot:2	Epoch:3	Loss:2.862	translation_Loss:1.551	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.311                                                   	MRR:21.55	Hits@10:38.39	Best:21.55
2024-12-26 23:42:52,590: Snapshot:2	Epoch:4	Loss:2.605	translation_Loss:1.314	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.29                                                   	MRR:21.53	Hits@10:38.3	Best:21.55
2024-12-26 23:43:02,993: Snapshot:2	Epoch:5	Loss:2.474	translation_Loss:1.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.275                                                   	MRR:21.83	Hits@10:38.58	Best:21.83
2024-12-26 23:43:13,328: Snapshot:2	Epoch:6	Loss:2.405	translation_Loss:1.133	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.271                                                   	MRR:21.68	Hits@10:38.49	Best:21.83
2024-12-26 23:43:23,680: Snapshot:2	Epoch:7	Loss:2.352	translation_Loss:1.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.266                                                   	MRR:21.58	Hits@10:38.85	Best:21.83
2024-12-26 23:43:34,545: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 21.83
2024-12-26 23:43:34,545: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:2.319 MRR:21.69 Best Results: 21.83
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([2, 200]), requires_grad: True
 - torch.Size([2, 200]), requires_grad: True
2024-12-26 23:43:34,546: Snapshot:2	Epoch:8	Loss:2.319	translation_Loss:1.05	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.269                                                   	MRR:21.69	Hits@10:38.93	Best:21.83
2024-12-26 23:43:43,849: Snapshot:2	Epoch:9	Loss:34.193	translation_Loss:24.154	multi_layer_Loss:10.039	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.69	Hits@10:38.93	Best:21.83
2024-12-26 23:43:52,855: End of token training: 2 Epoch: 10 Loss:24.194 MRR:21.69 Best Results: 21.83
2024-12-26 23:43:52,856: Snapshot:2	Epoch:10	Loss:24.194	translation_Loss:24.176	multi_layer_Loss:0.018	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.69	Hits@10:38.93	Best:21.83
2024-12-26 23:43:53,139: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2024-12-26 23:44:00,590: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.244  | 0.1389 | 0.2924 | 0.3593 |  0.4421 |
|     1      | 0.2627 | 0.1623 | 0.3026 | 0.3654 |  0.4554 |
|     2      | 0.2205 | 0.1344 | 0.2493 | 0.3085 |  0.3905 |
+------------+--------+--------+--------+--------+---------+
