2024-12-29 02:36:43,453: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229023607/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=3, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 02:36:51,348: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-29 02:36:55,164: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.11	Best:9.49
2024-12-29 02:36:59,405: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.71	Best:14.08
2024-12-29 02:37:03,201: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.75	Best:19.63
2024-12-29 02:37:07,047: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.67	Hits@10:48.73	Best:24.67
2024-12-29 02:37:11,238: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.28	Hits@10:52.03	Best:28.28
2024-12-29 02:37:15,103: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.42	Hits@10:53.89	Best:30.42
2024-12-29 02:37:19,344: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.82	Hits@10:55.44	Best:31.82
2024-12-29 02:37:23,156: Snapshot:0	Epoch:8	Loss:1.3	translation_Loss:1.3	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.66	Hits@10:56.1	Best:32.66
2024-12-29 02:37:26,962: Snapshot:0	Epoch:9	Loss:0.969	translation_Loss:0.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.14	Hits@10:56.53	Best:33.14
2024-12-29 02:37:31,159: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.47	Hits@10:57.04	Best:33.47
2024-12-29 02:37:34,994: Snapshot:0	Epoch:11	Loss:0.607	translation_Loss:0.607	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.57	Hits@10:57.16	Best:33.57
2024-12-29 02:37:38,906: Snapshot:0	Epoch:12	Loss:0.499	translation_Loss:0.499	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.76	Hits@10:57.13	Best:33.76
2024-12-29 02:37:43,100: Snapshot:0	Epoch:13	Loss:0.421	translation_Loss:0.421	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.61	Hits@10:57.08	Best:33.76
2024-12-29 02:37:46,887: Snapshot:0	Epoch:14	Loss:0.374	translation_Loss:0.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.65	Hits@10:56.97	Best:33.76
2024-12-29 02:37:50,757: Snapshot:0	Epoch:15	Loss:0.331	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.65	Hits@10:56.88	Best:33.76
2024-12-29 02:37:55,012: Snapshot:0	Epoch:16	Loss:0.302	translation_Loss:0.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:56.75	Best:33.76
2024-12-29 02:37:58,804: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 33.76
2024-12-29 02:37:58,805: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.278 MRR:33.68 Best Results: 33.76
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-29 02:37:58,805: Snapshot:0	Epoch:17	Loss:0.278	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:56.91	Best:33.76
2024-12-29 02:38:03,105: Snapshot:0	Epoch:18	Loss:20.953	translation_Loss:9.721	multi_layer_Loss:11.233	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:56.91	Best:33.76
2024-12-29 02:38:07,322: End of token training: 0 Epoch: 19 Loss:10.156 MRR:33.68 Best Results: 33.76
2024-12-29 02:38:07,322: Snapshot:0	Epoch:19	Loss:10.156	translation_Loss:9.714	multi_layer_Loss:0.442	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.68	Hits@10:56.91	Best:33.76
2024-12-29 02:38:07,572: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-29 02:38:08,924: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3418 | 0.2217 | 0.3955 |  0.47  |  0.5724 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 02:38:34,157: Snapshot:1	Epoch:0	Loss:13.249	translation_Loss:12.775	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.473                                                   	MRR:15.25	Hits@10:25.91	Best:15.25
2024-12-29 02:38:40,740: Snapshot:1	Epoch:1	Loss:5.581	translation_Loss:5.216	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.365                                                   	MRR:20.56	Hits@10:36.72	Best:20.56
2024-12-29 02:38:47,328: Snapshot:1	Epoch:2	Loss:3.017	translation_Loss:2.774	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.244                                                   	MRR:23.07	Hits@10:41.27	Best:23.07
2024-12-29 02:38:53,923: Snapshot:1	Epoch:3	Loss:2.153	translation_Loss:1.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.203                                                   	MRR:23.97	Hits@10:42.69	Best:23.97
2024-12-29 02:39:00,530: Snapshot:1	Epoch:4	Loss:1.771	translation_Loss:1.59	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.181                                                   	MRR:24.41	Hits@10:43.41	Best:24.41
2024-12-29 02:39:07,538: Snapshot:1	Epoch:5	Loss:1.553	translation_Loss:1.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:24.65	Hits@10:43.88	Best:24.65
2024-12-29 02:39:14,124: Snapshot:1	Epoch:6	Loss:1.433	translation_Loss:1.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:25.04	Hits@10:44.14	Best:25.04
2024-12-29 02:39:21,070: Snapshot:1	Epoch:7	Loss:1.346	translation_Loss:1.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.162                                                   	MRR:24.91	Hits@10:44.03	Best:25.04
2024-12-29 02:39:27,665: Snapshot:1	Epoch:8	Loss:1.276	translation_Loss:1.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.16                                                   	MRR:24.93	Hits@10:44.25	Best:25.04
2024-12-29 02:39:34,662: Snapshot:1	Epoch:9	Loss:1.245	translation_Loss:1.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.159                                                   	MRR:25.09	Hits@10:44.26	Best:25.09
2024-12-29 02:39:41,309: Snapshot:1	Epoch:10	Loss:1.197	translation_Loss:1.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.157                                                   	MRR:25.12	Hits@10:44.46	Best:25.12
2024-12-29 02:39:48,330: Snapshot:1	Epoch:11	Loss:1.172	translation_Loss:1.015	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.158                                                   	MRR:25.09	Hits@10:44.7	Best:25.12
2024-12-29 02:39:54,939: Snapshot:1	Epoch:12	Loss:1.153	translation_Loss:0.996	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.157                                                   	MRR:25.15	Hits@10:44.59	Best:25.15
2024-12-29 02:40:01,849: Snapshot:1	Epoch:13	Loss:1.127	translation_Loss:0.971	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:25.14	Hits@10:44.52	Best:25.15
2024-12-29 02:40:08,544: Snapshot:1	Epoch:14	Loss:1.108	translation_Loss:0.952	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.157                                                   	MRR:25.23	Hits@10:44.62	Best:25.23
2024-12-29 02:40:15,538: Snapshot:1	Epoch:15	Loss:1.096	translation_Loss:0.938	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.158                                                   	MRR:25.21	Hits@10:44.77	Best:25.23
2024-12-29 02:40:22,475: Snapshot:1	Epoch:16	Loss:1.078	translation_Loss:0.92	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.157                                                   	MRR:25.27	Hits@10:44.66	Best:25.27
2024-12-29 02:40:29,029: Snapshot:1	Epoch:17	Loss:1.068	translation_Loss:0.915	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:25.25	Hits@10:44.85	Best:25.27
2024-12-29 02:40:35,969: Snapshot:1	Epoch:18	Loss:1.051	translation_Loss:0.895	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:25.13	Hits@10:44.77	Best:25.27
2024-12-29 02:40:42,588: Snapshot:1	Epoch:19	Loss:1.051	translation_Loss:0.897	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:25.28	Hits@10:44.6	Best:25.28
2024-12-29 02:40:49,624: Snapshot:1	Epoch:20	Loss:1.045	translation_Loss:0.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:25.3	Hits@10:44.79	Best:25.3
2024-12-29 02:40:56,192: Snapshot:1	Epoch:21	Loss:1.036	translation_Loss:0.878	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.157                                                   	MRR:25.35	Hits@10:44.49	Best:25.35
2024-12-29 02:41:03,125: Snapshot:1	Epoch:22	Loss:1.014	translation_Loss:0.859	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:25.43	Hits@10:44.67	Best:25.43
2024-12-29 02:41:09,913: Snapshot:1	Epoch:23	Loss:1.019	translation_Loss:0.864	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:25.53	Hits@10:44.61	Best:25.53
2024-12-29 02:41:16,881: Snapshot:1	Epoch:24	Loss:1.002	translation_Loss:0.848	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:25.28	Hits@10:44.55	Best:25.53
2024-12-29 02:41:23,451: Snapshot:1	Epoch:25	Loss:0.994	translation_Loss:0.839	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:25.26	Hits@10:44.77	Best:25.53
2024-12-29 02:41:30,582: Snapshot:1	Epoch:26	Loss:0.997	translation_Loss:0.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:25.22	Hits@10:44.68	Best:25.53
2024-12-29 02:41:37,136: Snapshot:1	Epoch:27	Loss:0.986	translation_Loss:0.831	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:25.32	Hits@10:44.78	Best:25.53
2024-12-29 02:41:44,047: Early Stopping! Snapshot: 1 Epoch: 28 Best Results: 25.53
2024-12-29 02:41:44,047: Start to training tokens! Snapshot: 1 Epoch: 28 Loss:0.989 MRR:25.18 Best Results: 25.53
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-29 02:41:44,048: Snapshot:1	Epoch:28	Loss:0.989	translation_Loss:0.835	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.154                                                   	MRR:25.18	Hits@10:44.52	Best:25.53
2024-12-29 02:41:51,043: Snapshot:1	Epoch:29	Loss:27.241	translation_Loss:15.702	multi_layer_Loss:11.539	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.18	Hits@10:44.52	Best:25.53
2024-12-29 02:41:57,663: End of token training: 1 Epoch: 30 Loss:15.938 MRR:25.18 Best Results: 25.53
2024-12-29 02:41:57,663: Snapshot:1	Epoch:30	Loss:15.938	translation_Loss:15.731	multi_layer_Loss:0.207	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.18	Hits@10:44.52	Best:25.53
2024-12-29 02:41:57,966: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-29 02:42:01,889: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3406 | 0.2201 | 0.3942 | 0.4693 |  0.5724 |
|     1      | 0.2559 | 0.157  | 0.2902 | 0.3583 |  0.4487 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 02:42:28,320: Snapshot:2	Epoch:0	Loss:11.891	translation_Loss:11.263	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.629                                                   	MRR:14.97	Hits@10:25.2	Best:14.97
2024-12-29 02:42:35,743: Snapshot:2	Epoch:1	Loss:4.425	translation_Loss:3.96	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.465                                                   	MRR:18.45	Hits@10:32.39	Best:18.45
2024-12-29 02:42:43,090: Snapshot:2	Epoch:2	Loss:2.526	translation_Loss:2.229	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.297                                                   	MRR:20.47	Hits@10:36.18	Best:20.47
2024-12-29 02:42:50,411: Snapshot:2	Epoch:3	Loss:1.94	translation_Loss:1.692	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.247                                                   	MRR:21.43	Hits@10:37.84	Best:21.43
2024-12-29 02:42:58,155: Snapshot:2	Epoch:4	Loss:1.664	translation_Loss:1.437	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.227                                                   	MRR:22.05	Hits@10:39.08	Best:22.05
2024-12-29 02:43:05,541: Snapshot:2	Epoch:5	Loss:1.525	translation_Loss:1.309	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.216                                                   	MRR:22.4	Hits@10:39.57	Best:22.4
2024-12-29 02:43:13,350: Snapshot:2	Epoch:6	Loss:1.432	translation_Loss:1.22	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.212                                                   	MRR:22.67	Hits@10:39.88	Best:22.67
2024-12-29 02:43:21,109: Snapshot:2	Epoch:7	Loss:1.362	translation_Loss:1.154	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:22.83	Hits@10:40.21	Best:22.83
2024-12-29 02:43:28,416: Snapshot:2	Epoch:8	Loss:1.315	translation_Loss:1.11	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:23.04	Hits@10:40.46	Best:23.04
2024-12-29 02:43:36,017: Snapshot:2	Epoch:9	Loss:1.282	translation_Loss:1.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.206                                                   	MRR:23.03	Hits@10:40.51	Best:23.04
2024-12-29 02:43:43,342: Snapshot:2	Epoch:10	Loss:1.255	translation_Loss:1.051	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:23.1	Hits@10:40.57	Best:23.1
2024-12-29 02:43:51,034: Snapshot:2	Epoch:11	Loss:1.23	translation_Loss:1.026	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:23.17	Hits@10:40.74	Best:23.17
2024-12-29 02:43:58,332: Snapshot:2	Epoch:12	Loss:1.207	translation_Loss:1.002	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:23.27	Hits@10:40.95	Best:23.27
2024-12-29 02:44:06,049: Snapshot:2	Epoch:13	Loss:1.193	translation_Loss:0.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:23.39	Hits@10:41.0	Best:23.39
2024-12-29 02:44:13,415: Snapshot:2	Epoch:14	Loss:1.175	translation_Loss:0.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:23.3	Hits@10:41.15	Best:23.39
2024-12-29 02:44:21,174: Snapshot:2	Epoch:15	Loss:1.166	translation_Loss:0.96	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.206                                                   	MRR:23.36	Hits@10:41.41	Best:23.39
2024-12-29 02:44:28,797: Snapshot:2	Epoch:16	Loss:1.15	translation_Loss:0.945	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:23.35	Hits@10:41.06	Best:23.39
2024-12-29 02:44:36,038: Snapshot:2	Epoch:17	Loss:1.146	translation_Loss:0.941	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:23.33	Hits@10:41.16	Best:23.39
2024-12-29 02:44:43,703: Snapshot:2	Epoch:18	Loss:1.136	translation_Loss:0.932	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:23.43	Hits@10:41.36	Best:23.43
2024-12-29 02:44:51,003: Snapshot:2	Epoch:19	Loss:1.135	translation_Loss:0.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.206                                                   	MRR:23.42	Hits@10:41.35	Best:23.43
2024-12-29 02:44:58,816: Snapshot:2	Epoch:20	Loss:1.115	translation_Loss:0.91	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:23.51	Hits@10:41.26	Best:23.51
2024-12-29 02:45:06,137: Snapshot:2	Epoch:21	Loss:1.11	translation_Loss:0.903	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.206                                                   	MRR:23.41	Hits@10:41.29	Best:23.51
2024-12-29 02:45:13,858: Snapshot:2	Epoch:22	Loss:1.101	translation_Loss:0.896	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:23.69	Hits@10:41.39	Best:23.69
2024-12-29 02:45:21,200: Snapshot:2	Epoch:23	Loss:1.105	translation_Loss:0.9	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:23.46	Hits@10:41.44	Best:23.69
2024-12-29 02:45:28,941: Snapshot:2	Epoch:24	Loss:1.104	translation_Loss:0.898	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.206                                                   	MRR:23.46	Hits@10:41.35	Best:23.69
2024-12-29 02:45:36,583: Snapshot:2	Epoch:25	Loss:1.094	translation_Loss:0.886	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:23.6	Hits@10:41.51	Best:23.69
2024-12-29 02:45:43,917: Snapshot:2	Epoch:26	Loss:1.094	translation_Loss:0.887	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.207                                                   	MRR:23.67	Hits@10:41.54	Best:23.69
2024-12-29 02:45:51,541: Early Stopping! Snapshot: 2 Epoch: 27 Best Results: 23.69
2024-12-29 02:45:51,541: Start to training tokens! Snapshot: 2 Epoch: 27 Loss:1.084 MRR:23.56 Best Results: 23.69
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-29 02:45:51,542: Snapshot:2	Epoch:27	Loss:1.084	translation_Loss:0.877	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.207                                                   	MRR:23.56	Hits@10:41.53	Best:23.69
2024-12-29 02:45:58,930: Snapshot:2	Epoch:28	Loss:28.066	translation_Loss:15.524	multi_layer_Loss:12.542	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.56	Hits@10:41.53	Best:23.69
2024-12-29 02:46:06,557: End of token training: 2 Epoch: 29 Loss:15.775 MRR:23.56 Best Results: 23.69
2024-12-29 02:46:06,557: Snapshot:2	Epoch:29	Loss:15.775	translation_Loss:15.543	multi_layer_Loss:0.232	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.56	Hits@10:41.53	Best:23.69
2024-12-29 02:46:06,809: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-29 02:46:14,401: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3401 | 0.2197 | 0.395  | 0.4686 |  0.5724 |
|     1      | 0.2572 | 0.1584 | 0.2928 | 0.3586 |  0.4497 |
|     2      | 0.2374 | 0.141  | 0.2753 | 0.3353 |  0.4206 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 02:46:41,617: Snapshot:3	Epoch:0	Loss:10.827	translation_Loss:10.153	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.674                                                   	MRR:14.92	Hits@10:26.45	Best:14.92
2024-12-29 02:46:49,116: Snapshot:3	Epoch:1	Loss:3.549	translation_Loss:3.018	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.531                                                   	MRR:18.54	Hits@10:33.12	Best:18.54
2024-12-29 02:46:56,651: Snapshot:3	Epoch:2	Loss:1.991	translation_Loss:1.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.311                                                   	MRR:19.97	Hits@10:36.04	Best:19.97
2024-12-29 02:47:04,260: Snapshot:3	Epoch:3	Loss:1.528	translation_Loss:1.275	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.253                                                   	MRR:20.76	Hits@10:37.34	Best:20.76
2024-12-29 02:47:11,793: Snapshot:3	Epoch:4	Loss:1.334	translation_Loss:1.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.227                                                   	MRR:21.43	Hits@10:38.39	Best:21.43
2024-12-29 02:47:19,315: Snapshot:3	Epoch:5	Loss:1.222	translation_Loss:1.004	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:21.73	Hits@10:39.23	Best:21.73
2024-12-29 02:47:27,223: Snapshot:3	Epoch:6	Loss:1.145	translation_Loss:0.932	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:21.93	Hits@10:39.46	Best:21.93
2024-12-29 02:47:34,725: Snapshot:3	Epoch:7	Loss:1.104	translation_Loss:0.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.212                                                   	MRR:22.21	Hits@10:39.94	Best:22.21
2024-12-29 02:47:42,645: Snapshot:3	Epoch:8	Loss:1.065	translation_Loss:0.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.212                                                   	MRR:22.35	Hits@10:40.11	Best:22.35
2024-12-29 02:47:50,104: Snapshot:3	Epoch:9	Loss:1.035	translation_Loss:0.826	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:22.28	Hits@10:40.09	Best:22.35
2024-12-29 02:47:58,133: Snapshot:3	Epoch:10	Loss:1.009	translation_Loss:0.802	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:22.57	Hits@10:40.46	Best:22.57
2024-12-29 02:48:05,590: Snapshot:3	Epoch:11	Loss:0.997	translation_Loss:0.79	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.207                                                   	MRR:22.56	Hits@10:40.47	Best:22.57
2024-12-29 02:48:13,490: Snapshot:3	Epoch:12	Loss:0.981	translation_Loss:0.774	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.207                                                   	MRR:22.73	Hits@10:40.76	Best:22.73
2024-12-29 02:48:21,042: Snapshot:3	Epoch:13	Loss:0.974	translation_Loss:0.765	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:22.77	Hits@10:40.84	Best:22.77
2024-12-29 02:48:28,848: Snapshot:3	Epoch:14	Loss:0.967	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:22.71	Hits@10:40.85	Best:22.77
2024-12-29 02:48:36,264: Snapshot:3	Epoch:15	Loss:0.948	translation_Loss:0.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:22.71	Hits@10:40.84	Best:22.77
2024-12-29 02:48:44,039: Snapshot:3	Epoch:16	Loss:0.943	translation_Loss:0.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:22.61	Hits@10:40.87	Best:22.77
2024-12-29 02:48:51,513: Snapshot:3	Epoch:17	Loss:0.934	translation_Loss:0.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:22.81	Hits@10:41.31	Best:22.81
2024-12-29 02:48:59,402: Snapshot:3	Epoch:18	Loss:0.932	translation_Loss:0.723	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:22.78	Hits@10:41.08	Best:22.81
2024-12-29 02:49:06,887: Snapshot:3	Epoch:19	Loss:0.917	translation_Loss:0.708	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:22.74	Hits@10:41.14	Best:22.81
2024-12-29 02:49:14,821: Snapshot:3	Epoch:20	Loss:0.919	translation_Loss:0.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:22.92	Hits@10:41.52	Best:22.92
2024-12-29 02:49:22,325: Snapshot:3	Epoch:21	Loss:0.909	translation_Loss:0.701	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:22.78	Hits@10:41.07	Best:22.92
2024-12-29 02:49:30,193: Snapshot:3	Epoch:22	Loss:0.905	translation_Loss:0.697	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:23.0	Hits@10:41.14	Best:23.0
2024-12-29 02:49:38,079: Snapshot:3	Epoch:23	Loss:0.904	translation_Loss:0.695	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:22.87	Hits@10:41.12	Best:23.0
2024-12-29 02:49:45,617: Snapshot:3	Epoch:24	Loss:0.901	translation_Loss:0.692	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:22.91	Hits@10:41.18	Best:23.0
2024-12-29 02:49:53,418: Snapshot:3	Epoch:25	Loss:0.897	translation_Loss:0.687	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.21                                                   	MRR:22.8	Hits@10:41.26	Best:23.0
2024-12-29 02:50:00,855: Snapshot:3	Epoch:26	Loss:0.898	translation_Loss:0.686	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.212                                                   	MRR:22.71	Hits@10:41.18	Best:23.0
2024-12-29 02:50:08,858: Early Stopping! Snapshot: 3 Epoch: 27 Best Results: 23.0
2024-12-29 02:50:08,858: Start to training tokens! Snapshot: 3 Epoch: 27 Loss:0.877 MRR:22.9 Best Results: 23.0
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-29 02:50:08,859: Snapshot:3	Epoch:27	Loss:0.877	translation_Loss:0.671	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.207                                                   	MRR:22.9	Hits@10:41.18	Best:23.0
2024-12-29 02:50:16,334: Snapshot:3	Epoch:28	Loss:25.772	translation_Loss:14.012	multi_layer_Loss:11.76	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.9	Hits@10:41.18	Best:23.0
2024-12-29 02:50:24,184: End of token training: 3 Epoch: 29 Loss:14.257 MRR:22.9 Best Results: 23.0
2024-12-29 02:50:24,184: Snapshot:3	Epoch:29	Loss:14.257	translation_Loss:14.01	multi_layer_Loss:0.247	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.9	Hits@10:41.18	Best:23.0
2024-12-29 02:50:24,436: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-29 02:50:34,636: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3367 | 0.2154 | 0.3918 | 0.4666 |  0.5721 |
|     1      | 0.2566 | 0.156  | 0.2947 | 0.3585 |  0.4507 |
|     2      | 0.239  | 0.1422 | 0.2778 | 0.3381 |  0.4217 |
|     3      | 0.2314 | 0.1369 | 0.2695 | 0.3295 |  0.4107 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 02:50:54,775: Snapshot:4	Epoch:0	Loss:8.052	translation_Loss:7.614	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.438                                                   	MRR:17.27	Hits@10:32.34	Best:17.27
2024-12-29 02:51:00,632: Snapshot:4	Epoch:1	Loss:2.554	translation_Loss:2.081	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.473                                                   	MRR:23.11	Hits@10:41.75	Best:23.11
2024-12-29 02:51:06,134: Snapshot:4	Epoch:2	Loss:1.131	translation_Loss:0.85	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.281                                                   	MRR:24.69	Hits@10:43.81	Best:24.69
2024-12-29 02:51:11,931: Snapshot:4	Epoch:3	Loss:0.737	translation_Loss:0.56	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.177                                                   	MRR:25.19	Hits@10:44.72	Best:25.19
2024-12-29 02:51:17,887: Snapshot:4	Epoch:4	Loss:0.587	translation_Loss:0.448	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.139                                                   	MRR:25.74	Hits@10:45.61	Best:25.74
2024-12-29 02:51:23,427: Snapshot:4	Epoch:5	Loss:0.517	translation_Loss:0.394	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.123                                                   	MRR:26.23	Hits@10:46.23	Best:26.23
2024-12-29 02:51:29,360: Snapshot:4	Epoch:6	Loss:0.473	translation_Loss:0.357	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.115                                                   	MRR:26.4	Hits@10:46.55	Best:26.4
2024-12-29 02:51:34,875: Snapshot:4	Epoch:7	Loss:0.442	translation_Loss:0.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.11                                                   	MRR:26.56	Hits@10:46.7	Best:26.56
2024-12-29 02:51:40,448: Snapshot:4	Epoch:8	Loss:0.418	translation_Loss:0.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:26.79	Hits@10:47.18	Best:26.79
2024-12-29 02:51:46,410: Snapshot:4	Epoch:9	Loss:0.403	translation_Loss:0.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:26.92	Hits@10:47.45	Best:26.92
2024-12-29 02:51:51,958: Snapshot:4	Epoch:10	Loss:0.388	translation_Loss:0.283	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.105                                                   	MRR:26.99	Hits@10:47.67	Best:26.99
2024-12-29 02:51:57,442: Snapshot:4	Epoch:11	Loss:0.376	translation_Loss:0.272	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.104                                                   	MRR:26.94	Hits@10:47.51	Best:26.99
2024-12-29 02:52:03,332: Snapshot:4	Epoch:12	Loss:0.375	translation_Loss:0.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:27.25	Hits@10:47.97	Best:27.25
2024-12-29 02:52:08,880: Snapshot:4	Epoch:13	Loss:0.365	translation_Loss:0.263	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.15	Hits@10:47.69	Best:27.25
2024-12-29 02:52:14,447: Snapshot:4	Epoch:14	Loss:0.359	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.28	Hits@10:47.96	Best:27.28
2024-12-29 02:52:20,369: Snapshot:4	Epoch:15	Loss:0.355	translation_Loss:0.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:27.26	Hits@10:47.9	Best:27.28
2024-12-29 02:52:25,876: Snapshot:4	Epoch:16	Loss:0.352	translation_Loss:0.25	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.35	Hits@10:48.23	Best:27.35
2024-12-29 02:52:31,354: Snapshot:4	Epoch:17	Loss:0.341	translation_Loss:0.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:27.1	Hits@10:48.25	Best:27.35
2024-12-29 02:52:37,367: Snapshot:4	Epoch:18	Loss:0.341	translation_Loss:0.24	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:27.43	Hits@10:48.82	Best:27.43
2024-12-29 02:52:43,025: Snapshot:4	Epoch:19	Loss:0.343	translation_Loss:0.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:27.47	Hits@10:48.84	Best:27.47
2024-12-29 02:52:48,533: Snapshot:4	Epoch:20	Loss:0.338	translation_Loss:0.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.48	Hits@10:48.76	Best:27.48
2024-12-29 02:52:54,410: Snapshot:4	Epoch:21	Loss:0.331	translation_Loss:0.229	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.3	Hits@10:48.87	Best:27.48
2024-12-29 02:52:59,920: Snapshot:4	Epoch:22	Loss:0.333	translation_Loss:0.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:27.08	Hits@10:48.89	Best:27.48
2024-12-29 02:53:05,726: Snapshot:4	Epoch:23	Loss:0.332	translation_Loss:0.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.1	Hits@10:48.52	Best:27.48
2024-12-29 02:53:11,240: Snapshot:4	Epoch:24	Loss:0.33	translation_Loss:0.228	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.36	Hits@10:48.92	Best:27.48
2024-12-29 02:53:16,746: Snapshot:4	Epoch:25	Loss:0.326	translation_Loss:0.225	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.49	Hits@10:48.98	Best:27.49
2024-12-29 02:53:22,672: Snapshot:4	Epoch:26	Loss:0.328	translation_Loss:0.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.104                                                   	MRR:27.61	Hits@10:49.09	Best:27.61
2024-12-29 02:53:28,119: Snapshot:4	Epoch:27	Loss:0.318	translation_Loss:0.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:27.36	Hits@10:48.73	Best:27.61
2024-12-29 02:53:33,560: Snapshot:4	Epoch:28	Loss:0.324	translation_Loss:0.221	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.26	Hits@10:48.95	Best:27.61
2024-12-29 02:53:39,042: Snapshot:4	Epoch:29	Loss:0.319	translation_Loss:0.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.43	Hits@10:48.57	Best:27.61
2024-12-29 02:53:44,973: Snapshot:4	Epoch:30	Loss:0.322	translation_Loss:0.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.43	Hits@10:48.71	Best:27.61
2024-12-29 02:53:50,442: Early Stopping! Snapshot: 4 Epoch: 31 Best Results: 27.61
2024-12-29 02:53:50,443: Start to training tokens! Snapshot: 4 Epoch: 31 Loss:0.316 MRR:27.41 Best Results: 27.61
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([3, 200]), requires_grad: True
 - torch.Size([3, 200]), requires_grad: True
2024-12-29 02:53:50,443: Snapshot:4	Epoch:31	Loss:0.316	translation_Loss:0.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.41	Hits@10:48.84	Best:27.61
2024-12-29 02:53:55,826: Snapshot:4	Epoch:32	Loss:19.355	translation_Loss:7.618	multi_layer_Loss:11.738	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.41	Hits@10:48.84	Best:27.61
2024-12-29 02:54:01,554: End of token training: 4 Epoch: 33 Loss:8.052 MRR:27.41 Best Results: 27.61
2024-12-29 02:54:01,554: Snapshot:4	Epoch:33	Loss:8.052	translation_Loss:7.596	multi_layer_Loss:0.455	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.41	Hits@10:48.84	Best:27.61
2024-12-29 02:54:01,809: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-29 02:54:15,037: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3338 | 0.2111 | 0.3926 | 0.4638 |  0.5674 |
|     1      | 0.2555 | 0.1548 | 0.2928 | 0.3586 |  0.4492 |
|     2      | 0.2391 | 0.1427 | 0.2765 | 0.3367 |  0.421  |
|     3      | 0.2334 | 0.1385 | 0.2716 | 0.3315 |  0.4139 |
|     4      | 0.2789 | 0.1659 | 0.3338 | 0.4069 |  0.496  |
+------------+--------+--------+--------+--------+---------+
2024-12-29 02:54:15,040: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3418 | 0.2217 | 0.3955 |  0.47  |  0.5724 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3406 | 0.2201 | 0.3942 | 0.4693 |  0.5724 |
|     1      | 0.2559 | 0.157  | 0.2902 | 0.3583 |  0.4487 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3401 | 0.2197 | 0.395  | 0.4686 |  0.5724 |
|     1      | 0.2572 | 0.1584 | 0.2928 | 0.3586 |  0.4497 |
|     2      | 0.2374 | 0.141  | 0.2753 | 0.3353 |  0.4206 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3367 | 0.2154 | 0.3918 | 0.4666 |  0.5721 |
|     1      | 0.2566 | 0.156  | 0.2947 | 0.3585 |  0.4507 |
|     2      | 0.239  | 0.1422 | 0.2778 | 0.3381 |  0.4217 |
|     3      | 0.2314 | 0.1369 | 0.2695 | 0.3295 |  0.4107 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3338 | 0.2111 | 0.3926 | 0.4638 |  0.5674 |
|     1      | 0.2555 | 0.1548 | 0.2928 | 0.3586 |  0.4492 |
|     2      | 0.2391 | 0.1427 | 0.2765 | 0.3367 |  0.421  |
|     3      | 0.2334 | 0.1385 | 0.2716 | 0.3315 |  0.4139 |
|     4      | 0.2789 | 0.1659 | 0.3338 | 0.4069 |  0.496  |
+------------+--------+--------+--------+--------+---------+]
2024-12-29 02:54:15,040: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 83.86811518669128  |   0.342   |    0.222     |    0.396     |     0.572     |
|    1     | 226.35868072509766 |   0.289   |    0.182     |    0.331     |     0.497     |
|    2     | 241.76199412345886 |    0.27   |    0.167     |    0.311     |     0.468     |
|    3     | 246.21423363685608 |   0.259   |    0.157     |     0.3      |     0.453     |
|    4     | 203.9224624633789  |   0.262   |    0.158     |    0.305     |     0.459     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-29 02:54:15,040: Sum_Training_Time:1002.1254861354828
2024-12-29 02:54:15,040: Every_Training_Time:[83.86811518669128, 226.35868072509766, 241.76199412345886, 246.21423363685608, 203.9224624633789]
2024-12-29 02:54:15,040: Forward transfer: 0.047 Backward transfer: -0.0011750000000000024
2024-12-29 02:54:51,283: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229025420/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=4, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 02:54:59,150: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-29 02:55:03,017: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.11	Best:9.49
2024-12-29 02:55:07,285: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.71	Best:14.08
2024-12-29 02:55:11,172: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.75	Best:19.63
2024-12-29 02:55:14,994: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:48.72	Best:24.66
2024-12-29 02:55:19,234: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.28	Hits@10:52.0	Best:28.28
2024-12-29 02:55:23,079: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.39	Hits@10:53.85	Best:30.39
2024-12-29 02:55:27,296: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.83	Hits@10:55.44	Best:31.83
2024-12-29 02:55:31,115: Snapshot:0	Epoch:8	Loss:1.3	translation_Loss:1.3	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.68	Hits@10:56.08	Best:32.68
2024-12-29 02:55:34,989: Snapshot:0	Epoch:9	Loss:0.968	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.13	Hits@10:56.51	Best:33.13
2024-12-29 02:55:39,231: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.49	Hits@10:57.05	Best:33.49
2024-12-29 02:55:43,133: Snapshot:0	Epoch:11	Loss:0.607	translation_Loss:0.607	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.47	Hits@10:57.08	Best:33.49
2024-12-29 02:55:46,999: Snapshot:0	Epoch:12	Loss:0.499	translation_Loss:0.499	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:57.0	Best:33.68
2024-12-29 02:55:51,201: Snapshot:0	Epoch:13	Loss:0.421	translation_Loss:0.421	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.59	Hits@10:57.07	Best:33.68
2024-12-29 02:55:54,999: Snapshot:0	Epoch:14	Loss:0.373	translation_Loss:0.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.65	Hits@10:56.92	Best:33.68
2024-12-29 02:55:58,813: Snapshot:0	Epoch:15	Loss:0.331	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.62	Hits@10:56.82	Best:33.68
2024-12-29 02:56:03,032: Snapshot:0	Epoch:16	Loss:0.302	translation_Loss:0.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.69	Hits@10:56.7	Best:33.69
2024-12-29 02:56:06,899: Snapshot:0	Epoch:17	Loss:0.277	translation_Loss:0.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.7	Hits@10:56.9	Best:33.7
2024-12-29 02:56:10,904: Snapshot:0	Epoch:18	Loss:0.257	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.44	Hits@10:56.83	Best:33.7
2024-12-29 02:56:15,074: Snapshot:0	Epoch:19	Loss:0.241	translation_Loss:0.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.43	Hits@10:56.82	Best:33.7
2024-12-29 02:56:18,892: Snapshot:0	Epoch:20	Loss:0.224	translation_Loss:0.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.52	Hits@10:56.6	Best:33.7
2024-12-29 02:56:22,699: Snapshot:0	Epoch:21	Loss:0.214	translation_Loss:0.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.5	Hits@10:56.64	Best:33.7
2024-12-29 02:56:26,860: Early Stopping! Snapshot: 0 Epoch: 22 Best Results: 33.7
2024-12-29 02:56:26,860: Start to training tokens! Snapshot: 0 Epoch: 22 Loss:0.202 MRR:33.61 Best Results: 33.7
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-29 02:56:26,861: Snapshot:0	Epoch:22	Loss:0.202	translation_Loss:0.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.61	Hits@10:56.58	Best:33.7
2024-12-29 02:56:31,160: Snapshot:0	Epoch:23	Loss:22.942	translation_Loss:9.735	multi_layer_Loss:13.208	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.61	Hits@10:56.58	Best:33.7
2024-12-29 02:56:34,979: End of token training: 0 Epoch: 24 Loss:10.2 MRR:33.61 Best Results: 33.7
2024-12-29 02:56:34,979: Snapshot:0	Epoch:24	Loss:10.2	translation_Loss:9.726	multi_layer_Loss:0.474	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.61	Hits@10:56.58	Best:33.7
2024-12-29 02:56:35,227: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-29 02:56:36,864: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3395 | 0.2193 | 0.3947 | 0.4672 |  0.5716 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 02:57:01,990: Snapshot:1	Epoch:0	Loss:13.089	translation_Loss:12.612	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.477                                                   	MRR:15.07	Hits@10:25.57	Best:15.07
2024-12-29 02:57:08,627: Snapshot:1	Epoch:1	Loss:5.136	translation_Loss:4.79	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.345                                                   	MRR:20.11	Hits@10:35.63	Best:20.11
2024-12-29 02:57:15,274: Snapshot:1	Epoch:2	Loss:2.573	translation_Loss:2.35	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:22.91	Hits@10:40.24	Best:22.91
2024-12-29 02:57:21,947: Snapshot:1	Epoch:3	Loss:1.757	translation_Loss:1.582	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.176                                                   	MRR:23.92	Hits@10:41.95	Best:23.92
2024-12-29 02:57:28,546: Snapshot:1	Epoch:4	Loss:1.422	translation_Loss:1.266	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:24.37	Hits@10:42.91	Best:24.37
2024-12-29 02:57:35,550: Snapshot:1	Epoch:5	Loss:1.243	translation_Loss:1.097	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.146                                                   	MRR:24.62	Hits@10:43.25	Best:24.62
2024-12-29 02:57:42,181: Snapshot:1	Epoch:6	Loss:1.13	translation_Loss:0.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.141                                                   	MRR:24.89	Hits@10:43.75	Best:24.89
2024-12-29 02:57:49,277: Snapshot:1	Epoch:7	Loss:1.051	translation_Loss:0.916	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.135                                                   	MRR:24.79	Hits@10:43.66	Best:24.89
2024-12-29 02:57:55,866: Snapshot:1	Epoch:8	Loss:0.984	translation_Loss:0.854	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.13                                                   	MRR:24.7	Hits@10:43.59	Best:24.89
2024-12-29 02:58:02,818: Snapshot:1	Epoch:9	Loss:0.958	translation_Loss:0.83	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.129                                                   	MRR:24.81	Hits@10:44.1	Best:24.89
2024-12-29 02:58:09,432: Snapshot:1	Epoch:10	Loss:0.926	translation_Loss:0.798	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.129                                                   	MRR:24.84	Hits@10:43.89	Best:24.89
2024-12-29 02:58:16,410: Snapshot:1	Epoch:11	Loss:0.9	translation_Loss:0.772	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.128                                                   	MRR:25.08	Hits@10:44.15	Best:25.08
2024-12-29 02:58:23,042: Snapshot:1	Epoch:12	Loss:0.877	translation_Loss:0.751	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:25.05	Hits@10:44.1	Best:25.08
2024-12-29 02:58:30,032: Snapshot:1	Epoch:13	Loss:0.862	translation_Loss:0.737	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:25.02	Hits@10:44.14	Best:25.08
2024-12-29 02:58:36,989: Snapshot:1	Epoch:14	Loss:0.845	translation_Loss:0.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.125                                                   	MRR:25.08	Hits@10:44.31	Best:25.08
2024-12-29 02:58:43,566: Snapshot:1	Epoch:15	Loss:0.837	translation_Loss:0.71	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:24.97	Hits@10:44.1	Best:25.08
2024-12-29 02:58:50,527: Early Stopping! Snapshot: 1 Epoch: 16 Best Results: 25.08
2024-12-29 02:58:50,527: Start to training tokens! Snapshot: 1 Epoch: 16 Loss:0.826 MRR:25.02 Best Results: 25.08
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-29 02:58:50,527: Snapshot:1	Epoch:16	Loss:0.826	translation_Loss:0.7	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.125                                                   	MRR:25.02	Hits@10:44.36	Best:25.08
2024-12-29 02:58:57,116: Snapshot:1	Epoch:17	Loss:29.999	translation_Loss:15.827	multi_layer_Loss:14.171	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.02	Hits@10:44.36	Best:25.08
2024-12-29 02:59:04,116: End of token training: 1 Epoch: 18 Loss:16.045 MRR:25.02 Best Results: 25.08
2024-12-29 02:59:04,116: Snapshot:1	Epoch:18	Loss:16.045	translation_Loss:15.827	multi_layer_Loss:0.218	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.02	Hits@10:44.36	Best:25.08
2024-12-29 02:59:04,370: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-29 02:59:08,184: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3388 | 0.218  | 0.3942 | 0.4666 |  0.5709 |
|     1      | 0.2512 | 0.1534 | 0.2859 | 0.3509 |  0.4428 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 02:59:34,542: Snapshot:2	Epoch:0	Loss:11.747	translation_Loss:11.074	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.673                                                   	MRR:14.87	Hits@10:25.16	Best:14.87
2024-12-29 02:59:41,914: Snapshot:2	Epoch:1	Loss:4.058	translation_Loss:3.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.461                                                   	MRR:18.32	Hits@10:32.11	Best:18.32
2024-12-29 02:59:49,351: Snapshot:2	Epoch:2	Loss:2.188	translation_Loss:1.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.288                                                   	MRR:20.38	Hits@10:36.14	Best:20.38
2024-12-29 02:59:57,024: Snapshot:2	Epoch:3	Loss:1.641	translation_Loss:1.405	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.235                                                   	MRR:21.42	Hits@10:37.77	Best:21.42
2024-12-29 03:00:04,380: Snapshot:2	Epoch:4	Loss:1.41	translation_Loss:1.196	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.215                                                   	MRR:21.86	Hits@10:38.77	Best:21.86
2024-12-29 03:00:12,377: Snapshot:2	Epoch:5	Loss:1.279	translation_Loss:1.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:22.34	Hits@10:39.46	Best:22.34
2024-12-29 03:00:20,066: Snapshot:2	Epoch:6	Loss:1.197	translation_Loss:0.996	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:22.38	Hits@10:39.6	Best:22.38
2024-12-29 03:00:27,389: Snapshot:2	Epoch:7	Loss:1.136	translation_Loss:0.938	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:22.67	Hits@10:40.02	Best:22.67
2024-12-29 03:00:35,115: Snapshot:2	Epoch:8	Loss:1.096	translation_Loss:0.898	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:22.69	Hits@10:40.08	Best:22.69
2024-12-29 03:00:42,439: Snapshot:2	Epoch:9	Loss:1.056	translation_Loss:0.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:22.92	Hits@10:40.33	Best:22.92
2024-12-29 03:00:50,071: Snapshot:2	Epoch:10	Loss:1.032	translation_Loss:0.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:22.85	Hits@10:40.33	Best:22.92
2024-12-29 03:00:57,438: Snapshot:2	Epoch:11	Loss:1.026	translation_Loss:0.832	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:22.96	Hits@10:40.57	Best:22.96
2024-12-29 03:01:05,159: Snapshot:2	Epoch:12	Loss:0.997	translation_Loss:0.802	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:23.03	Hits@10:40.82	Best:23.03
2024-12-29 03:01:12,621: Snapshot:2	Epoch:13	Loss:0.988	translation_Loss:0.792	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:23.0	Hits@10:40.83	Best:23.03
2024-12-29 03:01:20,426: Snapshot:2	Epoch:14	Loss:0.976	translation_Loss:0.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:23.05	Hits@10:40.86	Best:23.05
2024-12-29 03:01:28,137: Snapshot:2	Epoch:15	Loss:0.97	translation_Loss:0.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:23.16	Hits@10:41.05	Best:23.16
2024-12-29 03:01:35,485: Snapshot:2	Epoch:16	Loss:0.956	translation_Loss:0.759	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:23.25	Hits@10:41.03	Best:23.25
2024-12-29 03:01:43,181: Snapshot:2	Epoch:17	Loss:0.942	translation_Loss:0.746	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:23.2	Hits@10:40.92	Best:23.25
2024-12-29 03:01:50,460: Snapshot:2	Epoch:18	Loss:0.935	translation_Loss:0.738	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:23.28	Hits@10:41.0	Best:23.28
2024-12-29 03:01:58,138: Snapshot:2	Epoch:19	Loss:0.925	translation_Loss:0.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:23.19	Hits@10:41.01	Best:23.28
2024-12-29 03:02:05,414: Snapshot:2	Epoch:20	Loss:0.921	translation_Loss:0.725	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:23.13	Hits@10:40.97	Best:23.28
2024-12-29 03:02:13,085: Snapshot:2	Epoch:21	Loss:0.919	translation_Loss:0.722	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:23.19	Hits@10:41.13	Best:23.28
2024-12-29 03:02:20,373: Snapshot:2	Epoch:22	Loss:0.919	translation_Loss:0.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:23.23	Hits@10:41.02	Best:23.28
2024-12-29 03:02:28,099: Early Stopping! Snapshot: 2 Epoch: 23 Best Results: 23.28
2024-12-29 03:02:28,099: Start to training tokens! Snapshot: 2 Epoch: 23 Loss:0.908 MRR:23.16 Best Results: 23.28
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-29 03:02:28,100: Snapshot:2	Epoch:23	Loss:0.908	translation_Loss:0.71	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:23.16	Hits@10:41.05	Best:23.28
2024-12-29 03:02:35,724: Snapshot:2	Epoch:24	Loss:29.585	translation_Loss:15.668	multi_layer_Loss:13.917	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.16	Hits@10:41.05	Best:23.28
2024-12-29 03:02:43,113: End of token training: 2 Epoch: 25 Loss:15.902 MRR:23.16 Best Results: 23.28
2024-12-29 03:02:43,114: Snapshot:2	Epoch:25	Loss:15.902	translation_Loss:15.677	multi_layer_Loss:0.226	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.16	Hits@10:41.05	Best:23.28
2024-12-29 03:02:43,363: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-29 03:02:50,400: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3378 | 0.2176 | 0.394  | 0.465  |  0.5681 |
|     1      | 0.2514 | 0.1535 | 0.2858 | 0.3519 |  0.4423 |
|     2      | 0.2342 | 0.1396 | 0.2701 | 0.3286 |  0.4138 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:03:17,522: Snapshot:3	Epoch:0	Loss:10.7	translation_Loss:9.972	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.728                                                   	MRR:14.84	Hits@10:26.21	Best:14.84
2024-12-29 03:03:25,200: Snapshot:3	Epoch:1	Loss:3.273	translation_Loss:2.751	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.522                                                   	MRR:18.22	Hits@10:32.4	Best:18.22
2024-12-29 03:03:32,913: Snapshot:3	Epoch:2	Loss:1.758	translation_Loss:1.464	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.294                                                   	MRR:19.81	Hits@10:35.56	Best:19.81
2024-12-29 03:03:40,567: Snapshot:3	Epoch:3	Loss:1.328	translation_Loss:1.094	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.234                                                   	MRR:20.59	Hits@10:37.0	Best:20.59
2024-12-29 03:03:48,156: Snapshot:3	Epoch:4	Loss:1.139	translation_Loss:0.927	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.212                                                   	MRR:21.18	Hits@10:38.21	Best:21.18
2024-12-29 03:03:55,731: Snapshot:3	Epoch:5	Loss:1.041	translation_Loss:0.839	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:21.47	Hits@10:38.65	Best:21.47
2024-12-29 03:04:03,798: Snapshot:3	Epoch:6	Loss:0.984	translation_Loss:0.785	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:21.8	Hits@10:39.27	Best:21.8
2024-12-29 03:04:11,507: Snapshot:3	Epoch:7	Loss:0.942	translation_Loss:0.744	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:21.85	Hits@10:39.41	Best:21.85
2024-12-29 03:04:19,524: Snapshot:3	Epoch:8	Loss:0.912	translation_Loss:0.716	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:22.07	Hits@10:39.84	Best:22.07
2024-12-29 03:04:27,089: Snapshot:3	Epoch:9	Loss:0.897	translation_Loss:0.699	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:21.97	Hits@10:40.04	Best:22.07
2024-12-29 03:04:35,051: Snapshot:3	Epoch:10	Loss:0.868	translation_Loss:0.672	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:22.0	Hits@10:39.84	Best:22.07
2024-12-29 03:04:42,674: Snapshot:3	Epoch:11	Loss:0.856	translation_Loss:0.66	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:22.19	Hits@10:39.96	Best:22.19
2024-12-29 03:04:50,718: Snapshot:3	Epoch:12	Loss:0.844	translation_Loss:0.647	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:22.26	Hits@10:40.18	Best:22.26
2024-12-29 03:04:58,355: Snapshot:3	Epoch:13	Loss:0.831	translation_Loss:0.634	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:22.3	Hits@10:40.36	Best:22.3
2024-12-29 03:05:06,367: Snapshot:3	Epoch:14	Loss:0.821	translation_Loss:0.624	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:22.37	Hits@10:40.39	Best:22.37
2024-12-29 03:05:14,048: Snapshot:3	Epoch:15	Loss:0.811	translation_Loss:0.614	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:22.3	Hits@10:40.49	Best:22.37
2024-12-29 03:05:22,038: Snapshot:3	Epoch:16	Loss:0.801	translation_Loss:0.604	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:22.45	Hits@10:40.43	Best:22.45
2024-12-29 03:05:29,623: Snapshot:3	Epoch:17	Loss:0.798	translation_Loss:0.601	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:22.43	Hits@10:40.31	Best:22.45
2024-12-29 03:05:37,554: Snapshot:3	Epoch:18	Loss:0.8	translation_Loss:0.601	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:22.37	Hits@10:40.29	Best:22.45
2024-12-29 03:05:45,522: Snapshot:3	Epoch:19	Loss:0.783	translation_Loss:0.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:22.35	Hits@10:40.02	Best:22.45
2024-12-29 03:05:53,257: Snapshot:3	Epoch:20	Loss:0.79	translation_Loss:0.591	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:22.5	Hits@10:40.4	Best:22.5
2024-12-29 03:06:00,908: Snapshot:3	Epoch:21	Loss:0.773	translation_Loss:0.576	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:22.48	Hits@10:40.36	Best:22.5
2024-12-29 03:06:08,870: Snapshot:3	Epoch:22	Loss:0.777	translation_Loss:0.577	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:22.44	Hits@10:40.46	Best:22.5
2024-12-29 03:06:17,003: Snapshot:3	Epoch:23	Loss:0.771	translation_Loss:0.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:22.56	Hits@10:40.64	Best:22.56
2024-12-29 03:06:24,635: Snapshot:3	Epoch:24	Loss:0.774	translation_Loss:0.573	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:22.53	Hits@10:40.67	Best:22.56
2024-12-29 03:06:32,709: Snapshot:3	Epoch:25	Loss:0.763	translation_Loss:0.562	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:22.54	Hits@10:40.48	Best:22.56
2024-12-29 03:06:40,264: Snapshot:3	Epoch:26	Loss:0.771	translation_Loss:0.566	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:22.35	Hits@10:40.49	Best:22.56
2024-12-29 03:06:48,217: Snapshot:3	Epoch:27	Loss:0.758	translation_Loss:0.556	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:22.44	Hits@10:40.66	Best:22.56
2024-12-29 03:06:55,830: Early Stopping! Snapshot: 3 Epoch: 28 Best Results: 22.56
2024-12-29 03:06:55,830: Start to training tokens! Snapshot: 3 Epoch: 28 Loss:0.758 MRR:22.51 Best Results: 22.56
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-29 03:06:55,830: Snapshot:3	Epoch:28	Loss:0.758	translation_Loss:0.557	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:22.51	Hits@10:40.75	Best:22.56
2024-12-29 03:07:03,829: Snapshot:3	Epoch:29	Loss:27.541	translation_Loss:14.136	multi_layer_Loss:13.406	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.51	Hits@10:40.75	Best:22.56
2024-12-29 03:07:11,285: End of token training: 3 Epoch: 30 Loss:14.38 MRR:22.51 Best Results: 22.56
2024-12-29 03:07:11,285: Snapshot:3	Epoch:30	Loss:14.38	translation_Loss:14.146	multi_layer_Loss:0.234	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.51	Hits@10:40.75	Best:22.56
2024-12-29 03:07:11,537: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-29 03:07:22,062: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3375 | 0.2173 | 0.393  | 0.4646 |  0.569  |
|     1      | 0.2516 | 0.1539 | 0.2856 | 0.3511 |  0.4442 |
|     2      | 0.2344 | 0.1391 | 0.271  | 0.3305 |  0.4156 |
|     3      | 0.2287 | 0.1354 | 0.2654 | 0.3236 |  0.4058 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:07:42,504: Snapshot:4	Epoch:0	Loss:8.018	translation_Loss:7.547	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.472                                                   	MRR:17.13	Hits@10:32.07	Best:17.13
2024-12-29 03:07:48,051: Snapshot:4	Epoch:1	Loss:2.439	translation_Loss:1.972	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.467                                                   	MRR:22.6	Hits@10:41.22	Best:22.6
2024-12-29 03:07:53,644: Snapshot:4	Epoch:2	Loss:1.021	translation_Loss:0.764	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.257                                                   	MRR:24.31	Hits@10:42.97	Best:24.31
2024-12-29 03:07:59,202: Snapshot:4	Epoch:3	Loss:0.644	translation_Loss:0.489	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.155                                                   	MRR:25.06	Hits@10:44.39	Best:25.06
2024-12-29 03:08:04,950: Snapshot:4	Epoch:4	Loss:0.509	translation_Loss:0.387	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.122                                                   	MRR:25.58	Hits@10:45.16	Best:25.58
2024-12-29 03:08:11,004: Snapshot:4	Epoch:5	Loss:0.444	translation_Loss:0.336	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:25.92	Hits@10:45.81	Best:25.92
2024-12-29 03:08:16,635: Snapshot:4	Epoch:6	Loss:0.407	translation_Loss:0.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:26.29	Hits@10:46.28	Best:26.29
2024-12-29 03:08:22,114: Snapshot:4	Epoch:7	Loss:0.38	translation_Loss:0.283	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:26.21	Hits@10:46.43	Best:26.29
2024-12-29 03:08:27,972: Snapshot:4	Epoch:8	Loss:0.365	translation_Loss:0.269	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.096                                                   	MRR:26.29	Hits@10:46.67	Best:26.29
2024-12-29 03:08:33,544: Snapshot:4	Epoch:9	Loss:0.353	translation_Loss:0.259	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.47	Hits@10:47.04	Best:26.47
2024-12-29 03:08:39,105: Snapshot:4	Epoch:10	Loss:0.343	translation_Loss:0.249	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:26.65	Hits@10:47.38	Best:26.65
2024-12-29 03:08:45,004: Snapshot:4	Epoch:11	Loss:0.328	translation_Loss:0.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:26.72	Hits@10:47.39	Best:26.72
2024-12-29 03:08:50,599: Snapshot:4	Epoch:12	Loss:0.321	translation_Loss:0.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:26.74	Hits@10:47.29	Best:26.74
2024-12-29 03:08:56,220: Snapshot:4	Epoch:13	Loss:0.318	translation_Loss:0.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:26.96	Hits@10:47.58	Best:26.96
2024-12-29 03:09:02,022: Snapshot:4	Epoch:14	Loss:0.308	translation_Loss:0.216	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:26.95	Hits@10:47.49	Best:26.96
2024-12-29 03:09:07,587: Snapshot:4	Epoch:15	Loss:0.31	translation_Loss:0.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:27.01	Hits@10:47.76	Best:27.01
2024-12-29 03:09:13,565: Snapshot:4	Epoch:16	Loss:0.302	translation_Loss:0.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:26.96	Hits@10:48.01	Best:27.01
2024-12-29 03:09:19,123: Snapshot:4	Epoch:17	Loss:0.302	translation_Loss:0.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:27.19	Hits@10:48.11	Best:27.19
2024-12-29 03:09:24,587: Snapshot:4	Epoch:18	Loss:0.297	translation_Loss:0.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:27.02	Hits@10:47.65	Best:27.19
2024-12-29 03:09:30,535: Snapshot:4	Epoch:19	Loss:0.298	translation_Loss:0.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:27.15	Hits@10:47.93	Best:27.19
2024-12-29 03:09:36,091: Snapshot:4	Epoch:20	Loss:0.291	translation_Loss:0.2	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:27.18	Hits@10:48.19	Best:27.19
2024-12-29 03:09:41,560: Snapshot:4	Epoch:21	Loss:0.292	translation_Loss:0.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:27.18	Hits@10:48.12	Best:27.19
2024-12-29 03:09:47,152: Snapshot:4	Epoch:22	Loss:0.289	translation_Loss:0.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:27.25	Hits@10:48.13	Best:27.25
2024-12-29 03:09:52,958: Snapshot:4	Epoch:23	Loss:0.294	translation_Loss:0.2	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:27.22	Hits@10:48.08	Best:27.25
2024-12-29 03:09:58,451: Snapshot:4	Epoch:24	Loss:0.29	translation_Loss:0.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:27.18	Hits@10:48.19	Best:27.25
2024-12-29 03:10:03,937: Snapshot:4	Epoch:25	Loss:0.284	translation_Loss:0.192	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:27.13	Hits@10:47.97	Best:27.25
2024-12-29 03:10:09,932: Snapshot:4	Epoch:26	Loss:0.281	translation_Loss:0.191	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:27.43	Hits@10:48.84	Best:27.43
2024-12-29 03:10:15,448: Snapshot:4	Epoch:27	Loss:0.285	translation_Loss:0.192	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:27.25	Hits@10:48.47	Best:27.43
2024-12-29 03:10:21,390: Snapshot:4	Epoch:28	Loss:0.28	translation_Loss:0.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:27.15	Hits@10:48.42	Best:27.43
2024-12-29 03:10:26,899: Snapshot:4	Epoch:29	Loss:0.28	translation_Loss:0.188	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:27.42	Hits@10:48.27	Best:27.43
2024-12-29 03:10:32,360: Snapshot:4	Epoch:30	Loss:0.284	translation_Loss:0.19	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:27.39	Hits@10:48.42	Best:27.43
2024-12-29 03:10:38,199: Early Stopping! Snapshot: 4 Epoch: 31 Best Results: 27.43
2024-12-29 03:10:38,199: Start to training tokens! Snapshot: 4 Epoch: 31 Loss:0.279 MRR:27.23 Best Results: 27.43
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([4, 200]), requires_grad: True
 - torch.Size([4, 200]), requires_grad: True
2024-12-29 03:10:38,200: Snapshot:4	Epoch:31	Loss:0.279	translation_Loss:0.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:27.23	Hits@10:48.32	Best:27.43
2024-12-29 03:10:43,635: Snapshot:4	Epoch:32	Loss:21.569	translation_Loss:7.691	multi_layer_Loss:13.878	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.23	Hits@10:48.32	Best:27.43
2024-12-29 03:10:49,051: End of token training: 4 Epoch: 33 Loss:8.155 MRR:27.23 Best Results: 27.43
2024-12-29 03:10:49,051: Snapshot:4	Epoch:33	Loss:8.155	translation_Loss:7.669	multi_layer_Loss:0.486	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.23	Hits@10:48.32	Best:27.43
2024-12-29 03:10:49,303: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-29 03:11:02,522: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3358 | 0.215  |  0.39  | 0.463  |  0.566  |
|     1      | 0.2515 | 0.1535 | 0.2854 | 0.3511 |  0.4438 |
|     2      | 0.2362 | 0.1408 | 0.2739 | 0.332  |  0.4163 |
|     3      | 0.2304 | 0.137  | 0.267  | 0.3262 |  0.4091 |
|     4      | 0.275  | 0.1632 | 0.3275 | 0.4023 |  0.4877 |
+------------+--------+--------+--------+--------+---------+
2024-12-29 03:11:02,525: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3395 | 0.2193 | 0.3947 | 0.4672 |  0.5716 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3388 | 0.218  | 0.3942 | 0.4666 |  0.5709 |
|     1      | 0.2512 | 0.1534 | 0.2859 | 0.3509 |  0.4428 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3378 | 0.2176 | 0.394  | 0.465  |  0.5681 |
|     1      | 0.2514 | 0.1535 | 0.2858 | 0.3519 |  0.4423 |
|     2      | 0.2342 | 0.1396 | 0.2701 | 0.3286 |  0.4138 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3375 | 0.2173 | 0.393  | 0.4646 |  0.569  |
|     1      | 0.2516 | 0.1539 | 0.2856 | 0.3511 |  0.4442 |
|     2      | 0.2344 | 0.1391 | 0.271  | 0.3305 |  0.4156 |
|     3      | 0.2287 | 0.1354 | 0.2654 | 0.3236 |  0.4058 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3358 | 0.215  |  0.39  | 0.463  |  0.566  |
|     1      | 0.2515 | 0.1535 | 0.2854 | 0.3511 |  0.4438 |
|     2      | 0.2362 | 0.1408 | 0.2739 | 0.332  |  0.4163 |
|     3      | 0.2304 | 0.137  | 0.267  | 0.3262 |  0.4091 |
|     4      | 0.275  | 0.1632 | 0.3275 | 0.4023 |  0.4877 |
+------------+--------+--------+--------+--------+---------+]
2024-12-29 03:11:02,525: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 103.69509077072144 |    0.34   |    0.219     |    0.395     |     0.572     |
|    1     | 144.88446688652039 |   0.285   |    0.179     |    0.328     |     0.493     |
|    2     | 212.0240387916565  |   0.266   |    0.164     |    0.306     |     0.462     |
|    3     | 257.57177901268005 |   0.256   |    0.156     |    0.295     |     0.448     |
|    4     | 204.22829246520996 |   0.259   |    0.157     |    0.301     |     0.454     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-29 03:11:02,525: Sum_Training_Time:922.4036679267883
2024-12-29 03:11:02,525: Every_Training_Time:[103.69509077072144, 144.88446688652039, 212.0240387916565, 257.57177901268005, 204.22829246520996]
2024-12-29 03:11:02,525: Forward transfer: 0.044724999999999994 Backward transfer: 7.499999999999868e-05
2024-12-29 03:11:38,843: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229031107/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 03:11:46,649: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-29 03:11:50,409: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.12	Best:9.49
2024-12-29 03:11:54,574: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.7	Best:14.08
2024-12-29 03:11:58,344: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.75	Best:19.63
2024-12-29 03:12:02,108: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.65	Hits@10:48.73	Best:24.65
2024-12-29 03:12:06,243: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.29	Hits@10:52.04	Best:28.29
2024-12-29 03:12:10,064: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.38	Hits@10:53.79	Best:30.38
2024-12-29 03:12:14,183: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.78	Hits@10:55.51	Best:31.78
2024-12-29 03:12:17,973: Snapshot:0	Epoch:8	Loss:1.299	translation_Loss:1.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.65	Hits@10:56.13	Best:32.65
2024-12-29 03:12:21,743: Snapshot:0	Epoch:9	Loss:0.968	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.16	Hits@10:56.6	Best:33.16
2024-12-29 03:12:25,879: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.57	Hits@10:56.97	Best:33.57
2024-12-29 03:12:29,672: Snapshot:0	Epoch:11	Loss:0.607	translation_Loss:0.607	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.52	Hits@10:57.08	Best:33.57
2024-12-29 03:12:33,453: Snapshot:0	Epoch:12	Loss:0.5	translation_Loss:0.5	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.72	Hits@10:57.12	Best:33.72
2024-12-29 03:12:37,670: Snapshot:0	Epoch:13	Loss:0.422	translation_Loss:0.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.54	Hits@10:57.11	Best:33.72
2024-12-29 03:12:41,474: Snapshot:0	Epoch:14	Loss:0.374	translation_Loss:0.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:56.93	Best:33.72
2024-12-29 03:12:45,320: Snapshot:0	Epoch:15	Loss:0.331	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.6	Hits@10:56.72	Best:33.72
2024-12-29 03:12:49,502: Snapshot:0	Epoch:16	Loss:0.302	translation_Loss:0.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.58	Hits@10:56.65	Best:33.72
2024-12-29 03:12:53,260: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 33.72
2024-12-29 03:12:53,260: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.277 MRR:33.71 Best Results: 33.72
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-29 03:12:53,260: Snapshot:0	Epoch:17	Loss:0.277	translation_Loss:0.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.71	Hits@10:56.88	Best:33.72
2024-12-29 03:12:57,626: Snapshot:0	Epoch:18	Loss:24.549	translation_Loss:9.718	multi_layer_Loss:14.831	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.71	Hits@10:56.88	Best:33.72
2024-12-29 03:13:01,845: End of token training: 0 Epoch: 19 Loss:10.264 MRR:33.71 Best Results: 33.72
2024-12-29 03:13:01,846: Snapshot:0	Epoch:19	Loss:10.264	translation_Loss:9.712	multi_layer_Loss:0.552	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.71	Hits@10:56.88	Best:33.72
2024-12-29 03:13:02,092: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-29 03:13:03,423: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3412 | 0.221  | 0.3959 | 0.4685 |  0.5723 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:13:28,571: Snapshot:1	Epoch:0	Loss:13.298	translation_Loss:12.828	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.47                                                   	MRR:15.09	Hits@10:25.84	Best:15.09
2024-12-29 03:13:35,128: Snapshot:1	Epoch:1	Loss:5.552	translation_Loss:5.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.335                                                   	MRR:20.56	Hits@10:36.76	Best:20.56
2024-12-29 03:13:41,703: Snapshot:1	Epoch:2	Loss:2.995	translation_Loss:2.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.234                                                   	MRR:23.15	Hits@10:41.26	Best:23.15
2024-12-29 03:13:48,280: Snapshot:1	Epoch:3	Loss:2.133	translation_Loss:1.939	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:24.04	Hits@10:42.69	Best:24.04
2024-12-29 03:13:54,837: Snapshot:1	Epoch:4	Loss:1.753	translation_Loss:1.58	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:24.5	Hits@10:43.31	Best:24.5
2024-12-29 03:14:01,809: Snapshot:1	Epoch:5	Loss:1.535	translation_Loss:1.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.162                                                   	MRR:24.66	Hits@10:43.83	Best:24.66
2024-12-29 03:14:08,326: Snapshot:1	Epoch:6	Loss:1.416	translation_Loss:1.259	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:24.95	Hits@10:44.14	Best:24.95
2024-12-29 03:14:15,262: Snapshot:1	Epoch:7	Loss:1.331	translation_Loss:1.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:24.87	Hits@10:44.11	Best:24.95
2024-12-29 03:14:21,838: Snapshot:1	Epoch:8	Loss:1.264	translation_Loss:1.114	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.15                                                   	MRR:24.83	Hits@10:44.1	Best:24.95
2024-12-29 03:14:28,807: Snapshot:1	Epoch:9	Loss:1.23	translation_Loss:1.081	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:25.03	Hits@10:44.29	Best:25.03
2024-12-29 03:14:35,389: Snapshot:1	Epoch:10	Loss:1.183	translation_Loss:1.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.147                                                   	MRR:25.05	Hits@10:44.35	Best:25.05
2024-12-29 03:14:42,368: Snapshot:1	Epoch:11	Loss:1.155	translation_Loss:1.009	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.146                                                   	MRR:25.1	Hits@10:44.51	Best:25.1
2024-12-29 03:14:48,949: Snapshot:1	Epoch:12	Loss:1.138	translation_Loss:0.992	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.146                                                   	MRR:25.17	Hits@10:44.53	Best:25.17
2024-12-29 03:14:55,877: Snapshot:1	Epoch:13	Loss:1.111	translation_Loss:0.967	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.144                                                   	MRR:25.18	Hits@10:44.34	Best:25.18
2024-12-29 03:15:02,436: Snapshot:1	Epoch:14	Loss:1.094	translation_Loss:0.949	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.145                                                   	MRR:25.22	Hits@10:44.64	Best:25.22
2024-12-29 03:15:09,410: Snapshot:1	Epoch:15	Loss:1.08	translation_Loss:0.933	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.147                                                   	MRR:25.21	Hits@10:44.79	Best:25.22
2024-12-29 03:15:16,457: Snapshot:1	Epoch:16	Loss:1.059	translation_Loss:0.915	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.143                                                   	MRR:25.25	Hits@10:44.6	Best:25.25
2024-12-29 03:15:22,979: Snapshot:1	Epoch:17	Loss:1.053	translation_Loss:0.911	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.142                                                   	MRR:25.25	Hits@10:44.75	Best:25.25
2024-12-29 03:15:29,969: Snapshot:1	Epoch:18	Loss:1.037	translation_Loss:0.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.144                                                   	MRR:25.13	Hits@10:44.62	Best:25.25
2024-12-29 03:15:36,566: Snapshot:1	Epoch:19	Loss:1.037	translation_Loss:0.895	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.143                                                   	MRR:25.22	Hits@10:44.65	Best:25.25
2024-12-29 03:15:43,500: Snapshot:1	Epoch:20	Loss:1.031	translation_Loss:0.887	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.143                                                   	MRR:25.22	Hits@10:44.67	Best:25.25
2024-12-29 03:15:50,072: Early Stopping! Snapshot: 1 Epoch: 21 Best Results: 25.25
2024-12-29 03:15:50,073: Start to training tokens! Snapshot: 1 Epoch: 21 Loss:1.021 MRR:25.19 Best Results: 25.25
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-29 03:15:50,073: Snapshot:1	Epoch:21	Loss:1.021	translation_Loss:0.876	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.145                                                   	MRR:25.19	Hits@10:44.65	Best:25.25
2024-12-29 03:15:57,026: Snapshot:1	Epoch:22	Loss:31.711	translation_Loss:15.756	multi_layer_Loss:15.955	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.19	Hits@10:44.65	Best:25.25
2024-12-29 03:16:03,557: End of token training: 1 Epoch: 23 Loss:15.969 MRR:25.19 Best Results: 25.25
2024-12-29 03:16:03,557: Snapshot:1	Epoch:23	Loss:15.969	translation_Loss:15.75	multi_layer_Loss:0.219	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.19	Hits@10:44.65	Best:25.25
2024-12-29 03:16:03,806: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-29 03:16:07,917: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      |  0.34  | 0.2184 | 0.3963 | 0.4698 |  0.5723 |
|     1      | 0.2542 | 0.1549 | 0.2889 | 0.3559 |  0.4465 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:16:34,405: Snapshot:2	Epoch:0	Loss:11.955	translation_Loss:11.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.653                                                   	MRR:14.82	Hits@10:24.98	Best:14.82
2024-12-29 03:16:41,658: Snapshot:2	Epoch:1	Loss:4.452	translation_Loss:4.002	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.449                                                   	MRR:18.35	Hits@10:32.43	Best:18.35
2024-12-29 03:16:48,933: Snapshot:2	Epoch:2	Loss:2.569	translation_Loss:2.26	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.309                                                   	MRR:20.49	Hits@10:36.19	Best:20.49
2024-12-29 03:16:56,671: Snapshot:2	Epoch:3	Loss:1.968	translation_Loss:1.705	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.263                                                   	MRR:21.49	Hits@10:37.9	Best:21.49
2024-12-29 03:17:03,937: Snapshot:2	Epoch:4	Loss:1.701	translation_Loss:1.459	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.243                                                   	MRR:22.06	Hits@10:38.63	Best:22.06
2024-12-29 03:17:11,584: Snapshot:2	Epoch:5	Loss:1.565	translation_Loss:1.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.234                                                   	MRR:22.33	Hits@10:39.34	Best:22.33
2024-12-29 03:17:18,870: Snapshot:2	Epoch:6	Loss:1.468	translation_Loss:1.239	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.229                                                   	MRR:22.49	Hits@10:39.87	Best:22.49
2024-12-29 03:17:26,459: Snapshot:2	Epoch:7	Loss:1.397	translation_Loss:1.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.225                                                   	MRR:22.83	Hits@10:40.22	Best:22.83
2024-12-29 03:17:33,720: Snapshot:2	Epoch:8	Loss:1.35	translation_Loss:1.125	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.225                                                   	MRR:22.88	Hits@10:40.6	Best:22.88
2024-12-29 03:17:41,313: Snapshot:2	Epoch:9	Loss:1.321	translation_Loss:1.098	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.224                                                   	MRR:23.01	Hits@10:40.71	Best:23.01
2024-12-29 03:17:48,962: Snapshot:2	Epoch:10	Loss:1.284	translation_Loss:1.062	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:23.07	Hits@10:40.64	Best:23.07
2024-12-29 03:17:56,239: Snapshot:2	Epoch:11	Loss:1.258	translation_Loss:1.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:23.19	Hits@10:40.7	Best:23.19
2024-12-29 03:18:03,916: Snapshot:2	Epoch:12	Loss:1.237	translation_Loss:1.017	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:23.24	Hits@10:40.66	Best:23.24
2024-12-29 03:18:11,143: Snapshot:2	Epoch:13	Loss:1.223	translation_Loss:1.001	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.223                                                   	MRR:23.18	Hits@10:40.84	Best:23.24
2024-12-29 03:18:18,759: Snapshot:2	Epoch:14	Loss:1.201	translation_Loss:0.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:23.2	Hits@10:40.78	Best:23.24
2024-12-29 03:18:26,016: Snapshot:2	Epoch:15	Loss:1.206	translation_Loss:0.984	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:23.25	Hits@10:40.9	Best:23.25
2024-12-29 03:18:33,677: Snapshot:2	Epoch:16	Loss:1.188	translation_Loss:0.967	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:23.26	Hits@10:40.99	Best:23.26
2024-12-29 03:18:40,937: Snapshot:2	Epoch:17	Loss:1.167	translation_Loss:0.946	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:23.25	Hits@10:40.95	Best:23.26
2024-12-29 03:18:48,491: Snapshot:2	Epoch:18	Loss:1.179	translation_Loss:0.956	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.223                                                   	MRR:23.26	Hits@10:41.1	Best:23.26
2024-12-29 03:18:56,048: Snapshot:2	Epoch:19	Loss:1.152	translation_Loss:0.93	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:23.4	Hits@10:41.23	Best:23.4
2024-12-29 03:19:03,237: Snapshot:2	Epoch:20	Loss:1.155	translation_Loss:0.934	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:23.33	Hits@10:41.27	Best:23.4
2024-12-29 03:19:10,916: Snapshot:2	Epoch:21	Loss:1.142	translation_Loss:0.919	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.223                                                   	MRR:23.35	Hits@10:41.21	Best:23.4
2024-12-29 03:19:18,183: Snapshot:2	Epoch:22	Loss:1.139	translation_Loss:0.917	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:23.44	Hits@10:41.38	Best:23.44
2024-12-29 03:19:25,711: Snapshot:2	Epoch:23	Loss:1.131	translation_Loss:0.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:23.23	Hits@10:41.05	Best:23.44
2024-12-29 03:19:32,953: Snapshot:2	Epoch:24	Loss:1.127	translation_Loss:0.905	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:23.25	Hits@10:41.11	Best:23.44
2024-12-29 03:19:40,538: Snapshot:2	Epoch:25	Loss:1.129	translation_Loss:0.905	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.224                                                   	MRR:23.43	Hits@10:41.29	Best:23.44
2024-12-29 03:19:47,730: Snapshot:2	Epoch:26	Loss:1.113	translation_Loss:0.892	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:23.33	Hits@10:41.22	Best:23.44
2024-12-29 03:19:55,281: Early Stopping! Snapshot: 2 Epoch: 27 Best Results: 23.44
2024-12-29 03:19:55,281: Start to training tokens! Snapshot: 2 Epoch: 27 Loss:1.115 MRR:23.36 Best Results: 23.44
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-29 03:19:55,281: Snapshot:2	Epoch:27	Loss:1.115	translation_Loss:0.892	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.223                                                   	MRR:23.36	Hits@10:41.44	Best:23.44
2024-12-29 03:20:02,857: Snapshot:2	Epoch:28	Loss:30.804	translation_Loss:15.583	multi_layer_Loss:15.221	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.36	Hits@10:41.44	Best:23.44
2024-12-29 03:20:10,387: End of token training: 2 Epoch: 29 Loss:15.805 MRR:23.36 Best Results: 23.44
2024-12-29 03:20:10,388: Snapshot:2	Epoch:29	Loss:15.805	translation_Loss:15.586	multi_layer_Loss:0.22	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.36	Hits@10:41.44	Best:23.44
2024-12-29 03:20:10,652: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-29 03:20:18,094: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.339  | 0.2185 | 0.3938 | 0.4691 |  0.5725 |
|     1      | 0.2535 | 0.1543 | 0.2878 | 0.355  |  0.4464 |
|     2      | 0.2357 |  0.14  | 0.2728 | 0.3336 |  0.4198 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:20:44,795: Snapshot:3	Epoch:0	Loss:10.943	translation_Loss:10.232	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.712                                                   	MRR:14.71	Hits@10:26.0	Best:14.71
2024-12-29 03:20:52,417: Snapshot:3	Epoch:1	Loss:3.62	translation_Loss:3.113	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.507                                                   	MRR:18.26	Hits@10:32.86	Best:18.26
2024-12-29 03:20:59,945: Snapshot:3	Epoch:2	Loss:2.073	translation_Loss:1.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.311                                                   	MRR:19.82	Hits@10:35.69	Best:19.82
2024-12-29 03:21:07,461: Snapshot:3	Epoch:3	Loss:1.602	translation_Loss:1.345	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.256                                                   	MRR:20.74	Hits@10:37.43	Best:20.74
2024-12-29 03:21:15,297: Snapshot:3	Epoch:4	Loss:1.387	translation_Loss:1.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.235                                                   	MRR:21.23	Hits@10:38.12	Best:21.23
2024-12-29 03:21:22,933: Snapshot:3	Epoch:5	Loss:1.282	translation_Loss:1.057	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.225                                                   	MRR:21.43	Hits@10:38.82	Best:21.43
2024-12-29 03:21:30,938: Snapshot:3	Epoch:6	Loss:1.219	translation_Loss:0.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.224                                                   	MRR:21.63	Hits@10:39.41	Best:21.63
2024-12-29 03:21:38,492: Snapshot:3	Epoch:7	Loss:1.17	translation_Loss:0.947	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.223                                                   	MRR:21.93	Hits@10:39.49	Best:21.93
2024-12-29 03:21:46,415: Snapshot:3	Epoch:8	Loss:1.129	translation_Loss:0.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:22.02	Hits@10:39.61	Best:22.02
2024-12-29 03:21:53,962: Snapshot:3	Epoch:9	Loss:1.104	translation_Loss:0.885	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.219                                                   	MRR:22.12	Hits@10:39.8	Best:22.12
2024-12-29 03:22:01,903: Snapshot:3	Epoch:10	Loss:1.081	translation_Loss:0.86	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:22.15	Hits@10:40.0	Best:22.15
2024-12-29 03:22:09,504: Snapshot:3	Epoch:11	Loss:1.058	translation_Loss:0.84	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.219                                                   	MRR:22.34	Hits@10:40.25	Best:22.34
2024-12-29 03:22:17,525: Snapshot:3	Epoch:12	Loss:1.048	translation_Loss:0.826	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:22.41	Hits@10:40.36	Best:22.41
2024-12-29 03:22:25,108: Snapshot:3	Epoch:13	Loss:1.037	translation_Loss:0.815	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:22.61	Hits@10:40.49	Best:22.61
2024-12-29 03:22:33,097: Snapshot:3	Epoch:14	Loss:1.017	translation_Loss:0.796	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:22.41	Hits@10:40.57	Best:22.61
2024-12-29 03:22:40,693: Snapshot:3	Epoch:15	Loss:1.002	translation_Loss:0.783	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:22.41	Hits@10:40.44	Best:22.61
2024-12-29 03:22:48,683: Snapshot:3	Epoch:16	Loss:1.006	translation_Loss:0.784	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:22.54	Hits@10:40.58	Best:22.61
2024-12-29 03:22:56,269: Snapshot:3	Epoch:17	Loss:0.997	translation_Loss:0.774	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.223                                                   	MRR:22.62	Hits@10:40.8	Best:22.62
2024-12-29 03:23:04,172: Snapshot:3	Epoch:18	Loss:0.983	translation_Loss:0.761	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:22.5	Hits@10:40.57	Best:22.62
2024-12-29 03:23:12,136: Snapshot:3	Epoch:19	Loss:0.981	translation_Loss:0.759	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.223                                                   	MRR:22.5	Hits@10:40.59	Best:22.62
2024-12-29 03:23:19,640: Snapshot:3	Epoch:20	Loss:0.971	translation_Loss:0.749	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:22.53	Hits@10:40.57	Best:22.62
2024-12-29 03:23:27,169: Snapshot:3	Epoch:21	Loss:0.974	translation_Loss:0.751	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.223                                                   	MRR:22.44	Hits@10:40.66	Best:22.62
2024-12-29 03:23:35,047: Early Stopping! Snapshot: 3 Epoch: 22 Best Results: 22.62
2024-12-29 03:23:35,047: Start to training tokens! Snapshot: 3 Epoch: 22 Loss:0.967 MRR:22.61 Best Results: 22.62
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-29 03:23:35,047: Snapshot:3	Epoch:22	Loss:0.967	translation_Loss:0.745	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:22.61	Hits@10:40.71	Best:22.62
2024-12-29 03:23:42,866: Snapshot:3	Epoch:23	Loss:28.557	translation_Loss:14.094	multi_layer_Loss:14.463	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.61	Hits@10:40.71	Best:22.62
2024-12-29 03:23:50,259: End of token training: 3 Epoch: 24 Loss:14.327 MRR:22.61 Best Results: 22.62
2024-12-29 03:23:50,259: Snapshot:3	Epoch:24	Loss:14.327	translation_Loss:14.085	multi_layer_Loss:0.241	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.61	Hits@10:40.71	Best:22.62
2024-12-29 03:23:50,514: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-29 03:24:00,794: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3383 | 0.2166 | 0.3958 | 0.4695 |  0.5725 |
|     1      | 0.2539 | 0.1539 | 0.2892 | 0.3561 |  0.4478 |
|     2      | 0.2372 | 0.141  | 0.2748 | 0.3353 |  0.4213 |
|     3      | 0.2277 | 0.1348 | 0.2651 | 0.3228 |  0.4033 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:24:21,029: Snapshot:4	Epoch:0	Loss:8.163	translation_Loss:7.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.481                                                   	MRR:16.86	Hits@10:31.93	Best:16.86
2024-12-29 03:24:26,657: Snapshot:4	Epoch:1	Loss:2.638	translation_Loss:2.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.452                                                   	MRR:22.49	Hits@10:41.06	Best:22.49
2024-12-29 03:24:32,150: Snapshot:4	Epoch:2	Loss:1.178	translation_Loss:0.926	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.251                                                   	MRR:24.47	Hits@10:43.28	Best:24.47
2024-12-29 03:24:37,673: Snapshot:4	Epoch:3	Loss:0.771	translation_Loss:0.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:25.19	Hits@10:44.5	Best:25.19
2024-12-29 03:24:43,189: Snapshot:4	Epoch:4	Loss:0.618	translation_Loss:0.487	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.131                                                   	MRR:25.68	Hits@10:45.52	Best:25.68
2024-12-29 03:24:49,192: Snapshot:4	Epoch:5	Loss:0.541	translation_Loss:0.424	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.118                                                   	MRR:25.92	Hits@10:46.08	Best:25.92
2024-12-29 03:24:54,662: Snapshot:4	Epoch:6	Loss:0.497	translation_Loss:0.388	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:26.17	Hits@10:46.48	Best:26.17
2024-12-29 03:25:00,500: Snapshot:4	Epoch:7	Loss:0.466	translation_Loss:0.359	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.106                                                   	MRR:26.42	Hits@10:46.71	Best:26.42
2024-12-29 03:25:05,984: Snapshot:4	Epoch:8	Loss:0.447	translation_Loss:0.342	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.104                                                   	MRR:26.6	Hits@10:47.17	Best:26.6
2024-12-29 03:25:11,439: Snapshot:4	Epoch:9	Loss:0.432	translation_Loss:0.328	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.104                                                   	MRR:26.6	Hits@10:47.36	Best:26.6
2024-12-29 03:25:17,286: Snapshot:4	Epoch:10	Loss:0.416	translation_Loss:0.312	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:26.77	Hits@10:47.42	Best:26.77
2024-12-29 03:25:22,870: Snapshot:4	Epoch:11	Loss:0.408	translation_Loss:0.306	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:26.91	Hits@10:47.67	Best:26.91
2024-12-29 03:25:28,429: Snapshot:4	Epoch:12	Loss:0.399	translation_Loss:0.298	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:26.92	Hits@10:47.72	Best:26.92
2024-12-29 03:25:34,278: Snapshot:4	Epoch:13	Loss:0.394	translation_Loss:0.291	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:26.93	Hits@10:47.74	Best:26.93
2024-12-29 03:25:39,740: Snapshot:4	Epoch:14	Loss:0.389	translation_Loss:0.287	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:26.9	Hits@10:47.88	Best:26.93
2024-12-29 03:25:45,218: Snapshot:4	Epoch:15	Loss:0.384	translation_Loss:0.282	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:26.97	Hits@10:47.82	Best:26.97
2024-12-29 03:25:51,073: Snapshot:4	Epoch:16	Loss:0.381	translation_Loss:0.28	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:27.23	Hits@10:48.24	Best:27.23
2024-12-29 03:25:56,594: Snapshot:4	Epoch:17	Loss:0.376	translation_Loss:0.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:27.25	Hits@10:48.26	Best:27.25
2024-12-29 03:26:02,034: Snapshot:4	Epoch:18	Loss:0.376	translation_Loss:0.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.07	Hits@10:48.08	Best:27.25
2024-12-29 03:26:07,911: Snapshot:4	Epoch:19	Loss:0.366	translation_Loss:0.265	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:27.1	Hits@10:48.21	Best:27.25
2024-12-29 03:26:13,516: Snapshot:4	Epoch:20	Loss:0.369	translation_Loss:0.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:27.14	Hits@10:48.19	Best:27.25
2024-12-29 03:26:19,307: Snapshot:4	Epoch:21	Loss:0.363	translation_Loss:0.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:27.25	Hits@10:48.27	Best:27.25
2024-12-29 03:26:24,703: Early Stopping! Snapshot: 4 Epoch: 22 Best Results: 27.25
2024-12-29 03:26:24,704: Start to training tokens! Snapshot: 4 Epoch: 22 Loss:0.358 MRR:27.13 Best Results: 27.25
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-29 03:26:24,704: Snapshot:4	Epoch:22	Loss:0.358	translation_Loss:0.258	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:27.13	Hits@10:48.27	Best:27.25
2024-12-29 03:26:30,081: Snapshot:4	Epoch:23	Loss:22.523	translation_Loss:7.68	multi_layer_Loss:14.843	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.13	Hits@10:48.27	Best:27.25
2024-12-29 03:26:35,422: End of token training: 4 Epoch: 24 Loss:8.287 MRR:27.13 Best Results: 27.25
2024-12-29 03:26:35,422: Snapshot:4	Epoch:24	Loss:8.287	translation_Loss:7.679	multi_layer_Loss:0.607	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.13	Hits@10:48.27	Best:27.25
2024-12-29 03:26:35,678: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-29 03:26:48,726: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3342 | 0.2109 | 0.3924 | 0.4654 |  0.5715 |
|     1      | 0.2518 | 0.1502 | 0.2898 | 0.3563 |  0.4477 |
|     2      | 0.2376 | 0.1406 | 0.2757 | 0.3373 |  0.4232 |
|     3      | 0.2287 | 0.1348 | 0.2659 | 0.3245 |  0.4076 |
|     4      | 0.272  | 0.1602 | 0.3262 | 0.3975 |  0.4872 |
+------------+--------+--------+--------+--------+---------+
2024-12-29 03:26:48,728: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3412 | 0.221  | 0.3959 | 0.4685 |  0.5723 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      |  0.34  | 0.2184 | 0.3963 | 0.4698 |  0.5723 |
|     1      | 0.2542 | 0.1549 | 0.2889 | 0.3559 |  0.4465 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.339  | 0.2185 | 0.3938 | 0.4691 |  0.5725 |
|     1      | 0.2535 | 0.1543 | 0.2878 | 0.355  |  0.4464 |
|     2      | 0.2357 |  0.14  | 0.2728 | 0.3336 |  0.4198 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3383 | 0.2166 | 0.3958 | 0.4695 |  0.5725 |
|     1      | 0.2539 | 0.1539 | 0.2892 | 0.3561 |  0.4478 |
|     2      | 0.2372 | 0.141  | 0.2748 | 0.3353 |  0.4213 |
|     3      | 0.2277 | 0.1348 | 0.2651 | 0.3228 |  0.4033 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3342 | 0.2109 | 0.3924 | 0.4654 |  0.5715 |
|     1      | 0.2518 | 0.1502 | 0.2898 | 0.3563 |  0.4477 |
|     2      | 0.2376 | 0.1406 | 0.2757 | 0.3373 |  0.4232 |
|     3      | 0.2287 | 0.1348 | 0.2659 | 0.3245 |  0.4076 |
|     4      | 0.272  | 0.1602 | 0.3262 | 0.3975 |  0.4872 |
+------------+--------+--------+--------+--------+---------+]
2024-12-29 03:26:48,729: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 83.00116872787476  |   0.341   |    0.221     |    0.396     |     0.572     |
|    1     | 177.77669858932495 |   0.288   |     0.18     |    0.331     |     0.496     |
|    2     | 239.4902994632721  |   0.267   |    0.164     |    0.308     |     0.467     |
|    3     | 208.8587052822113  |   0.257   |    0.156     |    0.298     |      0.45     |
|    4     | 151.8861038684845  |   0.259   |    0.155     |    0.302     |     0.457     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-29 03:26:48,729: Sum_Training_Time:861.0129759311676
2024-12-29 03:26:48,729: Every_Training_Time:[83.00116872787476, 177.77669858932495, 239.4902994632721, 208.8587052822113, 151.8861038684845]
2024-12-29 03:26:48,729: Forward transfer: 0.047374999999999994 Backward transfer: -0.0016249999999999945
2024-12-29 03:27:24,972: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229032654/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=6, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 03:27:32,764: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-29 03:27:36,626: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.11	Best:9.49
2024-12-29 03:27:40,794: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.71	Best:14.08
2024-12-29 03:27:44,569: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.74	Best:19.63
2024-12-29 03:27:48,324: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:48.74	Best:24.66
2024-12-29 03:27:52,449: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.31	Hits@10:52.04	Best:28.31
2024-12-29 03:27:56,196: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.34	Hits@10:53.84	Best:30.34
2024-12-29 03:28:00,298: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.76	Hits@10:55.38	Best:31.76
2024-12-29 03:28:04,074: Snapshot:0	Epoch:8	Loss:1.299	translation_Loss:1.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.61	Hits@10:56.08	Best:32.61
2024-12-29 03:28:07,835: Snapshot:0	Epoch:9	Loss:0.968	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.1	Hits@10:56.53	Best:33.1
2024-12-29 03:28:11,989: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.44	Hits@10:56.94	Best:33.44
2024-12-29 03:28:15,737: Snapshot:0	Epoch:11	Loss:0.608	translation_Loss:0.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.47	Hits@10:57.15	Best:33.47
2024-12-29 03:28:19,526: Snapshot:0	Epoch:12	Loss:0.5	translation_Loss:0.5	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.65	Hits@10:56.94	Best:33.65
2024-12-29 03:28:23,702: Snapshot:0	Epoch:13	Loss:0.422	translation_Loss:0.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.64	Hits@10:57.05	Best:33.65
2024-12-29 03:28:27,486: Snapshot:0	Epoch:14	Loss:0.374	translation_Loss:0.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.69	Hits@10:57.07	Best:33.69
2024-12-29 03:28:31,214: Snapshot:0	Epoch:15	Loss:0.331	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.64	Hits@10:56.93	Best:33.69
2024-12-29 03:28:35,362: Snapshot:0	Epoch:16	Loss:0.302	translation_Loss:0.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.62	Hits@10:56.68	Best:33.69
2024-12-29 03:28:39,100: Snapshot:0	Epoch:17	Loss:0.278	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.77	Hits@10:56.94	Best:33.77
2024-12-29 03:28:42,838: Snapshot:0	Epoch:18	Loss:0.257	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.44	Hits@10:56.77	Best:33.77
2024-12-29 03:28:46,960: Snapshot:0	Epoch:19	Loss:0.241	translation_Loss:0.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.42	Hits@10:56.96	Best:33.77
2024-12-29 03:28:50,697: Snapshot:0	Epoch:20	Loss:0.224	translation_Loss:0.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.49	Hits@10:56.71	Best:33.77
2024-12-29 03:28:54,472: Snapshot:0	Epoch:21	Loss:0.213	translation_Loss:0.213	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.45	Hits@10:56.67	Best:33.77
2024-12-29 03:28:58,574: Early Stopping! Snapshot: 0 Epoch: 22 Best Results: 33.77
2024-12-29 03:28:58,574: Start to training tokens! Snapshot: 0 Epoch: 22 Loss:0.202 MRR:33.56 Best Results: 33.77
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-29 03:28:58,575: Snapshot:0	Epoch:22	Loss:0.202	translation_Loss:0.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.56	Hits@10:56.45	Best:33.77
2024-12-29 03:29:02,826: Snapshot:0	Epoch:23	Loss:24.911	translation_Loss:9.744	multi_layer_Loss:15.168	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.56	Hits@10:56.45	Best:33.77
2024-12-29 03:29:06,586: End of token training: 0 Epoch: 24 Loss:10.384 MRR:33.56 Best Results: 33.77
2024-12-29 03:29:06,587: Snapshot:0	Epoch:24	Loss:10.384	translation_Loss:9.735	multi_layer_Loss:0.649	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.56	Hits@10:56.45	Best:33.77
2024-12-29 03:29:06,836: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-29 03:29:08,430: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3395 | 0.219  | 0.3948 | 0.4671 |  0.5719 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:29:33,468: Snapshot:1	Epoch:0	Loss:13.131	translation_Loss:12.653	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.478                                                   	MRR:14.87	Hits@10:25.47	Best:14.87
2024-12-29 03:29:40,037: Snapshot:1	Epoch:1	Loss:5.101	translation_Loss:4.786	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.315                                                   	MRR:20.06	Hits@10:35.68	Best:20.06
2024-12-29 03:29:46,577: Snapshot:1	Epoch:2	Loss:2.544	translation_Loss:2.336	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.207                                                   	MRR:22.97	Hits@10:40.33	Best:22.97
2024-12-29 03:29:53,195: Snapshot:1	Epoch:3	Loss:1.73	translation_Loss:1.569	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:23.94	Hits@10:42.23	Best:23.94
2024-12-29 03:29:59,712: Snapshot:1	Epoch:4	Loss:1.397	translation_Loss:1.256	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.141                                                   	MRR:24.53	Hits@10:42.95	Best:24.53
2024-12-29 03:30:06,647: Snapshot:1	Epoch:5	Loss:1.219	translation_Loss:1.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.131                                                   	MRR:24.69	Hits@10:43.37	Best:24.69
2024-12-29 03:30:13,418: Snapshot:1	Epoch:6	Loss:1.11	translation_Loss:0.984	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:24.89	Hits@10:43.72	Best:24.89
2024-12-29 03:30:20,340: Snapshot:1	Epoch:7	Loss:1.033	translation_Loss:0.912	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.121                                                   	MRR:24.81	Hits@10:43.68	Best:24.89
2024-12-29 03:30:26,828: Snapshot:1	Epoch:8	Loss:0.968	translation_Loss:0.852	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.116                                                   	MRR:24.81	Hits@10:43.69	Best:24.89
2024-12-29 03:30:33,780: Snapshot:1	Epoch:9	Loss:0.943	translation_Loss:0.828	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.115                                                   	MRR:24.86	Hits@10:44.01	Best:24.89
2024-12-29 03:30:40,336: Snapshot:1	Epoch:10	Loss:0.913	translation_Loss:0.796	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.116                                                   	MRR:24.9	Hits@10:43.86	Best:24.9
2024-12-29 03:30:47,229: Snapshot:1	Epoch:11	Loss:0.887	translation_Loss:0.772	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.115                                                   	MRR:25.09	Hits@10:44.2	Best:25.09
2024-12-29 03:30:53,746: Snapshot:1	Epoch:12	Loss:0.866	translation_Loss:0.752	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:24.96	Hits@10:43.99	Best:25.09
2024-12-29 03:31:00,690: Snapshot:1	Epoch:13	Loss:0.849	translation_Loss:0.736	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:24.9	Hits@10:44.19	Best:25.09
2024-12-29 03:31:07,497: Snapshot:1	Epoch:14	Loss:0.833	translation_Loss:0.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.112                                                   	MRR:25.04	Hits@10:44.13	Best:25.09
2024-12-29 03:31:14,180: Snapshot:1	Epoch:15	Loss:0.826	translation_Loss:0.712	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:25.02	Hits@10:44.13	Best:25.09
2024-12-29 03:31:21,107: Snapshot:1	Epoch:16	Loss:0.815	translation_Loss:0.702	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:25.26	Hits@10:44.29	Best:25.26
2024-12-29 03:31:27,625: Snapshot:1	Epoch:17	Loss:0.798	translation_Loss:0.685	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:25.0	Hits@10:44.15	Best:25.26
2024-12-29 03:31:34,588: Snapshot:1	Epoch:18	Loss:0.787	translation_Loss:0.675	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.112                                                   	MRR:25.04	Hits@10:44.19	Best:25.26
2024-12-29 03:31:41,059: Snapshot:1	Epoch:19	Loss:0.786	translation_Loss:0.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.112                                                   	MRR:24.99	Hits@10:44.39	Best:25.26
2024-12-29 03:31:47,908: Snapshot:1	Epoch:20	Loss:0.782	translation_Loss:0.667	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:25.12	Hits@10:44.53	Best:25.26
2024-12-29 03:31:54,362: Early Stopping! Snapshot: 1 Epoch: 21 Best Results: 25.26
2024-12-29 03:31:54,363: Start to training tokens! Snapshot: 1 Epoch: 21 Loss:0.767 MRR:25.1 Best Results: 25.26
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-29 03:31:54,364: Snapshot:1	Epoch:21	Loss:0.767	translation_Loss:0.655	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.112                                                   	MRR:25.1	Hits@10:44.37	Best:25.26
2024-12-29 03:32:01,246: Snapshot:1	Epoch:22	Loss:32.742	translation_Loss:15.831	multi_layer_Loss:16.911	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.1	Hits@10:44.37	Best:25.26
2024-12-29 03:32:07,778: End of token training: 1 Epoch: 23 Loss:16.05 MRR:25.1 Best Results: 25.26
2024-12-29 03:32:07,780: Snapshot:1	Epoch:23	Loss:16.05	translation_Loss:15.822	multi_layer_Loss:0.229	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.1	Hits@10:44.37	Best:25.26
2024-12-29 03:32:08,031: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-29 03:32:12,026: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3401 | 0.2205 | 0.3949 | 0.4673 |  0.5705 |
|     1      | 0.2554 | 0.1579 | 0.2906 | 0.3545 |  0.4454 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:32:38,309: Snapshot:2	Epoch:0	Loss:11.769	translation_Loss:11.103	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.666                                                   	MRR:14.79	Hits@10:24.73	Best:14.79
2024-12-29 03:32:45,723: Snapshot:2	Epoch:1	Loss:4.022	translation_Loss:3.591	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.431                                                   	MRR:18.1	Hits@10:31.76	Best:18.1
2024-12-29 03:32:53,080: Snapshot:2	Epoch:2	Loss:2.169	translation_Loss:1.881	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.287                                                   	MRR:20.35	Hits@10:35.81	Best:20.35
2024-12-29 03:33:00,834: Snapshot:2	Epoch:3	Loss:1.634	translation_Loss:1.396	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.238                                                   	MRR:21.34	Hits@10:37.63	Best:21.34
2024-12-29 03:33:08,245: Snapshot:2	Epoch:4	Loss:1.399	translation_Loss:1.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.219                                                   	MRR:21.85	Hits@10:38.46	Best:21.85
2024-12-29 03:33:15,983: Snapshot:2	Epoch:5	Loss:1.264	translation_Loss:1.057	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:22.25	Hits@10:39.01	Best:22.25
2024-12-29 03:33:23,315: Snapshot:2	Epoch:6	Loss:1.179	translation_Loss:0.977	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:22.54	Hits@10:39.49	Best:22.54
2024-12-29 03:33:30,989: Snapshot:2	Epoch:7	Loss:1.12	translation_Loss:0.922	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:22.59	Hits@10:39.72	Best:22.59
2024-12-29 03:33:38,357: Snapshot:2	Epoch:8	Loss:1.071	translation_Loss:0.875	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:22.62	Hits@10:40.03	Best:22.62
2024-12-29 03:33:46,053: Snapshot:2	Epoch:9	Loss:1.054	translation_Loss:0.859	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:23.01	Hits@10:40.29	Best:23.01
2024-12-29 03:33:53,763: Snapshot:2	Epoch:10	Loss:1.022	translation_Loss:0.828	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:23.02	Hits@10:40.28	Best:23.02
2024-12-29 03:34:01,067: Snapshot:2	Epoch:11	Loss:1.008	translation_Loss:0.815	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.193                                                   	MRR:22.97	Hits@10:40.35	Best:23.02
2024-12-29 03:34:08,750: Snapshot:2	Epoch:12	Loss:0.987	translation_Loss:0.795	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.193                                                   	MRR:23.13	Hits@10:40.35	Best:23.13
2024-12-29 03:34:16,118: Snapshot:2	Epoch:13	Loss:0.971	translation_Loss:0.778	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.193                                                   	MRR:23.13	Hits@10:40.52	Best:23.13
2024-12-29 03:34:23,775: Snapshot:2	Epoch:14	Loss:0.971	translation_Loss:0.777	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:23.13	Hits@10:40.55	Best:23.13
2024-12-29 03:34:31,108: Snapshot:2	Epoch:15	Loss:0.944	translation_Loss:0.752	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.192                                                   	MRR:23.29	Hits@10:40.84	Best:23.29
2024-12-29 03:34:38,749: Snapshot:2	Epoch:16	Loss:0.935	translation_Loss:0.744	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.191                                                   	MRR:23.18	Hits@10:40.83	Best:23.29
2024-12-29 03:34:46,034: Snapshot:2	Epoch:17	Loss:0.928	translation_Loss:0.737	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.191                                                   	MRR:23.1	Hits@10:40.77	Best:23.29
2024-12-29 03:34:53,712: Snapshot:2	Epoch:18	Loss:0.912	translation_Loss:0.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.192                                                   	MRR:22.96	Hits@10:40.72	Best:23.29
2024-12-29 03:35:01,426: Snapshot:2	Epoch:19	Loss:0.914	translation_Loss:0.723	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.191                                                   	MRR:23.14	Hits@10:40.76	Best:23.29
2024-12-29 03:35:08,717: Early Stopping! Snapshot: 2 Epoch: 20 Best Results: 23.29
2024-12-29 03:35:08,717: Start to training tokens! Snapshot: 2 Epoch: 20 Loss:0.906 MRR:22.99 Best Results: 23.29
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-29 03:35:08,717: Snapshot:2	Epoch:20	Loss:0.906	translation_Loss:0.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.191                                                   	MRR:22.99	Hits@10:40.68	Best:23.29
2024-12-29 03:35:16,313: Snapshot:2	Epoch:21	Loss:31.669	translation_Loss:15.706	multi_layer_Loss:15.962	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.99	Hits@10:40.68	Best:23.29
2024-12-29 03:35:23,452: End of token training: 2 Epoch: 22 Loss:15.938 MRR:22.99 Best Results: 23.29
2024-12-29 03:35:23,453: Snapshot:2	Epoch:22	Loss:15.938	translation_Loss:15.708	multi_layer_Loss:0.23	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.99	Hits@10:40.68	Best:23.29
2024-12-29 03:35:23,711: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-29 03:35:30,547: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3383 | 0.2178 | 0.3939 | 0.4635 |  0.5704 |
|     1      | 0.2548 | 0.1565 | 0.2908 | 0.3553 |  0.4445 |
|     2      | 0.2321 | 0.1383 | 0.2658 | 0.328  |  0.4108 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:35:56,861: Snapshot:3	Epoch:0	Loss:10.769	translation_Loss:10.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.745                                                   	MRR:14.71	Hits@10:25.97	Best:14.71
2024-12-29 03:36:04,462: Snapshot:3	Epoch:1	Loss:3.294	translation_Loss:2.797	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.497                                                   	MRR:18.06	Hits@10:32.28	Best:18.06
2024-12-29 03:36:12,579: Snapshot:3	Epoch:2	Loss:1.803	translation_Loss:1.507	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.297                                                   	MRR:19.78	Hits@10:35.69	Best:19.78
2024-12-29 03:36:20,168: Snapshot:3	Epoch:3	Loss:1.358	translation_Loss:1.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.24                                                   	MRR:20.57	Hits@10:36.96	Best:20.57
2024-12-29 03:36:28,074: Snapshot:3	Epoch:4	Loss:1.172	translation_Loss:0.953	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:20.9	Hits@10:38.15	Best:20.9
2024-12-29 03:36:35,631: Snapshot:3	Epoch:5	Loss:1.075	translation_Loss:0.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:21.35	Hits@10:38.63	Best:21.35
2024-12-29 03:36:43,573: Snapshot:3	Epoch:6	Loss:1.022	translation_Loss:0.814	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:21.65	Hits@10:39.36	Best:21.65
2024-12-29 03:36:51,193: Snapshot:3	Epoch:7	Loss:0.966	translation_Loss:0.761	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.206                                                   	MRR:21.9	Hits@10:39.47	Best:21.9
2024-12-29 03:36:59,138: Snapshot:3	Epoch:8	Loss:0.933	translation_Loss:0.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.203                                                   	MRR:21.85	Hits@10:39.6	Best:21.9
2024-12-29 03:37:06,651: Snapshot:3	Epoch:9	Loss:0.912	translation_Loss:0.709	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:22.11	Hits@10:39.92	Best:22.11
2024-12-29 03:37:14,718: Snapshot:3	Epoch:10	Loss:0.897	translation_Loss:0.693	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:22.29	Hits@10:39.99	Best:22.29
2024-12-29 03:37:22,672: Snapshot:3	Epoch:11	Loss:0.873	translation_Loss:0.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.203                                                   	MRR:22.23	Hits@10:40.07	Best:22.29
2024-12-29 03:37:30,229: Snapshot:3	Epoch:12	Loss:0.863	translation_Loss:0.66	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:22.38	Hits@10:40.08	Best:22.38
2024-12-29 03:37:37,841: Snapshot:3	Epoch:13	Loss:0.853	translation_Loss:0.649	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:22.38	Hits@10:40.16	Best:22.38
2024-12-29 03:37:45,714: Snapshot:3	Epoch:14	Loss:0.847	translation_Loss:0.643	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:22.39	Hits@10:40.22	Best:22.39
2024-12-29 03:37:53,659: Snapshot:3	Epoch:15	Loss:0.835	translation_Loss:0.63	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:22.51	Hits@10:40.33	Best:22.51
2024-12-29 03:38:01,324: Snapshot:3	Epoch:16	Loss:0.823	translation_Loss:0.621	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:22.38	Hits@10:40.26	Best:22.51
2024-12-29 03:38:09,164: Snapshot:3	Epoch:17	Loss:0.816	translation_Loss:0.613	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.203                                                   	MRR:22.49	Hits@10:40.39	Best:22.51
2024-12-29 03:38:16,729: Snapshot:3	Epoch:18	Loss:0.814	translation_Loss:0.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:22.28	Hits@10:40.27	Best:22.51
2024-12-29 03:38:24,665: Snapshot:3	Epoch:19	Loss:0.802	translation_Loss:0.599	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:22.36	Hits@10:40.35	Best:22.51
2024-12-29 03:38:32,153: Early Stopping! Snapshot: 3 Epoch: 20 Best Results: 22.51
2024-12-29 03:38:32,154: Start to training tokens! Snapshot: 3 Epoch: 20 Loss:0.806 MRR:22.44 Best Results: 22.51
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-29 03:38:32,154: Snapshot:3	Epoch:20	Loss:0.806	translation_Loss:0.599	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.206                                                   	MRR:22.44	Hits@10:40.46	Best:22.51
2024-12-29 03:38:39,902: Snapshot:3	Epoch:21	Loss:29.514	translation_Loss:14.167	multi_layer_Loss:15.347	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.44	Hits@10:40.46	Best:22.51
2024-12-29 03:38:47,285: End of token training: 3 Epoch: 22 Loss:14.408 MRR:22.44 Best Results: 22.51
2024-12-29 03:38:47,285: Snapshot:3	Epoch:22	Loss:14.408	translation_Loss:14.164	multi_layer_Loss:0.244	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.44	Hits@10:40.46	Best:22.51
2024-12-29 03:38:47,540: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-29 03:38:57,748: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3386 | 0.2182 | 0.3937 | 0.4637 |  0.5694 |
|     1      | 0.2553 | 0.1566 | 0.2913 | 0.3557 |  0.4469 |
|     2      | 0.2336 | 0.1393 | 0.268  | 0.3284 |  0.4117 |
|     3      | 0.2248 | 0.1318 | 0.2616 | 0.3204 |  0.3991 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:39:17,947: Snapshot:4	Epoch:0	Loss:8.076	translation_Loss:7.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.508                                                   	MRR:16.94	Hits@10:31.6	Best:16.94
2024-12-29 03:39:23,497: Snapshot:4	Epoch:1	Loss:2.485	translation_Loss:2.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.447                                                   	MRR:22.19	Hits@10:40.35	Best:22.19
2024-12-29 03:39:29,089: Snapshot:4	Epoch:2	Loss:1.048	translation_Loss:0.815	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.234                                                   	MRR:24.05	Hits@10:42.69	Best:24.05
2024-12-29 03:39:34,639: Snapshot:4	Epoch:3	Loss:0.666	translation_Loss:0.521	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.145                                                   	MRR:24.92	Hits@10:44.4	Best:24.92
2024-12-29 03:39:40,187: Snapshot:4	Epoch:4	Loss:0.531	translation_Loss:0.416	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.115                                                   	MRR:25.25	Hits@10:45.03	Best:25.25
2024-12-29 03:39:46,090: Snapshot:4	Epoch:5	Loss:0.462	translation_Loss:0.359	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.104                                                   	MRR:25.76	Hits@10:45.57	Best:25.76
2024-12-29 03:39:51,639: Snapshot:4	Epoch:6	Loss:0.424	translation_Loss:0.326	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:26.0	Hits@10:45.98	Best:26.0
2024-12-29 03:39:57,488: Snapshot:4	Epoch:7	Loss:0.397	translation_Loss:0.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.09	Hits@10:46.36	Best:26.09
2024-12-29 03:40:02,998: Snapshot:4	Epoch:8	Loss:0.382	translation_Loss:0.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.34	Hits@10:46.69	Best:26.34
2024-12-29 03:40:08,484: Snapshot:4	Epoch:9	Loss:0.366	translation_Loss:0.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:26.41	Hits@10:46.76	Best:26.41
2024-12-29 03:40:14,376: Snapshot:4	Epoch:10	Loss:0.354	translation_Loss:0.262	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:26.57	Hits@10:46.93	Best:26.57
2024-12-29 03:40:19,907: Snapshot:4	Epoch:11	Loss:0.351	translation_Loss:0.259	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:26.8	Hits@10:47.33	Best:26.8
2024-12-29 03:40:25,330: Snapshot:4	Epoch:12	Loss:0.335	translation_Loss:0.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:26.54	Hits@10:47.41	Best:26.8
2024-12-29 03:40:31,105: Snapshot:4	Epoch:13	Loss:0.33	translation_Loss:0.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:26.72	Hits@10:47.54	Best:26.8
2024-12-29 03:40:36,573: Snapshot:4	Epoch:14	Loss:0.326	translation_Loss:0.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:26.91	Hits@10:47.73	Best:26.91
2024-12-29 03:40:42,044: Snapshot:4	Epoch:15	Loss:0.321	translation_Loss:0.229	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:26.72	Hits@10:47.73	Best:26.91
2024-12-29 03:40:47,939: Snapshot:4	Epoch:16	Loss:0.316	translation_Loss:0.228	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:26.79	Hits@10:47.76	Best:26.91
2024-12-29 03:40:53,394: Snapshot:4	Epoch:17	Loss:0.315	translation_Loss:0.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:26.99	Hits@10:47.77	Best:26.99
2024-12-29 03:40:58,914: Snapshot:4	Epoch:18	Loss:0.32	translation_Loss:0.228	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:27.01	Hits@10:47.84	Best:27.01
2024-12-29 03:41:04,739: Snapshot:4	Epoch:19	Loss:0.311	translation_Loss:0.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:26.94	Hits@10:47.86	Best:27.01
2024-12-29 03:41:10,241: Snapshot:4	Epoch:20	Loss:0.311	translation_Loss:0.221	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:27.04	Hits@10:47.88	Best:27.04
2024-12-29 03:41:15,882: Snapshot:4	Epoch:21	Loss:0.305	translation_Loss:0.213	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:27.16	Hits@10:48.05	Best:27.16
2024-12-29 03:41:21,755: Snapshot:4	Epoch:22	Loss:0.31	translation_Loss:0.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:27.12	Hits@10:47.91	Best:27.16
2024-12-29 03:41:27,158: Snapshot:4	Epoch:23	Loss:0.309	translation_Loss:0.215	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:27.12	Hits@10:48.18	Best:27.16
2024-12-29 03:41:32,621: Snapshot:4	Epoch:24	Loss:0.304	translation_Loss:0.212	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:27.27	Hits@10:48.27	Best:27.27
2024-12-29 03:41:38,436: Snapshot:4	Epoch:25	Loss:0.294	translation_Loss:0.203	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:27.37	Hits@10:48.39	Best:27.37
2024-12-29 03:41:43,962: Snapshot:4	Epoch:26	Loss:0.299	translation_Loss:0.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:27.51	Hits@10:48.42	Best:27.51
2024-12-29 03:41:49,931: Snapshot:4	Epoch:27	Loss:0.297	translation_Loss:0.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:27.33	Hits@10:48.38	Best:27.51
2024-12-29 03:41:55,332: Snapshot:4	Epoch:28	Loss:0.295	translation_Loss:0.203	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:27.39	Hits@10:48.31	Best:27.51
2024-12-29 03:42:00,751: Snapshot:4	Epoch:29	Loss:0.3	translation_Loss:0.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:27.41	Hits@10:48.48	Best:27.51
2024-12-29 03:42:06,577: Snapshot:4	Epoch:30	Loss:0.291	translation_Loss:0.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:27.42	Hits@10:48.61	Best:27.51
2024-12-29 03:42:12,029: Early Stopping! Snapshot: 4 Epoch: 31 Best Results: 27.51
2024-12-29 03:42:12,029: Start to training tokens! Snapshot: 4 Epoch: 31 Loss:0.293 MRR:27.33 Best Results: 27.51
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([6, 200]), requires_grad: True
 - torch.Size([6, 200]), requires_grad: True
2024-12-29 03:42:12,029: Snapshot:4	Epoch:31	Loss:0.293	translation_Loss:0.2	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:27.33	Hits@10:48.43	Best:27.51
2024-12-29 03:42:17,363: Snapshot:4	Epoch:32	Loss:22.972	translation_Loss:7.722	multi_layer_Loss:15.251	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.33	Hits@10:48.43	Best:27.51
2024-12-29 03:42:23,037: End of token training: 4 Epoch: 33 Loss:8.421 MRR:27.33 Best Results: 27.51
2024-12-29 03:42:23,038: Snapshot:4	Epoch:33	Loss:8.421	translation_Loss:7.733	multi_layer_Loss:0.689	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.33	Hits@10:48.43	Best:27.51
2024-12-29 03:42:23,290: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-29 03:42:36,200: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3366 | 0.2163 | 0.3919 | 0.4629 |  0.5667 |
|     1      | 0.2553 | 0.1566 | 0.2897 | 0.3558 |  0.4468 |
|     2      | 0.2342 | 0.1397 | 0.2688 | 0.3301 |  0.4114 |
|     3      | 0.2269 | 0.1349 | 0.2618 | 0.321  |  0.4023 |
|     4      | 0.2744 | 0.163  | 0.3284 | 0.4009 |  0.4863 |
+------------+--------+--------+--------+--------+---------+
2024-12-29 03:42:36,203: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3395 | 0.219  | 0.3948 | 0.4671 |  0.5719 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3401 | 0.2205 | 0.3949 | 0.4673 |  0.5705 |
|     1      | 0.2554 | 0.1579 | 0.2906 | 0.3545 |  0.4454 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3383 | 0.2178 | 0.3939 | 0.4635 |  0.5704 |
|     1      | 0.2548 | 0.1565 | 0.2908 | 0.3553 |  0.4445 |
|     2      | 0.2321 | 0.1383 | 0.2658 | 0.328  |  0.4108 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3386 | 0.2182 | 0.3937 | 0.4637 |  0.5694 |
|     1      | 0.2553 | 0.1566 | 0.2913 | 0.3557 |  0.4469 |
|     2      | 0.2336 | 0.1393 | 0.268  | 0.3284 |  0.4117 |
|     3      | 0.2248 | 0.1318 | 0.2616 | 0.3204 |  0.3991 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3366 | 0.2163 | 0.3919 | 0.4629 |  0.5667 |
|     1      | 0.2553 | 0.1566 | 0.2897 | 0.3558 |  0.4468 |
|     2      | 0.2342 | 0.1397 | 0.2688 | 0.3301 |  0.4114 |
|     3      | 0.2269 | 0.1349 | 0.2618 | 0.321  |  0.4023 |
|     4      | 0.2744 | 0.163  | 0.3284 | 0.4009 |  0.4863 |
+------------+--------+--------+--------+--------+---------+]
2024-12-29 03:42:36,203: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 101.61357927322388 |    0.34   |    0.219     |    0.395     |     0.572     |
|    1     | 176.9670193195343  |   0.289   |    0.182     |    0.331     |     0.494     |
|    2     | 188.52670407295227 |   0.266   |    0.164     |    0.306     |     0.462     |
|    3     | 193.45061826705933 |   0.256   |    0.156     |    0.295     |     0.446     |
|    4     | 202.56571507453918 |   0.259   |    0.158     |     0.3      |     0.452     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-29 03:42:36,203: Sum_Training_Time:863.123636007309
2024-12-29 03:42:36,203: Every_Training_Time:[101.61357927322388, 176.9670193195343, 188.52670407295227, 193.45061826705933, 202.56571507453918]
2024-12-29 03:42:36,203: Forward transfer: 0.0453 Backward transfer: 0.0002999999999999947
2024-12-29 03:43:12,580: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229034241/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 03:43:20,432: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-29 03:43:24,262: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.11	Best:9.49
2024-12-29 03:43:28,484: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.71	Best:14.08
2024-12-29 03:43:32,282: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.75	Best:19.63
2024-12-29 03:43:36,106: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:48.76	Best:24.66
2024-12-29 03:43:40,276: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.3	Hits@10:52.03	Best:28.3
2024-12-29 03:43:44,120: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.37	Hits@10:53.92	Best:30.37
2024-12-29 03:43:48,282: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.81	Hits@10:55.44	Best:31.81
2024-12-29 03:43:52,083: Snapshot:0	Epoch:8	Loss:1.299	translation_Loss:1.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.63	Hits@10:56.21	Best:32.63
2024-12-29 03:43:55,978: Snapshot:0	Epoch:9	Loss:0.968	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.15	Hits@10:56.63	Best:33.15
2024-12-29 03:44:00,147: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.46	Hits@10:57.15	Best:33.46
2024-12-29 03:44:03,938: Snapshot:0	Epoch:11	Loss:0.607	translation_Loss:0.607	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.45	Hits@10:57.17	Best:33.46
2024-12-29 03:44:07,736: Snapshot:0	Epoch:12	Loss:0.5	translation_Loss:0.5	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.69	Hits@10:57.17	Best:33.69
2024-12-29 03:44:11,982: Snapshot:0	Epoch:13	Loss:0.422	translation_Loss:0.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.61	Hits@10:57.19	Best:33.69
2024-12-29 03:44:15,773: Snapshot:0	Epoch:14	Loss:0.374	translation_Loss:0.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:57.08	Best:33.69
2024-12-29 03:44:19,570: Snapshot:0	Epoch:15	Loss:0.331	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.62	Hits@10:56.96	Best:33.69
2024-12-29 03:44:23,786: Snapshot:0	Epoch:16	Loss:0.303	translation_Loss:0.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.68	Hits@10:56.64	Best:33.69
2024-12-29 03:44:27,602: Snapshot:0	Epoch:17	Loss:0.278	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.74	Hits@10:56.84	Best:33.74
2024-12-29 03:44:31,384: Snapshot:0	Epoch:18	Loss:0.257	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.5	Hits@10:56.84	Best:33.74
2024-12-29 03:44:35,535: Snapshot:0	Epoch:19	Loss:0.242	translation_Loss:0.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.56	Hits@10:56.91	Best:33.74
2024-12-29 03:44:39,328: Snapshot:0	Epoch:20	Loss:0.224	translation_Loss:0.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.49	Hits@10:56.66	Best:33.74
2024-12-29 03:44:43,130: Snapshot:0	Epoch:21	Loss:0.214	translation_Loss:0.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.54	Hits@10:56.62	Best:33.74
2024-12-29 03:44:47,297: Early Stopping! Snapshot: 0 Epoch: 22 Best Results: 33.74
2024-12-29 03:44:47,298: Start to training tokens! Snapshot: 0 Epoch: 22 Loss:0.202 MRR:33.63 Best Results: 33.74
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([7, 200]), requires_grad: True
 - torch.Size([7, 200]), requires_grad: True
2024-12-29 03:44:47,298: Snapshot:0	Epoch:22	Loss:0.202	translation_Loss:0.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.63	Hits@10:56.57	Best:33.74
2024-12-29 03:44:51,653: Snapshot:0	Epoch:23	Loss:25.395	translation_Loss:9.734	multi_layer_Loss:15.661	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.63	Hits@10:56.57	Best:33.74
2024-12-29 03:44:55,493: End of token training: 0 Epoch: 24 Loss:10.462 MRR:33.63 Best Results: 33.74
2024-12-29 03:44:55,493: Snapshot:0	Epoch:24	Loss:10.462	translation_Loss:9.726	multi_layer_Loss:0.737	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.63	Hits@10:56.57	Best:33.74
2024-12-29 03:44:55,741: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-29 03:44:57,303: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3404 | 0.2205 | 0.3954 | 0.4666 |  0.571  |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:45:22,585: Snapshot:1	Epoch:0	Loss:13.15	translation_Loss:12.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.481                                                   	MRR:14.84	Hits@10:25.36	Best:14.84
2024-12-29 03:45:29,152: Snapshot:1	Epoch:1	Loss:5.09	translation_Loss:4.788	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.302                                                   	MRR:20.14	Hits@10:35.64	Best:20.14
2024-12-29 03:45:35,761: Snapshot:1	Epoch:2	Loss:2.531	translation_Loss:2.333	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:22.86	Hits@10:40.3	Best:22.86
2024-12-29 03:45:42,345: Snapshot:1	Epoch:3	Loss:1.72	translation_Loss:1.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:23.9	Hits@10:42.05	Best:23.9
2024-12-29 03:45:49,018: Snapshot:1	Epoch:4	Loss:1.39	translation_Loss:1.256	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.134                                                   	MRR:24.35	Hits@10:42.75	Best:24.35
2024-12-29 03:45:55,991: Snapshot:1	Epoch:5	Loss:1.212	translation_Loss:1.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.124                                                   	MRR:24.63	Hits@10:43.23	Best:24.63
2024-12-29 03:46:02,572: Snapshot:1	Epoch:6	Loss:1.104	translation_Loss:0.984	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.121                                                   	MRR:24.79	Hits@10:43.66	Best:24.79
2024-12-29 03:46:09,674: Snapshot:1	Epoch:7	Loss:1.029	translation_Loss:0.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.116                                                   	MRR:24.81	Hits@10:43.8	Best:24.81
2024-12-29 03:46:16,474: Snapshot:1	Epoch:8	Loss:0.964	translation_Loss:0.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.111                                                   	MRR:24.76	Hits@10:43.78	Best:24.81
2024-12-29 03:46:23,457: Snapshot:1	Epoch:9	Loss:0.941	translation_Loss:0.831	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.11                                                   	MRR:24.83	Hits@10:44.25	Best:24.83
2024-12-29 03:46:30,075: Snapshot:1	Epoch:10	Loss:0.907	translation_Loss:0.797	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.11                                                   	MRR:24.79	Hits@10:43.96	Best:24.83
2024-12-29 03:46:37,100: Snapshot:1	Epoch:11	Loss:0.883	translation_Loss:0.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.111                                                   	MRR:24.98	Hits@10:44.18	Best:24.98
2024-12-29 03:46:43,765: Snapshot:1	Epoch:12	Loss:0.865	translation_Loss:0.755	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.11                                                   	MRR:25.0	Hits@10:44.13	Best:25.0
2024-12-29 03:46:50,735: Snapshot:1	Epoch:13	Loss:0.849	translation_Loss:0.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:24.93	Hits@10:44.17	Best:25.0
2024-12-29 03:46:57,713: Snapshot:1	Epoch:14	Loss:0.831	translation_Loss:0.723	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:24.96	Hits@10:44.2	Best:25.0
2024-12-29 03:47:04,264: Snapshot:1	Epoch:15	Loss:0.824	translation_Loss:0.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:24.95	Hits@10:44.07	Best:25.0
2024-12-29 03:47:11,275: Snapshot:1	Epoch:16	Loss:0.814	translation_Loss:0.705	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:25.1	Hits@10:44.22	Best:25.1
2024-12-29 03:47:17,897: Snapshot:1	Epoch:17	Loss:0.797	translation_Loss:0.688	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:24.89	Hits@10:44.16	Best:25.1
2024-12-29 03:47:24,893: Snapshot:1	Epoch:18	Loss:0.784	translation_Loss:0.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:25.0	Hits@10:44.1	Best:25.1
2024-12-29 03:47:31,459: Snapshot:1	Epoch:19	Loss:0.784	translation_Loss:0.677	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:25.04	Hits@10:44.14	Best:25.1
2024-12-29 03:47:38,423: Snapshot:1	Epoch:20	Loss:0.779	translation_Loss:0.67	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:25.09	Hits@10:44.28	Best:25.1
2024-12-29 03:47:45,019: Early Stopping! Snapshot: 1 Epoch: 21 Best Results: 25.1
2024-12-29 03:47:45,019: Start to training tokens! Snapshot: 1 Epoch: 21 Loss:0.763 MRR:24.95 Best Results: 25.1
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([7, 200]), requires_grad: True
 - torch.Size([7, 200]), requires_grad: True
2024-12-29 03:47:45,019: Snapshot:1	Epoch:21	Loss:0.763	translation_Loss:0.655	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:24.95	Hits@10:44.26	Best:25.1
2024-12-29 03:47:51,937: Snapshot:1	Epoch:22	Loss:33.252	translation_Loss:15.832	multi_layer_Loss:17.42	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.95	Hits@10:44.26	Best:25.1
2024-12-29 03:47:58,534: End of token training: 1 Epoch: 23 Loss:16.063 MRR:24.95 Best Results: 25.1
2024-12-29 03:47:58,534: Snapshot:1	Epoch:23	Loss:16.063	translation_Loss:15.822	multi_layer_Loss:0.241	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.95	Hits@10:44.26	Best:25.1
2024-12-29 03:47:58,785: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-29 03:48:02,705: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3404 | 0.2203 | 0.3964 | 0.467  |  0.5712 |
|     1      | 0.2542 | 0.157  | 0.2887 | 0.3521 |  0.4449 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:48:29,364: Snapshot:2	Epoch:0	Loss:11.788	translation_Loss:11.119	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.669                                                   	MRR:14.73	Hits@10:24.56	Best:14.73
2024-12-29 03:48:36,804: Snapshot:2	Epoch:1	Loss:4.01	translation_Loss:3.588	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.422                                                   	MRR:18.03	Hits@10:31.77	Best:18.03
2024-12-29 03:48:44,230: Snapshot:2	Epoch:2	Loss:2.161	translation_Loss:1.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.287                                                   	MRR:20.31	Hits@10:35.79	Best:20.31
2024-12-29 03:48:52,094: Snapshot:2	Epoch:3	Loss:1.627	translation_Loss:1.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.237                                                   	MRR:21.34	Hits@10:37.46	Best:21.34
2024-12-29 03:48:59,523: Snapshot:2	Epoch:4	Loss:1.392	translation_Loss:1.174	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:21.9	Hits@10:38.45	Best:21.9
2024-12-29 03:49:07,366: Snapshot:2	Epoch:5	Loss:1.257	translation_Loss:1.051	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.207                                                   	MRR:22.18	Hits@10:39.07	Best:22.18
2024-12-29 03:49:14,848: Snapshot:2	Epoch:6	Loss:1.172	translation_Loss:0.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:22.42	Hits@10:39.35	Best:22.42
2024-12-29 03:49:22,625: Snapshot:2	Epoch:7	Loss:1.115	translation_Loss:0.92	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:22.58	Hits@10:39.62	Best:22.58
2024-12-29 03:49:30,169: Snapshot:2	Epoch:8	Loss:1.065	translation_Loss:0.872	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.193                                                   	MRR:22.69	Hits@10:39.92	Best:22.69
2024-12-29 03:49:37,998: Snapshot:2	Epoch:9	Loss:1.047	translation_Loss:0.856	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.192                                                   	MRR:22.98	Hits@10:40.09	Best:22.98
2024-12-29 03:49:45,934: Snapshot:2	Epoch:10	Loss:1.017	translation_Loss:0.826	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.191                                                   	MRR:23.01	Hits@10:40.26	Best:23.01
2024-12-29 03:49:53,373: Snapshot:2	Epoch:11	Loss:1.001	translation_Loss:0.811	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.19                                                   	MRR:23.05	Hits@10:40.19	Best:23.05
2024-12-29 03:50:01,156: Snapshot:2	Epoch:12	Loss:0.98	translation_Loss:0.791	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.189                                                   	MRR:23.1	Hits@10:40.39	Best:23.1
2024-12-29 03:50:08,608: Snapshot:2	Epoch:13	Loss:0.963	translation_Loss:0.774	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.19                                                   	MRR:23.09	Hits@10:40.44	Best:23.1
2024-12-29 03:50:16,372: Snapshot:2	Epoch:14	Loss:0.965	translation_Loss:0.775	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.19                                                   	MRR:23.05	Hits@10:40.56	Best:23.1
2024-12-29 03:50:23,785: Snapshot:2	Epoch:15	Loss:0.937	translation_Loss:0.748	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:23.13	Hits@10:40.75	Best:23.13
2024-12-29 03:50:31,548: Snapshot:2	Epoch:16	Loss:0.929	translation_Loss:0.742	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:23.13	Hits@10:40.63	Best:23.13
2024-12-29 03:50:38,926: Snapshot:2	Epoch:17	Loss:0.923	translation_Loss:0.736	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:23.04	Hits@10:40.63	Best:23.13
2024-12-29 03:50:46,683: Snapshot:2	Epoch:18	Loss:0.906	translation_Loss:0.718	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:23.11	Hits@10:40.54	Best:23.13
2024-12-29 03:50:54,538: Snapshot:2	Epoch:19	Loss:0.911	translation_Loss:0.723	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:23.2	Hits@10:40.74	Best:23.2
2024-12-29 03:51:01,926: Snapshot:2	Epoch:20	Loss:0.901	translation_Loss:0.714	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:23.06	Hits@10:40.59	Best:23.2
2024-12-29 03:51:09,705: Snapshot:2	Epoch:21	Loss:0.894	translation_Loss:0.705	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:23.27	Hits@10:40.89	Best:23.27
2024-12-29 03:51:17,391: Snapshot:2	Epoch:22	Loss:0.885	translation_Loss:0.698	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:23.31	Hits@10:40.93	Best:23.31
2024-12-29 03:51:25,149: Snapshot:2	Epoch:23	Loss:0.885	translation_Loss:0.696	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:23.38	Hits@10:41.02	Best:23.38
2024-12-29 03:51:32,613: Snapshot:2	Epoch:24	Loss:0.873	translation_Loss:0.686	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:23.44	Hits@10:40.97	Best:23.44
2024-12-29 03:51:40,359: Snapshot:2	Epoch:25	Loss:0.873	translation_Loss:0.686	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:23.27	Hits@10:41.08	Best:23.44
2024-12-29 03:51:47,712: Snapshot:2	Epoch:26	Loss:0.864	translation_Loss:0.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.186                                                   	MRR:23.13	Hits@10:40.96	Best:23.44
2024-12-29 03:51:55,471: Snapshot:2	Epoch:27	Loss:0.863	translation_Loss:0.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.184                                                   	MRR:23.24	Hits@10:40.96	Best:23.44
2024-12-29 03:52:03,346: Snapshot:2	Epoch:28	Loss:0.862	translation_Loss:0.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.187                                                   	MRR:23.34	Hits@10:41.02	Best:23.44
2024-12-29 03:52:10,877: Early Stopping! Snapshot: 2 Epoch: 29 Best Results: 23.44
2024-12-29 03:52:10,877: Start to training tokens! Snapshot: 2 Epoch: 29 Loss:0.855 MRR:23.43 Best Results: 23.44
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([7, 200]), requires_grad: True
 - torch.Size([7, 200]), requires_grad: True
2024-12-29 03:52:10,877: Snapshot:2	Epoch:29	Loss:0.855	translation_Loss:0.671	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.184                                                   	MRR:23.43	Hits@10:41.18	Best:23.44
2024-12-29 03:52:18,613: Snapshot:2	Epoch:30	Loss:32.136	translation_Loss:15.698	multi_layer_Loss:16.439	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.43	Hits@10:41.18	Best:23.44
2024-12-29 03:52:25,919: End of token training: 2 Epoch: 31 Loss:15.926 MRR:23.43 Best Results: 23.44
2024-12-29 03:52:25,919: Snapshot:2	Epoch:31	Loss:15.926	translation_Loss:15.694	multi_layer_Loss:0.232	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.43	Hits@10:41.18	Best:23.44
2024-12-29 03:52:26,174: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-29 03:52:33,109: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3384 | 0.2177 | 0.3938 | 0.4669 |  0.5696 |
|     1      | 0.2544 | 0.1575 | 0.2878 | 0.3522 |  0.4444 |
|     2      | 0.2348 | 0.1414 | 0.2686 | 0.3289 |  0.4134 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:53:00,085: Snapshot:3	Epoch:0	Loss:10.769	translation_Loss:10.035	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.734                                                   	MRR:14.59	Hits@10:25.66	Best:14.59
2024-12-29 03:53:07,706: Snapshot:3	Epoch:1	Loss:3.284	translation_Loss:2.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.476                                                   	MRR:17.92	Hits@10:32.2	Best:17.92
2024-12-29 03:53:15,455: Snapshot:3	Epoch:2	Loss:1.786	translation_Loss:1.495	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.291                                                   	MRR:19.57	Hits@10:35.5	Best:19.57
2024-12-29 03:53:23,172: Snapshot:3	Epoch:3	Loss:1.355	translation_Loss:1.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.238                                                   	MRR:20.41	Hits@10:36.82	Best:20.41
2024-12-29 03:53:30,837: Snapshot:3	Epoch:4	Loss:1.172	translation_Loss:0.954	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:20.92	Hits@10:37.8	Best:20.92
2024-12-29 03:53:38,562: Snapshot:3	Epoch:5	Loss:1.071	translation_Loss:0.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:21.22	Hits@10:38.31	Best:21.22
2024-12-29 03:53:46,659: Snapshot:3	Epoch:6	Loss:1.0	translation_Loss:0.797	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.203                                                   	MRR:21.38	Hits@10:38.6	Best:21.38
2024-12-29 03:53:54,390: Snapshot:3	Epoch:7	Loss:0.966	translation_Loss:0.764	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:21.61	Hits@10:38.78	Best:21.61
2024-12-29 03:54:02,460: Snapshot:3	Epoch:8	Loss:0.928	translation_Loss:0.729	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:21.75	Hits@10:39.1	Best:21.75
2024-12-29 03:54:10,072: Snapshot:3	Epoch:9	Loss:0.913	translation_Loss:0.713	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:21.74	Hits@10:39.2	Best:21.75
2024-12-29 03:54:18,134: Snapshot:3	Epoch:10	Loss:0.887	translation_Loss:0.687	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:21.8	Hits@10:39.37	Best:21.8
2024-12-29 03:54:25,834: Snapshot:3	Epoch:11	Loss:0.878	translation_Loss:0.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:21.86	Hits@10:39.43	Best:21.86
2024-12-29 03:54:33,895: Snapshot:3	Epoch:12	Loss:0.851	translation_Loss:0.653	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:21.97	Hits@10:39.51	Best:21.97
2024-12-29 03:54:41,461: Snapshot:3	Epoch:13	Loss:0.848	translation_Loss:0.648	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:21.88	Hits@10:39.78	Best:21.97
2024-12-29 03:54:49,431: Snapshot:3	Epoch:14	Loss:0.835	translation_Loss:0.634	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:22.04	Hits@10:39.95	Best:22.04
2024-12-29 03:54:57,113: Snapshot:3	Epoch:15	Loss:0.821	translation_Loss:0.623	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:22.08	Hits@10:39.93	Best:22.08
2024-12-29 03:55:05,118: Snapshot:3	Epoch:16	Loss:0.819	translation_Loss:0.621	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:22.17	Hits@10:40.03	Best:22.17
2024-12-29 03:55:12,740: Snapshot:3	Epoch:17	Loss:0.818	translation_Loss:0.618	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:22.14	Hits@10:39.71	Best:22.17
2024-12-29 03:55:20,752: Snapshot:3	Epoch:18	Loss:0.811	translation_Loss:0.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:22.29	Hits@10:40.17	Best:22.29
2024-12-29 03:55:28,917: Snapshot:3	Epoch:19	Loss:0.797	translation_Loss:0.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:22.24	Hits@10:40.14	Best:22.29
2024-12-29 03:55:36,470: Snapshot:3	Epoch:20	Loss:0.803	translation_Loss:0.602	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:22.15	Hits@10:39.96	Best:22.29
2024-12-29 03:55:44,407: Snapshot:3	Epoch:21	Loss:0.791	translation_Loss:0.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:22.24	Hits@10:40.3	Best:22.29
2024-12-29 03:55:51,955: Snapshot:3	Epoch:22	Loss:0.783	translation_Loss:0.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:22.16	Hits@10:40.05	Best:22.29
2024-12-29 03:55:59,969: Snapshot:3	Epoch:23	Loss:0.771	translation_Loss:0.574	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:22.32	Hits@10:40.37	Best:22.32
2024-12-29 03:56:07,564: Snapshot:3	Epoch:24	Loss:0.771	translation_Loss:0.574	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:22.13	Hits@10:40.3	Best:22.32
2024-12-29 03:56:15,669: Snapshot:3	Epoch:25	Loss:0.771	translation_Loss:0.57	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:22.15	Hits@10:40.22	Best:22.32
2024-12-29 03:56:23,290: Snapshot:3	Epoch:26	Loss:0.762	translation_Loss:0.564	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:22.37	Hits@10:40.27	Best:22.37
2024-12-29 03:56:31,305: Snapshot:3	Epoch:27	Loss:0.763	translation_Loss:0.564	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:22.28	Hits@10:40.24	Best:22.37
2024-12-29 03:56:38,923: Snapshot:3	Epoch:28	Loss:0.763	translation_Loss:0.561	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:22.23	Hits@10:40.21	Best:22.37
2024-12-29 03:56:46,895: Snapshot:3	Epoch:29	Loss:0.753	translation_Loss:0.554	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:22.25	Hits@10:40.09	Best:22.37
2024-12-29 03:56:54,478: Snapshot:3	Epoch:30	Loss:0.75	translation_Loss:0.552	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:22.28	Hits@10:40.34	Best:22.37
2024-12-29 03:57:02,447: Early Stopping! Snapshot: 3 Epoch: 31 Best Results: 22.37
2024-12-29 03:57:02,447: Start to training tokens! Snapshot: 3 Epoch: 31 Loss:0.753 MRR:22.37 Best Results: 22.37
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([7, 200]), requires_grad: True
 - torch.Size([7, 200]), requires_grad: True
2024-12-29 03:57:02,447: Snapshot:3	Epoch:31	Loss:0.753	translation_Loss:0.553	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:22.37	Hits@10:40.47	Best:22.37
2024-12-29 03:57:09,874: Snapshot:3	Epoch:32	Loss:30.262	translation_Loss:14.196	multi_layer_Loss:16.066	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.37	Hits@10:40.47	Best:22.37
2024-12-29 03:57:17,724: End of token training: 3 Epoch: 33 Loss:14.436 MRR:22.37 Best Results: 22.37
2024-12-29 03:57:17,724: Snapshot:3	Epoch:33	Loss:14.436	translation_Loss:14.185	multi_layer_Loss:0.251	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.37	Hits@10:40.47	Best:22.37
2024-12-29 03:57:17,978: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-29 03:57:28,182: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3392 | 0.2194 | 0.3927 | 0.4674 |  0.5691 |
|     1      | 0.2542 | 0.1563 | 0.2879 | 0.3524 |  0.4443 |
|     2      | 0.2353 | 0.1423 | 0.2688 | 0.3302 |  0.4145 |
|     3      | 0.2241 | 0.1326 | 0.2591 | 0.3156 |  0.3973 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 03:57:48,204: Snapshot:4	Epoch:0	Loss:8.113	translation_Loss:7.612	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.502                                                   	MRR:16.54	Hits@10:31.32	Best:16.54
2024-12-29 03:57:53,703: Snapshot:4	Epoch:1	Loss:2.492	translation_Loss:2.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.417                                                   	MRR:21.53	Hits@10:39.7	Best:21.53
2024-12-29 03:57:59,728: Snapshot:4	Epoch:2	Loss:1.049	translation_Loss:0.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:23.85	Hits@10:42.45	Best:23.85
2024-12-29 03:58:05,286: Snapshot:4	Epoch:3	Loss:0.677	translation_Loss:0.544	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.133                                                   	MRR:24.62	Hits@10:43.96	Best:24.62
2024-12-29 03:58:10,838: Snapshot:4	Epoch:4	Loss:0.527	translation_Loss:0.42	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:25.2	Hits@10:44.96	Best:25.2
2024-12-29 03:58:16,811: Snapshot:4	Epoch:5	Loss:0.463	translation_Loss:0.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:25.49	Hits@10:45.54	Best:25.49
2024-12-29 03:58:22,341: Snapshot:4	Epoch:6	Loss:0.427	translation_Loss:0.336	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:25.7	Hits@10:45.87	Best:25.7
2024-12-29 03:58:28,254: Snapshot:4	Epoch:7	Loss:0.397	translation_Loss:0.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:25.72	Hits@10:45.84	Best:25.72
2024-12-29 03:58:33,753: Snapshot:4	Epoch:8	Loss:0.379	translation_Loss:0.292	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:26.01	Hits@10:46.5	Best:26.01
2024-12-29 03:58:39,253: Snapshot:4	Epoch:9	Loss:0.367	translation_Loss:0.282	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:26.19	Hits@10:46.9	Best:26.19
2024-12-29 03:58:45,139: Snapshot:4	Epoch:10	Loss:0.357	translation_Loss:0.27	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:26.2	Hits@10:46.74	Best:26.2
2024-12-29 03:58:50,708: Snapshot:4	Epoch:11	Loss:0.348	translation_Loss:0.262	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:26.3	Hits@10:47.07	Best:26.3
2024-12-29 03:58:56,276: Snapshot:4	Epoch:12	Loss:0.344	translation_Loss:0.259	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:26.53	Hits@10:47.26	Best:26.53
2024-12-29 03:59:02,153: Snapshot:4	Epoch:13	Loss:0.329	translation_Loss:0.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.084                                                   	MRR:26.49	Hits@10:47.22	Best:26.53
2024-12-29 03:59:07,621: Snapshot:4	Epoch:14	Loss:0.327	translation_Loss:0.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:26.53	Hits@10:47.47	Best:26.53
2024-12-29 03:59:13,112: Snapshot:4	Epoch:15	Loss:0.322	translation_Loss:0.237	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:26.46	Hits@10:47.3	Best:26.53
2024-12-29 03:59:19,074: Snapshot:4	Epoch:16	Loss:0.319	translation_Loss:0.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:26.32	Hits@10:47.3	Best:26.53
2024-12-29 03:59:24,584: Early Stopping! Snapshot: 4 Epoch: 17 Best Results: 26.53
2024-12-29 03:59:24,584: Start to training tokens! Snapshot: 4 Epoch: 17 Loss:0.316 MRR:26.42 Best Results: 26.53
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([7, 200]), requires_grad: True
 - torch.Size([7, 200]), requires_grad: True
2024-12-29 03:59:24,585: Snapshot:4	Epoch:17	Loss:0.316	translation_Loss:0.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:26.42	Hits@10:47.23	Best:26.53
2024-12-29 03:59:29,992: Snapshot:4	Epoch:18	Loss:23.515	translation_Loss:7.771	multi_layer_Loss:15.744	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.42	Hits@10:47.23	Best:26.53
2024-12-29 03:59:35,703: End of token training: 4 Epoch: 19 Loss:8.547 MRR:26.42 Best Results: 26.53
2024-12-29 03:59:35,704: Snapshot:4	Epoch:19	Loss:8.547	translation_Loss:7.775	multi_layer_Loss:0.772	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.42	Hits@10:47.23	Best:26.53
2024-12-29 03:59:35,956: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-29 03:59:48,753: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3374 | 0.2166 | 0.394  | 0.4662 |  0.5666 |
|     1      | 0.2544 | 0.1563 | 0.2889 | 0.3536 |  0.4437 |
|     2      | 0.2373 | 0.1445 | 0.2705 | 0.3316 |  0.4165 |
|     3      | 0.2263 | 0.1349 | 0.2605 | 0.3189 |  0.4009 |
|     4      | 0.2662 | 0.1571 | 0.3181 | 0.388  |  0.4753 |
+------------+--------+--------+--------+--------+---------+
2024-12-29 03:59:48,755: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3404 | 0.2205 | 0.3954 | 0.4666 |  0.571  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3404 | 0.2203 | 0.3964 | 0.467  |  0.5712 |
|     1      | 0.2542 | 0.157  | 0.2887 | 0.3521 |  0.4449 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3384 | 0.2177 | 0.3938 | 0.4669 |  0.5696 |
|     1      | 0.2544 | 0.1575 | 0.2878 | 0.3522 |  0.4444 |
|     2      | 0.2348 | 0.1414 | 0.2686 | 0.3289 |  0.4134 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3392 | 0.2194 | 0.3927 | 0.4674 |  0.5691 |
|     1      | 0.2542 | 0.1563 | 0.2879 | 0.3524 |  0.4443 |
|     2      | 0.2353 | 0.1423 | 0.2688 | 0.3302 |  0.4145 |
|     3      | 0.2241 | 0.1326 | 0.2591 | 0.3156 |  0.3973 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3374 | 0.2166 | 0.394  | 0.4662 |  0.5666 |
|     1      | 0.2544 | 0.1563 | 0.2889 | 0.3536 |  0.4437 |
|     2      | 0.2373 | 0.1445 | 0.2705 | 0.3316 |  0.4165 |
|     3      | 0.2263 | 0.1349 | 0.2605 | 0.3189 |  0.4009 |
|     4      | 0.2662 | 0.1571 | 0.3181 | 0.388  |  0.4753 |
+------------+--------+--------+--------+--------+---------+]
2024-12-29 03:59:48,756: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 102.91313648223877 |    0.34   |    0.221     |    0.395     |     0.571     |
|    1     | 178.87209725379944 |   0.288   |    0.182     |    0.331     |     0.494     |
|    2     | 260.3257656097412  |   0.267   |    0.166     |    0.306     |     0.463     |
|    3     | 281.32154512405396 |   0.256   |    0.157     |    0.293     |     0.445     |
|    4     | 124.77317214012146 |   0.258   |    0.158     |    0.298     |     0.451     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-29 03:59:48,756: Sum_Training_Time:948.2057166099548
2024-12-29 03:59:48,756: Every_Training_Time:[102.91313648223877, 178.87209725379944, 260.3257656097412, 281.32154512405396, 124.77317214012146]
2024-12-29 03:59:48,756: Forward transfer: 0.04535 Backward transfer: 0.00047500000000001014
2024-12-29 04:00:25,368: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229035954/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=8, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 04:00:33,221: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-29 04:00:37,024: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.11	Best:9.49
2024-12-29 04:00:41,246: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.7	Best:14.08
2024-12-29 04:00:45,090: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.74	Best:19.63
2024-12-29 04:00:48,937: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:48.72	Best:24.66
2024-12-29 04:00:53,130: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.33	Hits@10:52.03	Best:28.33
2024-12-29 04:00:56,952: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.35	Hits@10:53.86	Best:30.35
2024-12-29 04:01:01,131: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.8	Hits@10:55.52	Best:31.8
2024-12-29 04:01:04,952: Snapshot:0	Epoch:8	Loss:1.299	translation_Loss:1.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.58	Hits@10:56.12	Best:32.58
2024-12-29 04:01:08,794: Snapshot:0	Epoch:9	Loss:0.968	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.09	Hits@10:56.59	Best:33.09
2024-12-29 04:01:13,087: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.42	Hits@10:56.98	Best:33.42
2024-12-29 04:01:16,998: Snapshot:0	Epoch:11	Loss:0.607	translation_Loss:0.607	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.47	Hits@10:57.17	Best:33.47
2024-12-29 04:01:20,870: Snapshot:0	Epoch:12	Loss:0.499	translation_Loss:0.499	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.71	Hits@10:57.08	Best:33.71
2024-12-29 04:01:25,075: Snapshot:0	Epoch:13	Loss:0.421	translation_Loss:0.421	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.63	Hits@10:57.11	Best:33.71
2024-12-29 04:01:28,900: Snapshot:0	Epoch:14	Loss:0.374	translation_Loss:0.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.6	Hits@10:56.98	Best:33.71
2024-12-29 04:01:32,723: Snapshot:0	Epoch:15	Loss:0.33	translation_Loss:0.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.58	Hits@10:56.83	Best:33.71
2024-12-29 04:01:36,961: Snapshot:0	Epoch:16	Loss:0.303	translation_Loss:0.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.65	Hits@10:56.81	Best:33.71
2024-12-29 04:01:40,760: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 33.71
2024-12-29 04:01:40,761: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.278 MRR:33.63 Best Results: 33.71
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-29 04:01:40,761: Snapshot:0	Epoch:17	Loss:0.278	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.63	Hits@10:56.76	Best:33.71
2024-12-29 04:01:45,072: Snapshot:0	Epoch:18	Loss:25.888	translation_Loss:9.72	multi_layer_Loss:16.167	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.63	Hits@10:56.76	Best:33.71
2024-12-29 04:01:49,250: End of token training: 0 Epoch: 19 Loss:10.5 MRR:33.63 Best Results: 33.71
2024-12-29 04:01:49,250: Snapshot:0	Epoch:19	Loss:10.5	translation_Loss:9.714	multi_layer_Loss:0.786	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.63	Hits@10:56.76	Best:33.71
2024-12-29 04:01:49,500: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-29 04:01:50,804: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3411 | 0.2201 | 0.3973 | 0.4704 |  0.5733 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 04:02:16,098: Snapshot:1	Epoch:0	Loss:13.352	translation_Loss:12.87	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.482                                                   	MRR:14.95	Hits@10:25.68	Best:14.95
2024-12-29 04:02:22,729: Snapshot:1	Epoch:1	Loss:5.515	translation_Loss:5.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.296                                                   	MRR:20.59	Hits@10:36.77	Best:20.59
2024-12-29 04:02:29,330: Snapshot:1	Epoch:2	Loss:2.962	translation_Loss:2.755	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.207                                                   	MRR:23.05	Hits@10:41.32	Best:23.05
2024-12-29 04:02:35,942: Snapshot:1	Epoch:3	Loss:2.102	translation_Loss:1.934	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:24.02	Hits@10:42.77	Best:24.02
2024-12-29 04:02:42,569: Snapshot:1	Epoch:4	Loss:1.727	translation_Loss:1.578	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:24.45	Hits@10:43.22	Best:24.45
2024-12-29 04:02:49,554: Snapshot:1	Epoch:5	Loss:1.512	translation_Loss:1.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.139                                                   	MRR:24.69	Hits@10:43.77	Best:24.69
2024-12-29 04:02:56,288: Snapshot:1	Epoch:6	Loss:1.396	translation_Loss:1.262	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.134                                                   	MRR:25.03	Hits@10:44.0	Best:25.03
2024-12-29 04:03:03,217: Snapshot:1	Epoch:7	Loss:1.315	translation_Loss:1.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.132                                                   	MRR:24.87	Hits@10:44.19	Best:25.03
2024-12-29 04:03:09,819: Snapshot:1	Epoch:8	Loss:1.247	translation_Loss:1.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.129                                                   	MRR:24.79	Hits@10:44.05	Best:25.03
2024-12-29 04:03:16,887: Snapshot:1	Epoch:9	Loss:1.217	translation_Loss:1.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.129                                                   	MRR:25.06	Hits@10:44.31	Best:25.06
2024-12-29 04:03:23,519: Snapshot:1	Epoch:10	Loss:1.17	translation_Loss:1.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.129                                                   	MRR:25.13	Hits@10:44.43	Best:25.13
2024-12-29 04:03:30,533: Snapshot:1	Epoch:11	Loss:1.143	translation_Loss:1.017	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:25.1	Hits@10:44.55	Best:25.13
2024-12-29 04:03:37,135: Snapshot:1	Epoch:12	Loss:1.126	translation_Loss:0.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:25.14	Hits@10:44.39	Best:25.14
2024-12-29 04:03:44,054: Snapshot:1	Epoch:13	Loss:1.1	translation_Loss:0.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.125                                                   	MRR:25.07	Hits@10:44.23	Best:25.14
2024-12-29 04:03:50,641: Snapshot:1	Epoch:14	Loss:1.084	translation_Loss:0.958	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:25.26	Hits@10:44.49	Best:25.26
2024-12-29 04:03:57,576: Snapshot:1	Epoch:15	Loss:1.07	translation_Loss:0.941	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.129                                                   	MRR:25.1	Hits@10:44.44	Best:25.26
2024-12-29 04:04:04,631: Snapshot:1	Epoch:16	Loss:1.05	translation_Loss:0.925	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:25.09	Hits@10:44.47	Best:25.26
2024-12-29 04:04:11,205: Snapshot:1	Epoch:17	Loss:1.045	translation_Loss:0.92	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.124                                                   	MRR:25.13	Hits@10:44.56	Best:25.26
2024-12-29 04:04:18,189: Snapshot:1	Epoch:18	Loss:1.029	translation_Loss:0.902	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:25.01	Hits@10:44.6	Best:25.26
2024-12-29 04:04:24,763: Early Stopping! Snapshot: 1 Epoch: 19 Best Results: 25.26
2024-12-29 04:04:24,763: Start to training tokens! Snapshot: 1 Epoch: 19 Loss:1.03 MRR:25.13 Best Results: 25.26
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-29 04:04:24,763: Snapshot:1	Epoch:19	Loss:1.03	translation_Loss:0.903	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:25.13	Hits@10:44.48	Best:25.26
2024-12-29 04:04:31,855: Snapshot:1	Epoch:20	Loss:33.73	translation_Loss:15.764	multi_layer_Loss:17.967	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.13	Hits@10:44.48	Best:25.26
2024-12-29 04:04:38,473: End of token training: 1 Epoch: 21 Loss:16.031 MRR:25.13 Best Results: 25.26
2024-12-29 04:04:38,473: Snapshot:1	Epoch:21	Loss:16.031	translation_Loss:15.773	multi_layer_Loss:0.258	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.13	Hits@10:44.48	Best:25.26
2024-12-29 04:04:38,736: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-29 04:04:42,712: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3411 | 0.2199 | 0.3963 | 0.4705 |  0.5732 |
|     1      | 0.2536 | 0.1547 | 0.2893 | 0.354  |  0.4449 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 04:05:09,458: Snapshot:2	Epoch:0	Loss:12.024	translation_Loss:11.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.669                                                   	MRR:14.56	Hits@10:24.72	Best:14.56
2024-12-29 04:05:16,981: Snapshot:2	Epoch:1	Loss:4.449	translation_Loss:4.021	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.428                                                   	MRR:18.18	Hits@10:32.42	Best:18.18
2024-12-29 04:05:24,421: Snapshot:2	Epoch:2	Loss:2.565	translation_Loss:2.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.309                                                   	MRR:20.54	Hits@10:36.56	Best:20.54
2024-12-29 04:05:31,883: Snapshot:2	Epoch:3	Loss:1.973	translation_Loss:1.708	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.266                                                   	MRR:21.53	Hits@10:38.05	Best:21.53
2024-12-29 04:05:39,444: Snapshot:2	Epoch:4	Loss:1.71	translation_Loss:1.465	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.246                                                   	MRR:22.03	Hits@10:38.94	Best:22.03
2024-12-29 04:05:46,965: Snapshot:2	Epoch:5	Loss:1.556	translation_Loss:1.321	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.235                                                   	MRR:22.44	Hits@10:39.54	Best:22.44
2024-12-29 04:05:54,838: Snapshot:2	Epoch:6	Loss:1.459	translation_Loss:1.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.228                                                   	MRR:22.6	Hits@10:39.75	Best:22.6
2024-12-29 04:06:02,629: Snapshot:2	Epoch:7	Loss:1.401	translation_Loss:1.176	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.225                                                   	MRR:22.96	Hits@10:40.19	Best:22.96
2024-12-29 04:06:10,132: Snapshot:2	Epoch:8	Loss:1.347	translation_Loss:1.126	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:22.99	Hits@10:40.32	Best:22.99
2024-12-29 04:06:18,280: Snapshot:2	Epoch:9	Loss:1.31	translation_Loss:1.09	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.219                                                   	MRR:23.02	Hits@10:40.43	Best:23.02
2024-12-29 04:06:25,721: Snapshot:2	Epoch:10	Loss:1.278	translation_Loss:1.06	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:23.21	Hits@10:40.49	Best:23.21
2024-12-29 04:06:33,440: Snapshot:2	Epoch:11	Loss:1.251	translation_Loss:1.032	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.219                                                   	MRR:23.16	Hits@10:40.65	Best:23.21
2024-12-29 04:06:40,827: Snapshot:2	Epoch:12	Loss:1.226	translation_Loss:1.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.216                                                   	MRR:23.11	Hits@10:40.63	Best:23.21
2024-12-29 04:06:48,641: Snapshot:2	Epoch:13	Loss:1.211	translation_Loss:0.996	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.215                                                   	MRR:23.17	Hits@10:40.91	Best:23.21
2024-12-29 04:06:56,107: Snapshot:2	Epoch:14	Loss:1.198	translation_Loss:0.983	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:23.28	Hits@10:40.83	Best:23.28
2024-12-29 04:07:03,931: Snapshot:2	Epoch:15	Loss:1.183	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:23.2	Hits@10:40.99	Best:23.28
2024-12-29 04:07:11,682: Snapshot:2	Epoch:16	Loss:1.173	translation_Loss:0.958	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.215                                                   	MRR:23.38	Hits@10:41.08	Best:23.38
2024-12-29 04:07:19,245: Snapshot:2	Epoch:17	Loss:1.171	translation_Loss:0.955	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.216                                                   	MRR:23.41	Hits@10:40.97	Best:23.41
2024-12-29 04:07:27,060: Snapshot:2	Epoch:18	Loss:1.157	translation_Loss:0.943	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:23.23	Hits@10:40.88	Best:23.41
2024-12-29 04:07:34,519: Snapshot:2	Epoch:19	Loss:1.151	translation_Loss:0.937	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:23.38	Hits@10:40.99	Best:23.41
2024-12-29 04:07:42,266: Snapshot:2	Epoch:20	Loss:1.141	translation_Loss:0.926	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.215                                                   	MRR:23.38	Hits@10:41.07	Best:23.41
2024-12-29 04:07:49,670: Snapshot:2	Epoch:21	Loss:1.141	translation_Loss:0.928	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:23.39	Hits@10:41.1	Best:23.41
2024-12-29 04:07:57,573: Snapshot:2	Epoch:22	Loss:1.117	translation_Loss:0.906	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.212                                                   	MRR:23.42	Hits@10:41.16	Best:23.42
2024-12-29 04:08:05,066: Snapshot:2	Epoch:23	Loss:1.115	translation_Loss:0.903	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:23.46	Hits@10:41.19	Best:23.46
2024-12-29 04:08:13,056: Snapshot:2	Epoch:24	Loss:1.116	translation_Loss:0.902	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:23.5	Hits@10:41.34	Best:23.5
2024-12-29 04:08:20,877: Snapshot:2	Epoch:25	Loss:1.11	translation_Loss:0.897	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:23.5	Hits@10:41.25	Best:23.5
2024-12-29 04:08:28,338: Snapshot:2	Epoch:26	Loss:1.105	translation_Loss:0.89	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:23.62	Hits@10:41.24	Best:23.62
2024-12-29 04:08:36,154: Snapshot:2	Epoch:27	Loss:1.103	translation_Loss:0.89	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:23.52	Hits@10:41.19	Best:23.62
2024-12-29 04:08:43,549: Snapshot:2	Epoch:28	Loss:1.092	translation_Loss:0.878	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:23.6	Hits@10:41.28	Best:23.62
2024-12-29 04:08:51,289: Snapshot:2	Epoch:29	Loss:1.097	translation_Loss:0.883	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.214                                                   	MRR:23.47	Hits@10:41.27	Best:23.62
2024-12-29 04:08:58,688: Snapshot:2	Epoch:30	Loss:1.087	translation_Loss:0.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:23.42	Hits@10:41.28	Best:23.62
2024-12-29 04:09:06,641: Early Stopping! Snapshot: 2 Epoch: 31 Best Results: 23.62
2024-12-29 04:09:06,641: Start to training tokens! Snapshot: 2 Epoch: 31 Loss:1.08 MRR:23.47 Best Results: 23.62
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-29 04:09:06,642: Snapshot:2	Epoch:31	Loss:1.08	translation_Loss:0.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:23.47	Hits@10:41.21	Best:23.62
2024-12-29 04:09:13,935: Snapshot:2	Epoch:32	Loss:32.471	translation_Loss:15.612	multi_layer_Loss:16.859	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.47	Hits@10:41.21	Best:23.62
2024-12-29 04:09:21,600: End of token training: 2 Epoch: 33 Loss:15.855 MRR:23.47 Best Results: 23.62
2024-12-29 04:09:21,600: Snapshot:2	Epoch:33	Loss:15.855	translation_Loss:15.616	multi_layer_Loss:0.24	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.47	Hits@10:41.21	Best:23.62
2024-12-29 04:09:21,849: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-29 04:09:28,674: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3392 | 0.2173 | 0.3958 | 0.4711 |  0.5731 |
|     1      | 0.2527 | 0.1539 | 0.2875 | 0.3538 |  0.4455 |
|     2      | 0.237  | 0.142  | 0.272  | 0.3328 |  0.4205 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 04:09:55,493: Snapshot:3	Epoch:0	Loss:11.016	translation_Loss:10.285	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.731                                                   	MRR:14.56	Hits@10:25.56	Best:14.56
2024-12-29 04:10:03,180: Snapshot:3	Epoch:1	Loss:3.646	translation_Loss:3.164	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.483                                                   	MRR:17.88	Hits@10:32.47	Best:17.88
2024-12-29 04:10:10,881: Snapshot:3	Epoch:2	Loss:2.108	translation_Loss:1.788	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.321                                                   	MRR:19.86	Hits@10:35.81	Best:19.86
2024-12-29 04:10:18,548: Snapshot:3	Epoch:3	Loss:1.633	translation_Loss:1.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.269                                                   	MRR:20.55	Hits@10:37.4	Best:20.55
2024-12-29 04:10:26,663: Snapshot:3	Epoch:4	Loss:1.437	translation_Loss:1.187	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.249                                                   	MRR:21.22	Hits@10:38.34	Best:21.22
2024-12-29 04:10:34,266: Snapshot:3	Epoch:5	Loss:1.315	translation_Loss:1.077	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.239                                                   	MRR:21.48	Hits@10:38.79	Best:21.48
2024-12-29 04:10:42,253: Snapshot:3	Epoch:6	Loss:1.24	translation_Loss:1.005	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.235                                                   	MRR:21.57	Hits@10:38.97	Best:21.57
2024-12-29 04:10:49,935: Snapshot:3	Epoch:7	Loss:1.194	translation_Loss:0.963	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.232                                                   	MRR:21.78	Hits@10:39.52	Best:21.78
2024-12-29 04:10:57,917: Snapshot:3	Epoch:8	Loss:1.151	translation_Loss:0.92	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.231                                                   	MRR:21.93	Hits@10:39.71	Best:21.93
2024-12-29 04:11:05,641: Snapshot:3	Epoch:9	Loss:1.12	translation_Loss:0.889	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.231                                                   	MRR:22.05	Hits@10:39.87	Best:22.05
2024-12-29 04:11:13,698: Snapshot:3	Epoch:10	Loss:1.099	translation_Loss:0.869	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.23                                                   	MRR:22.03	Hits@10:40.08	Best:22.05
2024-12-29 04:11:21,413: Snapshot:3	Epoch:11	Loss:1.079	translation_Loss:0.852	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.227                                                   	MRR:22.13	Hits@10:40.06	Best:22.13
2024-12-29 04:11:29,480: Snapshot:3	Epoch:12	Loss:1.065	translation_Loss:0.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.228                                                   	MRR:22.3	Hits@10:40.16	Best:22.3
2024-12-29 04:11:37,083: Snapshot:3	Epoch:13	Loss:1.043	translation_Loss:0.814	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.228                                                   	MRR:22.26	Hits@10:40.24	Best:22.3
2024-12-29 04:11:45,019: Snapshot:3	Epoch:14	Loss:1.034	translation_Loss:0.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.226                                                   	MRR:22.28	Hits@10:40.37	Best:22.3
2024-12-29 04:11:52,610: Snapshot:3	Epoch:15	Loss:1.023	translation_Loss:0.795	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.229                                                   	MRR:22.44	Hits@10:40.54	Best:22.44
2024-12-29 04:12:00,616: Snapshot:3	Epoch:16	Loss:1.016	translation_Loss:0.789	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.227                                                   	MRR:22.54	Hits@10:40.61	Best:22.54
2024-12-29 04:12:08,550: Snapshot:3	Epoch:17	Loss:1.01	translation_Loss:0.783	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.227                                                   	MRR:22.4	Hits@10:40.51	Best:22.54
2024-12-29 04:12:16,197: Snapshot:3	Epoch:18	Loss:0.999	translation_Loss:0.771	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.229                                                   	MRR:22.56	Hits@10:40.65	Best:22.56
2024-12-29 04:12:23,860: Snapshot:3	Epoch:19	Loss:0.994	translation_Loss:0.766	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.227                                                   	MRR:22.43	Hits@10:40.75	Best:22.56
2024-12-29 04:12:31,936: Snapshot:3	Epoch:20	Loss:0.988	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.23                                                   	MRR:22.41	Hits@10:40.38	Best:22.56
2024-12-29 04:12:39,902: Snapshot:3	Epoch:21	Loss:0.977	translation_Loss:0.748	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.229                                                   	MRR:22.52	Hits@10:40.45	Best:22.56
2024-12-29 04:12:47,503: Snapshot:3	Epoch:22	Loss:0.985	translation_Loss:0.756	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.228                                                   	MRR:22.55	Hits@10:40.48	Best:22.56
2024-12-29 04:12:55,449: Early Stopping! Snapshot: 3 Epoch: 23 Best Results: 22.56
2024-12-29 04:12:55,449: Start to training tokens! Snapshot: 3 Epoch: 23 Loss:0.976 MRR:22.42 Best Results: 22.56
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-29 04:12:55,450: Snapshot:3	Epoch:23	Loss:0.976	translation_Loss:0.748	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.228                                                   	MRR:22.42	Hits@10:40.64	Best:22.56
2024-12-29 04:13:02,910: Snapshot:3	Epoch:24	Loss:30.709	translation_Loss:14.122	multi_layer_Loss:16.588	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.42	Hits@10:40.64	Best:22.56
2024-12-29 04:13:10,784: End of token training: 3 Epoch: 25 Loss:14.389 MRR:22.42 Best Results: 22.56
2024-12-29 04:13:10,785: Snapshot:3	Epoch:25	Loss:14.389	translation_Loss:14.124	multi_layer_Loss:0.265	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.42	Hits@10:40.64	Best:22.56
2024-12-29 04:13:11,036: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-29 04:13:21,236: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3388 | 0.2169 | 0.3964 | 0.4684 |  0.5729 |
|     1      | 0.252  | 0.152  | 0.2877 | 0.356  |  0.4456 |
|     2      | 0.2386 | 0.1437 | 0.2741 | 0.3344 |  0.4213 |
|     3      | 0.2257 | 0.1332 | 0.2613 | 0.3202 |  0.3996 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 04:13:41,281: Snapshot:4	Epoch:0	Loss:8.243	translation_Loss:7.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.516                                                   	MRR:16.62	Hits@10:31.46	Best:16.62
2024-12-29 04:13:46,919: Snapshot:4	Epoch:1	Loss:2.712	translation_Loss:2.291	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.42                                                   	MRR:21.88	Hits@10:40.32	Best:21.88
2024-12-29 04:13:52,481: Snapshot:4	Epoch:2	Loss:1.209	translation_Loss:0.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.224                                                   	MRR:24.02	Hits@10:42.6	Best:24.02
2024-12-29 04:13:58,529: Snapshot:4	Epoch:3	Loss:0.801	translation_Loss:0.655	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.146                                                   	MRR:25.0	Hits@10:44.39	Best:25.0
2024-12-29 04:14:04,083: Snapshot:4	Epoch:4	Loss:0.642	translation_Loss:0.522	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.119                                                   	MRR:25.57	Hits@10:45.16	Best:25.57
2024-12-29 04:14:09,699: Snapshot:4	Epoch:5	Loss:0.57	translation_Loss:0.462	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.108                                                   	MRR:25.92	Hits@10:45.61	Best:25.92
2024-12-29 04:14:15,646: Snapshot:4	Epoch:6	Loss:0.524	translation_Loss:0.42	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.105                                                   	MRR:26.18	Hits@10:46.13	Best:26.18
2024-12-29 04:14:21,193: Snapshot:4	Epoch:7	Loss:0.489	translation_Loss:0.389	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:26.26	Hits@10:46.3	Best:26.26
2024-12-29 04:14:26,797: Snapshot:4	Epoch:8	Loss:0.471	translation_Loss:0.372	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:26.48	Hits@10:46.39	Best:26.48
2024-12-29 04:14:32,663: Snapshot:4	Epoch:9	Loss:0.456	translation_Loss:0.357	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:26.7	Hits@10:46.93	Best:26.7
2024-12-29 04:14:38,152: Snapshot:4	Epoch:10	Loss:0.438	translation_Loss:0.338	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:26.68	Hits@10:46.75	Best:26.7
2024-12-29 04:14:43,698: Snapshot:4	Epoch:11	Loss:0.432	translation_Loss:0.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:26.74	Hits@10:46.86	Best:26.74
2024-12-29 04:14:49,773: Snapshot:4	Epoch:12	Loss:0.42	translation_Loss:0.323	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:26.85	Hits@10:46.92	Best:26.85
2024-12-29 04:14:55,354: Snapshot:4	Epoch:13	Loss:0.417	translation_Loss:0.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:26.95	Hits@10:47.18	Best:26.95
2024-12-29 04:15:00,877: Snapshot:4	Epoch:14	Loss:0.409	translation_Loss:0.311	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:26.77	Hits@10:47.34	Best:26.95
2024-12-29 04:15:06,809: Snapshot:4	Epoch:15	Loss:0.405	translation_Loss:0.308	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:26.91	Hits@10:47.34	Best:26.95
2024-12-29 04:15:12,309: Snapshot:4	Epoch:16	Loss:0.397	translation_Loss:0.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:26.86	Hits@10:47.43	Best:26.95
2024-12-29 04:15:17,913: Snapshot:4	Epoch:17	Loss:0.394	translation_Loss:0.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:26.84	Hits@10:47.37	Best:26.95
2024-12-29 04:15:23,757: Early Stopping! Snapshot: 4 Epoch: 18 Best Results: 26.95
2024-12-29 04:15:23,758: Start to training tokens! Snapshot: 4 Epoch: 18 Loss:0.392 MRR:26.85 Best Results: 26.95
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([8, 200]), requires_grad: True
 - torch.Size([8, 200]), requires_grad: True
2024-12-29 04:15:23,758: Snapshot:4	Epoch:18	Loss:0.392	translation_Loss:0.294	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:26.85	Hits@10:47.5	Best:26.95
2024-12-29 04:15:29,175: Snapshot:4	Epoch:19	Loss:24.187	translation_Loss:7.745	multi_layer_Loss:16.442	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.85	Hits@10:47.5	Best:26.95
2024-12-29 04:15:34,941: End of token training: 4 Epoch: 20 Loss:8.579 MRR:26.85 Best Results: 26.95
2024-12-29 04:15:34,941: Snapshot:4	Epoch:20	Loss:8.579	translation_Loss:7.738	multi_layer_Loss:0.841	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.85	Hits@10:47.5	Best:26.95
2024-12-29 04:15:35,193: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-29 04:15:47,800: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3354 | 0.2117 | 0.3956 | 0.4665 |  0.5705 |
|     1      | 0.2516 | 0.1513 | 0.288  | 0.3546 |  0.4455 |
|     2      | 0.2396 | 0.1439 | 0.2757 | 0.3362 |  0.4226 |
|     3      | 0.2288 | 0.1363 | 0.2644 | 0.323  |  0.4045 |
|     4      | 0.2712 | 0.1613 | 0.3239 | 0.3957 |  0.4797 |
+------------+--------+--------+--------+--------+---------+
2024-12-29 04:15:47,802: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3411 | 0.2201 | 0.3973 | 0.4704 |  0.5733 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3411 | 0.2199 | 0.3963 | 0.4705 |  0.5732 |
|     1      | 0.2536 | 0.1547 | 0.2893 | 0.354  |  0.4449 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3392 | 0.2173 | 0.3958 | 0.4711 |  0.5731 |
|     1      | 0.2527 | 0.1539 | 0.2875 | 0.3538 |  0.4455 |
|     2      | 0.237  | 0.142  | 0.272  | 0.3328 |  0.4205 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3388 | 0.2169 | 0.3964 | 0.4684 |  0.5729 |
|     1      | 0.252  | 0.152  | 0.2877 | 0.356  |  0.4456 |
|     2      | 0.2386 | 0.1437 | 0.2741 | 0.3344 |  0.4213 |
|     3      | 0.2257 | 0.1332 | 0.2613 | 0.3202 |  0.3996 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3354 | 0.2117 | 0.3956 | 0.4665 |  0.5705 |
|     1      | 0.2516 | 0.1513 | 0.288  | 0.3546 |  0.4455 |
|     2      | 0.2396 | 0.1439 | 0.2757 | 0.3362 |  0.4226 |
|     3      | 0.2288 | 0.1363 | 0.2644 | 0.323  |  0.4045 |
|     4      | 0.2712 | 0.1613 | 0.3239 | 0.3957 |  0.4797 |
+------------+--------+--------+--------+--------+---------+]
2024-12-29 04:15:47,802: Report Result:
+----------+-------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time       | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+-------------------+-----------+--------------+--------------+---------------+
|    0     | 83.88187837600708 |   0.341   |     0.22     |    0.397     |     0.573     |
|    1     | 165.3234462738037 |   0.288   |     0.18     |    0.331     |     0.495     |
|    2     | 275.9747836589813 |   0.268   |    0.165     |    0.308     |     0.467     |
|    3     | 218.8174934387207 |   0.257   |    0.156     |    0.296     |     0.449     |
|    4     | 130.9552285671234 |   0.259   |    0.157     |    0.301     |     0.455     |
+----------+-------------------+-----------+--------------+--------------+---------------+
2024-12-29 04:15:47,802: Sum_Training_Time:874.9528303146362
2024-12-29 04:15:47,802: Every_Training_Time:[83.88187837600708, 165.3234462738037, 275.9747836589813, 218.8174934387207, 130.9552285671234]
2024-12-29 04:15:47,802: Forward transfer: 0.047549999999999995 Backward transfer: -0.0005000000000000074
2024-12-29 04:16:23,822: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229041552/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=9, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 04:16:31,696: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-29 04:16:35,542: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.12	Best:9.49
2024-12-29 04:16:39,743: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.71	Best:14.08
2024-12-29 04:16:43,538: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.75	Best:19.63
2024-12-29 04:16:47,308: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.67	Hits@10:48.73	Best:24.67
2024-12-29 04:16:51,464: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.29	Hits@10:52.04	Best:28.29
2024-12-29 04:16:55,244: Snapshot:0	Epoch:6	Loss:2.524	translation_Loss:2.524	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.38	Hits@10:53.91	Best:30.38
2024-12-29 04:16:59,382: Snapshot:0	Epoch:7	Loss:1.793	translation_Loss:1.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.76	Hits@10:55.55	Best:31.76
2024-12-29 04:17:03,222: Snapshot:0	Epoch:8	Loss:1.299	translation_Loss:1.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:32.6	Hits@10:55.98	Best:32.6
2024-12-29 04:17:07,007: Snapshot:0	Epoch:9	Loss:0.968	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.13	Hits@10:56.55	Best:33.13
2024-12-29 04:17:11,183: Snapshot:0	Epoch:10	Loss:0.758	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.5	Hits@10:57.08	Best:33.5
2024-12-29 04:17:15,028: Snapshot:0	Epoch:11	Loss:0.607	translation_Loss:0.607	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.49	Hits@10:57.12	Best:33.5
2024-12-29 04:17:18,880: Snapshot:0	Epoch:12	Loss:0.499	translation_Loss:0.499	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.69	Hits@10:57.19	Best:33.69
2024-12-29 04:17:23,055: Snapshot:0	Epoch:13	Loss:0.422	translation_Loss:0.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.64	Hits@10:57.01	Best:33.69
2024-12-29 04:17:26,845: Snapshot:0	Epoch:14	Loss:0.373	translation_Loss:0.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.65	Hits@10:56.98	Best:33.69
2024-12-29 04:17:30,645: Snapshot:0	Epoch:15	Loss:0.331	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.64	Hits@10:56.9	Best:33.69
2024-12-29 04:17:34,877: Snapshot:0	Epoch:16	Loss:0.303	translation_Loss:0.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.69	Hits@10:56.69	Best:33.69
2024-12-29 04:17:38,678: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 33.69
2024-12-29 04:17:38,678: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.278 MRR:33.69 Best Results: 33.69
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([9, 200]), requires_grad: True
 - torch.Size([9, 200]), requires_grad: True
2024-12-29 04:17:38,679: Snapshot:0	Epoch:17	Loss:0.278	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.69	Hits@10:56.97	Best:33.69
2024-12-29 04:17:42,973: Snapshot:0	Epoch:18	Loss:26.656	translation_Loss:9.719	multi_layer_Loss:16.937	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:33.69	Hits@10:56.97	Best:33.69
2024-12-29 04:17:47,120: End of token training: 0 Epoch: 19 Loss:10.593 MRR:33.69 Best Results: 33.69
2024-12-29 04:17:47,121: Snapshot:0	Epoch:19	Loss:10.593	translation_Loss:9.712	multi_layer_Loss:0.88	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:33.69	Hits@10:56.97	Best:33.69
2024-12-29 04:17:47,364: => loading checkpoint './checkpoint/ENTITY/0model_best.tar'
2024-12-29 04:17:48,724: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3412 | 0.2206 | 0.397  | 0.4712 |  0.5727 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 04:18:13,902: Snapshot:1	Epoch:0	Loss:13.369	translation_Loss:12.88	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.489                                                   	MRR:14.9	Hits@10:25.66	Best:14.9
2024-12-29 04:18:20,549: Snapshot:1	Epoch:1	Loss:5.506	translation_Loss:5.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.287                                                   	MRR:20.63	Hits@10:36.74	Best:20.63
2024-12-29 04:18:27,145: Snapshot:1	Epoch:2	Loss:2.954	translation_Loss:2.755	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:23.16	Hits@10:41.19	Best:23.16
2024-12-29 04:18:33,767: Snapshot:1	Epoch:3	Loss:2.099	translation_Loss:1.937	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.162                                                   	MRR:23.98	Hits@10:42.53	Best:23.98
2024-12-29 04:18:40,365: Snapshot:1	Epoch:4	Loss:1.724	translation_Loss:1.581	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.143                                                   	MRR:24.4	Hits@10:43.16	Best:24.4
2024-12-29 04:18:47,378: Snapshot:1	Epoch:5	Loss:1.51	translation_Loss:1.376	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.134                                                   	MRR:24.74	Hits@10:43.75	Best:24.74
2024-12-29 04:18:53,939: Snapshot:1	Epoch:6	Loss:1.393	translation_Loss:1.264	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.129                                                   	MRR:24.93	Hits@10:43.9	Best:24.93
2024-12-29 04:19:00,896: Snapshot:1	Epoch:7	Loss:1.311	translation_Loss:1.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:24.9	Hits@10:44.07	Best:24.93
2024-12-29 04:19:07,441: Snapshot:1	Epoch:8	Loss:1.246	translation_Loss:1.12	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:24.89	Hits@10:44.15	Best:24.93
2024-12-29 04:19:14,511: Snapshot:1	Epoch:9	Loss:1.215	translation_Loss:1.09	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.125                                                   	MRR:25.05	Hits@10:44.37	Best:25.05
2024-12-29 04:19:21,258: Snapshot:1	Epoch:10	Loss:1.169	translation_Loss:1.045	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.124                                                   	MRR:25.14	Hits@10:44.35	Best:25.14
2024-12-29 04:19:28,268: Snapshot:1	Epoch:11	Loss:1.143	translation_Loss:1.019	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.124                                                   	MRR:25.13	Hits@10:44.66	Best:25.14
2024-12-29 04:19:34,807: Snapshot:1	Epoch:12	Loss:1.126	translation_Loss:1.001	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.125                                                   	MRR:25.07	Hits@10:44.52	Best:25.14
2024-12-29 04:19:41,690: Snapshot:1	Epoch:13	Loss:1.102	translation_Loss:0.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.123                                                   	MRR:25.11	Hits@10:44.28	Best:25.14
2024-12-29 04:19:48,266: Snapshot:1	Epoch:14	Loss:1.084	translation_Loss:0.96	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.124                                                   	MRR:25.18	Hits@10:44.47	Best:25.18
2024-12-29 04:19:55,203: Snapshot:1	Epoch:15	Loss:1.07	translation_Loss:0.943	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:25.2	Hits@10:44.47	Best:25.2
2024-12-29 04:20:02,100: Snapshot:1	Epoch:16	Loss:1.049	translation_Loss:0.926	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.122                                                   	MRR:25.14	Hits@10:44.43	Best:25.2
2024-12-29 04:20:08,675: Snapshot:1	Epoch:17	Loss:1.045	translation_Loss:0.923	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.122                                                   	MRR:25.2	Hits@10:44.6	Best:25.2
2024-12-29 04:20:15,643: Snapshot:1	Epoch:18	Loss:1.029	translation_Loss:0.904	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.125                                                   	MRR:25.12	Hits@10:44.47	Best:25.2
2024-12-29 04:20:22,231: Snapshot:1	Epoch:19	Loss:1.029	translation_Loss:0.905	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.123                                                   	MRR:25.13	Hits@10:44.46	Best:25.2
2024-12-29 04:20:29,210: Snapshot:1	Epoch:20	Loss:1.022	translation_Loss:0.898	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.124                                                   	MRR:25.21	Hits@10:44.55	Best:25.21
2024-12-29 04:20:35,745: Snapshot:1	Epoch:21	Loss:1.013	translation_Loss:0.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.125                                                   	MRR:25.16	Hits@10:44.62	Best:25.21
2024-12-29 04:20:42,754: Snapshot:1	Epoch:22	Loss:0.991	translation_Loss:0.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.124                                                   	MRR:25.3	Hits@10:44.45	Best:25.3
2024-12-29 04:20:49,326: Snapshot:1	Epoch:23	Loss:0.994	translation_Loss:0.872	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.122                                                   	MRR:25.37	Hits@10:44.46	Best:25.37
2024-12-29 04:20:56,255: Snapshot:1	Epoch:24	Loss:0.981	translation_Loss:0.858	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.122                                                   	MRR:25.25	Hits@10:44.47	Best:25.37
2024-12-29 04:21:02,820: Snapshot:1	Epoch:25	Loss:0.971	translation_Loss:0.848	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.123                                                   	MRR:25.25	Hits@10:44.8	Best:25.37
2024-12-29 04:21:09,706: Snapshot:1	Epoch:26	Loss:0.974	translation_Loss:0.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.123                                                   	MRR:25.24	Hits@10:44.71	Best:25.37
2024-12-29 04:21:16,470: Snapshot:1	Epoch:27	Loss:0.965	translation_Loss:0.842	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.123                                                   	MRR:25.15	Hits@10:44.66	Best:25.37
2024-12-29 04:21:23,408: Early Stopping! Snapshot: 1 Epoch: 28 Best Results: 25.37
2024-12-29 04:21:23,408: Start to training tokens! Snapshot: 1 Epoch: 28 Loss:0.967 MRR:25.19 Best Results: 25.37
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([9, 200]), requires_grad: True
 - torch.Size([9, 200]), requires_grad: True
2024-12-29 04:21:23,409: Snapshot:1	Epoch:28	Loss:0.967	translation_Loss:0.845	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.122                                                   	MRR:25.19	Hits@10:44.51	Best:25.37
2024-12-29 04:21:30,367: Snapshot:1	Epoch:29	Loss:33.881	translation_Loss:15.742	multi_layer_Loss:18.139	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.19	Hits@10:44.51	Best:25.37
2024-12-29 04:21:36,945: End of token training: 1 Epoch: 30 Loss:16.034 MRR:25.19 Best Results: 25.37
2024-12-29 04:21:36,945: Snapshot:1	Epoch:30	Loss:16.034	translation_Loss:15.771	multi_layer_Loss:0.264	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.19	Hits@10:44.51	Best:25.37
2024-12-29 04:21:37,233: => loading checkpoint './checkpoint/ENTITY/1model_best.tar'
2024-12-29 04:21:41,130: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3414 | 0.2204 | 0.3978 | 0.4707 |  0.5724 |
|     1      | 0.2544 | 0.1553 | 0.289  | 0.3571 |  0.446  |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 04:22:07,783: Snapshot:2	Epoch:0	Loss:12.034	translation_Loss:11.38	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.654                                                   	MRR:14.55	Hits@10:24.6	Best:14.55
2024-12-29 04:22:15,281: Snapshot:2	Epoch:1	Loss:4.403	translation_Loss:4.002	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.401                                                   	MRR:18.13	Hits@10:32.16	Best:18.13
2024-12-29 04:22:22,800: Snapshot:2	Epoch:2	Loss:2.53	translation_Loss:2.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.288                                                   	MRR:20.36	Hits@10:36.04	Best:20.36
2024-12-29 04:22:30,223: Snapshot:2	Epoch:3	Loss:1.943	translation_Loss:1.697	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.247                                                   	MRR:21.46	Hits@10:37.86	Best:21.46
2024-12-29 04:22:37,993: Snapshot:2	Epoch:4	Loss:1.671	translation_Loss:1.444	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.227                                                   	MRR:22.04	Hits@10:38.81	Best:22.04
2024-12-29 04:22:45,480: Snapshot:2	Epoch:5	Loss:1.53	translation_Loss:1.315	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.215                                                   	MRR:22.3	Hits@10:39.46	Best:22.3
2024-12-29 04:22:53,306: Snapshot:2	Epoch:6	Loss:1.438	translation_Loss:1.228	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.21                                                   	MRR:22.55	Hits@10:39.76	Best:22.55
2024-12-29 04:23:01,078: Snapshot:2	Epoch:7	Loss:1.366	translation_Loss:1.163	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:22.76	Hits@10:40.05	Best:22.76
2024-12-29 04:23:08,492: Snapshot:2	Epoch:8	Loss:1.322	translation_Loss:1.121	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.201                                                   	MRR:22.89	Hits@10:40.33	Best:22.89
2024-12-29 04:23:16,409: Snapshot:2	Epoch:9	Loss:1.288	translation_Loss:1.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:22.91	Hits@10:40.47	Best:22.91
2024-12-29 04:23:23,824: Snapshot:2	Epoch:10	Loss:1.26	translation_Loss:1.061	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:22.97	Hits@10:40.46	Best:22.97
2024-12-29 04:23:31,590: Snapshot:2	Epoch:11	Loss:1.231	translation_Loss:1.034	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:23.06	Hits@10:40.59	Best:23.06
2024-12-29 04:23:38,983: Snapshot:2	Epoch:12	Loss:1.208	translation_Loss:1.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:23.17	Hits@10:40.72	Best:23.17
2024-12-29 04:23:46,793: Snapshot:2	Epoch:13	Loss:1.195	translation_Loss:0.997	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:23.31	Hits@10:40.92	Best:23.31
2024-12-29 04:23:54,170: Snapshot:2	Epoch:14	Loss:1.173	translation_Loss:0.977	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:23.14	Hits@10:40.97	Best:23.31
2024-12-29 04:24:01,969: Snapshot:2	Epoch:15	Loss:1.166	translation_Loss:0.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:23.35	Hits@10:41.0	Best:23.35
2024-12-29 04:24:09,692: Snapshot:2	Epoch:16	Loss:1.147	translation_Loss:0.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:23.25	Hits@10:40.94	Best:23.35
2024-12-29 04:24:17,130: Snapshot:2	Epoch:17	Loss:1.141	translation_Loss:0.945	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:23.42	Hits@10:41.2	Best:23.42
2024-12-29 04:24:24,855: Snapshot:2	Epoch:18	Loss:1.133	translation_Loss:0.938	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:23.42	Hits@10:41.27	Best:23.42
2024-12-29 04:24:32,237: Snapshot:2	Epoch:19	Loss:1.131	translation_Loss:0.935	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:23.39	Hits@10:41.12	Best:23.42
2024-12-29 04:24:39,980: Snapshot:2	Epoch:20	Loss:1.112	translation_Loss:0.917	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:23.52	Hits@10:40.97	Best:23.52
2024-12-29 04:24:47,431: Snapshot:2	Epoch:21	Loss:1.105	translation_Loss:0.91	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:23.41	Hits@10:41.12	Best:23.52
2024-12-29 04:24:55,173: Snapshot:2	Epoch:22	Loss:1.095	translation_Loss:0.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:23.54	Hits@10:41.31	Best:23.54
2024-12-29 04:25:02,665: Snapshot:2	Epoch:23	Loss:1.098	translation_Loss:0.905	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:23.52	Hits@10:41.3	Best:23.54
2024-12-29 04:25:10,487: Snapshot:2	Epoch:24	Loss:1.099	translation_Loss:0.904	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:23.59	Hits@10:41.24	Best:23.59
2024-12-29 04:25:18,318: Snapshot:2	Epoch:25	Loss:1.085	translation_Loss:0.89	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:23.65	Hits@10:41.33	Best:23.65
2024-12-29 04:25:25,728: Snapshot:2	Epoch:26	Loss:1.085	translation_Loss:0.891	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:23.64	Hits@10:41.59	Best:23.65
2024-12-29 04:25:33,582: Snapshot:2	Epoch:27	Loss:1.074	translation_Loss:0.881	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:23.46	Hits@10:41.25	Best:23.65
2024-12-29 04:25:40,932: Snapshot:2	Epoch:28	Loss:1.07	translation_Loss:0.876	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:23.5	Hits@10:41.29	Best:23.65
2024-12-29 04:25:48,672: Snapshot:2	Epoch:29	Loss:1.069	translation_Loss:0.875	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:23.55	Hits@10:41.31	Best:23.65
2024-12-29 04:25:56,053: Early Stopping! Snapshot: 2 Epoch: 30 Best Results: 23.65
2024-12-29 04:25:56,053: Start to training tokens! Snapshot: 2 Epoch: 30 Loss:1.058 MRR:23.48 Best Results: 23.65
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([9, 200]), requires_grad: True
 - torch.Size([9, 200]), requires_grad: True
2024-12-29 04:25:56,054: Snapshot:2	Epoch:30	Loss:1.058	translation_Loss:0.864	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:23.48	Hits@10:41.28	Best:23.65
2024-12-29 04:26:03,655: Snapshot:2	Epoch:31	Loss:32.782	translation_Loss:15.606	multi_layer_Loss:17.176	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.48	Hits@10:41.28	Best:23.65
2024-12-29 04:26:10,893: End of token training: 2 Epoch: 32 Loss:15.888 MRR:23.48 Best Results: 23.65
2024-12-29 04:26:10,893: Snapshot:2	Epoch:32	Loss:15.888	translation_Loss:15.639	multi_layer_Loss:0.249	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.48	Hits@10:41.28	Best:23.65
2024-12-29 04:26:11,193: => loading checkpoint './checkpoint/ENTITY/2model_best.tar'
2024-12-29 04:26:18,148: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3404 | 0.2198 | 0.3956 | 0.4703 |  0.571  |
|     1      | 0.2546 | 0.1557 | 0.2877 | 0.3557 |  0.448  |
|     2      | 0.237  | 0.1425 | 0.2723 | 0.3326 |  0.4176 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 04:26:44,852: Snapshot:3	Epoch:0	Loss:11.018	translation_Loss:10.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.725                                                   	MRR:14.53	Hits@10:25.59	Best:14.53
2024-12-29 04:26:52,533: Snapshot:3	Epoch:1	Loss:3.626	translation_Loss:3.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.464                                                   	MRR:18.01	Hits@10:32.34	Best:18.01
2024-12-29 04:27:00,128: Snapshot:3	Epoch:2	Loss:2.103	translation_Loss:1.789	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.314                                                   	MRR:19.95	Hits@10:35.8	Best:19.95
2024-12-29 04:27:08,124: Snapshot:3	Epoch:3	Loss:1.618	translation_Loss:1.355	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.263                                                   	MRR:20.79	Hits@10:37.44	Best:20.79
2024-12-29 04:27:15,742: Snapshot:3	Epoch:4	Loss:1.417	translation_Loss:1.174	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.243                                                   	MRR:21.34	Hits@10:38.39	Best:21.34
2024-12-29 04:27:23,795: Snapshot:3	Epoch:5	Loss:1.305	translation_Loss:1.072	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.233                                                   	MRR:21.61	Hits@10:38.94	Best:21.61
2024-12-29 04:27:31,794: Snapshot:3	Epoch:6	Loss:1.225	translation_Loss:0.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.227                                                   	MRR:21.79	Hits@10:39.3	Best:21.79
2024-12-29 04:27:39,405: Snapshot:3	Epoch:7	Loss:1.183	translation_Loss:0.958	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.224                                                   	MRR:21.96	Hits@10:39.38	Best:21.96
2024-12-29 04:27:47,335: Snapshot:3	Epoch:8	Loss:1.135	translation_Loss:0.91	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.224                                                   	MRR:22.19	Hits@10:39.64	Best:22.19
2024-12-29 04:27:54,877: Snapshot:3	Epoch:9	Loss:1.106	translation_Loss:0.885	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.222                                                   	MRR:22.15	Hits@10:39.94	Best:22.19
2024-12-29 04:28:02,857: Snapshot:3	Epoch:10	Loss:1.092	translation_Loss:0.868	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.223                                                   	MRR:22.3	Hits@10:40.04	Best:22.3
2024-12-29 04:28:10,456: Snapshot:3	Epoch:11	Loss:1.069	translation_Loss:0.848	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:22.29	Hits@10:40.17	Best:22.3
2024-12-29 04:28:18,489: Snapshot:3	Epoch:12	Loss:1.047	translation_Loss:0.827	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:22.32	Hits@10:40.06	Best:22.32
2024-12-29 04:28:26,217: Snapshot:3	Epoch:13	Loss:1.028	translation_Loss:0.809	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:22.43	Hits@10:40.45	Best:22.43
2024-12-29 04:28:34,245: Snapshot:3	Epoch:14	Loss:1.02	translation_Loss:0.8	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:22.37	Hits@10:40.35	Best:22.43
2024-12-29 04:28:41,761: Snapshot:3	Epoch:15	Loss:1.015	translation_Loss:0.794	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:22.36	Hits@10:40.26	Best:22.43
2024-12-29 04:28:49,701: Snapshot:3	Epoch:16	Loss:1.0	translation_Loss:0.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.219                                                   	MRR:22.54	Hits@10:40.48	Best:22.54
2024-12-29 04:28:57,244: Snapshot:3	Epoch:17	Loss:1.0	translation_Loss:0.779	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:22.42	Hits@10:40.32	Best:22.54
2024-12-29 04:29:05,114: Snapshot:3	Epoch:18	Loss:0.981	translation_Loss:0.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.219                                                   	MRR:22.46	Hits@10:40.48	Best:22.54
2024-12-29 04:29:12,678: Snapshot:3	Epoch:19	Loss:0.979	translation_Loss:0.761	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.219                                                   	MRR:22.5	Hits@10:40.65	Best:22.54
2024-12-29 04:29:20,682: Snapshot:3	Epoch:20	Loss:0.981	translation_Loss:0.761	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:22.65	Hits@10:40.54	Best:22.65
2024-12-29 04:29:28,213: Snapshot:3	Epoch:21	Loss:0.966	translation_Loss:0.745	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:22.54	Hits@10:40.44	Best:22.65
2024-12-29 04:29:36,154: Snapshot:3	Epoch:22	Loss:0.957	translation_Loss:0.739	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:22.62	Hits@10:40.57	Best:22.65
2024-12-29 04:29:43,698: Snapshot:3	Epoch:23	Loss:0.957	translation_Loss:0.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.217                                                   	MRR:22.65	Hits@10:40.85	Best:22.65
2024-12-29 04:29:51,749: Snapshot:3	Epoch:24	Loss:0.945	translation_Loss:0.727	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:22.7	Hits@10:40.73	Best:22.7
2024-12-29 04:29:59,290: Snapshot:3	Epoch:25	Loss:0.946	translation_Loss:0.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.217                                                   	MRR:22.69	Hits@10:40.66	Best:22.7
2024-12-29 04:30:07,403: Snapshot:3	Epoch:26	Loss:0.939	translation_Loss:0.721	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.219                                                   	MRR:22.69	Hits@10:40.66	Best:22.7
2024-12-29 04:30:15,415: Snapshot:3	Epoch:27	Loss:0.934	translation_Loss:0.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:22.62	Hits@10:40.54	Best:22.7
2024-12-29 04:30:22,987: Snapshot:3	Epoch:28	Loss:0.933	translation_Loss:0.716	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.217                                                   	MRR:22.57	Hits@10:40.52	Best:22.7
2024-12-29 04:30:30,923: Early Stopping! Snapshot: 3 Epoch: 29 Best Results: 22.7
2024-12-29 04:30:30,923: Start to training tokens! Snapshot: 3 Epoch: 29 Loss:0.926 MRR:22.66 Best Results: 22.7
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([9, 200]), requires_grad: True
 - torch.Size([9, 200]), requires_grad: True
2024-12-29 04:30:30,923: Snapshot:3	Epoch:29	Loss:0.926	translation_Loss:0.706	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:22.66	Hits@10:40.82	Best:22.7
2024-12-29 04:30:38,420: Snapshot:3	Epoch:30	Loss:31.194	translation_Loss:14.138	multi_layer_Loss:17.056	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.66	Hits@10:40.82	Best:22.7
2024-12-29 04:30:46,268: End of token training: 3 Epoch: 31 Loss:14.409 MRR:22.66 Best Results: 22.7
2024-12-29 04:30:46,269: Snapshot:3	Epoch:31	Loss:14.409	translation_Loss:14.135	multi_layer_Loss:0.274	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.66	Hits@10:40.82	Best:22.7
2024-12-29 04:30:46,545: => loading checkpoint './checkpoint/ENTITY/3model_best.tar'
2024-12-29 04:30:56,430: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3397 | 0.2186 | 0.3941 | 0.4709 |  0.5729 |
|     1      | 0.2543 | 0.1549 | 0.2891 | 0.3559 |  0.4481 |
|     2      | 0.2388 | 0.1443 | 0.2737 | 0.3344 |  0.4188 |
|     3      | 0.2278 | 0.1352 | 0.2633 | 0.3238 |  0.4044 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-29 04:31:16,604: Snapshot:4	Epoch:0	Loss:8.249	translation_Loss:7.735	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.514                                                   	MRR:16.64	Hits@10:31.19	Best:16.64
2024-12-29 04:31:22,565: Snapshot:4	Epoch:1	Loss:2.713	translation_Loss:2.313	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.4                                                   	MRR:21.91	Hits@10:39.91	Best:21.91
2024-12-29 04:31:28,220: Snapshot:4	Epoch:2	Loss:1.224	translation_Loss:1.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.212                                                   	MRR:24.29	Hits@10:42.84	Best:24.29
2024-12-29 04:31:33,821: Snapshot:4	Epoch:3	Loss:0.807	translation_Loss:0.667	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.14                                                   	MRR:25.22	Hits@10:44.7	Best:25.22
2024-12-29 04:31:39,684: Snapshot:4	Epoch:4	Loss:0.647	translation_Loss:0.533	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.114                                                   	MRR:25.82	Hits@10:45.53	Best:25.82
2024-12-29 04:31:45,167: Snapshot:4	Epoch:5	Loss:0.57	translation_Loss:0.467	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.103                                                   	MRR:25.91	Hits@10:45.96	Best:25.91
2024-12-29 04:31:50,662: Snapshot:4	Epoch:6	Loss:0.53	translation_Loss:0.43	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:26.23	Hits@10:46.36	Best:26.23
2024-12-29 04:31:56,693: Snapshot:4	Epoch:7	Loss:0.49	translation_Loss:0.393	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:26.25	Hits@10:46.69	Best:26.25
2024-12-29 04:32:02,268: Snapshot:4	Epoch:8	Loss:0.466	translation_Loss:0.371	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:26.4	Hits@10:46.87	Best:26.4
2024-12-29 04:32:07,805: Snapshot:4	Epoch:9	Loss:0.454	translation_Loss:0.36	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.65	Hits@10:46.89	Best:26.65
2024-12-29 04:32:13,658: Snapshot:4	Epoch:10	Loss:0.444	translation_Loss:0.349	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:26.64	Hits@10:46.99	Best:26.65
2024-12-29 04:32:19,219: Snapshot:4	Epoch:11	Loss:0.431	translation_Loss:0.338	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:26.74	Hits@10:47.15	Best:26.74
2024-12-29 04:32:24,774: Snapshot:4	Epoch:12	Loss:0.421	translation_Loss:0.328	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.79	Hits@10:47.49	Best:26.79
2024-12-29 04:32:30,635: Snapshot:4	Epoch:13	Loss:0.42	translation_Loss:0.326	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.87	Hits@10:47.58	Best:26.87
2024-12-29 04:32:36,238: Snapshot:4	Epoch:14	Loss:0.412	translation_Loss:0.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:26.83	Hits@10:47.67	Best:26.87
2024-12-29 04:32:41,685: Snapshot:4	Epoch:15	Loss:0.411	translation_Loss:0.316	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:26.85	Hits@10:47.52	Best:26.87
2024-12-29 04:32:47,569: Snapshot:4	Epoch:16	Loss:0.4	translation_Loss:0.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:26.94	Hits@10:47.68	Best:26.94
2024-12-29 04:32:53,173: Snapshot:4	Epoch:17	Loss:0.4	translation_Loss:0.304	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:27.01	Hits@10:47.92	Best:27.01
2024-12-29 04:32:59,055: Snapshot:4	Epoch:18	Loss:0.398	translation_Loss:0.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:26.97	Hits@10:47.82	Best:27.01
2024-12-29 04:33:04,556: Snapshot:4	Epoch:19	Loss:0.392	translation_Loss:0.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:27.1	Hits@10:47.81	Best:27.1
2024-12-29 04:33:10,106: Snapshot:4	Epoch:20	Loss:0.39	translation_Loss:0.294	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.096                                                   	MRR:27.12	Hits@10:47.85	Best:27.12
2024-12-29 04:33:16,017: Snapshot:4	Epoch:21	Loss:0.382	translation_Loss:0.285	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:27.11	Hits@10:48.15	Best:27.12
2024-12-29 04:33:21,614: Snapshot:4	Epoch:22	Loss:0.384	translation_Loss:0.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:27.23	Hits@10:48.16	Best:27.23
2024-12-29 04:33:27,147: Snapshot:4	Epoch:23	Loss:0.381	translation_Loss:0.286	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:27.13	Hits@10:48.06	Best:27.23
2024-12-29 04:33:32,621: Snapshot:4	Epoch:24	Loss:0.377	translation_Loss:0.28	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:27.2	Hits@10:48.27	Best:27.23
2024-12-29 04:33:38,429: Snapshot:4	Epoch:25	Loss:0.377	translation_Loss:0.281	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.096                                                   	MRR:27.09	Hits@10:47.96	Best:27.23
2024-12-29 04:33:43,877: Snapshot:4	Epoch:26	Loss:0.375	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.096                                                   	MRR:27.14	Hits@10:47.88	Best:27.23
2024-12-29 04:33:49,355: Snapshot:4	Epoch:27	Loss:0.376	translation_Loss:0.279	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:27.29	Hits@10:48.29	Best:27.29
2024-12-29 04:33:55,246: Snapshot:4	Epoch:28	Loss:0.371	translation_Loss:0.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.096                                                   	MRR:27.3	Hits@10:48.29	Best:27.3
2024-12-29 04:34:00,792: Snapshot:4	Epoch:29	Loss:0.377	translation_Loss:0.279	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:27.25	Hits@10:48.22	Best:27.3
2024-12-29 04:34:06,691: Snapshot:4	Epoch:30	Loss:0.371	translation_Loss:0.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:27.21	Hits@10:48.16	Best:27.3
2024-12-29 04:34:12,228: Snapshot:4	Epoch:31	Loss:0.372	translation_Loss:0.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:27.33	Hits@10:48.21	Best:27.33
2024-12-29 04:34:17,867: Snapshot:4	Epoch:32	Loss:0.368	translation_Loss:0.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:27.34	Hits@10:48.21	Best:27.34
2024-12-29 04:34:23,815: Snapshot:4	Epoch:33	Loss:0.365	translation_Loss:0.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.097                                                   	MRR:27.06	Hits@10:48.05	Best:27.34
2024-12-29 04:34:29,255: Snapshot:4	Epoch:34	Loss:0.367	translation_Loss:0.269	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:27.27	Hits@10:48.57	Best:27.34
2024-12-29 04:34:34,726: Snapshot:4	Epoch:35	Loss:0.364	translation_Loss:0.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:27.03	Hits@10:48.16	Best:27.34
2024-12-29 04:34:40,556: Snapshot:4	Epoch:36	Loss:0.361	translation_Loss:0.264	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.098                                                   	MRR:26.9	Hits@10:48.38	Best:27.34
2024-12-29 04:34:46,014: Early Stopping! Snapshot: 4 Epoch: 37 Best Results: 27.34
2024-12-29 04:34:46,014: Start to training tokens! Snapshot: 4 Epoch: 37 Loss:0.363 MRR:26.71 Best Results: 27.34
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([9, 200]), requires_grad: True
 - torch.Size([9, 200]), requires_grad: True
2024-12-29 04:34:46,014: Snapshot:4	Epoch:37	Loss:0.363	translation_Loss:0.264	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.099                                                   	MRR:26.71	Hits@10:48.25	Best:27.34
2024-12-29 04:34:51,365: Snapshot:4	Epoch:38	Loss:24.5	translation_Loss:7.736	multi_layer_Loss:16.763	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.71	Hits@10:48.25	Best:27.34
2024-12-29 04:34:57,050: End of token training: 4 Epoch: 39 Loss:8.628 MRR:26.71 Best Results: 27.34
2024-12-29 04:34:57,050: Snapshot:4	Epoch:39	Loss:8.628	translation_Loss:7.72	multi_layer_Loss:0.908	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.71	Hits@10:48.25	Best:27.34
2024-12-29 04:34:57,303: => loading checkpoint './checkpoint/ENTITY/4model_best.tar'
2024-12-29 04:35:10,149: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3379 | 0.2158 | 0.3934 | 0.4682 |  0.5705 |
|     1      | 0.2547 | 0.1553 | 0.2893 | 0.357  |  0.4482 |
|     2      | 0.2391 | 0.144  | 0.2749 | 0.336  |  0.4195 |
|     3      | 0.2289 | 0.1357 | 0.2643 | 0.3261 |  0.4066 |
|     4      | 0.275  | 0.1618 | 0.332  | 0.4023 |  0.4924 |
+------------+--------+--------+--------+--------+---------+
2024-12-29 04:35:10,151: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3412 | 0.2206 | 0.397  | 0.4712 |  0.5727 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3414 | 0.2204 | 0.3978 | 0.4707 |  0.5724 |
|     1      | 0.2544 | 0.1553 | 0.289  | 0.3571 |  0.446  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3404 | 0.2198 | 0.3956 | 0.4703 |  0.571  |
|     1      | 0.2546 | 0.1557 | 0.2877 | 0.3557 |  0.448  |
|     2      | 0.237  | 0.1425 | 0.2723 | 0.3326 |  0.4176 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3397 | 0.2186 | 0.3941 | 0.4709 |  0.5729 |
|     1      | 0.2543 | 0.1549 | 0.2891 | 0.3559 |  0.4481 |
|     2      | 0.2388 | 0.1443 | 0.2737 | 0.3344 |  0.4188 |
|     3      | 0.2278 | 0.1352 | 0.2633 | 0.3238 |  0.4044 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.3379 | 0.2158 | 0.3934 | 0.4682 |  0.5705 |
|     1      | 0.2547 | 0.1553 | 0.2893 | 0.357  |  0.4482 |
|     2      | 0.2391 | 0.144  | 0.2749 | 0.336  |  0.4195 |
|     3      | 0.2289 | 0.1357 | 0.2643 | 0.3261 |  0.4066 |
|     4      | 0.275  | 0.1618 | 0.332  | 0.4023 |  0.4924 |
+------------+--------+--------+--------+--------+---------+]
2024-12-29 04:35:10,152: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 83.29824781417847  |   0.341   |    0.221     |    0.397     |     0.573     |
|    1     | 225.87523674964905 |   0.288   |    0.181     |    0.332     |     0.495     |
|    2     | 266.8661835193634  |   0.269   |    0.166     |    0.308     |     0.466     |
|    3     |  264.552463054657  |   0.258   |    0.158     |    0.296     |      0.45     |
|    4     | 237.64190816879272 |   0.261   |    0.158     |    0.302     |     0.457     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-29 04:35:10,152: Sum_Training_Time:1078.2340393066406
2024-12-29 04:35:10,152: Every_Training_Time:[83.29824781417847, 225.87523674964905, 266.8661835193634, 264.552463054657, 237.64190816879272]
2024-12-29 04:35:10,152: Forward transfer: 0.047675 Backward transfer: 4.9999999999987554e-05
2024-12-29 04:35:45,717: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/ENTITY/', dataset='ENTITY', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241229043515/ENTITY', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/ENTITY', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=10, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-29 04:35:53,526: Snapshot:0	Epoch:0	Loss:13.186	translation_Loss:13.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.93	Hits@10:10.95	Best:4.93
2024-12-29 04:35:57,322: Snapshot:0	Epoch:1	Loss:10.97	translation_Loss:10.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.49	Hits@10:23.11	Best:9.49
2024-12-29 04:36:01,512: Snapshot:0	Epoch:2	Loss:9.036	translation_Loss:9.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.08	Hits@10:35.71	Best:14.08
2024-12-29 04:36:05,302: Snapshot:0	Epoch:3	Loss:7.014	translation_Loss:7.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.63	Hits@10:43.75	Best:19.63
2024-12-29 04:36:09,076: Snapshot:0	Epoch:4	Loss:5.095	translation_Loss:5.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.65	Hits@10:48.72	Best:24.65
2024-12-29 04:36:13,226: Snapshot:0	Epoch:5	Loss:3.61	translation_Loss:3.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.3	Hits@10:52.05	Best:28.3
2024-12-29 04:36:17,189: Snapshot:0	Epoch:6	Loss:2.525	translation_Loss:2.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.36	Hits@10:53.87	Best:30.36
