2024-12-27 16:47:08,157: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227164630/RELATIONrelation_0.01_512_1000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.01_512_1000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.01_512_1000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 16:47:24,361: Snapshot:0	Epoch:0	Loss:103.039	translation_Loss:103.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.64	Hits@10:39.29	Best:20.64
2024-12-27 16:47:36,196: Snapshot:0	Epoch:1	Loss:38.069	translation_Loss:38.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.22	Hits@10:43.65	Best:24.22
2024-12-27 16:47:47,911: Snapshot:0	Epoch:2	Loss:16.477	translation_Loss:16.477	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.27	Hits@10:44.66	Best:25.27
2024-12-27 16:47:59,633: Snapshot:0	Epoch:3	Loss:9.914	translation_Loss:9.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.47	Hits@10:44.76	Best:25.47
2024-12-27 16:48:11,465: Snapshot:0	Epoch:4	Loss:7.512	translation_Loss:7.512	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.36	Hits@10:44.27	Best:25.47
2024-12-27 16:48:23,159: Snapshot:0	Epoch:5	Loss:6.382	translation_Loss:6.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.33	Hits@10:44.62	Best:25.47
2024-12-27 16:48:34,806: Snapshot:0	Epoch:6	Loss:5.726	translation_Loss:5.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.12	Hits@10:44.04	Best:25.47
2024-12-27 16:48:47,015: Snapshot:0	Epoch:7	Loss:5.251	translation_Loss:5.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.92	Hits@10:43.63	Best:25.47
2024-12-27 16:48:58,690: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 25.47
2024-12-27 16:48:58,690: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:4.923 MRR:24.99 Best Results: 25.47
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 16:48:58,691: Snapshot:0	Epoch:8	Loss:4.923	translation_Loss:4.923	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.99	Hits@10:43.56	Best:25.47
2024-12-27 16:49:11,179: Snapshot:0	Epoch:9	Loss:95.009	translation_Loss:94.973	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.99	Hits@10:43.56	Best:25.47
2024-12-27 16:49:23,142: End of token training: 0 Epoch: 10 Loss:94.975 MRR:24.99 Best Results: 25.47
2024-12-27 16:49:23,143: Snapshot:0	Epoch:10	Loss:94.975	translation_Loss:94.975	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.99	Hits@10:43.56	Best:25.47
2024-12-27 16:49:23,498: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_1000/0model_best.tar'
2024-12-27 16:49:28,878: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2579 | 0.154  | 0.3141 | 0.3817 |  0.4515 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:50:06,152: Snapshot:1	Epoch:0	Loss:71.055	translation_Loss:55.135	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:15.92                                                   	MRR:12.69	Hits@10:25.48	Best:12.69
2024-12-27 16:50:17,474: Snapshot:1	Epoch:1	Loss:52.979	translation_Loss:38.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.799                                                   	MRR:12.67	Hits@10:25.52	Best:12.69
2024-12-27 16:50:28,701: Snapshot:1	Epoch:2	Loss:50.525	translation_Loss:36.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.347                                                   	MRR:12.96	Hits@10:25.46	Best:12.96
2024-12-27 16:50:39,935: Snapshot:1	Epoch:3	Loss:49.497	translation_Loss:35.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.223                                                   	MRR:12.71	Hits@10:25.61	Best:12.96
2024-12-27 16:50:51,726: Snapshot:1	Epoch:4	Loss:48.816	translation_Loss:34.701	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.114                                                   	MRR:12.87	Hits@10:25.76	Best:12.96
2024-12-27 16:51:02,918: Snapshot:1	Epoch:5	Loss:48.37	translation_Loss:34.315	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.055                                                   	MRR:12.91	Hits@10:25.58	Best:12.96
2024-12-27 16:51:14,251: Snapshot:1	Epoch:6	Loss:48.14	translation_Loss:34.121	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.019                                                   	MRR:13.09	Hits@10:25.7	Best:13.09
2024-12-27 16:51:25,561: Snapshot:1	Epoch:7	Loss:47.83	translation_Loss:33.794	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.036                                                   	MRR:13.09	Hits@10:25.6	Best:13.09
2024-12-27 16:51:36,764: Snapshot:1	Epoch:8	Loss:47.723	translation_Loss:33.753	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:13.97                                                   	MRR:12.92	Hits@10:25.92	Best:13.09
2024-12-27 16:51:48,082: Snapshot:1	Epoch:9	Loss:47.68	translation_Loss:33.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.072                                                   	MRR:13.12	Hits@10:25.96	Best:13.12
2024-12-27 16:51:59,407: Snapshot:1	Epoch:10	Loss:47.617	translation_Loss:33.551	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.066                                                   	MRR:12.94	Hits@10:25.86	Best:13.12
2024-12-27 16:52:10,828: Snapshot:1	Epoch:11	Loss:47.347	translation_Loss:33.357	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:13.991                                                   	MRR:13.19	Hits@10:25.96	Best:13.19
2024-12-27 16:52:22,132: Snapshot:1	Epoch:12	Loss:47.253	translation_Loss:33.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.0                                                   	MRR:13.21	Hits@10:25.9	Best:13.21
2024-12-27 16:52:33,378: Snapshot:1	Epoch:13	Loss:47.223	translation_Loss:33.213	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.011                                                   	MRR:13.18	Hits@10:26.26	Best:13.21
2024-12-27 16:52:44,667: Snapshot:1	Epoch:14	Loss:47.276	translation_Loss:33.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.07                                                   	MRR:13.14	Hits@10:26.1	Best:13.21
2024-12-27 16:52:56,087: Snapshot:1	Epoch:15	Loss:47.156	translation_Loss:33.119	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.037                                                   	MRR:13.09	Hits@10:26.04	Best:13.21
2024-12-27 16:53:07,271: Snapshot:1	Epoch:16	Loss:47.023	translation_Loss:33.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:13.968                                                   	MRR:13.0	Hits@10:25.94	Best:13.21
2024-12-27 16:53:19,204: Early Stopping! Snapshot: 1 Epoch: 17 Best Results: 13.21
2024-12-27 16:53:19,204: Start to training tokens! Snapshot: 1 Epoch: 17 Loss:46.957 MRR:13.18 Best Results: 13.21
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 16:53:19,205: Snapshot:1	Epoch:17	Loss:46.957	translation_Loss:32.975	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:13.982                                                   	MRR:13.18	Hits@10:26.08	Best:13.21
2024-12-27 16:53:30,137: Snapshot:1	Epoch:18	Loss:127.269	translation_Loss:127.232	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.18	Hits@10:26.08	Best:13.21
2024-12-27 16:53:41,014: End of token training: 1 Epoch: 19 Loss:127.294 MRR:13.18 Best Results: 13.21
2024-12-27 16:53:41,014: Snapshot:1	Epoch:19	Loss:127.294	translation_Loss:127.294	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:13.18	Hits@10:26.08	Best:13.21
2024-12-27 16:53:41,316: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_1000/1model_best.tar'
2024-12-27 16:53:51,475: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2486 | 0.1437 | 0.3061 | 0.3725 |  0.4429 |
|     1      | 0.1316 | 0.0668 | 0.1527 | 0.2002 |  0.2579 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:54:19,958: Snapshot:2	Epoch:0	Loss:44.523	translation_Loss:30.656	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:13.867                                                   	MRR:15.64	Hits@10:25.72	Best:15.64
2024-12-27 16:54:28,332: Snapshot:2	Epoch:1	Loss:37.271	translation_Loss:23.169	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.101                                                   	MRR:15.56	Hits@10:25.59	Best:15.64
2024-12-27 16:54:36,656: Snapshot:2	Epoch:2	Loss:36.949	translation_Loss:22.792	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.157                                                   	MRR:15.56	Hits@10:25.53	Best:15.64
2024-12-27 16:54:44,969: Snapshot:2	Epoch:3	Loss:36.719	translation_Loss:22.566	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.153                                                   	MRR:15.53	Hits@10:25.25	Best:15.64
2024-12-27 16:54:53,253: Snapshot:2	Epoch:4	Loss:36.727	translation_Loss:22.495	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.232                                                   	MRR:15.43	Hits@10:25.43	Best:15.64
2024-12-27 16:55:01,658: Early Stopping! Snapshot: 2 Epoch: 5 Best Results: 15.64
2024-12-27 16:55:01,658: Start to training tokens! Snapshot: 2 Epoch: 5 Loss:36.686 MRR:15.55 Best Results: 15.64
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 16:55:01,658: Snapshot:2	Epoch:5	Loss:36.686	translation_Loss:22.443	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.243                                                   	MRR:15.55	Hits@10:25.55	Best:15.64
2024-12-27 16:55:09,825: Snapshot:2	Epoch:6	Loss:105.627	translation_Loss:105.589	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.55	Hits@10:25.55	Best:15.64
2024-12-27 16:55:17,916: End of token training: 2 Epoch: 7 Loss:105.65 MRR:15.55 Best Results: 15.64
2024-12-27 16:55:17,917: Snapshot:2	Epoch:7	Loss:105.65	translation_Loss:105.65	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:15.55	Hits@10:25.55	Best:15.64
2024-12-27 16:55:18,289: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_1000/2model_best.tar'
2024-12-27 16:55:31,914: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2233 | 0.1205 | 0.2799 | 0.344  |  0.4137 |
|     1      | 0.1305 | 0.0647 | 0.1524 | 0.2012 |  0.2588 |
|     2      | 0.154  | 0.1021 | 0.1629 | 0.1988 |  0.2555 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:55:47,605: Snapshot:3	Epoch:0	Loss:21.953	translation_Loss:17.28	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.673                                                   	MRR:22.49	Hits@10:33.79	Best:22.49
2024-12-27 16:55:51,447: Snapshot:3	Epoch:1	Loss:15.173	translation_Loss:10.594	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.579                                                   	MRR:22.2	Hits@10:33.87	Best:22.49
2024-12-27 16:55:55,284: Snapshot:3	Epoch:2	Loss:14.657	translation_Loss:10.091	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.566                                                   	MRR:22.23	Hits@10:33.84	Best:22.49
2024-12-27 16:55:59,092: Snapshot:3	Epoch:3	Loss:14.429	translation_Loss:9.879	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.55                                                   	MRR:22.29	Hits@10:33.93	Best:22.49
2024-12-27 16:56:02,920: Snapshot:3	Epoch:4	Loss:14.338	translation_Loss:9.822	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.516                                                   	MRR:22.45	Hits@10:34.15	Best:22.49
2024-12-27 16:56:06,726: Early Stopping! Snapshot: 3 Epoch: 5 Best Results: 22.49
2024-12-27 16:56:06,727: Start to training tokens! Snapshot: 3 Epoch: 5 Loss:14.301 MRR:22.28 Best Results: 22.49
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 16:56:06,727: Snapshot:3	Epoch:5	Loss:14.301	translation_Loss:9.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.539                                                   	MRR:22.28	Hits@10:33.89	Best:22.49
2024-12-27 16:56:10,440: Snapshot:3	Epoch:6	Loss:39.414	translation_Loss:39.378	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.28	Hits@10:33.89	Best:22.49
2024-12-27 16:56:14,178: End of token training: 3 Epoch: 7 Loss:39.417 MRR:22.28 Best Results: 22.49
2024-12-27 16:56:14,178: Snapshot:3	Epoch:7	Loss:39.417	translation_Loss:39.417	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.28	Hits@10:33.89	Best:22.49
2024-12-27 16:56:14,549: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_1000/3model_best.tar'
2024-12-27 16:56:30,651: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2221 | 0.1194 | 0.2795 | 0.3429 |  0.4117 |
|     1      | 0.1311 | 0.0653 | 0.1526 | 0.201  |  0.2598 |
|     2      | 0.1519 | 0.0973 | 0.1628 | 0.1998 |  0.2594 |
|     3      | 0.2219 | 0.1553 | 0.2509 | 0.2907 |  0.3394 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 16:56:43,585: Snapshot:4	Epoch:0	Loss:17.34	translation_Loss:12.884	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.455                                                   	MRR:18.64	Hits@10:32.99	Best:18.64
2024-12-27 16:56:46,385: Snapshot:4	Epoch:1	Loss:12.287	translation_Loss:7.353	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.934                                                   	MRR:18.7	Hits@10:33.57	Best:18.7
2024-12-27 16:56:49,145: Snapshot:4	Epoch:2	Loss:11.944	translation_Loss:6.925	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.019                                                   	MRR:19.23	Hits@10:34.07	Best:19.23
2024-12-27 16:56:51,964: Snapshot:4	Epoch:3	Loss:11.831	translation_Loss:6.823	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.009                                                   	MRR:19.27	Hits@10:34.27	Best:19.27
2024-12-27 16:56:54,777: Snapshot:4	Epoch:4	Loss:11.764	translation_Loss:6.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.003                                                   	MRR:18.9	Hits@10:34.13	Best:19.27
2024-12-27 16:56:57,487: Snapshot:4	Epoch:5	Loss:11.77	translation_Loss:6.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.044                                                   	MRR:18.97	Hits@10:34.06	Best:19.27
2024-12-27 16:57:00,186: Snapshot:4	Epoch:6	Loss:11.716	translation_Loss:6.684	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.031                                                   	MRR:19.15	Hits@10:34.28	Best:19.27
2024-12-27 16:57:02,969: Snapshot:4	Epoch:7	Loss:11.699	translation_Loss:6.664	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.035                                                   	MRR:19.23	Hits@10:34.45	Best:19.27
2024-12-27 16:57:05,702: Early Stopping! Snapshot: 4 Epoch: 8 Best Results: 19.27
2024-12-27 16:57:05,703: Start to training tokens! Snapshot: 4 Epoch: 8 Loss:11.672 MRR:19.06 Best Results: 19.27
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 16:57:05,703: Snapshot:4	Epoch:8	Loss:11.672	translation_Loss:6.629	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.044                                                   	MRR:19.06	Hits@10:34.51	Best:19.27
2024-12-27 16:57:08,325: Snapshot:4	Epoch:9	Loss:25.941	translation_Loss:25.904	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.06	Hits@10:34.51	Best:19.27
2024-12-27 16:57:10,951: End of token training: 4 Epoch: 10 Loss:25.962 MRR:19.06 Best Results: 19.27
2024-12-27 16:57:10,951: Snapshot:4	Epoch:10	Loss:25.962	translation_Loss:25.962	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.06	Hits@10:34.51	Best:19.27
2024-12-27 16:57:11,237: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_1000/4model_best.tar'
2024-12-27 16:57:28,211: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2203 | 0.1189 | 0.2754 | 0.3385 |  0.4083 |
|     1      | 0.1312 | 0.0652 | 0.1525 | 0.2006 |  0.2607 |
|     2      | 0.143  | 0.0893 | 0.1506 | 0.1894 |  0.2509 |
|     3      | 0.2232 | 0.1557 | 0.2523 | 0.2897 |  0.3401 |
|     4      | 0.1907 | 0.1119 | 0.2101 | 0.2622 |  0.3401 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 16:57:28,213: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2579 | 0.154  | 0.3141 | 0.3817 |  0.4515 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2486 | 0.1437 | 0.3061 | 0.3725 |  0.4429 |
|     1      | 0.1316 | 0.0668 | 0.1527 | 0.2002 |  0.2579 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2233 | 0.1205 | 0.2799 | 0.344  |  0.4137 |
|     1      | 0.1305 | 0.0647 | 0.1524 | 0.2012 |  0.2588 |
|     2      | 0.154  | 0.1021 | 0.1629 | 0.1988 |  0.2555 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2221 | 0.1194 | 0.2795 | 0.3429 |  0.4117 |
|     1      | 0.1311 | 0.0653 | 0.1526 | 0.201  |  0.2598 |
|     2      | 0.1519 | 0.0973 | 0.1628 | 0.1998 |  0.2594 |
|     3      | 0.2219 | 0.1553 | 0.2509 | 0.2907 |  0.3394 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2203 | 0.1189 | 0.2754 | 0.3385 |  0.4083 |
|     1      | 0.1312 | 0.0652 | 0.1525 | 0.2006 |  0.2607 |
|     2      | 0.143  | 0.0893 | 0.1506 | 0.1894 |  0.2509 |
|     3      | 0.2232 | 0.1557 | 0.2523 | 0.2897 |  0.3401 |
|     4      | 0.1907 | 0.1119 | 0.2101 | 0.2622 |  0.3401 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 16:57:28,214: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 134.98474025726318 |   0.258   |    0.154     |    0.314     |     0.452     |
|    1     | 247.8094871044159  |   0.192   |    0.106     |    0.232     |     0.353     |
|    2     |  82.8247127532959  |   0.172   |    0.096     |    0.204     |     0.317     |
|    3     | 40.63750338554382  |   0.176   |    0.101     |    0.209     |      0.32     |
|    4     | 38.74053120613098  |   0.175   |    0.099     |    0.205     |     0.319     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 16:57:28,214: Sum_Training_Time:544.9969747066498
2024-12-27 16:57:28,214: Every_Training_Time:[134.98474025726318, 247.8094871044159, 82.8247127532959, 40.63750338554382, 38.74053120613098]
2024-12-27 16:57:28,214: Forward transfer: 0.0125 Backward transfer: -0.011924999999999998
2024-12-27 16:58:05,643: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227165732/RELATIONrelation_0.01_512_5000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.01_512_5000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.01_512_5000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 16:58:21,769: Snapshot:0	Epoch:0	Loss:103.048	translation_Loss:103.048	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.73	Hits@10:39.16	Best:20.73
2024-12-27 16:58:33,406: Snapshot:0	Epoch:1	Loss:38.108	translation_Loss:38.108	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.2	Hits@10:43.69	Best:24.2
2024-12-27 16:58:45,049: Snapshot:0	Epoch:2	Loss:16.499	translation_Loss:16.499	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.23	Hits@10:44.56	Best:25.23
2024-12-27 16:58:56,817: Snapshot:0	Epoch:3	Loss:9.944	translation_Loss:9.944	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.51	Hits@10:44.7	Best:25.51
2024-12-27 16:59:08,396: Snapshot:0	Epoch:4	Loss:7.499	translation_Loss:7.499	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.39	Hits@10:44.43	Best:25.51
2024-12-27 16:59:20,100: Snapshot:0	Epoch:5	Loss:6.399	translation_Loss:6.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.33	Hits@10:44.52	Best:25.51
2024-12-27 16:59:31,867: Snapshot:0	Epoch:6	Loss:5.725	translation_Loss:5.725	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.21	Hits@10:43.99	Best:25.51
2024-12-27 16:59:44,047: Snapshot:0	Epoch:7	Loss:5.23	translation_Loss:5.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.68	Hits@10:43.56	Best:25.51
2024-12-27 16:59:55,696: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 25.51
2024-12-27 16:59:55,696: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:4.905 MRR:24.74 Best Results: 25.51
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 16:59:55,696: Snapshot:0	Epoch:8	Loss:4.905	translation_Loss:4.905	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.74	Hits@10:43.43	Best:25.51
2024-12-27 17:00:08,207: Snapshot:0	Epoch:9	Loss:95.132	translation_Loss:95.096	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.74	Hits@10:43.43	Best:25.51
2024-12-27 17:00:20,183: End of token training: 0 Epoch: 10 Loss:95.104 MRR:24.74 Best Results: 25.51
2024-12-27 17:00:20,183: Snapshot:0	Epoch:10	Loss:95.104	translation_Loss:95.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.74	Hits@10:43.43	Best:25.51
2024-12-27 17:00:20,535: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_5000/0model_best.tar'
2024-12-27 17:00:26,012: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2596 | 0.1555 | 0.3184 | 0.3837 |  0.4531 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:01:03,060: Snapshot:1	Epoch:0	Loss:72.131	translation_Loss:57.481	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.649                                                   	MRR:11.92	Hits@10:24.01	Best:11.92
2024-12-27 17:01:14,385: Snapshot:1	Epoch:1	Loss:53.374	translation_Loss:40.939	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.435                                                   	MRR:11.93	Hits@10:23.95	Best:11.93
2024-12-27 17:01:25,706: Snapshot:1	Epoch:2	Loss:51.243	translation_Loss:39.026	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.216                                                   	MRR:11.93	Hits@10:23.93	Best:11.93
2024-12-27 17:01:36,891: Snapshot:1	Epoch:3	Loss:50.494	translation_Loss:38.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.22                                                   	MRR:11.88	Hits@10:24.01	Best:11.93
2024-12-27 17:01:48,642: Snapshot:1	Epoch:4	Loss:49.914	translation_Loss:37.737	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.177                                                   	MRR:11.96	Hits@10:24.08	Best:11.96
2024-12-27 17:01:59,952: Snapshot:1	Epoch:5	Loss:49.542	translation_Loss:37.37	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.172                                                   	MRR:12.03	Hits@10:24.11	Best:12.03
2024-12-27 17:02:11,159: Snapshot:1	Epoch:6	Loss:49.326	translation_Loss:37.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.147                                                   	MRR:11.96	Hits@10:24.16	Best:12.03
2024-12-27 17:02:22,461: Snapshot:1	Epoch:7	Loss:49.008	translation_Loss:36.868	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.14                                                   	MRR:11.99	Hits@10:23.94	Best:12.03
2024-12-27 17:02:33,730: Snapshot:1	Epoch:8	Loss:48.973	translation_Loss:36.855	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.118                                                   	MRR:12.04	Hits@10:24.24	Best:12.04
2024-12-27 17:02:45,011: Snapshot:1	Epoch:9	Loss:48.869	translation_Loss:36.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.19                                                   	MRR:12.0	Hits@10:24.26	Best:12.04
2024-12-27 17:02:56,238: Snapshot:1	Epoch:10	Loss:48.781	translation_Loss:36.637	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.143                                                   	MRR:11.89	Hits@10:24.04	Best:12.04
2024-12-27 17:03:07,479: Snapshot:1	Epoch:11	Loss:48.577	translation_Loss:36.448	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.129                                                   	MRR:12.05	Hits@10:24.19	Best:12.05
2024-12-27 17:03:18,826: Snapshot:1	Epoch:12	Loss:48.431	translation_Loss:36.343	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.087                                                   	MRR:12.1	Hits@10:24.14	Best:12.1
2024-12-27 17:03:30,284: Snapshot:1	Epoch:13	Loss:48.409	translation_Loss:36.312	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.097                                                   	MRR:12.11	Hits@10:24.29	Best:12.11
2024-12-27 17:03:41,656: Snapshot:1	Epoch:14	Loss:48.435	translation_Loss:36.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.142                                                   	MRR:12.13	Hits@10:24.29	Best:12.13
2024-12-27 17:03:53,020: Snapshot:1	Epoch:15	Loss:48.39	translation_Loss:36.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.173                                                   	MRR:12.05	Hits@10:24.25	Best:12.13
2024-12-27 17:04:04,210: Snapshot:1	Epoch:16	Loss:48.274	translation_Loss:36.141	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.133                                                   	MRR:12.03	Hits@10:24.04	Best:12.13
2024-12-27 17:04:16,070: Snapshot:1	Epoch:17	Loss:48.175	translation_Loss:36.079	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.096                                                   	MRR:12.09	Hits@10:24.25	Best:12.13
2024-12-27 17:04:27,299: Snapshot:1	Epoch:18	Loss:48.15	translation_Loss:36.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.098                                                   	MRR:12.13	Hits@10:24.29	Best:12.13
2024-12-27 17:04:38,684: Early Stopping! Snapshot: 1 Epoch: 19 Best Results: 12.13
2024-12-27 17:04:38,685: Start to training tokens! Snapshot: 1 Epoch: 19 Loss:48.075 MRR:12.12 Best Results: 12.13
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:04:38,685: Snapshot:1	Epoch:19	Loss:48.075	translation_Loss:35.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.106                                                   	MRR:12.12	Hits@10:24.34	Best:12.13
2024-12-27 17:04:49,770: Snapshot:1	Epoch:20	Loss:129.594	translation_Loss:129.557	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.12	Hits@10:24.34	Best:12.13
2024-12-27 17:05:00,748: End of token training: 1 Epoch: 21 Loss:129.618 MRR:12.12 Best Results: 12.13
2024-12-27 17:05:00,748: Snapshot:1	Epoch:21	Loss:129.618	translation_Loss:129.618	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:12.12	Hits@10:24.34	Best:12.13
2024-12-27 17:05:01,123: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_5000/1model_best.tar'
2024-12-27 17:05:11,101: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2562 | 0.1518 | 0.3139 | 0.3811 |  0.4529 |
|     1      | 0.1231 | 0.0607 | 0.1425 | 0.1829 |  0.2439 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:05:40,288: Snapshot:2	Epoch:0	Loss:50.482	translation_Loss:37.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:13.271                                                   	MRR:12.69	Hits@10:20.48	Best:12.69
2024-12-27 17:05:48,715: Snapshot:2	Epoch:1	Loss:42.874	translation_Loss:30.459	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.415                                                   	MRR:12.75	Hits@10:20.43	Best:12.75
2024-12-27 17:05:57,013: Snapshot:2	Epoch:2	Loss:42.262	translation_Loss:29.88	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.383                                                   	MRR:12.73	Hits@10:20.35	Best:12.75
2024-12-27 17:06:05,404: Snapshot:2	Epoch:3	Loss:42.173	translation_Loss:29.8	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.373                                                   	MRR:12.84	Hits@10:20.29	Best:12.84
2024-12-27 17:06:13,866: Snapshot:2	Epoch:4	Loss:41.996	translation_Loss:29.614	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.382                                                   	MRR:12.74	Hits@10:20.37	Best:12.84
2024-12-27 17:06:22,226: Snapshot:2	Epoch:5	Loss:41.927	translation_Loss:29.537	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.39                                                   	MRR:12.73	Hits@10:20.24	Best:12.84
2024-12-27 17:06:30,708: Snapshot:2	Epoch:6	Loss:41.91	translation_Loss:29.485	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.425                                                   	MRR:12.7	Hits@10:20.4	Best:12.84
2024-12-27 17:06:39,172: Snapshot:2	Epoch:7	Loss:41.825	translation_Loss:29.451	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.374                                                   	MRR:12.87	Hits@10:20.32	Best:12.87
2024-12-27 17:06:47,555: Snapshot:2	Epoch:8	Loss:41.784	translation_Loss:29.424	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.36                                                   	MRR:12.69	Hits@10:20.48	Best:12.87
2024-12-27 17:06:55,915: Snapshot:2	Epoch:9	Loss:41.724	translation_Loss:29.363	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.361                                                   	MRR:12.7	Hits@10:20.23	Best:12.87
2024-12-27 17:07:04,246: Snapshot:2	Epoch:10	Loss:41.724	translation_Loss:29.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.393                                                   	MRR:12.7	Hits@10:20.43	Best:12.87
2024-12-27 17:07:12,653: Snapshot:2	Epoch:11	Loss:41.661	translation_Loss:29.301	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.36                                                   	MRR:12.88	Hits@10:20.31	Best:12.88
2024-12-27 17:07:21,128: Snapshot:2	Epoch:12	Loss:41.587	translation_Loss:29.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.349                                                   	MRR:12.67	Hits@10:20.3	Best:12.88
2024-12-27 17:07:29,611: Snapshot:2	Epoch:13	Loss:41.72	translation_Loss:29.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.389                                                   	MRR:12.85	Hits@10:20.46	Best:12.88
2024-12-27 17:07:37,918: Snapshot:2	Epoch:14	Loss:41.668	translation_Loss:29.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.371                                                   	MRR:12.75	Hits@10:20.29	Best:12.88
2024-12-27 17:07:46,268: Snapshot:2	Epoch:15	Loss:41.585	translation_Loss:29.225	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.36                                                   	MRR:12.8	Hits@10:20.48	Best:12.88
2024-12-27 17:07:54,588: Early Stopping! Snapshot: 2 Epoch: 16 Best Results: 12.88
2024-12-27 17:07:54,588: Start to training tokens! Snapshot: 2 Epoch: 16 Loss:41.632 MRR:12.82 Best Results: 12.88
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:07:54,589: Snapshot:2	Epoch:16	Loss:41.632	translation_Loss:29.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.359                                                   	MRR:12.82	Hits@10:20.32	Best:12.88
2024-12-27 17:08:02,675: Snapshot:2	Epoch:17	Loss:113.255	translation_Loss:113.217	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.82	Hits@10:20.32	Best:12.88
2024-12-27 17:08:10,775: End of token training: 2 Epoch: 18 Loss:113.187 MRR:12.82 Best Results: 12.88
2024-12-27 17:08:10,775: Snapshot:2	Epoch:18	Loss:113.187	translation_Loss:113.187	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:12.82	Hits@10:20.32	Best:12.88
2024-12-27 17:08:11,161: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_5000/2model_best.tar'
2024-12-27 17:08:24,435: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2374 | 0.1347 | 0.2936 | 0.3605 |  0.4316 |
|     1      | 0.1224 | 0.0599 | 0.1418 | 0.1831 |  0.2443 |
|     2      | 0.1276 | 0.0864 | 0.1336 | 0.1583 |  0.2018 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:08:40,474: Snapshot:3	Epoch:0	Loss:23.816	translation_Loss:19.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.752                                                   	MRR:20.31	Hits@10:31.45	Best:20.31
2024-12-27 17:08:44,409: Snapshot:3	Epoch:1	Loss:15.943	translation_Loss:12.508	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.435                                                   	MRR:20.82	Hits@10:31.03	Best:20.82
2024-12-27 17:08:48,317: Snapshot:3	Epoch:2	Loss:15.385	translation_Loss:11.977	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.408                                                   	MRR:20.37	Hits@10:31.01	Best:20.82
2024-12-27 17:08:52,194: Snapshot:3	Epoch:3	Loss:15.186	translation_Loss:11.791	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.395                                                   	MRR:21.07	Hits@10:31.35	Best:21.07
2024-12-27 17:08:56,086: Snapshot:3	Epoch:4	Loss:15.142	translation_Loss:11.729	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.413                                                   	MRR:20.67	Hits@10:31.19	Best:21.07
2024-12-27 17:08:59,935: Snapshot:3	Epoch:5	Loss:14.981	translation_Loss:11.579	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.402                                                   	MRR:20.63	Hits@10:31.29	Best:21.07
2024-12-27 17:09:03,772: Snapshot:3	Epoch:6	Loss:14.975	translation_Loss:11.56	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.414                                                   	MRR:20.63	Hits@10:31.25	Best:21.07
2024-12-27 17:09:07,650: Snapshot:3	Epoch:7	Loss:14.931	translation_Loss:11.512	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.419                                                   	MRR:20.69	Hits@10:31.47	Best:21.07
2024-12-27 17:09:11,529: Early Stopping! Snapshot: 3 Epoch: 8 Best Results: 21.07
2024-12-27 17:09:11,529: Start to training tokens! Snapshot: 3 Epoch: 8 Loss:14.897 MRR:20.87 Best Results: 21.07
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:09:11,529: Snapshot:3	Epoch:8	Loss:14.897	translation_Loss:11.49	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.406                                                   	MRR:20.87	Hits@10:31.29	Best:21.07
2024-12-27 17:09:15,284: Snapshot:3	Epoch:9	Loss:41.464	translation_Loss:41.429	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.87	Hits@10:31.29	Best:21.07
2024-12-27 17:09:18,996: End of token training: 3 Epoch: 10 Loss:41.391 MRR:20.87 Best Results: 21.07
2024-12-27 17:09:18,996: Snapshot:3	Epoch:10	Loss:41.391	translation_Loss:41.391	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.87	Hits@10:31.29	Best:21.07
2024-12-27 17:09:19,381: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_5000/3model_best.tar'
2024-12-27 17:09:34,910: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2348 | 0.1331 | 0.2894 | 0.3553 |  0.4277 |
|     1      | 0.1223 |  0.06  | 0.1417 | 0.1828 |  0.244  |
|     2      | 0.1303 | 0.0891 | 0.1361 | 0.1617 |  0.2051 |
|     3      | 0.2078 | 0.1481 | 0.2306 | 0.2639 |  0.3156 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:09:47,750: Snapshot:4	Epoch:0	Loss:20.473	translation_Loss:16.223	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.25                                                   	MRR:15.85	Hits@10:27.56	Best:15.85
2024-12-27 17:09:50,501: Snapshot:4	Epoch:1	Loss:15.159	translation_Loss:12.164	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.995                                                   	MRR:15.82	Hits@10:28.25	Best:15.85
2024-12-27 17:09:53,312: Snapshot:4	Epoch:2	Loss:14.888	translation_Loss:11.87	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.018                                                   	MRR:16.02	Hits@10:28.14	Best:16.02
2024-12-27 17:09:56,090: Snapshot:4	Epoch:3	Loss:14.799	translation_Loss:11.747	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.052                                                   	MRR:15.93	Hits@10:28.25	Best:16.02
2024-12-27 17:09:58,830: Snapshot:4	Epoch:4	Loss:14.754	translation_Loss:11.7	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.054                                                   	MRR:15.99	Hits@10:28.35	Best:16.02
2024-12-27 17:10:01,617: Snapshot:4	Epoch:5	Loss:14.676	translation_Loss:11.619	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.057                                                   	MRR:16.39	Hits@10:28.48	Best:16.39
2024-12-27 17:10:04,365: Snapshot:4	Epoch:6	Loss:14.668	translation_Loss:11.605	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.063                                                   	MRR:16.35	Hits@10:28.35	Best:16.39
2024-12-27 17:10:07,177: Snapshot:4	Epoch:7	Loss:14.615	translation_Loss:11.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.069                                                   	MRR:16.37	Hits@10:28.69	Best:16.39
2024-12-27 17:10:09,925: Snapshot:4	Epoch:8	Loss:14.622	translation_Loss:11.551	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.071                                                   	MRR:16.27	Hits@10:28.53	Best:16.39
2024-12-27 17:10:12,688: Snapshot:4	Epoch:9	Loss:14.59	translation_Loss:11.511	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.079                                                   	MRR:16.56	Hits@10:28.47	Best:16.56
2024-12-27 17:10:15,482: Snapshot:4	Epoch:10	Loss:14.586	translation_Loss:11.517	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.069                                                   	MRR:16.62	Hits@10:28.51	Best:16.62
2024-12-27 17:10:18,311: Snapshot:4	Epoch:11	Loss:14.517	translation_Loss:11.451	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.067                                                   	MRR:16.46	Hits@10:28.33	Best:16.62
2024-12-27 17:10:21,069: Snapshot:4	Epoch:12	Loss:14.514	translation_Loss:11.431	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.083                                                   	MRR:16.26	Hits@10:28.66	Best:16.62
2024-12-27 17:10:23,801: Snapshot:4	Epoch:13	Loss:14.512	translation_Loss:11.432	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.08                                                   	MRR:16.38	Hits@10:28.57	Best:16.62
2024-12-27 17:10:26,551: Snapshot:4	Epoch:14	Loss:14.486	translation_Loss:11.396	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.089                                                   	MRR:16.46	Hits@10:28.65	Best:16.62
2024-12-27 17:10:29,275: Early Stopping! Snapshot: 4 Epoch: 15 Best Results: 16.62
2024-12-27 17:10:29,275: Start to training tokens! Snapshot: 4 Epoch: 15 Loss:14.511 MRR:16.39 Best Results: 16.62
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:10:29,276: Snapshot:4	Epoch:15	Loss:14.511	translation_Loss:11.427	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.085                                                   	MRR:16.39	Hits@10:28.63	Best:16.62
2024-12-27 17:10:31,895: Snapshot:4	Epoch:16	Loss:29.649	translation_Loss:29.612	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.39	Hits@10:28.63	Best:16.62
2024-12-27 17:10:34,509: End of token training: 4 Epoch: 17 Loss:29.627 MRR:16.39 Best Results: 16.62
2024-12-27 17:10:34,510: Snapshot:4	Epoch:17	Loss:29.627	translation_Loss:29.627	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:16.39	Hits@10:28.63	Best:16.62
2024-12-27 17:10:34,895: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_5000/4model_best.tar'
2024-12-27 17:10:51,867: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2337 | 0.1318 | 0.2887 | 0.3549 |  0.4291 |
|     1      | 0.1221 | 0.0593 | 0.1417 | 0.1828 |  0.244  |
|     2      |  0.13  | 0.089  | 0.1358 | 0.1609 |  0.2044 |
|     3      | 0.2082 | 0.1477 | 0.231  | 0.2659 |  0.3168 |
|     4      | 0.1569 | 0.0947 | 0.1668 | 0.2122 |  0.2853 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 17:10:51,869: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2596 | 0.1555 | 0.3184 | 0.3837 |  0.4531 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2562 | 0.1518 | 0.3139 | 0.3811 |  0.4529 |
|     1      | 0.1231 | 0.0607 | 0.1425 | 0.1829 |  0.2439 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2374 | 0.1347 | 0.2936 | 0.3605 |  0.4316 |
|     1      | 0.1224 | 0.0599 | 0.1418 | 0.1831 |  0.2443 |
|     2      | 0.1276 | 0.0864 | 0.1336 | 0.1583 |  0.2018 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2348 | 0.1331 | 0.2894 | 0.3553 |  0.4277 |
|     1      | 0.1223 |  0.06  | 0.1417 | 0.1828 |  0.244  |
|     2      | 0.1303 | 0.0891 | 0.1361 | 0.1617 |  0.2051 |
|     3      | 0.2078 | 0.1481 | 0.2306 | 0.2639 |  0.3156 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2337 | 0.1318 | 0.2887 | 0.3549 |  0.4291 |
|     1      | 0.1221 | 0.0593 | 0.1417 | 0.1828 |  0.244  |
|     2      |  0.13  | 0.089  | 0.1358 | 0.1609 |  0.2044 |
|     3      | 0.2082 | 0.1477 | 0.231  | 0.2659 |  0.3168 |
|     4      | 0.1569 | 0.0947 | 0.1668 | 0.2122 |  0.2853 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 17:10:51,870: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 134.5389223098755  |    0.26   |    0.155     |    0.318     |     0.453     |
|    1     | 270.4095640182495  |   0.191   |    0.108     |    0.231     |     0.351     |
|    2     | 176.05768823623657 |   0.168   |    0.095     |    0.198     |     0.305     |
|    3     | 52.620774030685425 |   0.172   |    0.101     |     0.2      |     0.305     |
|    4     | 58.087788343429565 |    0.17   |     0.1      |    0.198     |     0.304     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 17:10:51,870: Sum_Training_Time:691.7147369384766
2024-12-27 17:10:51,870: Every_Training_Time:[134.5389223098755, 270.4095640182495, 176.05768823623657, 52.620774030685425, 58.087788343429565]
2024-12-27 17:10:51,870: Forward transfer: 0.0117 Backward transfer: -0.006025000000000003
2024-12-27 17:11:29,266: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227171055/RELATIONrelation_0.01_512_10000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.01_512_10000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.01_512_10000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 17:11:45,689: Snapshot:0	Epoch:0	Loss:103.043	translation_Loss:103.043	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.83	Hits@10:39.14	Best:20.83
2024-12-27 17:11:57,526: Snapshot:0	Epoch:1	Loss:38.087	translation_Loss:38.087	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.21	Hits@10:43.78	Best:24.21
2024-12-27 17:12:09,400: Snapshot:0	Epoch:2	Loss:16.482	translation_Loss:16.482	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.47	Hits@10:44.74	Best:25.47
2024-12-27 17:12:21,315: Snapshot:0	Epoch:3	Loss:9.944	translation_Loss:9.944	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.48	Hits@10:44.78	Best:25.48
2024-12-27 17:12:33,236: Snapshot:0	Epoch:4	Loss:7.479	translation_Loss:7.479	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.23	Hits@10:44.23	Best:25.48
2024-12-27 17:12:45,129: Snapshot:0	Epoch:5	Loss:6.39	translation_Loss:6.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.31	Hits@10:44.5	Best:25.48
2024-12-27 17:12:57,003: Snapshot:0	Epoch:6	Loss:5.724	translation_Loss:5.724	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.2	Hits@10:44.01	Best:25.48
2024-12-27 17:13:09,593: Snapshot:0	Epoch:7	Loss:5.252	translation_Loss:5.252	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.88	Hits@10:43.53	Best:25.48
2024-12-27 17:13:21,415: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 25.48
2024-12-27 17:13:21,415: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:4.911 MRR:24.85 Best Results: 25.48
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:13:21,416: Snapshot:0	Epoch:8	Loss:4.911	translation_Loss:4.911	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.85	Hits@10:43.59	Best:25.48
2024-12-27 17:13:34,135: Snapshot:0	Epoch:9	Loss:94.807	translation_Loss:94.771	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.85	Hits@10:43.59	Best:25.48
2024-12-27 17:13:46,287: End of token training: 0 Epoch: 10 Loss:94.78 MRR:24.85 Best Results: 25.48
2024-12-27 17:13:46,287: Snapshot:0	Epoch:10	Loss:94.78	translation_Loss:94.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.85	Hits@10:43.59	Best:25.48
2024-12-27 17:13:46,647: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_10000/0model_best.tar'
2024-12-27 17:13:52,225: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2597 | 0.1569 | 0.3168 | 0.3815 |  0.4525 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:14:29,667: Snapshot:1	Epoch:0	Loss:72.74	translation_Loss:58.033	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.707                                                   	MRR:11.71	Hits@10:23.91	Best:11.71
2024-12-27 17:14:41,146: Snapshot:1	Epoch:1	Loss:52.318	translation_Loss:41.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.905                                                   	MRR:11.72	Hits@10:23.54	Best:11.72
2024-12-27 17:14:52,801: Snapshot:1	Epoch:2	Loss:50.3	translation_Loss:39.52	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.78                                                   	MRR:11.77	Hits@10:23.89	Best:11.77
2024-12-27 17:15:04,260: Snapshot:1	Epoch:3	Loss:49.605	translation_Loss:38.788	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.817                                                   	MRR:11.73	Hits@10:23.54	Best:11.77
2024-12-27 17:15:16,354: Snapshot:1	Epoch:4	Loss:49.044	translation_Loss:38.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.784                                                   	MRR:11.8	Hits@10:23.74	Best:11.8
2024-12-27 17:15:27,889: Snapshot:1	Epoch:5	Loss:48.688	translation_Loss:37.89	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.799                                                   	MRR:11.91	Hits@10:23.74	Best:11.91
2024-12-27 17:15:39,273: Snapshot:1	Epoch:6	Loss:48.5	translation_Loss:37.718	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.781                                                   	MRR:11.83	Hits@10:23.61	Best:11.91
2024-12-27 17:15:50,773: Snapshot:1	Epoch:7	Loss:48.255	translation_Loss:37.427	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.829                                                   	MRR:11.84	Hits@10:23.82	Best:11.91
2024-12-27 17:16:02,304: Snapshot:1	Epoch:8	Loss:48.142	translation_Loss:37.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.76                                                   	MRR:11.79	Hits@10:23.79	Best:11.91
2024-12-27 17:16:13,783: Snapshot:1	Epoch:9	Loss:48.06	translation_Loss:37.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.825                                                   	MRR:11.86	Hits@10:23.75	Best:11.91
2024-12-27 17:16:25,233: Snapshot:1	Epoch:10	Loss:47.977	translation_Loss:37.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.795                                                   	MRR:11.93	Hits@10:24.07	Best:11.93
2024-12-27 17:16:36,732: Snapshot:1	Epoch:11	Loss:47.799	translation_Loss:37.02	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.779                                                   	MRR:11.95	Hits@10:23.91	Best:11.95
2024-12-27 17:16:48,235: Snapshot:1	Epoch:12	Loss:47.698	translation_Loss:36.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.777                                                   	MRR:12.03	Hits@10:24.01	Best:12.03
2024-12-27 17:16:59,665: Snapshot:1	Epoch:13	Loss:47.665	translation_Loss:36.894	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.771                                                   	MRR:11.92	Hits@10:24.06	Best:12.03
2024-12-27 17:17:11,192: Snapshot:1	Epoch:14	Loss:47.668	translation_Loss:36.884	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.784                                                   	MRR:11.94	Hits@10:23.89	Best:12.03
2024-12-27 17:17:22,679: Snapshot:1	Epoch:15	Loss:47.606	translation_Loss:36.811	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.795                                                   	MRR:11.93	Hits@10:24.04	Best:12.03
2024-12-27 17:17:34,137: Snapshot:1	Epoch:16	Loss:47.479	translation_Loss:36.716	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.763                                                   	MRR:11.89	Hits@10:24.06	Best:12.03
2024-12-27 17:17:46,133: Early Stopping! Snapshot: 1 Epoch: 17 Best Results: 12.03
2024-12-27 17:17:46,133: Start to training tokens! Snapshot: 1 Epoch: 17 Loss:47.412 MRR:12.02 Best Results: 12.03
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:17:46,133: Snapshot:1	Epoch:17	Loss:47.412	translation_Loss:36.657	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.755                                                   	MRR:12.02	Hits@10:24.04	Best:12.03
2024-12-27 17:17:57,167: Snapshot:1	Epoch:18	Loss:130.801	translation_Loss:130.764	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.02	Hits@10:24.04	Best:12.03
2024-12-27 17:18:08,424: End of token training: 1 Epoch: 19 Loss:130.812 MRR:12.02 Best Results: 12.03
2024-12-27 17:18:08,425: Snapshot:1	Epoch:19	Loss:130.812	translation_Loss:130.812	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:12.02	Hits@10:24.04	Best:12.03
2024-12-27 17:18:08,744: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_10000/1model_best.tar'
2024-12-27 17:18:18,750: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2581 | 0.1544 | 0.3157 | 0.3813 |  0.4527 |
|     1      | 0.1204 | 0.0589 | 0.1391 | 0.1808 |  0.2404 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:18:47,442: Snapshot:2	Epoch:0	Loss:52.498	translation_Loss:39.733	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.765                                                   	MRR:11.59	Hits@10:18.43	Best:11.59
2024-12-27 17:18:56,028: Snapshot:2	Epoch:1	Loss:43.392	translation_Loss:33.083	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.309                                                   	MRR:11.77	Hits@10:18.74	Best:11.77
2024-12-27 17:19:04,650: Snapshot:2	Epoch:2	Loss:42.979	translation_Loss:32.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.381                                                   	MRR:11.61	Hits@10:18.38	Best:11.77
2024-12-27 17:19:13,160: Snapshot:2	Epoch:3	Loss:42.73	translation_Loss:32.317	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.413                                                   	MRR:11.48	Hits@10:18.3	Best:11.77
2024-12-27 17:19:21,670: Snapshot:2	Epoch:4	Loss:42.648	translation_Loss:32.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.404                                                   	MRR:11.59	Hits@10:18.5	Best:11.77
2024-12-27 17:19:30,205: Snapshot:2	Epoch:5	Loss:42.675	translation_Loss:32.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.44                                                   	MRR:11.48	Hits@10:18.46	Best:11.77
2024-12-27 17:19:38,666: Early Stopping! Snapshot: 2 Epoch: 6 Best Results: 11.77
2024-12-27 17:19:38,667: Start to training tokens! Snapshot: 2 Epoch: 6 Loss:42.638 MRR:11.58 Best Results: 11.77
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:19:38,667: Snapshot:2	Epoch:6	Loss:42.638	translation_Loss:32.197	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.442                                                   	MRR:11.58	Hits@10:18.36	Best:11.77
2024-12-27 17:19:46,883: Snapshot:2	Epoch:7	Loss:115.145	translation_Loss:115.107	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.58	Hits@10:18.36	Best:11.77
2024-12-27 17:19:55,088: End of token training: 2 Epoch: 8 Loss:115.111 MRR:11.58 Best Results: 11.77
2024-12-27 17:19:55,089: Snapshot:2	Epoch:8	Loss:115.111	translation_Loss:115.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:11.58	Hits@10:18.36	Best:11.77
2024-12-27 17:19:55,466: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_10000/2model_best.tar'
2024-12-27 17:20:09,658: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2438 | 0.139  | 0.3001 | 0.3677 |  0.4424 |
|     1      | 0.1199 | 0.0582 | 0.1387 | 0.1805 |  0.2403 |
|     2      | 0.1149 | 0.0756 | 0.1204 | 0.1439 |  0.1854 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:20:25,546: Snapshot:3	Epoch:0	Loss:25.502	translation_Loss:19.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.917                                                   	MRR:20.28	Hits@10:30.91	Best:20.28
2024-12-27 17:20:29,570: Snapshot:3	Epoch:1	Loss:15.946	translation_Loss:12.966	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.979                                                   	MRR:20.75	Hits@10:30.82	Best:20.75
2024-12-27 17:20:33,614: Snapshot:3	Epoch:2	Loss:15.47	translation_Loss:12.49	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.979                                                   	MRR:20.93	Hits@10:30.75	Best:20.93
2024-12-27 17:20:37,646: Snapshot:3	Epoch:3	Loss:15.241	translation_Loss:12.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.997                                                   	MRR:20.83	Hits@10:30.81	Best:20.93
2024-12-27 17:20:41,566: Snapshot:3	Epoch:4	Loss:15.189	translation_Loss:12.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.043                                                   	MRR:20.65	Hits@10:30.67	Best:20.93
2024-12-27 17:20:45,512: Snapshot:3	Epoch:5	Loss:15.166	translation_Loss:12.127	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.039                                                   	MRR:20.67	Hits@10:30.91	Best:20.93
2024-12-27 17:20:49,425: Snapshot:3	Epoch:6	Loss:15.088	translation_Loss:12.031	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.057                                                   	MRR:20.45	Hits@10:30.85	Best:20.93
2024-12-27 17:20:53,309: Early Stopping! Snapshot: 3 Epoch: 7 Best Results: 20.93
2024-12-27 17:20:53,309: Start to training tokens! Snapshot: 3 Epoch: 7 Loss:15.118 MRR:20.67 Best Results: 20.93
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:20:53,309: Snapshot:3	Epoch:7	Loss:15.118	translation_Loss:12.043	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.076                                                   	MRR:20.67	Hits@10:31.09	Best:20.93
2024-12-27 17:20:57,090: Snapshot:3	Epoch:8	Loss:41.627	translation_Loss:41.592	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.67	Hits@10:31.09	Best:20.93
2024-12-27 17:21:00,840: End of token training: 3 Epoch: 9 Loss:41.582 MRR:20.67 Best Results: 20.93
2024-12-27 17:21:00,840: Snapshot:3	Epoch:9	Loss:41.582	translation_Loss:41.582	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.67	Hits@10:31.09	Best:20.93
2024-12-27 17:21:01,207: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_10000/3model_best.tar'
2024-12-27 17:21:16,734: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2407 | 0.1364 | 0.2962 | 0.3638 |  0.4384 |
|     1      | 0.1201 | 0.0584 | 0.139  | 0.1807 |  0.2403 |
|     2      | 0.1164 | 0.0765 | 0.1225 | 0.147  |  0.1884 |
|     3      | 0.2102 | 0.1516 | 0.2346 | 0.2652 |  0.3116 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:21:29,838: Snapshot:4	Epoch:0	Loss:22.483	translation_Loss:17.082	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.401                                                   	MRR:15.69	Hits@10:27.66	Best:15.69
2024-12-27 17:21:32,649: Snapshot:4	Epoch:1	Loss:15.706	translation_Loss:13.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.493                                                   	MRR:15.66	Hits@10:27.78	Best:15.69
2024-12-27 17:21:35,426: Snapshot:4	Epoch:2	Loss:15.423	translation_Loss:12.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.511                                                   	MRR:15.56	Hits@10:28.07	Best:15.69
2024-12-27 17:21:38,214: Snapshot:4	Epoch:3	Loss:15.359	translation_Loss:12.794	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.565                                                   	MRR:15.54	Hits@10:27.82	Best:15.69
2024-12-27 17:21:41,047: Snapshot:4	Epoch:4	Loss:15.323	translation_Loss:12.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.583                                                   	MRR:15.72	Hits@10:28.06	Best:15.72
2024-12-27 17:21:43,864: Snapshot:4	Epoch:5	Loss:15.266	translation_Loss:12.673	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.593                                                   	MRR:15.54	Hits@10:27.88	Best:15.72
2024-12-27 17:21:46,634: Snapshot:4	Epoch:6	Loss:15.227	translation_Loss:12.633	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.594                                                   	MRR:15.52	Hits@10:28.15	Best:15.72
2024-12-27 17:21:49,458: Snapshot:4	Epoch:7	Loss:15.247	translation_Loss:12.627	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.62                                                   	MRR:15.73	Hits@10:28.24	Best:15.73
2024-12-27 17:21:52,329: Snapshot:4	Epoch:8	Loss:15.18	translation_Loss:12.568	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.613                                                   	MRR:15.83	Hits@10:27.89	Best:15.83
2024-12-27 17:21:55,159: Snapshot:4	Epoch:9	Loss:15.229	translation_Loss:12.592	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.637                                                   	MRR:16.08	Hits@10:28.07	Best:16.08
2024-12-27 17:21:57,933: Snapshot:4	Epoch:10	Loss:15.192	translation_Loss:12.562	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.63                                                   	MRR:15.79	Hits@10:28.19	Best:16.08
2024-12-27 17:22:00,690: Snapshot:4	Epoch:11	Loss:15.193	translation_Loss:12.55	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.643                                                   	MRR:15.82	Hits@10:27.95	Best:16.08
2024-12-27 17:22:03,481: Snapshot:4	Epoch:12	Loss:15.176	translation_Loss:12.531	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.645                                                   	MRR:15.77	Hits@10:28.13	Best:16.08
2024-12-27 17:22:06,257: Snapshot:4	Epoch:13	Loss:15.192	translation_Loss:12.545	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.647                                                   	MRR:15.84	Hits@10:28.29	Best:16.08
2024-12-27 17:22:09,048: Early Stopping! Snapshot: 4 Epoch: 14 Best Results: 16.08
2024-12-27 17:22:09,049: Start to training tokens! Snapshot: 4 Epoch: 14 Loss:15.125 MRR:16.03 Best Results: 16.08
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:22:09,049: Snapshot:4	Epoch:14	Loss:15.125	translation_Loss:12.491	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.634                                                   	MRR:16.03	Hits@10:28.26	Best:16.08
2024-12-27 17:22:11,716: Snapshot:4	Epoch:15	Loss:30.154	translation_Loss:30.116	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.03	Hits@10:28.26	Best:16.08
2024-12-27 17:22:14,394: End of token training: 4 Epoch: 16 Loss:30.127 MRR:16.03 Best Results: 16.08
2024-12-27 17:22:14,394: Snapshot:4	Epoch:16	Loss:30.127	translation_Loss:30.127	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:16.03	Hits@10:28.26	Best:16.08
2024-12-27 17:22:14,772: => loading checkpoint './checkpoint/RELATIONrelation_0.01_512_10000/4model_best.tar'
2024-12-27 17:22:31,589: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2371 | 0.1335 | 0.2928 | 0.3598 |  0.4326 |
|     1      | 0.1195 | 0.0577 | 0.1383 | 0.1806 |  0.2399 |
|     2      | 0.1182 | 0.0789 | 0.1232 | 0.1477 |  0.1887 |
|     3      | 0.2106 | 0.1512 | 0.2367 | 0.2658 |  0.3118 |
|     4      | 0.1558 | 0.096  | 0.1638 | 0.2109 |  0.2785 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 17:22:31,592: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2597 | 0.1569 | 0.3168 | 0.3815 |  0.4525 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2581 | 0.1544 | 0.3157 | 0.3813 |  0.4527 |
|     1      | 0.1204 | 0.0589 | 0.1391 | 0.1808 |  0.2404 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2438 | 0.139  | 0.3001 | 0.3677 |  0.4424 |
|     1      | 0.1199 | 0.0582 | 0.1387 | 0.1805 |  0.2403 |
|     2      | 0.1149 | 0.0756 | 0.1204 | 0.1439 |  0.1854 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2407 | 0.1364 | 0.2962 | 0.3638 |  0.4384 |
|     1      | 0.1201 | 0.0584 | 0.139  | 0.1807 |  0.2403 |
|     2      | 0.1164 | 0.0765 | 0.1225 | 0.147  |  0.1884 |
|     3      | 0.2102 | 0.1516 | 0.2346 | 0.2652 |  0.3116 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2371 | 0.1335 | 0.2928 | 0.3598 |  0.4326 |
|     1      | 0.1195 | 0.0577 | 0.1383 | 0.1806 |  0.2399 |
|     2      | 0.1182 | 0.0789 | 0.1232 | 0.1477 |  0.1887 |
|     3      | 0.2106 | 0.1512 | 0.2367 | 0.2658 |  0.3118 |
|     4      | 0.1558 | 0.096  | 0.1638 | 0.2109 |  0.2785 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 17:22:31,592: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 137.0197024345398  |    0.26   |    0.157     |    0.317     |     0.453     |
|    1     | 251.85429573059082 |   0.191   |    0.108     |     0.23     |     0.349     |
|    2     | 92.72905802726746  |   0.166   |    0.094     |    0.196     |     0.304     |
|    3     | 49.21260333061218  |    0.17   |    0.099     |    0.199     |     0.304     |
|    4     | 56.14079189300537  |   0.168   |    0.098     |    0.196     |      0.3      |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 17:22:31,592: Sum_Training_Time:586.9564514160156
2024-12-27 17:22:31,592: Every_Training_Time:[137.0197024345398, 251.85429573059082, 92.72905802726746, 49.21260333061218, 56.14079189300537]
2024-12-27 17:22:31,592: Forward transfer: 0.011800000000000001 Backward transfer: -0.004949999999999993
2024-12-27 17:23:09,358: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227172236/RELATIONrelation_0.01_1024_1000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.01_1024_1000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.01_1024_1000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 17:23:25,220: Snapshot:0	Epoch:0	Loss:54.118	translation_Loss:54.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.48	Hits@10:39.35	Best:20.48
2024-12-27 17:23:36,563: Snapshot:0	Epoch:1	Loss:21.818	translation_Loss:21.818	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.42	Hits@10:44.32	Best:24.42
2024-12-27 17:23:47,972: Snapshot:0	Epoch:2	Loss:9.34	translation_Loss:9.34	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.95	Hits@10:45.83	Best:25.95
2024-12-27 17:23:59,312: Snapshot:0	Epoch:3	Loss:5.293	translation_Loss:5.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.85	Hits@10:45.63	Best:25.95
2024-12-27 17:24:10,812: Snapshot:0	Epoch:4	Loss:3.826	translation_Loss:3.826	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.96	Hits@10:45.53	Best:25.96
2024-12-27 17:24:22,137: Snapshot:0	Epoch:5	Loss:3.182	translation_Loss:3.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.8	Hits@10:45.6	Best:25.96
2024-12-27 17:24:33,975: Snapshot:0	Epoch:6	Loss:2.805	translation_Loss:2.805	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.87	Hits@10:45.2	Best:25.96
2024-12-27 17:24:45,360: Snapshot:0	Epoch:7	Loss:2.56	translation_Loss:2.56	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.51	Hits@10:44.73	Best:25.96
2024-12-27 17:24:56,745: Snapshot:0	Epoch:8	Loss:2.381	translation_Loss:2.381	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.7	Hits@10:44.83	Best:25.96
2024-12-27 17:25:08,106: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 25.96
2024-12-27 17:25:08,106: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:2.198 MRR:25.36 Best Results: 25.96
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:25:08,107: Snapshot:0	Epoch:9	Loss:2.198	translation_Loss:2.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.36	Hits@10:44.83	Best:25.96
2024-12-27 17:25:20,074: Snapshot:0	Epoch:10	Loss:48.683	translation_Loss:48.646	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.36	Hits@10:44.83	Best:25.96
2024-12-27 17:25:31,803: End of token training: 0 Epoch: 11 Loss:48.683 MRR:25.36 Best Results: 25.96
2024-12-27 17:25:31,804: Snapshot:0	Epoch:11	Loss:48.683	translation_Loss:48.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.36	Hits@10:44.83	Best:25.96
2024-12-27 17:25:32,169: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_1000/0model_best.tar'
2024-12-27 17:25:37,933: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2628 | 0.1566 | 0.3233 | 0.3901 |  0.4581 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:26:13,846: Snapshot:1	Epoch:0	Loss:35.996	translation_Loss:28.602	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.393                                                   	MRR:12.81	Hits@10:25.95	Best:12.81
2024-12-27 17:26:24,465: Snapshot:1	Epoch:1	Loss:25.105	translation_Loss:18.503	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.601                                                   	MRR:12.63	Hits@10:25.85	Best:12.81
2024-12-27 17:26:35,076: Snapshot:1	Epoch:2	Loss:23.829	translation_Loss:17.462	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.367                                                   	MRR:12.77	Hits@10:26.07	Best:12.81
2024-12-27 17:26:45,886: Snapshot:1	Epoch:3	Loss:23.296	translation_Loss:17.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.272                                                   	MRR:12.81	Hits@10:25.98	Best:12.81
2024-12-27 17:26:56,543: Snapshot:1	Epoch:4	Loss:22.938	translation_Loss:16.752	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.186                                                   	MRR:12.98	Hits@10:26.1	Best:12.98
2024-12-27 17:27:07,272: Snapshot:1	Epoch:5	Loss:22.718	translation_Loss:16.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.108                                                   	MRR:13.0	Hits@10:26.11	Best:13.0
2024-12-27 17:27:17,998: Snapshot:1	Epoch:6	Loss:22.513	translation_Loss:16.437	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.075                                                   	MRR:13.1	Hits@10:26.37	Best:13.1
2024-12-27 17:27:28,779: Snapshot:1	Epoch:7	Loss:22.368	translation_Loss:16.308	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.059                                                   	MRR:13.05	Hits@10:26.19	Best:13.1
2024-12-27 17:27:39,382: Snapshot:1	Epoch:8	Loss:22.298	translation_Loss:16.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.044                                                   	MRR:13.07	Hits@10:26.26	Best:13.1
2024-12-27 17:27:50,104: Snapshot:1	Epoch:9	Loss:22.18	translation_Loss:16.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.018                                                   	MRR:13.32	Hits@10:26.41	Best:13.32
2024-12-27 17:28:00,924: Snapshot:1	Epoch:10	Loss:22.133	translation_Loss:16.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.022                                                   	MRR:13.13	Hits@10:26.36	Best:13.32
2024-12-27 17:28:11,522: Snapshot:1	Epoch:11	Loss:22.093	translation_Loss:16.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.027                                                   	MRR:13.02	Hits@10:26.37	Best:13.32
2024-12-27 17:28:22,159: Snapshot:1	Epoch:12	Loss:21.993	translation_Loss:15.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.998                                                   	MRR:13.0	Hits@10:26.41	Best:13.32
2024-12-27 17:28:32,799: Snapshot:1	Epoch:13	Loss:21.976	translation_Loss:15.967	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.009                                                   	MRR:13.15	Hits@10:26.46	Best:13.32
2024-12-27 17:28:43,999: Early Stopping! Snapshot: 1 Epoch: 14 Best Results: 13.32
2024-12-27 17:28:43,999: Start to training tokens! Snapshot: 1 Epoch: 14 Loss:21.951 MRR:13.18 Best Results: 13.32
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:28:44,000: Snapshot:1	Epoch:14	Loss:21.951	translation_Loss:15.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.982                                                   	MRR:13.18	Hits@10:26.44	Best:13.32
2024-12-27 17:28:54,492: Snapshot:1	Epoch:15	Loss:63.861	translation_Loss:63.824	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.18	Hits@10:26.44	Best:13.32
2024-12-27 17:29:04,897: End of token training: 1 Epoch: 16 Loss:63.858 MRR:13.18 Best Results: 13.32
2024-12-27 17:29:04,897: Snapshot:1	Epoch:16	Loss:63.858	translation_Loss:63.858	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:13.18	Hits@10:26.44	Best:13.32
2024-12-27 17:29:05,261: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_1000/1model_best.tar'
2024-12-27 17:29:15,142: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2415 | 0.1365 | 0.2993 | 0.3654 |  0.437  |
|     1      | 0.1334 | 0.0671 | 0.1566 | 0.2026 |  0.2624 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:29:43,236: Snapshot:2	Epoch:0	Loss:22.778	translation_Loss:15.994	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.784                                                   	MRR:17.02	Hits@10:28.45	Best:17.02
2024-12-27 17:29:51,268: Snapshot:2	Epoch:1	Loss:16.859	translation_Loss:10.483	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.376                                                   	MRR:17.03	Hits@10:28.58	Best:17.03
2024-12-27 17:29:59,390: Snapshot:2	Epoch:2	Loss:16.65	translation_Loss:10.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.382                                                   	MRR:17.22	Hits@10:28.53	Best:17.22
2024-12-27 17:30:07,410: Snapshot:2	Epoch:3	Loss:16.514	translation_Loss:10.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.368                                                   	MRR:16.95	Hits@10:28.15	Best:17.22
2024-12-27 17:30:15,400: Snapshot:2	Epoch:4	Loss:16.546	translation_Loss:10.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.392                                                   	MRR:17.01	Hits@10:28.32	Best:17.22
2024-12-27 17:30:23,295: Snapshot:2	Epoch:5	Loss:16.467	translation_Loss:10.056	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.412                                                   	MRR:16.93	Hits@10:28.21	Best:17.22
2024-12-27 17:30:31,184: Snapshot:2	Epoch:6	Loss:16.462	translation_Loss:10.056	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.406                                                   	MRR:16.91	Hits@10:28.27	Best:17.22
2024-12-27 17:30:39,061: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 17.22
2024-12-27 17:30:39,061: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:16.462 MRR:17.06 Best Results: 17.22
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:30:39,062: Snapshot:2	Epoch:7	Loss:16.462	translation_Loss:10.052	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.41                                                   	MRR:17.06	Hits@10:28.26	Best:17.22
2024-12-27 17:30:46,820: Snapshot:2	Epoch:8	Loss:51.966	translation_Loss:51.928	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.06	Hits@10:28.26	Best:17.22
2024-12-27 17:30:54,576: End of token training: 2 Epoch: 9 Loss:51.901 MRR:17.06 Best Results: 17.22
2024-12-27 17:30:54,576: Snapshot:2	Epoch:9	Loss:51.901	translation_Loss:51.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:17.06	Hits@10:28.26	Best:17.22
2024-12-27 17:30:54,959: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_1000/2model_best.tar'
2024-12-27 17:31:07,839: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.215  | 0.1137 | 0.2693 | 0.3345 |  0.4036 |
|     1      | 0.1322 | 0.0644 | 0.1557 | 0.2034 |  0.2649 |
|     2      | 0.1698 | 0.1111 | 0.1839 | 0.2235 |  0.2838 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:31:23,653: Snapshot:3	Epoch:0	Loss:11.749	translation_Loss:9.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.494                                                   	MRR:23.61	Hits@10:35.4	Best:23.61
2024-12-27 17:31:27,321: Snapshot:3	Epoch:1	Loss:7.075	translation_Loss:4.801	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.274                                                   	MRR:23.3	Hits@10:35.12	Best:23.61
2024-12-27 17:31:31,011: Snapshot:3	Epoch:2	Loss:6.72	translation_Loss:4.51	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.209                                                   	MRR:23.53	Hits@10:34.88	Best:23.61
2024-12-27 17:31:34,672: Snapshot:3	Epoch:3	Loss:6.598	translation_Loss:4.413	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.185                                                   	MRR:23.39	Hits@10:34.98	Best:23.61
2024-12-27 17:31:38,370: Snapshot:3	Epoch:4	Loss:6.547	translation_Loss:4.379	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.168                                                   	MRR:23.42	Hits@10:35.38	Best:23.61
2024-12-27 17:31:42,064: Early Stopping! Snapshot: 3 Epoch: 5 Best Results: 23.61
2024-12-27 17:31:42,064: Start to training tokens! Snapshot: 3 Epoch: 5 Loss:6.561 MRR:23.18 Best Results: 23.61
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:31:42,064: Snapshot:3	Epoch:5	Loss:6.561	translation_Loss:4.369	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.192                                                   	MRR:23.18	Hits@10:35.15	Best:23.61
2024-12-27 17:31:45,656: Snapshot:3	Epoch:6	Loss:19.879	translation_Loss:19.844	multi_layer_Loss:0.035	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.18	Hits@10:35.15	Best:23.61
2024-12-27 17:31:49,235: End of token training: 3 Epoch: 7 Loss:19.86 MRR:23.18 Best Results: 23.61
2024-12-27 17:31:49,235: Snapshot:3	Epoch:7	Loss:19.86	translation_Loss:19.86	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.18	Hits@10:35.15	Best:23.61
2024-12-27 17:31:49,472: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_1000/3model_best.tar'
2024-12-27 17:32:04,589: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2131 | 0.1131 | 0.2677 | 0.3309 |  0.4002 |
|     1      | 0.1329 | 0.0656 | 0.1548 | 0.204  |  0.2649 |
|     2      | 0.1616 | 0.1015 | 0.1765 | 0.2178 |  0.2784 |
|     3      | 0.2321 | 0.164  | 0.2625 | 0.3009 |  0.3526 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:32:17,417: Snapshot:4	Epoch:0	Loss:8.93	translation_Loss:6.646	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.285                                                   	MRR:19.33	Hits@10:35.66	Best:19.33
2024-12-27 17:32:20,087: Snapshot:4	Epoch:1	Loss:5.34	translation_Loss:3.018	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.322                                                   	MRR:20.38	Hits@10:36.8	Best:20.38
2024-12-27 17:32:22,675: Snapshot:4	Epoch:2	Loss:4.882	translation_Loss:2.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.156                                                   	MRR:20.21	Hits@10:37.29	Best:20.38
2024-12-27 17:32:25,302: Snapshot:4	Epoch:3	Loss:4.798	translation_Loss:2.665	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.134                                                   	MRR:20.12	Hits@10:37.28	Best:20.38
2024-12-27 17:32:27,898: Snapshot:4	Epoch:4	Loss:4.744	translation_Loss:2.629	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.115                                                   	MRR:20.17	Hits@10:37.12	Best:20.38
2024-12-27 17:32:30,470: Snapshot:4	Epoch:5	Loss:4.747	translation_Loss:2.626	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.121                                                   	MRR:20.31	Hits@10:37.52	Best:20.38
2024-12-27 17:32:33,073: Early Stopping! Snapshot: 4 Epoch: 6 Best Results: 20.38
2024-12-27 17:32:33,073: Start to training tokens! Snapshot: 4 Epoch: 6 Loss:4.718 MRR:20.23 Best Results: 20.38
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:32:33,073: Snapshot:4	Epoch:6	Loss:4.718	translation_Loss:2.619	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.099                                                   	MRR:20.23	Hits@10:37.06	Best:20.38
2024-12-27 17:32:35,608: Snapshot:4	Epoch:7	Loss:12.442	translation_Loss:12.405	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.23	Hits@10:37.06	Best:20.38
2024-12-27 17:32:38,147: End of token training: 4 Epoch: 8 Loss:12.393 MRR:20.23 Best Results: 20.38
2024-12-27 17:32:38,148: Snapshot:4	Epoch:8	Loss:12.393	translation_Loss:12.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.23	Hits@10:37.06	Best:20.38
2024-12-27 17:32:38,381: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_1000/4model_best.tar'
2024-12-27 17:32:55,188: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2113 | 0.1122 | 0.2637 | 0.326  |  0.3972 |
|     1      | 0.1302 | 0.0618 | 0.1534 | 0.2027 |  0.2652 |
|     2      | 0.1543 | 0.096  | 0.1688 | 0.2074 |  0.2668 |
|     3      | 0.232  | 0.1617 | 0.2634 | 0.3027 |  0.3555 |
|     4      | 0.1994 | 0.1125 | 0.2191 | 0.2824 |  0.3708 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 17:32:55,190: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2628 | 0.1566 | 0.3233 | 0.3901 |  0.4581 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2415 | 0.1365 | 0.2993 | 0.3654 |  0.437  |
|     1      | 0.1334 | 0.0671 | 0.1566 | 0.2026 |  0.2624 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.215  | 0.1137 | 0.2693 | 0.3345 |  0.4036 |
|     1      | 0.1322 | 0.0644 | 0.1557 | 0.2034 |  0.2649 |
|     2      | 0.1698 | 0.1111 | 0.1839 | 0.2235 |  0.2838 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2131 | 0.1131 | 0.2677 | 0.3309 |  0.4002 |
|     1      | 0.1329 | 0.0656 | 0.1548 | 0.204  |  0.2649 |
|     2      | 0.1616 | 0.1015 | 0.1765 | 0.2178 |  0.2784 |
|     3      | 0.2321 | 0.164  | 0.2625 | 0.3009 |  0.3526 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2113 | 0.1122 | 0.2637 | 0.326  |  0.3972 |
|     1      | 0.1302 | 0.0618 | 0.1534 | 0.2027 |  0.2652 |
|     2      | 0.1543 | 0.096  | 0.1688 | 0.2074 |  0.2668 |
|     3      | 0.232  | 0.1617 | 0.2634 | 0.3027 |  0.3555 |
|     4      | 0.1994 | 0.1125 | 0.2191 | 0.2824 |  0.3708 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 17:32:55,190: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 142.44487738609314 |   0.263   |    0.157     |    0.323     |     0.458     |
|    1     | 202.64462208747864 |   0.189   |    0.103     |     0.23     |     0.352     |
|    2     | 95.86897397041321  |   0.173   |    0.095     |    0.206     |     0.323     |
|    3     | 39.427977561950684 |   0.177   |     0.1      |     0.21     |     0.323     |
|    4     | 32.080167293548584 |   0.176   |    0.098     |    0.207     |     0.324     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 17:32:55,190: Sum_Training_Time:512.4666182994843
2024-12-27 17:32:55,191: Every_Training_Time:[142.44487738609314, 202.64462208747864, 95.86897397041321, 39.427977561950684, 32.080167293548584]
2024-12-27 17:32:55,191: Forward transfer: 0.012825 Backward transfer: -0.017574999999999993
2024-12-27 17:33:32,919: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227173259/RELATIONrelation_0.01_1024_5000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.01_1024_5000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.01_1024_5000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 17:33:48,826: Snapshot:0	Epoch:0	Loss:54.118	translation_Loss:54.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.47	Hits@10:39.29	Best:20.47
2024-12-27 17:34:00,369: Snapshot:0	Epoch:1	Loss:21.825	translation_Loss:21.825	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.44	Hits@10:44.15	Best:24.44
2024-12-27 17:34:12,005: Snapshot:0	Epoch:2	Loss:9.343	translation_Loss:9.343	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.85	Hits@10:45.77	Best:25.85
2024-12-27 17:34:23,519: Snapshot:0	Epoch:3	Loss:5.309	translation_Loss:5.309	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.01	Hits@10:45.62	Best:26.01
2024-12-27 17:34:35,054: Snapshot:0	Epoch:4	Loss:3.827	translation_Loss:3.827	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.91	Hits@10:45.36	Best:26.01
2024-12-27 17:34:46,536: Snapshot:0	Epoch:5	Loss:3.184	translation_Loss:3.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.85	Hits@10:45.25	Best:26.01
2024-12-27 17:34:58,572: Snapshot:0	Epoch:6	Loss:2.813	translation_Loss:2.813	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.78	Hits@10:45.24	Best:26.01
2024-12-27 17:35:10,132: Snapshot:0	Epoch:7	Loss:2.547	translation_Loss:2.547	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.43	Hits@10:44.74	Best:26.01
2024-12-27 17:35:21,707: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 26.01
2024-12-27 17:35:21,707: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:2.372 MRR:25.72 Best Results: 26.01
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:35:21,707: Snapshot:0	Epoch:8	Loss:2.372	translation_Loss:2.372	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.72	Hits@10:44.95	Best:26.01
2024-12-27 17:35:33,952: Snapshot:0	Epoch:9	Loss:48.694	translation_Loss:48.658	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.72	Hits@10:44.95	Best:26.01
2024-12-27 17:35:45,570: End of token training: 0 Epoch: 10 Loss:48.666 MRR:25.72 Best Results: 26.01
2024-12-27 17:35:45,571: Snapshot:0	Epoch:10	Loss:48.666	translation_Loss:48.666	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.72	Hits@10:44.95	Best:26.01
2024-12-27 17:35:45,939: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_5000/0model_best.tar'
2024-12-27 17:35:51,334: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2648 | 0.1594 | 0.3246 |  0.39  |  0.4597 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:36:27,751: Snapshot:1	Epoch:0	Loss:38.775	translation_Loss:30.953	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.822                                                   	MRR:12.32	Hits@10:25.06	Best:12.32
2024-12-27 17:36:38,669: Snapshot:1	Epoch:1	Loss:26.414	translation_Loss:20.797	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.617                                                   	MRR:12.26	Hits@10:24.9	Best:12.32
2024-12-27 17:36:49,540: Snapshot:1	Epoch:2	Loss:25.237	translation_Loss:19.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.457                                                   	MRR:12.28	Hits@10:24.98	Best:12.32
2024-12-27 17:37:00,398: Snapshot:1	Epoch:3	Loss:24.825	translation_Loss:19.383	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.442                                                   	MRR:12.19	Hits@10:25.08	Best:12.32
2024-12-27 17:37:11,659: Snapshot:1	Epoch:4	Loss:24.56	translation_Loss:19.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.438                                                   	MRR:12.17	Hits@10:25.14	Best:12.32
2024-12-27 17:37:22,452: Early Stopping! Snapshot: 1 Epoch: 5 Best Results: 12.32
2024-12-27 17:37:22,452: Start to training tokens! Snapshot: 1 Epoch: 5 Loss:24.346 MRR:12.2 Best Results: 12.32
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:37:22,453: Snapshot:1	Epoch:5	Loss:24.346	translation_Loss:18.927	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.418                                                   	MRR:12.2	Hits@10:25.03	Best:12.32
2024-12-27 17:37:32,989: Snapshot:1	Epoch:6	Loss:65.926	translation_Loss:65.889	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.2	Hits@10:25.03	Best:12.32
2024-12-27 17:37:43,529: End of token training: 1 Epoch: 7 Loss:65.995 MRR:12.2 Best Results: 12.32
2024-12-27 17:37:43,529: Snapshot:1	Epoch:7	Loss:65.995	translation_Loss:65.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:12.2	Hits@10:25.03	Best:12.32
2024-12-27 17:37:43,836: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_5000/1model_best.tar'
2024-12-27 17:37:53,718: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2612 | 0.1552 | 0.3202 | 0.3876 |  0.4595 |
|     1      | 0.1239 | 0.0619 | 0.1412 | 0.1842 |  0.2483 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:38:21,952: Snapshot:2	Epoch:0	Loss:28.86	translation_Loss:20.768	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.093                                                   	MRR:14.31	Hits@10:23.09	Best:14.31
2024-12-27 17:38:30,240: Snapshot:2	Epoch:1	Loss:22.204	translation_Loss:15.735	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.47                                                   	MRR:14.33	Hits@10:23.16	Best:14.33
2024-12-27 17:38:38,240: Snapshot:2	Epoch:2	Loss:21.95	translation_Loss:15.465	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.485                                                   	MRR:14.28	Hits@10:23.15	Best:14.33
2024-12-27 17:38:46,268: Snapshot:2	Epoch:3	Loss:21.866	translation_Loss:15.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.485                                                   	MRR:14.16	Hits@10:22.91	Best:14.33
2024-12-27 17:38:54,335: Snapshot:2	Epoch:4	Loss:21.854	translation_Loss:15.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.522                                                   	MRR:14.29	Hits@10:22.95	Best:14.33
2024-12-27 17:39:02,405: Snapshot:2	Epoch:5	Loss:21.8	translation_Loss:15.284	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.516                                                   	MRR:14.41	Hits@10:23.14	Best:14.41
2024-12-27 17:39:10,461: Snapshot:2	Epoch:6	Loss:21.771	translation_Loss:15.246	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.525                                                   	MRR:14.27	Hits@10:23.01	Best:14.41
2024-12-27 17:39:18,476: Snapshot:2	Epoch:7	Loss:21.767	translation_Loss:15.26	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.507                                                   	MRR:14.27	Hits@10:22.88	Best:14.41
2024-12-27 17:39:26,602: Snapshot:2	Epoch:8	Loss:21.711	translation_Loss:15.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.516                                                   	MRR:14.28	Hits@10:23.03	Best:14.41
2024-12-27 17:39:34,565: Snapshot:2	Epoch:9	Loss:21.741	translation_Loss:15.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.511                                                   	MRR:14.28	Hits@10:23.07	Best:14.41
2024-12-27 17:39:42,615: Early Stopping! Snapshot: 2 Epoch: 10 Best Results: 14.41
2024-12-27 17:39:42,616: Start to training tokens! Snapshot: 2 Epoch: 10 Loss:21.71 MRR:14.29 Best Results: 14.41
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:39:42,616: Snapshot:2	Epoch:10	Loss:21.71	translation_Loss:15.174	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.535                                                   	MRR:14.29	Hits@10:23.08	Best:14.41
2024-12-27 17:39:50,545: Snapshot:2	Epoch:11	Loss:55.981	translation_Loss:55.943	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.29	Hits@10:23.08	Best:14.41
2024-12-27 17:39:58,382: End of token training: 2 Epoch: 12 Loss:55.93 MRR:14.29 Best Results: 14.41
2024-12-27 17:39:58,382: Snapshot:2	Epoch:12	Loss:55.93	translation_Loss:55.93	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:14.29	Hits@10:23.08	Best:14.41
2024-12-27 17:39:58,756: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_5000/2model_best.tar'
2024-12-27 17:40:12,004: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2415 | 0.137  | 0.3011 | 0.3659 |  0.4365 |
|     1      | 0.1221 | 0.059  | 0.1407 | 0.1825 |  0.2476 |
|     2      | 0.1404 | 0.0935 | 0.1487 | 0.179  |  0.2269 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:40:27,222: Snapshot:3	Epoch:0	Loss:15.411	translation_Loss:11.466	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.945                                                   	MRR:21.62	Hits@10:32.89	Best:21.62
2024-12-27 17:40:30,921: Snapshot:3	Epoch:1	Loss:9.377	translation_Loss:7.068	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.308                                                   	MRR:21.47	Hits@10:32.37	Best:21.62
2024-12-27 17:40:34,611: Snapshot:3	Epoch:2	Loss:8.897	translation_Loss:6.662	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.235                                                   	MRR:21.29	Hits@10:32.15	Best:21.62
2024-12-27 17:40:38,340: Snapshot:3	Epoch:3	Loss:8.793	translation_Loss:6.572	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.221                                                   	MRR:21.27	Hits@10:32.17	Best:21.62
2024-12-27 17:40:42,145: Snapshot:3	Epoch:4	Loss:8.72	translation_Loss:6.516	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.204                                                   	MRR:21.35	Hits@10:32.27	Best:21.62
2024-12-27 17:40:46,359: Early Stopping! Snapshot: 3 Epoch: 5 Best Results: 21.62
2024-12-27 17:40:46,359: Start to training tokens! Snapshot: 3 Epoch: 5 Loss:8.734 MRR:21.2 Best Results: 21.62
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:40:46,359: Snapshot:3	Epoch:5	Loss:8.734	translation_Loss:6.509	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.225                                                   	MRR:21.2	Hits@10:32.18	Best:21.62
2024-12-27 17:40:49,995: Snapshot:3	Epoch:6	Loss:21.172	translation_Loss:21.137	multi_layer_Loss:0.035	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.2	Hits@10:32.18	Best:21.62
2024-12-27 17:40:53,649: End of token training: 3 Epoch: 7 Loss:21.143 MRR:21.2 Best Results: 21.62
2024-12-27 17:40:53,649: Snapshot:3	Epoch:7	Loss:21.143	translation_Loss:21.143	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.2	Hits@10:32.18	Best:21.62
2024-12-27 17:40:53,956: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_5000/3model_best.tar'
2024-12-27 17:41:08,787: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.238  | 0.1354 | 0.2939 | 0.3573 |  0.4314 |
|     1      | 0.1223 | 0.0594 | 0.1405 | 0.182  |  0.2479 |
|     2      | 0.1419 | 0.0943 | 0.1503 | 0.1811 |  0.2307 |
|     3      | 0.2131 | 0.1474 | 0.246  | 0.2798 |  0.3301 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:41:21,604: Snapshot:4	Epoch:0	Loss:13.178	translation_Loss:9.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.078                                                   	MRR:17.14	Hits@10:31.56	Best:17.14
2024-12-27 17:41:24,297: Snapshot:4	Epoch:1	Loss:8.718	translation_Loss:5.625	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.093                                                   	MRR:18.37	Hits@10:31.77	Best:18.37
2024-12-27 17:41:26,933: Snapshot:4	Epoch:2	Loss:8.295	translation_Loss:5.316	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.98                                                   	MRR:17.83	Hits@10:31.89	Best:18.37
2024-12-27 17:41:29,509: Snapshot:4	Epoch:3	Loss:8.212	translation_Loss:5.233	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.979                                                   	MRR:18.0	Hits@10:32.19	Best:18.37
2024-12-27 17:41:32,135: Snapshot:4	Epoch:4	Loss:8.168	translation_Loss:5.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.983                                                   	MRR:17.97	Hits@10:32.25	Best:18.37
2024-12-27 17:41:34,740: Snapshot:4	Epoch:5	Loss:8.161	translation_Loss:5.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.991                                                   	MRR:18.03	Hits@10:32.19	Best:18.37
2024-12-27 17:41:37,345: Early Stopping! Snapshot: 4 Epoch: 6 Best Results: 18.37
2024-12-27 17:41:37,345: Start to training tokens! Snapshot: 4 Epoch: 6 Loss:8.14 MRR:18.3 Best Results: 18.37
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:41:37,345: Snapshot:4	Epoch:6	Loss:8.14	translation_Loss:5.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.998                                                   	MRR:18.3	Hits@10:32.29	Best:18.37
2024-12-27 17:41:39,865: Snapshot:4	Epoch:7	Loss:14.39	translation_Loss:14.353	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.3	Hits@10:32.29	Best:18.37
2024-12-27 17:41:42,430: End of token training: 4 Epoch: 8 Loss:14.378 MRR:18.3 Best Results: 18.37
2024-12-27 17:41:42,431: Snapshot:4	Epoch:8	Loss:14.378	translation_Loss:14.377	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:18.3	Hits@10:32.29	Best:18.37
2024-12-27 17:41:42,764: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_5000/4model_best.tar'
2024-12-27 17:41:59,456: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2384 | 0.1355 | 0.2945 | 0.3601 |  0.4343 |
|     1      | 0.1221 | 0.0592 | 0.141  | 0.1828 |  0.2484 |
|     2      | 0.1384 | 0.0897 | 0.1475 | 0.1798 |  0.2295 |
|     3      | 0.2148 | 0.1473 | 0.2462 | 0.2836 |  0.3356 |
|     4      | 0.1804 | 0.1094 | 0.1901 | 0.241  |  0.3229 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 17:41:59,458: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2648 | 0.1594 | 0.3246 |  0.39  |  0.4597 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2612 | 0.1552 | 0.3202 | 0.3876 |  0.4595 |
|     1      | 0.1239 | 0.0619 | 0.1412 | 0.1842 |  0.2483 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2415 | 0.137  | 0.3011 | 0.3659 |  0.4365 |
|     1      | 0.1221 | 0.059  | 0.1407 | 0.1825 |  0.2476 |
|     2      | 0.1404 | 0.0935 | 0.1487 | 0.179  |  0.2269 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.238  | 0.1354 | 0.2939 | 0.3573 |  0.4314 |
|     1      | 0.1223 | 0.0594 | 0.1405 | 0.182  |  0.2479 |
|     2      | 0.1419 | 0.0943 | 0.1503 | 0.1811 |  0.2307 |
|     3      | 0.2131 | 0.1474 | 0.246  | 0.2798 |  0.3301 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2384 | 0.1355 | 0.2945 | 0.3601 |  0.4343 |
|     1      | 0.1221 | 0.0592 | 0.141  | 0.1828 |  0.2484 |
|     2      | 0.1384 | 0.0897 | 0.1475 | 0.1798 |  0.2295 |
|     3      | 0.2148 | 0.1473 | 0.2462 | 0.2836 |  0.3356 |
|     4      | 0.1804 | 0.1094 | 0.1901 | 0.241  |  0.3229 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 17:41:59,459: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 132.6505584716797  |   0.265   |    0.159     |    0.325     |      0.46     |
|    1     | 107.92049813270569 |   0.194   |     0.11     |    0.233     |     0.357     |
|    2     | 121.08253479003906 |   0.172   |    0.098     |    0.204     |     0.315     |
|    3     | 39.67849922180176  |   0.176   |    0.103     |    0.206     |     0.315     |
|    4     | 31.83741593360901  |   0.176   |    0.102     |    0.205     |     0.317     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 17:41:59,459: Sum_Training_Time:433.1695065498352
2024-12-27 17:41:59,459: Every_Training_Time:[132.6505584716797, 107.92049813270569, 121.08253479003906, 39.67849922180176, 31.83741593360901]
2024-12-27 17:41:59,459: Forward transfer: 0.010525 Backward transfer: -0.007124999999999999
2024-12-27 17:42:37,098: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227174203/RELATIONrelation_0.01_1024_10000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.01_1024_10000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.01_1024_10000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 17:42:52,977: Snapshot:0	Epoch:0	Loss:54.119	translation_Loss:54.119	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.48	Hits@10:39.31	Best:20.48
2024-12-27 17:43:04,516: Snapshot:0	Epoch:1	Loss:21.813	translation_Loss:21.813	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.43	Hits@10:44.15	Best:24.43
2024-12-27 17:43:16,058: Snapshot:0	Epoch:2	Loss:9.338	translation_Loss:9.338	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.9	Hits@10:45.58	Best:25.9
2024-12-27 17:43:27,651: Snapshot:0	Epoch:3	Loss:5.302	translation_Loss:5.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.0	Hits@10:45.59	Best:26.0
2024-12-27 17:43:39,101: Snapshot:0	Epoch:4	Loss:3.83	translation_Loss:3.83	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.86	Hits@10:45.46	Best:26.0
2024-12-27 17:43:50,508: Snapshot:0	Epoch:5	Loss:3.167	translation_Loss:3.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.75	Hits@10:45.38	Best:26.0
2024-12-27 17:44:02,494: Snapshot:0	Epoch:6	Loss:2.816	translation_Loss:2.816	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.64	Hits@10:45.22	Best:26.0
2024-12-27 17:44:13,954: Snapshot:0	Epoch:7	Loss:2.55	translation_Loss:2.55	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.43	Hits@10:44.9	Best:26.0
2024-12-27 17:44:25,365: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 26.0
2024-12-27 17:44:25,365: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:2.369 MRR:25.68 Best Results: 26.0
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:44:25,365: Snapshot:0	Epoch:8	Loss:2.369	translation_Loss:2.369	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.68	Hits@10:44.91	Best:26.0
2024-12-27 17:44:37,431: Snapshot:0	Epoch:9	Loss:48.879	translation_Loss:48.842	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.68	Hits@10:44.91	Best:26.0
2024-12-27 17:44:49,026: End of token training: 0 Epoch: 10 Loss:48.849 MRR:25.68 Best Results: 26.0
2024-12-27 17:44:49,026: Snapshot:0	Epoch:10	Loss:48.849	translation_Loss:48.849	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.68	Hits@10:44.91	Best:26.0
2024-12-27 17:44:49,387: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_10000/0model_best.tar'
2024-12-27 17:44:54,966: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2638 | 0.1582 | 0.3246 | 0.3879 |  0.4596 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:45:31,382: Snapshot:1	Epoch:0	Loss:40.136	translation_Loss:31.354	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.782                                                   	MRR:12.26	Hits@10:24.7	Best:12.26
2024-12-27 17:45:42,150: Snapshot:1	Epoch:1	Loss:25.98	translation_Loss:21.2	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.78                                                   	MRR:12.07	Hits@10:24.3	Best:12.26
2024-12-27 17:45:52,887: Snapshot:1	Epoch:2	Loss:24.971	translation_Loss:20.2	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.771                                                   	MRR:12.17	Hits@10:24.39	Best:12.26
2024-12-27 17:46:03,667: Snapshot:1	Epoch:3	Loss:24.63	translation_Loss:19.824	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.806                                                   	MRR:12.05	Hits@10:24.5	Best:12.26
2024-12-27 17:46:15,041: Snapshot:1	Epoch:4	Loss:24.39	translation_Loss:19.566	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.824                                                   	MRR:12.05	Hits@10:24.58	Best:12.26
2024-12-27 17:46:25,699: Early Stopping! Snapshot: 1 Epoch: 5 Best Results: 12.26
2024-12-27 17:46:25,700: Start to training tokens! Snapshot: 1 Epoch: 5 Loss:24.184 MRR:12.13 Best Results: 12.26
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:46:25,700: Snapshot:1	Epoch:5	Loss:24.184	translation_Loss:19.359	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.825                                                   	MRR:12.13	Hits@10:24.6	Best:12.26
2024-12-27 17:46:36,154: Snapshot:1	Epoch:6	Loss:66.356	translation_Loss:66.319	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.13	Hits@10:24.6	Best:12.26
2024-12-27 17:46:46,798: End of token training: 1 Epoch: 7 Loss:66.415 MRR:12.13 Best Results: 12.26
2024-12-27 17:46:46,798: Snapshot:1	Epoch:7	Loss:66.415	translation_Loss:66.415	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:12.13	Hits@10:24.6	Best:12.26
2024-12-27 17:46:47,104: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_10000/1model_best.tar'
2024-12-27 17:46:57,319: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2616 | 0.1552 | 0.3224 | 0.3874 |  0.4592 |
|     1      | 0.1238 | 0.0616 | 0.144  | 0.184  |  0.2463 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:47:25,650: Snapshot:2	Epoch:0	Loss:31.272	translation_Loss:22.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.973                                                   	MRR:13.1	Hits@10:21.07	Best:13.1
2024-12-27 17:47:33,645: Snapshot:2	Epoch:1	Loss:22.923	translation_Loss:17.319	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.604                                                   	MRR:13.2	Hits@10:21.13	Best:13.2
2024-12-27 17:47:41,665: Snapshot:2	Epoch:2	Loss:22.759	translation_Loss:17.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.692                                                   	MRR:13.25	Hits@10:21.18	Best:13.25
2024-12-27 17:47:49,677: Snapshot:2	Epoch:3	Loss:22.696	translation_Loss:16.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.722                                                   	MRR:13.06	Hits@10:21.0	Best:13.25
2024-12-27 17:47:57,646: Snapshot:2	Epoch:4	Loss:22.693	translation_Loss:16.936	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.756                                                   	MRR:13.18	Hits@10:21.07	Best:13.25
2024-12-27 17:48:05,593: Snapshot:2	Epoch:5	Loss:22.642	translation_Loss:16.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.775                                                   	MRR:13.08	Hits@10:20.94	Best:13.25
2024-12-27 17:48:13,599: Snapshot:2	Epoch:6	Loss:22.633	translation_Loss:16.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.797                                                   	MRR:12.95	Hits@10:20.92	Best:13.25
2024-12-27 17:48:21,569: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 13.25
2024-12-27 17:48:21,569: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:22.618 MRR:13.11 Best Results: 13.25
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:48:21,569: Snapshot:2	Epoch:7	Loss:22.618	translation_Loss:16.825	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.793                                                   	MRR:13.11	Hits@10:20.88	Best:13.25
2024-12-27 17:48:29,469: Snapshot:2	Epoch:8	Loss:57.387	translation_Loss:57.349	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.11	Hits@10:20.88	Best:13.25
2024-12-27 17:48:37,257: End of token training: 2 Epoch: 9 Loss:57.408 MRR:13.11 Best Results: 13.25
2024-12-27 17:48:37,257: Snapshot:2	Epoch:9	Loss:57.408	translation_Loss:57.408	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:13.11	Hits@10:20.88	Best:13.25
2024-12-27 17:48:37,637: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_10000/2model_best.tar'
2024-12-27 17:48:50,729: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2434 | 0.1385 | 0.3032 | 0.3669 |  0.4374 |
|     1      | 0.1227 | 0.0604 | 0.1424 | 0.1831 |  0.2462 |
|     2      | 0.1298 | 0.086  | 0.1355 | 0.1651 |  0.2124 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:49:06,248: Snapshot:3	Epoch:0	Loss:17.402	translation_Loss:11.877	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.525                                                   	MRR:20.97	Hits@10:31.36	Best:20.97
2024-12-27 17:49:10,051: Snapshot:3	Epoch:1	Loss:9.527	translation_Loss:7.57	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.957                                                   	MRR:20.58	Hits@10:30.95	Best:20.97
2024-12-27 17:49:13,704: Snapshot:3	Epoch:2	Loss:9.026	translation_Loss:7.174	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.852                                                   	MRR:20.85	Hits@10:30.9	Best:20.97
2024-12-27 17:49:17,344: Snapshot:3	Epoch:3	Loss:8.924	translation_Loss:7.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.844                                                   	MRR:20.64	Hits@10:30.92	Best:20.97
2024-12-27 17:49:21,070: Snapshot:3	Epoch:4	Loss:8.822	translation_Loss:6.98	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.842                                                   	MRR:20.78	Hits@10:30.68	Best:20.97
2024-12-27 17:49:24,757: Early Stopping! Snapshot: 3 Epoch: 5 Best Results: 20.97
2024-12-27 17:49:24,757: Start to training tokens! Snapshot: 3 Epoch: 5 Loss:8.804 MRR:20.8 Best Results: 20.97
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:49:24,758: Snapshot:3	Epoch:5	Loss:8.804	translation_Loss:6.961	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.843                                                   	MRR:20.8	Hits@10:30.83	Best:20.97
2024-12-27 17:49:28,329: Snapshot:3	Epoch:6	Loss:21.442	translation_Loss:21.407	multi_layer_Loss:0.035	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.8	Hits@10:30.83	Best:20.97
2024-12-27 17:49:31,892: End of token training: 3 Epoch: 7 Loss:21.4 MRR:20.8 Best Results: 20.97
2024-12-27 17:49:31,892: Snapshot:3	Epoch:7	Loss:21.4	translation_Loss:21.4	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.8	Hits@10:30.83	Best:20.97
2024-12-27 17:49:32,181: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_10000/3model_best.tar'
2024-12-27 17:49:47,738: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2402 | 0.1362 | 0.2974 | 0.3623 |  0.4367 |
|     1      | 0.1229 | 0.0606 | 0.1423 | 0.183  |  0.2463 |
|     2      | 0.1319 | 0.0876 | 0.1383 | 0.1674 |  0.2141 |
|     3      | 0.2062 | 0.1428 | 0.2349 | 0.2709 |  0.318  |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:50:00,178: Snapshot:4	Epoch:0	Loss:15.895	translation_Loss:10.517	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.378                                                   	MRR:15.52	Hits@10:27.95	Best:15.52
2024-12-27 17:50:02,900: Snapshot:4	Epoch:1	Loss:10.037	translation_Loss:7.799	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.238                                                   	MRR:16.49	Hits@10:28.44	Best:16.49
2024-12-27 17:50:05,520: Snapshot:4	Epoch:2	Loss:9.51	translation_Loss:7.508	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.002                                                   	MRR:16.41	Hits@10:28.87	Best:16.49
2024-12-27 17:50:08,156: Snapshot:4	Epoch:3	Loss:9.419	translation_Loss:7.43	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.989                                                   	MRR:16.29	Hits@10:29.16	Best:16.49
2024-12-27 17:50:10,754: Snapshot:4	Epoch:4	Loss:9.384	translation_Loss:7.377	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.007                                                   	MRR:16.31	Hits@10:29.0	Best:16.49
2024-12-27 17:50:13,369: Snapshot:4	Epoch:5	Loss:9.386	translation_Loss:7.363	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.023                                                   	MRR:16.32	Hits@10:29.02	Best:16.49
2024-12-27 17:50:15,969: Early Stopping! Snapshot: 4 Epoch: 6 Best Results: 16.49
2024-12-27 17:50:15,969: Start to training tokens! Snapshot: 4 Epoch: 6 Loss:9.367 MRR:16.24 Best Results: 16.49
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:50:15,969: Snapshot:4	Epoch:6	Loss:9.367	translation_Loss:7.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.048                                                   	MRR:16.24	Hits@10:28.68	Best:16.49
2024-12-27 17:50:18,511: Snapshot:4	Epoch:7	Loss:15.81	translation_Loss:15.773	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.24	Hits@10:28.68	Best:16.49
2024-12-27 17:50:21,033: End of token training: 4 Epoch: 8 Loss:15.786 MRR:16.24 Best Results: 16.49
2024-12-27 17:50:21,034: Snapshot:4	Epoch:8	Loss:15.786	translation_Loss:15.786	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:16.24	Hits@10:28.68	Best:16.49
2024-12-27 17:50:21,270: => loading checkpoint './checkpoint/RELATIONrelation_0.01_1024_10000/4model_best.tar'
2024-12-27 17:50:38,094: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2407 | 0.1362 | 0.3001 | 0.3648 |  0.4361 |
|     1      | 0.1224 | 0.0598 | 0.142  | 0.1828 |  0.2467 |
|     2      | 0.1315 | 0.0873 | 0.1378 | 0.167  |  0.2134 |
|     3      | 0.2075 | 0.1433 | 0.2355 | 0.2723 |  0.3214 |
|     4      | 0.1609 | 0.1014 | 0.1747 | 0.2129 |  0.2782 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 17:50:38,096: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2638 | 0.1582 | 0.3246 | 0.3879 |  0.4596 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2616 | 0.1552 | 0.3224 | 0.3874 |  0.4592 |
|     1      | 0.1238 | 0.0616 | 0.144  | 0.184  |  0.2463 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2434 | 0.1385 | 0.3032 | 0.3669 |  0.4374 |
|     1      | 0.1227 | 0.0604 | 0.1424 | 0.1831 |  0.2462 |
|     2      | 0.1298 | 0.086  | 0.1355 | 0.1651 |  0.2124 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2402 | 0.1362 | 0.2974 | 0.3623 |  0.4367 |
|     1      | 0.1229 | 0.0606 | 0.1423 | 0.183  |  0.2463 |
|     2      | 0.1319 | 0.0876 | 0.1383 | 0.1674 |  0.2141 |
|     3      | 0.2062 | 0.1428 | 0.2349 | 0.2709 |  0.318  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2407 | 0.1362 | 0.3001 | 0.3648 |  0.4361 |
|     1      | 0.1224 | 0.0598 | 0.142  | 0.1828 |  0.2467 |
|     2      | 0.1315 | 0.0873 | 0.1378 | 0.167  |  0.2134 |
|     3      | 0.2075 | 0.1433 | 0.2355 | 0.2723 |  0.3214 |
|     4      | 0.1609 | 0.1014 | 0.1747 | 0.2129 |  0.2782 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 17:50:38,096: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 131.9278268814087  |   0.264   |    0.158     |    0.325     |      0.46     |
|    1     | 107.53578996658325 |   0.195   |     0.11     |    0.236     |     0.356     |
|    2     |  96.3313934803009  |   0.171   |    0.097     |    0.202     |     0.311     |
|    3     | 39.242899894714355 |   0.174   |    0.101     |    0.204     |     0.312     |
|    4     |  32.1225323677063  |   0.173   |    0.101     |    0.203     |     0.309     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 17:50:38,096: Sum_Training_Time:407.1604425907135
2024-12-27 17:50:38,096: Every_Training_Time:[131.9278268814087, 107.53578996658325, 96.3313934803009, 39.242899894714355, 32.1225323677063]
2024-12-27 17:50:38,096: Forward transfer: 0.010225000000000001 Backward transfer: -0.005374999999999994
2024-12-27 17:51:15,609: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227175042/RELATIONrelation_0.01_2048_1000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.01_2048_1000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.01_2048_1000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 17:51:31,595: Snapshot:0	Epoch:0	Loss:28.797	translation_Loss:28.797	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.8	Hits@10:38.27	Best:19.8
2024-12-27 17:51:43,476: Snapshot:0	Epoch:1	Loss:13.16	translation_Loss:13.16	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.58	Hits@10:44.59	Best:24.58
2024-12-27 17:51:55,051: Snapshot:0	Epoch:2	Loss:5.8	translation_Loss:5.8	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.63	Hits@10:46.87	Best:26.63
2024-12-27 17:52:06,458: Snapshot:0	Epoch:3	Loss:3.052	translation_Loss:3.052	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.0	Hits@10:47.11	Best:27.0
2024-12-27 17:52:17,956: Snapshot:0	Epoch:4	Loss:2.058	translation_Loss:2.058	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.9	Hits@10:47.02	Best:27.0
2024-12-27 17:52:29,939: Snapshot:0	Epoch:5	Loss:1.661	translation_Loss:1.661	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.93	Hits@10:46.76	Best:27.0
2024-12-27 17:52:41,325: Snapshot:0	Epoch:6	Loss:1.453	translation_Loss:1.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.65	Hits@10:46.39	Best:27.0
2024-12-27 17:52:52,803: Snapshot:0	Epoch:7	Loss:1.338	translation_Loss:1.338	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.35	Hits@10:46.29	Best:27.0
2024-12-27 17:53:04,694: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 27.0
2024-12-27 17:53:04,695: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:1.242 MRR:26.53 Best Results: 27.0
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:53:04,695: Snapshot:0	Epoch:8	Loss:1.242	translation_Loss:1.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.53	Hits@10:46.14	Best:27.0
2024-12-27 17:53:16,663: Snapshot:0	Epoch:9	Loss:24.337	translation_Loss:24.301	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.53	Hits@10:46.14	Best:27.0
2024-12-27 17:53:28,237: End of token training: 0 Epoch: 10 Loss:24.305 MRR:26.53 Best Results: 27.0
2024-12-27 17:53:28,237: Snapshot:0	Epoch:10	Loss:24.305	translation_Loss:24.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.53	Hits@10:46.14	Best:27.0
2024-12-27 17:53:28,571: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_1000/0model_best.tar'
2024-12-27 17:53:33,826: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2729 | 0.1646 | 0.3374 | 0.402  |  0.4734 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:54:10,491: Snapshot:1	Epoch:0	Loss:20.768	translation_Loss:16.713	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.055                                                   	MRR:13.78	Hits@10:27.17	Best:13.78
2024-12-27 17:54:21,094: Snapshot:1	Epoch:1	Loss:13.386	translation_Loss:9.956	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.43                                                   	MRR:13.37	Hits@10:27.01	Best:13.78
2024-12-27 17:54:31,714: Snapshot:1	Epoch:2	Loss:12.631	translation_Loss:9.341	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.291                                                   	MRR:13.29	Hits@10:26.89	Best:13.78
2024-12-27 17:54:42,264: Snapshot:1	Epoch:3	Loss:12.38	translation_Loss:9.128	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.252                                                   	MRR:13.25	Hits@10:26.95	Best:13.78
2024-12-27 17:54:52,810: Snapshot:1	Epoch:4	Loss:12.199	translation_Loss:8.988	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.211                                                   	MRR:13.58	Hits@10:26.83	Best:13.78
2024-12-27 17:55:03,416: Snapshot:1	Epoch:5	Loss:12.031	translation_Loss:8.877	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.154                                                   	MRR:13.9	Hits@10:26.98	Best:13.9
2024-12-27 17:55:14,136: Snapshot:1	Epoch:6	Loss:11.918	translation_Loss:8.819	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.099                                                   	MRR:13.85	Hits@10:27.12	Best:13.9
2024-12-27 17:55:24,850: Snapshot:1	Epoch:7	Loss:11.794	translation_Loss:8.737	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.057                                                   	MRR:13.81	Hits@10:26.96	Best:13.9
2024-12-27 17:55:35,375: Snapshot:1	Epoch:8	Loss:11.768	translation_Loss:8.728	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.039                                                   	MRR:13.77	Hits@10:27.08	Best:13.9
2024-12-27 17:55:46,004: Snapshot:1	Epoch:9	Loss:11.714	translation_Loss:8.684	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.03                                                   	MRR:14.1	Hits@10:27.08	Best:14.1
2024-12-27 17:55:56,688: Snapshot:1	Epoch:10	Loss:11.678	translation_Loss:8.657	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.021                                                   	MRR:13.84	Hits@10:27.11	Best:14.1
2024-12-27 17:56:07,204: Snapshot:1	Epoch:11	Loss:11.624	translation_Loss:8.623	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.002                                                   	MRR:13.83	Hits@10:27.2	Best:14.1
2024-12-27 17:56:17,836: Snapshot:1	Epoch:12	Loss:11.579	translation_Loss:8.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.994                                                   	MRR:13.83	Hits@10:27.27	Best:14.1
2024-12-27 17:56:29,030: Snapshot:1	Epoch:13	Loss:11.544	translation_Loss:8.562	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.981                                                   	MRR:13.81	Hits@10:27.25	Best:14.1
2024-12-27 17:56:39,611: Early Stopping! Snapshot: 1 Epoch: 14 Best Results: 14.1
2024-12-27 17:56:39,611: Start to training tokens! Snapshot: 1 Epoch: 14 Loss:11.554 MRR:13.83 Best Results: 14.1
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:56:39,612: Snapshot:1	Epoch:14	Loss:11.554	translation_Loss:8.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.991                                                   	MRR:13.83	Hits@10:27.15	Best:14.1
2024-12-27 17:56:50,041: Snapshot:1	Epoch:15	Loss:32.349	translation_Loss:32.312	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.83	Hits@10:27.15	Best:14.1
2024-12-27 17:57:00,977: End of token training: 1 Epoch: 16 Loss:32.259 MRR:13.83 Best Results: 14.1
2024-12-27 17:57:00,977: Snapshot:1	Epoch:16	Loss:32.259	translation_Loss:32.259	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:13.83	Hits@10:27.15	Best:14.1
2024-12-27 17:57:01,274: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_1000/1model_best.tar'
2024-12-27 17:57:11,310: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2605 | 0.1477 | 0.3282 | 0.3952 |  0.4677 |
|     1      | 0.1403 | 0.0729 | 0.1644 | 0.2112 |  0.2714 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:57:38,665: Snapshot:2	Epoch:0	Loss:13.413	translation_Loss:9.532	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.881                                                   	MRR:17.8	Hits@10:30.96	Best:17.8
2024-12-27 17:57:46,558: Snapshot:2	Epoch:1	Loss:8.347	translation_Loss:5.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.17                                                   	MRR:18.1	Hits@10:31.09	Best:18.1
2024-12-27 17:57:54,555: Snapshot:2	Epoch:2	Loss:8.109	translation_Loss:4.996	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.113                                                   	MRR:18.17	Hits@10:31.07	Best:18.17
2024-12-27 17:58:02,452: Snapshot:2	Epoch:3	Loss:8.085	translation_Loss:4.966	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.118                                                   	MRR:17.94	Hits@10:30.78	Best:18.17
2024-12-27 17:58:10,283: Snapshot:2	Epoch:4	Loss:8.076	translation_Loss:4.955	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.121                                                   	MRR:17.97	Hits@10:30.95	Best:18.17
2024-12-27 17:58:18,195: Snapshot:2	Epoch:5	Loss:8.062	translation_Loss:4.931	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.13                                                   	MRR:18.1	Hits@10:30.84	Best:18.17
2024-12-27 17:58:26,575: Snapshot:2	Epoch:6	Loss:8.042	translation_Loss:4.916	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.126                                                   	MRR:18.02	Hits@10:30.78	Best:18.17
2024-12-27 17:58:34,376: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 18.17
2024-12-27 17:58:34,376: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:8.023 MRR:18.1 Best Results: 18.17
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:58:34,376: Snapshot:2	Epoch:7	Loss:8.023	translation_Loss:4.898	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.125                                                   	MRR:18.1	Hits@10:30.78	Best:18.17
2024-12-27 17:58:42,064: Snapshot:2	Epoch:8	Loss:25.445	translation_Loss:25.407	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.1	Hits@10:30.78	Best:18.17
2024-12-27 17:58:49,761: End of token training: 2 Epoch: 9 Loss:25.398 MRR:18.1 Best Results: 18.17
2024-12-27 17:58:49,761: Snapshot:2	Epoch:9	Loss:25.398	translation_Loss:25.398	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:18.1	Hits@10:30.78	Best:18.17
2024-12-27 17:58:50,071: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_1000/2model_best.tar'
2024-12-27 17:59:03,466: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2335 | 0.1261 | 0.295  | 0.3599 |  0.4339 |
|     1      | 0.1376 | 0.0681 | 0.1625 | 0.2115 |  0.2745 |
|     2      | 0.178  | 0.1127 | 0.1964 | 0.2412 |  0.3067 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 17:59:18,614: Snapshot:3	Epoch:0	Loss:7.057	translation_Loss:5.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.447                                                   	MRR:23.75	Hits@10:37.71	Best:23.75
2024-12-27 17:59:22,689: Snapshot:3	Epoch:1	Loss:3.853	translation_Loss:2.582	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.271                                                   	MRR:24.87	Hits@10:37.82	Best:24.87
2024-12-27 17:59:26,335: Snapshot:3	Epoch:2	Loss:3.166	translation_Loss:2.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.958                                                   	MRR:24.74	Hits@10:37.5	Best:24.87
2024-12-27 17:59:29,973: Snapshot:3	Epoch:3	Loss:3.013	translation_Loss:2.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.89                                                   	MRR:24.95	Hits@10:37.58	Best:24.95
2024-12-27 17:59:33,769: Snapshot:3	Epoch:4	Loss:2.968	translation_Loss:2.099	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.869                                                   	MRR:24.83	Hits@10:37.35	Best:24.95
2024-12-27 17:59:37,537: Snapshot:3	Epoch:5	Loss:2.945	translation_Loss:2.078	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.867                                                   	MRR:24.67	Hits@10:37.48	Best:24.95
2024-12-27 17:59:41,189: Snapshot:3	Epoch:6	Loss:2.933	translation_Loss:2.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.868                                                   	MRR:24.65	Hits@10:37.43	Best:24.95
2024-12-27 17:59:44,843: Snapshot:3	Epoch:7	Loss:2.928	translation_Loss:2.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.861                                                   	MRR:24.93	Hits@10:37.3	Best:24.95
2024-12-27 17:59:48,490: Early Stopping! Snapshot: 3 Epoch: 8 Best Results: 24.95
2024-12-27 17:59:48,490: Start to training tokens! Snapshot: 3 Epoch: 8 Loss:2.923 MRR:24.64 Best Results: 24.95
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 17:59:48,490: Snapshot:3	Epoch:8	Loss:2.923	translation_Loss:2.058	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.865                                                   	MRR:24.64	Hits@10:37.13	Best:24.95
2024-12-27 17:59:52,034: Snapshot:3	Epoch:9	Loss:9.547	translation_Loss:9.513	multi_layer_Loss:0.034	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.64	Hits@10:37.13	Best:24.95
2024-12-27 17:59:55,562: End of token training: 3 Epoch: 10 Loss:9.508 MRR:24.64 Best Results: 24.95
2024-12-27 17:59:55,562: Snapshot:3	Epoch:10	Loss:9.508	translation_Loss:9.507	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:24.64	Hits@10:37.13	Best:24.95
2024-12-27 17:59:55,802: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_1000/3model_best.tar'
2024-12-27 18:00:11,044: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2317 | 0.1251 | 0.294  | 0.3598 |  0.4289 |
|     1      | 0.1408 | 0.0722 | 0.1646 | 0.2125 |  0.2747 |
|     2      | 0.1693 | 0.1041 | 0.1853 | 0.231  |  0.3004 |
|     3      | 0.2484 | 0.1763 | 0.2784 | 0.3189 |  0.3767 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:00:23,737: Snapshot:4	Epoch:0	Loss:4.758	translation_Loss:3.675	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.083                                                   	MRR:19.81	Hits@10:37.95	Best:19.81
2024-12-27 18:00:26,365: Snapshot:4	Epoch:1	Loss:2.397	translation_Loss:1.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.192                                                   	MRR:22.9	Hits@10:42.0	Best:22.9
2024-12-27 18:00:28,932: Snapshot:4	Epoch:2	Loss:1.862	translation_Loss:1.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.824                                                   	MRR:22.63	Hits@10:41.77	Best:22.9
2024-12-27 18:00:31,464: Snapshot:4	Epoch:3	Loss:1.706	translation_Loss:0.948	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.758                                                   	MRR:22.77	Hits@10:42.12	Best:22.9
2024-12-27 18:00:34,033: Snapshot:4	Epoch:4	Loss:1.642	translation_Loss:0.933	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.709                                                   	MRR:22.32	Hits@10:41.56	Best:22.9
2024-12-27 18:00:36,580: Snapshot:4	Epoch:5	Loss:1.638	translation_Loss:0.927	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.711                                                   	MRR:22.22	Hits@10:41.63	Best:22.9
2024-12-27 18:00:39,127: Early Stopping! Snapshot: 4 Epoch: 6 Best Results: 22.9
2024-12-27 18:00:39,127: Start to training tokens! Snapshot: 4 Epoch: 6 Loss:1.635 MRR:21.83 Best Results: 22.9
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:00:39,127: Snapshot:4	Epoch:6	Loss:1.635	translation_Loss:0.933	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.702                                                   	MRR:21.83	Hits@10:41.09	Best:22.9
2024-12-27 18:00:41,647: Snapshot:4	Epoch:7	Loss:5.965	translation_Loss:5.93	multi_layer_Loss:0.035	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.83	Hits@10:41.09	Best:22.9
2024-12-27 18:00:44,159: End of token training: 4 Epoch: 8 Loss:5.935 MRR:21.83 Best Results: 22.9
2024-12-27 18:00:44,159: Snapshot:4	Epoch:8	Loss:5.935	translation_Loss:5.933	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.83	Hits@10:41.09	Best:22.9
2024-12-27 18:00:44,398: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_1000/4model_best.tar'
2024-12-27 18:01:01,206: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2243 | 0.1198 | 0.2853 | 0.3464 |  0.4156 |
|     1      | 0.1377 | 0.069  | 0.162  | 0.2084 |  0.273  |
|     2      | 0.1608 | 0.0979 | 0.1763 | 0.219  |  0.2841 |
|     3      | 0.2402 | 0.1675 | 0.265  | 0.3082 |  0.3776 |
|     4      | 0.2232 | 0.1285 | 0.2458 | 0.3127 |  0.4157 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 18:01:01,208: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2729 | 0.1646 | 0.3374 | 0.402  |  0.4734 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2605 | 0.1477 | 0.3282 | 0.3952 |  0.4677 |
|     1      | 0.1403 | 0.0729 | 0.1644 | 0.2112 |  0.2714 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2335 | 0.1261 | 0.295  | 0.3599 |  0.4339 |
|     1      | 0.1376 | 0.0681 | 0.1625 | 0.2115 |  0.2745 |
|     2      | 0.178  | 0.1127 | 0.1964 | 0.2412 |  0.3067 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2317 | 0.1251 | 0.294  | 0.3598 |  0.4289 |
|     1      | 0.1408 | 0.0722 | 0.1646 | 0.2125 |  0.2747 |
|     2      | 0.1693 | 0.1041 | 0.1853 | 0.231  |  0.3004 |
|     3      | 0.2484 | 0.1763 | 0.2784 | 0.3189 |  0.3767 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2243 | 0.1198 | 0.2853 | 0.3464 |  0.4156 |
|     1      | 0.1377 | 0.069  | 0.162  | 0.2084 |  0.273  |
|     2      | 0.1608 | 0.0979 | 0.1763 | 0.219  |  0.2841 |
|     3      | 0.2402 | 0.1675 | 0.265  | 0.3082 |  0.3776 |
|     4      | 0.2232 | 0.1285 | 0.2458 | 0.3127 |  0.4157 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 18:01:01,209: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 132.62714266777039 |   0.273   |    0.165     |    0.337     |     0.473     |
|    1     | 202.88231229782104 |   0.202   |    0.111     |    0.249     |     0.372     |
|    2     | 94.85662198066711  |   0.185   |    0.102     |    0.222     |     0.344     |
|    3     |  50.1073579788208  |    0.19   |    0.108     |    0.226     |     0.344     |
|    4     | 31.28636384010315  |   0.186   |    0.105     |     0.22     |     0.341     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 18:01:01,209: Sum_Training_Time:511.7597987651825
2024-12-27 18:01:01,209: Every_Training_Time:[132.62714266777039, 202.88231229782104, 94.85662198066711, 50.1073579788208, 31.28636384010315]
2024-12-27 18:01:01,209: Forward transfer: 0.01435 Backward transfer: -0.01915
2024-12-27 18:01:40,352: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227180106/RELATIONrelation_0.01_2048_5000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.01_2048_5000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.01_2048_5000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 18:01:56,144: Snapshot:0	Epoch:0	Loss:28.797	translation_Loss:28.797	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.8	Hits@10:38.3	Best:19.8
2024-12-27 18:02:07,893: Snapshot:0	Epoch:1	Loss:13.165	translation_Loss:13.165	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.59	Hits@10:44.77	Best:24.59
2024-12-27 18:02:19,347: Snapshot:0	Epoch:2	Loss:5.799	translation_Loss:5.799	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.71	Hits@10:46.96	Best:26.71
2024-12-27 18:02:30,766: Snapshot:0	Epoch:3	Loss:3.052	translation_Loss:3.052	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.88	Hits@10:47.2	Best:26.88
2024-12-27 18:02:42,139: Snapshot:0	Epoch:4	Loss:2.06	translation_Loss:2.06	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.93	Hits@10:46.9	Best:26.93
2024-12-27 18:02:54,013: Snapshot:0	Epoch:5	Loss:1.658	translation_Loss:1.658	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.86	Hits@10:46.63	Best:26.93
2024-12-27 18:03:05,361: Snapshot:0	Epoch:6	Loss:1.448	translation_Loss:1.448	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.65	Hits@10:46.51	Best:26.93
2024-12-27 18:03:16,752: Snapshot:0	Epoch:7	Loss:1.333	translation_Loss:1.333	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.43	Hits@10:46.4	Best:26.93
2024-12-27 18:03:28,782: Snapshot:0	Epoch:8	Loss:1.244	translation_Loss:1.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.47	Hits@10:46.21	Best:26.93
2024-12-27 18:03:40,173: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 26.93
2024-12-27 18:03:40,174: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:1.151 MRR:26.44 Best Results: 26.93
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:03:40,174: Snapshot:0	Epoch:9	Loss:1.151	translation_Loss:1.151	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.44	Hits@10:46.18	Best:26.93
2024-12-27 18:03:52,096: Snapshot:0	Epoch:10	Loss:24.222	translation_Loss:24.186	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.44	Hits@10:46.18	Best:26.93
2024-12-27 18:04:03,526: End of token training: 0 Epoch: 11 Loss:24.21 MRR:26.44 Best Results: 26.93
2024-12-27 18:04:03,527: Snapshot:0	Epoch:11	Loss:24.21	translation_Loss:24.21	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.44	Hits@10:46.18	Best:26.93
2024-12-27 18:04:03,869: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_5000/0model_best.tar'
2024-12-27 18:04:09,464: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2738 | 0.1662 | 0.3372 | 0.4028 |  0.4735 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:04:45,749: Snapshot:1	Epoch:0	Loss:21.621	translation_Loss:16.988	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.633                                                   	MRR:12.47	Hits@10:25.45	Best:12.47
2024-12-27 18:04:56,251: Snapshot:1	Epoch:1	Loss:12.806	translation_Loss:10.448	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.358                                                   	MRR:12.24	Hits@10:25.02	Best:12.47
2024-12-27 18:05:06,924: Snapshot:1	Epoch:2	Loss:12.162	translation_Loss:9.868	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.294                                                   	MRR:12.39	Hits@10:24.99	Best:12.47
2024-12-27 18:05:17,660: Snapshot:1	Epoch:3	Loss:11.985	translation_Loss:9.681	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.305                                                   	MRR:12.43	Hits@10:25.04	Best:12.47
2024-12-27 18:05:28,305: Snapshot:1	Epoch:4	Loss:11.877	translation_Loss:9.565	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.312                                                   	MRR:12.28	Hits@10:24.88	Best:12.47
2024-12-27 18:05:38,797: Early Stopping! Snapshot: 1 Epoch: 5 Best Results: 12.47
2024-12-27 18:05:38,797: Start to training tokens! Snapshot: 1 Epoch: 5 Loss:11.804 MRR:12.4 Best Results: 12.47
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:05:38,797: Snapshot:1	Epoch:5	Loss:11.804	translation_Loss:9.498	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.307                                                   	MRR:12.4	Hits@10:24.98	Best:12.47
2024-12-27 18:05:49,146: Snapshot:1	Epoch:6	Loss:33.238	translation_Loss:33.201	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.4	Hits@10:24.98	Best:12.47
2024-12-27 18:05:59,506: End of token training: 1 Epoch: 7 Loss:33.217 MRR:12.4 Best Results: 12.47
2024-12-27 18:05:59,507: Snapshot:1	Epoch:7	Loss:33.217	translation_Loss:33.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:12.4	Hits@10:24.98	Best:12.47
2024-12-27 18:05:59,875: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_5000/1model_best.tar'
2024-12-27 18:06:09,383: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2716 | 0.1623 | 0.3364 | 0.4042 |  0.4733 |
|     1      | 0.1265 | 0.064  | 0.1461 | 0.1877 |  0.2527 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:06:36,529: Snapshot:2	Epoch:0	Loss:16.553	translation_Loss:11.5	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.053                                                   	MRR:15.54	Hits@10:25.09	Best:15.54
2024-12-27 18:06:44,388: Snapshot:2	Epoch:1	Loss:10.332	translation_Loss:7.422	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.911                                                   	MRR:15.89	Hits@10:25.6	Best:15.89
2024-12-27 18:06:52,771: Snapshot:2	Epoch:2	Loss:10.137	translation_Loss:7.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.858                                                   	MRR:15.98	Hits@10:25.64	Best:15.98
2024-12-27 18:07:00,664: Snapshot:2	Epoch:3	Loss:10.098	translation_Loss:7.229	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.869                                                   	MRR:15.99	Hits@10:25.46	Best:15.99
2024-12-27 18:07:08,598: Snapshot:2	Epoch:4	Loss:10.076	translation_Loss:7.192	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.884                                                   	MRR:15.97	Hits@10:25.43	Best:15.99
2024-12-27 18:07:16,453: Snapshot:2	Epoch:5	Loss:10.061	translation_Loss:7.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.894                                                   	MRR:16.09	Hits@10:25.33	Best:16.09
2024-12-27 18:07:24,322: Snapshot:2	Epoch:6	Loss:10.078	translation_Loss:7.175	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.903                                                   	MRR:15.98	Hits@10:25.49	Best:16.09
2024-12-27 18:07:32,668: Snapshot:2	Epoch:7	Loss:10.054	translation_Loss:7.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.902                                                   	MRR:15.99	Hits@10:25.57	Best:16.09
2024-12-27 18:07:40,452: Snapshot:2	Epoch:8	Loss:10.041	translation_Loss:7.141	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.901                                                   	MRR:15.9	Hits@10:25.5	Best:16.09
2024-12-27 18:07:48,323: Snapshot:2	Epoch:9	Loss:10.049	translation_Loss:7.153	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.897                                                   	MRR:15.93	Hits@10:25.52	Best:16.09
2024-12-27 18:07:56,219: Early Stopping! Snapshot: 2 Epoch: 10 Best Results: 16.09
2024-12-27 18:07:56,220: Start to training tokens! Snapshot: 2 Epoch: 10 Loss:10.044 MRR:15.84 Best Results: 16.09
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:07:56,220: Snapshot:2	Epoch:10	Loss:10.044	translation_Loss:7.139	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.904                                                   	MRR:15.84	Hits@10:25.63	Best:16.09
2024-12-27 18:08:03,890: Snapshot:2	Epoch:11	Loss:27.625	translation_Loss:27.587	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.84	Hits@10:25.63	Best:16.09
2024-12-27 18:08:12,033: End of token training: 2 Epoch: 12 Loss:27.573 MRR:15.84 Best Results: 16.09
2024-12-27 18:08:12,033: Snapshot:2	Epoch:12	Loss:27.573	translation_Loss:27.573	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:15.84	Hits@10:25.63	Best:16.09
2024-12-27 18:08:12,333: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_5000/2model_best.tar'
2024-12-27 18:08:25,865: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2497 | 0.1424 | 0.3128 | 0.3788 |  0.4484 |
|     1      | 0.1236 |  0.06  | 0.1425 | 0.1856 |  0.2511 |
|     2      | 0.1551 | 0.1049 | 0.1636 | 0.1972 |  0.2505 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:08:40,716: Snapshot:3	Epoch:0	Loss:9.537	translation_Loss:6.681	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.856                                                   	MRR:21.89	Hits@10:33.94	Best:21.89
2024-12-27 18:08:44,811: Snapshot:3	Epoch:1	Loss:5.038	translation_Loss:3.7	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.337                                                   	MRR:22.5	Hits@10:33.5	Best:22.5
2024-12-27 18:08:48,427: Snapshot:3	Epoch:2	Loss:4.453	translation_Loss:3.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.097                                                   	MRR:22.36	Hits@10:33.37	Best:22.5
2024-12-27 18:08:51,993: Snapshot:3	Epoch:3	Loss:4.31	translation_Loss:3.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.042                                                   	MRR:22.39	Hits@10:33.12	Best:22.5
2024-12-27 18:08:55,620: Snapshot:3	Epoch:4	Loss:4.246	translation_Loss:3.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.012                                                   	MRR:22.26	Hits@10:32.91	Best:22.5
2024-12-27 18:08:59,198: Snapshot:3	Epoch:5	Loss:4.219	translation_Loss:3.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.992                                                   	MRR:22.15	Hits@10:32.87	Best:22.5
2024-12-27 18:09:02,783: Early Stopping! Snapshot: 3 Epoch: 6 Best Results: 22.5
2024-12-27 18:09:02,783: Start to training tokens! Snapshot: 3 Epoch: 6 Loss:4.214 MRR:22.15 Best Results: 22.5
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:09:02,784: Snapshot:3	Epoch:6	Loss:4.214	translation_Loss:3.222	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.993                                                   	MRR:22.15	Hits@10:32.73	Best:22.5
2024-12-27 18:09:06,321: Snapshot:3	Epoch:7	Loss:10.49	translation_Loss:10.456	multi_layer_Loss:0.034	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.15	Hits@10:32.73	Best:22.5
2024-12-27 18:09:09,863: End of token training: 3 Epoch: 8 Loss:10.446 MRR:22.15 Best Results: 22.5
2024-12-27 18:09:09,863: Snapshot:3	Epoch:8	Loss:10.446	translation_Loss:10.445	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.15	Hits@10:32.73	Best:22.5
2024-12-27 18:09:10,098: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_5000/3model_best.tar'
2024-12-27 18:09:25,749: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2449 | 0.1382 | 0.3062 | 0.3729 |  0.4463 |
|     1      | 0.1243 | 0.0607 | 0.1428 | 0.1859 |  0.2515 |
|     2      | 0.1562 | 0.105  | 0.1651 | 0.1982 |  0.2532 |
|     3      | 0.2211 | 0.1556 | 0.2513 | 0.2839 |  0.3369 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:09:38,017: Snapshot:4	Epoch:0	Loss:7.542	translation_Loss:4.906	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.636                                                   	MRR:17.31	Hits@10:32.57	Best:17.31
2024-12-27 18:09:40,644: Snapshot:4	Epoch:1	Loss:4.332	translation_Loss:2.5	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.832                                                   	MRR:19.08	Hits@10:34.46	Best:19.08
2024-12-27 18:09:43,253: Snapshot:4	Epoch:2	Loss:3.627	translation_Loss:2.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.424                                                   	MRR:18.83	Hits@10:35.36	Best:19.08
2024-12-27 18:09:45,797: Snapshot:4	Epoch:3	Loss:3.416	translation_Loss:2.105	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.311                                                   	MRR:18.88	Hits@10:35.3	Best:19.08
2024-12-27 18:09:48,350: Snapshot:4	Epoch:4	Loss:3.332	translation_Loss:2.087	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.245                                                   	MRR:18.74	Hits@10:35.31	Best:19.08
2024-12-27 18:09:50,924: Snapshot:4	Epoch:5	Loss:3.308	translation_Loss:2.075	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.233                                                   	MRR:18.7	Hits@10:35.24	Best:19.08
2024-12-27 18:09:53,470: Early Stopping! Snapshot: 4 Epoch: 6 Best Results: 19.08
2024-12-27 18:09:53,470: Start to training tokens! Snapshot: 4 Epoch: 6 Loss:3.294 MRR:18.55 Best Results: 19.08
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:09:53,470: Snapshot:4	Epoch:6	Loss:3.294	translation_Loss:2.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.229                                                   	MRR:18.55	Hits@10:35.59	Best:19.08
2024-12-27 18:09:55,948: Snapshot:4	Epoch:7	Loss:6.91	translation_Loss:6.875	multi_layer_Loss:0.035	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.55	Hits@10:35.59	Best:19.08
2024-12-27 18:09:58,462: End of token training: 4 Epoch: 8 Loss:6.867 MRR:18.55 Best Results: 19.08
2024-12-27 18:09:58,463: Snapshot:4	Epoch:8	Loss:6.867	translation_Loss:6.866	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:18.55	Hits@10:35.59	Best:19.08
2024-12-27 18:09:58,698: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_5000/4model_best.tar'
2024-12-27 18:10:15,824: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2436 | 0.137  | 0.3046 | 0.373  |  0.444  |
|     1      | 0.1242 | 0.0601 | 0.1433 | 0.1866 |  0.253  |
|     2      | 0.1486 | 0.0959 | 0.1577 | 0.1928 |  0.2486 |
|     3      | 0.2269 | 0.1583 | 0.2579 | 0.2937 |  0.3512 |
|     4      | 0.1883 | 0.1081 | 0.2022 | 0.2605 |  0.3483 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 18:10:15,826: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2738 | 0.1662 | 0.3372 | 0.4028 |  0.4735 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2716 | 0.1623 | 0.3364 | 0.4042 |  0.4733 |
|     1      | 0.1265 | 0.064  | 0.1461 | 0.1877 |  0.2527 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2497 | 0.1424 | 0.3128 | 0.3788 |  0.4484 |
|     1      | 0.1236 |  0.06  | 0.1425 | 0.1856 |  0.2511 |
|     2      | 0.1551 | 0.1049 | 0.1636 | 0.1972 |  0.2505 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2449 | 0.1382 | 0.3062 | 0.3729 |  0.4463 |
|     1      | 0.1243 | 0.0607 | 0.1428 | 0.1859 |  0.2515 |
|     2      | 0.1562 | 0.105  | 0.1651 | 0.1982 |  0.2532 |
|     3      | 0.2211 | 0.1556 | 0.2513 | 0.2839 |  0.3369 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2436 | 0.137  | 0.3046 | 0.373  |  0.444  |
|     1      | 0.1242 | 0.0601 | 0.1433 | 0.1866 |  0.253  |
|     2      | 0.1486 | 0.0959 | 0.1577 | 0.1928 |  0.2486 |
|     3      | 0.2269 | 0.1583 | 0.2579 | 0.2937 |  0.3512 |
|     4      | 0.1883 | 0.1081 | 0.2022 | 0.2605 |  0.3483 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 18:10:15,827: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 143.17442965507507 |   0.274   |    0.166     |    0.337     |     0.473     |
|    1     | 105.69705748558044 |   0.201   |    0.114     |    0.244     |     0.366     |
|    2     | 119.10021638870239 |    0.18   |    0.103     |    0.213     |     0.326     |
|    3     | 42.390061378479004 |   0.183   |    0.107     |    0.215     |     0.327     |
|    4     | 31.214359998703003 |   0.182   |    0.105     |    0.213     |     0.329     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 18:10:15,827: Sum_Training_Time:441.5761249065399
2024-12-27 18:10:15,827: Every_Training_Time:[143.17442965507507, 105.69705748558044, 119.10021638870239, 42.390061378479004, 31.214359998703003]
2024-12-27 18:10:15,827: Forward transfer: 0.011199999999999998 Backward transfer: -0.008299999999999988
2024-12-27 18:10:53,012: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.01, lifelong_name='double_tokened', log_path='./logs/20241227181019/RELATIONrelation_0.01_2048_10000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.01_2048_10000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.01_2048_10000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 18:11:08,790: Snapshot:0	Epoch:0	Loss:28.797	translation_Loss:28.797	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.79	Hits@10:38.3	Best:19.79
2024-12-27 18:11:20,615: Snapshot:0	Epoch:1	Loss:13.16	translation_Loss:13.16	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.61	Hits@10:44.65	Best:24.61
2024-12-27 18:11:32,113: Snapshot:0	Epoch:2	Loss:5.799	translation_Loss:5.799	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.6	Hits@10:46.91	Best:26.6
2024-12-27 18:11:43,501: Snapshot:0	Epoch:3	Loss:3.052	translation_Loss:3.052	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.84	Hits@10:47.04	Best:26.84
2024-12-27 18:11:54,860: Snapshot:0	Epoch:4	Loss:2.053	translation_Loss:2.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.78	Hits@10:46.85	Best:26.84
2024-12-27 18:12:06,833: Snapshot:0	Epoch:5	Loss:1.654	translation_Loss:1.654	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.73	Hits@10:46.81	Best:26.84
2024-12-27 18:12:18,141: Snapshot:0	Epoch:6	Loss:1.453	translation_Loss:1.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.73	Hits@10:46.45	Best:26.84
2024-12-27 18:12:29,492: Snapshot:0	Epoch:7	Loss:1.33	translation_Loss:1.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.44	Hits@10:46.23	Best:26.84
2024-12-27 18:12:41,335: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 26.84
2024-12-27 18:12:41,336: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:1.243 MRR:26.5 Best Results: 26.84
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:12:41,336: Snapshot:0	Epoch:8	Loss:1.243	translation_Loss:1.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.5	Hits@10:46.23	Best:26.84
2024-12-27 18:12:53,243: Snapshot:0	Epoch:9	Loss:24.315	translation_Loss:24.279	multi_layer_Loss:0.036	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.5	Hits@10:46.23	Best:26.84
2024-12-27 18:13:04,722: End of token training: 0 Epoch: 10 Loss:24.282 MRR:26.5 Best Results: 26.84
2024-12-27 18:13:04,722: Snapshot:0	Epoch:10	Loss:24.282	translation_Loss:24.282	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.5	Hits@10:46.23	Best:26.84
2024-12-27 18:13:05,028: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_10000/0model_best.tar'
2024-12-27 18:13:10,360: 
+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.272 | 0.1626 | 0.3373 | 0.4022 |  0.4749 |
+------------+-------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:13:46,768: Snapshot:1	Epoch:0	Loss:24.291	translation_Loss:17.85	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.441                                                   	MRR:12.61	Hits@10:24.92	Best:12.61
2024-12-27 18:13:57,194: Snapshot:1	Epoch:1	Loss:13.209	translation_Loss:11.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.007                                                   	MRR:12.48	Hits@10:24.84	Best:12.61
2024-12-27 18:14:07,812: Snapshot:1	Epoch:2	Loss:12.623	translation_Loss:10.592	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.031                                                   	MRR:12.44	Hits@10:24.68	Best:12.61
2024-12-27 18:14:18,345: Snapshot:1	Epoch:3	Loss:12.455	translation_Loss:10.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.065                                                   	MRR:12.48	Hits@10:24.76	Best:12.61
2024-12-27 18:14:28,885: Snapshot:1	Epoch:4	Loss:12.342	translation_Loss:10.259	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.083                                                   	MRR:12.46	Hits@10:24.73	Best:12.61
2024-12-27 18:14:39,353: Early Stopping! Snapshot: 1 Epoch: 5 Best Results: 12.61
2024-12-27 18:14:39,353: Start to training tokens! Snapshot: 1 Epoch: 5 Loss:12.256 MRR:12.31 Best Results: 12.61
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:14:39,354: Snapshot:1	Epoch:5	Loss:12.256	translation_Loss:10.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.098                                                   	MRR:12.31	Hits@10:24.77	Best:12.61
2024-12-27 18:14:49,731: Snapshot:1	Epoch:6	Loss:33.469	translation_Loss:33.432	multi_layer_Loss:0.037	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.31	Hits@10:24.77	Best:12.61
2024-12-27 18:15:00,047: End of token training: 1 Epoch: 7 Loss:33.483 MRR:12.31 Best Results: 12.61
2024-12-27 18:15:00,048: Snapshot:1	Epoch:7	Loss:33.483	translation_Loss:33.483	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:12.31	Hits@10:24.77	Best:12.61
2024-12-27 18:15:00,397: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_10000/1model_best.tar'
2024-12-27 18:15:09,975: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2713 | 0.1615 | 0.3366 | 0.4028 |  0.475  |
|     1      | 0.1264 | 0.0646 | 0.1459 | 0.1862 |  0.2479 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:15:37,484: Snapshot:2	Epoch:0	Loss:19.616	translation_Loss:12.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.695                                                   	MRR:14.25	Hits@10:22.73	Best:14.25
2024-12-27 18:15:45,346: Snapshot:2	Epoch:1	Loss:11.473	translation_Loss:8.944	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.529                                                   	MRR:14.59	Hits@10:23.06	Best:14.59
2024-12-27 18:15:53,179: Snapshot:2	Epoch:2	Loss:11.283	translation_Loss:8.777	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.506                                                   	MRR:14.57	Hits@10:23.09	Best:14.59
2024-12-27 18:16:00,995: Snapshot:2	Epoch:3	Loss:11.272	translation_Loss:8.727	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.545                                                   	MRR:14.61	Hits@10:23.16	Best:14.61
2024-12-27 18:16:08,766: Snapshot:2	Epoch:4	Loss:11.285	translation_Loss:8.717	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.568                                                   	MRR:14.43	Hits@10:22.92	Best:14.61
2024-12-27 18:16:16,603: Snapshot:2	Epoch:5	Loss:11.276	translation_Loss:8.693	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.583                                                   	MRR:14.43	Hits@10:22.97	Best:14.61
2024-12-27 18:16:24,381: Snapshot:2	Epoch:6	Loss:11.268	translation_Loss:8.662	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.606                                                   	MRR:14.44	Hits@10:23.02	Best:14.61
2024-12-27 18:16:32,174: Snapshot:2	Epoch:7	Loss:11.284	translation_Loss:8.677	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.608                                                   	MRR:14.4	Hits@10:23.0	Best:14.61
2024-12-27 18:16:40,400: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 14.61
2024-12-27 18:16:40,400: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:11.268 MRR:14.5 Best Results: 14.61
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:16:40,400: Snapshot:2	Epoch:8	Loss:11.268	translation_Loss:8.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.618                                                   	MRR:14.5	Hits@10:23.02	Best:14.61
2024-12-27 18:16:48,069: Snapshot:2	Epoch:9	Loss:28.444	translation_Loss:28.406	multi_layer_Loss:0.038	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.5	Hits@10:23.02	Best:14.61
2024-12-27 18:16:55,806: End of token training: 2 Epoch: 10 Loss:28.408 MRR:14.5 Best Results: 14.61
2024-12-27 18:16:55,806: Snapshot:2	Epoch:10	Loss:28.408	translation_Loss:28.408	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:14.5	Hits@10:23.02	Best:14.61
2024-12-27 18:16:56,126: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_10000/2model_best.tar'
2024-12-27 18:17:09,413: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2527 | 0.145  | 0.3162 | 0.3811 |  0.4525 |
|     1      | 0.1263 | 0.0646 | 0.1448 | 0.1861 |  0.2487 |
|     2      | 0.1426 | 0.0962 | 0.1507 | 0.1811 |  0.2279 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:17:24,701: Snapshot:3	Epoch:0	Loss:11.661	translation_Loss:7.032	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.629                                                   	MRR:20.9	Hits@10:32.72	Best:20.9
2024-12-27 18:17:28,418: Snapshot:3	Epoch:1	Loss:5.441	translation_Loss:4.108	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.333                                                   	MRR:21.38	Hits@10:32.36	Best:21.38
2024-12-27 18:17:31,981: Snapshot:3	Epoch:2	Loss:4.593	translation_Loss:3.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.859                                                   	MRR:21.19	Hits@10:31.8	Best:21.38
2024-12-27 18:17:35,928: Snapshot:3	Epoch:3	Loss:4.401	translation_Loss:3.635	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.766                                                   	MRR:21.22	Hits@10:31.8	Best:21.38
2024-12-27 18:17:39,496: Snapshot:3	Epoch:4	Loss:4.377	translation_Loss:3.625	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.751                                                   	MRR:21.31	Hits@10:31.73	Best:21.38
2024-12-27 18:17:43,116: Snapshot:3	Epoch:5	Loss:4.351	translation_Loss:3.596	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.755                                                   	MRR:21.08	Hits@10:31.54	Best:21.38
2024-12-27 18:17:46,678: Early Stopping! Snapshot: 3 Epoch: 6 Best Results: 21.38
2024-12-27 18:17:46,679: Start to training tokens! Snapshot: 3 Epoch: 6 Loss:4.348 MRR:21.12 Best Results: 21.38
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:17:46,679: Snapshot:3	Epoch:6	Loss:4.348	translation_Loss:3.591	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.757                                                   	MRR:21.12	Hits@10:31.53	Best:21.38
2024-12-27 18:17:50,212: Snapshot:3	Epoch:7	Loss:10.575	translation_Loss:10.54	multi_layer_Loss:0.034	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.12	Hits@10:31.53	Best:21.38
2024-12-27 18:17:53,709: End of token training: 3 Epoch: 8 Loss:10.564 MRR:21.12 Best Results: 21.38
2024-12-27 18:17:53,710: Snapshot:3	Epoch:8	Loss:10.564	translation_Loss:10.563	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.12	Hits@10:31.53	Best:21.38
2024-12-27 18:17:54,056: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_10000/3model_best.tar'
2024-12-27 18:18:08,935: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2501 | 0.142  | 0.3134 |  0.38  |  0.4515 |
|     1      | 0.1266 | 0.0649 | 0.1448 | 0.1867 |  0.2489 |
|     2      | 0.1444 | 0.0974 | 0.1532 | 0.183  |  0.2317 |
|     3      | 0.2106 | 0.1447 | 0.2407 | 0.2773 |  0.3224 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:18:21,402: Snapshot:4	Epoch:0	Loss:9.866	translation_Loss:5.613	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.253                                                   	MRR:16.01	Hits@10:30.53	Best:16.01
2024-12-27 18:18:24,068: Snapshot:4	Epoch:1	Loss:5.54	translation_Loss:3.628	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.913                                                   	MRR:17.69	Hits@10:31.06	Best:17.69
2024-12-27 18:18:26,651: Snapshot:4	Epoch:2	Loss:4.657	translation_Loss:3.323	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.334                                                   	MRR:17.9	Hits@10:31.49	Best:17.9
2024-12-27 18:18:29,156: Snapshot:4	Epoch:3	Loss:4.394	translation_Loss:3.222	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.172                                                   	MRR:17.71	Hits@10:31.58	Best:17.9
2024-12-27 18:18:31,703: Snapshot:4	Epoch:4	Loss:4.305	translation_Loss:3.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.107                                                   	MRR:17.75	Hits@10:31.5	Best:17.9
2024-12-27 18:18:34,242: Snapshot:4	Epoch:5	Loss:4.256	translation_Loss:3.166	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.09                                                   	MRR:17.76	Hits@10:31.74	Best:17.9
2024-12-27 18:18:36,789: Snapshot:4	Epoch:6	Loss:4.234	translation_Loss:3.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.083                                                   	MRR:17.46	Hits@10:31.52	Best:17.9
2024-12-27 18:18:39,354: Early Stopping! Snapshot: 4 Epoch: 7 Best Results: 17.9
2024-12-27 18:18:39,354: Start to training tokens! Snapshot: 4 Epoch: 7 Loss:4.22 MRR:17.57 Best Results: 17.9
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:18:39,355: Snapshot:4	Epoch:7	Loss:4.22	translation_Loss:3.145	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.074                                                   	MRR:17.57	Hits@10:31.32	Best:17.9
2024-12-27 18:18:41,842: Snapshot:4	Epoch:8	Loss:7.601	translation_Loss:7.566	multi_layer_Loss:0.035	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.57	Hits@10:31.32	Best:17.9
2024-12-27 18:18:44,341: End of token training: 4 Epoch: 9 Loss:7.563 MRR:17.57 Best Results: 17.9
2024-12-27 18:18:44,341: Snapshot:4	Epoch:9	Loss:7.563	translation_Loss:7.562	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:17.57	Hits@10:31.32	Best:17.9
2024-12-27 18:18:44,573: => loading checkpoint './checkpoint/RELATIONrelation_0.01_2048_10000/4model_best.tar'
2024-12-27 18:19:01,213: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2498 | 0.142  | 0.3133 |  0.38  |  0.4506 |
|     1      | 0.1263 | 0.0642 | 0.1455 | 0.1862 |  0.2491 |
|     2      | 0.1436 | 0.0966 | 0.152  | 0.1832 |  0.2307 |
|     3      | 0.2174 | 0.1495 | 0.2486 | 0.2862 |  0.3355 |
|     4      | 0.1714 | 0.1026 | 0.1843 | 0.2313 |  0.3106 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 18:19:01,215: Final Result:
[+------------+-------+--------+--------+--------+---------+
| Snapshot:0 |  MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+-------+--------+--------+--------+---------+
|     0      | 0.272 | 0.1626 | 0.3373 | 0.4022 |  0.4749 |
+------------+-------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2713 | 0.1615 | 0.3366 | 0.4028 |  0.475  |
|     1      | 0.1264 | 0.0646 | 0.1459 | 0.1862 |  0.2479 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2527 | 0.145  | 0.3162 | 0.3811 |  0.4525 |
|     1      | 0.1263 | 0.0646 | 0.1448 | 0.1861 |  0.2487 |
|     2      | 0.1426 | 0.0962 | 0.1507 | 0.1811 |  0.2279 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2501 | 0.142  | 0.3134 |  0.38  |  0.4515 |
|     1      | 0.1266 | 0.0649 | 0.1448 | 0.1867 |  0.2489 |
|     2      | 0.1444 | 0.0974 | 0.1532 | 0.183  |  0.2317 |
|     3      | 0.2106 | 0.1447 | 0.2407 | 0.2773 |  0.3224 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2498 | 0.142  | 0.3133 |  0.38  |  0.4506 |
|     1      | 0.1263 | 0.0642 | 0.1455 | 0.1862 |  0.2491 |
|     2      | 0.1436 | 0.0966 | 0.152  | 0.1832 |  0.2307 |
|     3      | 0.2174 | 0.1495 | 0.2486 | 0.2862 |  0.3355 |
|     4      | 0.1714 | 0.1026 | 0.1843 | 0.2313 |  0.3106 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 18:19:01,216: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 131.70929980278015 |   0.272   |    0.163     |    0.337     |     0.475     |
|    1     | 105.43139266967773 |   0.201   |    0.114     |    0.244     |     0.365     |
|    2     | 102.2726731300354  |   0.179   |    0.103     |    0.212     |     0.321     |
|    3     | 42.06460118293762  |   0.182   |    0.107     |    0.214     |     0.322     |
|    4     | 33.63029980659485  |   0.181   |    0.107     |    0.213     |     0.322     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 18:19:01,216: Sum_Training_Time:415.10826659202576
2024-12-27 18:19:01,216: Every_Training_Time:[131.70929980278015, 105.43139266967773, 102.2726731300354, 42.06460118293762, 33.63029980659485]
2024-12-27 18:19:01,216: Forward transfer: 0.010849999999999999 Backward transfer: -0.00362500000000001
2024-12-27 18:19:38,767: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227181905/RELATIONrelation_0.001_512_1000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.001_512_1000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.001_512_1000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 18:19:54,827: Snapshot:0	Epoch:0	Loss:118.278	translation_Loss:118.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.09	Hits@10:38.43	Best:19.09
2024-12-27 18:20:06,518: Snapshot:0	Epoch:1	Loss:50.418	translation_Loss:50.418	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.1	Hits@10:44.38	Best:24.1
2024-12-27 18:20:18,251: Snapshot:0	Epoch:2	Loss:22.406	translation_Loss:22.406	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.95	Hits@10:46.14	Best:25.95
2024-12-27 18:20:29,855: Snapshot:0	Epoch:3	Loss:12.461	translation_Loss:12.461	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.31	Hits@10:46.41	Best:26.31
2024-12-27 18:20:41,454: Snapshot:0	Epoch:4	Loss:8.646	translation_Loss:8.646	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.3	Hits@10:46.32	Best:26.31
2024-12-27 18:20:53,104: Snapshot:0	Epoch:5	Loss:6.951	translation_Loss:6.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.13	Hits@10:46.15	Best:26.31
2024-12-27 18:21:04,901: Snapshot:0	Epoch:6	Loss:5.99	translation_Loss:5.99	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.09	Hits@10:45.8	Best:26.31
2024-12-27 18:21:17,186: Snapshot:0	Epoch:7	Loss:5.389	translation_Loss:5.389	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.94	Hits@10:45.4	Best:26.31
2024-12-27 18:21:28,903: Early Stopping! Snapshot: 0 Epoch: 8 Best Results: 26.31
2024-12-27 18:21:28,903: Start to training tokens! Snapshot: 0 Epoch: 8 Loss:4.971 MRR:25.83 Best Results: 26.31
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:21:28,903: Snapshot:0	Epoch:8	Loss:4.971	translation_Loss:4.971	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.83	Hits@10:45.28	Best:26.31
2024-12-27 18:21:41,300: Snapshot:0	Epoch:9	Loss:98.944	translation_Loss:98.787	multi_layer_Loss:0.157	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.83	Hits@10:45.28	Best:26.31
2024-12-27 18:21:53,194: End of token training: 0 Epoch: 10 Loss:98.789 MRR:25.83 Best Results: 26.31
2024-12-27 18:21:53,195: Snapshot:0	Epoch:10	Loss:98.789	translation_Loss:98.789	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.83	Hits@10:45.28	Best:26.31
2024-12-27 18:21:53,542: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_1000/0model_best.tar'
2024-12-27 18:21:59,246: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2678 | 0.1609 | 0.3282 | 0.3954 |  0.4683 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:22:36,451: Snapshot:1	Epoch:0	Loss:77.141	translation_Loss:67.747	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.394                                                   	MRR:16.53	Hits@10:32.29	Best:16.53
2024-12-27 18:22:47,851: Snapshot:1	Epoch:1	Loss:34.995	translation_Loss:20.692	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.303                                                   	MRR:16.79	Hits@10:32.43	Best:16.79
2024-12-27 18:22:59,099: Snapshot:1	Epoch:2	Loss:31.355	translation_Loss:16.469	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:14.887                                                   	MRR:16.65	Hits@10:32.2	Best:16.79
2024-12-27 18:23:10,249: Snapshot:1	Epoch:3	Loss:30.498	translation_Loss:15.478	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:15.021                                                   	MRR:16.71	Hits@10:32.22	Best:16.79
2024-12-27 18:23:21,919: Snapshot:1	Epoch:4	Loss:30.084	translation_Loss:15.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:15.07                                                   	MRR:16.17	Hits@10:31.92	Best:16.79
2024-12-27 18:23:33,159: Snapshot:1	Epoch:5	Loss:29.874	translation_Loss:14.781	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:15.092                                                   	MRR:16.59	Hits@10:32.25	Best:16.79
2024-12-27 18:23:44,357: Early Stopping! Snapshot: 1 Epoch: 6 Best Results: 16.79
2024-12-27 18:23:44,357: Start to training tokens! Snapshot: 1 Epoch: 6 Loss:29.724 MRR:16.37 Best Results: 16.79
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:23:44,357: Snapshot:1	Epoch:6	Loss:29.724	translation_Loss:14.677	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:15.046                                                   	MRR:16.37	Hits@10:31.84	Best:16.79
2024-12-27 18:23:55,189: Snapshot:1	Epoch:7	Loss:114.319	translation_Loss:114.161	multi_layer_Loss:0.158	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.37	Hits@10:31.84	Best:16.79
2024-12-27 18:24:06,218: End of token training: 1 Epoch: 8 Loss:113.874 MRR:16.37 Best Results: 16.79
2024-12-27 18:24:06,219: Snapshot:1	Epoch:8	Loss:113.874	translation_Loss:113.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:16.37	Hits@10:31.84	Best:16.79
2024-12-27 18:24:06,522: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_1000/1model_best.tar'
2024-12-27 18:24:16,570: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2298 | 0.1297 | 0.2832 | 0.3442 |  0.4156 |
|     1      | 0.1675 | 0.0857 | 0.2004 | 0.2552 |  0.3232 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:24:45,431: Snapshot:2	Epoch:0	Loss:41.353	translation_Loss:35.547	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.806                                                   	MRR:20.9	Hits@10:37.44	Best:20.9
2024-12-27 18:24:53,901: Snapshot:2	Epoch:1	Loss:14.893	translation_Loss:7.83	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.063                                                   	MRR:21.23	Hits@10:38.14	Best:21.23
2024-12-27 18:25:02,404: Snapshot:2	Epoch:2	Loss:13.074	translation_Loss:5.993	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.081                                                   	MRR:20.73	Hits@10:37.46	Best:21.23
2024-12-27 18:25:10,833: Snapshot:2	Epoch:3	Loss:12.738	translation_Loss:5.54	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.198                                                   	MRR:20.29	Hits@10:36.51	Best:21.23
2024-12-27 18:25:19,243: Snapshot:2	Epoch:4	Loss:12.677	translation_Loss:5.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.263                                                   	MRR:20.28	Hits@10:36.65	Best:21.23
2024-12-27 18:25:27,681: Snapshot:2	Epoch:5	Loss:12.632	translation_Loss:5.309	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.324                                                   	MRR:20.1	Hits@10:36.13	Best:21.23
2024-12-27 18:25:36,032: Early Stopping! Snapshot: 2 Epoch: 6 Best Results: 21.23
2024-12-27 18:25:36,032: Start to training tokens! Snapshot: 2 Epoch: 6 Loss:12.639 MRR:20.01 Best Results: 21.23
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:25:36,033: Snapshot:2	Epoch:6	Loss:12.639	translation_Loss:5.283	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.357                                                   	MRR:20.01	Hits@10:36.19	Best:21.23
2024-12-27 18:25:44,210: Snapshot:2	Epoch:7	Loss:78.494	translation_Loss:78.329	multi_layer_Loss:0.165	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.01	Hits@10:36.19	Best:21.23
2024-12-27 18:25:52,279: End of token training: 2 Epoch: 8 Loss:78.338 MRR:20.01 Best Results: 21.23
2024-12-27 18:25:52,279: Snapshot:2	Epoch:8	Loss:78.338	translation_Loss:78.338	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.01	Hits@10:36.19	Best:21.23
2024-12-27 18:25:52,633: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_1000/2model_best.tar'
2024-12-27 18:26:05,499: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1862 | 0.1012 | 0.2285 | 0.2837 |  0.3449 |
|     1      | 0.1451 | 0.0711 | 0.1742 | 0.221  |  0.2806 |
|     2      | 0.211  | 0.1261 | 0.2359 | 0.2949 |   0.38  |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:26:21,062: Snapshot:3	Epoch:0	Loss:23.789	translation_Loss:22.129	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.66                                                   	MRR:25.95	Hits@10:43.17	Best:25.95
2024-12-27 18:26:25,008: Snapshot:3	Epoch:1	Loss:6.687	translation_Loss:4.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.618                                                   	MRR:29.76	Hits@10:46.58	Best:29.76
2024-12-27 18:26:28,938: Snapshot:3	Epoch:2	Loss:4.026	translation_Loss:1.459	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.567                                                   	MRR:30.16	Hits@10:46.34	Best:30.16
2024-12-27 18:26:32,828: Snapshot:3	Epoch:3	Loss:3.482	translation_Loss:1.001	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.481                                                   	MRR:30.6	Hits@10:47.18	Best:30.6
2024-12-27 18:26:36,706: Snapshot:3	Epoch:4	Loss:3.32	translation_Loss:0.887	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.433                                                   	MRR:29.76	Hits@10:46.23	Best:30.6
2024-12-27 18:26:40,539: Snapshot:3	Epoch:5	Loss:3.203	translation_Loss:0.821	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.382                                                   	MRR:30.04	Hits@10:46.25	Best:30.6
2024-12-27 18:26:44,414: Snapshot:3	Epoch:6	Loss:3.185	translation_Loss:0.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.377                                                   	MRR:29.86	Hits@10:45.9	Best:30.6
2024-12-27 18:26:48,230: Snapshot:3	Epoch:7	Loss:3.178	translation_Loss:0.802	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.375                                                   	MRR:29.72	Hits@10:46.18	Best:30.6
2024-12-27 18:26:52,043: Early Stopping! Snapshot: 3 Epoch: 8 Best Results: 30.6
2024-12-27 18:26:52,043: Start to training tokens! Snapshot: 3 Epoch: 8 Loss:3.118 MRR:29.71 Best Results: 30.6
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:26:52,043: Snapshot:3	Epoch:8	Loss:3.118	translation_Loss:0.759	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.359                                                   	MRR:29.71	Hits@10:46.01	Best:30.6
2024-12-27 18:26:55,778: Snapshot:3	Epoch:9	Loss:29.21	translation_Loss:29.067	multi_layer_Loss:0.142	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:29.71	Hits@10:46.01	Best:30.6
2024-12-27 18:26:59,482: End of token training: 3 Epoch: 10 Loss:29.104 MRR:29.71 Best Results: 30.6
2024-12-27 18:26:59,482: Snapshot:3	Epoch:10	Loss:29.104	translation_Loss:29.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:29.71	Hits@10:46.01	Best:30.6
2024-12-27 18:26:59,839: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_1000/3model_best.tar'
2024-12-27 18:27:15,332: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1822 | 0.1003 | 0.2241 | 0.2756 |  0.3354 |
|     1      | 0.1379 | 0.0661 | 0.1627 | 0.2102 |  0.2727 |
|     2      | 0.1725 | 0.0986 | 0.186  | 0.2344 |  0.3192 |
|     3      | 0.3045 | 0.2143 | 0.3452 | 0.3958 |  0.4691 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:27:28,309: Snapshot:4	Epoch:0	Loss:12.741	translation_Loss:11.801	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.939                                                   	MRR:21.03	Hits@10:43.33	Best:21.03
2024-12-27 18:27:31,077: Snapshot:4	Epoch:1	Loss:3.361	translation_Loss:2.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.285                                                   	MRR:27.59	Hits@10:49.42	Best:27.59
2024-12-27 18:27:33,909: Snapshot:4	Epoch:2	Loss:1.694	translation_Loss:0.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.188                                                   	MRR:28.21	Hits@10:50.64	Best:28.21
2024-12-27 18:27:36,667: Snapshot:4	Epoch:3	Loss:1.392	translation_Loss:0.336	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.055                                                   	MRR:27.97	Hits@10:49.99	Best:28.21
2024-12-27 18:27:39,413: Snapshot:4	Epoch:4	Loss:1.295	translation_Loss:0.283	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.012                                                   	MRR:28.41	Hits@10:51.24	Best:28.41
2024-12-27 18:27:42,210: Snapshot:4	Epoch:5	Loss:1.256	translation_Loss:0.279	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.977                                                   	MRR:28.7	Hits@10:51.59	Best:28.7
2024-12-27 18:27:44,990: Snapshot:4	Epoch:6	Loss:1.225	translation_Loss:0.265	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.959                                                   	MRR:28.12	Hits@10:51.76	Best:28.7
2024-12-27 18:27:47,711: Snapshot:4	Epoch:7	Loss:1.202	translation_Loss:0.259	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.943                                                   	MRR:28.36	Hits@10:51.55	Best:28.7
2024-12-27 18:27:50,428: Snapshot:4	Epoch:8	Loss:1.202	translation_Loss:0.26	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.943                                                   	MRR:28.49	Hits@10:51.93	Best:28.7
2024-12-27 18:27:53,191: Snapshot:4	Epoch:9	Loss:1.202	translation_Loss:0.264	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.939                                                   	MRR:28.15	Hits@10:51.68	Best:28.7
2024-12-27 18:27:55,926: Early Stopping! Snapshot: 4 Epoch: 10 Best Results: 28.7
2024-12-27 18:27:55,927: Start to training tokens! Snapshot: 4 Epoch: 10 Loss:1.188 MRR:28.27 Best Results: 28.7
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:27:55,927: Snapshot:4	Epoch:10	Loss:1.188	translation_Loss:0.263	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.925                                                   	MRR:28.27	Hits@10:51.32	Best:28.7
2024-12-27 18:27:58,561: Snapshot:4	Epoch:11	Loss:16.282	translation_Loss:16.126	multi_layer_Loss:0.156	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.27	Hits@10:51.32	Best:28.7
2024-12-27 18:28:01,198: End of token training: 4 Epoch: 12 Loss:16.129 MRR:28.27 Best Results: 28.7
2024-12-27 18:28:01,198: Snapshot:4	Epoch:12	Loss:16.129	translation_Loss:16.129	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:28.27	Hits@10:51.32	Best:28.7
2024-12-27 18:28:01,553: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_1000/4model_best.tar'
2024-12-27 18:28:18,223: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1716 | 0.0938 | 0.2104 | 0.2584 |  0.3155 |
|     1      | 0.133  | 0.0619 | 0.1578 | 0.2043 |  0.265  |
|     2      | 0.1631 | 0.091  | 0.1781 | 0.2259 |  0.3042 |
|     3      | 0.271  | 0.1922 | 0.2962 | 0.3363 |  0.4143 |
|     4      | 0.2819 | 0.1699 | 0.3129 | 0.3977 |  0.5161 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 18:28:18,225: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2678 | 0.1609 | 0.3282 | 0.3954 |  0.4683 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2298 | 0.1297 | 0.2832 | 0.3442 |  0.4156 |
|     1      | 0.1675 | 0.0857 | 0.2004 | 0.2552 |  0.3232 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1862 | 0.1012 | 0.2285 | 0.2837 |  0.3449 |
|     1      | 0.1451 | 0.0711 | 0.1742 | 0.221  |  0.2806 |
|     2      | 0.211  | 0.1261 | 0.2359 | 0.2949 |   0.38  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1822 | 0.1003 | 0.2241 | 0.2756 |  0.3354 |
|     1      | 0.1379 | 0.0661 | 0.1627 | 0.2102 |  0.2727 |
|     2      | 0.1725 | 0.0986 | 0.186  | 0.2344 |  0.3192 |
|     3      | 0.3045 | 0.2143 | 0.3452 | 0.3958 |  0.4691 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1716 | 0.0938 | 0.2104 | 0.2584 |  0.3155 |
|     1      | 0.133  | 0.0619 | 0.1578 | 0.2043 |  0.265  |
|     2      | 0.1631 | 0.091  | 0.1781 | 0.2259 |  0.3042 |
|     3      | 0.271  | 0.1922 | 0.2962 | 0.3363 |  0.4143 |
|     4      | 0.2819 | 0.1699 | 0.3129 | 0.3977 |  0.5161 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 18:28:18,226: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 134.42721009254456 |   0.268   |    0.161     |    0.328     |     0.468     |
|    1     | 122.63754105567932 |    0.2    |    0.108     |    0.243     |     0.371     |
|    2     | 92.15439963340759  |   0.178   |    0.097     |    0.211     |     0.331     |
|    3     | 52.37321186065674  |   0.178   |    0.101     |    0.208     |     0.325     |
|    4     | 44.328853130340576 |   0.175   |    0.098     |    0.203     |     0.321     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 18:28:18,226: Sum_Training_Time:445.9212157726288
2024-12-27 18:28:18,226: Every_Training_Time:[134.42721009254456, 122.63754105567932, 92.15439963340759, 52.37321186065674, 44.328853130340576]
2024-12-27 18:28:18,226: Forward transfer: 0.017875000000000002 Backward transfer: -0.05302499999999999
2024-12-27 18:28:55,373: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227182822/RELATIONrelation_0.001_512_5000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.001_512_5000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.001_512_5000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 18:29:11,483: Snapshot:0	Epoch:0	Loss:118.276	translation_Loss:118.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.08	Hits@10:38.46	Best:19.08
2024-12-27 18:29:23,198: Snapshot:0	Epoch:1	Loss:50.423	translation_Loss:50.423	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.07	Hits@10:44.36	Best:24.07
2024-12-27 18:29:34,849: Snapshot:0	Epoch:2	Loss:22.399	translation_Loss:22.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.0	Hits@10:46.08	Best:26.0
2024-12-27 18:29:46,623: Snapshot:0	Epoch:3	Loss:12.473	translation_Loss:12.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.28	Hits@10:46.23	Best:26.28
2024-12-27 18:29:58,424: Snapshot:0	Epoch:4	Loss:8.652	translation_Loss:8.652	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.36	Hits@10:46.1	Best:26.36
2024-12-27 18:30:10,163: Snapshot:0	Epoch:5	Loss:6.966	translation_Loss:6.966	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.24	Hits@10:46.03	Best:26.36
2024-12-27 18:30:21,763: Snapshot:0	Epoch:6	Loss:5.985	translation_Loss:5.985	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.11	Hits@10:45.54	Best:26.36
2024-12-27 18:30:33,933: Snapshot:0	Epoch:7	Loss:5.406	translation_Loss:5.406	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.88	Hits@10:45.55	Best:26.36
2024-12-27 18:30:45,571: Snapshot:0	Epoch:8	Loss:4.98	translation_Loss:4.98	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.79	Hits@10:45.08	Best:26.36
2024-12-27 18:30:57,266: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 26.36
2024-12-27 18:30:57,266: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:4.622 MRR:25.82 Best Results: 26.36
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:30:57,267: Snapshot:0	Epoch:9	Loss:4.622	translation_Loss:4.622	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.82	Hits@10:45.14	Best:26.36
2024-12-27 18:31:09,761: Snapshot:0	Epoch:10	Loss:98.664	translation_Loss:98.508	multi_layer_Loss:0.157	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.82	Hits@10:45.14	Best:26.36
2024-12-27 18:31:21,714: End of token training: 0 Epoch: 11 Loss:98.577 MRR:25.82 Best Results: 26.36
2024-12-27 18:31:21,714: Snapshot:0	Epoch:11	Loss:98.577	translation_Loss:98.577	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.82	Hits@10:45.14	Best:26.36
2024-12-27 18:31:22,091: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_5000/0model_best.tar'
2024-12-27 18:31:27,312: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2677 | 0.1619 | 0.3272 | 0.394  |  0.4655 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:32:05,451: Snapshot:1	Epoch:0	Loss:83.102	translation_Loss:70.826	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.276                                                   	MRR:14.17	Hits@10:28.62	Best:14.17
2024-12-27 18:32:16,759: Snapshot:1	Epoch:1	Loss:46.405	translation_Loss:32.823	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:13.582                                                   	MRR:14.26	Hits@10:28.5	Best:14.26
2024-12-27 18:32:28,070: Snapshot:1	Epoch:2	Loss:43.195	translation_Loss:30.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:13.185                                                   	MRR:14.32	Hits@10:28.65	Best:14.32
2024-12-27 18:32:39,269: Snapshot:1	Epoch:3	Loss:42.126	translation_Loss:29.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:13.062                                                   	MRR:14.09	Hits@10:28.39	Best:14.32
2024-12-27 18:32:50,643: Snapshot:1	Epoch:4	Loss:41.594	translation_Loss:28.56	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:13.034                                                   	MRR:13.95	Hits@10:28.23	Best:14.32
2024-12-27 18:33:01,865: Snapshot:1	Epoch:5	Loss:41.347	translation_Loss:28.354	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.993                                                   	MRR:13.82	Hits@10:27.94	Best:14.32
2024-12-27 18:33:13,124: Snapshot:1	Epoch:6	Loss:41.045	translation_Loss:28.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.991                                                   	MRR:13.93	Hits@10:28.28	Best:14.32
2024-12-27 18:33:24,472: Early Stopping! Snapshot: 1 Epoch: 7 Best Results: 14.32
2024-12-27 18:33:24,472: Start to training tokens! Snapshot: 1 Epoch: 7 Loss:40.873 MRR:14.09 Best Results: 14.32
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:33:24,473: Snapshot:1	Epoch:7	Loss:40.873	translation_Loss:27.865	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:13.008                                                   	MRR:14.09	Hits@10:28.39	Best:14.32
2024-12-27 18:33:35,358: Snapshot:1	Epoch:8	Loss:124.447	translation_Loss:124.289	multi_layer_Loss:0.158	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.09	Hits@10:28.39	Best:14.32
2024-12-27 18:33:46,274: End of token training: 1 Epoch: 9 Loss:124.377 MRR:14.09 Best Results: 14.32
2024-12-27 18:33:46,275: Snapshot:1	Epoch:9	Loss:124.377	translation_Loss:124.377	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:14.09	Hits@10:28.39	Best:14.32
2024-12-27 18:33:46,652: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_5000/1model_best.tar'
2024-12-27 18:33:56,302: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2489 | 0.1401 | 0.308  | 0.3808 |  0.4552 |
|     1      | 0.1414 | 0.0708 | 0.165  | 0.2154 |  0.2807 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:34:25,577: Snapshot:2	Epoch:0	Loss:50.117	translation_Loss:39.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.398                                                   	MRR:19.53	Hits@10:34.68	Best:19.53
2024-12-27 18:34:33,972: Snapshot:2	Epoch:1	Loss:24.424	translation_Loss:14.537	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.887                                                   	MRR:19.28	Hits@10:34.13	Best:19.53
2024-12-27 18:34:42,333: Snapshot:2	Epoch:2	Loss:23.014	translation_Loss:13.35	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.664                                                   	MRR:19.09	Hits@10:33.69	Best:19.53
2024-12-27 18:34:50,665: Snapshot:2	Epoch:3	Loss:22.558	translation_Loss:12.935	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.623                                                   	MRR:19.1	Hits@10:33.91	Best:19.53
2024-12-27 18:34:58,997: Snapshot:2	Epoch:4	Loss:22.498	translation_Loss:12.856	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.642                                                   	MRR:19.01	Hits@10:33.41	Best:19.53
2024-12-27 18:35:07,384: Early Stopping! Snapshot: 2 Epoch: 5 Best Results: 19.53
2024-12-27 18:35:07,384: Start to training tokens! Snapshot: 2 Epoch: 5 Loss:22.348 MRR:18.64 Best Results: 19.53
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:35:07,385: Snapshot:2	Epoch:5	Loss:22.348	translation_Loss:12.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.668                                                   	MRR:18.64	Hits@10:33.11	Best:19.53
2024-12-27 18:35:15,446: Snapshot:2	Epoch:6	Loss:92.444	translation_Loss:92.279	multi_layer_Loss:0.165	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.64	Hits@10:33.11	Best:19.53
2024-12-27 18:35:23,552: End of token training: 2 Epoch: 7 Loss:92.424 MRR:18.64 Best Results: 19.53
2024-12-27 18:35:23,552: Snapshot:2	Epoch:7	Loss:92.424	translation_Loss:92.424	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:18.64	Hits@10:33.11	Best:19.53
2024-12-27 18:35:23,926: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_5000/2model_best.tar'
2024-12-27 18:35:36,663: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2067 | 0.1084 | 0.2575 | 0.321  |  0.3961 |
|     1      | 0.129  | 0.0611 | 0.1495 | 0.1983 |  0.2614 |
|     2      | 0.194  | 0.1183 | 0.2159 | 0.2683 |  0.3468 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:35:52,720: Snapshot:3	Epoch:0	Loss:28.188	translation_Loss:25.137	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.051                                                   	MRR:23.69	Hits@10:40.19	Best:23.69
2024-12-27 18:35:56,644: Snapshot:3	Epoch:1	Loss:12.58	translation_Loss:8.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.382                                                   	MRR:27.18	Hits@10:42.58	Best:27.18
2024-12-27 18:36:00,570: Snapshot:3	Epoch:2	Loss:9.783	translation_Loss:5.526	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.258                                                   	MRR:27.49	Hits@10:42.48	Best:27.49
2024-12-27 18:36:04,446: Snapshot:3	Epoch:3	Loss:9.024	translation_Loss:4.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.157                                                   	MRR:27.07	Hits@10:42.08	Best:27.49
2024-12-27 18:36:08,276: Snapshot:3	Epoch:4	Loss:8.758	translation_Loss:4.638	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.12                                                   	MRR:27.08	Hits@10:42.02	Best:27.49
2024-12-27 18:36:12,128: Snapshot:3	Epoch:5	Loss:8.551	translation_Loss:4.481	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.069                                                   	MRR:26.44	Hits@10:41.86	Best:27.49
2024-12-27 18:36:15,978: Snapshot:3	Epoch:6	Loss:8.458	translation_Loss:4.391	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.067                                                   	MRR:26.52	Hits@10:41.63	Best:27.49
2024-12-27 18:36:19,800: Early Stopping! Snapshot: 3 Epoch: 7 Best Results: 27.49
2024-12-27 18:36:19,801: Start to training tokens! Snapshot: 3 Epoch: 7 Loss:8.381 MRR:26.58 Best Results: 27.49
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:36:19,801: Snapshot:3	Epoch:7	Loss:8.381	translation_Loss:4.345	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.036                                                   	MRR:26.58	Hits@10:41.74	Best:27.49
2024-12-27 18:36:23,531: Snapshot:3	Epoch:8	Loss:34.312	translation_Loss:34.17	multi_layer_Loss:0.142	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.58	Hits@10:41.74	Best:27.49
2024-12-27 18:36:27,269: End of token training: 3 Epoch: 9 Loss:34.209 MRR:26.58 Best Results: 27.49
2024-12-27 18:36:27,270: Snapshot:3	Epoch:9	Loss:34.209	translation_Loss:34.209	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.58	Hits@10:41.74	Best:27.49
2024-12-27 18:36:27,624: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_5000/3model_best.tar'
2024-12-27 18:36:43,094: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2034 | 0.107  | 0.252  | 0.3179 |   0.39  |
|     1      | 0.1283 | 0.0604 | 0.149  | 0.1971 |  0.2614 |
|     2      | 0.175  | 0.1017 | 0.1918 | 0.2406 |  0.3226 |
|     3      | 0.2744 | 0.191  | 0.3099 | 0.3572 |  0.4306 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:36:56,049: Snapshot:4	Epoch:0	Loss:16.551	translation_Loss:14.706	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.845                                                   	MRR:19.37	Hits@10:40.02	Best:19.37
2024-12-27 18:36:58,831: Snapshot:4	Epoch:1	Loss:6.843	translation_Loss:4.122	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.721                                                   	MRR:25.51	Hits@10:46.91	Best:25.51
2024-12-27 18:37:01,642: Snapshot:4	Epoch:2	Loss:4.733	translation_Loss:2.161	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.572                                                   	MRR:26.25	Hits@10:48.68	Best:26.25
2024-12-27 18:37:04,446: Snapshot:4	Epoch:3	Loss:4.168	translation_Loss:1.718	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.45                                                   	MRR:26.2	Hits@10:48.81	Best:26.25
2024-12-27 18:37:07,184: Snapshot:4	Epoch:4	Loss:3.908	translation_Loss:1.556	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.352                                                   	MRR:26.11	Hits@10:48.76	Best:26.25
2024-12-27 18:37:09,938: Snapshot:4	Epoch:5	Loss:3.771	translation_Loss:1.484	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.287                                                   	MRR:25.7	Hits@10:49.14	Best:26.25
2024-12-27 18:37:12,673: Snapshot:4	Epoch:6	Loss:3.728	translation_Loss:1.462	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.266                                                   	MRR:24.9	Hits@10:48.3	Best:26.25
2024-12-27 18:37:15,421: Early Stopping! Snapshot: 4 Epoch: 7 Best Results: 26.25
2024-12-27 18:37:15,421: Start to training tokens! Snapshot: 4 Epoch: 7 Loss:3.662 MRR:25.09 Best Results: 26.25
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:37:15,422: Snapshot:4	Epoch:7	Loss:3.662	translation_Loss:1.421	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.241                                                   	MRR:25.09	Hits@10:48.68	Best:26.25
2024-12-27 18:37:18,042: Snapshot:4	Epoch:8	Loss:19.835	translation_Loss:19.679	multi_layer_Loss:0.156	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.09	Hits@10:48.68	Best:26.25
2024-12-27 18:37:20,676: End of token training: 4 Epoch: 9 Loss:19.717 MRR:25.09 Best Results: 26.25
2024-12-27 18:37:20,677: Snapshot:4	Epoch:9	Loss:19.717	translation_Loss:19.716	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.09	Hits@10:48.68	Best:26.25
2024-12-27 18:37:21,053: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_5000/4model_best.tar'
2024-12-27 18:37:37,763: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1948 | 0.1024 | 0.2415 | 0.3009 |  0.3704 |
|     1      | 0.1284 | 0.0607 | 0.1483 | 0.1955 |  0.2594 |
|     2      | 0.1656 | 0.0961 | 0.1809 | 0.2291 |  0.3069 |
|     3      | 0.258  | 0.1824 | 0.2822 | 0.3251 |  0.3965 |
|     4      | 0.2605 | 0.1506 | 0.2914 | 0.3746 |  0.4913 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 18:37:37,765: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2677 | 0.1619 | 0.3272 | 0.394  |  0.4655 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2489 | 0.1401 | 0.308  | 0.3808 |  0.4552 |
|     1      | 0.1414 | 0.0708 | 0.165  | 0.2154 |  0.2807 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2067 | 0.1084 | 0.2575 | 0.321  |  0.3961 |
|     1      | 0.129  | 0.0611 | 0.1495 | 0.1983 |  0.2614 |
|     2      | 0.194  | 0.1183 | 0.2159 | 0.2683 |  0.3468 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2034 | 0.107  | 0.252  | 0.3179 |   0.39  |
|     1      | 0.1283 | 0.0604 | 0.149  | 0.1971 |  0.2614 |
|     2      | 0.175  | 0.1017 | 0.1918 | 0.2406 |  0.3226 |
|     3      | 0.2744 | 0.191  | 0.3099 | 0.3572 |  0.4306 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1948 | 0.1024 | 0.2415 | 0.3009 |  0.3704 |
|     1      | 0.1284 | 0.0607 | 0.1483 | 0.1955 |  0.2594 |
|     2      | 0.1656 | 0.0961 | 0.1809 | 0.2291 |  0.3069 |
|     3      | 0.258  | 0.1824 | 0.2822 | 0.3251 |  0.3965 |
|     4      | 0.2605 | 0.1506 | 0.2914 | 0.3746 |  0.4913 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 18:37:37,766: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 146.34037566184998 |   0.268   |    0.162     |    0.327     |     0.465     |
|    1     | 134.6443395614624  |   0.197   |    0.106     |    0.238     |      0.37     |
|    2     | 83.60777974128723  |   0.175   |    0.094     |    0.208     |     0.335     |
|    3     | 48.67727255821228  |    0.18   |    0.099     |    0.211     |     0.337     |
|    4     | 36.045318365097046 |   0.179   |     0.1      |    0.208     |     0.334     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 18:37:37,766: Sum_Training_Time:449.31508588790894
2024-12-27 18:37:37,766: Every_Training_Time:[146.34037566184998, 134.6443395614624, 83.60777974128723, 48.67727255821228, 36.045318365097046]
2024-12-27 18:37:37,766: Forward transfer: 0.0165 Backward transfer: -0.032674999999999996
2024-12-27 18:38:15,153: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227183741/RELATIONrelation_0.001_512_10000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.001_512_10000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.001_512_10000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 18:38:31,410: Snapshot:0	Epoch:0	Loss:118.277	translation_Loss:118.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.07	Hits@10:38.51	Best:19.07
2024-12-27 18:38:43,096: Snapshot:0	Epoch:1	Loss:50.419	translation_Loss:50.419	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.05	Hits@10:44.39	Best:24.05
2024-12-27 18:38:54,746: Snapshot:0	Epoch:2	Loss:22.393	translation_Loss:22.393	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.91	Hits@10:46.13	Best:25.91
2024-12-27 18:39:06,392: Snapshot:0	Epoch:3	Loss:12.493	translation_Loss:12.493	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.3	Hits@10:46.21	Best:26.3
2024-12-27 18:39:18,123: Snapshot:0	Epoch:4	Loss:8.667	translation_Loss:8.667	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.4	Hits@10:46.32	Best:26.4
2024-12-27 18:39:29,932: Snapshot:0	Epoch:5	Loss:6.928	translation_Loss:6.928	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.24	Hits@10:46.15	Best:26.4
2024-12-27 18:39:41,700: Snapshot:0	Epoch:6	Loss:5.993	translation_Loss:5.993	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.03	Hits@10:45.7	Best:26.4
2024-12-27 18:39:53,991: Snapshot:0	Epoch:7	Loss:5.384	translation_Loss:5.384	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.7	Hits@10:45.26	Best:26.4
2024-12-27 18:40:05,866: Snapshot:0	Epoch:8	Loss:4.98	translation_Loss:4.98	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.69	Hits@10:45.1	Best:26.4
2024-12-27 18:40:17,679: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 26.4
2024-12-27 18:40:17,679: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:4.597 MRR:25.67 Best Results: 26.4
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:40:17,680: Snapshot:0	Epoch:9	Loss:4.597	translation_Loss:4.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.67	Hits@10:45.1	Best:26.4
2024-12-27 18:40:30,144: Snapshot:0	Epoch:10	Loss:98.756	translation_Loss:98.599	multi_layer_Loss:0.157	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.67	Hits@10:45.1	Best:26.4
2024-12-27 18:40:42,079: End of token training: 0 Epoch: 11 Loss:98.68 MRR:25.67 Best Results: 26.4
2024-12-27 18:40:42,079: Snapshot:0	Epoch:11	Loss:98.68	translation_Loss:98.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.67	Hits@10:45.1	Best:26.4
2024-12-27 18:40:42,446: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_10000/0model_best.tar'
2024-12-27 18:40:48,004: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2681 | 0.1619 | 0.3282 | 0.3954 |  0.4665 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:41:25,987: Snapshot:1	Epoch:0	Loss:85.581	translation_Loss:73.323	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.258                                                   	MRR:13.33	Hits@10:27.35	Best:13.33
2024-12-27 18:41:37,152: Snapshot:1	Epoch:1	Loss:49.148	translation_Loss:36.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.474                                                   	MRR:13.2	Hits@10:27.18	Best:13.33
2024-12-27 18:41:48,531: Snapshot:1	Epoch:2	Loss:45.802	translation_Loss:33.79	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.012                                                   	MRR:13.32	Hits@10:27.28	Best:13.33
2024-12-27 18:41:59,716: Snapshot:1	Epoch:3	Loss:44.725	translation_Loss:32.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.916                                                   	MRR:13.07	Hits@10:27.09	Best:13.33
2024-12-27 18:42:10,949: Snapshot:1	Epoch:4	Loss:44.141	translation_Loss:32.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.853                                                   	MRR:13.22	Hits@10:26.91	Best:13.33
2024-12-27 18:42:22,237: Early Stopping! Snapshot: 1 Epoch: 5 Best Results: 13.33
2024-12-27 18:42:22,238: Start to training tokens! Snapshot: 1 Epoch: 5 Loss:43.916 MRR:13.26 Best Results: 13.33
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:42:22,238: Snapshot:1	Epoch:5	Loss:43.916	translation_Loss:32.068	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.849                                                   	MRR:13.26	Hits@10:27.07	Best:13.33
2024-12-27 18:42:33,172: Snapshot:1	Epoch:6	Loss:127.655	translation_Loss:127.497	multi_layer_Loss:0.158	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.26	Hits@10:27.07	Best:13.33
2024-12-27 18:42:44,074: End of token training: 1 Epoch: 7 Loss:127.582 MRR:13.26 Best Results: 13.33
2024-12-27 18:42:44,075: Snapshot:1	Epoch:7	Loss:127.582	translation_Loss:127.582	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:13.26	Hits@10:27.07	Best:13.33
2024-12-27 18:42:44,433: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_10000/1model_best.tar'
2024-12-27 18:42:53,802: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2491 | 0.1397 | 0.309  | 0.381  |  0.4561 |
|     1      | 0.1321 | 0.0632 | 0.1553 | 0.2041 |  0.2702 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:43:22,574: Snapshot:2	Epoch:0	Loss:55.489	translation_Loss:42.971	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:12.518                                                   	MRR:18.41	Hits@10:32.93	Best:18.41
2024-12-27 18:43:30,932: Snapshot:2	Epoch:1	Loss:29.84	translation_Loss:18.339	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.501                                                   	MRR:18.52	Hits@10:32.83	Best:18.52
2024-12-27 18:43:39,329: Snapshot:2	Epoch:2	Loss:28.464	translation_Loss:17.154	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.31                                                   	MRR:18.3	Hits@10:32.39	Best:18.52
2024-12-27 18:43:47,731: Snapshot:2	Epoch:3	Loss:28.073	translation_Loss:16.839	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.234                                                   	MRR:18.24	Hits@10:32.17	Best:18.52
2024-12-27 18:43:56,106: Snapshot:2	Epoch:4	Loss:27.868	translation_Loss:16.632	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.236                                                   	MRR:18.18	Hits@10:32.0	Best:18.52
2024-12-27 18:44:04,429: Snapshot:2	Epoch:5	Loss:27.728	translation_Loss:16.498	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.23                                                   	MRR:18.32	Hits@10:32.06	Best:18.52
2024-12-27 18:44:12,777: Early Stopping! Snapshot: 2 Epoch: 6 Best Results: 18.52
2024-12-27 18:44:12,777: Start to training tokens! Snapshot: 2 Epoch: 6 Loss:27.728 MRR:18.39 Best Results: 18.52
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:44:12,777: Snapshot:2	Epoch:6	Loss:27.728	translation_Loss:16.483	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.245                                                   	MRR:18.39	Hits@10:32.32	Best:18.52
2024-12-27 18:44:20,978: Snapshot:2	Epoch:7	Loss:97.529	translation_Loss:97.364	multi_layer_Loss:0.165	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.39	Hits@10:32.32	Best:18.52
2024-12-27 18:44:29,185: End of token training: 2 Epoch: 8 Loss:97.431 MRR:18.39 Best Results: 18.52
2024-12-27 18:44:29,185: Snapshot:2	Epoch:8	Loss:97.431	translation_Loss:97.431	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:18.39	Hits@10:32.32	Best:18.52
2024-12-27 18:44:29,568: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_10000/2model_best.tar'
2024-12-27 18:44:43,132: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2159 | 0.1142 | 0.2675 | 0.3363 |  0.4119 |
|     1      | 0.1217 | 0.0545 | 0.1421 | 0.1905 |  0.2558 |
|     2      | 0.1821 | 0.1129 | 0.1986 | 0.2495 |  0.3217 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:44:58,827: Snapshot:3	Epoch:0	Loss:31.974	translation_Loss:28.169	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.805                                                   	MRR:22.34	Hits@10:37.93	Best:22.34
2024-12-27 18:45:02,749: Snapshot:3	Epoch:1	Loss:16.597	translation_Loss:11.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.207                                                   	MRR:25.88	Hits@10:40.0	Best:25.88
2024-12-27 18:45:06,701: Snapshot:3	Epoch:2	Loss:13.451	translation_Loss:8.429	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.021                                                   	MRR:26.04	Hits@10:40.19	Best:26.04
2024-12-27 18:45:10,579: Snapshot:3	Epoch:3	Loss:12.54	translation_Loss:7.626	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.914                                                   	MRR:25.61	Hits@10:39.49	Best:26.04
2024-12-27 18:45:14,467: Snapshot:3	Epoch:4	Loss:12.26	translation_Loss:7.408	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.852                                                   	MRR:25.77	Hits@10:39.85	Best:26.04
2024-12-27 18:45:18,349: Snapshot:3	Epoch:5	Loss:12.055	translation_Loss:7.237	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.818                                                   	MRR:25.38	Hits@10:39.74	Best:26.04
2024-12-27 18:45:22,246: Snapshot:3	Epoch:6	Loss:11.951	translation_Loss:7.153	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.798                                                   	MRR:25.51	Hits@10:39.4	Best:26.04
2024-12-27 18:45:26,171: Early Stopping! Snapshot: 3 Epoch: 7 Best Results: 26.04
2024-12-27 18:45:26,171: Start to training tokens! Snapshot: 3 Epoch: 7 Loss:11.886 MRR:25.44 Best Results: 26.04
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:45:26,171: Snapshot:3	Epoch:7	Loss:11.886	translation_Loss:7.106	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.779                                                   	MRR:25.44	Hits@10:39.65	Best:26.04
2024-12-27 18:45:29,965: Snapshot:3	Epoch:8	Loss:37.008	translation_Loss:36.866	multi_layer_Loss:0.142	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.44	Hits@10:39.65	Best:26.04
2024-12-27 18:45:34,152: End of token training: 3 Epoch: 9 Loss:36.931 MRR:25.44 Best Results: 26.04
2024-12-27 18:45:34,152: Snapshot:3	Epoch:9	Loss:36.931	translation_Loss:36.931	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.44	Hits@10:39.65	Best:26.04
2024-12-27 18:45:34,468: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_10000/3model_best.tar'
2024-12-27 18:45:50,328: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2129 | 0.1122 | 0.2649 | 0.3333 |  0.409  |
|     1      | 0.1219 | 0.0549 | 0.1426 | 0.1903 |  0.2548 |
|     2      | 0.1687 | 0.1007 | 0.1832 | 0.2315 |  0.3076 |
|     3      | 0.2587 | 0.1795 | 0.2932 | 0.3417 |  0.4043 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:46:03,215: Snapshot:4	Epoch:0	Loss:18.824	translation_Loss:16.358	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.466                                                   	MRR:17.95	Hits@10:37.81	Best:17.95
2024-12-27 18:46:06,055: Snapshot:4	Epoch:1	Loss:9.19	translation_Loss:5.716	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.473                                                   	MRR:24.28	Hits@10:45.64	Best:24.28
2024-12-27 18:46:08,889: Snapshot:4	Epoch:2	Loss:6.956	translation_Loss:3.782	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.175                                                   	MRR:24.63	Hits@10:47.21	Best:24.63
2024-12-27 18:46:11,648: Snapshot:4	Epoch:3	Loss:6.262	translation_Loss:3.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.034                                                   	MRR:24.5	Hits@10:47.29	Best:24.63
2024-12-27 18:46:14,463: Snapshot:4	Epoch:4	Loss:5.968	translation_Loss:3.049	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.919                                                   	MRR:24.53	Hits@10:46.35	Best:24.63
2024-12-27 18:46:17,235: Snapshot:4	Epoch:5	Loss:5.805	translation_Loss:2.937	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.868                                                   	MRR:24.23	Hits@10:46.41	Best:24.63
2024-12-27 18:46:19,941: Snapshot:4	Epoch:6	Loss:5.708	translation_Loss:2.871	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.837                                                   	MRR:23.89	Hits@10:46.32	Best:24.63
2024-12-27 18:46:22,679: Early Stopping! Snapshot: 4 Epoch: 7 Best Results: 24.63
2024-12-27 18:46:22,680: Start to training tokens! Snapshot: 4 Epoch: 7 Loss:5.629 MRR:23.77 Best Results: 24.63
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:46:22,680: Snapshot:4	Epoch:7	Loss:5.629	translation_Loss:2.816	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.813                                                   	MRR:23.77	Hits@10:46.09	Best:24.63
2024-12-27 18:46:25,318: Snapshot:4	Epoch:8	Loss:21.35	translation_Loss:21.195	multi_layer_Loss:0.156	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.77	Hits@10:46.09	Best:24.63
2024-12-27 18:46:27,960: End of token training: 4 Epoch: 9 Loss:21.054 MRR:23.77 Best Results: 24.63
2024-12-27 18:46:27,960: Snapshot:4	Epoch:9	Loss:21.054	translation_Loss:21.054	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.77	Hits@10:46.09	Best:24.63
2024-12-27 18:46:28,204: => loading checkpoint './checkpoint/RELATIONrelation_0.001_512_10000/4model_best.tar'
2024-12-27 18:46:44,985: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2073 | 0.1098 | 0.2566 | 0.3222 |  0.3936 |
|     1      | 0.122  | 0.0549 | 0.1429 | 0.189  |  0.2535 |
|     2      | 0.1611 | 0.0972 | 0.1756 | 0.2186 |  0.2886 |
|     3      | 0.2441 | 0.1671 | 0.2708 | 0.3175 |  0.3895 |
|     4      | 0.2466 |  0.14  | 0.2768 | 0.3537 |  0.4756 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 18:46:44,988: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2681 | 0.1619 | 0.3282 | 0.3954 |  0.4665 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2491 | 0.1397 | 0.309  | 0.381  |  0.4561 |
|     1      | 0.1321 | 0.0632 | 0.1553 | 0.2041 |  0.2702 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2159 | 0.1142 | 0.2675 | 0.3363 |  0.4119 |
|     1      | 0.1217 | 0.0545 | 0.1421 | 0.1905 |  0.2558 |
|     2      | 0.1821 | 0.1129 | 0.1986 | 0.2495 |  0.3217 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2129 | 0.1122 | 0.2649 | 0.3333 |  0.409  |
|     1      | 0.1219 | 0.0549 | 0.1426 | 0.1903 |  0.2548 |
|     2      | 0.1687 | 0.1007 | 0.1832 | 0.2315 |  0.3076 |
|     3      | 0.2587 | 0.1795 | 0.2932 | 0.3417 |  0.4043 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2073 | 0.1098 | 0.2566 | 0.3222 |  0.3936 |
|     1      | 0.122  | 0.0549 | 0.1429 | 0.189  |  0.2535 |
|     2      | 0.1611 | 0.0972 | 0.1756 | 0.2186 |  0.2886 |
|     3      | 0.2441 | 0.1671 | 0.2708 | 0.3175 |  0.3895 |
|     4      | 0.2466 |  0.14  | 0.2768 | 0.3537 |  0.4756 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 18:46:44,988: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 146.9251251220703  |   0.268   |    0.162     |    0.328     |     0.467     |
|    1     | 111.76609301567078 |   0.192   |    0.102     |    0.234     |     0.366     |
|    2     | 91.72475123405457  |   0.173   |    0.092     |    0.204     |     0.332     |
|    3     | 49.041719913482666 |   0.178   |    0.098     |    0.209     |     0.335     |
|    4     | 36.111971855163574 |   0.178   |    0.098     |    0.208     |     0.334     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 18:46:44,988: Sum_Training_Time:435.5696611404419
2024-12-27 18:46:44,988: Every_Training_Time:[146.9251251220703, 111.76609301567078, 91.72475123405457, 49.041719913482666, 36.111971855163574]
2024-12-27 18:46:44,988: Forward transfer: 0.0152 Backward transfer: -0.026624999999999996
2024-12-27 18:47:22,748: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227184648/RELATIONrelation_0.001_1024_1000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.001_1024_1000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.001_1024_1000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 18:47:38,643: Snapshot:0	Epoch:0	Loss:64.234	translation_Loss:64.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.66	Hits@10:35.49	Best:16.66
2024-12-27 18:47:50,311: Snapshot:0	Epoch:1	Loss:30.863	translation_Loss:30.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.29	Hits@10:44.21	Best:23.29
2024-12-27 18:48:01,882: Snapshot:0	Epoch:2	Loss:14.473	translation_Loss:14.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.03	Hits@10:46.45	Best:26.03
2024-12-27 18:48:13,482: Snapshot:0	Epoch:3	Loss:7.686	translation_Loss:7.686	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.91	Hits@10:47.18	Best:26.91
2024-12-27 18:48:25,040: Snapshot:0	Epoch:4	Loss:4.986	translation_Loss:4.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.13	Hits@10:47.42	Best:27.13
2024-12-27 18:48:36,555: Snapshot:0	Epoch:5	Loss:3.777	translation_Loss:3.777	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.19	Hits@10:47.45	Best:27.19
2024-12-27 18:48:48,598: Snapshot:0	Epoch:6	Loss:3.146	translation_Loss:3.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.88	Hits@10:46.93	Best:27.19
2024-12-27 18:49:00,101: Snapshot:0	Epoch:7	Loss:2.759	translation_Loss:2.759	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.73	Hits@10:46.73	Best:27.19
2024-12-27 18:49:11,677: Snapshot:0	Epoch:8	Loss:2.511	translation_Loss:2.511	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.63	Hits@10:46.68	Best:27.19
2024-12-27 18:49:23,235: Snapshot:0	Epoch:9	Loss:2.295	translation_Loss:2.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.63	Hits@10:46.44	Best:27.19
2024-12-27 18:49:34,758: Early Stopping! Snapshot: 0 Epoch: 10 Best Results: 27.19
2024-12-27 18:49:34,758: Start to training tokens! Snapshot: 0 Epoch: 10 Loss:2.142 MRR:26.36 Best Results: 27.19
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:49:34,758: Snapshot:0	Epoch:10	Loss:2.142	translation_Loss:2.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.36	Hits@10:46.24	Best:27.19
2024-12-27 18:49:47,002: Snapshot:0	Epoch:11	Loss:49.502	translation_Loss:49.346	multi_layer_Loss:0.157	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.36	Hits@10:46.24	Best:27.19
2024-12-27 18:49:59,184: End of token training: 0 Epoch: 12 Loss:49.326 MRR:26.36 Best Results: 27.19
2024-12-27 18:49:59,184: Snapshot:0	Epoch:12	Loss:49.326	translation_Loss:49.326	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.36	Hits@10:46.24	Best:27.19
2024-12-27 18:49:59,485: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_1000/0model_best.tar'
2024-12-27 18:50:04,465: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2741 | 0.1655 | 0.3368 | 0.4057 |  0.4779 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:50:40,981: Snapshot:1	Epoch:0	Loss:44.74	translation_Loss:41.157	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.583                                                   	MRR:16.51	Hits@10:32.39	Best:16.51
2024-12-27 18:50:51,974: Snapshot:1	Epoch:1	Loss:16.39	translation_Loss:10.252	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.138                                                   	MRR:17.43	Hits@10:33.81	Best:17.43
2024-12-27 18:51:02,863: Snapshot:1	Epoch:2	Loss:12.729	translation_Loss:6.367	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.362                                                   	MRR:17.7	Hits@10:33.75	Best:17.7
2024-12-27 18:51:13,735: Snapshot:1	Epoch:3	Loss:11.995	translation_Loss:5.656	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.34                                                   	MRR:17.4	Hits@10:33.55	Best:17.7
2024-12-27 18:51:24,725: Snapshot:1	Epoch:4	Loss:11.767	translation_Loss:5.409	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.357                                                   	MRR:17.23	Hits@10:33.35	Best:17.7
2024-12-27 18:51:36,018: Snapshot:1	Epoch:5	Loss:11.592	translation_Loss:5.256	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.336                                                   	MRR:17.22	Hits@10:33.18	Best:17.7
2024-12-27 18:51:46,857: Snapshot:1	Epoch:6	Loss:11.533	translation_Loss:5.189	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.344                                                   	MRR:17.22	Hits@10:33.47	Best:17.7
2024-12-27 18:51:57,670: Early Stopping! Snapshot: 1 Epoch: 7 Best Results: 17.7
2024-12-27 18:51:57,670: Start to training tokens! Snapshot: 1 Epoch: 7 Loss:11.494 MRR:17.16 Best Results: 17.7
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:51:57,670: Snapshot:1	Epoch:7	Loss:11.494	translation_Loss:5.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.353                                                   	MRR:17.16	Hits@10:33.24	Best:17.7
2024-12-27 18:52:08,456: Snapshot:1	Epoch:8	Loss:55.519	translation_Loss:55.361	multi_layer_Loss:0.158	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.16	Hits@10:33.24	Best:17.7
2024-12-27 18:52:19,232: End of token training: 1 Epoch: 9 Loss:55.42 MRR:17.16 Best Results: 17.7
2024-12-27 18:52:19,232: Snapshot:1	Epoch:9	Loss:55.42	translation_Loss:55.42	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:17.16	Hits@10:33.24	Best:17.7
2024-12-27 18:52:19,607: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_1000/1model_best.tar'
2024-12-27 18:52:30,051: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2298 | 0.1277 | 0.2826 | 0.347  |  0.4216 |
|     1      | 0.1776 | 0.0951 | 0.2106 | 0.2631 |  0.3359 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:52:58,095: Snapshot:2	Epoch:0	Loss:24.94	translation_Loss:22.472	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.468                                                   	MRR:19.74	Hits@10:36.57	Best:19.74
2024-12-27 18:53:06,167: Snapshot:2	Epoch:1	Loss:7.349	translation_Loss:4.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.294                                                   	MRR:22.05	Hits@10:39.78	Best:22.05
2024-12-27 18:53:14,353: Snapshot:2	Epoch:2	Loss:5.32	translation_Loss:2.323	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.997                                                   	MRR:22.16	Hits@10:39.49	Best:22.16
2024-12-27 18:53:22,609: Snapshot:2	Epoch:3	Loss:4.798	translation_Loss:1.935	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.864                                                   	MRR:21.95	Hits@10:39.02	Best:22.16
2024-12-27 18:53:30,642: Snapshot:2	Epoch:4	Loss:4.632	translation_Loss:1.829	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.803                                                   	MRR:21.29	Hits@10:37.95	Best:22.16
2024-12-27 18:53:38,765: Snapshot:2	Epoch:5	Loss:4.517	translation_Loss:1.743	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.773                                                   	MRR:21.31	Hits@10:37.93	Best:22.16
2024-12-27 18:53:46,931: Snapshot:2	Epoch:6	Loss:4.498	translation_Loss:1.727	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.771                                                   	MRR:21.05	Hits@10:37.97	Best:22.16
2024-12-27 18:53:54,970: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 22.16
2024-12-27 18:53:54,971: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:4.512 MRR:21.1 Best Results: 22.16
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:53:54,971: Snapshot:2	Epoch:7	Loss:4.512	translation_Loss:1.736	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.776                                                   	MRR:21.1	Hits@10:37.34	Best:22.16
2024-12-27 18:54:02,873: Snapshot:2	Epoch:8	Loss:38.457	translation_Loss:38.292	multi_layer_Loss:0.165	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.1	Hits@10:37.34	Best:22.16
2024-12-27 18:54:10,866: End of token training: 2 Epoch: 9 Loss:38.298 MRR:21.1 Best Results: 22.16
2024-12-27 18:54:10,866: Snapshot:2	Epoch:9	Loss:38.298	translation_Loss:38.298	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.1	Hits@10:37.34	Best:22.16
2024-12-27 18:54:11,245: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_1000/2model_best.tar'
2024-12-27 18:54:24,790: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1855 | 0.0982 | 0.228  | 0.2866 |  0.3513 |
|     1      | 0.149  | 0.0755 | 0.1769 | 0.2232 |  0.2841 |
|     2      | 0.2182 | 0.1304 | 0.2448 | 0.3044 |  0.3939 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:54:40,329: Snapshot:3	Epoch:0	Loss:13.663	translation_Loss:13.021	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.643                                                   	MRR:21.54	Hits@10:39.96	Best:21.54
2024-12-27 18:54:44,122: Snapshot:3	Epoch:1	Loss:4.103	translation_Loss:2.934	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.169                                                   	MRR:28.55	Hits@10:46.05	Best:28.55
2024-12-27 18:54:47,876: Snapshot:3	Epoch:2	Loss:1.984	translation_Loss:0.788	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.195                                                   	MRR:30.0	Hits@10:47.31	Best:30.0
2024-12-27 18:54:51,738: Snapshot:3	Epoch:3	Loss:1.477	translation_Loss:0.397	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.08                                                   	MRR:30.43	Hits@10:47.68	Best:30.43
2024-12-27 18:54:55,494: Snapshot:3	Epoch:4	Loss:1.316	translation_Loss:0.321	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.995                                                   	MRR:30.08	Hits@10:47.78	Best:30.43
2024-12-27 18:54:59,295: Snapshot:3	Epoch:5	Loss:1.238	translation_Loss:0.291	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.947                                                   	MRR:30.56	Hits@10:47.52	Best:30.56
2024-12-27 18:55:03,139: Snapshot:3	Epoch:6	Loss:1.187	translation_Loss:0.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.916                                                   	MRR:30.3	Hits@10:47.7	Best:30.56
2024-12-27 18:55:06,984: Snapshot:3	Epoch:7	Loss:1.145	translation_Loss:0.26	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.885                                                   	MRR:30.59	Hits@10:47.19	Best:30.59
2024-12-27 18:55:10,716: Snapshot:3	Epoch:8	Loss:1.12	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.863                                                   	MRR:30.42	Hits@10:47.29	Best:30.59
2024-12-27 18:55:14,456: Snapshot:3	Epoch:9	Loss:1.11	translation_Loss:0.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.855                                                   	MRR:30.12	Hits@10:47.28	Best:30.59
2024-12-27 18:55:18,185: Snapshot:3	Epoch:10	Loss:1.093	translation_Loss:0.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.84                                                   	MRR:30.25	Hits@10:47.07	Best:30.59
2024-12-27 18:55:21,919: Snapshot:3	Epoch:11	Loss:1.08	translation_Loss:0.249	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.831                                                   	MRR:30.41	Hits@10:47.21	Best:30.59
2024-12-27 18:55:25,688: Early Stopping! Snapshot: 3 Epoch: 12 Best Results: 30.59
2024-12-27 18:55:25,688: Start to training tokens! Snapshot: 3 Epoch: 12 Loss:1.068 MRR:30.1 Best Results: 30.59
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:55:25,688: Snapshot:3	Epoch:12	Loss:1.068	translation_Loss:0.249	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.82                                                   	MRR:30.1	Hits@10:46.73	Best:30.59
2024-12-27 18:55:29,315: Snapshot:3	Epoch:13	Loss:13.719	translation_Loss:13.577	multi_layer_Loss:0.141	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.1	Hits@10:46.73	Best:30.59
2024-12-27 18:55:32,917: End of token training: 3 Epoch: 14 Loss:13.628 MRR:30.1 Best Results: 30.59
2024-12-27 18:55:32,918: Snapshot:3	Epoch:14	Loss:13.628	translation_Loss:13.627	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.1	Hits@10:46.73	Best:30.59
2024-12-27 18:55:33,242: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_1000/3model_best.tar'
2024-12-27 18:55:48,740: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.181  | 0.0967 | 0.2223 | 0.2769 |  0.3388 |
|     1      | 0.143  | 0.0707 | 0.1694 | 0.2161 |  0.2762 |
|     2      | 0.1824 | 0.1027 | 0.201  | 0.2544 |  0.3335 |
|     3      | 0.3041 | 0.2121 | 0.342  | 0.3987 |  0.4783 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 18:56:01,411: Snapshot:4	Epoch:0	Loss:7.289	translation_Loss:6.906	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.383                                                   	MRR:16.56	Hits@10:36.51	Best:16.56
2024-12-27 18:56:04,119: Snapshot:4	Epoch:1	Loss:2.352	translation_Loss:1.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.618                                                   	MRR:25.06	Hits@10:47.01	Best:25.06
2024-12-27 18:56:06,886: Snapshot:4	Epoch:2	Loss:0.998	translation_Loss:0.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.613                                                   	MRR:26.91	Hits@10:48.7	Best:26.91
2024-12-27 18:56:09,554: Snapshot:4	Epoch:3	Loss:0.698	translation_Loss:0.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.531                                                   	MRR:27.57	Hits@10:49.65	Best:27.57
2024-12-27 18:56:12,223: Snapshot:4	Epoch:4	Loss:0.593	translation_Loss:0.124	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.469                                                   	MRR:28.07	Hits@10:50.42	Best:28.07
2024-12-27 18:56:14,908: Snapshot:4	Epoch:5	Loss:0.535	translation_Loss:0.105	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.431                                                   	MRR:27.86	Hits@10:50.3	Best:28.07
2024-12-27 18:56:17,564: Snapshot:4	Epoch:6	Loss:0.509	translation_Loss:0.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.405                                                   	MRR:28.35	Hits@10:50.46	Best:28.35
2024-12-27 18:56:20,218: Snapshot:4	Epoch:7	Loss:0.475	translation_Loss:0.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.386                                                   	MRR:28.21	Hits@10:51.02	Best:28.35
2024-12-27 18:56:22,912: Snapshot:4	Epoch:8	Loss:0.467	translation_Loss:0.094	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.372                                                   	MRR:28.51	Hits@10:51.45	Best:28.51
2024-12-27 18:56:25,530: Snapshot:4	Epoch:9	Loss:0.463	translation_Loss:0.097	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.366                                                   	MRR:28.47	Hits@10:51.35	Best:28.51
2024-12-27 18:56:28,167: Snapshot:4	Epoch:10	Loss:0.446	translation_Loss:0.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.356                                                   	MRR:28.11	Hits@10:51.78	Best:28.51
2024-12-27 18:56:30,805: Snapshot:4	Epoch:11	Loss:0.424	translation_Loss:0.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.344                                                   	MRR:28.21	Hits@10:51.84	Best:28.51
2024-12-27 18:56:33,435: Snapshot:4	Epoch:12	Loss:0.429	translation_Loss:0.091	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.338                                                   	MRR:28.16	Hits@10:51.49	Best:28.51
2024-12-27 18:56:36,117: Early Stopping! Snapshot: 4 Epoch: 13 Best Results: 28.51
2024-12-27 18:56:36,117: Start to training tokens! Snapshot: 4 Epoch: 13 Loss:0.431 MRR:28.2 Best Results: 28.51
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:56:36,117: Snapshot:4	Epoch:13	Loss:0.431	translation_Loss:0.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.344                                                   	MRR:28.2	Hits@10:51.99	Best:28.51
2024-12-27 18:56:38,700: Snapshot:4	Epoch:14	Loss:7.822	translation_Loss:7.669	multi_layer_Loss:0.153	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.2	Hits@10:51.99	Best:28.51
2024-12-27 18:56:41,282: End of token training: 4 Epoch: 15 Loss:7.697 MRR:28.2 Best Results: 28.51
2024-12-27 18:56:41,282: Snapshot:4	Epoch:15	Loss:7.697	translation_Loss:7.694	multi_layer_Loss:0.003	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:28.2	Hits@10:51.99	Best:28.51
2024-12-27 18:56:41,518: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_1000/4model_best.tar'
2024-12-27 18:56:58,512: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1725 | 0.0934 | 0.2117 | 0.2617 |  0.3202 |
|     1      | 0.1382 | 0.0678 | 0.1628 | 0.2064 |  0.2694 |
|     2      | 0.172  | 0.0969 | 0.1899 | 0.2372 |  0.3164 |
|     3      | 0.2645 | 0.1829 | 0.2929 | 0.3383 |  0.4134 |
|     4      | 0.282  | 0.1682 | 0.3167 | 0.3929 |  0.516  |
+------------+--------+--------+--------+--------+---------+
2024-12-27 18:56:58,514: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2741 | 0.1655 | 0.3368 | 0.4057 |  0.4779 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2298 | 0.1277 | 0.2826 | 0.347  |  0.4216 |
|     1      | 0.1776 | 0.0951 | 0.2106 | 0.2631 |  0.3359 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1855 | 0.0982 | 0.228  | 0.2866 |  0.3513 |
|     1      | 0.149  | 0.0755 | 0.1769 | 0.2232 |  0.2841 |
|     2      | 0.2182 | 0.1304 | 0.2448 | 0.3044 |  0.3939 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.181  | 0.0967 | 0.2223 | 0.2769 |  0.3388 |
|     1      | 0.143  | 0.0707 | 0.1694 | 0.2161 |  0.2762 |
|     2      | 0.1824 | 0.1027 | 0.201  | 0.2544 |  0.3335 |
|     3      | 0.3041 | 0.2121 | 0.342  | 0.3987 |  0.4783 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1725 | 0.0934 | 0.2117 | 0.2617 |  0.3202 |
|     1      | 0.1382 | 0.0678 | 0.1628 | 0.2064 |  0.2694 |
|     2      | 0.172  | 0.0969 | 0.1899 | 0.2372 |  0.3164 |
|     3      | 0.2645 | 0.1829 | 0.2929 | 0.3383 |  0.4134 |
|     4      | 0.282  | 0.1682 | 0.3167 | 0.3929 |  0.516  |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 18:56:58,514: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 156.4350609779358  |   0.274   |    0.166     |    0.337     |     0.478     |
|    1     | 130.11543369293213 |   0.204   |    0.112     |    0.248     |      0.38     |
|    2     | 97.23937892913818  |   0.181   |    0.098     |    0.214     |     0.338     |
|    3     | 66.13986849784851  |   0.182   |    0.102     |    0.213     |     0.332     |
|    4     | 51.005701303482056 |   0.179   |     0.1      |    0.207     |     0.327     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 18:56:58,515: Sum_Training_Time:500.93544340133667
2024-12-27 18:56:58,515: Every_Training_Time:[156.4350609779358, 130.11543369293213, 97.23937892913818, 66.13986849784851, 51.005701303482056]
2024-12-27 18:56:58,515: Forward transfer: 0.01845 Backward transfer: -0.05670000000000001
2024-12-27 18:57:36,049: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227185702/RELATIONrelation_0.001_1024_5000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.001_1024_5000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.001_1024_5000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 18:57:51,972: Snapshot:0	Epoch:0	Loss:64.234	translation_Loss:64.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.67	Hits@10:35.49	Best:16.67
2024-12-27 18:58:03,464: Snapshot:0	Epoch:1	Loss:30.863	translation_Loss:30.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.22	Hits@10:44.21	Best:23.22
2024-12-27 18:58:15,044: Snapshot:0	Epoch:2	Loss:14.474	translation_Loss:14.474	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.02	Hits@10:46.53	Best:26.02
2024-12-27 18:58:26,672: Snapshot:0	Epoch:3	Loss:7.682	translation_Loss:7.682	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.85	Hits@10:47.22	Best:26.85
2024-12-27 18:58:38,163: Snapshot:0	Epoch:4	Loss:4.976	translation_Loss:4.976	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.06	Hits@10:47.36	Best:27.06
2024-12-27 18:58:49,677: Snapshot:0	Epoch:5	Loss:3.77	translation_Loss:3.77	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.13	Hits@10:47.43	Best:27.13
2024-12-27 18:59:01,676: Snapshot:0	Epoch:6	Loss:3.138	translation_Loss:3.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.93	Hits@10:47.24	Best:27.13
2024-12-27 18:59:13,105: Snapshot:0	Epoch:7	Loss:2.76	translation_Loss:2.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.69	Hits@10:46.8	Best:27.13
2024-12-27 18:59:24,598: Snapshot:0	Epoch:8	Loss:2.511	translation_Loss:2.511	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.67	Hits@10:46.83	Best:27.13
2024-12-27 18:59:36,025: Snapshot:0	Epoch:9	Loss:2.302	translation_Loss:2.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.53	Hits@10:46.62	Best:27.13
2024-12-27 18:59:47,583: Early Stopping! Snapshot: 0 Epoch: 10 Best Results: 27.13
2024-12-27 18:59:47,583: Start to training tokens! Snapshot: 0 Epoch: 10 Loss:2.152 MRR:26.38 Best Results: 27.13
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 18:59:47,583: Snapshot:0	Epoch:10	Loss:2.152	translation_Loss:2.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.38	Hits@10:46.26	Best:27.13
2024-12-27 18:59:59,755: Snapshot:0	Epoch:11	Loss:49.425	translation_Loss:49.268	multi_layer_Loss:0.157	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.38	Hits@10:46.26	Best:27.13
2024-12-27 19:00:12,095: End of token training: 0 Epoch: 12 Loss:49.245 MRR:26.38 Best Results: 27.13
2024-12-27 19:00:12,095: Snapshot:0	Epoch:12	Loss:49.245	translation_Loss:49.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.38	Hits@10:46.26	Best:27.13
2024-12-27 19:00:12,391: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_5000/0model_best.tar'
2024-12-27 19:00:17,560: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2734 | 0.1642 | 0.3366 | 0.4058 |  0.4775 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:00:53,903: Snapshot:1	Epoch:0	Loss:48.364	translation_Loss:42.903	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.461                                                   	MRR:14.3	Hits@10:29.27	Best:14.3
2024-12-27 19:01:04,816: Snapshot:1	Epoch:1	Loss:23.438	translation_Loss:16.796	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.642                                                   	MRR:15.11	Hits@10:29.59	Best:15.11
2024-12-27 19:01:15,716: Snapshot:1	Epoch:2	Loss:20.234	translation_Loss:13.887	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.348                                                   	MRR:15.03	Hits@10:29.42	Best:15.11
2024-12-27 19:01:26,634: Snapshot:1	Epoch:3	Loss:19.447	translation_Loss:13.246	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.201                                                   	MRR:14.96	Hits@10:29.48	Best:15.11
2024-12-27 19:01:37,357: Snapshot:1	Epoch:4	Loss:19.155	translation_Loss:12.998	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.156                                                   	MRR:14.81	Hits@10:29.43	Best:15.11
2024-12-27 19:01:48,243: Snapshot:1	Epoch:5	Loss:18.872	translation_Loss:12.778	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.093                                                   	MRR:14.85	Hits@10:29.49	Best:15.11
2024-12-27 19:01:59,456: Early Stopping! Snapshot: 1 Epoch: 6 Best Results: 15.11
2024-12-27 19:01:59,457: Start to training tokens! Snapshot: 1 Epoch: 6 Loss:18.769 MRR:14.78 Best Results: 15.11
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:01:59,457: Snapshot:1	Epoch:6	Loss:18.769	translation_Loss:12.691	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.077                                                   	MRR:14.78	Hits@10:29.51	Best:15.11
2024-12-27 19:02:10,039: Snapshot:1	Epoch:7	Loss:61.003	translation_Loss:60.845	multi_layer_Loss:0.158	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.78	Hits@10:29.51	Best:15.11
2024-12-27 19:02:20,628: End of token training: 1 Epoch: 8 Loss:60.867 MRR:14.78 Best Results: 15.11
2024-12-27 19:02:20,629: Snapshot:1	Epoch:8	Loss:60.867	translation_Loss:60.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:14.78	Hits@10:29.51	Best:15.11
2024-12-27 19:02:20,936: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_5000/1model_best.tar'
2024-12-27 19:02:30,766: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2505 | 0.1426 | 0.3095 | 0.3778 |  0.4567 |
|     1      | 0.1513 | 0.0769 | 0.1783 | 0.228  |  0.297  |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:02:58,923: Snapshot:2	Epoch:0	Loss:30.012	translation_Loss:24.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.098                                                   	MRR:19.3	Hits@10:36.57	Best:19.3
2024-12-27 19:03:06,924: Snapshot:2	Epoch:1	Loss:13.072	translation_Loss:7.71	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.362                                                   	MRR:20.12	Hits@10:36.45	Best:20.12
2024-12-27 19:03:15,006: Snapshot:2	Epoch:2	Loss:10.691	translation_Loss:6.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.536                                                   	MRR:20.19	Hits@10:36.03	Best:20.19
2024-12-27 19:03:23,117: Snapshot:2	Epoch:3	Loss:10.207	translation_Loss:5.84	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.367                                                   	MRR:19.85	Hits@10:35.39	Best:20.19
2024-12-27 19:03:31,092: Snapshot:2	Epoch:4	Loss:9.983	translation_Loss:5.66	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.323                                                   	MRR:19.87	Hits@10:35.49	Best:20.19
2024-12-27 19:03:39,087: Snapshot:2	Epoch:5	Loss:9.949	translation_Loss:5.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.299                                                   	MRR:19.92	Hits@10:35.24	Best:20.19
2024-12-27 19:03:47,041: Snapshot:2	Epoch:6	Loss:9.877	translation_Loss:5.576	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.302                                                   	MRR:19.86	Hits@10:35.35	Best:20.19
2024-12-27 19:03:55,017: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 20.19
2024-12-27 19:03:55,018: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:9.886 MRR:19.91 Best Results: 20.19
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:03:55,018: Snapshot:2	Epoch:7	Loss:9.886	translation_Loss:5.566	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.32                                                   	MRR:19.91	Hits@10:35.28	Best:20.19
2024-12-27 19:04:02,839: Snapshot:2	Epoch:8	Loss:45.327	translation_Loss:45.161	multi_layer_Loss:0.165	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.91	Hits@10:35.28	Best:20.19
2024-12-27 19:04:10,650: End of token training: 2 Epoch: 9 Loss:45.128 MRR:19.91 Best Results: 20.19
2024-12-27 19:04:10,650: Snapshot:2	Epoch:9	Loss:45.128	translation_Loss:45.128	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.91	Hits@10:35.28	Best:20.19
2024-12-27 19:04:11,034: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_5000/2model_best.tar'
2024-12-27 19:04:24,193: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.212  | 0.1117 | 0.2672 | 0.3305 |  0.4007 |
|     1      | 0.1387 | 0.0653 | 0.1637 | 0.2129 |  0.2816 |
|     2      | 0.198  | 0.1192 | 0.222  | 0.2763 |  0.3557 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:04:39,921: Snapshot:3	Epoch:0	Loss:16.44	translation_Loss:15.149	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.291                                                   	MRR:19.52	Hits@10:37.4	Best:19.52
2024-12-27 19:04:43,648: Snapshot:3	Epoch:1	Loss:7.473	translation_Loss:5.196	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.277                                                   	MRR:27.23	Hits@10:43.82	Best:27.23
2024-12-27 19:04:47,510: Snapshot:3	Epoch:2	Loss:4.874	translation_Loss:2.595	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.279                                                   	MRR:28.18	Hits@10:44.87	Best:28.18
2024-12-27 19:04:51,271: Snapshot:3	Epoch:3	Loss:4.055	translation_Loss:1.932	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.123                                                   	MRR:28.75	Hits@10:44.9	Best:28.75
2024-12-27 19:04:55,070: Snapshot:3	Epoch:4	Loss:3.688	translation_Loss:1.672	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.016                                                   	MRR:28.7	Hits@10:44.57	Best:28.75
2024-12-27 19:04:58,803: Snapshot:3	Epoch:5	Loss:3.497	translation_Loss:1.561	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.936                                                   	MRR:28.34	Hits@10:44.04	Best:28.75
2024-12-27 19:05:02,491: Snapshot:3	Epoch:6	Loss:3.389	translation_Loss:1.504	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.885                                                   	MRR:28.3	Hits@10:43.77	Best:28.75
2024-12-27 19:05:06,207: Snapshot:3	Epoch:7	Loss:3.316	translation_Loss:1.458	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.858                                                   	MRR:27.82	Hits@10:43.74	Best:28.75
2024-12-27 19:05:09,916: Early Stopping! Snapshot: 3 Epoch: 8 Best Results: 28.75
2024-12-27 19:05:09,916: Start to training tokens! Snapshot: 3 Epoch: 8 Loss:3.283 MRR:28.06 Best Results: 28.75
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:05:09,916: Snapshot:3	Epoch:8	Loss:3.283	translation_Loss:1.446	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.838                                                   	MRR:28.06	Hits@10:43.24	Best:28.75
2024-12-27 19:05:13,522: Snapshot:3	Epoch:9	Loss:16.498	translation_Loss:16.357	multi_layer_Loss:0.141	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.06	Hits@10:43.24	Best:28.75
2024-12-27 19:05:17,142: End of token training: 3 Epoch: 10 Loss:16.368 MRR:28.06 Best Results: 28.75
2024-12-27 19:05:17,143: Snapshot:3	Epoch:10	Loss:16.368	translation_Loss:16.367	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:28.06	Hits@10:43.24	Best:28.75
2024-12-27 19:05:17,497: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_5000/3model_best.tar'
2024-12-27 19:05:32,834: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2092 | 0.1103 | 0.2652 | 0.3252 |  0.3936 |
|     1      | 0.1378 | 0.0645 | 0.162  | 0.2114 |  0.2809 |
|     2      | 0.1727 | 0.0992 | 0.1917 | 0.2402 |  0.3158 |
|     3      | 0.2876 | 0.2013 | 0.3225 | 0.3759 |  0.4483 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:05:45,343: Snapshot:4	Epoch:0	Loss:9.057	translation_Loss:8.291	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.766                                                   	MRR:15.63	Hits@10:35.29	Best:15.63
2024-12-27 19:05:48,026: Snapshot:4	Epoch:1	Loss:4.018	translation_Loss:2.699	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.318                                                   	MRR:23.79	Hits@10:45.49	Best:23.79
2024-12-27 19:05:50,687: Snapshot:4	Epoch:2	Loss:2.448	translation_Loss:1.094	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.354                                                   	MRR:26.34	Hits@10:48.06	Best:26.34
2024-12-27 19:05:53,383: Snapshot:4	Epoch:3	Loss:1.925	translation_Loss:0.698	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.228                                                   	MRR:26.72	Hits@10:49.68	Best:26.72
2024-12-27 19:05:56,179: Snapshot:4	Epoch:4	Loss:1.682	translation_Loss:0.555	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.127                                                   	MRR:27.22	Hits@10:50.22	Best:27.22
2024-12-27 19:05:58,825: Snapshot:4	Epoch:5	Loss:1.534	translation_Loss:0.497	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.037                                                   	MRR:26.6	Hits@10:50.27	Best:27.22
2024-12-27 19:06:01,485: Snapshot:4	Epoch:6	Loss:1.45	translation_Loss:0.467	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.983                                                   	MRR:27.23	Hits@10:50.54	Best:27.23
2024-12-27 19:06:04,205: Snapshot:4	Epoch:7	Loss:1.393	translation_Loss:0.446	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.946                                                   	MRR:27.48	Hits@10:51.13	Best:27.48
2024-12-27 19:06:06,781: Snapshot:4	Epoch:8	Loss:1.344	translation_Loss:0.427	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.917                                                   	MRR:27.36	Hits@10:50.57	Best:27.48
2024-12-27 19:06:09,406: Snapshot:4	Epoch:9	Loss:1.323	translation_Loss:0.425	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.897                                                   	MRR:27.12	Hits@10:50.72	Best:27.48
2024-12-27 19:06:12,016: Snapshot:4	Epoch:10	Loss:1.305	translation_Loss:0.418	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.887                                                   	MRR:26.91	Hits@10:50.82	Best:27.48
2024-12-27 19:06:14,640: Snapshot:4	Epoch:11	Loss:1.278	translation_Loss:0.405	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.872                                                   	MRR:26.9	Hits@10:50.68	Best:27.48
2024-12-27 19:06:17,255: Early Stopping! Snapshot: 4 Epoch: 12 Best Results: 27.48
2024-12-27 19:06:17,255: Start to training tokens! Snapshot: 4 Epoch: 12 Loss:1.275 MRR:27.06 Best Results: 27.48
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:06:17,255: Snapshot:4	Epoch:12	Loss:1.275	translation_Loss:0.409	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.866                                                   	MRR:27.06	Hits@10:51.11	Best:27.48
2024-12-27 19:06:19,831: Snapshot:4	Epoch:13	Loss:9.573	translation_Loss:9.42	multi_layer_Loss:0.153	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.06	Hits@10:51.11	Best:27.48
2024-12-27 19:06:22,363: End of token training: 4 Epoch: 14 Loss:9.424 MRR:27.06 Best Results: 27.48
2024-12-27 19:06:22,364: Snapshot:4	Epoch:14	Loss:9.424	translation_Loss:9.421	multi_layer_Loss:0.003	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.06	Hits@10:51.11	Best:27.48
2024-12-27 19:06:22,746: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_5000/4model_best.tar'
2024-12-27 19:06:39,634: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2007 | 0.1049 | 0.252  | 0.312  |  0.3774 |
|     1      | 0.1359 | 0.0624 | 0.1597 | 0.2109 |  0.2811 |
|     2      | 0.1656 | 0.096  | 0.1812 | 0.2286 |  0.3039 |
|     3      |  0.27  | 0.1875 | 0.2979 | 0.345  |  0.4264 |
|     4      | 0.2693 | 0.1558 | 0.3016 | 0.3853 |  0.5112 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 19:06:39,636: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2734 | 0.1642 | 0.3366 | 0.4058 |  0.4775 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2505 | 0.1426 | 0.3095 | 0.3778 |  0.4567 |
|     1      | 0.1513 | 0.0769 | 0.1783 | 0.228  |  0.297  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.212  | 0.1117 | 0.2672 | 0.3305 |  0.4007 |
|     1      | 0.1387 | 0.0653 | 0.1637 | 0.2129 |  0.2816 |
|     2      | 0.198  | 0.1192 | 0.222  | 0.2763 |  0.3557 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2092 | 0.1103 | 0.2652 | 0.3252 |  0.3936 |
|     1      | 0.1378 | 0.0645 | 0.162  | 0.2114 |  0.2809 |
|     2      | 0.1727 | 0.0992 | 0.1917 | 0.2402 |  0.3158 |
|     3      | 0.2876 | 0.2013 | 0.3225 | 0.3759 |  0.4483 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2007 | 0.1049 | 0.252  | 0.312  |  0.3774 |
|     1      | 0.1359 | 0.0624 | 0.1597 | 0.2109 |  0.2811 |
|     2      | 0.1656 | 0.096  | 0.1812 | 0.2286 |  0.3039 |
|     3      |  0.27  | 0.1875 | 0.2979 | 0.345  |  0.4264 |
|     4      | 0.2693 | 0.1558 | 0.3016 | 0.3853 |  0.5112 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 19:06:39,637: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 156.0456485748291  |   0.273   |    0.164     |    0.337     |     0.477     |
|    1     | 118.44719004631042 |   0.202   |    0.111     |    0.246     |     0.379     |
|    2     | 96.31780648231506  |   0.182   |    0.097     |    0.218     |     0.346     |
|    3     | 51.00653553009033  |   0.186   |    0.102     |    0.221     |     0.345     |
|    4     | 48.02407765388489  |   0.185   |    0.102     |    0.217     |     0.347     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 19:06:39,637: Sum_Training_Time:469.8412582874298
2024-12-27 19:06:39,637: Every_Training_Time:[156.0456485748291, 118.44719004631042, 96.31780648231506, 51.00653553009033, 48.02407765388489]
2024-12-27 19:06:39,637: Forward transfer: 0.017575 Backward transfer: -0.034525
2024-12-27 19:07:17,184: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227190643/RELATIONrelation_0.001_1024_10000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.001_1024_10000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.001_1024_10000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 19:07:33,136: Snapshot:0	Epoch:0	Loss:64.234	translation_Loss:64.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.67	Hits@10:35.49	Best:16.67
2024-12-27 19:07:44,566: Snapshot:0	Epoch:1	Loss:30.86	translation_Loss:30.86	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.33	Hits@10:44.31	Best:23.33
2024-12-27 19:07:56,078: Snapshot:0	Epoch:2	Loss:14.473	translation_Loss:14.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.03	Hits@10:46.53	Best:26.03
2024-12-27 19:08:07,687: Snapshot:0	Epoch:3	Loss:7.682	translation_Loss:7.682	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.75	Hits@10:47.24	Best:26.75
2024-12-27 19:08:19,258: Snapshot:0	Epoch:4	Loss:4.98	translation_Loss:4.98	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.09	Hits@10:47.5	Best:27.09
2024-12-27 19:08:30,774: Snapshot:0	Epoch:5	Loss:3.766	translation_Loss:3.766	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.07	Hits@10:47.42	Best:27.09
2024-12-27 19:08:42,763: Snapshot:0	Epoch:6	Loss:3.131	translation_Loss:3.131	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.82	Hits@10:47.15	Best:27.09
2024-12-27 19:08:54,378: Snapshot:0	Epoch:7	Loss:2.761	translation_Loss:2.761	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.71	Hits@10:46.76	Best:27.09
2024-12-27 19:09:05,865: Snapshot:0	Epoch:8	Loss:2.52	translation_Loss:2.52	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.56	Hits@10:46.56	Best:27.09
2024-12-27 19:09:17,408: Early Stopping! Snapshot: 0 Epoch: 9 Best Results: 27.09
2024-12-27 19:09:17,408: Start to training tokens! Snapshot: 0 Epoch: 9 Loss:2.293 MRR:26.53 Best Results: 27.09
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:09:17,409: Snapshot:0	Epoch:9	Loss:2.293	translation_Loss:2.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.53	Hits@10:46.62	Best:27.09
2024-12-27 19:09:29,677: Snapshot:0	Epoch:10	Loss:49.67	translation_Loss:49.514	multi_layer_Loss:0.157	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.53	Hits@10:46.62	Best:27.09
2024-12-27 19:09:41,329: End of token training: 0 Epoch: 11 Loss:49.545 MRR:26.53 Best Results: 27.09
2024-12-27 19:09:41,329: Snapshot:0	Epoch:11	Loss:49.545	translation_Loss:49.545	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.53	Hits@10:46.62	Best:27.09
2024-12-27 19:09:41,698: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_10000/0model_best.tar'
2024-12-27 19:09:47,532: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2736 | 0.1641 | 0.3374 | 0.4042 |  0.4768 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:10:23,810: Snapshot:1	Epoch:0	Loss:50.571	translation_Loss:44.834	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.738                                                   	MRR:13.24	Hits@10:28.03	Best:13.24
2024-12-27 19:10:34,626: Snapshot:1	Epoch:1	Loss:26.125	translation_Loss:19.779	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.347                                                   	MRR:13.94	Hits@10:28.16	Best:13.94
2024-12-27 19:10:45,484: Snapshot:1	Epoch:2	Loss:22.84	translation_Loss:16.827	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.013                                                   	MRR:14.14	Hits@10:28.25	Best:14.14
2024-12-27 19:10:56,287: Snapshot:1	Epoch:3	Loss:21.981	translation_Loss:16.114	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.866                                                   	MRR:13.97	Hits@10:27.97	Best:14.14
2024-12-27 19:11:07,057: Snapshot:1	Epoch:4	Loss:21.59	translation_Loss:15.79	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.801                                                   	MRR:13.92	Hits@10:28.22	Best:14.14
2024-12-27 19:11:17,807: Snapshot:1	Epoch:5	Loss:21.422	translation_Loss:15.654	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.768                                                   	MRR:13.86	Hits@10:28.17	Best:14.14
2024-12-27 19:11:28,627: Snapshot:1	Epoch:6	Loss:21.202	translation_Loss:15.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.748                                                   	MRR:13.98	Hits@10:28.34	Best:14.14
2024-12-27 19:11:39,343: Early Stopping! Snapshot: 1 Epoch: 7 Best Results: 14.14
2024-12-27 19:11:39,343: Start to training tokens! Snapshot: 1 Epoch: 7 Loss:21.058 MRR:13.87 Best Results: 14.14
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:11:39,343: Snapshot:1	Epoch:7	Loss:21.058	translation_Loss:15.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.725                                                   	MRR:13.87	Hits@10:28.3	Best:14.14
2024-12-27 19:11:49,945: Snapshot:1	Epoch:8	Loss:63.138	translation_Loss:62.98	multi_layer_Loss:0.158	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.87	Hits@10:28.3	Best:14.14
2024-12-27 19:12:00,474: End of token training: 1 Epoch: 9 Loss:63.015 MRR:13.87 Best Results: 14.14
2024-12-27 19:12:00,474: Snapshot:1	Epoch:9	Loss:63.015	translation_Loss:63.015	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:13.87	Hits@10:28.3	Best:14.14
2024-12-27 19:12:00,846: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_10000/1model_best.tar'
2024-12-27 19:12:10,898: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2552 | 0.1414 | 0.3219 | 0.3949 |  0.4692 |
|     1      | 0.1423 | 0.071  | 0.1672 | 0.2156 |  0.2829 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:12:38,892: Snapshot:2	Epoch:0	Loss:33.078	translation_Loss:26.763	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.315                                                   	MRR:18.69	Hits@10:34.62	Best:18.69
2024-12-27 19:12:46,887: Snapshot:2	Epoch:1	Loss:15.805	translation_Loss:9.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.997                                                   	MRR:19.46	Hits@10:34.67	Best:19.46
2024-12-27 19:12:55,012: Snapshot:2	Epoch:2	Loss:13.271	translation_Loss:8.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.124                                                   	MRR:19.49	Hits@10:34.46	Best:19.49
2024-12-27 19:13:02,980: Snapshot:2	Epoch:3	Loss:12.748	translation_Loss:7.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.988                                                   	MRR:19.49	Hits@10:34.43	Best:19.49
2024-12-27 19:13:10,933: Snapshot:2	Epoch:4	Loss:12.607	translation_Loss:7.663	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.945                                                   	MRR:19.29	Hits@10:33.99	Best:19.49
2024-12-27 19:13:18,943: Snapshot:2	Epoch:5	Loss:12.48	translation_Loss:7.551	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.929                                                   	MRR:19.17	Hits@10:34.1	Best:19.49
2024-12-27 19:13:27,067: Snapshot:2	Epoch:6	Loss:12.464	translation_Loss:7.538	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.925                                                   	MRR:19.27	Hits@10:34.1	Best:19.49
2024-12-27 19:13:35,036: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 19.49
2024-12-27 19:13:35,037: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:12.407 MRR:19.26 Best Results: 19.49
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:13:35,037: Snapshot:2	Epoch:7	Loss:12.407	translation_Loss:7.484	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.923                                                   	MRR:19.26	Hits@10:34.0	Best:19.49
2024-12-27 19:13:42,876: Snapshot:2	Epoch:8	Loss:47.769	translation_Loss:47.604	multi_layer_Loss:0.165	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.26	Hits@10:34.0	Best:19.49
2024-12-27 19:13:50,649: End of token training: 2 Epoch: 9 Loss:47.574 MRR:19.26 Best Results: 19.49
2024-12-27 19:13:50,649: Snapshot:2	Epoch:9	Loss:47.574	translation_Loss:47.574	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.26	Hits@10:34.0	Best:19.49
2024-12-27 19:13:51,029: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_10000/2model_best.tar'
2024-12-27 19:14:04,860: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2197 | 0.1154 | 0.2743 | 0.345  |  0.4224 |
|     1      | 0.1346 | 0.0639 | 0.1573 | 0.206  |  0.2733 |
|     2      | 0.1934 | 0.1192 | 0.2153 | 0.2665 |  0.3423 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:14:20,644: Snapshot:3	Epoch:0	Loss:17.405	translation_Loss:15.778	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.627                                                   	MRR:18.25	Hits@10:35.68	Best:18.25
2024-12-27 19:14:24,425: Snapshot:3	Epoch:1	Loss:9.12	translation_Loss:6.625	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.495                                                   	MRR:25.49	Hits@10:41.23	Best:25.49
2024-12-27 19:14:28,216: Snapshot:3	Epoch:2	Loss:6.399	translation_Loss:4.047	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.352                                                   	MRR:26.88	Hits@10:42.18	Best:26.88
2024-12-27 19:14:32,041: Snapshot:3	Epoch:3	Loss:5.445	translation_Loss:3.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.2                                                   	MRR:27.17	Hits@10:42.26	Best:27.17
2024-12-27 19:14:35,747: Snapshot:3	Epoch:4	Loss:5.008	translation_Loss:2.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.094                                                   	MRR:27.11	Hits@10:42.13	Best:27.17
2024-12-27 19:14:39,506: Snapshot:3	Epoch:5	Loss:4.805	translation_Loss:2.781	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.024                                                   	MRR:27.05	Hits@10:41.78	Best:27.17
2024-12-27 19:14:43,214: Snapshot:3	Epoch:6	Loss:4.653	translation_Loss:2.67	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.983                                                   	MRR:26.9	Hits@10:41.47	Best:27.17
2024-12-27 19:14:46,897: Snapshot:3	Epoch:7	Loss:4.57	translation_Loss:2.613	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.957                                                   	MRR:26.66	Hits@10:41.75	Best:27.17
2024-12-27 19:14:50,545: Early Stopping! Snapshot: 3 Epoch: 8 Best Results: 27.17
2024-12-27 19:14:50,545: Start to training tokens! Snapshot: 3 Epoch: 8 Loss:4.516 MRR:26.5 Best Results: 27.17
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:14:50,546: Snapshot:3	Epoch:8	Loss:4.516	translation_Loss:2.6	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.916                                                   	MRR:26.5	Hits@10:41.43	Best:27.17
2024-12-27 19:14:54,177: Snapshot:3	Epoch:9	Loss:17.758	translation_Loss:17.617	multi_layer_Loss:0.141	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.5	Hits@10:41.43	Best:27.17
2024-12-27 19:14:57,792: End of token training: 3 Epoch: 10 Loss:17.636 MRR:26.5 Best Results: 27.17
2024-12-27 19:14:57,792: Snapshot:3	Epoch:10	Loss:17.636	translation_Loss:17.635	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.5	Hits@10:41.43	Best:27.17
2024-12-27 19:14:58,030: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_10000/3model_best.tar'
2024-12-27 19:15:13,505: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.218  | 0.1154 | 0.2738 | 0.3416 |  0.4174 |
|     1      | 0.1349 | 0.0645 | 0.1582 | 0.2062 |  0.2739 |
|     2      | 0.1715 | 0.1019 | 0.1861 | 0.2378 |  0.3105 |
|     3      | 0.2685 | 0.182  | 0.3062 | 0.3607 |  0.4283 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:15:26,165: Snapshot:4	Epoch:0	Loss:10.21	translation_Loss:9.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.012                                                   	MRR:14.78	Hits@10:34.5	Best:14.78
2024-12-27 19:15:28,868: Snapshot:4	Epoch:1	Loss:5.253	translation_Loss:3.507	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.746                                                   	MRR:22.7	Hits@10:43.53	Best:22.7
2024-12-27 19:15:31,518: Snapshot:4	Epoch:2	Loss:3.579	translation_Loss:1.912	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.666                                                   	MRR:25.38	Hits@10:46.96	Best:25.38
2024-12-27 19:15:34,245: Snapshot:4	Epoch:3	Loss:2.88	translation_Loss:1.376	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.505                                                   	MRR:26.07	Hits@10:47.62	Best:26.07
2024-12-27 19:15:36,943: Snapshot:4	Epoch:4	Loss:2.558	translation_Loss:1.166	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.392                                                   	MRR:26.2	Hits@10:48.78	Best:26.2
2024-12-27 19:15:39,619: Snapshot:4	Epoch:5	Loss:2.343	translation_Loss:1.031	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.312                                                   	MRR:26.46	Hits@10:49.39	Best:26.46
2024-12-27 19:15:42,251: Snapshot:4	Epoch:6	Loss:2.25	translation_Loss:0.991	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.259                                                   	MRR:26.07	Hits@10:48.77	Best:26.46
2024-12-27 19:15:44,839: Snapshot:4	Epoch:7	Loss:2.183	translation_Loss:0.958	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.225                                                   	MRR:25.88	Hits@10:48.82	Best:26.46
2024-12-27 19:15:47,413: Snapshot:4	Epoch:8	Loss:2.123	translation_Loss:0.928	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.195                                                   	MRR:25.88	Hits@10:48.53	Best:26.46
2024-12-27 19:15:50,019: Snapshot:4	Epoch:9	Loss:2.091	translation_Loss:0.915	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.175                                                   	MRR:25.46	Hits@10:48.02	Best:26.46
2024-12-27 19:15:52,601: Early Stopping! Snapshot: 4 Epoch: 10 Best Results: 26.46
2024-12-27 19:15:52,601: Start to training tokens! Snapshot: 4 Epoch: 10 Loss:2.059 MRR:25.13 Best Results: 26.46
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:15:52,601: Snapshot:4	Epoch:10	Loss:2.059	translation_Loss:0.891	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.168                                                   	MRR:25.13	Hits@10:48.25	Best:26.46
2024-12-27 19:15:55,129: Snapshot:4	Epoch:11	Loss:10.422	translation_Loss:10.269	multi_layer_Loss:0.153	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.13	Hits@10:48.25	Best:26.46
2024-12-27 19:15:57,657: End of token training: 4 Epoch: 12 Loss:10.25 MRR:25.13 Best Results: 26.46
2024-12-27 19:15:57,657: Snapshot:4	Epoch:12	Loss:10.25	translation_Loss:10.247	multi_layer_Loss:0.003	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:25.13	Hits@10:48.25	Best:26.46
2024-12-27 19:15:57,891: => loading checkpoint './checkpoint/RELATIONrelation_0.001_1024_10000/4model_best.tar'
2024-12-27 19:16:14,871: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2091 | 0.1088 | 0.2624 | 0.3275 |   0.4   |
|     1      | 0.1342 | 0.0637 | 0.1576 | 0.2052 |  0.2734 |
|     2      | 0.1669 | 0.1006 | 0.1816 | 0.2281 |  0.3002 |
|     3      | 0.2579 | 0.1751 | 0.2885 | 0.3364 |  0.4148 |
|     4      | 0.2608 | 0.1498 | 0.2913 | 0.3783 |  0.4943 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 19:16:14,873: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2736 | 0.1641 | 0.3374 | 0.4042 |  0.4768 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2552 | 0.1414 | 0.3219 | 0.3949 |  0.4692 |
|     1      | 0.1423 | 0.071  | 0.1672 | 0.2156 |  0.2829 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2197 | 0.1154 | 0.2743 | 0.345  |  0.4224 |
|     1      | 0.1346 | 0.0639 | 0.1573 | 0.206  |  0.2733 |
|     2      | 0.1934 | 0.1192 | 0.2153 | 0.2665 |  0.3423 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.218  | 0.1154 | 0.2738 | 0.3416 |  0.4174 |
|     1      | 0.1349 | 0.0645 | 0.1582 | 0.2062 |  0.2739 |
|     2      | 0.1715 | 0.1019 | 0.1861 | 0.2378 |  0.3105 |
|     3      | 0.2685 | 0.182  | 0.3062 | 0.3607 |  0.4283 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2091 | 0.1088 | 0.2624 | 0.3275 |   0.4   |
|     1      | 0.1342 | 0.0637 | 0.1576 | 0.2052 |  0.2734 |
|     2      | 0.1669 | 0.1006 | 0.1816 | 0.2281 |  0.3002 |
|     3      | 0.2579 | 0.1751 | 0.2885 | 0.3364 |  0.4148 |
|     4      | 0.2608 | 0.1498 | 0.2913 | 0.3783 |  0.4943 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 19:16:14,874: Report Result:
+----------+-------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time       | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+-------------------+-----------+--------------+--------------+---------------+
|    0     | 144.1443955898285 |   0.274   |    0.164     |    0.337     |     0.477     |
|    1     | 128.5937795639038 |    0.2    |    0.107     |    0.247     |     0.379     |
|    2     | 96.18296456336975 |   0.182   |    0.098     |    0.217     |     0.348     |
|    3     | 50.95915508270264 |   0.186   |    0.103     |     0.22     |     0.348     |
|    4     | 42.60897088050842 |   0.186   |    0.103     |    0.218     |     0.349     |
+----------+-------------------+-----------+--------------+--------------+---------------+
2024-12-27 19:16:14,874: Sum_Training_Time:462.4892656803131
2024-12-27 19:16:14,874: Every_Training_Time:[144.1443955898285, 128.5937795639038, 96.18296456336975, 50.95915508270264, 42.60897088050842]
2024-12-27 19:16:14,874: Forward transfer: 0.01685 Backward transfer: -0.027424999999999998
2024-12-27 19:16:52,124: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227191618/RELATIONrelation_0.001_2048_1000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.001_2048_1000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.001_2048_1000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 19:17:07,958: Snapshot:0	Epoch:0	Loss:34.762	translation_Loss:34.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.3	Hits@10:29.6	Best:12.3
2024-12-27 19:17:19,928: Snapshot:0	Epoch:1	Loss:19.584	translation_Loss:19.584	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.22	Hits@10:42.58	Best:21.22
2024-12-27 19:17:31,412: Snapshot:0	Epoch:2	Loss:10.296	translation_Loss:10.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.1	Hits@10:46.25	Best:25.1
2024-12-27 19:17:42,956: Snapshot:0	Epoch:3	Loss:5.408	translation_Loss:5.408	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.6	Hits@10:47.58	Best:26.6
2024-12-27 19:17:54,362: Snapshot:0	Epoch:4	Loss:3.236	translation_Loss:3.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.2	Hits@10:48.06	Best:27.2
2024-12-27 19:18:06,233: Snapshot:0	Epoch:5	Loss:2.271	translation_Loss:2.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.4	Hits@10:48.17	Best:27.4
2024-12-27 19:18:17,599: Snapshot:0	Epoch:6	Loss:1.781	translation_Loss:1.781	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.39	Hits@10:47.78	Best:27.4
2024-12-27 19:18:29,011: Snapshot:0	Epoch:7	Loss:1.504	translation_Loss:1.504	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.17	Hits@10:47.77	Best:27.4
2024-12-27 19:18:41,107: Snapshot:0	Epoch:8	Loss:1.332	translation_Loss:1.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.27	Hits@10:47.67	Best:27.4
2024-12-27 19:18:52,484: Snapshot:0	Epoch:9	Loss:1.198	translation_Loss:1.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.31	Hits@10:47.6	Best:27.4
2024-12-27 19:19:03,972: Early Stopping! Snapshot: 0 Epoch: 10 Best Results: 27.4
2024-12-27 19:19:03,972: Start to training tokens! Snapshot: 0 Epoch: 10 Loss:1.109 MRR:27.03 Best Results: 27.4
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:19:03,973: Snapshot:0	Epoch:10	Loss:1.109	translation_Loss:1.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.03	Hits@10:47.38	Best:27.4
2024-12-27 19:19:16,037: Snapshot:0	Epoch:11	Loss:24.848	translation_Loss:24.692	multi_layer_Loss:0.157	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.03	Hits@10:47.38	Best:27.4
2024-12-27 19:19:27,929: End of token training: 0 Epoch: 12 Loss:24.681 MRR:27.03 Best Results: 27.4
2024-12-27 19:19:27,929: Snapshot:0	Epoch:12	Loss:24.681	translation_Loss:24.681	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.03	Hits@10:47.38	Best:27.4
2024-12-27 19:19:28,223: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_1000/0model_best.tar'
2024-12-27 19:19:33,649: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2783 | 0.1666 | 0.3452 | 0.4138 |  0.4854 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:20:10,132: Snapshot:1	Epoch:0	Loss:27.148	translation_Loss:25.814	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.334                                                   	MRR:13.47	Hits@10:29.53	Best:13.47
2024-12-27 19:20:20,865: Snapshot:1	Epoch:1	Loss:10.713	translation_Loss:7.906	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.807                                                   	MRR:18.3	Hits@10:35.52	Best:18.3
2024-12-27 19:20:31,409: Snapshot:1	Epoch:2	Loss:6.301	translation_Loss:3.168	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.132                                                   	MRR:18.73	Hits@10:35.62	Best:18.73
2024-12-27 19:20:41,924: Snapshot:1	Epoch:3	Loss:5.243	translation_Loss:2.264	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.979                                                   	MRR:18.45	Hits@10:35.51	Best:18.73
2024-12-27 19:20:52,489: Snapshot:1	Epoch:4	Loss:4.931	translation_Loss:2.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.89                                                   	MRR:18.57	Hits@10:35.34	Best:18.73
2024-12-27 19:21:03,052: Snapshot:1	Epoch:5	Loss:4.779	translation_Loss:1.939	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.839                                                   	MRR:18.63	Hits@10:35.32	Best:18.73
2024-12-27 19:21:13,618: Snapshot:1	Epoch:6	Loss:4.715	translation_Loss:1.9	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.815                                                   	MRR:18.23	Hits@10:35.15	Best:18.73
2024-12-27 19:21:24,340: Early Stopping! Snapshot: 1 Epoch: 7 Best Results: 18.73
2024-12-27 19:21:24,340: Start to training tokens! Snapshot: 1 Epoch: 7 Loss:4.678 MRR:18.11 Best Results: 18.73
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:21:24,341: Snapshot:1	Epoch:7	Loss:4.678	translation_Loss:1.866	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.813                                                   	MRR:18.11	Hits@10:35.11	Best:18.73
2024-12-27 19:21:34,751: Snapshot:1	Epoch:8	Loss:27.045	translation_Loss:26.887	multi_layer_Loss:0.158	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.11	Hits@10:35.11	Best:18.73
2024-12-27 19:21:45,127: End of token training: 1 Epoch: 9 Loss:26.913 MRR:18.11 Best Results: 18.73
2024-12-27 19:21:45,128: Snapshot:1	Epoch:9	Loss:26.913	translation_Loss:26.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:18.11	Hits@10:35.11	Best:18.73
2024-12-27 19:21:45,498: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_1000/1model_best.tar'
2024-12-27 19:21:55,637: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2216 | 0.1188 | 0.2768 | 0.3419 |  0.4123 |
|     1      | 0.1887 | 0.1005 | 0.2249 | 0.2824 |  0.3577 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:22:23,188: Snapshot:2	Epoch:0	Loss:15.357	translation_Loss:14.389	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.967                                                   	MRR:14.68	Hits@10:30.73	Best:14.68
2024-12-27 19:22:31,083: Snapshot:2	Epoch:1	Loss:4.664	translation_Loss:3.0	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.665                                                   	MRR:20.28	Hits@10:38.13	Best:20.28
2024-12-27 19:22:39,069: Snapshot:2	Epoch:2	Loss:2.824	translation_Loss:1.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.567                                                   	MRR:21.79	Hits@10:40.21	Best:21.79
2024-12-27 19:22:47,637: Snapshot:2	Epoch:3	Loss:2.277	translation_Loss:0.864	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.413                                                   	MRR:22.07	Hits@10:40.57	Best:22.07
2024-12-27 19:22:55,459: Snapshot:2	Epoch:4	Loss:2.046	translation_Loss:0.718	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.328                                                   	MRR:21.87	Hits@10:39.96	Best:22.07
2024-12-27 19:23:03,309: Snapshot:2	Epoch:5	Loss:1.893	translation_Loss:0.64	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.253                                                   	MRR:22.38	Hits@10:39.97	Best:22.38
2024-12-27 19:23:11,197: Snapshot:2	Epoch:6	Loss:1.823	translation_Loss:0.617	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.206                                                   	MRR:22.48	Hits@10:40.04	Best:22.48
2024-12-27 19:23:19,121: Snapshot:2	Epoch:7	Loss:1.776	translation_Loss:0.606	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.17                                                   	MRR:22.51	Hits@10:39.68	Best:22.51
2024-12-27 19:23:27,630: Snapshot:2	Epoch:8	Loss:1.737	translation_Loss:0.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.152                                                   	MRR:22.34	Hits@10:40.16	Best:22.51
2024-12-27 19:23:35,448: Snapshot:2	Epoch:9	Loss:1.695	translation_Loss:0.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.127                                                   	MRR:21.82	Hits@10:39.31	Best:22.51
2024-12-27 19:23:43,502: Snapshot:2	Epoch:10	Loss:1.704	translation_Loss:0.582	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.123                                                   	MRR:21.85	Hits@10:39.18	Best:22.51
2024-12-27 19:23:51,377: Snapshot:2	Epoch:11	Loss:1.684	translation_Loss:0.568	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.116                                                   	MRR:21.78	Hits@10:38.78	Best:22.51
2024-12-27 19:23:59,220: Early Stopping! Snapshot: 2 Epoch: 12 Best Results: 22.51
2024-12-27 19:23:59,220: Start to training tokens! Snapshot: 2 Epoch: 12 Loss:1.698 MRR:21.02 Best Results: 22.51
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:23:59,220: Snapshot:2	Epoch:12	Loss:1.698	translation_Loss:0.579	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.119                                                   	MRR:21.02	Hits@10:38.28	Best:22.51
2024-12-27 19:24:07,463: Snapshot:2	Epoch:13	Loss:18.788	translation_Loss:18.624	multi_layer_Loss:0.164	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.02	Hits@10:38.28	Best:22.51
2024-12-27 19:24:15,155: End of token training: 2 Epoch: 14 Loss:18.632 MRR:21.02 Best Results: 22.51
2024-12-27 19:24:15,156: Snapshot:2	Epoch:14	Loss:18.632	translation_Loss:18.631	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.02	Hits@10:38.28	Best:22.51
2024-12-27 19:24:15,464: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_1000/2model_best.tar'
2024-12-27 19:24:29,489: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1837 | 0.0958 | 0.2298 | 0.2867 |  0.3484 |
|     1      | 0.1591 | 0.0808 | 0.1882 | 0.2391 |  0.3071 |
|     2      | 0.2211 | 0.1341 | 0.2463 | 0.307  |  0.3936 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:24:44,993: Snapshot:3	Epoch:0	Loss:7.899	translation_Loss:7.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.216                                                   	MRR:13.77	Hits@10:31.35	Best:13.77
2024-12-27 19:24:48,694: Snapshot:3	Epoch:1	Loss:3.028	translation_Loss:2.526	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.502                                                   	MRR:24.57	Hits@10:44.02	Best:24.57
2024-12-27 19:24:52,450: Snapshot:3	Epoch:2	Loss:1.303	translation_Loss:0.685	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.619                                                   	MRR:28.82	Hits@10:47.3	Best:28.82
2024-12-27 19:24:56,147: Snapshot:3	Epoch:3	Loss:0.822	translation_Loss:0.229	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.593                                                   	MRR:29.74	Hits@10:47.89	Best:29.74
2024-12-27 19:24:59,789: Snapshot:3	Epoch:4	Loss:0.659	translation_Loss:0.14	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.519                                                   	MRR:30.21	Hits@10:48.07	Best:30.21
2024-12-27 19:25:03,526: Snapshot:3	Epoch:5	Loss:0.579	translation_Loss:0.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.461                                                   	MRR:30.33	Hits@10:48.04	Best:30.33
2024-12-27 19:25:07,185: Snapshot:3	Epoch:6	Loss:0.54	translation_Loss:0.112	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.428                                                   	MRR:30.12	Hits@10:47.9	Best:30.33
2024-12-27 19:25:10,857: Snapshot:3	Epoch:7	Loss:0.505	translation_Loss:0.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.409                                                   	MRR:30.37	Hits@10:47.69	Best:30.37
2024-12-27 19:25:14,440: Snapshot:3	Epoch:8	Loss:0.487	translation_Loss:0.098	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.388                                                   	MRR:30.36	Hits@10:47.59	Best:30.37
2024-12-27 19:25:18,071: Snapshot:3	Epoch:9	Loss:0.471	translation_Loss:0.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.376                                                   	MRR:30.62	Hits@10:48.03	Best:30.62
2024-12-27 19:25:21,757: Snapshot:3	Epoch:10	Loss:0.453	translation_Loss:0.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.364                                                   	MRR:30.78	Hits@10:48.13	Best:30.78
2024-12-27 19:25:25,398: Snapshot:3	Epoch:11	Loss:0.438	translation_Loss:0.084	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.354                                                   	MRR:30.64	Hits@10:47.84	Best:30.78
2024-12-27 19:25:29,066: Snapshot:3	Epoch:12	Loss:0.43	translation_Loss:0.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.344                                                   	MRR:30.87	Hits@10:47.94	Best:30.87
2024-12-27 19:25:32,778: Snapshot:3	Epoch:13	Loss:0.423	translation_Loss:0.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.336                                                   	MRR:30.97	Hits@10:48.19	Best:30.97
2024-12-27 19:25:36,429: Snapshot:3	Epoch:14	Loss:0.411	translation_Loss:0.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.332                                                   	MRR:30.52	Hits@10:48.02	Best:30.97
2024-12-27 19:25:40,066: Snapshot:3	Epoch:15	Loss:0.409	translation_Loss:0.083	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.327                                                   	MRR:30.55	Hits@10:48.07	Best:30.97
2024-12-27 19:25:44,262: Snapshot:3	Epoch:16	Loss:0.404	translation_Loss:0.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.324                                                   	MRR:30.68	Hits@10:48.04	Best:30.97
2024-12-27 19:25:47,829: Snapshot:3	Epoch:17	Loss:0.406	translation_Loss:0.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.32                                                   	MRR:30.96	Hits@10:48.14	Best:30.97
2024-12-27 19:25:51,456: Early Stopping! Snapshot: 3 Epoch: 18 Best Results: 30.97
2024-12-27 19:25:51,456: Start to training tokens! Snapshot: 3 Epoch: 18 Loss:0.395 MRR:30.97 Best Results: 30.97
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:25:51,456: Snapshot:3	Epoch:18	Loss:0.395	translation_Loss:0.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.319                                                   	MRR:30.97	Hits@10:48.31	Best:30.97
2024-12-27 19:25:54,955: Snapshot:3	Epoch:19	Loss:6.307	translation_Loss:6.171	multi_layer_Loss:0.135	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.97	Hits@10:48.31	Best:30.97
2024-12-27 19:25:58,516: End of token training: 3 Epoch: 20 Loss:6.185 MRR:30.97 Best Results: 30.97
2024-12-27 19:25:58,516: Snapshot:3	Epoch:20	Loss:6.185	translation_Loss:6.179	multi_layer_Loss:0.006	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.97	Hits@10:48.31	Best:30.97
2024-12-27 19:25:58,848: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_1000/3model_best.tar'
2024-12-27 19:26:14,262: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1801 | 0.094  | 0.226  |  0.28  |  0.3397 |
|     1      | 0.1513 | 0.0746 | 0.1779 | 0.2281 |  0.2961 |
|     2      | 0.1788 | 0.1032 | 0.1916 | 0.2457 |  0.3272 |
|     3      | 0.3107 | 0.218  | 0.3508 | 0.4064 |  0.4838 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:26:26,920: Snapshot:4	Epoch:0	Loss:4.039	translation_Loss:3.917	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.123                                                   	MRR:11.81	Hits@10:28.25	Best:11.81
2024-12-27 19:26:29,534: Snapshot:4	Epoch:1	Loss:1.749	translation_Loss:1.461	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.288                                                   	MRR:19.09	Hits@10:41.35	Best:19.09
2024-12-27 19:26:32,187: Snapshot:4	Epoch:2	Loss:0.831	translation_Loss:0.517	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.314                                                   	MRR:24.48	Hits@10:46.84	Best:24.48
2024-12-27 19:26:34,831: Snapshot:4	Epoch:3	Loss:0.461	translation_Loss:0.154	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.307                                                   	MRR:26.21	Hits@10:48.46	Best:26.21
2024-12-27 19:26:37,444: Snapshot:4	Epoch:4	Loss:0.342	translation_Loss:0.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.275                                                   	MRR:26.86	Hits@10:49.17	Best:26.86
2024-12-27 19:26:40,063: Snapshot:4	Epoch:5	Loss:0.287	translation_Loss:0.048	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.238                                                   	MRR:27.18	Hits@10:49.29	Best:27.18
2024-12-27 19:26:42,644: Snapshot:4	Epoch:6	Loss:0.255	translation_Loss:0.043	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.212                                                   	MRR:27.1	Hits@10:49.63	Best:27.18
2024-12-27 19:26:45,222: Snapshot:4	Epoch:7	Loss:0.236	translation_Loss:0.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:27.37	Hits@10:50.19	Best:27.37
2024-12-27 19:26:47,843: Snapshot:4	Epoch:8	Loss:0.223	translation_Loss:0.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.184                                                   	MRR:27.94	Hits@10:50.8	Best:27.94
2024-12-27 19:26:50,443: Snapshot:4	Epoch:9	Loss:0.214	translation_Loss:0.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.177                                                   	MRR:27.96	Hits@10:51.05	Best:27.96
2024-12-27 19:26:53,107: Snapshot:4	Epoch:10	Loss:0.206	translation_Loss:0.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:28.19	Hits@10:50.76	Best:28.19
2024-12-27 19:26:55,739: Snapshot:4	Epoch:11	Loss:0.197	translation_Loss:0.033	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.164                                                   	MRR:28.17	Hits@10:51.62	Best:28.19
2024-12-27 19:26:58,302: Snapshot:4	Epoch:12	Loss:0.191	translation_Loss:0.033	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.157                                                   	MRR:27.88	Hits@10:51.27	Best:28.19
2024-12-27 19:27:00,921: Snapshot:4	Epoch:13	Loss:0.186	translation_Loss:0.033	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:28.4	Hits@10:51.2	Best:28.4
2024-12-27 19:27:03,533: Snapshot:4	Epoch:14	Loss:0.182	translation_Loss:0.032	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:28.48	Hits@10:51.34	Best:28.48
2024-12-27 19:27:06,151: Snapshot:4	Epoch:15	Loss:0.178	translation_Loss:0.032	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.146                                                   	MRR:28.64	Hits@10:51.55	Best:28.64
2024-12-27 19:27:08,770: Snapshot:4	Epoch:16	Loss:0.174	translation_Loss:0.031	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.143                                                   	MRR:28.71	Hits@10:52.1	Best:28.71
2024-12-27 19:27:11,398: Snapshot:4	Epoch:17	Loss:0.169	translation_Loss:0.028	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.141                                                   	MRR:28.72	Hits@10:52.55	Best:28.72
2024-12-27 19:27:14,536: Snapshot:4	Epoch:18	Loss:0.165	translation_Loss:0.029	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.137                                                   	MRR:28.85	Hits@10:53.16	Best:28.85
2024-12-27 19:27:17,173: Snapshot:4	Epoch:19	Loss:0.164	translation_Loss:0.031	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.133                                                   	MRR:28.92	Hits@10:52.85	Best:28.92
2024-12-27 19:27:19,783: Snapshot:4	Epoch:20	Loss:0.161	translation_Loss:0.029	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.132                                                   	MRR:28.63	Hits@10:52.07	Best:28.92
2024-12-27 19:27:22,347: Snapshot:4	Epoch:21	Loss:0.159	translation_Loss:0.028	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.13                                                   	MRR:28.61	Hits@10:51.7	Best:28.92
2024-12-27 19:27:24,868: Snapshot:4	Epoch:22	Loss:0.159	translation_Loss:0.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.129                                                   	MRR:28.58	Hits@10:52.28	Best:28.92
2024-12-27 19:27:27,428: Snapshot:4	Epoch:23	Loss:0.158	translation_Loss:0.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.128                                                   	MRR:28.46	Hits@10:52.38	Best:28.92
2024-12-27 19:27:30,002: Early Stopping! Snapshot: 4 Epoch: 24 Best Results: 28.92
2024-12-27 19:27:30,002: Start to training tokens! Snapshot: 4 Epoch: 24 Loss:0.153 MRR:28.73 Best Results: 28.92
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:27:30,003: Snapshot:4	Epoch:24	Loss:0.153	translation_Loss:0.026	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:28.73	Hits@10:52.5	Best:28.92
2024-12-27 19:27:32,469: Snapshot:4	Epoch:25	Loss:3.816	translation_Loss:3.678	multi_layer_Loss:0.138	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.73	Hits@10:52.5	Best:28.92
2024-12-27 19:27:34,979: End of token training: 4 Epoch: 26 Loss:3.7 MRR:28.73 Best Results: 28.92
2024-12-27 19:27:34,979: Snapshot:4	Epoch:26	Loss:3.7	translation_Loss:3.685	multi_layer_Loss:0.014	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:28.73	Hits@10:52.5	Best:28.92
2024-12-27 19:27:35,283: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_1000/4model_best.tar'
2024-12-27 19:27:52,120: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1675 | 0.0873 | 0.2059 | 0.2581 |  0.3162 |
|     1      | 0.1456 | 0.0697 | 0.1708 | 0.2218 |  0.2893 |
|     2      | 0.1663 | 0.0958 | 0.1766 | 0.2254 |  0.3089 |
|     3      | 0.2729 | 0.1909 | 0.2995 | 0.3448 |  0.4265 |
|     4      | 0.294  | 0.1762 | 0.3307 | 0.4156 |  0.5336 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 19:27:52,122: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2783 | 0.1666 | 0.3452 | 0.4138 |  0.4854 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2216 | 0.1188 | 0.2768 | 0.3419 |  0.4123 |
|     1      | 0.1887 | 0.1005 | 0.2249 | 0.2824 |  0.3577 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1837 | 0.0958 | 0.2298 | 0.2867 |  0.3484 |
|     1      | 0.1591 | 0.0808 | 0.1882 | 0.2391 |  0.3071 |
|     2      | 0.2211 | 0.1341 | 0.2463 | 0.307  |  0.3936 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1801 | 0.094  | 0.226  |  0.28  |  0.3397 |
|     1      | 0.1513 | 0.0746 | 0.1779 | 0.2281 |  0.2961 |
|     2      | 0.1788 | 0.1032 | 0.1916 | 0.2457 |  0.3272 |
|     3      | 0.3107 | 0.218  | 0.3508 | 0.4064 |  0.4838 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1675 | 0.0873 | 0.2059 | 0.2581 |  0.3162 |
|     1      | 0.1456 | 0.0697 | 0.1708 | 0.2218 |  0.2893 |
|     2      | 0.1663 | 0.0958 | 0.1766 | 0.2254 |  0.3089 |
|     3      | 0.2729 | 0.1909 | 0.2995 | 0.3448 |  0.4265 |
|     4      | 0.294  | 0.1762 | 0.3307 | 0.4156 |  0.5336 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 19:27:52,123: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 155.80437684059143 |   0.278   |    0.167     |    0.345     |     0.485     |
|    1     | 127.17700409889221 |   0.206   |     0.11     |    0.252     |     0.386     |
|    2     | 135.96326541900635 |   0.184   |     0.1      |    0.219     |     0.345     |
|    3     | 87.08836102485657  |   0.184   |    0.103     |    0.216     |     0.338     |
|    4     | 79.24392127990723  |    0.18   |     0.1      |    0.207     |     0.332     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 19:27:52,123: Sum_Training_Time:585.2769286632538
2024-12-27 19:27:52,123: Every_Training_Time:[155.80437684059143, 127.17700409889221, 135.96326541900635, 87.08836102485657, 79.24392127990723]
2024-12-27 19:27:52,123: Forward transfer: 0.018625000000000003 Backward transfer: -0.06162499999999999
2024-12-27 19:28:29,385: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227192755/RELATIONrelation_0.001_2048_5000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.001_2048_5000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.001_2048_5000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 19:28:45,142: Snapshot:0	Epoch:0	Loss:34.762	translation_Loss:34.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.3	Hits@10:29.61	Best:12.3
2024-12-27 19:28:56,949: Snapshot:0	Epoch:1	Loss:19.583	translation_Loss:19.583	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.23	Hits@10:42.6	Best:21.23
2024-12-27 19:29:08,300: Snapshot:0	Epoch:2	Loss:10.296	translation_Loss:10.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.02	Hits@10:46.29	Best:25.02
2024-12-27 19:29:19,705: Snapshot:0	Epoch:3	Loss:5.409	translation_Loss:5.409	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.56	Hits@10:47.42	Best:26.56
2024-12-27 19:29:31,205: Snapshot:0	Epoch:4	Loss:3.235	translation_Loss:3.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.21	Hits@10:47.98	Best:27.21
2024-12-27 19:29:43,164: Snapshot:0	Epoch:5	Loss:2.269	translation_Loss:2.269	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.49	Hits@10:48.15	Best:27.49
2024-12-27 19:29:54,535: Snapshot:0	Epoch:6	Loss:1.783	translation_Loss:1.783	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.37	Hits@10:47.97	Best:27.49
2024-12-27 19:30:05,964: Snapshot:0	Epoch:7	Loss:1.501	translation_Loss:1.501	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.27	Hits@10:47.66	Best:27.49
2024-12-27 19:30:17,881: Snapshot:0	Epoch:8	Loss:1.332	translation_Loss:1.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.32	Hits@10:47.8	Best:27.49
2024-12-27 19:30:29,247: Snapshot:0	Epoch:9	Loss:1.2	translation_Loss:1.2	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.3	Hits@10:47.62	Best:27.49
2024-12-27 19:30:40,602: Early Stopping! Snapshot: 0 Epoch: 10 Best Results: 27.49
2024-12-27 19:30:40,602: Start to training tokens! Snapshot: 0 Epoch: 10 Loss:1.106 MRR:27.12 Best Results: 27.49
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:30:40,603: Snapshot:0	Epoch:10	Loss:1.106	translation_Loss:1.106	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.12	Hits@10:47.29	Best:27.49
2024-12-27 19:30:52,562: Snapshot:0	Epoch:11	Loss:24.889	translation_Loss:24.732	multi_layer_Loss:0.157	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.12	Hits@10:47.29	Best:27.49
2024-12-27 19:31:04,531: End of token training: 0 Epoch: 12 Loss:24.724 MRR:27.12 Best Results: 27.49
2024-12-27 19:31:04,531: Snapshot:0	Epoch:12	Loss:24.724	translation_Loss:24.724	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.12	Hits@10:47.29	Best:27.49
2024-12-27 19:31:04,832: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_5000/0model_best.tar'
2024-12-27 19:31:10,423: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2784 | 0.1662 | 0.3449 | 0.4133 |  0.4859 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:31:46,640: Snapshot:1	Epoch:0	Loss:28.719	translation_Loss:26.324	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.395                                                   	MRR:12.46	Hits@10:27.74	Best:12.46
2024-12-27 19:31:57,315: Snapshot:1	Epoch:1	Loss:14.818	translation_Loss:11.472	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.346                                                   	MRR:15.67	Hits@10:31.27	Best:15.67
2024-12-27 19:32:07,848: Snapshot:1	Epoch:2	Loss:10.656	translation_Loss:7.406	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.25                                                   	MRR:15.93	Hits@10:31.31	Best:15.93
2024-12-27 19:32:18,387: Snapshot:1	Epoch:3	Loss:9.582	translation_Loss:6.464	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.118                                                   	MRR:15.79	Hits@10:31.13	Best:15.93
2024-12-27 19:32:28,910: Snapshot:1	Epoch:4	Loss:9.222	translation_Loss:6.176	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.046                                                   	MRR:15.86	Hits@10:31.25	Best:15.93
2024-12-27 19:32:39,388: Snapshot:1	Epoch:5	Loss:9.013	translation_Loss:6.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.003                                                   	MRR:15.91	Hits@10:31.05	Best:15.93
2024-12-27 19:32:49,959: Snapshot:1	Epoch:6	Loss:8.928	translation_Loss:5.955	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.973                                                   	MRR:15.66	Hits@10:31.06	Best:15.93
2024-12-27 19:33:00,486: Early Stopping! Snapshot: 1 Epoch: 7 Best Results: 15.93
2024-12-27 19:33:00,487: Start to training tokens! Snapshot: 1 Epoch: 7 Loss:8.856 MRR:15.73 Best Results: 15.93
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:33:00,487: Snapshot:1	Epoch:7	Loss:8.856	translation_Loss:5.895	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.961                                                   	MRR:15.73	Hits@10:31.15	Best:15.93
2024-12-27 19:33:10,795: Snapshot:1	Epoch:8	Loss:30.128	translation_Loss:29.971	multi_layer_Loss:0.158	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.73	Hits@10:31.15	Best:15.93
2024-12-27 19:33:21,109: End of token training: 1 Epoch: 9 Loss:29.998 MRR:15.73 Best Results: 15.93
2024-12-27 19:33:21,109: Snapshot:1	Epoch:9	Loss:29.998	translation_Loss:29.998	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:15.73	Hits@10:31.15	Best:15.93
2024-12-27 19:33:21,487: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_5000/1model_best.tar'
2024-12-27 19:33:31,344: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2524 | 0.141  | 0.3154 | 0.3833 |  0.4603 |
|     1      | 0.1599 | 0.0815 |  0.19  | 0.2424 |  0.3113 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:33:58,741: Snapshot:2	Epoch:0	Loss:17.985	translation_Loss:15.828	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.157                                                   	MRR:14.95	Hits@10:31.75	Best:14.95
2024-12-27 19:34:06,559: Snapshot:2	Epoch:1	Loss:8.129	translation_Loss:4.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.15                                                   	MRR:21.33	Hits@10:39.0	Best:21.33
2024-12-27 19:34:14,487: Snapshot:2	Epoch:2	Loss:5.815	translation_Loss:3.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.547                                                   	MRR:20.96	Hits@10:39.03	Best:21.33
2024-12-27 19:34:22,788: Snapshot:2	Epoch:3	Loss:4.898	translation_Loss:2.686	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.212                                                   	MRR:21.08	Hits@10:38.13	Best:21.33
2024-12-27 19:34:30,584: Snapshot:2	Epoch:4	Loss:4.493	translation_Loss:2.464	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.029                                                   	MRR:21.17	Hits@10:37.82	Best:21.33
2024-12-27 19:34:38,369: Snapshot:2	Epoch:5	Loss:4.281	translation_Loss:2.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.936                                                   	MRR:21.16	Hits@10:37.71	Best:21.33
2024-12-27 19:34:46,175: Early Stopping! Snapshot: 2 Epoch: 6 Best Results: 21.33
2024-12-27 19:34:46,175: Start to training tokens! Snapshot: 2 Epoch: 6 Loss:4.209 MRR:20.9 Best Results: 21.33
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:34:46,175: Snapshot:2	Epoch:6	Loss:4.209	translation_Loss:2.306	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.903                                                   	MRR:20.9	Hits@10:37.85	Best:21.33
2024-12-27 19:34:53,810: Snapshot:2	Epoch:7	Loss:21.432	translation_Loss:21.267	multi_layer_Loss:0.164	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.9	Hits@10:37.85	Best:21.33
2024-12-27 19:35:02,067: End of token training: 2 Epoch: 8 Loss:21.287 MRR:20.9 Best Results: 21.33
2024-12-27 19:35:02,067: Snapshot:2	Epoch:8	Loss:21.287	translation_Loss:21.286	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:20.9	Hits@10:37.85	Best:21.33
2024-12-27 19:35:02,365: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_5000/2model_best.tar'
2024-12-27 19:35:15,826: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2104 | 0.1127 | 0.2652 | 0.3252 |  0.392  |
|     1      | 0.1331 | 0.0599 | 0.1608 | 0.2109 |  0.2735 |
|     2      | 0.2096 | 0.1201 | 0.2406 | 0.2949 |  0.3848 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:35:30,814: Snapshot:3	Epoch:0	Loss:8.903	translation_Loss:8.41	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.493                                                   	MRR:12.49	Hits@10:29.11	Best:12.49
2024-12-27 19:35:34,939: Snapshot:3	Epoch:1	Loss:4.593	translation_Loss:3.565	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.028                                                   	MRR:23.2	Hits@10:42.37	Best:23.2
2024-12-27 19:35:38,634: Snapshot:3	Epoch:2	Loss:2.786	translation_Loss:1.531	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.255                                                   	MRR:27.3	Hits@10:45.37	Best:27.3
2024-12-27 19:35:42,315: Snapshot:3	Epoch:3	Loss:2.114	translation_Loss:0.926	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.188                                                   	MRR:27.88	Hits@10:45.64	Best:27.88
2024-12-27 19:35:45,980: Snapshot:3	Epoch:4	Loss:1.797	translation_Loss:0.714	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.082                                                   	MRR:28.46	Hits@10:45.85	Best:28.46
2024-12-27 19:35:49,745: Snapshot:3	Epoch:5	Loss:1.617	translation_Loss:0.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.009                                                   	MRR:28.66	Hits@10:45.98	Best:28.66
2024-12-27 19:35:53,387: Snapshot:3	Epoch:6	Loss:1.495	translation_Loss:0.543	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.952                                                   	MRR:28.76	Hits@10:45.7	Best:28.76
2024-12-27 19:35:57,128: Snapshot:3	Epoch:7	Loss:1.406	translation_Loss:0.5	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.906                                                   	MRR:28.94	Hits@10:45.64	Best:28.94
2024-12-27 19:36:00,710: Snapshot:3	Epoch:8	Loss:1.354	translation_Loss:0.484	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.87                                                   	MRR:28.91	Hits@10:45.75	Best:28.94
2024-12-27 19:36:04,297: Snapshot:3	Epoch:9	Loss:1.307	translation_Loss:0.458	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.849                                                   	MRR:28.93	Hits@10:45.47	Best:28.94
2024-12-27 19:36:07,891: Snapshot:3	Epoch:10	Loss:1.278	translation_Loss:0.455	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.823                                                   	MRR:28.76	Hits@10:45.49	Best:28.94
2024-12-27 19:36:11,514: Snapshot:3	Epoch:11	Loss:1.243	translation_Loss:0.431	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.812                                                   	MRR:28.83	Hits@10:45.47	Best:28.94
2024-12-27 19:36:15,127: Early Stopping! Snapshot: 3 Epoch: 12 Best Results: 28.94
2024-12-27 19:36:15,127: Start to training tokens! Snapshot: 3 Epoch: 12 Loss:1.225 MRR:28.48 Best Results: 28.94
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:36:15,127: Snapshot:3	Epoch:12	Loss:1.225	translation_Loss:0.43	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.794                                                   	MRR:28.48	Hits@10:45.02	Best:28.94
2024-12-27 19:36:19,149: Snapshot:3	Epoch:13	Loss:7.606	translation_Loss:7.471	multi_layer_Loss:0.135	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.48	Hits@10:45.02	Best:28.94
2024-12-27 19:36:22,670: End of token training: 3 Epoch: 14 Loss:7.473 MRR:28.48 Best Results: 28.94
2024-12-27 19:36:22,670: Snapshot:3	Epoch:14	Loss:7.473	translation_Loss:7.467	multi_layer_Loss:0.006	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:28.48	Hits@10:45.02	Best:28.94
2024-12-27 19:36:22,970: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_5000/3model_best.tar'
2024-12-27 19:36:38,416: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2066 | 0.1104 | 0.259  | 0.3202 |  0.3847 |
|     1      | 0.1321 | 0.0599 | 0.158  | 0.2083 |  0.2702 |
|     2      | 0.185  | 0.1009 | 0.2064 | 0.2624 |  0.3499 |
|     3      | 0.2897 | 0.1981 | 0.3281 | 0.3834 |  0.4589 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:36:50,845: Snapshot:4	Epoch:0	Loss:4.892	translation_Loss:4.592	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.301                                                   	MRR:10.8	Hits@10:26.73	Best:10.8
2024-12-27 19:36:53,486: Snapshot:4	Epoch:1	Loss:2.498	translation_Loss:1.925	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.573                                                   	MRR:18.12	Hits@10:40.34	Best:18.12
2024-12-27 19:36:56,101: Snapshot:4	Epoch:2	Loss:1.575	translation_Loss:0.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.722                                                   	MRR:23.87	Hits@10:46.1	Best:23.87
2024-12-27 19:36:58,753: Snapshot:4	Epoch:3	Loss:1.111	translation_Loss:0.394	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.716                                                   	MRR:25.67	Hits@10:47.5	Best:25.67
2024-12-27 19:37:01,329: Snapshot:4	Epoch:4	Loss:0.903	translation_Loss:0.266	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.636                                                   	MRR:27.02	Hits@10:48.6	Best:27.02
2024-12-27 19:37:03,982: Snapshot:4	Epoch:5	Loss:0.787	translation_Loss:0.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.57                                                   	MRR:27.61	Hits@10:50.19	Best:27.61
2024-12-27 19:37:06,594: Snapshot:4	Epoch:6	Loss:0.703	translation_Loss:0.183	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.52                                                   	MRR:27.63	Hits@10:50.3	Best:27.63
2024-12-27 19:37:09,214: Snapshot:4	Epoch:7	Loss:0.644	translation_Loss:0.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.477                                                   	MRR:27.96	Hits@10:50.59	Best:27.96
2024-12-27 19:37:11,841: Snapshot:4	Epoch:8	Loss:0.605	translation_Loss:0.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.447                                                   	MRR:28.42	Hits@10:51.01	Best:28.42
2024-12-27 19:37:14,396: Snapshot:4	Epoch:9	Loss:0.566	translation_Loss:0.144	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.422                                                   	MRR:28.07	Hits@10:50.85	Best:28.42
2024-12-27 19:37:16,944: Snapshot:4	Epoch:10	Loss:0.543	translation_Loss:0.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.401                                                   	MRR:27.85	Hits@10:50.57	Best:28.42
2024-12-27 19:37:19,468: Snapshot:4	Epoch:11	Loss:0.524	translation_Loss:0.14	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.384                                                   	MRR:27.89	Hits@10:50.91	Best:28.42
2024-12-27 19:37:22,033: Snapshot:4	Epoch:12	Loss:0.509	translation_Loss:0.137	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.372                                                   	MRR:28.27	Hits@10:51.52	Best:28.42
2024-12-27 19:37:24,569: Early Stopping! Snapshot: 4 Epoch: 13 Best Results: 28.42
2024-12-27 19:37:24,569: Start to training tokens! Snapshot: 4 Epoch: 13 Loss:0.495 MRR:28.29 Best Results: 28.42
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:37:24,569: Snapshot:4	Epoch:13	Loss:0.495	translation_Loss:0.129	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.365                                                   	MRR:28.29	Hits@10:51.46	Best:28.42
2024-12-27 19:37:27,059: Snapshot:4	Epoch:14	Loss:4.423	translation_Loss:4.285	multi_layer_Loss:0.138	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.29	Hits@10:51.46	Best:28.42
2024-12-27 19:37:29,557: End of token training: 4 Epoch: 15 Loss:4.316 MRR:28.29 Best Results: 28.42
2024-12-27 19:37:29,557: Snapshot:4	Epoch:15	Loss:4.316	translation_Loss:4.301	multi_layer_Loss:0.014	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:28.29	Hits@10:51.46	Best:28.42
2024-12-27 19:37:29,905: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_5000/4model_best.tar'
2024-12-27 19:37:46,815: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1946 | 0.1032 | 0.2443 | 0.3003 |  0.3619 |
|     1      | 0.1304 | 0.0594 | 0.1549 | 0.2045 |  0.2684 |
|     2      | 0.1762 | 0.096  | 0.1962 | 0.2506 |  0.3343 |
|     3      | 0.2623 | 0.1801 | 0.2912 | 0.3348 |  0.4103 |
|     4      | 0.276  | 0.161  | 0.3094 | 0.3963 |  0.5107 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 19:37:46,817: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2784 | 0.1662 | 0.3449 | 0.4133 |  0.4859 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2524 | 0.141  | 0.3154 | 0.3833 |  0.4603 |
|     1      | 0.1599 | 0.0815 |  0.19  | 0.2424 |  0.3113 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2104 | 0.1127 | 0.2652 | 0.3252 |  0.392  |
|     1      | 0.1331 | 0.0599 | 0.1608 | 0.2109 |  0.2735 |
|     2      | 0.2096 | 0.1201 | 0.2406 | 0.2949 |  0.3848 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2066 | 0.1104 | 0.259  | 0.3202 |  0.3847 |
|     1      | 0.1321 | 0.0599 | 0.158  | 0.2083 |  0.2702 |
|     2      | 0.185  | 0.1009 | 0.2064 | 0.2624 |  0.3499 |
|     3      | 0.2897 | 0.1981 | 0.3281 | 0.3834 |  0.4589 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1946 | 0.1032 | 0.2443 | 0.3003 |  0.3619 |
|     1      | 0.1304 | 0.0594 | 0.1549 | 0.2045 |  0.2684 |
|     2      | 0.1762 | 0.096  | 0.1962 | 0.2506 |  0.3343 |
|     3      | 0.2623 | 0.1801 | 0.2912 | 0.3348 |  0.4103 |
|     4      | 0.276  | 0.161  | 0.3094 | 0.3963 |  0.5107 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 19:37:46,818: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 155.14571332931519 |   0.278   |    0.166     |    0.345     |     0.486     |
|    1     | 126.3883044719696  |   0.207   |    0.112     |    0.254     |     0.388     |
|    2     | 87.18962168693542  |   0.182   |    0.095     |    0.221     |     0.347     |
|    3     | 65.23322415351868  |   0.186   |    0.101     |    0.221     |     0.347     |
|    4     | 49.63167762756348  |   0.184   |     0.1      |    0.216     |     0.343     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 19:37:46,818: Sum_Training_Time:483.58854126930237
2024-12-27 19:37:46,818: Every_Training_Time:[155.14571332931519, 126.3883044719696, 87.18962168693542, 65.23322415351868, 49.63167762756348]
2024-12-27 19:37:46,818: Forward transfer: 0.01805 Backward transfer: -0.04352500000000001
2024-12-27 19:38:24,439: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20241227193750/RELATIONrelation_0.001_2048_10000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.001_2048_10000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.001_2048_10000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 19:38:40,247: Snapshot:0	Epoch:0	Loss:34.762	translation_Loss:34.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.3	Hits@10:29.6	Best:12.3
2024-12-27 19:38:52,118: Snapshot:0	Epoch:1	Loss:19.584	translation_Loss:19.584	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.23	Hits@10:42.62	Best:21.23
2024-12-27 19:39:03,641: Snapshot:0	Epoch:2	Loss:10.295	translation_Loss:10.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.08	Hits@10:46.3	Best:25.08
2024-12-27 19:39:15,069: Snapshot:0	Epoch:3	Loss:5.41	translation_Loss:5.41	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.5	Hits@10:47.52	Best:26.5
2024-12-27 19:39:26,666: Snapshot:0	Epoch:4	Loss:3.235	translation_Loss:3.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.11	Hits@10:48.01	Best:27.11
2024-12-27 19:39:38,546: Snapshot:0	Epoch:5	Loss:2.27	translation_Loss:2.27	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.41	Hits@10:48.14	Best:27.41
2024-12-27 19:39:49,925: Snapshot:0	Epoch:6	Loss:1.785	translation_Loss:1.785	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.37	Hits@10:47.99	Best:27.41
2024-12-27 19:40:01,351: Snapshot:0	Epoch:7	Loss:1.5	translation_Loss:1.5	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.24	Hits@10:47.77	Best:27.41
2024-12-27 19:40:13,358: Snapshot:0	Epoch:8	Loss:1.331	translation_Loss:1.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.25	Hits@10:47.62	Best:27.41
2024-12-27 19:40:24,686: Snapshot:0	Epoch:9	Loss:1.197	translation_Loss:1.197	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.22	Hits@10:47.5	Best:27.41
2024-12-27 19:40:36,088: Early Stopping! Snapshot: 0 Epoch: 10 Best Results: 27.41
2024-12-27 19:40:36,088: Start to training tokens! Snapshot: 0 Epoch: 10 Loss:1.101 MRR:27.07 Best Results: 27.41
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:40:36,089: Snapshot:0	Epoch:10	Loss:1.101	translation_Loss:1.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.07	Hits@10:47.43	Best:27.41
2024-12-27 19:40:48,089: Snapshot:0	Epoch:11	Loss:24.806	translation_Loss:24.65	multi_layer_Loss:0.157	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.07	Hits@10:47.43	Best:27.41
2024-12-27 19:41:00,071: End of token training: 0 Epoch: 12 Loss:24.639 MRR:27.07 Best Results: 27.41
2024-12-27 19:41:00,071: Snapshot:0	Epoch:12	Loss:24.639	translation_Loss:24.639	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.07	Hits@10:47.43	Best:27.41
2024-12-27 19:41:00,374: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_10000/0model_best.tar'
2024-12-27 19:41:05,664: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2777 | 0.1657 | 0.3441 | 0.4123 |  0.4845 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:41:42,032: Snapshot:1	Epoch:0	Loss:29.352	translation_Loss:26.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.579                                                   	MRR:11.76	Hits@10:26.21	Best:11.76
2024-12-27 19:41:52,556: Snapshot:1	Epoch:1	Loss:16.031	translation_Loss:12.959	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.072                                                   	MRR:14.36	Hits@10:29.32	Best:14.36
2024-12-27 19:42:03,174: Snapshot:1	Epoch:2	Loss:11.914	translation_Loss:8.953	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.961                                                   	MRR:14.74	Hits@10:29.32	Best:14.74
2024-12-27 19:42:13,817: Snapshot:1	Epoch:3	Loss:10.83	translation_Loss:7.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.85                                                   	MRR:14.71	Hits@10:29.24	Best:14.74
2024-12-27 19:42:24,344: Snapshot:1	Epoch:4	Loss:10.448	translation_Loss:7.665	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.784                                                   	MRR:14.54	Hits@10:29.26	Best:14.74
2024-12-27 19:42:34,861: Snapshot:1	Epoch:5	Loss:10.221	translation_Loss:7.486	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.735                                                   	MRR:14.66	Hits@10:29.28	Best:14.74
2024-12-27 19:42:45,334: Snapshot:1	Epoch:6	Loss:10.125	translation_Loss:7.417	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.708                                                   	MRR:14.44	Hits@10:29.15	Best:14.74
2024-12-27 19:42:55,865: Early Stopping! Snapshot: 1 Epoch: 7 Best Results: 14.74
2024-12-27 19:42:55,865: Start to training tokens! Snapshot: 1 Epoch: 7 Loss:10.045 MRR:14.51 Best Results: 14.74
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:42:55,866: Snapshot:1	Epoch:7	Loss:10.045	translation_Loss:7.357	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.688                                                   	MRR:14.51	Hits@10:29.39	Best:14.74
2024-12-27 19:43:06,180: Snapshot:1	Epoch:8	Loss:31.202	translation_Loss:31.045	multi_layer_Loss:0.158	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.51	Hits@10:29.39	Best:14.74
2024-12-27 19:43:16,636: End of token training: 1 Epoch: 9 Loss:31.071 MRR:14.51 Best Results: 14.74
2024-12-27 19:43:16,636: Snapshot:1	Epoch:9	Loss:31.071	translation_Loss:31.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:14.51	Hits@10:29.39	Best:14.74
2024-12-27 19:43:17,010: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_10000/1model_best.tar'
2024-12-27 19:43:26,709: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2567 | 0.1429 | 0.3213 | 0.3912 |  0.4721 |
|     1      | 0.1487 | 0.0746 | 0.1742 | 0.2275 |  0.294  |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:43:54,100: Snapshot:2	Epoch:0	Loss:19.394	translation_Loss:16.621	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.773                                                   	MRR:15.36	Hits@10:31.6	Best:15.36
2024-12-27 19:44:02,092: Snapshot:2	Epoch:1	Loss:10.018	translation_Loss:6.395	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.623                                                   	MRR:19.44	Hits@10:36.71	Best:19.44
2024-12-27 19:44:09,956: Snapshot:2	Epoch:2	Loss:7.373	translation_Loss:4.561	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.811                                                   	MRR:20.1	Hits@10:36.29	Best:20.1
2024-12-27 19:44:18,255: Snapshot:2	Epoch:3	Loss:6.317	translation_Loss:3.9	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.417                                                   	MRR:20.37	Hits@10:36.26	Best:20.37
2024-12-27 19:44:26,150: Snapshot:2	Epoch:4	Loss:5.892	translation_Loss:3.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.223                                                   	MRR:20.34	Hits@10:36.04	Best:20.37
2024-12-27 19:44:34,100: Snapshot:2	Epoch:5	Loss:5.698	translation_Loss:3.55	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.148                                                   	MRR:20.38	Hits@10:36.26	Best:20.38
2024-12-27 19:44:41,973: Snapshot:2	Epoch:6	Loss:5.64	translation_Loss:3.516	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.124                                                   	MRR:20.16	Hits@10:36.01	Best:20.38
2024-12-27 19:44:49,783: Snapshot:2	Epoch:7	Loss:5.599	translation_Loss:3.494	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.105                                                   	MRR:20.06	Hits@10:35.98	Best:20.38
2024-12-27 19:44:58,165: Snapshot:2	Epoch:8	Loss:5.577	translation_Loss:3.478	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.099                                                   	MRR:19.87	Hits@10:35.71	Best:20.38
2024-12-27 19:45:06,102: Snapshot:2	Epoch:9	Loss:5.527	translation_Loss:3.436	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.091                                                   	MRR:20.22	Hits@10:36.06	Best:20.38
2024-12-27 19:45:14,017: Early Stopping! Snapshot: 2 Epoch: 10 Best Results: 20.38
2024-12-27 19:45:14,017: Start to training tokens! Snapshot: 2 Epoch: 10 Loss:5.533 MRR:19.78 Best Results: 20.38
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:45:14,017: Snapshot:2	Epoch:10	Loss:5.533	translation_Loss:3.447	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.086                                                   	MRR:19.78	Hits@10:35.71	Best:20.38
2024-12-27 19:45:21,724: Snapshot:2	Epoch:11	Loss:23.098	translation_Loss:22.934	multi_layer_Loss:0.164	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.78	Hits@10:35.71	Best:20.38
2024-12-27 19:45:29,479: End of token training: 2 Epoch: 12 Loss:22.94 MRR:19.78 Best Results: 20.38
2024-12-27 19:45:29,479: Snapshot:2	Epoch:12	Loss:22.94	translation_Loss:22.939	multi_layer_Loss:0.001	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.78	Hits@10:35.71	Best:20.38
2024-12-27 19:45:29,832: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_10000/2model_best.tar'
2024-12-27 19:45:43,665: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2236 | 0.1178 | 0.2824 | 0.3474 |  0.4233 |
|     1      | 0.138  | 0.0636 | 0.1619 | 0.2139 |  0.2839 |
|     2      | 0.1998 | 0.1231 | 0.2217 | 0.2743 |  0.3552 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:45:58,848: Snapshot:3	Epoch:0	Loss:9.608	translation_Loss:8.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.634                                                   	MRR:11.56	Hits@10:27.29	Best:11.56
2024-12-27 19:46:02,539: Snapshot:3	Epoch:1	Loss:5.565	translation_Loss:4.342	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.223                                                   	MRR:21.35	Hits@10:39.93	Best:21.35
2024-12-27 19:46:06,238: Snapshot:3	Epoch:2	Loss:3.75	translation_Loss:2.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.358                                                   	MRR:25.5	Hits@10:43.09	Best:25.5
2024-12-27 19:46:10,015: Snapshot:3	Epoch:3	Loss:2.943	translation_Loss:1.668	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.275                                                   	MRR:26.62	Hits@10:43.86	Best:26.62
2024-12-27 19:46:13,657: Snapshot:3	Epoch:4	Loss:2.527	translation_Loss:1.353	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.174                                                   	MRR:27.31	Hits@10:44.07	Best:27.31
2024-12-27 19:46:17,315: Snapshot:3	Epoch:5	Loss:2.278	translation_Loss:1.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.101                                                   	MRR:27.72	Hits@10:44.22	Best:27.72
2024-12-27 19:46:21,360: Snapshot:3	Epoch:6	Loss:2.109	translation_Loss:1.073	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.035                                                   	MRR:27.6	Hits@10:44.04	Best:27.72
2024-12-27 19:46:24,957: Snapshot:3	Epoch:7	Loss:2.006	translation_Loss:1.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.99                                                   	MRR:27.69	Hits@10:43.8	Best:27.72
2024-12-27 19:46:28,645: Snapshot:3	Epoch:8	Loss:1.93	translation_Loss:0.971	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.959                                                   	MRR:27.81	Hits@10:43.58	Best:27.81
2024-12-27 19:46:32,375: Snapshot:3	Epoch:9	Loss:1.888	translation_Loss:0.954	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.933                                                   	MRR:27.86	Hits@10:43.47	Best:27.86
2024-12-27 19:46:35,990: Snapshot:3	Epoch:10	Loss:1.843	translation_Loss:0.931	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.913                                                   	MRR:27.73	Hits@10:43.51	Best:27.86
2024-12-27 19:46:39,599: Snapshot:3	Epoch:11	Loss:1.801	translation_Loss:0.906	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.896                                                   	MRR:27.82	Hits@10:43.44	Best:27.86
2024-12-27 19:46:43,221: Snapshot:3	Epoch:12	Loss:1.782	translation_Loss:0.9	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.882                                                   	MRR:27.77	Hits@10:43.18	Best:27.86
2024-12-27 19:46:46,839: Snapshot:3	Epoch:13	Loss:1.761	translation_Loss:0.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.872                                                   	MRR:27.57	Hits@10:42.88	Best:27.86
2024-12-27 19:46:50,474: Early Stopping! Snapshot: 3 Epoch: 14 Best Results: 27.86
2024-12-27 19:46:50,474: Start to training tokens! Snapshot: 3 Epoch: 14 Loss:1.754 MRR:27.17 Best Results: 27.86
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:46:50,474: Snapshot:3	Epoch:14	Loss:1.754	translation_Loss:0.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.866                                                   	MRR:27.17	Hits@10:43.16	Best:27.86
2024-12-27 19:46:54,025: Snapshot:3	Epoch:15	Loss:8.65	translation_Loss:8.515	multi_layer_Loss:0.135	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.17	Hits@10:43.16	Best:27.86
2024-12-27 19:46:57,598: End of token training: 3 Epoch: 16 Loss:8.504 MRR:27.17 Best Results: 27.86
2024-12-27 19:46:57,598: Snapshot:3	Epoch:16	Loss:8.504	translation_Loss:8.498	multi_layer_Loss:0.006	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.17	Hits@10:43.16	Best:27.86
2024-12-27 19:46:57,974: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_10000/3model_best.tar'
2024-12-27 19:47:13,505: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.221  | 0.1168 | 0.2792 | 0.3438 |  0.4186 |
|     1      | 0.1372 | 0.0631 | 0.1609 | 0.2117 |  0.2818 |
|     2      | 0.1796 | 0.1051 | 0.197  |  0.25  |  0.3313 |
|     3      | 0.2784 | 0.1929 | 0.3124 | 0.3632 |  0.4362 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:47:26,059: Snapshot:4	Epoch:0	Loss:5.462	translation_Loss:5.082	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.379                                                   	MRR:10.05	Hits@10:25.49	Best:10.05
2024-12-27 19:47:28,669: Snapshot:4	Epoch:1	Loss:3.129	translation_Loss:2.35	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.78                                                   	MRR:17.67	Hits@10:38.96	Best:17.67
2024-12-27 19:47:31,347: Snapshot:4	Epoch:2	Loss:2.199	translation_Loss:1.263	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.936                                                   	MRR:22.28	Hits@10:44.37	Best:22.28
2024-12-27 19:47:33,971: Snapshot:4	Epoch:3	Loss:1.688	translation_Loss:0.802	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.885                                                   	MRR:24.71	Hits@10:46.26	Best:24.71
2024-12-27 19:47:36,607: Snapshot:4	Epoch:4	Loss:1.405	translation_Loss:0.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.802                                                   	MRR:25.98	Hits@10:47.29	Best:25.98
2024-12-27 19:47:39,179: Snapshot:4	Epoch:5	Loss:1.224	translation_Loss:0.491	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.733                                                   	MRR:26.45	Hits@10:47.95	Best:26.45
2024-12-27 19:47:41,809: Snapshot:4	Epoch:6	Loss:1.098	translation_Loss:0.417	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.681                                                   	MRR:26.74	Hits@10:48.38	Best:26.74
2024-12-27 19:47:44,703: Snapshot:4	Epoch:7	Loss:1.002	translation_Loss:0.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.634                                                   	MRR:26.98	Hits@10:49.07	Best:26.98
2024-12-27 19:47:47,344: Snapshot:4	Epoch:8	Loss:0.946	translation_Loss:0.352	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.594                                                   	MRR:27.07	Hits@10:49.37	Best:27.07
2024-12-27 19:47:49,959: Snapshot:4	Epoch:9	Loss:0.891	translation_Loss:0.321	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.571                                                   	MRR:27.21	Hits@10:49.55	Best:27.21
2024-12-27 19:47:52,606: Snapshot:4	Epoch:10	Loss:0.854	translation_Loss:0.311	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.544                                                   	MRR:27.24	Hits@10:49.43	Best:27.24
2024-12-27 19:47:55,160: Snapshot:4	Epoch:11	Loss:0.831	translation_Loss:0.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.528                                                   	MRR:26.87	Hits@10:49.29	Best:27.24
2024-12-27 19:47:57,725: Snapshot:4	Epoch:12	Loss:0.804	translation_Loss:0.292	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.512                                                   	MRR:26.67	Hits@10:49.53	Best:27.24
2024-12-27 19:48:00,280: Snapshot:4	Epoch:13	Loss:0.79	translation_Loss:0.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.497                                                   	MRR:26.89	Hits@10:49.83	Best:27.24
2024-12-27 19:48:02,812: Snapshot:4	Epoch:14	Loss:0.78	translation_Loss:0.291	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.489                                                   	MRR:26.53	Hits@10:49.36	Best:27.24
2024-12-27 19:48:05,332: Early Stopping! Snapshot: 4 Epoch: 15 Best Results: 27.24
2024-12-27 19:48:05,333: Start to training tokens! Snapshot: 4 Epoch: 15 Loss:0.766 MRR:26.44 Best Results: 27.24
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:48:05,333: Snapshot:4	Epoch:15	Loss:0.766	translation_Loss:0.285	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.481                                                   	MRR:26.44	Hits@10:49.77	Best:27.24
2024-12-27 19:48:07,806: Snapshot:4	Epoch:16	Loss:5.045	translation_Loss:4.907	multi_layer_Loss:0.138	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.44	Hits@10:49.77	Best:27.24
2024-12-27 19:48:10,315: End of token training: 4 Epoch: 17 Loss:4.924 MRR:26.44 Best Results: 27.24
2024-12-27 19:48:10,315: Snapshot:4	Epoch:17	Loss:4.924	translation_Loss:4.909	multi_layer_Loss:0.014	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.44	Hits@10:49.77	Best:27.24
2024-12-27 19:48:10,693: => loading checkpoint './checkpoint/RELATIONrelation_0.001_2048_10000/4model_best.tar'
2024-12-27 19:48:27,584: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2127 | 0.1113 | 0.2679 | 0.3302 |  0.4019 |
|     1      | 0.1369 | 0.0635 | 0.1596 | 0.2108 |  0.2816 |
|     2      | 0.1717 | 0.101  | 0.1886 | 0.2379 |  0.3146 |
|     3      | 0.2615 | 0.1811 | 0.2894 | 0.335  |  0.4089 |
|     4      | 0.2663 | 0.1556 | 0.2945 | 0.3776 |  0.4954 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 19:48:27,586: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2777 | 0.1657 | 0.3441 | 0.4123 |  0.4845 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2567 | 0.1429 | 0.3213 | 0.3912 |  0.4721 |
|     1      | 0.1487 | 0.0746 | 0.1742 | 0.2275 |  0.294  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2236 | 0.1178 | 0.2824 | 0.3474 |  0.4233 |
|     1      | 0.138  | 0.0636 | 0.1619 | 0.2139 |  0.2839 |
|     2      | 0.1998 | 0.1231 | 0.2217 | 0.2743 |  0.3552 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.221  | 0.1168 | 0.2792 | 0.3438 |  0.4186 |
|     1      | 0.1372 | 0.0631 | 0.1609 | 0.2117 |  0.2818 |
|     2      | 0.1796 | 0.1051 | 0.197  |  0.25  |  0.3313 |
|     3      | 0.2784 | 0.1929 | 0.3124 | 0.3632 |  0.4362 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2127 | 0.1113 | 0.2679 | 0.3302 |  0.4019 |
|     1      | 0.1369 | 0.0635 | 0.1596 | 0.2108 |  0.2816 |
|     2      | 0.1717 | 0.101  | 0.1886 | 0.2379 |  0.3146 |
|     3      | 0.2615 | 0.1811 | 0.2894 | 0.335  |  0.4089 |
|     4      | 0.2663 | 0.1556 | 0.2945 | 0.3776 |  0.4954 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 19:48:27,587: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 155.6320686340332  |   0.278   |    0.166     |    0.344     |     0.484     |
|    1     | 126.64940524101257 |   0.204   |     0.11     |     0.25     |     0.385     |
|    2     | 119.21447777748108 |   0.187   |     0.1      |    0.223     |     0.355     |
|    3     | 71.97296452522278  |    0.19   |    0.105     |    0.225     |     0.356     |
|    4     | 55.28909397125244  |    0.19   |    0.105     |    0.222     |     0.354     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 19:48:27,587: Sum_Training_Time:528.7580101490021
2024-12-27 19:48:27,587: Every_Training_Time:[155.6320686340332, 126.64940524101257, 119.21447777748108, 71.97296452522278, 55.28909397125244]
2024-12-27 19:48:27,587: Forward transfer: 0.017225 Backward transfer: -0.030449999999999998
2024-12-27 19:49:05,326: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.0001, lifelong_name='double_tokened', log_path='./logs/20241227194831/RELATIONrelation_0.0001_512_1000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.0001_512_1000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.0001_512_1000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 19:49:21,633: Snapshot:0	Epoch:0	Loss:156.019	translation_Loss:156.019	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.96	Hits@10:16.66	Best:7.96
2024-12-27 19:49:33,479: Snapshot:0	Epoch:1	Loss:132.307	translation_Loss:132.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.71	Hits@10:22.31	Best:9.71
2024-12-27 19:49:45,359: Snapshot:0	Epoch:2	Loss:113.356	translation_Loss:113.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.55	Hits@10:26.79	Best:11.55
2024-12-27 19:49:57,108: Snapshot:0	Epoch:3	Loss:95.555	translation_Loss:95.555	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.14	Hits@10:33.0	Best:15.14
2024-12-27 19:50:08,952: Snapshot:0	Epoch:4	Loss:78.62	translation_Loss:78.62	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.23	Hits@10:37.81	Best:18.23
2024-12-27 19:50:20,687: Snapshot:0	Epoch:5	Loss:63.317	translation_Loss:63.317	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.42	Hits@10:40.94	Best:20.42
2024-12-27 19:50:32,350: Snapshot:0	Epoch:6	Loss:50.768	translation_Loss:50.768	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.09	Hits@10:43.04	Best:22.09
2024-12-27 19:50:44,712: Snapshot:0	Epoch:7	Loss:40.615	translation_Loss:40.615	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.29	Hits@10:44.33	Best:23.29
2024-12-27 19:50:56,473: Snapshot:0	Epoch:8	Loss:32.456	translation_Loss:32.456	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.24	Hits@10:45.41	Best:24.24
2024-12-27 19:51:08,331: Snapshot:0	Epoch:9	Loss:25.941	translation_Loss:25.941	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.97	Hits@10:46.09	Best:24.97
2024-12-27 19:51:20,144: Snapshot:0	Epoch:10	Loss:20.897	translation_Loss:20.897	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.57	Hits@10:46.64	Best:25.57
2024-12-27 19:51:31,988: Snapshot:0	Epoch:11	Loss:17.103	translation_Loss:17.103	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.08	Hits@10:47.15	Best:26.08
2024-12-27 19:51:43,875: Snapshot:0	Epoch:12	Loss:14.162	translation_Loss:14.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.43	Hits@10:47.42	Best:26.43
2024-12-27 19:51:55,696: Snapshot:0	Epoch:13	Loss:12.025	translation_Loss:12.025	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.68	Hits@10:47.6	Best:26.68
2024-12-27 19:52:07,457: Snapshot:0	Epoch:14	Loss:10.305	translation_Loss:10.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.81	Hits@10:47.75	Best:26.81
2024-12-27 19:52:19,334: Snapshot:0	Epoch:15	Loss:9.065	translation_Loss:9.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.07	Hits@10:47.98	Best:27.07
2024-12-27 19:52:31,237: Snapshot:0	Epoch:16	Loss:8.038	translation_Loss:8.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.17	Hits@10:47.99	Best:27.17
2024-12-27 19:52:42,957: Snapshot:0	Epoch:17	Loss:7.151	translation_Loss:7.151	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.23	Hits@10:47.97	Best:27.23
2024-12-27 19:52:54,693: Snapshot:0	Epoch:18	Loss:6.545	translation_Loss:6.545	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.27	Hits@10:48.07	Best:27.27
2024-12-27 19:53:06,958: Snapshot:0	Epoch:19	Loss:5.984	translation_Loss:5.984	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.31	Hits@10:48.21	Best:27.31
2024-12-27 19:53:18,636: Snapshot:0	Epoch:20	Loss:5.579	translation_Loss:5.579	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.3	Hits@10:48.13	Best:27.31
2024-12-27 19:53:30,460: Snapshot:0	Epoch:21	Loss:5.194	translation_Loss:5.194	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.35	Hits@10:48.06	Best:27.35
2024-12-27 19:53:42,193: Snapshot:0	Epoch:22	Loss:4.863	translation_Loss:4.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.43	Hits@10:47.98	Best:27.43
2024-12-27 19:53:53,904: Snapshot:0	Epoch:23	Loss:4.642	translation_Loss:4.642	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.44	Hits@10:48.0	Best:27.44
2024-12-27 19:54:05,652: Snapshot:0	Epoch:24	Loss:4.405	translation_Loss:4.405	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.38	Hits@10:48.02	Best:27.44
2024-12-27 19:54:17,349: Snapshot:0	Epoch:25	Loss:4.203	translation_Loss:4.203	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.38	Hits@10:47.92	Best:27.44
2024-12-27 19:54:29,175: Snapshot:0	Epoch:26	Loss:3.995	translation_Loss:3.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.43	Hits@10:47.8	Best:27.44
2024-12-27 19:54:40,906: Snapshot:0	Epoch:27	Loss:3.862	translation_Loss:3.862	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.36	Hits@10:47.95	Best:27.44
2024-12-27 19:54:52,676: Early Stopping! Snapshot: 0 Epoch: 28 Best Results: 27.44
2024-12-27 19:54:52,677: Start to training tokens! Snapshot: 0 Epoch: 28 Loss:3.71 MRR:27.33 Best Results: 27.44
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:54:52,677: Snapshot:0	Epoch:28	Loss:3.71	translation_Loss:3.71	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.33	Hits@10:47.82	Best:27.44
2024-12-27 19:55:05,322: Snapshot:0	Epoch:29	Loss:101.717	translation_Loss:100.437	multi_layer_Loss:1.28	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.33	Hits@10:47.82	Best:27.44
2024-12-27 19:55:17,268: End of token training: 0 Epoch: 30 Loss:100.329 MRR:27.33 Best Results: 27.44
2024-12-27 19:55:17,268: Snapshot:0	Epoch:30	Loss:100.329	translation_Loss:100.327	multi_layer_Loss:0.002	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.33	Hits@10:47.82	Best:27.44
2024-12-27 19:55:17,624: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_1000/0model_best.tar'
2024-12-27 19:55:23,298: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2774 | 0.1664 | 0.342  | 0.4116 |  0.4849 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:56:00,786: Snapshot:1	Epoch:0	Loss:135.76	translation_Loss:135.347	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.413                                                   	MRR:5.53	Hits@10:14.11	Best:5.53
2024-12-27 19:56:12,215: Snapshot:1	Epoch:1	Loss:92.628	translation_Loss:91.081	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.547                                                   	MRR:10.49	Hits@10:23.62	Best:10.49
2024-12-27 19:56:23,538: Snapshot:1	Epoch:2	Loss:60.865	translation_Loss:57.803	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.062                                                   	MRR:14.35	Hits@10:30.05	Best:14.35
2024-12-27 19:56:34,966: Snapshot:1	Epoch:3	Loss:38.221	translation_Loss:33.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.571                                                   	MRR:17.05	Hits@10:33.64	Best:17.05
2024-12-27 19:56:46,307: Snapshot:1	Epoch:4	Loss:24.762	translation_Loss:19.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.698                                                   	MRR:18.2	Hits@10:35.66	Best:18.2
2024-12-27 19:56:57,757: Snapshot:1	Epoch:5	Loss:17.95	translation_Loss:11.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.281                                                   	MRR:18.98	Hits@10:36.27	Best:18.98
2024-12-27 19:57:09,080: Snapshot:1	Epoch:6	Loss:14.463	translation_Loss:7.965	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.498                                                   	MRR:19.26	Hits@10:36.77	Best:19.26
2024-12-27 19:57:20,568: Snapshot:1	Epoch:7	Loss:12.56	translation_Loss:6.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.545                                                   	MRR:19.45	Hits@10:36.96	Best:19.45
2024-12-27 19:57:31,948: Snapshot:1	Epoch:8	Loss:11.311	translation_Loss:4.822	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.489                                                   	MRR:19.43	Hits@10:37.29	Best:19.45
2024-12-27 19:57:43,213: Snapshot:1	Epoch:9	Loss:10.482	translation_Loss:4.09	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.392                                                   	MRR:19.44	Hits@10:37.3	Best:19.45
2024-12-27 19:57:54,498: Snapshot:1	Epoch:10	Loss:9.902	translation_Loss:3.619	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.282                                                   	MRR:19.57	Hits@10:37.2	Best:19.57
2024-12-27 19:58:05,768: Snapshot:1	Epoch:11	Loss:9.488	translation_Loss:3.312	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.176                                                   	MRR:19.34	Hits@10:37.26	Best:19.57
2024-12-27 19:58:17,116: Snapshot:1	Epoch:12	Loss:9.193	translation_Loss:3.131	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.062                                                   	MRR:19.35	Hits@10:37.28	Best:19.57
2024-12-27 19:58:28,466: Snapshot:1	Epoch:13	Loss:8.929	translation_Loss:2.961	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.969                                                   	MRR:19.46	Hits@10:37.42	Best:19.57
2024-12-27 19:58:39,848: Snapshot:1	Epoch:14	Loss:8.714	translation_Loss:2.834	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.88                                                   	MRR:19.53	Hits@10:37.29	Best:19.57
2024-12-27 19:58:51,151: Early Stopping! Snapshot: 1 Epoch: 15 Best Results: 19.57
2024-12-27 19:58:51,152: Start to training tokens! Snapshot: 1 Epoch: 15 Loss:8.562 MRR:19.32 Best Results: 19.57
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 19:58:51,152: Snapshot:1	Epoch:15	Loss:8.562	translation_Loss:2.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.803                                                   	MRR:19.32	Hits@10:37.2	Best:19.57
2024-12-27 19:59:02,126: Snapshot:1	Epoch:16	Loss:103.778	translation_Loss:102.498	multi_layer_Loss:1.28	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.32	Hits@10:37.2	Best:19.57
2024-12-27 19:59:13,091: End of token training: 1 Epoch: 17 Loss:102.387 MRR:19.32 Best Results: 19.57
2024-12-27 19:59:13,092: Snapshot:1	Epoch:17	Loss:102.387	translation_Loss:102.385	multi_layer_Loss:0.002	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.32	Hits@10:37.2	Best:19.57
2024-12-27 19:59:13,455: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_1000/1model_best.tar'
2024-12-27 19:59:23,278: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1949 | 0.0967 | 0.2466 | 0.3068 |  0.3793 |
|     1      | 0.1983 | 0.1063 | 0.2373 | 0.2978 |  0.3742 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 19:59:52,370: Snapshot:2	Epoch:0	Loss:81.331	translation_Loss:81.033	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.298                                                   	MRR:6.49	Hits@10:16.09	Best:6.49
2024-12-27 20:00:00,816: Snapshot:2	Epoch:1	Loss:34.69	translation_Loss:33.6	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.09                                                   	MRR:16.36	Hits@10:33.44	Best:16.36
2024-12-27 20:00:09,348: Snapshot:2	Epoch:2	Loss:19.851	translation_Loss:18.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.653                                                   	MRR:19.57	Hits@10:37.6	Best:19.57
2024-12-27 20:00:17,845: Snapshot:2	Epoch:3	Loss:13.096	translation_Loss:11.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.026                                                   	MRR:21.13	Hits@10:39.97	Best:21.13
2024-12-27 20:00:26,510: Snapshot:2	Epoch:4	Loss:9.572	translation_Loss:7.29	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.281                                                   	MRR:21.44	Hits@10:40.18	Best:21.44
2024-12-27 20:00:34,896: Snapshot:2	Epoch:5	Loss:7.535	translation_Loss:5.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.448                                                   	MRR:21.91	Hits@10:40.41	Best:21.91
2024-12-27 20:00:43,355: Snapshot:2	Epoch:6	Loss:6.327	translation_Loss:3.784	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.543                                                   	MRR:22.15	Hits@10:40.71	Best:22.15
2024-12-27 20:00:51,719: Snapshot:2	Epoch:7	Loss:5.502	translation_Loss:2.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.589                                                   	MRR:22.13	Hits@10:41.05	Best:22.15
2024-12-27 20:01:00,127: Snapshot:2	Epoch:8	Loss:4.949	translation_Loss:2.354	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.596                                                   	MRR:22.45	Hits@10:40.9	Best:22.45
2024-12-27 20:01:08,723: Snapshot:2	Epoch:9	Loss:4.532	translation_Loss:1.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.581                                                   	MRR:22.85	Hits@10:41.32	Best:22.85
2024-12-27 20:01:17,175: Snapshot:2	Epoch:10	Loss:4.231	translation_Loss:1.677	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.555                                                   	MRR:23.11	Hits@10:41.62	Best:23.11
2024-12-27 20:01:26,143: Snapshot:2	Epoch:11	Loss:3.968	translation_Loss:1.454	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.513                                                   	MRR:23.1	Hits@10:41.64	Best:23.11
2024-12-27 20:01:34,489: Snapshot:2	Epoch:12	Loss:3.769	translation_Loss:1.302	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.468                                                   	MRR:23.08	Hits@10:41.43	Best:23.11
2024-12-27 20:01:42,869: Snapshot:2	Epoch:13	Loss:3.598	translation_Loss:1.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.418                                                   	MRR:23.37	Hits@10:41.74	Best:23.37
2024-12-27 20:01:51,253: Snapshot:2	Epoch:14	Loss:3.462	translation_Loss:1.094	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.369                                                   	MRR:23.32	Hits@10:41.84	Best:23.37
2024-12-27 20:01:59,650: Snapshot:2	Epoch:15	Loss:3.351	translation_Loss:1.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.321                                                   	MRR:23.22	Hits@10:41.52	Best:23.37
2024-12-27 20:02:08,184: Snapshot:2	Epoch:16	Loss:3.245	translation_Loss:0.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.271                                                   	MRR:23.23	Hits@10:41.65	Best:23.37
2024-12-27 20:02:16,611: Snapshot:2	Epoch:17	Loss:3.175	translation_Loss:0.945	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.229                                                   	MRR:23.16	Hits@10:41.64	Best:23.37
2024-12-27 20:02:25,092: Early Stopping! Snapshot: 2 Epoch: 18 Best Results: 23.37
2024-12-27 20:02:25,092: Start to training tokens! Snapshot: 2 Epoch: 18 Loss:3.111 MRR:23.13 Best Results: 23.37
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:02:25,093: Snapshot:2	Epoch:18	Loss:3.111	translation_Loss:0.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.19                                                   	MRR:23.13	Hits@10:41.83	Best:23.37
2024-12-27 20:02:33,159: Snapshot:2	Epoch:19	Loss:64.65	translation_Loss:63.332	multi_layer_Loss:1.318	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.13	Hits@10:41.83	Best:23.37
2024-12-27 20:02:41,235: End of token training: 2 Epoch: 20 Loss:63.318 MRR:23.13 Best Results: 23.37
2024-12-27 20:02:41,235: Snapshot:2	Epoch:20	Loss:63.318	translation_Loss:63.292	multi_layer_Loss:0.026	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.13	Hits@10:41.83	Best:23.37
2024-12-27 20:02:41,600: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_1000/2model_best.tar'
2024-12-27 20:02:55,257: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1616 | 0.0824 | 0.2006 | 0.249  |  0.3089 |
|     1      | 0.148  | 0.0749 | 0.1761 | 0.2234 |  0.2853 |
|     2      | 0.2313 | 0.1406 | 0.2559 |  0.32  |  0.4145 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:03:11,285: Snapshot:3	Epoch:0	Loss:36.155	translation_Loss:36.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.046                                                   	MRR:5.22	Hits@10:10.59	Best:5.22
2024-12-27 20:03:15,305: Snapshot:3	Epoch:1	Loss:25.515	translation_Loss:25.362	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:10.42	Hits@10:22.67	Best:10.42
2024-12-27 20:03:19,342: Snapshot:3	Epoch:2	Loss:17.701	translation_Loss:17.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.287                                                   	MRR:17.2	Hits@10:36.08	Best:17.2
2024-12-27 20:03:23,372: Snapshot:3	Epoch:3	Loss:11.942	translation_Loss:11.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.436                                                   	MRR:21.88	Hits@10:41.07	Best:21.88
2024-12-27 20:03:27,418: Snapshot:3	Epoch:4	Loss:8.013	translation_Loss:7.437	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.576                                                   	MRR:24.25	Hits@10:43.97	Best:24.25
2024-12-27 20:03:31,446: Snapshot:3	Epoch:5	Loss:5.459	translation_Loss:4.767	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.693                                                   	MRR:25.89	Hits@10:45.24	Best:25.89
2024-12-27 20:03:35,425: Snapshot:3	Epoch:6	Loss:3.767	translation_Loss:2.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.781                                                   	MRR:27.29	Hits@10:46.19	Best:27.29
2024-12-27 20:03:39,461: Snapshot:3	Epoch:7	Loss:2.739	translation_Loss:1.9	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.839                                                   	MRR:28.29	Hits@10:47.01	Best:28.29
2024-12-27 20:03:43,502: Snapshot:3	Epoch:8	Loss:2.113	translation_Loss:1.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.87                                                   	MRR:29.12	Hits@10:47.2	Best:29.12
2024-12-27 20:03:47,431: Snapshot:3	Epoch:9	Loss:1.751	translation_Loss:0.869	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.881                                                   	MRR:29.52	Hits@10:47.65	Best:29.52
2024-12-27 20:03:51,354: Snapshot:3	Epoch:10	Loss:1.507	translation_Loss:0.63	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.878                                                   	MRR:29.95	Hits@10:47.79	Best:29.95
2024-12-27 20:03:55,323: Snapshot:3	Epoch:11	Loss:1.374	translation_Loss:0.507	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.867                                                   	MRR:30.12	Hits@10:47.88	Best:30.12
2024-12-27 20:03:59,263: Snapshot:3	Epoch:12	Loss:1.249	translation_Loss:0.395	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.854                                                   	MRR:30.33	Hits@10:48.07	Best:30.33
2024-12-27 20:04:03,217: Snapshot:3	Epoch:13	Loss:1.183	translation_Loss:0.345	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.838                                                   	MRR:30.44	Hits@10:48.29	Best:30.44
2024-12-27 20:04:07,154: Snapshot:3	Epoch:14	Loss:1.121	translation_Loss:0.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.822                                                   	MRR:30.47	Hits@10:48.37	Best:30.47
2024-12-27 20:04:11,192: Snapshot:3	Epoch:15	Loss:1.07	translation_Loss:0.265	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.805                                                   	MRR:30.74	Hits@10:48.39	Best:30.74
2024-12-27 20:04:15,109: Snapshot:3	Epoch:16	Loss:1.034	translation_Loss:0.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.79                                                   	MRR:30.58	Hits@10:48.39	Best:30.74
2024-12-27 20:04:19,040: Snapshot:3	Epoch:17	Loss:0.999	translation_Loss:0.223	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.776                                                   	MRR:30.8	Hits@10:48.37	Best:30.8
2024-12-27 20:04:22,990: Snapshot:3	Epoch:18	Loss:0.965	translation_Loss:0.203	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.763                                                   	MRR:31.15	Hits@10:48.62	Best:31.15
2024-12-27 20:04:27,555: Snapshot:3	Epoch:19	Loss:0.941	translation_Loss:0.192	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.749                                                   	MRR:31.23	Hits@10:48.67	Best:31.23
2024-12-27 20:04:31,460: Snapshot:3	Epoch:20	Loss:0.923	translation_Loss:0.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.738                                                   	MRR:31.19	Hits@10:48.73	Best:31.23
2024-12-27 20:04:35,349: Snapshot:3	Epoch:21	Loss:0.909	translation_Loss:0.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.728                                                   	MRR:31.22	Hits@10:48.99	Best:31.23
2024-12-27 20:04:39,259: Snapshot:3	Epoch:22	Loss:0.882	translation_Loss:0.163	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.719                                                   	MRR:31.33	Hits@10:49.15	Best:31.33
2024-12-27 20:04:43,168: Snapshot:3	Epoch:23	Loss:0.871	translation_Loss:0.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.71                                                   	MRR:31.11	Hits@10:48.8	Best:31.33
2024-12-27 20:04:47,023: Snapshot:3	Epoch:24	Loss:0.862	translation_Loss:0.161	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.701                                                   	MRR:30.94	Hits@10:48.77	Best:31.33
2024-12-27 20:04:50,908: Snapshot:3	Epoch:25	Loss:0.839	translation_Loss:0.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.692                                                   	MRR:31.04	Hits@10:48.95	Best:31.33
2024-12-27 20:04:54,788: Snapshot:3	Epoch:26	Loss:0.834	translation_Loss:0.149	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.685                                                   	MRR:30.89	Hits@10:48.93	Best:31.33
2024-12-27 20:04:58,656: Early Stopping! Snapshot: 3 Epoch: 27 Best Results: 31.33
2024-12-27 20:04:58,656: Start to training tokens! Snapshot: 3 Epoch: 27 Loss:0.817 MRR:31.05 Best Results: 31.33
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:04:58,657: Snapshot:3	Epoch:27	Loss:0.817	translation_Loss:0.14	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.677                                                   	MRR:31.05	Hits@10:48.99	Best:31.33
2024-12-27 20:05:02,426: Snapshot:3	Epoch:28	Loss:21.05	translation_Loss:20.134	multi_layer_Loss:0.916	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.05	Hits@10:48.99	Best:31.33
2024-12-27 20:05:06,191: End of token training: 3 Epoch: 29 Loss:20.242 MRR:31.05 Best Results: 31.33
2024-12-27 20:05:06,191: Snapshot:3	Epoch:29	Loss:20.242	translation_Loss:20.029	multi_layer_Loss:0.213	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.05	Hits@10:48.99	Best:31.33
2024-12-27 20:05:06,527: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_1000/3model_best.tar'
2024-12-27 20:05:21,861: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1559 | 0.0795 | 0.1921 | 0.2386 |  0.2988 |
|     1      | 0.1351 | 0.0649 | 0.159  | 0.2063 |  0.2664 |
|     2      | 0.161  | 0.0839 | 0.1746 | 0.2244 |  0.3079 |
|     3      | 0.3151 | 0.2169 | 0.3607 | 0.4152 |  0.4961 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:05:34,768: Snapshot:4	Epoch:0	Loss:18.329	translation_Loss:18.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.026                                                   	MRR:7.13	Hits@10:18.89	Best:7.13
2024-12-27 20:05:37,579: Snapshot:4	Epoch:1	Loss:12.48	translation_Loss:12.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:10.79	Hits@10:26.34	Best:10.79
2024-12-27 20:05:40,375: Snapshot:4	Epoch:2	Loss:8.741	translation_Loss:8.588	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.153                                                   	MRR:14.46	Hits@10:34.04	Best:14.46
2024-12-27 20:05:43,239: Snapshot:4	Epoch:3	Loss:6.207	translation_Loss:6.0	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.208                                                   	MRR:17.76	Hits@10:39.69	Best:17.76
2024-12-27 20:05:46,051: Snapshot:4	Epoch:4	Loss:4.473	translation_Loss:4.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.255                                                   	MRR:20.84	Hits@10:44.11	Best:20.84
2024-12-27 20:05:48,886: Snapshot:4	Epoch:5	Loss:3.294	translation_Loss:3.001	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.293                                                   	MRR:22.77	Hits@10:47.16	Best:22.77
2024-12-27 20:05:51,695: Snapshot:4	Epoch:6	Loss:2.476	translation_Loss:2.153	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.323                                                   	MRR:23.78	Hits@10:48.93	Best:23.78
2024-12-27 20:05:54,565: Snapshot:4	Epoch:7	Loss:1.81	translation_Loss:1.465	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.345                                                   	MRR:25.34	Hits@10:50.0	Best:25.34
2024-12-27 20:05:57,376: Snapshot:4	Epoch:8	Loss:1.281	translation_Loss:0.92	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.361                                                   	MRR:26.57	Hits@10:50.5	Best:26.57
2024-12-27 20:06:00,191: Snapshot:4	Epoch:9	Loss:0.955	translation_Loss:0.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.37                                                   	MRR:26.65	Hits@10:50.21	Best:26.65
2024-12-27 20:06:03,127: Snapshot:4	Epoch:10	Loss:0.79	translation_Loss:0.417	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.374                                                   	MRR:27.07	Hits@10:51.07	Best:27.07
2024-12-27 20:06:05,982: Snapshot:4	Epoch:11	Loss:0.672	translation_Loss:0.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.373                                                   	MRR:27.18	Hits@10:51.2	Best:27.18
2024-12-27 20:06:08,764: Snapshot:4	Epoch:12	Loss:0.614	translation_Loss:0.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.369                                                   	MRR:27.25	Hits@10:51.33	Best:27.25
2024-12-27 20:06:11,581: Snapshot:4	Epoch:13	Loss:0.567	translation_Loss:0.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.365                                                   	MRR:27.44	Hits@10:51.32	Best:27.44
2024-12-27 20:06:14,396: Snapshot:4	Epoch:14	Loss:0.529	translation_Loss:0.168	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.36                                                   	MRR:27.46	Hits@10:51.29	Best:27.46
2024-12-27 20:06:17,175: Snapshot:4	Epoch:15	Loss:0.495	translation_Loss:0.141	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.354                                                   	MRR:27.26	Hits@10:51.5	Best:27.46
2024-12-27 20:06:19,915: Snapshot:4	Epoch:16	Loss:0.47	translation_Loss:0.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.348                                                   	MRR:27.18	Hits@10:51.34	Best:27.46
2024-12-27 20:06:22,669: Snapshot:4	Epoch:17	Loss:0.458	translation_Loss:0.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.342                                                   	MRR:27.28	Hits@10:51.53	Best:27.46
2024-12-27 20:06:25,399: Snapshot:4	Epoch:18	Loss:0.45	translation_Loss:0.114	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.336                                                   	MRR:27.39	Hits@10:51.88	Best:27.46
2024-12-27 20:06:28,188: Snapshot:4	Epoch:19	Loss:0.431	translation_Loss:0.099	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.332                                                   	MRR:27.54	Hits@10:51.91	Best:27.54
2024-12-27 20:06:30,895: Snapshot:4	Epoch:20	Loss:0.42	translation_Loss:0.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.328                                                   	MRR:27.54	Hits@10:51.71	Best:27.54
2024-12-27 20:06:33,676: Snapshot:4	Epoch:21	Loss:0.411	translation_Loss:0.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.323                                                   	MRR:27.57	Hits@10:51.37	Best:27.57
2024-12-27 20:06:36,475: Snapshot:4	Epoch:22	Loss:0.404	translation_Loss:0.085	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.32                                                   	MRR:27.82	Hits@10:51.53	Best:27.82
2024-12-27 20:06:39,285: Snapshot:4	Epoch:23	Loss:0.398	translation_Loss:0.082	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.316                                                   	MRR:27.99	Hits@10:51.78	Best:27.99
2024-12-27 20:06:42,150: Snapshot:4	Epoch:24	Loss:0.387	translation_Loss:0.074	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.313                                                   	MRR:28.12	Hits@10:51.44	Best:28.12
2024-12-27 20:06:44,874: Snapshot:4	Epoch:25	Loss:0.388	translation_Loss:0.079	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.31                                                   	MRR:28.09	Hits@10:51.64	Best:28.12
2024-12-27 20:06:47,674: Snapshot:4	Epoch:26	Loss:0.381	translation_Loss:0.074	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.306                                                   	MRR:28.24	Hits@10:51.7	Best:28.24
2024-12-27 20:06:50,430: Snapshot:4	Epoch:27	Loss:0.373	translation_Loss:0.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.304                                                   	MRR:28.05	Hits@10:51.62	Best:28.24
2024-12-27 20:06:53,161: Snapshot:4	Epoch:28	Loss:0.367	translation_Loss:0.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.301                                                   	MRR:27.93	Hits@10:51.89	Best:28.24
2024-12-27 20:06:55,886: Snapshot:4	Epoch:29	Loss:0.365	translation_Loss:0.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.299                                                   	MRR:28.18	Hits@10:52.14	Best:28.24
2024-12-27 20:06:58,687: Snapshot:4	Epoch:30	Loss:0.361	translation_Loss:0.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.296                                                   	MRR:28.36	Hits@10:52.37	Best:28.36
2024-12-27 20:07:01,513: Snapshot:4	Epoch:31	Loss:0.353	translation_Loss:0.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.293                                                   	MRR:28.4	Hits@10:52.49	Best:28.4
2024-12-27 20:07:04,375: Snapshot:4	Epoch:32	Loss:0.348	translation_Loss:0.058	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.29                                                   	MRR:28.43	Hits@10:52.6	Best:28.43
2024-12-27 20:07:07,221: Snapshot:4	Epoch:33	Loss:0.344	translation_Loss:0.056	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.288                                                   	MRR:28.72	Hits@10:53.03	Best:28.72
2024-12-27 20:07:10,056: Snapshot:4	Epoch:34	Loss:0.339	translation_Loss:0.054	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.285                                                   	MRR:29.1	Hits@10:53.18	Best:29.1
2024-12-27 20:07:12,834: Snapshot:4	Epoch:35	Loss:0.339	translation_Loss:0.056	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.282                                                   	MRR:29.05	Hits@10:53.08	Best:29.1
2024-12-27 20:07:15,532: Snapshot:4	Epoch:36	Loss:0.329	translation_Loss:0.049	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.28                                                   	MRR:28.96	Hits@10:53.29	Best:29.1
2024-12-27 20:07:18,269: Snapshot:4	Epoch:37	Loss:0.337	translation_Loss:0.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.278                                                   	MRR:28.83	Hits@10:53.37	Best:29.1
2024-12-27 20:07:21,000: Snapshot:4	Epoch:38	Loss:0.33	translation_Loss:0.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.277                                                   	MRR:28.87	Hits@10:53.46	Best:29.1
2024-12-27 20:07:23,785: Early Stopping! Snapshot: 4 Epoch: 39 Best Results: 29.1
2024-12-27 20:07:23,785: Start to training tokens! Snapshot: 4 Epoch: 39 Loss:0.328 MRR:28.8 Best Results: 29.1
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:07:23,786: Snapshot:4	Epoch:39	Loss:0.328	translation_Loss:0.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.275                                                   	MRR:28.8	Hits@10:53.77	Best:29.1
2024-12-27 20:07:26,432: Snapshot:4	Epoch:40	Loss:12.441	translation_Loss:11.642	multi_layer_Loss:0.798	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.8	Hits@10:53.77	Best:29.1
2024-12-27 20:07:29,081: End of token training: 4 Epoch: 41 Loss:11.926 MRR:28.8 Best Results: 29.1
2024-12-27 20:07:29,081: Snapshot:4	Epoch:41	Loss:11.926	translation_Loss:11.579	multi_layer_Loss:0.347	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:28.8	Hits@10:53.77	Best:29.1
2024-12-27 20:07:29,455: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_1000/4model_best.tar'
2024-12-27 20:07:46,487: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1461 | 0.0748 | 0.1797 | 0.2213 |  0.2765 |
|     1      | 0.1284 | 0.061  | 0.1507 | 0.1946 |  0.2556 |
|     2      | 0.1472 | 0.0765 | 0.1587 | 0.2061 |  0.2814 |
|     3      | 0.2576 | 0.1723 | 0.2889 | 0.3336 |  0.4119 |
|     4      | 0.2899 | 0.1705 | 0.3335 | 0.4124 |  0.5331 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 20:07:46,489: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2774 | 0.1664 | 0.342  | 0.4116 |  0.4849 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1949 | 0.0967 | 0.2466 | 0.3068 |  0.3793 |
|     1      | 0.1983 | 0.1063 | 0.2373 | 0.2978 |  0.3742 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1616 | 0.0824 | 0.2006 | 0.249  |  0.3089 |
|     1      | 0.148  | 0.0749 | 0.1761 | 0.2234 |  0.2853 |
|     2      | 0.2313 | 0.1406 | 0.2559 |  0.32  |  0.4145 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1559 | 0.0795 | 0.1921 | 0.2386 |  0.2988 |
|     1      | 0.1351 | 0.0649 | 0.159  | 0.2063 |  0.2664 |
|     2      | 0.161  | 0.0839 | 0.1746 | 0.2244 |  0.3079 |
|     3      | 0.3151 | 0.2169 | 0.3607 | 0.4152 |  0.4961 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1461 | 0.0748 | 0.1797 | 0.2213 |  0.2765 |
|     1      | 0.1284 | 0.061  | 0.1507 | 0.1946 |  0.2556 |
|     2      | 0.1472 | 0.0765 | 0.1587 | 0.2061 |  0.2814 |
|     3      | 0.2576 | 0.1723 | 0.2889 | 0.3336 |  0.4119 |
|     4      | 0.2899 | 0.1705 | 0.3335 | 0.4124 |  0.5331 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 20:07:46,489: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 371.94126749038696 |   0.277   |    0.166     |    0.342     |     0.485     |
|    1     | 225.45962715148926 |   0.197   |    0.101     |    0.242     |     0.377     |
|    2     | 194.02999448776245 |   0.175   |    0.095     |    0.206     |     0.327     |
|    3     | 128.99443316459656 |   0.167   |     0.09     |    0.195     |     0.311     |
|    4     | 125.69526290893555 |   0.162   |    0.087     |    0.188     |     0.302     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 20:07:46,489: Sum_Training_Time:1046.1205852031708
2024-12-27 20:07:46,489: Every_Training_Time:[371.94126749038696, 225.45962715148926, 194.02999448776245, 128.99443316459656, 125.69526290893555]
2024-12-27 20:07:46,489: Forward transfer: 0.018575 Backward transfer: -0.0857
2024-12-27 20:08:23,889: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.0001, lifelong_name='double_tokened', log_path='./logs/20241227200750/RELATIONrelation_0.0001_512_5000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.0001_512_5000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.0001_512_5000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 20:08:40,128: Snapshot:0	Epoch:0	Loss:156.019	translation_Loss:156.019	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.96	Hits@10:16.66	Best:7.96
2024-12-27 20:08:52,000: Snapshot:0	Epoch:1	Loss:132.307	translation_Loss:132.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.71	Hits@10:22.31	Best:9.71
2024-12-27 20:09:03,779: Snapshot:0	Epoch:2	Loss:113.356	translation_Loss:113.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.55	Hits@10:26.79	Best:11.55
2024-12-27 20:09:15,632: Snapshot:0	Epoch:3	Loss:95.555	translation_Loss:95.555	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.13	Hits@10:32.98	Best:15.13
2024-12-27 20:09:27,340: Snapshot:0	Epoch:4	Loss:78.62	translation_Loss:78.62	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.23	Hits@10:37.84	Best:18.23
2024-12-27 20:09:39,047: Snapshot:0	Epoch:5	Loss:63.319	translation_Loss:63.319	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.44	Hits@10:40.92	Best:20.44
2024-12-27 20:09:50,828: Snapshot:0	Epoch:6	Loss:50.771	translation_Loss:50.771	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.05	Hits@10:42.99	Best:22.05
2024-12-27 20:10:03,165: Snapshot:0	Epoch:7	Loss:40.61	translation_Loss:40.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.29	Hits@10:44.37	Best:23.29
2024-12-27 20:10:15,018: Snapshot:0	Epoch:8	Loss:32.457	translation_Loss:32.457	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.25	Hits@10:45.41	Best:24.25
2024-12-27 20:10:26,746: Snapshot:0	Epoch:9	Loss:25.939	translation_Loss:25.939	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.03	Hits@10:46.1	Best:25.03
2024-12-27 20:10:38,650: Snapshot:0	Epoch:10	Loss:20.894	translation_Loss:20.894	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.53	Hits@10:46.56	Best:25.53
2024-12-27 20:10:50,388: Snapshot:0	Epoch:11	Loss:17.099	translation_Loss:17.099	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.04	Hits@10:47.1	Best:26.04
2024-12-27 20:11:02,250: Snapshot:0	Epoch:12	Loss:14.16	translation_Loss:14.16	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.44	Hits@10:47.46	Best:26.44
2024-12-27 20:11:14,050: Snapshot:0	Epoch:13	Loss:12.02	translation_Loss:12.02	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.69	Hits@10:47.64	Best:26.69
2024-12-27 20:11:25,819: Snapshot:0	Epoch:14	Loss:10.304	translation_Loss:10.304	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.85	Hits@10:47.86	Best:26.85
2024-12-27 20:11:37,707: Snapshot:0	Epoch:15	Loss:9.066	translation_Loss:9.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.08	Hits@10:47.95	Best:27.08
2024-12-27 20:11:49,531: Snapshot:0	Epoch:16	Loss:8.035	translation_Loss:8.035	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.22	Hits@10:47.96	Best:27.22
2024-12-27 20:12:01,400: Snapshot:0	Epoch:17	Loss:7.152	translation_Loss:7.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.3	Hits@10:47.99	Best:27.3
2024-12-27 20:12:13,161: Snapshot:0	Epoch:18	Loss:6.543	translation_Loss:6.543	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.36	Hits@10:48.13	Best:27.36
2024-12-27 20:12:25,370: Snapshot:0	Epoch:19	Loss:5.978	translation_Loss:5.978	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.33	Hits@10:48.25	Best:27.36
2024-12-27 20:12:37,042: Snapshot:0	Epoch:20	Loss:5.578	translation_Loss:5.578	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.36	Hits@10:48.18	Best:27.36
2024-12-27 20:12:48,710: Snapshot:0	Epoch:21	Loss:5.196	translation_Loss:5.196	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.35	Hits@10:48.09	Best:27.36
2024-12-27 20:13:00,522: Snapshot:0	Epoch:22	Loss:4.861	translation_Loss:4.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.44	Hits@10:48.03	Best:27.44
2024-12-27 20:13:12,286: Snapshot:0	Epoch:23	Loss:4.642	translation_Loss:4.642	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.44	Hits@10:47.93	Best:27.44
2024-12-27 20:13:24,032: Snapshot:0	Epoch:24	Loss:4.404	translation_Loss:4.404	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.37	Hits@10:48.01	Best:27.44
2024-12-27 20:13:35,729: Snapshot:0	Epoch:25	Loss:4.212	translation_Loss:4.212	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.41	Hits@10:47.96	Best:27.44
2024-12-27 20:13:47,456: Snapshot:0	Epoch:26	Loss:3.995	translation_Loss:3.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.46	Hits@10:47.97	Best:27.46
2024-12-27 20:13:59,161: Snapshot:0	Epoch:27	Loss:3.863	translation_Loss:3.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.42	Hits@10:47.95	Best:27.46
2024-12-27 20:14:10,837: Snapshot:0	Epoch:28	Loss:3.707	translation_Loss:3.707	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.31	Hits@10:47.86	Best:27.46
2024-12-27 20:14:22,547: Snapshot:0	Epoch:29	Loss:3.603	translation_Loss:3.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.3	Hits@10:47.62	Best:27.46
2024-12-27 20:14:34,209: Snapshot:0	Epoch:30	Loss:3.452	translation_Loss:3.452	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.26	Hits@10:47.78	Best:27.46
2024-12-27 20:14:45,925: Early Stopping! Snapshot: 0 Epoch: 31 Best Results: 27.46
2024-12-27 20:14:45,926: Start to training tokens! Snapshot: 0 Epoch: 31 Loss:3.357 MRR:27.15 Best Results: 27.46
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:14:45,927: Snapshot:0	Epoch:31	Loss:3.357	translation_Loss:3.357	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.15	Hits@10:47.69	Best:27.46
2024-12-27 20:14:58,894: Snapshot:0	Epoch:32	Loss:101.038	translation_Loss:99.758	multi_layer_Loss:1.28	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.15	Hits@10:47.69	Best:27.46
2024-12-27 20:15:11,072: End of token training: 0 Epoch: 33 Loss:99.847 MRR:27.15 Best Results: 27.46
2024-12-27 20:15:11,072: Snapshot:0	Epoch:33	Loss:99.847	translation_Loss:99.846	multi_layer_Loss:0.002	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.15	Hits@10:47.69	Best:27.46
2024-12-27 20:15:11,337: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_5000/0model_best.tar'
2024-12-27 20:15:16,883: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2765 | 0.1651 | 0.3422 | 0.4115 |  0.4821 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:15:54,241: Snapshot:1	Epoch:0	Loss:136.681	translation_Loss:135.349	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.332                                                   	MRR:5.45	Hits@10:13.77	Best:5.45
2024-12-27 20:16:05,576: Snapshot:1	Epoch:1	Loss:97.335	translation_Loss:93.233	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.102                                                   	MRR:10.25	Hits@10:22.9	Best:10.25
2024-12-27 20:16:16,990: Snapshot:1	Epoch:2	Loss:69.753	translation_Loss:62.904	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.849                                                   	MRR:13.76	Hits@10:28.66	Best:13.76
2024-12-27 20:16:28,384: Snapshot:1	Epoch:3	Loss:50.405	translation_Loss:41.478	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.927                                                   	MRR:15.88	Hits@10:31.64	Best:15.88
2024-12-27 20:16:39,639: Snapshot:1	Epoch:4	Loss:38.105	translation_Loss:27.881	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.225                                                   	MRR:16.79	Hits@10:33.25	Best:16.79
2024-12-27 20:16:50,964: Snapshot:1	Epoch:5	Loss:31.244	translation_Loss:20.407	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.837                                                   	MRR:17.1	Hits@10:33.77	Best:17.1
2024-12-27 20:17:02,299: Snapshot:1	Epoch:6	Loss:27.38	translation_Loss:16.379	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.001                                                   	MRR:17.09	Hits@10:34.0	Best:17.1
2024-12-27 20:17:13,710: Snapshot:1	Epoch:7	Loss:24.863	translation_Loss:13.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.934                                                   	MRR:17.28	Hits@10:33.83	Best:17.28
2024-12-27 20:17:25,161: Snapshot:1	Epoch:8	Loss:23.274	translation_Loss:12.508	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.766                                                   	MRR:17.54	Hits@10:33.84	Best:17.54
2024-12-27 20:17:36,362: Snapshot:1	Epoch:9	Loss:22.154	translation_Loss:11.559	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.595                                                   	MRR:17.53	Hits@10:34.0	Best:17.54
2024-12-27 20:17:47,687: Snapshot:1	Epoch:10	Loss:21.326	translation_Loss:10.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.437                                                   	MRR:17.26	Hits@10:33.76	Best:17.54
2024-12-27 20:17:59,006: Snapshot:1	Epoch:11	Loss:20.834	translation_Loss:10.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.27                                                   	MRR:17.36	Hits@10:33.93	Best:17.54
2024-12-27 20:18:10,218: Snapshot:1	Epoch:12	Loss:20.349	translation_Loss:10.215	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.134                                                   	MRR:17.36	Hits@10:33.73	Best:17.54
2024-12-27 20:18:21,544: Early Stopping! Snapshot: 1 Epoch: 13 Best Results: 17.54
2024-12-27 20:18:21,545: Start to training tokens! Snapshot: 1 Epoch: 13 Loss:19.998 MRR:17.34 Best Results: 17.54
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:18:21,545: Snapshot:1	Epoch:13	Loss:19.998	translation_Loss:9.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.025                                                   	MRR:17.34	Hits@10:33.68	Best:17.54
2024-12-27 20:18:32,518: Snapshot:1	Epoch:14	Loss:113.787	translation_Loss:112.507	multi_layer_Loss:1.28	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.34	Hits@10:33.68	Best:17.54
2024-12-27 20:18:43,380: End of token training: 1 Epoch: 15 Loss:112.55 MRR:17.34 Best Results: 17.54
2024-12-27 20:18:43,380: Snapshot:1	Epoch:15	Loss:112.55	translation_Loss:112.548	multi_layer_Loss:0.002	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:17.34	Hits@10:33.68	Best:17.54
2024-12-27 20:18:43,730: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_5000/1model_best.tar'
2024-12-27 20:18:54,105: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2302 | 0.1229 | 0.2877 | 0.3547 |  0.431  |
|     1      | 0.1762 | 0.0912 | 0.2089 | 0.2661 |  0.3399 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:19:22,495: Snapshot:2	Epoch:0	Loss:85.2	translation_Loss:84.119	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.08                                                   	MRR:5.91	Hits@10:14.16	Best:5.91
2024-12-27 20:19:30,862: Snapshot:2	Epoch:1	Loss:41.774	translation_Loss:38.209	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.564                                                   	MRR:15.94	Hits@10:32.24	Best:15.94
2024-12-27 20:19:39,330: Snapshot:2	Epoch:2	Loss:27.375	translation_Loss:22.393	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.983                                                   	MRR:19.64	Hits@10:37.41	Best:19.64
2024-12-27 20:19:47,882: Snapshot:2	Epoch:3	Loss:20.924	translation_Loss:15.188	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.735                                                   	MRR:21.19	Hits@10:39.53	Best:21.19
2024-12-27 20:19:56,425: Snapshot:2	Epoch:4	Loss:17.219	translation_Loss:11.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.108                                                   	MRR:22.12	Hits@10:40.76	Best:22.12
2024-12-27 20:20:04,876: Snapshot:2	Epoch:5	Loss:14.993	translation_Loss:8.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.233                                                   	MRR:22.35	Hits@10:41.37	Best:22.35
2024-12-27 20:20:13,401: Snapshot:2	Epoch:6	Loss:13.42	translation_Loss:7.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.176                                                   	MRR:22.44	Hits@10:41.45	Best:22.44
2024-12-27 20:20:21,899: Snapshot:2	Epoch:7	Loss:12.218	translation_Loss:6.19	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.029                                                   	MRR:23.06	Hits@10:41.77	Best:23.06
2024-12-27 20:20:30,360: Snapshot:2	Epoch:8	Loss:11.294	translation_Loss:5.448	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.846                                                   	MRR:22.88	Hits@10:41.59	Best:23.06
2024-12-27 20:20:38,793: Snapshot:2	Epoch:9	Loss:10.56	translation_Loss:4.9	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.659                                                   	MRR:23.24	Hits@10:41.43	Best:23.24
2024-12-27 20:20:47,312: Snapshot:2	Epoch:10	Loss:9.931	translation_Loss:4.472	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.46                                                   	MRR:23.27	Hits@10:41.56	Best:23.27
2024-12-27 20:20:55,741: Snapshot:2	Epoch:11	Loss:9.441	translation_Loss:4.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.299                                                   	MRR:23.14	Hits@10:41.53	Best:23.27
2024-12-27 20:21:04,563: Snapshot:2	Epoch:12	Loss:9.054	translation_Loss:3.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.133                                                   	MRR:23.27	Hits@10:41.4	Best:23.27
2024-12-27 20:21:12,997: Snapshot:2	Epoch:13	Loss:8.714	translation_Loss:3.729	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.985                                                   	MRR:22.97	Hits@10:40.88	Best:23.27
2024-12-27 20:21:21,381: Snapshot:2	Epoch:14	Loss:8.465	translation_Loss:3.616	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.849                                                   	MRR:22.98	Hits@10:40.66	Best:23.27
2024-12-27 20:21:29,883: Early Stopping! Snapshot: 2 Epoch: 15 Best Results: 23.27
2024-12-27 20:21:29,883: Start to training tokens! Snapshot: 2 Epoch: 15 Loss:8.221 MRR:22.9 Best Results: 23.27
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:21:29,883: Snapshot:2	Epoch:15	Loss:8.221	translation_Loss:3.482	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.739                                                   	MRR:22.9	Hits@10:40.26	Best:23.27
2024-12-27 20:21:37,929: Snapshot:2	Epoch:16	Loss:77.59	translation_Loss:76.273	multi_layer_Loss:1.318	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.9	Hits@10:40.26	Best:23.27
2024-12-27 20:21:45,979: End of token training: 2 Epoch: 17 Loss:76.169 MRR:22.9 Best Results: 23.27
2024-12-27 20:21:45,979: Snapshot:2	Epoch:17	Loss:76.169	translation_Loss:76.143	multi_layer_Loss:0.026	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.9	Hits@10:40.26	Best:23.27
2024-12-27 20:21:46,306: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_5000/2model_best.tar'
2024-12-27 20:21:59,583: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1921 | 0.0985 | 0.2396 | 0.3015 |  0.371  |
|     1      | 0.1483 | 0.0736 | 0.1762 | 0.2242 |  0.2917 |
|     2      | 0.2305 | 0.1396 | 0.2596 | 0.3204 |  0.413  |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:22:15,641: Snapshot:3	Epoch:0	Loss:38.403	translation_Loss:38.221	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.181                                                   	MRR:4.75	Hits@10:10.17	Best:4.75
2024-12-27 20:22:19,562: Snapshot:3	Epoch:1	Loss:28.402	translation_Loss:27.872	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.53                                                   	MRR:10.1	Hits@10:21.79	Best:10.1
2024-12-27 20:22:23,720: Snapshot:3	Epoch:2	Loss:21.193	translation_Loss:20.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.95                                                   	MRR:16.28	Hits@10:34.2	Best:16.28
2024-12-27 20:22:27,741: Snapshot:3	Epoch:3	Loss:15.688	translation_Loss:14.287	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.401                                                   	MRR:20.78	Hits@10:40.33	Best:20.78
2024-12-27 20:22:31,692: Snapshot:3	Epoch:4	Loss:11.79	translation_Loss:9.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.804                                                   	MRR:23.76	Hits@10:43.32	Best:23.76
2024-12-27 20:22:35,639: Snapshot:3	Epoch:5	Loss:9.029	translation_Loss:6.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.116                                                   	MRR:25.63	Hits@10:44.96	Best:25.63
2024-12-27 20:22:39,542: Snapshot:3	Epoch:6	Loss:7.202	translation_Loss:4.873	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.33                                                   	MRR:26.92	Hits@10:46.05	Best:26.92
2024-12-27 20:22:43,499: Snapshot:3	Epoch:7	Loss:6.0	translation_Loss:3.544	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.456                                                   	MRR:28.03	Hits@10:46.79	Best:28.03
2024-12-27 20:22:47,479: Snapshot:3	Epoch:8	Loss:5.209	translation_Loss:2.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.531                                                   	MRR:28.87	Hits@10:47.48	Best:28.87
2024-12-27 20:22:51,412: Snapshot:3	Epoch:9	Loss:4.646	translation_Loss:2.081	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.565                                                   	MRR:29.45	Hits@10:47.81	Best:29.45
2024-12-27 20:22:55,389: Snapshot:3	Epoch:10	Loss:4.244	translation_Loss:1.672	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.571                                                   	MRR:29.89	Hits@10:47.8	Best:29.89
2024-12-27 20:22:59,316: Snapshot:3	Epoch:11	Loss:3.956	translation_Loss:1.396	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.561                                                   	MRR:30.24	Hits@10:47.94	Best:30.24
2024-12-27 20:23:03,253: Snapshot:3	Epoch:12	Loss:3.722	translation_Loss:1.188	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.534                                                   	MRR:30.36	Hits@10:48.1	Best:30.36
2024-12-27 20:23:07,174: Snapshot:3	Epoch:13	Loss:3.559	translation_Loss:1.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.495                                                   	MRR:30.26	Hits@10:48.16	Best:30.36
2024-12-27 20:23:11,100: Snapshot:3	Epoch:14	Loss:3.398	translation_Loss:0.944	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.454                                                   	MRR:30.38	Hits@10:48.19	Best:30.38
2024-12-27 20:23:15,018: Snapshot:3	Epoch:15	Loss:3.287	translation_Loss:0.883	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.404                                                   	MRR:30.59	Hits@10:48.32	Best:30.59
2024-12-27 20:23:18,838: Snapshot:3	Epoch:16	Loss:3.149	translation_Loss:0.803	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.346                                                   	MRR:30.59	Hits@10:48.27	Best:30.59
2024-12-27 20:23:22,746: Snapshot:3	Epoch:17	Loss:3.053	translation_Loss:0.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.293                                                   	MRR:30.69	Hits@10:48.24	Best:30.69
2024-12-27 20:23:26,690: Snapshot:3	Epoch:18	Loss:2.959	translation_Loss:0.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.245                                                   	MRR:30.87	Hits@10:48.46	Best:30.87
2024-12-27 20:23:30,559: Snapshot:3	Epoch:19	Loss:2.894	translation_Loss:0.694	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.2                                                   	MRR:30.82	Hits@10:48.08	Best:30.87
2024-12-27 20:23:34,485: Snapshot:3	Epoch:20	Loss:2.829	translation_Loss:0.672	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.157                                                   	MRR:30.89	Hits@10:48.4	Best:30.89
2024-12-27 20:23:38,406: Snapshot:3	Epoch:21	Loss:2.747	translation_Loss:0.631	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.116                                                   	MRR:30.77	Hits@10:48.22	Best:30.89
2024-12-27 20:23:42,230: Snapshot:3	Epoch:22	Loss:2.691	translation_Loss:0.618	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.073                                                   	MRR:30.81	Hits@10:48.17	Best:30.89
2024-12-27 20:23:46,116: Snapshot:3	Epoch:23	Loss:2.629	translation_Loss:0.596	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.034                                                   	MRR:30.94	Hits@10:48.05	Best:30.94
2024-12-27 20:23:50,034: Snapshot:3	Epoch:24	Loss:2.575	translation_Loss:0.574	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.0                                                   	MRR:30.67	Hits@10:48.25	Best:30.94
2024-12-27 20:23:53,864: Snapshot:3	Epoch:25	Loss:2.525	translation_Loss:0.568	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.957                                                   	MRR:30.69	Hits@10:48.09	Best:30.94
2024-12-27 20:23:57,704: Snapshot:3	Epoch:26	Loss:2.486	translation_Loss:0.555	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.931                                                   	MRR:30.69	Hits@10:48.28	Best:30.94
2024-12-27 20:24:01,528: Snapshot:3	Epoch:27	Loss:2.463	translation_Loss:0.562	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.901                                                   	MRR:30.77	Hits@10:47.84	Best:30.94
2024-12-27 20:24:05,353: Early Stopping! Snapshot: 3 Epoch: 28 Best Results: 30.94
2024-12-27 20:24:05,353: Start to training tokens! Snapshot: 3 Epoch: 28 Loss:2.41 MRR:30.76 Best Results: 30.94
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:24:05,354: Snapshot:3	Epoch:28	Loss:2.41	translation_Loss:0.536	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.874                                                   	MRR:30.76	Hits@10:47.85	Best:30.94
2024-12-27 20:24:09,091: Snapshot:3	Epoch:29	Loss:26.249	translation_Loss:25.333	multi_layer_Loss:0.916	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.76	Hits@10:47.85	Best:30.94
2024-12-27 20:24:12,855: End of token training: 3 Epoch: 30 Loss:25.527 MRR:30.76 Best Results: 30.94
2024-12-27 20:24:12,855: Snapshot:3	Epoch:30	Loss:25.527	translation_Loss:25.314	multi_layer_Loss:0.213	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.76	Hits@10:47.85	Best:30.94
2024-12-27 20:24:13,201: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_5000/3model_best.tar'
2024-12-27 20:24:28,260: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1883 | 0.0963 | 0.2353 | 0.2963 |  0.3622 |
|     1      | 0.1415 | 0.0669 | 0.1677 | 0.2166 |  0.2841 |
|     2      | 0.1766 | 0.0963 | 0.1944 | 0.247  |  0.3318 |
|     3      | 0.3096 | 0.215  | 0.3511 | 0.4081 |  0.4853 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:24:41,030: Snapshot:4	Epoch:0	Loss:20.304	translation_Loss:20.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:6.73	Hits@10:18.7	Best:6.73
2024-12-27 20:24:43,803: Snapshot:4	Epoch:1	Loss:14.336	translation_Loss:14.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.326                                                   	MRR:9.73	Hits@10:25.04	Best:9.73
2024-12-27 20:24:46,673: Snapshot:4	Epoch:2	Loss:10.527	translation_Loss:10.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.516                                                   	MRR:13.43	Hits@10:31.64	Best:13.43
2024-12-27 20:24:49,477: Snapshot:4	Epoch:3	Loss:7.931	translation_Loss:7.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.679                                                   	MRR:16.6	Hits@10:37.51	Best:16.6
2024-12-27 20:24:52,267: Snapshot:4	Epoch:4	Loss:6.129	translation_Loss:5.306	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.822                                                   	MRR:19.36	Hits@10:41.84	Best:19.36
2024-12-27 20:24:55,107: Snapshot:4	Epoch:5	Loss:4.824	translation_Loss:3.882	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.942                                                   	MRR:21.6	Hits@10:45.02	Best:21.6
2024-12-27 20:24:57,870: Snapshot:4	Epoch:6	Loss:3.893	translation_Loss:2.859	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.034                                                   	MRR:22.87	Hits@10:48.1	Best:22.87
2024-12-27 20:25:00,685: Snapshot:4	Epoch:7	Loss:3.209	translation_Loss:2.106	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.103                                                   	MRR:24.45	Hits@10:48.76	Best:24.45
2024-12-27 20:25:03,505: Snapshot:4	Epoch:8	Loss:2.601	translation_Loss:1.452	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.149                                                   	MRR:25.91	Hits@10:49.66	Best:25.91
2024-12-27 20:25:06,356: Snapshot:4	Epoch:9	Loss:2.199	translation_Loss:1.026	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.173                                                   	MRR:26.41	Hits@10:50.25	Best:26.41
2024-12-27 20:25:09,196: Snapshot:4	Epoch:10	Loss:1.966	translation_Loss:0.785	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.18                                                   	MRR:26.82	Hits@10:50.93	Best:26.82
2024-12-27 20:25:12,004: Snapshot:4	Epoch:11	Loss:1.809	translation_Loss:0.637	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.172                                                   	MRR:27.38	Hits@10:51.05	Best:27.38
2024-12-27 20:25:14,811: Snapshot:4	Epoch:12	Loss:1.709	translation_Loss:0.548	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.161                                                   	MRR:27.49	Hits@10:51.33	Best:27.49
2024-12-27 20:25:17,633: Snapshot:4	Epoch:13	Loss:1.622	translation_Loss:0.472	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.15                                                   	MRR:27.68	Hits@10:51.64	Best:27.68
2024-12-27 20:25:20,426: Snapshot:4	Epoch:14	Loss:1.556	translation_Loss:0.42	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.136                                                   	MRR:27.81	Hits@10:51.24	Best:27.81
2024-12-27 20:25:23,264: Snapshot:4	Epoch:15	Loss:1.501	translation_Loss:0.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.12                                                   	MRR:27.95	Hits@10:51.88	Best:27.95
2024-12-27 20:25:26,048: Snapshot:4	Epoch:16	Loss:1.442	translation_Loss:0.34	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.102                                                   	MRR:28.1	Hits@10:52.21	Best:28.1
2024-12-27 20:25:28,822: Snapshot:4	Epoch:17	Loss:1.398	translation_Loss:0.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.081                                                   	MRR:28.33	Hits@10:52.82	Best:28.33
2024-12-27 20:25:31,619: Snapshot:4	Epoch:18	Loss:1.341	translation_Loss:0.283	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.059                                                   	MRR:28.59	Hits@10:52.19	Best:28.59
2024-12-27 20:25:34,368: Snapshot:4	Epoch:19	Loss:1.313	translation_Loss:0.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.037                                                   	MRR:28.49	Hits@10:52.56	Best:28.59
2024-12-27 20:25:37,108: Snapshot:4	Epoch:20	Loss:1.295	translation_Loss:0.281	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.014                                                   	MRR:28.4	Hits@10:51.98	Best:28.59
2024-12-27 20:25:39,856: Snapshot:4	Epoch:21	Loss:1.266	translation_Loss:0.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.998                                                   	MRR:28.62	Hits@10:52.27	Best:28.62
2024-12-27 20:25:42,651: Snapshot:4	Epoch:22	Loss:1.233	translation_Loss:0.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.98                                                   	MRR:28.76	Hits@10:52.66	Best:28.76
2024-12-27 20:25:45,476: Snapshot:4	Epoch:23	Loss:1.202	translation_Loss:0.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.963                                                   	MRR:28.89	Hits@10:52.96	Best:28.89
2024-12-27 20:25:48,274: Snapshot:4	Epoch:24	Loss:1.177	translation_Loss:0.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.942                                                   	MRR:29.0	Hits@10:53.6	Best:29.0
2024-12-27 20:25:51,029: Snapshot:4	Epoch:25	Loss:1.155	translation_Loss:0.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.924                                                   	MRR:28.82	Hits@10:52.65	Best:29.0
2024-12-27 20:25:53,767: Snapshot:4	Epoch:26	Loss:1.127	translation_Loss:0.221	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.906                                                   	MRR:28.83	Hits@10:52.91	Best:29.0
2024-12-27 20:25:56,560: Snapshot:4	Epoch:27	Loss:1.107	translation_Loss:0.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.89                                                   	MRR:29.08	Hits@10:53.46	Best:29.08
2024-12-27 20:25:59,297: Snapshot:4	Epoch:28	Loss:1.091	translation_Loss:0.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.874                                                   	MRR:29.01	Hits@10:53.48	Best:29.08
2024-12-27 20:26:02,056: Snapshot:4	Epoch:29	Loss:1.071	translation_Loss:0.212	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.859                                                   	MRR:29.17	Hits@10:53.43	Best:29.17
2024-12-27 20:26:04,778: Snapshot:4	Epoch:30	Loss:1.048	translation_Loss:0.204	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.844                                                   	MRR:29.03	Hits@10:53.39	Best:29.17
2024-12-27 20:26:07,534: Snapshot:4	Epoch:31	Loss:1.028	translation_Loss:0.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.829                                                   	MRR:29.25	Hits@10:52.96	Best:29.25
2024-12-27 20:26:10,322: Snapshot:4	Epoch:32	Loss:1.013	translation_Loss:0.2	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.813                                                   	MRR:28.99	Hits@10:53.17	Best:29.25
2024-12-27 20:26:13,023: Snapshot:4	Epoch:33	Loss:0.999	translation_Loss:0.196	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.803                                                   	MRR:28.95	Hits@10:53.25	Best:29.25
2024-12-27 20:26:15,758: Snapshot:4	Epoch:34	Loss:0.971	translation_Loss:0.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.79                                                   	MRR:28.99	Hits@10:52.6	Best:29.25
2024-12-27 20:26:18,478: Snapshot:4	Epoch:35	Loss:0.971	translation_Loss:0.194	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.777                                                   	MRR:29.12	Hits@10:52.59	Best:29.25
2024-12-27 20:26:21,194: Early Stopping! Snapshot: 4 Epoch: 36 Best Results: 29.25
2024-12-27 20:26:21,194: Start to training tokens! Snapshot: 4 Epoch: 36 Loss:0.946 MRR:29.01 Best Results: 29.25
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:26:21,195: Snapshot:4	Epoch:36	Loss:0.946	translation_Loss:0.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.766                                                   	MRR:29.01	Hits@10:52.98	Best:29.25
2024-12-27 20:26:23,841: Snapshot:4	Epoch:37	Loss:15.257	translation_Loss:14.458	multi_layer_Loss:0.798	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:29.01	Hits@10:52.98	Best:29.25
2024-12-27 20:26:26,487: End of token training: 4 Epoch: 38 Loss:14.753 MRR:29.01 Best Results: 29.25
2024-12-27 20:26:26,487: Snapshot:4	Epoch:38	Loss:14.753	translation_Loss:14.406	multi_layer_Loss:0.347	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:29.01	Hits@10:52.98	Best:29.25
2024-12-27 20:26:26,836: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_5000/4model_best.tar'
2024-12-27 20:26:43,048: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1772 | 0.0913 | 0.2197 | 0.2759 |  0.3356 |
|     1      | 0.1375 | 0.0642 | 0.1622 | 0.2104 |  0.2785 |
|     2      | 0.1643 | 0.0897 | 0.1816 | 0.2282 |  0.3082 |
|     3      | 0.271  | 0.1871 | 0.3031 | 0.3444 |  0.4263 |
|     4      | 0.2884 | 0.1721 | 0.3218 | 0.4106 |  0.5345 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 20:26:43,050: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2765 | 0.1651 | 0.3422 | 0.4115 |  0.4821 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2302 | 0.1229 | 0.2877 | 0.3547 |  0.431  |
|     1      | 0.1762 | 0.0912 | 0.2089 | 0.2661 |  0.3399 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1921 | 0.0985 | 0.2396 | 0.3015 |  0.371  |
|     1      | 0.1483 | 0.0736 | 0.1762 | 0.2242 |  0.2917 |
|     2      | 0.2305 | 0.1396 | 0.2596 | 0.3204 |  0.413  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1883 | 0.0963 | 0.2353 | 0.2963 |  0.3622 |
|     1      | 0.1415 | 0.0669 | 0.1677 | 0.2166 |  0.2841 |
|     2      | 0.1766 | 0.0963 | 0.1944 | 0.247  |  0.3318 |
|     3      | 0.3096 | 0.215  | 0.3511 | 0.4081 |  0.4853 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1772 | 0.0913 | 0.2197 | 0.2759 |  0.3356 |
|     1      | 0.1375 | 0.0642 | 0.1622 | 0.2104 |  0.2785 |
|     2      | 0.1643 | 0.0897 | 0.1816 | 0.2282 |  0.3082 |
|     3      | 0.271  | 0.1871 | 0.3031 | 0.3444 |  0.4263 |
|     4      | 0.2884 | 0.1721 | 0.3218 | 0.4106 |  0.5345 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 20:26:43,051: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 407.1831376552582  |   0.277   |    0.165     |    0.342     |     0.482     |
|    1     | 202.18506956100464 |   0.204   |    0.107     |    0.249     |     0.387     |
|    2     | 168.31342101097107 |   0.186   |     0.1      |    0.222     |     0.353     |
|    3     | 131.35727429389954 |   0.183   |    0.099     |    0.216     |     0.343     |
|    4     | 116.72450256347656 |   0.179   |    0.098     |    0.209     |     0.335     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 20:26:43,051: Sum_Training_Time:1025.76340508461
2024-12-27 20:26:43,051: Every_Training_Time:[407.1831376552582, 202.18506956100464, 168.31342101097107, 131.35727429389954, 116.72450256347656]
2024-12-27 20:26:43,051: Forward transfer: 0.018500000000000003 Backward transfer: -0.0607
2024-12-27 20:27:20,365: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.0001, lifelong_name='double_tokened', log_path='./logs/20241227202646/RELATIONrelation_0.0001_512_10000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.0001_512_10000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.0001_512_10000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 20:27:36,451: Snapshot:0	Epoch:0	Loss:156.019	translation_Loss:156.019	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.96	Hits@10:16.66	Best:7.96
2024-12-27 20:27:48,048: Snapshot:0	Epoch:1	Loss:132.307	translation_Loss:132.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.71	Hits@10:22.31	Best:9.71
2024-12-27 20:27:59,711: Snapshot:0	Epoch:2	Loss:113.356	translation_Loss:113.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.55	Hits@10:26.79	Best:11.55
2024-12-27 20:28:11,346: Snapshot:0	Epoch:3	Loss:95.555	translation_Loss:95.555	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.14	Hits@10:32.99	Best:15.14
2024-12-27 20:28:23,081: Snapshot:0	Epoch:4	Loss:78.62	translation_Loss:78.62	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.21	Hits@10:37.87	Best:18.21
2024-12-27 20:28:34,740: Snapshot:0	Epoch:5	Loss:63.318	translation_Loss:63.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.41	Hits@10:40.95	Best:20.41
2024-12-27 20:28:46,389: Snapshot:0	Epoch:6	Loss:50.77	translation_Loss:50.77	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.07	Hits@10:43.02	Best:22.07
2024-12-27 20:28:58,570: Snapshot:0	Epoch:7	Loss:40.611	translation_Loss:40.611	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.28	Hits@10:44.35	Best:23.28
2024-12-27 20:29:10,319: Snapshot:0	Epoch:8	Loss:32.455	translation_Loss:32.455	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.27	Hits@10:45.38	Best:24.27
2024-12-27 20:29:21,925: Snapshot:0	Epoch:9	Loss:25.938	translation_Loss:25.938	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.96	Hits@10:46.11	Best:24.96
2024-12-27 20:29:33,564: Snapshot:0	Epoch:10	Loss:20.896	translation_Loss:20.896	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.56	Hits@10:46.57	Best:25.56
2024-12-27 20:29:45,260: Snapshot:0	Epoch:11	Loss:17.101	translation_Loss:17.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.03	Hits@10:47.06	Best:26.03
2024-12-27 20:29:56,939: Snapshot:0	Epoch:12	Loss:14.157	translation_Loss:14.157	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.44	Hits@10:47.43	Best:26.44
2024-12-27 20:30:08,816: Snapshot:0	Epoch:13	Loss:12.027	translation_Loss:12.027	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.66	Hits@10:47.58	Best:26.66
2024-12-27 20:30:20,540: Snapshot:0	Epoch:14	Loss:10.304	translation_Loss:10.304	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.88	Hits@10:47.79	Best:26.88
2024-12-27 20:30:32,219: Snapshot:0	Epoch:15	Loss:9.057	translation_Loss:9.057	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.1	Hits@10:48.02	Best:27.1
2024-12-27 20:30:43,921: Snapshot:0	Epoch:16	Loss:8.04	translation_Loss:8.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.26	Hits@10:48.05	Best:27.26
2024-12-27 20:30:55,644: Snapshot:0	Epoch:17	Loss:7.155	translation_Loss:7.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.28	Hits@10:48.11	Best:27.28
2024-12-27 20:31:07,266: Snapshot:0	Epoch:18	Loss:6.547	translation_Loss:6.547	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.32	Hits@10:48.17	Best:27.32
2024-12-27 20:31:19,382: Snapshot:0	Epoch:19	Loss:5.977	translation_Loss:5.977	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.35	Hits@10:48.22	Best:27.35
2024-12-27 20:31:31,166: Snapshot:0	Epoch:20	Loss:5.58	translation_Loss:5.58	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.37	Hits@10:48.1	Best:27.37
2024-12-27 20:31:42,791: Snapshot:0	Epoch:21	Loss:5.195	translation_Loss:5.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.37	Hits@10:48.1	Best:27.37
2024-12-27 20:31:54,450: Snapshot:0	Epoch:22	Loss:4.857	translation_Loss:4.857	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.41	Hits@10:47.97	Best:27.41
2024-12-27 20:32:06,043: Snapshot:0	Epoch:23	Loss:4.639	translation_Loss:4.639	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.39	Hits@10:47.95	Best:27.41
2024-12-27 20:32:17,659: Snapshot:0	Epoch:24	Loss:4.41	translation_Loss:4.41	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.34	Hits@10:48.1	Best:27.41
2024-12-27 20:32:29,285: Snapshot:0	Epoch:25	Loss:4.206	translation_Loss:4.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.41	Hits@10:48.0	Best:27.41
2024-12-27 20:32:40,896: Snapshot:0	Epoch:26	Loss:3.997	translation_Loss:3.997	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.47	Hits@10:47.84	Best:27.47
2024-12-27 20:32:52,493: Snapshot:0	Epoch:27	Loss:3.859	translation_Loss:3.859	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.42	Hits@10:47.88	Best:27.47
2024-12-27 20:33:04,080: Snapshot:0	Epoch:28	Loss:3.707	translation_Loss:3.707	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.39	Hits@10:47.85	Best:27.47
2024-12-27 20:33:15,690: Snapshot:0	Epoch:29	Loss:3.595	translation_Loss:3.595	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.37	Hits@10:47.82	Best:27.47
2024-12-27 20:33:27,374: Snapshot:0	Epoch:30	Loss:3.454	translation_Loss:3.454	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.3	Hits@10:47.66	Best:27.47
2024-12-27 20:33:38,962: Early Stopping! Snapshot: 0 Epoch: 31 Best Results: 27.47
2024-12-27 20:33:38,962: Start to training tokens! Snapshot: 0 Epoch: 31 Loss:3.359 MRR:27.14 Best Results: 27.47
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:33:38,962: Snapshot:0	Epoch:31	Loss:3.359	translation_Loss:3.359	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.14	Hits@10:47.74	Best:27.47
2024-12-27 20:33:51,931: Snapshot:0	Epoch:32	Loss:101.451	translation_Loss:100.171	multi_layer_Loss:1.28	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.14	Hits@10:47.74	Best:27.47
2024-12-27 20:34:03,907: End of token training: 0 Epoch: 33 Loss:100.257 MRR:27.14 Best Results: 27.47
2024-12-27 20:34:03,907: Snapshot:0	Epoch:33	Loss:100.257	translation_Loss:100.256	multi_layer_Loss:0.002	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.14	Hits@10:47.74	Best:27.47
2024-12-27 20:34:04,168: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_10000/0model_best.tar'
2024-12-27 20:34:09,471: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2765 | 0.1655 | 0.3421 | 0.4105 |  0.4814 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:34:46,652: Snapshot:1	Epoch:0	Loss:137.6	translation_Loss:135.689	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.91                                                   	MRR:5.35	Hits@10:13.59	Best:5.35
2024-12-27 20:34:57,916: Snapshot:1	Epoch:1	Loss:101.145	translation_Loss:96.018	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.126                                                   	MRR:9.88	Hits@10:22.24	Best:9.88
2024-12-27 20:35:09,265: Snapshot:1	Epoch:2	Loss:75.475	translation_Loss:67.877	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.598                                                   	MRR:13.0	Hits@10:27.49	Best:13.0
2024-12-27 20:35:20,567: Snapshot:1	Epoch:3	Loss:57.165	translation_Loss:48.074	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.091                                                   	MRR:14.8	Hits@10:30.02	Best:14.8
2024-12-27 20:35:31,921: Snapshot:1	Epoch:4	Loss:45.134	translation_Loss:35.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.915                                                   	MRR:15.55	Hits@10:31.33	Best:15.55
2024-12-27 20:35:43,172: Snapshot:1	Epoch:5	Loss:38.142	translation_Loss:27.858	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.285                                                   	MRR:15.84	Hits@10:31.64	Best:15.84
2024-12-27 20:35:54,399: Snapshot:1	Epoch:6	Loss:34.12	translation_Loss:23.751	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.369                                                   	MRR:15.78	Hits@10:31.8	Best:15.84
2024-12-27 20:36:05,597: Snapshot:1	Epoch:7	Loss:31.468	translation_Loss:21.127	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.341                                                   	MRR:15.87	Hits@10:31.57	Best:15.87
2024-12-27 20:36:16,907: Snapshot:1	Epoch:8	Loss:29.776	translation_Loss:19.547	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.229                                                   	MRR:16.02	Hits@10:31.61	Best:16.02
2024-12-27 20:36:28,272: Snapshot:1	Epoch:9	Loss:28.603	translation_Loss:18.492	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.111                                                   	MRR:16.05	Hits@10:31.59	Best:16.05
2024-12-27 20:36:39,440: Snapshot:1	Epoch:10	Loss:27.718	translation_Loss:17.721	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.997                                                   	MRR:15.83	Hits@10:31.43	Best:16.05
2024-12-27 20:36:50,602: Snapshot:1	Epoch:11	Loss:27.196	translation_Loss:17.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.89                                                   	MRR:15.84	Hits@10:31.51	Best:16.05
2024-12-27 20:37:01,808: Snapshot:1	Epoch:12	Loss:26.671	translation_Loss:16.887	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.784                                                   	MRR:16.0	Hits@10:31.41	Best:16.05
2024-12-27 20:37:12,976: Snapshot:1	Epoch:13	Loss:26.287	translation_Loss:16.575	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.712                                                   	MRR:15.83	Hits@10:31.42	Best:16.05
2024-12-27 20:37:24,190: Early Stopping! Snapshot: 1 Epoch: 14 Best Results: 16.05
2024-12-27 20:37:24,190: Start to training tokens! Snapshot: 1 Epoch: 14 Loss:25.946 MRR:15.81 Best Results: 16.05
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:37:24,191: Snapshot:1	Epoch:14	Loss:25.946	translation_Loss:16.311	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.635                                                   	MRR:15.81	Hits@10:31.29	Best:16.05
2024-12-27 20:37:35,006: Snapshot:1	Epoch:15	Loss:119.33	translation_Loss:118.049	multi_layer_Loss:1.28	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.81	Hits@10:31.29	Best:16.05
2024-12-27 20:37:46,381: End of token training: 1 Epoch: 16 Loss:118.058 MRR:15.81 Best Results: 16.05
2024-12-27 20:37:46,381: Snapshot:1	Epoch:16	Loss:118.058	translation_Loss:118.056	multi_layer_Loss:0.002	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:15.81	Hits@10:31.29	Best:16.05
2024-12-27 20:37:46,668: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_10000/1model_best.tar'
2024-12-27 20:37:56,555: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2454 | 0.135  | 0.3079 | 0.376  |  0.4499 |
|     1      | 0.1612 | 0.0811 | 0.1914 | 0.246  |  0.315  |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:38:25,120: Snapshot:2	Epoch:0	Loss:87.775	translation_Loss:86.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.664                                                   	MRR:5.57	Hits@10:12.9	Best:5.57
2024-12-27 20:38:33,576: Snapshot:2	Epoch:1	Loss:47.434	translation_Loss:42.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.341                                                   	MRR:15.64	Hits@10:31.59	Best:15.64
2024-12-27 20:38:42,050: Snapshot:2	Epoch:2	Loss:33.298	translation_Loss:26.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.229                                                   	MRR:19.42	Hits@10:36.6	Best:19.42
2024-12-27 20:38:50,415: Snapshot:2	Epoch:3	Loss:26.915	translation_Loss:18.99	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.926                                                   	MRR:21.1	Hits@10:38.49	Best:21.1
2024-12-27 20:38:58,862: Snapshot:2	Epoch:4	Loss:23.008	translation_Loss:14.936	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.072                                                   	MRR:21.82	Hits@10:39.76	Best:21.82
2024-12-27 20:39:07,173: Snapshot:2	Epoch:5	Loss:20.287	translation_Loss:12.386	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.901                                                   	MRR:21.98	Hits@10:40.11	Best:21.98
2024-12-27 20:39:15,518: Snapshot:2	Epoch:6	Loss:18.295	translation_Loss:10.684	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.611                                                   	MRR:22.02	Hits@10:40.41	Best:22.02
2024-12-27 20:39:23,877: Snapshot:2	Epoch:7	Loss:16.775	translation_Loss:9.505	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.27                                                   	MRR:22.27	Hits@10:40.06	Best:22.27
2024-12-27 20:39:32,186: Snapshot:2	Epoch:8	Loss:15.553	translation_Loss:8.637	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.916                                                   	MRR:22.46	Hits@10:39.92	Best:22.46
2024-12-27 20:39:40,447: Snapshot:2	Epoch:9	Loss:14.61	translation_Loss:7.994	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.616                                                   	MRR:22.16	Hits@10:39.59	Best:22.46
2024-12-27 20:39:48,843: Snapshot:2	Epoch:10	Loss:13.838	translation_Loss:7.504	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.334                                                   	MRR:22.01	Hits@10:39.19	Best:22.46
2024-12-27 20:39:57,220: Snapshot:2	Epoch:11	Loss:13.25	translation_Loss:7.145	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.105                                                   	MRR:22.01	Hits@10:39.12	Best:22.46
2024-12-27 20:40:06,015: Snapshot:2	Epoch:12	Loss:12.789	translation_Loss:6.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.926                                                   	MRR:21.98	Hits@10:39.01	Best:22.46
2024-12-27 20:40:14,374: Early Stopping! Snapshot: 2 Epoch: 13 Best Results: 22.46
2024-12-27 20:40:14,375: Start to training tokens! Snapshot: 2 Epoch: 13 Loss:12.384 MRR:21.81 Best Results: 22.46
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:40:14,375: Snapshot:2	Epoch:13	Loss:12.384	translation_Loss:6.611	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.773                                                   	MRR:21.81	Hits@10:38.9	Best:22.46
2024-12-27 20:40:22,363: Snapshot:2	Epoch:14	Loss:83.675	translation_Loss:82.358	multi_layer_Loss:1.318	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.81	Hits@10:38.9	Best:22.46
2024-12-27 20:40:30,400: End of token training: 2 Epoch: 15 Loss:82.216 MRR:21.81 Best Results: 22.46
2024-12-27 20:40:30,401: Snapshot:2	Epoch:15	Loss:82.216	translation_Loss:82.19	multi_layer_Loss:0.026	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:21.81	Hits@10:38.9	Best:22.46
2024-12-27 20:40:30,691: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_10000/2model_best.tar'
2024-12-27 20:40:43,775: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2048 | 0.1065 | 0.259  | 0.3204 |  0.3906 |
|     1      | 0.1391 | 0.0659 | 0.1651 | 0.2141 |  0.2777 |
|     2      | 0.222  | 0.1347 | 0.249  | 0.3084 |  0.3942 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:40:59,335: Snapshot:3	Epoch:0	Loss:39.73	translation_Loss:39.445	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.286                                                   	MRR:4.3	Hits@10:9.17	Best:4.3
2024-12-27 20:41:03,216: Snapshot:3	Epoch:1	Loss:30.257	translation_Loss:29.468	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.789                                                   	MRR:9.57	Hits@10:20.26	Best:9.57
2024-12-27 20:41:07,107: Snapshot:3	Epoch:2	Loss:23.592	translation_Loss:22.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.397                                                   	MRR:15.53	Hits@10:33.06	Best:15.53
2024-12-27 20:41:11,054: Snapshot:3	Epoch:3	Loss:18.509	translation_Loss:16.492	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.017                                                   	MRR:19.93	Hits@10:38.44	Best:19.93
2024-12-27 20:41:14,975: Snapshot:3	Epoch:4	Loss:14.8	translation_Loss:12.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.549                                                   	MRR:22.61	Hits@10:42.01	Best:22.61
2024-12-27 20:41:18,887: Snapshot:3	Epoch:5	Loss:12.046	translation_Loss:9.091	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.955                                                   	MRR:24.49	Hits@10:43.85	Best:24.49
2024-12-27 20:41:22,820: Snapshot:3	Epoch:6	Loss:10.121	translation_Loss:6.89	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.231                                                   	MRR:26.24	Hits@10:45.06	Best:26.24
2024-12-27 20:41:26,765: Snapshot:3	Epoch:7	Loss:8.755	translation_Loss:5.363	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.392                                                   	MRR:27.38	Hits@10:45.76	Best:27.38
2024-12-27 20:41:30,669: Snapshot:3	Epoch:8	Loss:7.785	translation_Loss:4.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.478                                                   	MRR:28.07	Hits@10:46.05	Best:28.07
2024-12-27 20:41:34,622: Snapshot:3	Epoch:9	Loss:7.13	translation_Loss:3.633	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.497                                                   	MRR:28.51	Hits@10:46.48	Best:28.51
2024-12-27 20:41:38,549: Snapshot:3	Epoch:10	Loss:6.644	translation_Loss:3.143	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.5                                                   	MRR:28.81	Hits@10:46.54	Best:28.81
2024-12-27 20:41:42,468: Snapshot:3	Epoch:11	Loss:6.226	translation_Loss:2.748	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.478                                                   	MRR:29.12	Hits@10:46.7	Best:29.12
2024-12-27 20:41:46,823: Snapshot:3	Epoch:12	Loss:5.892	translation_Loss:2.463	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.429                                                   	MRR:29.14	Hits@10:47.05	Best:29.14
2024-12-27 20:41:50,765: Snapshot:3	Epoch:13	Loss:5.621	translation_Loss:2.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.379                                                   	MRR:29.24	Hits@10:46.9	Best:29.24
2024-12-27 20:41:54,809: Snapshot:3	Epoch:14	Loss:5.367	translation_Loss:2.045	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.322                                                   	MRR:29.36	Hits@10:46.87	Best:29.36
2024-12-27 20:41:58,705: Snapshot:3	Epoch:15	Loss:5.185	translation_Loss:1.925	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.26                                                   	MRR:29.52	Hits@10:46.83	Best:29.52
2024-12-27 20:42:02,574: Snapshot:3	Epoch:16	Loss:5.01	translation_Loss:1.814	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.196                                                   	MRR:29.57	Hits@10:46.68	Best:29.57
2024-12-27 20:42:06,475: Snapshot:3	Epoch:17	Loss:4.842	translation_Loss:1.699	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.143                                                   	MRR:29.56	Hits@10:47.0	Best:29.57
2024-12-27 20:42:10,331: Snapshot:3	Epoch:18	Loss:4.701	translation_Loss:1.623	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.077                                                   	MRR:29.51	Hits@10:46.86	Best:29.57
2024-12-27 20:42:14,208: Snapshot:3	Epoch:19	Loss:4.567	translation_Loss:1.541	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.026                                                   	MRR:29.75	Hits@10:46.93	Best:29.75
2024-12-27 20:42:18,084: Snapshot:3	Epoch:20	Loss:4.46	translation_Loss:1.492	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.968                                                   	MRR:29.78	Hits@10:46.9	Best:29.78
2024-12-27 20:42:21,983: Snapshot:3	Epoch:21	Loss:4.35	translation_Loss:1.426	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.923                                                   	MRR:29.54	Hits@10:46.94	Best:29.78
2024-12-27 20:42:25,831: Snapshot:3	Epoch:22	Loss:4.274	translation_Loss:1.398	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.876                                                   	MRR:29.57	Hits@10:46.73	Best:29.78
2024-12-27 20:42:29,718: Snapshot:3	Epoch:23	Loss:4.194	translation_Loss:1.362	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.831                                                   	MRR:29.7	Hits@10:46.77	Best:29.78
2024-12-27 20:42:33,533: Snapshot:3	Epoch:24	Loss:4.098	translation_Loss:1.314	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.783                                                   	MRR:29.78	Hits@10:46.58	Best:29.78
2024-12-27 20:42:37,502: Snapshot:3	Epoch:25	Loss:4.037	translation_Loss:1.29	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.747                                                   	MRR:29.93	Hits@10:46.52	Best:29.93
2024-12-27 20:42:41,382: Snapshot:3	Epoch:26	Loss:3.974	translation_Loss:1.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.706                                                   	MRR:29.62	Hits@10:46.6	Best:29.93
2024-12-27 20:42:45,243: Snapshot:3	Epoch:27	Loss:3.897	translation_Loss:1.233	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.665                                                   	MRR:29.51	Hits@10:46.25	Best:29.93
2024-12-27 20:42:49,049: Snapshot:3	Epoch:28	Loss:3.864	translation_Loss:1.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.633                                                   	MRR:29.51	Hits@10:46.45	Best:29.93
2024-12-27 20:42:52,881: Snapshot:3	Epoch:29	Loss:3.776	translation_Loss:1.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.594                                                   	MRR:29.65	Hits@10:46.4	Best:29.93
2024-12-27 20:42:56,728: Early Stopping! Snapshot: 3 Epoch: 30 Best Results: 29.93
2024-12-27 20:42:56,728: Start to training tokens! Snapshot: 3 Epoch: 30 Loss:3.739 MRR:29.63 Best Results: 29.93
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:42:56,728: Snapshot:3	Epoch:30	Loss:3.739	translation_Loss:1.176	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.563                                                   	MRR:29.63	Hits@10:46.58	Best:29.93
2024-12-27 20:43:00,449: Snapshot:3	Epoch:31	Loss:29.757	translation_Loss:28.841	multi_layer_Loss:0.916	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:29.63	Hits@10:46.58	Best:29.93
2024-12-27 20:43:04,189: End of token training: 3 Epoch: 32 Loss:29.087 MRR:29.63 Best Results: 29.93
2024-12-27 20:43:04,190: Snapshot:3	Epoch:32	Loss:29.087	translation_Loss:28.874	multi_layer_Loss:0.213	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:29.63	Hits@10:46.58	Best:29.93
2024-12-27 20:43:04,537: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_10000/3model_best.tar'
2024-12-27 20:43:19,539: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2018 | 0.1053 | 0.2545 | 0.3165 |  0.3815 |
|     1      | 0.1352 | 0.0624 | 0.1604 | 0.2095 |  0.2753 |
|     2      | 0.1753 | 0.0957 | 0.1933 | 0.2479 |  0.3316 |
|     3      | 0.2994 | 0.2054 | 0.3403 | 0.3971 |  0.4715 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:43:32,588: Snapshot:4	Epoch:0	Loss:21.926	translation_Loss:21.746	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.18                                                   	MRR:6.23	Hits@10:16.97	Best:6.23
2024-12-27 20:43:35,439: Snapshot:4	Epoch:1	Loss:15.991	translation_Loss:15.507	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.484                                                   	MRR:9.13	Hits@10:23.73	Best:9.13
2024-12-27 20:43:38,310: Snapshot:4	Epoch:2	Loss:12.152	translation_Loss:11.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.774                                                   	MRR:12.37	Hits@10:29.64	Best:12.37
2024-12-27 20:43:41,135: Snapshot:4	Epoch:3	Loss:9.566	translation_Loss:8.521	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.045                                                   	MRR:15.47	Hits@10:34.88	Best:15.47
2024-12-27 20:43:43,927: Snapshot:4	Epoch:4	Loss:7.755	translation_Loss:6.466	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.289                                                   	MRR:18.24	Hits@10:40.06	Best:18.24
2024-12-27 20:43:46,820: Snapshot:4	Epoch:5	Loss:6.446	translation_Loss:4.953	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.493                                                   	MRR:20.47	Hits@10:43.15	Best:20.47
2024-12-27 20:43:49,629: Snapshot:4	Epoch:6	Loss:5.437	translation_Loss:3.788	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.649                                                   	MRR:21.97	Hits@10:45.57	Best:21.97
2024-12-27 20:43:52,470: Snapshot:4	Epoch:7	Loss:4.7	translation_Loss:2.943	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.757                                                   	MRR:23.54	Hits@10:47.22	Best:23.54
2024-12-27 20:43:55,285: Snapshot:4	Epoch:8	Loss:4.008	translation_Loss:2.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.827                                                   	MRR:25.14	Hits@10:48.41	Best:25.14
2024-12-27 20:43:58,105: Snapshot:4	Epoch:9	Loss:3.551	translation_Loss:1.685	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.866                                                   	MRR:26.04	Hits@10:48.93	Best:26.04
2024-12-27 20:44:00,865: Snapshot:4	Epoch:10	Loss:3.243	translation_Loss:1.366	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.877                                                   	MRR:26.58	Hits@10:49.68	Best:26.58
2024-12-27 20:44:03,608: Snapshot:4	Epoch:11	Loss:3.01	translation_Loss:1.137	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.873                                                   	MRR:26.85	Hits@10:49.54	Best:26.85
2024-12-27 20:44:06,413: Snapshot:4	Epoch:12	Loss:2.853	translation_Loss:0.998	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.855                                                   	MRR:26.8	Hits@10:50.2	Best:26.85
2024-12-27 20:44:09,201: Snapshot:4	Epoch:13	Loss:2.716	translation_Loss:0.889	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.827                                                   	MRR:27.26	Hits@10:50.31	Best:27.26
2024-12-27 20:44:11,993: Snapshot:4	Epoch:14	Loss:2.599	translation_Loss:0.799	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.8                                                   	MRR:27.35	Hits@10:50.94	Best:27.35
2024-12-27 20:44:14,792: Snapshot:4	Epoch:15	Loss:2.493	translation_Loss:0.727	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.766                                                   	MRR:27.43	Hits@10:51.18	Best:27.43
2024-12-27 20:44:17,600: Snapshot:4	Epoch:16	Loss:2.406	translation_Loss:0.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.728                                                   	MRR:27.83	Hits@10:51.17	Best:27.83
2024-12-27 20:44:20,337: Snapshot:4	Epoch:17	Loss:2.328	translation_Loss:0.637	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.691                                                   	MRR:27.76	Hits@10:50.87	Best:27.83
2024-12-27 20:44:23,083: Snapshot:4	Epoch:18	Loss:2.252	translation_Loss:0.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.655                                                   	MRR:27.97	Hits@10:51.2	Best:27.97
2024-12-27 20:44:25,904: Snapshot:4	Epoch:19	Loss:2.187	translation_Loss:0.57	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.617                                                   	MRR:28.17	Hits@10:51.59	Best:28.17
2024-12-27 20:44:28,647: Snapshot:4	Epoch:20	Loss:2.113	translation_Loss:0.534	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.579                                                   	MRR:28.04	Hits@10:51.91	Best:28.17
2024-12-27 20:44:31,377: Snapshot:4	Epoch:21	Loss:2.064	translation_Loss:0.522	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.542                                                   	MRR:28.12	Hits@10:51.94	Best:28.17
2024-12-27 20:44:34,083: Snapshot:4	Epoch:22	Loss:2.02	translation_Loss:0.511	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.509                                                   	MRR:28.14	Hits@10:52.19	Best:28.17
2024-12-27 20:44:36,787: Snapshot:4	Epoch:23	Loss:1.957	translation_Loss:0.481	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.476                                                   	MRR:28.01	Hits@10:52.23	Best:28.17
2024-12-27 20:44:39,487: Early Stopping! Snapshot: 4 Epoch: 24 Best Results: 28.17
2024-12-27 20:44:39,487: Start to training tokens! Snapshot: 4 Epoch: 24 Loss:1.889 MRR:27.91 Best Results: 28.17
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:44:39,488: Snapshot:4	Epoch:24	Loss:1.889	translation_Loss:0.45	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.439                                                   	MRR:27.91	Hits@10:52.23	Best:28.17
2024-12-27 20:44:42,124: Snapshot:4	Epoch:25	Loss:16.156	translation_Loss:15.358	multi_layer_Loss:0.798	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.91	Hits@10:52.23	Best:28.17
2024-12-27 20:44:44,747: End of token training: 4 Epoch: 26 Loss:15.735 MRR:27.91 Best Results: 28.17
2024-12-27 20:44:44,747: Snapshot:4	Epoch:26	Loss:15.735	translation_Loss:15.388	multi_layer_Loss:0.347	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.91	Hits@10:52.23	Best:28.17
2024-12-27 20:44:45,097: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_512_10000/4model_best.tar'
2024-12-27 20:45:01,676: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1885 | 0.0977 | 0.2367 | 0.2946 |  0.3547 |
|     1      | 0.1324 | 0.0607 | 0.1563 | 0.2046 |  0.2708 |
|     2      | 0.1623 | 0.0891 | 0.1778 | 0.2277 |  0.3062 |
|     3      | 0.2603 | 0.1784 | 0.2902 | 0.3334 |  0.408  |
|     4      | 0.2756 | 0.1584 | 0.3116 | 0.3995 |  0.5179 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 20:45:01,678: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2765 | 0.1655 | 0.3421 | 0.4105 |  0.4814 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2454 | 0.135  | 0.3079 | 0.376  |  0.4499 |
|     1      | 0.1612 | 0.0811 | 0.1914 | 0.246  |  0.315  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2048 | 0.1065 | 0.259  | 0.3204 |  0.3906 |
|     1      | 0.1391 | 0.0659 | 0.1651 | 0.2141 |  0.2777 |
|     2      | 0.222  | 0.1347 | 0.249  | 0.3084 |  0.3942 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2018 | 0.1053 | 0.2545 | 0.3165 |  0.3815 |
|     1      | 0.1352 | 0.0624 | 0.1604 | 0.2095 |  0.2753 |
|     2      | 0.1753 | 0.0957 | 0.1933 | 0.2479 |  0.3316 |
|     3      | 0.2994 | 0.2054 | 0.3403 | 0.3971 |  0.4715 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1885 | 0.0977 | 0.2367 | 0.2946 |  0.3547 |
|     1      | 0.1324 | 0.0607 | 0.1563 | 0.2046 |  0.2708 |
|     2      | 0.1623 | 0.0891 | 0.1778 | 0.2277 |  0.3062 |
|     3      | 0.2603 | 0.1784 | 0.2902 | 0.3334 |  0.408  |
|     4      | 0.2756 | 0.1584 | 0.3116 | 0.3995 |  0.5179 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 20:45:01,679: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 403.5416922569275  |   0.277   |    0.166     |    0.342     |     0.481     |
|    1     | 212.5788345336914  |   0.204   |    0.109     |    0.251     |     0.384     |
|    2     | 149.99858212471008 |   0.185   |    0.099     |    0.222     |     0.351     |
|    3     | 138.4834909439087  |   0.184   |     0.1      |    0.219     |     0.345     |
|    4     | 83.43538546562195  |   0.179   |    0.097     |     0.21     |     0.336     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 20:45:01,679: Sum_Training_Time:988.0379853248596
2024-12-27 20:45:01,679: Every_Training_Time:[403.5416922569275, 212.5788345336914, 149.99858212471008, 138.4834909439087, 83.43538546562195]
2024-12-27 20:45:01,679: Forward transfer: 0.018 Backward transfer: -0.05390000000000002
2024-12-27 20:45:40,643: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.0001, lifelong_name='double_tokened', log_path='./logs/20241227204506/RELATIONrelation_0.0001_1024_1000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.0001_1024_1000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.0001_1024_1000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 20:45:56,502: Snapshot:0	Epoch:0	Loss:79.901	translation_Loss:79.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.65	Hits@10:9.44	Best:4.65
2024-12-27 20:46:07,940: Snapshot:0	Epoch:1	Loss:71.045	translation_Loss:71.045	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.6	Hits@10:18.87	Best:8.6
2024-12-27 20:46:19,518: Snapshot:0	Epoch:2	Loss:63.624	translation_Loss:63.624	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.67	Hits@10:22.36	Best:9.67
2024-12-27 20:46:31,081: Snapshot:0	Epoch:3	Loss:56.95	translation_Loss:56.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.75	Hits@10:25.62	Best:10.75
2024-12-27 20:46:42,555: Snapshot:0	Epoch:4	Loss:50.574	translation_Loss:50.574	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.68	Hits@10:29.79	Best:12.68
2024-12-27 20:46:54,120: Snapshot:0	Epoch:5	Loss:44.362	translation_Loss:44.362	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.16	Hits@10:34.33	Best:15.16
2024-12-27 20:47:06,126: Snapshot:0	Epoch:6	Loss:38.303	translation_Loss:38.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.44	Hits@10:37.68	Best:17.44
2024-12-27 20:47:17,683: Snapshot:0	Epoch:7	Loss:32.599	translation_Loss:32.599	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.34	Hits@10:40.09	Best:19.34
2024-12-27 20:47:29,308: Snapshot:0	Epoch:8	Loss:27.616	translation_Loss:27.616	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.78	Hits@10:41.83	Best:20.78
2024-12-27 20:47:40,703: Snapshot:0	Epoch:9	Loss:23.298	translation_Loss:23.298	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.96	Hits@10:43.24	Best:21.96
2024-12-27 20:47:52,291: Snapshot:0	Epoch:10	Loss:19.669	translation_Loss:19.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.87	Hits@10:44.17	Best:22.87
2024-12-27 20:48:03,830: Snapshot:0	Epoch:11	Loss:16.592	translation_Loss:16.592	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.73	Hits@10:45.1	Best:23.73
2024-12-27 20:48:15,884: Snapshot:0	Epoch:12	Loss:13.989	translation_Loss:13.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.33	Hits@10:45.8	Best:24.33
2024-12-27 20:48:27,334: Snapshot:0	Epoch:13	Loss:11.892	translation_Loss:11.892	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.89	Hits@10:46.17	Best:24.89
2024-12-27 20:48:38,804: Snapshot:0	Epoch:14	Loss:10.107	translation_Loss:10.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.33	Hits@10:46.58	Best:25.33
2024-12-27 20:48:50,299: Snapshot:0	Epoch:15	Loss:8.72	translation_Loss:8.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.77	Hits@10:46.93	Best:25.77
2024-12-27 20:49:01,871: Snapshot:0	Epoch:16	Loss:7.515	translation_Loss:7.515	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.15	Hits@10:47.25	Best:26.15
2024-12-27 20:49:13,336: Snapshot:0	Epoch:17	Loss:6.527	translation_Loss:6.527	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.36	Hits@10:47.5	Best:26.36
2024-12-27 20:49:24,970: Snapshot:0	Epoch:18	Loss:5.779	translation_Loss:5.779	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.6	Hits@10:47.66	Best:26.6
2024-12-27 20:49:36,367: Snapshot:0	Epoch:19	Loss:5.138	translation_Loss:5.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.65	Hits@10:47.96	Best:26.65
2024-12-27 20:49:47,792: Snapshot:0	Epoch:20	Loss:4.63	translation_Loss:4.63	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.85	Hits@10:48.0	Best:26.85
2024-12-27 20:49:59,383: Snapshot:0	Epoch:21	Loss:4.18	translation_Loss:4.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.89	Hits@10:47.95	Best:26.89
2024-12-27 20:50:10,956: Snapshot:0	Epoch:22	Loss:3.824	translation_Loss:3.824	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.94	Hits@10:47.94	Best:26.94
2024-12-27 20:50:22,457: Snapshot:0	Epoch:23	Loss:3.546	translation_Loss:3.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.06	Hits@10:48.06	Best:27.06
2024-12-27 20:50:33,863: Snapshot:0	Epoch:24	Loss:3.276	translation_Loss:3.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.19	Hits@10:48.16	Best:27.19
2024-12-27 20:50:45,823: Snapshot:0	Epoch:25	Loss:3.062	translation_Loss:3.062	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.24	Hits@10:48.2	Best:27.24
2024-12-27 20:50:57,334: Snapshot:0	Epoch:26	Loss:2.852	translation_Loss:2.852	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.3	Hits@10:48.23	Best:27.3
2024-12-27 20:51:08,863: Snapshot:0	Epoch:27	Loss:2.701	translation_Loss:2.701	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.33	Hits@10:48.33	Best:27.33
2024-12-27 20:51:20,379: Snapshot:0	Epoch:28	Loss:2.545	translation_Loss:2.545	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.36	Hits@10:48.21	Best:27.36
2024-12-27 20:51:31,932: Snapshot:0	Epoch:29	Loss:2.428	translation_Loss:2.428	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.37	Hits@10:48.34	Best:27.37
2024-12-27 20:51:43,338: Snapshot:0	Epoch:30	Loss:2.297	translation_Loss:2.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.4	Hits@10:48.21	Best:27.4
2024-12-27 20:51:55,229: Snapshot:0	Epoch:31	Loss:2.211	translation_Loss:2.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.34	Hits@10:48.24	Best:27.4
2024-12-27 20:52:06,689: Snapshot:0	Epoch:32	Loss:2.115	translation_Loss:2.115	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.51	Hits@10:48.23	Best:27.51
2024-12-27 20:52:18,117: Snapshot:0	Epoch:33	Loss:2.049	translation_Loss:2.049	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.43	Hits@10:48.23	Best:27.51
2024-12-27 20:52:29,514: Snapshot:0	Epoch:34	Loss:1.944	translation_Loss:1.944	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.38	Hits@10:48.22	Best:27.51
2024-12-27 20:52:40,859: Snapshot:0	Epoch:35	Loss:1.89	translation_Loss:1.89	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.36	Hits@10:48.25	Best:27.51
2024-12-27 20:52:52,367: Snapshot:0	Epoch:36	Loss:1.843	translation_Loss:1.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.43	Hits@10:48.09	Best:27.51
2024-12-27 20:53:03,854: Early Stopping! Snapshot: 0 Epoch: 37 Best Results: 27.51
2024-12-27 20:53:03,855: Start to training tokens! Snapshot: 0 Epoch: 37 Loss:1.764 MRR:27.4 Best Results: 27.51
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:53:03,855: Snapshot:0	Epoch:37	Loss:1.764	translation_Loss:1.764	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.4	Hits@10:48.13	Best:27.51
2024-12-27 20:53:16,018: Snapshot:0	Epoch:38	Loss:51.212	translation_Loss:50.017	multi_layer_Loss:1.195	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.4	Hits@10:48.13	Best:27.51
2024-12-27 20:53:27,705: End of token training: 0 Epoch: 39 Loss:50.158 MRR:27.4 Best Results: 27.51
2024-12-27 20:53:27,705: Snapshot:0	Epoch:39	Loss:50.158	translation_Loss:50.073	multi_layer_Loss:0.085	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.4	Hits@10:48.13	Best:27.51
2024-12-27 20:53:27,981: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_1000/0model_best.tar'
2024-12-27 20:53:33,200: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2766 | 0.1644 | 0.3425 | 0.4125 |  0.4843 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:54:09,256: Snapshot:1	Epoch:0	Loss:71.676	translation_Loss:71.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:3.33	Hits@10:9.29	Best:3.33
2024-12-27 20:54:20,185: Snapshot:1	Epoch:1	Loss:55.907	translation_Loss:55.463	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.444                                                   	MRR:6.95	Hits@10:17.68	Best:6.95
2024-12-27 20:54:30,925: Snapshot:1	Epoch:2	Loss:42.815	translation_Loss:41.878	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.937                                                   	MRR:10.16	Hits@10:23.46	Best:10.16
2024-12-27 20:54:41,679: Snapshot:1	Epoch:3	Loss:32.184	translation_Loss:30.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.509                                                   	MRR:12.74	Hits@10:28.4	Best:12.74
2024-12-27 20:54:52,441: Snapshot:1	Epoch:4	Loss:23.669	translation_Loss:21.577	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.093                                                   	MRR:15.04	Hits@10:31.57	Best:15.04
2024-12-27 20:55:03,215: Snapshot:1	Epoch:5	Loss:17.272	translation_Loss:14.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.62                                                   	MRR:16.86	Hits@10:33.62	Best:16.86
2024-12-27 20:55:14,520: Snapshot:1	Epoch:6	Loss:12.827	translation_Loss:9.793	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.034                                                   	MRR:17.86	Hits@10:35.03	Best:17.86
2024-12-27 20:55:25,456: Snapshot:1	Epoch:7	Loss:10.022	translation_Loss:6.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.303                                                   	MRR:18.39	Hits@10:35.79	Best:18.39
2024-12-27 20:55:36,189: Snapshot:1	Epoch:8	Loss:8.33	translation_Loss:4.89	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.44                                                   	MRR:18.77	Hits@10:36.39	Best:18.77
2024-12-27 20:55:46,919: Snapshot:1	Epoch:9	Loss:7.178	translation_Loss:3.693	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.486                                                   	MRR:19.08	Hits@10:36.75	Best:19.08
2024-12-27 20:55:57,649: Snapshot:1	Epoch:10	Loss:6.467	translation_Loss:2.992	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.475                                                   	MRR:19.46	Hits@10:37.05	Best:19.46
2024-12-27 20:56:08,407: Snapshot:1	Epoch:11	Loss:5.964	translation_Loss:2.524	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.44                                                   	MRR:19.64	Hits@10:37.27	Best:19.64
2024-12-27 20:56:19,283: Snapshot:1	Epoch:12	Loss:5.547	translation_Loss:2.159	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.388                                                   	MRR:19.83	Hits@10:37.39	Best:19.83
2024-12-27 20:56:30,226: Snapshot:1	Epoch:13	Loss:5.205	translation_Loss:1.879	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.327                                                   	MRR:19.58	Hits@10:37.5	Best:19.83
2024-12-27 20:56:40,924: Snapshot:1	Epoch:14	Loss:4.988	translation_Loss:1.725	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.263                                                   	MRR:19.83	Hits@10:37.73	Best:19.83
2024-12-27 20:56:51,794: Snapshot:1	Epoch:15	Loss:4.811	translation_Loss:1.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.201                                                   	MRR:19.9	Hits@10:37.66	Best:19.9
2024-12-27 20:57:03,110: Snapshot:1	Epoch:16	Loss:4.622	translation_Loss:1.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.142                                                   	MRR:19.95	Hits@10:37.81	Best:19.95
2024-12-27 20:57:13,967: Snapshot:1	Epoch:17	Loss:4.473	translation_Loss:1.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.081                                                   	MRR:19.85	Hits@10:37.75	Best:19.95
2024-12-27 20:57:24,728: Snapshot:1	Epoch:18	Loss:4.363	translation_Loss:1.342	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.021                                                   	MRR:19.85	Hits@10:37.66	Best:19.95
2024-12-27 20:57:35,482: Snapshot:1	Epoch:19	Loss:4.257	translation_Loss:1.29	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.967                                                   	MRR:19.99	Hits@10:37.89	Best:19.99
2024-12-27 20:57:46,324: Snapshot:1	Epoch:20	Loss:4.155	translation_Loss:1.239	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.916                                                   	MRR:19.92	Hits@10:37.85	Best:19.99
2024-12-27 20:57:57,115: Snapshot:1	Epoch:21	Loss:4.082	translation_Loss:1.209	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.873                                                   	MRR:19.95	Hits@10:37.83	Best:19.99
2024-12-27 20:58:07,826: Snapshot:1	Epoch:22	Loss:4.016	translation_Loss:1.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.834                                                   	MRR:19.86	Hits@10:37.73	Best:19.99
2024-12-27 20:58:18,526: Snapshot:1	Epoch:23	Loss:3.945	translation_Loss:1.149	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.796                                                   	MRR:19.86	Hits@10:37.94	Best:19.99
2024-12-27 20:58:29,711: Early Stopping! Snapshot: 1 Epoch: 24 Best Results: 19.99
2024-12-27 20:58:29,711: Start to training tokens! Snapshot: 1 Epoch: 24 Loss:3.887 MRR:19.92 Best Results: 19.99
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 20:58:29,711: Snapshot:1	Epoch:24	Loss:3.887	translation_Loss:1.124	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.763                                                   	MRR:19.92	Hits@10:37.78	Best:19.99
2024-12-27 20:58:40,256: Snapshot:1	Epoch:25	Loss:51.48	translation_Loss:50.296	multi_layer_Loss:1.185	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.92	Hits@10:37.78	Best:19.99
2024-12-27 20:58:50,896: End of token training: 1 Epoch: 26 Loss:50.441 MRR:19.92 Best Results: 19.99
2024-12-27 20:58:50,896: Snapshot:1	Epoch:26	Loss:50.441	translation_Loss:50.345	multi_layer_Loss:0.096	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.92	Hits@10:37.78	Best:19.99
2024-12-27 20:58:51,183: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_1000/1model_best.tar'
2024-12-27 20:59:01,154: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1944 | 0.0945 | 0.249  | 0.3097 |  0.3785 |
|     1      | 0.2023 | 0.1099 | 0.2402 | 0.3027 |  0.3771 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 20:59:28,592: Snapshot:2	Epoch:0	Loss:46.082	translation_Loss:46.004	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.078                                                   	MRR:1.71	Hits@10:4.13	Best:1.71
2024-12-27 20:59:36,549: Snapshot:2	Epoch:1	Loss:26.265	translation_Loss:25.928	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.337                                                   	MRR:9.86	Hits@10:23.7	Best:9.86
2024-12-27 20:59:44,577: Snapshot:2	Epoch:2	Loss:15.074	translation_Loss:14.443	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.631                                                   	MRR:15.2	Hits@10:32.34	Best:15.2
2024-12-27 20:59:53,081: Snapshot:2	Epoch:3	Loss:10.273	translation_Loss:9.44	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.833                                                   	MRR:17.95	Hits@10:36.4	Best:17.95
2024-12-27 21:00:01,155: Snapshot:2	Epoch:4	Loss:7.53	translation_Loss:6.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.984                                                   	MRR:19.62	Hits@10:38.43	Best:19.62
2024-12-27 21:00:09,366: Snapshot:2	Epoch:5	Loss:5.834	translation_Loss:4.733	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.101                                                   	MRR:20.36	Hits@10:39.39	Best:20.36
2024-12-27 21:00:17,449: Snapshot:2	Epoch:6	Loss:4.761	translation_Loss:3.572	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.189                                                   	MRR:21.0	Hits@10:39.89	Best:21.0
2024-12-27 21:00:25,522: Snapshot:2	Epoch:7	Loss:4.032	translation_Loss:2.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.252                                                   	MRR:21.34	Hits@10:40.52	Best:21.34
2024-12-27 21:00:33,625: Snapshot:2	Epoch:8	Loss:3.511	translation_Loss:2.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.294                                                   	MRR:21.3	Hits@10:40.45	Best:21.34
2024-12-27 21:00:41,684: Snapshot:2	Epoch:9	Loss:3.147	translation_Loss:1.828	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.319                                                   	MRR:21.58	Hits@10:40.71	Best:21.58
2024-12-27 21:00:49,817: Snapshot:2	Epoch:10	Loss:2.854	translation_Loss:1.523	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.331                                                   	MRR:21.57	Hits@10:40.75	Best:21.58
2024-12-27 21:00:57,933: Snapshot:2	Epoch:11	Loss:2.632	translation_Loss:1.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.335                                                   	MRR:21.96	Hits@10:40.71	Best:21.96
2024-12-27 21:01:06,088: Snapshot:2	Epoch:12	Loss:2.434	translation_Loss:1.103	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.331                                                   	MRR:22.28	Hits@10:40.97	Best:22.28
2024-12-27 21:01:14,119: Snapshot:2	Epoch:13	Loss:2.284	translation_Loss:0.961	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.323                                                   	MRR:22.12	Hits@10:40.88	Best:22.28
2024-12-27 21:01:22,257: Snapshot:2	Epoch:14	Loss:2.17	translation_Loss:0.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.309                                                   	MRR:22.54	Hits@10:41.19	Best:22.54
2024-12-27 21:01:30,325: Snapshot:2	Epoch:15	Loss:2.073	translation_Loss:0.781	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.293                                                   	MRR:22.42	Hits@10:41.33	Best:22.54
2024-12-27 21:01:38,825: Snapshot:2	Epoch:16	Loss:1.988	translation_Loss:0.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.277                                                   	MRR:22.24	Hits@10:41.51	Best:22.54
2024-12-27 21:01:46,830: Snapshot:2	Epoch:17	Loss:1.911	translation_Loss:0.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.26                                                   	MRR:22.27	Hits@10:41.56	Best:22.54
2024-12-27 21:01:54,906: Snapshot:2	Epoch:18	Loss:1.847	translation_Loss:0.605	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.242                                                   	MRR:22.59	Hits@10:41.38	Best:22.59
2024-12-27 21:02:02,919: Snapshot:2	Epoch:19	Loss:1.788	translation_Loss:0.565	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.222                                                   	MRR:22.82	Hits@10:41.48	Best:22.82
2024-12-27 21:02:10,984: Snapshot:2	Epoch:20	Loss:1.721	translation_Loss:0.518	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.203                                                   	MRR:22.62	Hits@10:41.85	Best:22.82
2024-12-27 21:02:19,017: Snapshot:2	Epoch:21	Loss:1.675	translation_Loss:0.492	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.183                                                   	MRR:22.7	Hits@10:41.86	Best:22.82
2024-12-27 21:02:26,979: Snapshot:2	Epoch:22	Loss:1.649	translation_Loss:0.485	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.163                                                   	MRR:22.79	Hits@10:41.96	Best:22.82
2024-12-27 21:02:34,975: Snapshot:2	Epoch:23	Loss:1.614	translation_Loss:0.466	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.147                                                   	MRR:22.91	Hits@10:41.99	Best:22.91
2024-12-27 21:02:43,040: Snapshot:2	Epoch:24	Loss:1.564	translation_Loss:0.434	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.131                                                   	MRR:23.03	Hits@10:42.01	Best:23.03
2024-12-27 21:02:51,125: Snapshot:2	Epoch:25	Loss:1.526	translation_Loss:0.413	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.113                                                   	MRR:23.32	Hits@10:42.13	Best:23.32
2024-12-27 21:02:59,134: Snapshot:2	Epoch:26	Loss:1.506	translation_Loss:0.412	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.094                                                   	MRR:23.3	Hits@10:42.21	Best:23.32
2024-12-27 21:03:07,238: Snapshot:2	Epoch:27	Loss:1.479	translation_Loss:0.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.077                                                   	MRR:23.46	Hits@10:42.29	Best:23.46
2024-12-27 21:03:15,893: Snapshot:2	Epoch:28	Loss:1.442	translation_Loss:0.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.06                                                   	MRR:23.41	Hits@10:42.05	Best:23.46
2024-12-27 21:03:23,943: Snapshot:2	Epoch:29	Loss:1.421	translation_Loss:0.376	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.045                                                   	MRR:23.41	Hits@10:42.08	Best:23.46
2024-12-27 21:03:31,938: Snapshot:2	Epoch:30	Loss:1.406	translation_Loss:0.377	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.029                                                   	MRR:23.42	Hits@10:41.98	Best:23.46
2024-12-27 21:03:39,972: Snapshot:2	Epoch:31	Loss:1.392	translation_Loss:0.375	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.017                                                   	MRR:23.57	Hits@10:42.19	Best:23.57
2024-12-27 21:03:48,025: Snapshot:2	Epoch:32	Loss:1.361	translation_Loss:0.357	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.004                                                   	MRR:23.75	Hits@10:42.25	Best:23.75
2024-12-27 21:03:56,202: Snapshot:2	Epoch:33	Loss:1.345	translation_Loss:0.354	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.991                                                   	MRR:23.85	Hits@10:42.46	Best:23.85
2024-12-27 21:04:04,354: Snapshot:2	Epoch:34	Loss:1.32	translation_Loss:0.341	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.979                                                   	MRR:24.02	Hits@10:42.49	Best:24.02
2024-12-27 21:04:12,513: Snapshot:2	Epoch:35	Loss:1.314	translation_Loss:0.351	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.964                                                   	MRR:24.06	Hits@10:42.6	Best:24.06
2024-12-27 21:04:20,633: Snapshot:2	Epoch:36	Loss:1.287	translation_Loss:0.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.952                                                   	MRR:24.08	Hits@10:42.55	Best:24.08
2024-12-27 21:04:28,737: Snapshot:2	Epoch:37	Loss:1.274	translation_Loss:0.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.944                                                   	MRR:24.15	Hits@10:42.48	Best:24.15
2024-12-27 21:04:36,829: Snapshot:2	Epoch:38	Loss:1.265	translation_Loss:0.333	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.932                                                   	MRR:23.6	Hits@10:42.05	Best:24.15
2024-12-27 21:04:44,838: Snapshot:2	Epoch:39	Loss:1.255	translation_Loss:0.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.924                                                   	MRR:23.71	Hits@10:42.28	Best:24.15
2024-12-27 21:04:52,909: Snapshot:2	Epoch:40	Loss:1.23	translation_Loss:0.319	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.911                                                   	MRR:23.63	Hits@10:42.36	Best:24.15
2024-12-27 21:05:01,384: Snapshot:2	Epoch:41	Loss:1.225	translation_Loss:0.327	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.898                                                   	MRR:23.75	Hits@10:42.17	Best:24.15
2024-12-27 21:05:09,433: Early Stopping! Snapshot: 2 Epoch: 42 Best Results: 24.15
2024-12-27 21:05:09,433: Start to training tokens! Snapshot: 2 Epoch: 42 Loss:1.204 MRR:23.56 Best Results: 24.15
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:05:09,433: Snapshot:2	Epoch:42	Loss:1.204	translation_Loss:0.313	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.891                                                   	MRR:23.56	Hits@10:42.06	Best:24.15
2024-12-27 21:05:17,274: Snapshot:2	Epoch:43	Loss:34.405	translation_Loss:33.334	multi_layer_Loss:1.071	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.56	Hits@10:42.06	Best:24.15
2024-12-27 21:05:25,118: End of token training: 2 Epoch: 44 Loss:33.589 MRR:23.56 Best Results: 24.15
2024-12-27 21:05:25,118: Snapshot:2	Epoch:44	Loss:33.589	translation_Loss:33.341	multi_layer_Loss:0.247	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.56	Hits@10:42.06	Best:24.15
2024-12-27 21:05:25,410: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_1000/2model_best.tar'
2024-12-27 21:05:38,705: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1628 | 0.0794 | 0.2064 | 0.2577 |  0.3154 |
|     1      | 0.1525 | 0.0762 | 0.1813 | 0.2324 |  0.2973 |
|     2      | 0.2365 | 0.1434 | 0.2651 | 0.3279 |  0.4173 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 21:05:54,392: Snapshot:3	Epoch:0	Loss:19.329	translation_Loss:19.317	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.012                                                   	MRR:2.44	Hits@10:5.84	Best:2.44
2024-12-27 21:05:58,181: Snapshot:3	Epoch:1	Loss:15.043	translation_Loss:14.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.044                                                   	MRR:6.41	Hits@10:14.09	Best:6.41
2024-12-27 21:06:01,918: Snapshot:3	Epoch:2	Loss:11.77	translation_Loss:11.684	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:9.85	Hits@10:20.98	Best:9.85
2024-12-27 21:06:05,637: Snapshot:3	Epoch:3	Loss:9.114	translation_Loss:8.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.135                                                   	MRR:13.91	Hits@10:30.26	Best:13.91
2024-12-27 21:06:09,409: Snapshot:3	Epoch:4	Loss:6.913	translation_Loss:6.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:18.16	Hits@10:37.64	Best:18.16
2024-12-27 21:06:13,348: Snapshot:3	Epoch:5	Loss:5.174	translation_Loss:4.933	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.241                                                   	MRR:21.34	Hits@10:41.24	Best:21.34
2024-12-27 21:06:17,139: Snapshot:3	Epoch:6	Loss:3.911	translation_Loss:3.621	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.289                                                   	MRR:23.26	Hits@10:43.5	Best:23.26
2024-12-27 21:06:20,937: Snapshot:3	Epoch:7	Loss:2.958	translation_Loss:2.626	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.332                                                   	MRR:24.58	Hits@10:44.81	Best:24.58
2024-12-27 21:06:24,708: Snapshot:3	Epoch:8	Loss:2.224	translation_Loss:1.856	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.368                                                   	MRR:25.43	Hits@10:45.7	Best:25.43
2024-12-27 21:06:28,521: Snapshot:3	Epoch:9	Loss:1.687	translation_Loss:1.291	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.396                                                   	MRR:26.21	Hits@10:46.13	Best:26.21
2024-12-27 21:06:32,317: Snapshot:3	Epoch:10	Loss:1.339	translation_Loss:0.923	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.416                                                   	MRR:27.08	Hits@10:46.76	Best:27.08
2024-12-27 21:06:36,138: Snapshot:3	Epoch:11	Loss:1.11	translation_Loss:0.682	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.428                                                   	MRR:27.63	Hits@10:47.11	Best:27.63
2024-12-27 21:06:39,941: Snapshot:3	Epoch:12	Loss:0.943	translation_Loss:0.507	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.435                                                   	MRR:28.25	Hits@10:47.19	Best:28.25
2024-12-27 21:06:43,716: Snapshot:3	Epoch:13	Loss:0.84	translation_Loss:0.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.438                                                   	MRR:28.45	Hits@10:47.29	Best:28.45
2024-12-27 21:06:47,529: Snapshot:3	Epoch:14	Loss:0.753	translation_Loss:0.316	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.436                                                   	MRR:28.79	Hits@10:47.36	Best:28.79
2024-12-27 21:06:51,281: Snapshot:3	Epoch:15	Loss:0.694	translation_Loss:0.262	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.432                                                   	MRR:29.02	Hits@10:47.35	Best:29.02
2024-12-27 21:06:55,045: Snapshot:3	Epoch:16	Loss:0.664	translation_Loss:0.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.428                                                   	MRR:29.28	Hits@10:47.39	Best:29.28
2024-12-27 21:06:58,795: Snapshot:3	Epoch:17	Loss:0.622	translation_Loss:0.2	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.422                                                   	MRR:29.56	Hits@10:47.49	Best:29.56
2024-12-27 21:07:02,536: Snapshot:3	Epoch:18	Loss:0.592	translation_Loss:0.176	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.416                                                   	MRR:29.83	Hits@10:47.79	Best:29.83
2024-12-27 21:07:06,429: Snapshot:3	Epoch:19	Loss:0.565	translation_Loss:0.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.41                                                   	MRR:30.04	Hits@10:48.05	Best:30.04
2024-12-27 21:07:10,218: Snapshot:3	Epoch:20	Loss:0.545	translation_Loss:0.141	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.404                                                   	MRR:30.07	Hits@10:48.18	Best:30.07
2024-12-27 21:07:13,955: Snapshot:3	Epoch:21	Loss:0.529	translation_Loss:0.132	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.398                                                   	MRR:30.28	Hits@10:48.4	Best:30.28
2024-12-27 21:07:17,722: Snapshot:3	Epoch:22	Loss:0.523	translation_Loss:0.131	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.392                                                   	MRR:30.19	Hits@10:48.25	Best:30.28
2024-12-27 21:07:21,478: Snapshot:3	Epoch:23	Loss:0.503	translation_Loss:0.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.387                                                   	MRR:30.32	Hits@10:48.19	Best:30.32
2024-12-27 21:07:25,291: Snapshot:3	Epoch:24	Loss:0.491	translation_Loss:0.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.382                                                   	MRR:30.45	Hits@10:48.39	Best:30.45
2024-12-27 21:07:28,999: Snapshot:3	Epoch:25	Loss:0.478	translation_Loss:0.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.377                                                   	MRR:30.42	Hits@10:48.49	Best:30.45
2024-12-27 21:07:32,768: Snapshot:3	Epoch:26	Loss:0.468	translation_Loss:0.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.372                                                   	MRR:30.56	Hits@10:48.58	Best:30.56
2024-12-27 21:07:36,522: Snapshot:3	Epoch:27	Loss:0.465	translation_Loss:0.098	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.367                                                   	MRR:30.64	Hits@10:48.53	Best:30.64
2024-12-27 21:07:40,252: Snapshot:3	Epoch:28	Loss:0.455	translation_Loss:0.092	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.363                                                   	MRR:30.57	Hits@10:48.54	Best:30.64
2024-12-27 21:07:43,906: Snapshot:3	Epoch:29	Loss:0.448	translation_Loss:0.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.359                                                   	MRR:30.54	Hits@10:48.72	Best:30.64
2024-12-27 21:07:47,676: Snapshot:3	Epoch:30	Loss:0.437	translation_Loss:0.082	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.355                                                   	MRR:30.67	Hits@10:48.83	Best:30.67
2024-12-27 21:07:51,449: Snapshot:3	Epoch:31	Loss:0.436	translation_Loss:0.085	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.351                                                   	MRR:30.75	Hits@10:48.78	Best:30.75
2024-12-27 21:07:55,200: Snapshot:3	Epoch:32	Loss:0.43	translation_Loss:0.083	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.347                                                   	MRR:30.66	Hits@10:49.05	Best:30.75
2024-12-27 21:07:58,998: Snapshot:3	Epoch:33	Loss:0.421	translation_Loss:0.078	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.343                                                   	MRR:30.79	Hits@10:49.03	Best:30.79
2024-12-27 21:08:02,663: Snapshot:3	Epoch:34	Loss:0.418	translation_Loss:0.078	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.34                                                   	MRR:30.65	Hits@10:49.14	Best:30.79
2024-12-27 21:08:06,423: Snapshot:3	Epoch:35	Loss:0.412	translation_Loss:0.075	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.337                                                   	MRR:30.83	Hits@10:49.18	Best:30.83
2024-12-27 21:08:10,229: Snapshot:3	Epoch:36	Loss:0.407	translation_Loss:0.073	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.334                                                   	MRR:30.94	Hits@10:49.29	Best:30.94
2024-12-27 21:08:13,954: Snapshot:3	Epoch:37	Loss:0.403	translation_Loss:0.073	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.331                                                   	MRR:30.69	Hits@10:49.31	Best:30.94
2024-12-27 21:08:17,613: Snapshot:3	Epoch:38	Loss:0.394	translation_Loss:0.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.327                                                   	MRR:30.86	Hits@10:49.33	Best:30.94
2024-12-27 21:08:21,323: Snapshot:3	Epoch:39	Loss:0.391	translation_Loss:0.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.324                                                   	MRR:30.84	Hits@10:49.34	Best:30.94
2024-12-27 21:08:25,112: Snapshot:3	Epoch:40	Loss:0.389	translation_Loss:0.068	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.321                                                   	MRR:31.0	Hits@10:49.3	Best:31.0
2024-12-27 21:08:28,839: Snapshot:3	Epoch:41	Loss:0.384	translation_Loss:0.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.318                                                   	MRR:31.0	Hits@10:49.14	Best:31.0
2024-12-27 21:08:32,552: Snapshot:3	Epoch:42	Loss:0.384	translation_Loss:0.068	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.316                                                   	MRR:31.18	Hits@10:49.34	Best:31.18
2024-12-27 21:08:36,314: Snapshot:3	Epoch:43	Loss:0.378	translation_Loss:0.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.313                                                   	MRR:31.28	Hits@10:49.07	Best:31.28
2024-12-27 21:08:40,108: Snapshot:3	Epoch:44	Loss:0.377	translation_Loss:0.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.311                                                   	MRR:31.39	Hits@10:49.13	Best:31.39
2024-12-27 21:08:43,907: Snapshot:3	Epoch:45	Loss:0.369	translation_Loss:0.061	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.308                                                   	MRR:31.44	Hits@10:49.29	Best:31.44
2024-12-27 21:08:47,619: Snapshot:3	Epoch:46	Loss:0.369	translation_Loss:0.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.305                                                   	MRR:31.49	Hits@10:49.3	Best:31.49
2024-12-27 21:08:51,332: Snapshot:3	Epoch:47	Loss:0.363	translation_Loss:0.061	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.302                                                   	MRR:31.38	Hits@10:49.18	Best:31.49
2024-12-27 21:08:55,053: Snapshot:3	Epoch:48	Loss:0.36	translation_Loss:0.06	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.299                                                   	MRR:31.39	Hits@10:49.3	Best:31.49
2024-12-27 21:08:58,785: Snapshot:3	Epoch:49	Loss:0.352	translation_Loss:0.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.297                                                   	MRR:31.41	Hits@10:49.41	Best:31.49
2024-12-27 21:09:02,471: Snapshot:3	Epoch:50	Loss:0.35	translation_Loss:0.055	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.294                                                   	MRR:31.43	Hits@10:49.45	Best:31.49
2024-12-27 21:09:06,131: Early Stopping! Snapshot: 3 Epoch: 51 Best Results: 31.49
2024-12-27 21:09:06,131: Start to training tokens! Snapshot: 3 Epoch: 51 Loss:0.347 MRR:31.47 Best Results: 31.49
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:09:06,131: Snapshot:3	Epoch:51	Loss:0.347	translation_Loss:0.056	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.291                                                   	MRR:31.47	Hits@10:49.36	Best:31.49
2024-12-27 21:09:10,256: Snapshot:3	Epoch:52	Loss:10.577	translation_Loss:9.992	multi_layer_Loss:0.584	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.47	Hits@10:49.36	Best:31.49
2024-12-27 21:09:13,861: End of token training: 3 Epoch: 53 Loss:10.326 MRR:31.47 Best Results: 31.49
2024-12-27 21:09:13,861: Snapshot:3	Epoch:53	Loss:10.326	translation_Loss:9.988	multi_layer_Loss:0.338	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.47	Hits@10:49.36	Best:31.49
2024-12-27 21:09:14,153: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_1000/3model_best.tar'
2024-12-27 21:09:29,262: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1563 | 0.0762 | 0.1966 | 0.2451 |  0.3045 |
|     1      | 0.1376 | 0.0637 | 0.1624 | 0.2139 |  0.2793 |
|     2      | 0.1633 | 0.0863 | 0.1776 | 0.2283 |  0.3108 |
|     3      | 0.3159 | 0.2173 | 0.363  | 0.4184 |  0.4976 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 21:09:41,561: Snapshot:4	Epoch:0	Loss:9.609	translation_Loss:9.602	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.007                                                   	MRR:6.42	Hits@10:17.21	Best:6.42
2024-12-27 21:09:44,236: Snapshot:4	Epoch:1	Loss:7.329	translation_Loss:7.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.027                                                   	MRR:8.68	Hits@10:21.56	Best:8.68
2024-12-27 21:09:46,925: Snapshot:4	Epoch:2	Loss:5.713	translation_Loss:5.664	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.049                                                   	MRR:10.71	Hits@10:26.28	Best:10.71
2024-12-27 21:09:49,640: Snapshot:4	Epoch:3	Loss:4.489	translation_Loss:4.418	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.071                                                   	MRR:13.29	Hits@10:31.12	Best:13.29
2024-12-27 21:09:52,304: Snapshot:4	Epoch:4	Loss:3.537	translation_Loss:3.446	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:15.74	Hits@10:35.93	Best:15.74
2024-12-27 21:09:55,036: Snapshot:4	Epoch:5	Loss:2.786	translation_Loss:2.677	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.11                                                   	MRR:17.7	Hits@10:39.38	Best:17.7
2024-12-27 21:09:57,746: Snapshot:4	Epoch:6	Loss:2.206	translation_Loss:2.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:19.47	Hits@10:42.35	Best:19.47
2024-12-27 21:10:00,450: Snapshot:4	Epoch:7	Loss:1.78	translation_Loss:1.64	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.14                                                   	MRR:21.04	Hits@10:44.79	Best:21.04
2024-12-27 21:10:03,138: Snapshot:4	Epoch:8	Loss:1.441	translation_Loss:1.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:22.41	Hits@10:46.8	Best:22.41
2024-12-27 21:10:05,854: Snapshot:4	Epoch:9	Loss:1.188	translation_Loss:1.026	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.162                                                   	MRR:23.03	Hits@10:47.82	Best:23.03
2024-12-27 21:10:08,596: Snapshot:4	Epoch:10	Loss:0.959	translation_Loss:0.789	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:23.53	Hits@10:48.97	Best:23.53
2024-12-27 21:10:11,238: Snapshot:4	Epoch:11	Loss:0.763	translation_Loss:0.587	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.176                                                   	MRR:24.9	Hits@10:49.7	Best:24.9
2024-12-27 21:10:14,013: Snapshot:4	Epoch:12	Loss:0.6	translation_Loss:0.419	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.18                                                   	MRR:25.82	Hits@10:49.66	Best:25.82
2024-12-27 21:10:16,722: Snapshot:4	Epoch:13	Loss:0.48	translation_Loss:0.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.183                                                   	MRR:26.24	Hits@10:49.9	Best:26.24
2024-12-27 21:10:19,425: Snapshot:4	Epoch:14	Loss:0.396	translation_Loss:0.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.185                                                   	MRR:26.34	Hits@10:50.16	Best:26.34
2024-12-27 21:10:22,180: Snapshot:4	Epoch:15	Loss:0.362	translation_Loss:0.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.185                                                   	MRR:26.52	Hits@10:50.17	Best:26.52
2024-12-27 21:10:24,867: Snapshot:4	Epoch:16	Loss:0.329	translation_Loss:0.144	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.185                                                   	MRR:26.83	Hits@10:50.8	Best:26.83
2024-12-27 21:10:27,554: Snapshot:4	Epoch:17	Loss:0.306	translation_Loss:0.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.184                                                   	MRR:26.86	Hits@10:51.45	Best:26.86
2024-12-27 21:10:30,227: Snapshot:4	Epoch:18	Loss:0.288	translation_Loss:0.106	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.182                                                   	MRR:27.0	Hits@10:51.23	Best:27.0
2024-12-27 21:10:32,901: Snapshot:4	Epoch:19	Loss:0.274	translation_Loss:0.094	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.18                                                   	MRR:27.07	Hits@10:51.33	Best:27.07
2024-12-27 21:10:35,570: Snapshot:4	Epoch:20	Loss:0.26	translation_Loss:0.082	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.178                                                   	MRR:27.13	Hits@10:51.3	Best:27.13
2024-12-27 21:10:38,327: Snapshot:4	Epoch:21	Loss:0.248	translation_Loss:0.072	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.176                                                   	MRR:27.14	Hits@10:51.38	Best:27.14
2024-12-27 21:10:41,025: Snapshot:4	Epoch:22	Loss:0.241	translation_Loss:0.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.174                                                   	MRR:27.45	Hits@10:52.18	Best:27.45
2024-12-27 21:10:43,721: Snapshot:4	Epoch:23	Loss:0.234	translation_Loss:0.063	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:27.64	Hits@10:51.93	Best:27.64
2024-12-27 21:10:46,340: Snapshot:4	Epoch:24	Loss:0.227	translation_Loss:0.058	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:27.54	Hits@10:51.56	Best:27.64
2024-12-27 21:10:48,998: Snapshot:4	Epoch:25	Loss:0.226	translation_Loss:0.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:27.73	Hits@10:51.71	Best:27.73
2024-12-27 21:10:51,663: Snapshot:4	Epoch:26	Loss:0.216	translation_Loss:0.05	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:27.47	Hits@10:51.97	Best:27.73
2024-12-27 21:10:54,277: Snapshot:4	Epoch:27	Loss:0.215	translation_Loss:0.051	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.164                                                   	MRR:27.58	Hits@10:52.07	Best:27.73
2024-12-27 21:10:56,887: Snapshot:4	Epoch:28	Loss:0.209	translation_Loss:0.047	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.162                                                   	MRR:27.7	Hits@10:52.03	Best:27.73
2024-12-27 21:10:59,464: Snapshot:4	Epoch:29	Loss:0.203	translation_Loss:0.043	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:27.68	Hits@10:51.64	Best:27.73
2024-12-27 21:11:02,552: Early Stopping! Snapshot: 4 Epoch: 30 Best Results: 27.73
2024-12-27 21:11:02,553: Start to training tokens! Snapshot: 4 Epoch: 30 Loss:0.205 MRR:27.59 Best Results: 27.73
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:11:02,553: Snapshot:4	Epoch:30	Loss:0.205	translation_Loss:0.046	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.159                                                   	MRR:27.59	Hits@10:51.63	Best:27.73
2024-12-27 21:11:05,110: Snapshot:4	Epoch:31	Loss:5.944	translation_Loss:5.476	multi_layer_Loss:0.468	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.59	Hits@10:51.63	Best:27.73
2024-12-27 21:11:07,632: End of token training: 4 Epoch: 32 Loss:5.837 MRR:27.59 Best Results: 27.73
2024-12-27 21:11:07,632: Snapshot:4	Epoch:32	Loss:5.837	translation_Loss:5.496	multi_layer_Loss:0.341	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.59	Hits@10:51.63	Best:27.73
2024-12-27 21:11:07,924: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_1000/4model_best.tar'
2024-12-27 21:11:24,408: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1452 | 0.0732 | 0.1797 | 0.2244 |  0.275  |
|     1      | 0.127  | 0.0565 | 0.1491 | 0.1975 |  0.2629 |
|     2      | 0.1504 | 0.0812 | 0.1626 | 0.2078 |  0.2832 |
|     3      | 0.2518 | 0.1704 | 0.2828 | 0.3235 |  0.3989 |
|     4      | 0.2706 | 0.1525 | 0.3113 | 0.3948 |  0.5113 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 21:11:24,410: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2766 | 0.1644 | 0.3425 | 0.4125 |  0.4843 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1944 | 0.0945 | 0.249  | 0.3097 |  0.3785 |
|     1      | 0.2023 | 0.1099 | 0.2402 | 0.3027 |  0.3771 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1628 | 0.0794 | 0.2064 | 0.2577 |  0.3154 |
|     1      | 0.1525 | 0.0762 | 0.1813 | 0.2324 |  0.2973 |
|     2      | 0.2365 | 0.1434 | 0.2651 | 0.3279 |  0.4173 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1563 | 0.0762 | 0.1966 | 0.2451 |  0.3045 |
|     1      | 0.1376 | 0.0637 | 0.1624 | 0.2139 |  0.2793 |
|     2      | 0.1633 | 0.0863 | 0.1776 | 0.2283 |  0.3108 |
|     3      | 0.3159 | 0.2173 | 0.363  | 0.4184 |  0.4976 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1452 | 0.0732 | 0.1797 | 0.2244 |  0.275  |
|     1      | 0.127  | 0.0565 | 0.1491 | 0.1975 |  0.2629 |
|     2      | 0.1504 | 0.0812 | 0.1626 | 0.2078 |  0.2832 |
|     3      | 0.2518 | 0.1704 | 0.2828 | 0.3235 |  0.3989 |
|     4      | 0.2706 | 0.1525 | 0.3113 | 0.3948 |  0.5113 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 21:11:24,411: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 467.06160712242126 |   0.277   |    0.164     |    0.343     |     0.484     |
|    1     | 313.44914841651917 |   0.198   |    0.102     |    0.245     |     0.378     |
|    2     | 380.4181537628174  |   0.178   |    0.095     |    0.212     |     0.335     |
|    3     | 213.2432460784912  |   0.168   |    0.089     |    0.198     |     0.318     |
|    4     | 96.88381314277649  |    0.16   |    0.085     |    0.186     |     0.302     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 21:11:24,411: Sum_Training_Time:1471.0559685230255
2024-12-27 21:11:24,411: Every_Training_Time:[467.06160712242126, 313.44914841651917, 380.4181537628174, 213.2432460784912, 96.88381314277649]
2024-12-27 21:11:24,411: Forward transfer: 0.018799999999999997 Backward transfer: -0.089225
2024-12-27 21:12:01,935: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.0001, lifelong_name='double_tokened', log_path='./logs/20241227211128/RELATIONrelation_0.0001_1024_5000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.0001_1024_5000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.0001_1024_5000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 21:12:17,705: Snapshot:0	Epoch:0	Loss:79.901	translation_Loss:79.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.65	Hits@10:9.44	Best:4.65
2024-12-27 21:12:29,096: Snapshot:0	Epoch:1	Loss:71.045	translation_Loss:71.045	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.6	Hits@10:18.87	Best:8.6
2024-12-27 21:12:40,457: Snapshot:0	Epoch:2	Loss:63.624	translation_Loss:63.624	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.67	Hits@10:22.36	Best:9.67
2024-12-27 21:12:51,913: Snapshot:0	Epoch:3	Loss:56.95	translation_Loss:56.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.75	Hits@10:25.61	Best:10.75
2024-12-27 21:13:03,355: Snapshot:0	Epoch:4	Loss:50.574	translation_Loss:50.574	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.68	Hits@10:29.79	Best:12.68
2024-12-27 21:13:14,851: Snapshot:0	Epoch:5	Loss:44.361	translation_Loss:44.361	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.15	Hits@10:34.34	Best:15.15
2024-12-27 21:13:26,920: Snapshot:0	Epoch:6	Loss:38.303	translation_Loss:38.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.45	Hits@10:37.68	Best:17.45
2024-12-27 21:13:38,248: Snapshot:0	Epoch:7	Loss:32.598	translation_Loss:32.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.32	Hits@10:40.12	Best:19.32
2024-12-27 21:13:49,705: Snapshot:0	Epoch:8	Loss:27.616	translation_Loss:27.616	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.79	Hits@10:41.77	Best:20.79
2024-12-27 21:14:01,205: Snapshot:0	Epoch:9	Loss:23.298	translation_Loss:23.298	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.97	Hits@10:43.27	Best:21.97
2024-12-27 21:14:12,658: Snapshot:0	Epoch:10	Loss:19.67	translation_Loss:19.67	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.85	Hits@10:44.18	Best:22.85
2024-12-27 21:14:24,122: Snapshot:0	Epoch:11	Loss:16.592	translation_Loss:16.592	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.74	Hits@10:45.14	Best:23.74
2024-12-27 21:14:36,263: Snapshot:0	Epoch:12	Loss:13.989	translation_Loss:13.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.37	Hits@10:45.81	Best:24.37
2024-12-27 21:14:47,826: Snapshot:0	Epoch:13	Loss:11.893	translation_Loss:11.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.89	Hits@10:46.2	Best:24.89
2024-12-27 21:14:59,261: Snapshot:0	Epoch:14	Loss:10.107	translation_Loss:10.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.31	Hits@10:46.56	Best:25.31
2024-12-27 21:15:10,755: Snapshot:0	Epoch:15	Loss:8.721	translation_Loss:8.721	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.77	Hits@10:46.95	Best:25.77
2024-12-27 21:15:22,183: Snapshot:0	Epoch:16	Loss:7.515	translation_Loss:7.515	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.14	Hits@10:47.23	Best:26.14
2024-12-27 21:15:33,556: Snapshot:0	Epoch:17	Loss:6.528	translation_Loss:6.528	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.34	Hits@10:47.48	Best:26.34
2024-12-27 21:15:44,984: Snapshot:0	Epoch:18	Loss:5.781	translation_Loss:5.781	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.62	Hits@10:47.68	Best:26.62
2024-12-27 21:15:56,503: Snapshot:0	Epoch:19	Loss:5.139	translation_Loss:5.139	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.63	Hits@10:47.92	Best:26.63
2024-12-27 21:16:07,889: Snapshot:0	Epoch:20	Loss:4.631	translation_Loss:4.631	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.76	Hits@10:48.01	Best:26.76
2024-12-27 21:16:19,366: Snapshot:0	Epoch:21	Loss:4.181	translation_Loss:4.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.88	Hits@10:47.92	Best:26.88
2024-12-27 21:16:30,952: Snapshot:0	Epoch:22	Loss:3.826	translation_Loss:3.826	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.97	Hits@10:48.08	Best:26.97
2024-12-27 21:16:42,318: Snapshot:0	Epoch:23	Loss:3.545	translation_Loss:3.545	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.04	Hits@10:48.09	Best:27.04
2024-12-27 21:16:53,830: Snapshot:0	Epoch:24	Loss:3.277	translation_Loss:3.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.17	Hits@10:48.19	Best:27.17
2024-12-27 21:17:05,788: Snapshot:0	Epoch:25	Loss:3.062	translation_Loss:3.062	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.22	Hits@10:48.12	Best:27.22
2024-12-27 21:17:17,297: Snapshot:0	Epoch:26	Loss:2.853	translation_Loss:2.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.36	Hits@10:48.28	Best:27.36
2024-12-27 21:17:28,711: Snapshot:0	Epoch:27	Loss:2.7	translation_Loss:2.7	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.33	Hits@10:48.21	Best:27.36
2024-12-27 21:17:40,145: Snapshot:0	Epoch:28	Loss:2.547	translation_Loss:2.547	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.38	Hits@10:48.26	Best:27.38
2024-12-27 21:17:51,671: Snapshot:0	Epoch:29	Loss:2.429	translation_Loss:2.429	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.37	Hits@10:48.25	Best:27.38
2024-12-27 21:18:03,056: Snapshot:0	Epoch:30	Loss:2.297	translation_Loss:2.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.35	Hits@10:48.25	Best:27.38
2024-12-27 21:18:14,959: Snapshot:0	Epoch:31	Loss:2.21	translation_Loss:2.21	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.29	Hits@10:48.21	Best:27.38
2024-12-27 21:18:26,427: Snapshot:0	Epoch:32	Loss:2.117	translation_Loss:2.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.49	Hits@10:48.15	Best:27.49
2024-12-27 21:18:37,775: Snapshot:0	Epoch:33	Loss:2.048	translation_Loss:2.048	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.38	Hits@10:48.15	Best:27.49
2024-12-27 21:18:49,165: Snapshot:0	Epoch:34	Loss:1.944	translation_Loss:1.944	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.41	Hits@10:48.11	Best:27.49
2024-12-27 21:19:00,536: Snapshot:0	Epoch:35	Loss:1.888	translation_Loss:1.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.44	Hits@10:48.14	Best:27.49
2024-12-27 21:19:11,902: Snapshot:0	Epoch:36	Loss:1.843	translation_Loss:1.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.52	Hits@10:48.06	Best:27.52
2024-12-27 21:19:23,367: Snapshot:0	Epoch:37	Loss:1.762	translation_Loss:1.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.51	Hits@10:48.12	Best:27.52
2024-12-27 21:19:34,769: Snapshot:0	Epoch:38	Loss:1.705	translation_Loss:1.705	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.51	Hits@10:48.26	Best:27.52
2024-12-27 21:19:46,291: Snapshot:0	Epoch:39	Loss:1.67	translation_Loss:1.67	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.41	Hits@10:48.05	Best:27.52
2024-12-27 21:19:57,756: Snapshot:0	Epoch:40	Loss:1.61	translation_Loss:1.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.47	Hits@10:48.16	Best:27.52
2024-12-27 21:20:09,383: Early Stopping! Snapshot: 0 Epoch: 41 Best Results: 27.52
2024-12-27 21:20:09,383: Start to training tokens! Snapshot: 0 Epoch: 41 Loss:1.581 MRR:27.47 Best Results: 27.52
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:20:09,384: Snapshot:0	Epoch:41	Loss:1.581	translation_Loss:1.581	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.47	Hits@10:48.07	Best:27.52
2024-12-27 21:20:21,487: Snapshot:0	Epoch:42	Loss:51.095	translation_Loss:49.899	multi_layer_Loss:1.195	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.47	Hits@10:48.07	Best:27.52
2024-12-27 21:20:33,551: End of token training: 0 Epoch: 43 Loss:49.92 MRR:27.47 Best Results: 27.52
2024-12-27 21:20:33,551: Snapshot:0	Epoch:43	Loss:49.92	translation_Loss:49.835	multi_layer_Loss:0.085	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.47	Hits@10:48.07	Best:27.52
2024-12-27 21:20:33,852: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_5000/0model_best.tar'
2024-12-27 21:20:39,076: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2773 | 0.1653 | 0.3431 | 0.4128 |  0.4843 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 21:21:15,414: Snapshot:1	Epoch:0	Loss:71.964	translation_Loss:71.56	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.404                                                   	MRR:3.33	Hits@10:9.3	Best:3.33
2024-12-27 21:21:26,170: Snapshot:1	Epoch:1	Loss:57.405	translation_Loss:56.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.334                                                   	MRR:6.9	Hits@10:17.46	Best:6.9
2024-12-27 21:21:36,886: Snapshot:1	Epoch:2	Loss:45.983	translation_Loss:43.544	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.44                                                   	MRR:10.08	Hits@10:22.6	Best:10.08
2024-12-27 21:21:47,598: Snapshot:1	Epoch:3	Loss:37.0	translation_Loss:33.537	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.463                                                   	MRR:12.61	Hits@10:27.26	Best:12.61
2024-12-27 21:21:58,346: Snapshot:1	Epoch:4	Loss:29.886	translation_Loss:25.577	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.309                                                   	MRR:14.34	Hits@10:29.97	Best:14.34
2024-12-27 21:22:09,630: Snapshot:1	Epoch:5	Loss:24.393	translation_Loss:19.433	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.96                                                   	MRR:15.93	Hits@10:31.86	Best:15.93
2024-12-27 21:22:20,459: Snapshot:1	Epoch:6	Loss:20.311	translation_Loss:14.896	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.415                                                   	MRR:16.69	Hits@10:33.06	Best:16.69
2024-12-27 21:22:31,315: Snapshot:1	Epoch:7	Loss:17.408	translation_Loss:11.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.688                                                   	MRR:17.33	Hits@10:33.65	Best:17.33
2024-12-27 21:22:41,999: Snapshot:1	Epoch:8	Loss:15.359	translation_Loss:9.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.813                                                   	MRR:17.49	Hits@10:34.12	Best:17.49
2024-12-27 21:22:52,900: Snapshot:1	Epoch:9	Loss:13.873	translation_Loss:8.044	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.829                                                   	MRR:17.54	Hits@10:34.3	Best:17.54
2024-12-27 21:23:03,762: Snapshot:1	Epoch:10	Loss:12.808	translation_Loss:7.033	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.775                                                   	MRR:17.68	Hits@10:34.54	Best:17.68
2024-12-27 21:23:14,505: Snapshot:1	Epoch:11	Loss:11.99	translation_Loss:6.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.683                                                   	MRR:17.82	Hits@10:34.49	Best:17.82
2024-12-27 21:23:25,214: Snapshot:1	Epoch:12	Loss:11.388	translation_Loss:5.816	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.572                                                   	MRR:17.83	Hits@10:34.5	Best:17.83
2024-12-27 21:23:35,929: Snapshot:1	Epoch:13	Loss:10.915	translation_Loss:5.458	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.457                                                   	MRR:17.56	Hits@10:34.45	Best:17.83
2024-12-27 21:23:47,264: Snapshot:1	Epoch:14	Loss:10.491	translation_Loss:5.14	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.352                                                   	MRR:17.45	Hits@10:34.34	Best:17.83
2024-12-27 21:23:58,082: Snapshot:1	Epoch:15	Loss:10.207	translation_Loss:4.956	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.251                                                   	MRR:17.75	Hits@10:34.43	Best:17.83
2024-12-27 21:24:08,750: Snapshot:1	Epoch:16	Loss:9.946	translation_Loss:4.775	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.17                                                   	MRR:17.74	Hits@10:34.38	Best:17.83
2024-12-27 21:24:19,389: Early Stopping! Snapshot: 1 Epoch: 17 Best Results: 17.83
2024-12-27 21:24:19,389: Start to training tokens! Snapshot: 1 Epoch: 17 Loss:9.725 MRR:17.56 Best Results: 17.83
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:24:19,389: Snapshot:1	Epoch:17	Loss:9.725	translation_Loss:4.636	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.089                                                   	MRR:17.56	Hits@10:34.27	Best:17.83
2024-12-27 21:24:29,885: Snapshot:1	Epoch:18	Loss:55.832	translation_Loss:54.647	multi_layer_Loss:1.185	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.56	Hits@10:34.27	Best:17.83
2024-12-27 21:24:40,351: End of token training: 1 Epoch: 19 Loss:54.746 MRR:17.56 Best Results: 17.83
2024-12-27 21:24:40,351: Snapshot:1	Epoch:19	Loss:54.746	translation_Loss:54.65	multi_layer_Loss:0.096	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:17.56	Hits@10:34.27	Best:17.83
2024-12-27 21:24:40,725: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_5000/1model_best.tar'
2024-12-27 21:24:51,032: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2264 | 0.1186 | 0.2852 | 0.3524 |  0.4268 |
|     1      | 0.1794 | 0.0923 | 0.2147 | 0.273  |  0.3459 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 21:25:18,681: Snapshot:2	Epoch:0	Loss:47.54	translation_Loss:47.232	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.309                                                   	MRR:1.55	Hits@10:3.81	Best:1.55
2024-12-27 21:25:26,734: Snapshot:2	Epoch:1	Loss:29.376	translation_Loss:28.189	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.187                                                   	MRR:9.23	Hits@10:21.67	Best:9.23
2024-12-27 21:25:34,703: Snapshot:2	Epoch:2	Loss:18.82	translation_Loss:16.752	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.068                                                   	MRR:14.96	Hits@10:31.53	Best:14.96
2024-12-27 21:25:42,793: Snapshot:2	Epoch:3	Loss:14.191	translation_Loss:11.627	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.564                                                   	MRR:18.33	Hits@10:35.85	Best:18.33
2024-12-27 21:25:50,804: Snapshot:2	Epoch:4	Loss:11.623	translation_Loss:8.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.883                                                   	MRR:20.43	Hits@10:37.86	Best:20.43
2024-12-27 21:25:58,879: Snapshot:2	Epoch:5	Loss:9.931	translation_Loss:6.835	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.095                                                   	MRR:21.33	Hits@10:39.12	Best:21.33
2024-12-27 21:26:06,911: Snapshot:2	Epoch:6	Loss:8.794	translation_Loss:5.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.224                                                   	MRR:21.7	Hits@10:39.87	Best:21.7
2024-12-27 21:26:14,871: Snapshot:2	Epoch:7	Loss:7.97	translation_Loss:4.692	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.278                                                   	MRR:22.44	Hits@10:40.65	Best:22.44
2024-12-27 21:26:23,469: Snapshot:2	Epoch:8	Loss:7.334	translation_Loss:4.045	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.289                                                   	MRR:22.47	Hits@10:40.94	Best:22.47
2024-12-27 21:26:31,518: Snapshot:2	Epoch:9	Loss:6.831	translation_Loss:3.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.263                                                   	MRR:22.82	Hits@10:41.49	Best:22.82
2024-12-27 21:26:39,644: Snapshot:2	Epoch:10	Loss:6.409	translation_Loss:3.193	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.216                                                   	MRR:23.14	Hits@10:41.76	Best:23.14
2024-12-27 21:26:47,719: Snapshot:2	Epoch:11	Loss:5.995	translation_Loss:2.844	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.15                                                   	MRR:23.27	Hits@10:41.88	Best:23.27
2024-12-27 21:26:55,717: Snapshot:2	Epoch:12	Loss:5.7	translation_Loss:2.618	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.082                                                   	MRR:23.11	Hits@10:42.2	Best:23.27
2024-12-27 21:27:03,685: Snapshot:2	Epoch:13	Loss:5.416	translation_Loss:2.407	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.009                                                   	MRR:23.47	Hits@10:42.12	Best:23.47
2024-12-27 21:27:11,783: Snapshot:2	Epoch:14	Loss:5.181	translation_Loss:2.246	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.934                                                   	MRR:23.57	Hits@10:42.18	Best:23.57
2024-12-27 21:27:19,863: Snapshot:2	Epoch:15	Loss:4.971	translation_Loss:2.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.864                                                   	MRR:23.58	Hits@10:42.14	Best:23.58
2024-12-27 21:27:27,948: Snapshot:2	Epoch:16	Loss:4.77	translation_Loss:1.978	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.793                                                   	MRR:23.51	Hits@10:42.29	Best:23.58
2024-12-27 21:27:36,026: Snapshot:2	Epoch:17	Loss:4.608	translation_Loss:1.885	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.723                                                   	MRR:23.16	Hits@10:42.18	Best:23.58
2024-12-27 21:27:44,131: Snapshot:2	Epoch:18	Loss:4.459	translation_Loss:1.802	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.657                                                   	MRR:23.61	Hits@10:42.2	Best:23.61
2024-12-27 21:27:52,151: Snapshot:2	Epoch:19	Loss:4.319	translation_Loss:1.727	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.592                                                   	MRR:23.64	Hits@10:42.24	Best:23.64
2024-12-27 21:28:00,793: Snapshot:2	Epoch:20	Loss:4.215	translation_Loss:1.682	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.532                                                   	MRR:23.61	Hits@10:42.22	Best:23.64
2024-12-27 21:28:08,796: Snapshot:2	Epoch:21	Loss:4.092	translation_Loss:1.613	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.479                                                   	MRR:23.7	Hits@10:41.96	Best:23.7
2024-12-27 21:28:16,835: Snapshot:2	Epoch:22	Loss:4.001	translation_Loss:1.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.43                                                   	MRR:23.77	Hits@10:41.71	Best:23.77
2024-12-27 21:28:24,870: Snapshot:2	Epoch:23	Loss:3.91	translation_Loss:1.533	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.377                                                   	MRR:23.5	Hits@10:41.37	Best:23.77
2024-12-27 21:28:32,782: Snapshot:2	Epoch:24	Loss:3.836	translation_Loss:1.502	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.333                                                   	MRR:23.58	Hits@10:41.47	Best:23.77
2024-12-27 21:28:40,679: Snapshot:2	Epoch:25	Loss:3.772	translation_Loss:1.478	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.294                                                   	MRR:23.52	Hits@10:41.35	Best:23.77
2024-12-27 21:28:48,624: Snapshot:2	Epoch:26	Loss:3.703	translation_Loss:1.443	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.26                                                   	MRR:23.43	Hits@10:41.5	Best:23.77
2024-12-27 21:28:56,605: Early Stopping! Snapshot: 2 Epoch: 27 Best Results: 23.77
2024-12-27 21:28:56,605: Start to training tokens! Snapshot: 2 Epoch: 27 Loss:3.626 MRR:23.09 Best Results: 23.77
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:28:56,606: Snapshot:2	Epoch:27	Loss:3.626	translation_Loss:1.404	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.222                                                   	MRR:23.09	Hits@10:41.32	Best:23.77
2024-12-27 21:29:04,460: Snapshot:2	Epoch:28	Loss:38.836	translation_Loss:37.765	multi_layer_Loss:1.071	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.09	Hits@10:41.32	Best:23.77
2024-12-27 21:29:12,192: End of token training: 2 Epoch: 29 Loss:38.051 MRR:23.09 Best Results: 23.77
2024-12-27 21:29:12,192: Snapshot:2	Epoch:29	Loss:38.051	translation_Loss:37.804	multi_layer_Loss:0.247	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.09	Hits@10:41.32	Best:23.77
2024-12-27 21:29:12,570: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_5000/2model_best.tar'
2024-12-27 21:29:26,044: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1904 | 0.0948 | 0.2402 | 0.3026 |  0.3711 |
|     1      | 0.1512 | 0.0736 | 0.1804 | 0.2309 |  0.299  |
|     2      | 0.2327 | 0.1421 | 0.2619 | 0.3211 |  0.4126 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 21:29:41,513: Snapshot:3	Epoch:0	Loss:20.252	translation_Loss:20.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.054                                                   	MRR:2.68	Hits@10:6.44	Best:2.68
2024-12-27 21:29:45,217: Snapshot:3	Epoch:1	Loss:16.337	translation_Loss:16.168	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:5.95	Hits@10:13.56	Best:5.95
2024-12-27 21:29:48,953: Snapshot:3	Epoch:2	Loss:13.372	translation_Loss:13.063	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.31                                                   	MRR:9.12	Hits@10:19.8	Best:9.12
2024-12-27 21:29:52,641: Snapshot:3	Epoch:3	Loss:10.931	translation_Loss:10.463	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.468                                                   	MRR:13.01	Hits@10:28.48	Best:13.01
2024-12-27 21:29:56,389: Snapshot:3	Epoch:4	Loss:8.871	translation_Loss:8.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.633                                                   	MRR:17.15	Hits@10:36.34	Best:17.15
2024-12-27 21:30:00,616: Snapshot:3	Epoch:5	Loss:7.162	translation_Loss:6.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.794                                                   	MRR:20.15	Hits@10:40.1	Best:20.15
2024-12-27 21:30:04,429: Snapshot:3	Epoch:6	Loss:5.836	translation_Loss:4.897	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.939                                                   	MRR:22.4	Hits@10:42.61	Best:22.4
2024-12-27 21:30:08,189: Snapshot:3	Epoch:7	Loss:4.827	translation_Loss:3.769	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.058                                                   	MRR:23.84	Hits@10:44.39	Best:23.84
2024-12-27 21:30:11,939: Snapshot:3	Epoch:8	Loss:4.033	translation_Loss:2.884	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.149                                                   	MRR:25.01	Hits@10:44.92	Best:25.01
2024-12-27 21:30:15,684: Snapshot:3	Epoch:9	Loss:3.456	translation_Loss:2.24	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.215                                                   	MRR:25.97	Hits@10:45.57	Best:25.97
2024-12-27 21:30:19,399: Snapshot:3	Epoch:10	Loss:3.026	translation_Loss:1.764	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.262                                                   	MRR:27.06	Hits@10:46.05	Best:27.06
2024-12-27 21:30:23,178: Snapshot:3	Epoch:11	Loss:2.698	translation_Loss:1.406	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.291                                                   	MRR:27.65	Hits@10:46.79	Best:27.65
2024-12-27 21:30:26,935: Snapshot:3	Epoch:12	Loss:2.463	translation_Loss:1.156	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.307                                                   	MRR:28.11	Hits@10:47.23	Best:28.11
2024-12-27 21:30:30,695: Snapshot:3	Epoch:13	Loss:2.273	translation_Loss:0.959	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.314                                                   	MRR:28.58	Hits@10:47.36	Best:28.58
2024-12-27 21:30:34,438: Snapshot:3	Epoch:14	Loss:2.137	translation_Loss:0.822	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.315                                                   	MRR:29.03	Hits@10:47.54	Best:29.03
2024-12-27 21:30:38,138: Snapshot:3	Epoch:15	Loss:2.022	translation_Loss:0.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.311                                                   	MRR:29.29	Hits@10:48.0	Best:29.29
2024-12-27 21:30:41,874: Snapshot:3	Epoch:16	Loss:1.929	translation_Loss:0.628	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.301                                                   	MRR:29.67	Hits@10:48.05	Best:29.67
2024-12-27 21:30:45,659: Snapshot:3	Epoch:17	Loss:1.856	translation_Loss:0.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.289                                                   	MRR:29.82	Hits@10:48.2	Best:29.82
2024-12-27 21:30:49,400: Snapshot:3	Epoch:18	Loss:1.795	translation_Loss:0.522	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.274                                                   	MRR:29.77	Hits@10:48.3	Best:29.82
2024-12-27 21:30:53,150: Snapshot:3	Epoch:19	Loss:1.738	translation_Loss:0.482	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.256                                                   	MRR:30.01	Hits@10:48.42	Best:30.01
2024-12-27 21:30:56,884: Snapshot:3	Epoch:20	Loss:1.683	translation_Loss:0.445	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.238                                                   	MRR:30.06	Hits@10:48.29	Best:30.06
2024-12-27 21:31:00,533: Snapshot:3	Epoch:21	Loss:1.641	translation_Loss:0.421	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.219                                                   	MRR:29.96	Hits@10:48.3	Best:30.06
2024-12-27 21:31:04,226: Snapshot:3	Epoch:22	Loss:1.604	translation_Loss:0.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.201                                                   	MRR:30.03	Hits@10:48.34	Best:30.06
2024-12-27 21:31:07,974: Snapshot:3	Epoch:23	Loss:1.552	translation_Loss:0.369	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.183                                                   	MRR:30.09	Hits@10:48.5	Best:30.09
2024-12-27 21:31:11,621: Snapshot:3	Epoch:24	Loss:1.515	translation_Loss:0.353	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.162                                                   	MRR:29.95	Hits@10:48.48	Best:30.09
2024-12-27 21:31:15,352: Snapshot:3	Epoch:25	Loss:1.487	translation_Loss:0.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.141                                                   	MRR:30.21	Hits@10:48.37	Best:30.21
2024-12-27 21:31:19,597: Snapshot:3	Epoch:26	Loss:1.46	translation_Loss:0.337	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.124                                                   	MRR:30.19	Hits@10:48.4	Best:30.21
2024-12-27 21:31:23,358: Snapshot:3	Epoch:27	Loss:1.43	translation_Loss:0.323	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.106                                                   	MRR:30.26	Hits@10:48.44	Best:30.26
2024-12-27 21:31:27,095: Snapshot:3	Epoch:28	Loss:1.396	translation_Loss:0.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.089                                                   	MRR:30.41	Hits@10:48.58	Best:30.41
2024-12-27 21:31:30,828: Snapshot:3	Epoch:29	Loss:1.378	translation_Loss:0.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.071                                                   	MRR:30.67	Hits@10:48.44	Best:30.67
2024-12-27 21:31:34,565: Snapshot:3	Epoch:30	Loss:1.343	translation_Loss:0.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.054                                                   	MRR:30.74	Hits@10:48.63	Best:30.74
2024-12-27 21:31:38,299: Snapshot:3	Epoch:31	Loss:1.327	translation_Loss:0.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.037                                                   	MRR:30.59	Hits@10:48.29	Best:30.74
2024-12-27 21:31:42,044: Snapshot:3	Epoch:32	Loss:1.303	translation_Loss:0.281	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.022                                                   	MRR:30.81	Hits@10:48.34	Best:30.81
2024-12-27 21:31:45,767: Snapshot:3	Epoch:33	Loss:1.278	translation_Loss:0.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.008                                                   	MRR:30.6	Hits@10:48.24	Best:30.81
2024-12-27 21:31:49,428: Snapshot:3	Epoch:34	Loss:1.257	translation_Loss:0.265	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.992                                                   	MRR:30.67	Hits@10:48.26	Best:30.81
2024-12-27 21:31:53,080: Snapshot:3	Epoch:35	Loss:1.234	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.977                                                   	MRR:30.58	Hits@10:48.24	Best:30.81
2024-12-27 21:31:56,785: Snapshot:3	Epoch:36	Loss:1.22	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.963                                                   	MRR:30.62	Hits@10:48.0	Best:30.81
2024-12-27 21:32:00,414: Early Stopping! Snapshot: 3 Epoch: 37 Best Results: 30.81
2024-12-27 21:32:00,414: Start to training tokens! Snapshot: 3 Epoch: 37 Loss:1.204 MRR:30.6 Best Results: 30.81
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:32:00,415: Snapshot:3	Epoch:37	Loss:1.204	translation_Loss:0.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.949                                                   	MRR:30.6	Hits@10:48.14	Best:30.81
2024-12-27 21:32:04,011: Snapshot:3	Epoch:38	Loss:12.551	translation_Loss:11.967	multi_layer_Loss:0.584	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.6	Hits@10:48.14	Best:30.81
2024-12-27 21:32:07,634: End of token training: 3 Epoch: 39 Loss:12.256 MRR:30.6 Best Results: 30.81
2024-12-27 21:32:07,635: Snapshot:3	Epoch:39	Loss:12.256	translation_Loss:11.918	multi_layer_Loss:0.338	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.6	Hits@10:48.14	Best:30.81
2024-12-27 21:32:07,968: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_5000/3model_best.tar'
2024-12-27 21:32:23,105: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1862 | 0.0934 | 0.2326 | 0.2955 |  0.3631 |
|     1      | 0.1436 | 0.067  | 0.1706 | 0.223  |  0.289  |
|     2      | 0.1735 | 0.0971 | 0.1896 | 0.2379 |  0.3221 |
|     3      | 0.3096 | 0.2132 | 0.356  | 0.4109 |  0.4861 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 21:32:35,457: Snapshot:4	Epoch:0	Loss:10.617	translation_Loss:10.586	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.032                                                   	MRR:5.84	Hits@10:16.73	Best:5.84
2024-12-27 21:32:38,186: Snapshot:4	Epoch:1	Loss:8.274	translation_Loss:8.168	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.107                                                   	MRR:8.03	Hits@10:21.35	Best:8.03
2024-12-27 21:32:40,905: Snapshot:4	Epoch:2	Loss:6.621	translation_Loss:6.437	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.183                                                   	MRR:9.85	Hits@10:24.75	Best:9.85
2024-12-27 21:32:43,591: Snapshot:4	Epoch:3	Loss:5.359	translation_Loss:5.105	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.254                                                   	MRR:12.08	Hits@10:28.83	Best:12.08
2024-12-27 21:32:46,265: Snapshot:4	Epoch:4	Loss:4.404	translation_Loss:4.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.315                                                   	MRR:14.45	Hits@10:33.06	Best:14.45
2024-12-27 21:32:48,952: Snapshot:4	Epoch:5	Loss:3.646	translation_Loss:3.275	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.371                                                   	MRR:16.56	Hits@10:37.07	Best:16.56
2024-12-27 21:32:51,590: Snapshot:4	Epoch:6	Loss:3.044	translation_Loss:2.624	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.42                                                   	MRR:18.42	Hits@10:40.74	Best:18.42
2024-12-27 21:32:54,287: Snapshot:4	Epoch:7	Loss:2.566	translation_Loss:2.102	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.464                                                   	MRR:20.28	Hits@10:43.81	Best:20.28
2024-12-27 21:32:56,930: Snapshot:4	Epoch:8	Loss:2.203	translation_Loss:1.702	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.501                                                   	MRR:21.37	Hits@10:45.71	Best:21.37
2024-12-27 21:32:59,580: Snapshot:4	Epoch:9	Loss:1.907	translation_Loss:1.376	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.53                                                   	MRR:22.42	Hits@10:47.13	Best:22.42
2024-12-27 21:33:02,228: Snapshot:4	Epoch:10	Loss:1.66	translation_Loss:1.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.554                                                   	MRR:23.28	Hits@10:48.32	Best:23.28
2024-12-27 21:33:04,868: Snapshot:4	Epoch:11	Loss:1.444	translation_Loss:0.873	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.571                                                   	MRR:24.64	Hits@10:48.99	Best:24.64
2024-12-27 21:33:07,521: Snapshot:4	Epoch:12	Loss:1.25	translation_Loss:0.666	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.583                                                   	MRR:25.67	Hits@10:49.56	Best:25.67
2024-12-27 21:33:10,267: Snapshot:4	Epoch:13	Loss:1.103	translation_Loss:0.512	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.591                                                   	MRR:25.97	Hits@10:50.27	Best:25.97
2024-12-27 21:33:13,416: Snapshot:4	Epoch:14	Loss:1.017	translation_Loss:0.423	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.594                                                   	MRR:26.26	Hits@10:50.74	Best:26.26
2024-12-27 21:33:16,107: Snapshot:4	Epoch:15	Loss:0.955	translation_Loss:0.362	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.593                                                   	MRR:26.56	Hits@10:50.91	Best:26.56
2024-12-27 21:33:18,784: Snapshot:4	Epoch:16	Loss:0.896	translation_Loss:0.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.592                                                   	MRR:26.6	Hits@10:51.11	Best:26.6
2024-12-27 21:33:21,417: Snapshot:4	Epoch:17	Loss:0.872	translation_Loss:0.283	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.589                                                   	MRR:26.87	Hits@10:51.2	Best:26.87
2024-12-27 21:33:24,127: Snapshot:4	Epoch:18	Loss:0.835	translation_Loss:0.25	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.586                                                   	MRR:27.08	Hits@10:51.39	Best:27.08
2024-12-27 21:33:26,756: Snapshot:4	Epoch:19	Loss:0.8	translation_Loss:0.219	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.581                                                   	MRR:27.17	Hits@10:51.75	Best:27.17
2024-12-27 21:33:29,426: Snapshot:4	Epoch:20	Loss:0.783	translation_Loss:0.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.575                                                   	MRR:27.37	Hits@10:51.69	Best:27.37
2024-12-27 21:33:32,078: Snapshot:4	Epoch:21	Loss:0.765	translation_Loss:0.196	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.569                                                   	MRR:27.51	Hits@10:51.63	Best:27.51
2024-12-27 21:33:34,781: Snapshot:4	Epoch:22	Loss:0.737	translation_Loss:0.175	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.562                                                   	MRR:27.63	Hits@10:52.11	Best:27.63
2024-12-27 21:33:37,451: Snapshot:4	Epoch:23	Loss:0.729	translation_Loss:0.175	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.554                                                   	MRR:27.77	Hits@10:51.82	Best:27.77
2024-12-27 21:33:40,205: Snapshot:4	Epoch:24	Loss:0.71	translation_Loss:0.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.548                                                   	MRR:27.86	Hits@10:51.93	Best:27.86
2024-12-27 21:33:42,869: Snapshot:4	Epoch:25	Loss:0.696	translation_Loss:0.154	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.542                                                   	MRR:28.08	Hits@10:52.12	Best:28.08
2024-12-27 21:33:45,477: Snapshot:4	Epoch:26	Loss:0.681	translation_Loss:0.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.535                                                   	MRR:27.92	Hits@10:52.15	Best:28.08
2024-12-27 21:33:48,102: Snapshot:4	Epoch:27	Loss:0.672	translation_Loss:0.144	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.528                                                   	MRR:28.21	Hits@10:51.94	Best:28.21
2024-12-27 21:33:50,762: Snapshot:4	Epoch:28	Loss:0.655	translation_Loss:0.132	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.522                                                   	MRR:28.1	Hits@10:52.25	Best:28.21
2024-12-27 21:33:53,355: Snapshot:4	Epoch:29	Loss:0.642	translation_Loss:0.128	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.515                                                   	MRR:28.12	Hits@10:52.64	Best:28.21
2024-12-27 21:33:55,971: Snapshot:4	Epoch:30	Loss:0.63	translation_Loss:0.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.507                                                   	MRR:28.04	Hits@10:52.26	Best:28.21
2024-12-27 21:33:58,576: Snapshot:4	Epoch:31	Loss:0.621	translation_Loss:0.121	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.5                                                   	MRR:27.78	Hits@10:52.42	Best:28.21
2024-12-27 21:34:01,156: Early Stopping! Snapshot: 4 Epoch: 32 Best Results: 28.21
2024-12-27 21:34:01,156: Start to training tokens! Snapshot: 4 Epoch: 32 Loss:0.612 MRR:27.82 Best Results: 28.21
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:34:01,157: Snapshot:4	Epoch:32	Loss:0.612	translation_Loss:0.12	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.493                                                   	MRR:27.82	Hits@10:52.43	Best:28.21
2024-12-27 21:34:03,697: Snapshot:4	Epoch:33	Loss:6.87	translation_Loss:6.401	multi_layer_Loss:0.468	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.82	Hits@10:52.43	Best:28.21
2024-12-27 21:34:06,244: End of token training: 4 Epoch: 34 Loss:6.769 MRR:27.82 Best Results: 28.21
2024-12-27 21:34:06,244: Snapshot:4	Epoch:34	Loss:6.769	translation_Loss:6.428	multi_layer_Loss:0.341	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.82	Hits@10:52.43	Best:28.21
2024-12-27 21:34:06,600: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_5000/4model_best.tar'
2024-12-27 21:34:23,610: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.174  | 0.0885 | 0.217  | 0.2718 |  0.3309 |
|     1      | 0.1385 | 0.064  | 0.1635 | 0.213  |  0.2804 |
|     2      | 0.162  | 0.0914 | 0.1755 | 0.2232 |  0.3001 |
|     3      | 0.2607 | 0.1773 | 0.2956 | 0.3364 |  0.4106 |
|     4      | 0.2771 | 0.1565 | 0.3181 | 0.4036 |  0.5235 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 21:34:23,613: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2773 | 0.1653 | 0.3431 | 0.4128 |  0.4843 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2264 | 0.1186 | 0.2852 | 0.3524 |  0.4268 |
|     1      | 0.1794 | 0.0923 | 0.2147 | 0.273  |  0.3459 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1904 | 0.0948 | 0.2402 | 0.3026 |  0.3711 |
|     1      | 0.1512 | 0.0736 | 0.1804 | 0.2309 |  0.299  |
|     2      | 0.2327 | 0.1421 | 0.2619 | 0.3211 |  0.4126 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1862 | 0.0934 | 0.2326 | 0.2955 |  0.3631 |
|     1      | 0.1436 | 0.067  | 0.1706 | 0.223  |  0.289  |
|     2      | 0.1735 | 0.0971 | 0.1896 | 0.2379 |  0.3221 |
|     3      | 0.3096 | 0.2132 | 0.356  | 0.4109 |  0.4861 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.174  | 0.0885 | 0.217  | 0.2718 |  0.3309 |
|     1      | 0.1385 | 0.064  | 0.1635 | 0.213  |  0.2804 |
|     2      | 0.162  | 0.0914 | 0.1755 | 0.2232 |  0.3001 |
|     3      | 0.2607 | 0.1773 | 0.2956 | 0.3364 |  0.4106 |
|     4      | 0.2771 | 0.1565 | 0.3181 | 0.4036 |  0.5235 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 21:34:23,614: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 511.61528635025024 |   0.277   |    0.165     |    0.343     |     0.484     |
|    1     | 236.65656185150146 |   0.204   |    0.106     |    0.251     |     0.387     |
|    2     | 257.90104722976685 |   0.187   |    0.099     |    0.224     |     0.356     |
|    3     | 159.33786582946777 |   0.182   |    0.098     |    0.215     |     0.342     |
|    4     | 101.64326930046082 |   0.176   |    0.095     |    0.207     |      0.33     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 21:34:23,614: Sum_Training_Time:1267.1540305614471
2024-12-27 21:34:23,614: Every_Training_Time:[511.61528635025024, 236.65656185150146, 257.90104722976685, 159.33786582946777, 101.64326930046082]
2024-12-27 21:34:23,614: Forward transfer: 0.018874999999999996 Backward transfer: -0.06595
2024-12-27 21:35:01,131: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='1024', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.0001, lifelong_name='double_tokened', log_path='./logs/20241227213427/RELATIONrelation_0.0001_1024_10000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.0001_1024_10000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.0001_1024_10000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 21:35:17,146: Snapshot:0	Epoch:0	Loss:79.901	translation_Loss:79.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.65	Hits@10:9.44	Best:4.65
2024-12-27 21:35:28,658: Snapshot:0	Epoch:1	Loss:71.045	translation_Loss:71.045	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.6	Hits@10:18.87	Best:8.6
2024-12-27 21:35:40,107: Snapshot:0	Epoch:2	Loss:63.624	translation_Loss:63.624	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.67	Hits@10:22.36	Best:9.67
2024-12-27 21:35:51,674: Snapshot:0	Epoch:3	Loss:56.95	translation_Loss:56.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.75	Hits@10:25.62	Best:10.75
2024-12-27 21:36:03,198: Snapshot:0	Epoch:4	Loss:50.574	translation_Loss:50.574	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.68	Hits@10:29.8	Best:12.68
2024-12-27 21:36:14,751: Snapshot:0	Epoch:5	Loss:44.361	translation_Loss:44.361	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.15	Hits@10:34.31	Best:15.15
2024-12-27 21:36:26,701: Snapshot:0	Epoch:6	Loss:38.303	translation_Loss:38.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.43	Hits@10:37.65	Best:17.43
2024-12-27 21:36:38,181: Snapshot:0	Epoch:7	Loss:32.599	translation_Loss:32.599	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.32	Hits@10:40.1	Best:19.32
2024-12-27 21:36:49,603: Snapshot:0	Epoch:8	Loss:27.616	translation_Loss:27.616	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.76	Hits@10:41.84	Best:20.76
2024-12-27 21:37:01,188: Snapshot:0	Epoch:9	Loss:23.298	translation_Loss:23.298	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.96	Hits@10:43.22	Best:21.96
2024-12-27 21:37:12,780: Snapshot:0	Epoch:10	Loss:19.669	translation_Loss:19.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.87	Hits@10:44.12	Best:22.87
2024-12-27 21:37:24,318: Snapshot:0	Epoch:11	Loss:16.592	translation_Loss:16.592	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.69	Hits@10:45.07	Best:23.69
2024-12-27 21:37:36,436: Snapshot:0	Epoch:12	Loss:13.989	translation_Loss:13.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.33	Hits@10:45.77	Best:24.33
2024-12-27 21:37:47,952: Snapshot:0	Epoch:13	Loss:11.891	translation_Loss:11.891	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.87	Hits@10:46.22	Best:24.87
2024-12-27 21:37:59,441: Snapshot:0	Epoch:14	Loss:10.107	translation_Loss:10.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.33	Hits@10:46.64	Best:25.33
2024-12-27 21:38:11,000: Snapshot:0	Epoch:15	Loss:8.72	translation_Loss:8.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.76	Hits@10:46.92	Best:25.76
2024-12-27 21:38:22,466: Snapshot:0	Epoch:16	Loss:7.515	translation_Loss:7.515	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.11	Hits@10:47.22	Best:26.11
2024-12-27 21:38:33,949: Snapshot:0	Epoch:17	Loss:6.527	translation_Loss:6.527	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.37	Hits@10:47.47	Best:26.37
2024-12-27 21:38:45,510: Snapshot:0	Epoch:18	Loss:5.78	translation_Loss:5.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.58	Hits@10:47.63	Best:26.58
2024-12-27 21:38:57,119: Snapshot:0	Epoch:19	Loss:5.138	translation_Loss:5.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.68	Hits@10:47.9	Best:26.68
2024-12-27 21:39:08,598: Snapshot:0	Epoch:20	Loss:4.631	translation_Loss:4.631	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.75	Hits@10:47.98	Best:26.75
2024-12-27 21:39:20,145: Snapshot:0	Epoch:21	Loss:4.18	translation_Loss:4.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.89	Hits@10:47.98	Best:26.89
2024-12-27 21:39:31,660: Snapshot:0	Epoch:22	Loss:3.825	translation_Loss:3.825	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.95	Hits@10:48.04	Best:26.95
2024-12-27 21:39:43,256: Snapshot:0	Epoch:23	Loss:3.545	translation_Loss:3.545	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.11	Hits@10:48.08	Best:27.11
2024-12-27 21:39:54,731: Snapshot:0	Epoch:24	Loss:3.276	translation_Loss:3.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.18	Hits@10:48.11	Best:27.18
2024-12-27 21:40:06,838: Snapshot:0	Epoch:25	Loss:3.061	translation_Loss:3.061	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.23	Hits@10:48.09	Best:27.23
2024-12-27 21:40:18,298: Snapshot:0	Epoch:26	Loss:2.852	translation_Loss:2.852	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.31	Hits@10:48.2	Best:27.31
2024-12-27 21:40:29,693: Snapshot:0	Epoch:27	Loss:2.7	translation_Loss:2.7	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.29	Hits@10:48.28	Best:27.31
2024-12-27 21:40:41,270: Snapshot:0	Epoch:28	Loss:2.543	translation_Loss:2.543	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.4	Hits@10:48.25	Best:27.4
2024-12-27 21:40:52,713: Snapshot:0	Epoch:29	Loss:2.431	translation_Loss:2.431	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.36	Hits@10:48.28	Best:27.4
2024-12-27 21:41:04,205: Snapshot:0	Epoch:30	Loss:2.296	translation_Loss:2.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.32	Hits@10:48.22	Best:27.4
2024-12-27 21:41:16,226: Snapshot:0	Epoch:31	Loss:2.211	translation_Loss:2.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.33	Hits@10:48.25	Best:27.4
2024-12-27 21:41:27,771: Snapshot:0	Epoch:32	Loss:2.117	translation_Loss:2.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.44	Hits@10:48.25	Best:27.44
2024-12-27 21:41:39,209: Snapshot:0	Epoch:33	Loss:2.047	translation_Loss:2.047	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.39	Hits@10:48.11	Best:27.44
2024-12-27 21:41:50,728: Snapshot:0	Epoch:34	Loss:1.943	translation_Loss:1.943	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.4	Hits@10:48.13	Best:27.44
2024-12-27 21:42:02,212: Snapshot:0	Epoch:35	Loss:1.888	translation_Loss:1.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.41	Hits@10:48.13	Best:27.44
2024-12-27 21:42:13,704: Snapshot:0	Epoch:36	Loss:1.843	translation_Loss:1.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.46	Hits@10:48.08	Best:27.46
2024-12-27 21:42:25,188: Snapshot:0	Epoch:37	Loss:1.762	translation_Loss:1.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.51	Hits@10:48.05	Best:27.51
2024-12-27 21:42:36,634: Snapshot:0	Epoch:38	Loss:1.706	translation_Loss:1.706	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.54	Hits@10:48.22	Best:27.54
2024-12-27 21:42:48,125: Snapshot:0	Epoch:39	Loss:1.673	translation_Loss:1.673	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.37	Hits@10:47.98	Best:27.54
2024-12-27 21:42:59,636: Snapshot:0	Epoch:40	Loss:1.608	translation_Loss:1.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.4	Hits@10:48.11	Best:27.54
2024-12-27 21:43:11,180: Snapshot:0	Epoch:41	Loss:1.582	translation_Loss:1.582	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.38	Hits@10:47.99	Best:27.54
2024-12-27 21:43:22,766: Snapshot:0	Epoch:42	Loss:1.569	translation_Loss:1.569	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.33	Hits@10:47.82	Best:27.54
2024-12-27 21:43:34,779: Early Stopping! Snapshot: 0 Epoch: 43 Best Results: 27.54
2024-12-27 21:43:34,779: Start to training tokens! Snapshot: 0 Epoch: 43 Loss:1.52 MRR:27.5 Best Results: 27.54
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:43:34,780: Snapshot:0	Epoch:43	Loss:1.52	translation_Loss:1.52	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.5	Hits@10:47.83	Best:27.54
2024-12-27 21:43:46,911: Snapshot:0	Epoch:44	Loss:51.108	translation_Loss:49.913	multi_layer_Loss:1.195	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.5	Hits@10:47.83	Best:27.54
2024-12-27 21:43:58,496: End of token training: 0 Epoch: 45 Loss:49.981 MRR:27.5 Best Results: 27.54
2024-12-27 21:43:58,496: Snapshot:0	Epoch:45	Loss:49.981	translation_Loss:49.897	multi_layer_Loss:0.085	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.5	Hits@10:47.83	Best:27.54
2024-12-27 21:43:58,799: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_10000/0model_best.tar'
2024-12-27 21:44:04,068: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2764 | 0.1642 | 0.3434 | 0.4134 |  0.4841 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 21:44:40,991: Snapshot:1	Epoch:0	Loss:72.225	translation_Loss:71.618	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.607                                                   	MRR:3.3	Hits@10:9.2	Best:3.3
2024-12-27 21:44:51,715: Snapshot:1	Epoch:1	Loss:58.611	translation_Loss:56.826	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.785                                                   	MRR:6.86	Hits@10:17.2	Best:6.86
2024-12-27 21:45:02,570: Snapshot:1	Epoch:2	Loss:48.124	translation_Loss:45.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.943                                                   	MRR:9.8	Hits@10:21.98	Best:9.8
2024-12-27 21:45:13,472: Snapshot:1	Epoch:3	Loss:39.748	translation_Loss:35.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.834                                                   	MRR:11.82	Hits@10:25.99	Best:11.82
2024-12-27 21:45:24,203: Snapshot:1	Epoch:4	Loss:33.083	translation_Loss:28.627	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.456                                                   	MRR:13.53	Hits@10:28.54	Best:13.53
2024-12-27 21:45:35,117: Snapshot:1	Epoch:5	Loss:27.835	translation_Loss:22.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.862                                                   	MRR:14.82	Hits@10:30.25	Best:14.82
2024-12-27 21:45:46,088: Snapshot:1	Epoch:6	Loss:23.85	translation_Loss:18.732	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.118                                                   	MRR:15.56	Hits@10:31.24	Best:15.56
2024-12-27 21:45:56,951: Snapshot:1	Epoch:7	Loss:20.883	translation_Loss:15.625	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.258                                                   	MRR:15.98	Hits@10:31.69	Best:15.98
2024-12-27 21:46:07,779: Snapshot:1	Epoch:8	Loss:18.741	translation_Loss:13.429	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.312                                                   	MRR:16.09	Hits@10:31.93	Best:16.09
2024-12-27 21:46:18,667: Snapshot:1	Epoch:9	Loss:17.168	translation_Loss:11.855	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.313                                                   	MRR:16.13	Hits@10:32.03	Best:16.13
2024-12-27 21:46:29,738: Snapshot:1	Epoch:10	Loss:15.993	translation_Loss:10.706	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.287                                                   	MRR:16.26	Hits@10:32.15	Best:16.26
2024-12-27 21:46:40,415: Snapshot:1	Epoch:11	Loss:15.133	translation_Loss:9.895	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.238                                                   	MRR:16.22	Hits@10:32.15	Best:16.26
2024-12-27 21:46:51,185: Snapshot:1	Epoch:12	Loss:14.442	translation_Loss:9.26	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.182                                                   	MRR:16.27	Hits@10:32.2	Best:16.27
2024-12-27 21:47:01,980: Snapshot:1	Epoch:13	Loss:13.894	translation_Loss:8.765	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.129                                                   	MRR:16.18	Hits@10:32.19	Best:16.27
2024-12-27 21:47:12,711: Snapshot:1	Epoch:14	Loss:13.523	translation_Loss:8.458	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.065                                                   	MRR:16.25	Hits@10:31.99	Best:16.27
2024-12-27 21:47:23,405: Snapshot:1	Epoch:15	Loss:13.198	translation_Loss:8.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.004                                                   	MRR:16.27	Hits@10:32.08	Best:16.27
2024-12-27 21:47:34,218: Snapshot:1	Epoch:16	Loss:12.936	translation_Loss:7.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.967                                                   	MRR:16.23	Hits@10:31.95	Best:16.27
2024-12-27 21:47:44,931: Early Stopping! Snapshot: 1 Epoch: 17 Best Results: 16.27
2024-12-27 21:47:44,931: Start to training tokens! Snapshot: 1 Epoch: 17 Loss:12.732 MRR:16.17 Best Results: 16.27
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:47:44,932: Snapshot:1	Epoch:17	Loss:12.732	translation_Loss:7.811	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.92                                                   	MRR:16.17	Hits@10:32.04	Best:16.27
2024-12-27 21:47:55,406: Snapshot:1	Epoch:18	Loss:58.861	translation_Loss:57.677	multi_layer_Loss:1.185	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.17	Hits@10:32.04	Best:16.27
2024-12-27 21:48:05,907: End of token training: 1 Epoch: 19 Loss:57.743 MRR:16.17 Best Results: 16.27
2024-12-27 21:48:05,907: Snapshot:1	Epoch:19	Loss:57.743	translation_Loss:57.647	multi_layer_Loss:0.096	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:16.17	Hits@10:32.04	Best:16.27
2024-12-27 21:48:06,283: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_10000/1model_best.tar'
2024-12-27 21:48:16,234: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2414 | 0.1307 | 0.3046 | 0.3736 |  0.4477 |
|     1      | 0.1633 | 0.0818 | 0.1929 | 0.2493 |  0.3207 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 21:48:43,955: Snapshot:2	Epoch:0	Loss:48.573	translation_Loss:48.081	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.492                                                   	MRR:1.62	Hits@10:4.22	Best:1.62
2024-12-27 21:48:52,136: Snapshot:2	Epoch:1	Loss:31.826	translation_Loss:30.029	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.796                                                   	MRR:8.41	Hits@10:19.69	Best:8.41
2024-12-27 21:49:00,320: Snapshot:2	Epoch:2	Loss:21.819	translation_Loss:18.747	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.072                                                   	MRR:14.32	Hits@10:30.61	Best:14.32
2024-12-27 21:49:08,446: Snapshot:2	Epoch:3	Loss:17.281	translation_Loss:13.55	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.731                                                   	MRR:17.93	Hits@10:34.77	Best:17.93
2024-12-27 21:49:16,616: Snapshot:2	Epoch:4	Loss:14.788	translation_Loss:10.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.069                                                   	MRR:19.85	Hits@10:37.61	Best:19.85
2024-12-27 21:49:24,616: Snapshot:2	Epoch:5	Loss:13.073	translation_Loss:8.847	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.226                                                   	MRR:20.72	Hits@10:38.7	Best:20.72
2024-12-27 21:49:32,659: Snapshot:2	Epoch:6	Loss:11.859	translation_Loss:7.577	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.282                                                   	MRR:21.35	Hits@10:39.48	Best:21.35
2024-12-27 21:49:40,764: Snapshot:2	Epoch:7	Loss:10.868	translation_Loss:6.614	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.254                                                   	MRR:21.99	Hits@10:40.01	Best:21.99
2024-12-27 21:49:48,791: Snapshot:2	Epoch:8	Loss:10.091	translation_Loss:5.91	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.181                                                   	MRR:22.16	Hits@10:40.42	Best:22.16
2024-12-27 21:49:56,852: Snapshot:2	Epoch:9	Loss:9.43	translation_Loss:5.35	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.08                                                   	MRR:22.37	Hits@10:40.64	Best:22.37
2024-12-27 21:50:05,027: Snapshot:2	Epoch:10	Loss:8.853	translation_Loss:4.887	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.967                                                   	MRR:22.5	Hits@10:40.61	Best:22.5
2024-12-27 21:50:13,111: Snapshot:2	Epoch:11	Loss:8.352	translation_Loss:4.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.846                                                   	MRR:22.8	Hits@10:41.03	Best:22.8
2024-12-27 21:50:21,116: Snapshot:2	Epoch:12	Loss:7.938	translation_Loss:4.212	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.726                                                   	MRR:22.67	Hits@10:40.77	Best:22.8
2024-12-27 21:50:29,084: Snapshot:2	Epoch:13	Loss:7.537	translation_Loss:3.938	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.599                                                   	MRR:22.63	Hits@10:40.86	Best:22.8
2024-12-27 21:50:37,087: Snapshot:2	Epoch:14	Loss:7.226	translation_Loss:3.743	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.483                                                   	MRR:22.7	Hits@10:40.44	Best:22.8
2024-12-27 21:50:45,095: Snapshot:2	Epoch:15	Loss:6.96	translation_Loss:3.581	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.379                                                   	MRR:22.69	Hits@10:40.34	Best:22.8
2024-12-27 21:50:53,063: Early Stopping! Snapshot: 2 Epoch: 16 Best Results: 22.8
2024-12-27 21:50:53,064: Start to training tokens! Snapshot: 2 Epoch: 16 Loss:6.709 MRR:22.5 Best Results: 22.8
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:50:53,064: Snapshot:2	Epoch:16	Loss:6.709	translation_Loss:3.431	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.278                                                   	MRR:22.5	Hits@10:40.28	Best:22.8
2024-12-27 21:51:00,929: Snapshot:2	Epoch:17	Loss:38.79	translation_Loss:37.718	multi_layer_Loss:1.071	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.5	Hits@10:40.28	Best:22.8
2024-12-27 21:51:09,251: End of token training: 2 Epoch: 18 Loss:37.964 MRR:22.5 Best Results: 22.8
2024-12-27 21:51:09,251: Snapshot:2	Epoch:18	Loss:37.964	translation_Loss:37.717	multi_layer_Loss:0.247	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.5	Hits@10:40.28	Best:22.8
2024-12-27 21:51:09,602: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_10000/2model_best.tar'
2024-12-27 21:51:22,543: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2014 | 0.1031 | 0.2554 | 0.3186 |  0.3849 |
|     1      | 0.1358 | 0.0633 | 0.1623 | 0.2119 |  0.2763 |
|     2      | 0.2242 | 0.1351 | 0.2503 | 0.3107 |  0.4031 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 21:51:38,056: Snapshot:3	Epoch:0	Loss:20.691	translation_Loss:20.599	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:2.73	Hits@10:6.48	Best:2.73
2024-12-27 21:51:41,766: Snapshot:3	Epoch:1	Loss:17.089	translation_Loss:16.829	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.26                                                   	MRR:5.59	Hits@10:12.32	Best:5.59
2024-12-27 21:51:45,522: Snapshot:3	Epoch:2	Loss:14.359	translation_Loss:13.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.467                                                   	MRR:8.72	Hits@10:18.62	Best:8.72
2024-12-27 21:51:49,254: Snapshot:3	Epoch:3	Loss:12.167	translation_Loss:11.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.695                                                   	MRR:12.29	Hits@10:26.99	Best:12.29
2024-12-27 21:51:53,110: Snapshot:3	Epoch:4	Loss:10.287	translation_Loss:9.36	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.927                                                   	MRR:16.18	Hits@10:34.68	Best:16.18
2024-12-27 21:51:56,850: Snapshot:3	Epoch:5	Loss:8.689	translation_Loss:7.538	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.15                                                   	MRR:19.18	Hits@10:38.6	Best:19.18
2024-12-27 21:52:00,606: Snapshot:3	Epoch:6	Loss:7.409	translation_Loss:6.063	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.346                                                   	MRR:21.49	Hits@10:41.33	Best:21.49
2024-12-27 21:52:04,392: Snapshot:3	Epoch:7	Loss:6.374	translation_Loss:4.869	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.505                                                   	MRR:23.03	Hits@10:43.03	Best:23.03
2024-12-27 21:52:08,110: Snapshot:3	Epoch:8	Loss:5.554	translation_Loss:3.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.625                                                   	MRR:24.11	Hits@10:44.0	Best:24.11
2024-12-27 21:52:12,331: Snapshot:3	Epoch:9	Loss:4.941	translation_Loss:3.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.71                                                   	MRR:25.06	Hits@10:44.71	Best:25.06
2024-12-27 21:52:16,144: Snapshot:3	Epoch:10	Loss:4.447	translation_Loss:2.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.767                                                   	MRR:26.09	Hits@10:45.31	Best:26.09
2024-12-27 21:52:19,866: Snapshot:3	Epoch:11	Loss:4.063	translation_Loss:2.263	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.801                                                   	MRR:26.82	Hits@10:45.8	Best:26.82
2024-12-27 21:52:23,679: Snapshot:3	Epoch:12	Loss:3.8	translation_Loss:1.982	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.818                                                   	MRR:27.31	Hits@10:46.33	Best:27.31
2024-12-27 21:52:27,436: Snapshot:3	Epoch:13	Loss:3.574	translation_Loss:1.749	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.825                                                   	MRR:27.86	Hits@10:46.29	Best:27.86
2024-12-27 21:52:31,207: Snapshot:3	Epoch:14	Loss:3.391	translation_Loss:1.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.824                                                   	MRR:28.09	Hits@10:46.55	Best:28.09
2024-12-27 21:52:35,026: Snapshot:3	Epoch:15	Loss:3.233	translation_Loss:1.418	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.815                                                   	MRR:28.42	Hits@10:46.74	Best:28.42
2024-12-27 21:52:38,737: Snapshot:3	Epoch:16	Loss:3.103	translation_Loss:1.301	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.802                                                   	MRR:28.65	Hits@10:46.76	Best:28.65
2024-12-27 21:52:42,470: Snapshot:3	Epoch:17	Loss:2.983	translation_Loss:1.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.788                                                   	MRR:28.67	Hits@10:46.69	Best:28.67
2024-12-27 21:52:46,182: Snapshot:3	Epoch:18	Loss:2.885	translation_Loss:1.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.768                                                   	MRR:28.74	Hits@10:46.66	Best:28.74
2024-12-27 21:52:49,907: Snapshot:3	Epoch:19	Loss:2.793	translation_Loss:1.044	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.749                                                   	MRR:28.83	Hits@10:46.84	Best:28.83
2024-12-27 21:52:53,722: Snapshot:3	Epoch:20	Loss:2.707	translation_Loss:0.982	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.725                                                   	MRR:29.0	Hits@10:46.88	Best:29.0
2024-12-27 21:52:57,440: Snapshot:3	Epoch:21	Loss:2.63	translation_Loss:0.931	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.699                                                   	MRR:28.91	Hits@10:46.96	Best:29.0
2024-12-27 21:53:01,193: Snapshot:3	Epoch:22	Loss:2.56	translation_Loss:0.883	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.677                                                   	MRR:29.13	Hits@10:47.0	Best:29.13
2024-12-27 21:53:04,939: Snapshot:3	Epoch:23	Loss:2.489	translation_Loss:0.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.651                                                   	MRR:29.07	Hits@10:46.99	Best:29.13
2024-12-27 21:53:08,635: Snapshot:3	Epoch:24	Loss:2.44	translation_Loss:0.815	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.625                                                   	MRR:29.1	Hits@10:46.97	Best:29.13
2024-12-27 21:53:12,403: Snapshot:3	Epoch:25	Loss:2.386	translation_Loss:0.779	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.607                                                   	MRR:29.15	Hits@10:46.9	Best:29.15
2024-12-27 21:53:16,160: Snapshot:3	Epoch:26	Loss:2.332	translation_Loss:0.753	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.579                                                   	MRR:29.37	Hits@10:47.05	Best:29.37
2024-12-27 21:53:19,840: Snapshot:3	Epoch:27	Loss:2.289	translation_Loss:0.732	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.557                                                   	MRR:29.35	Hits@10:46.92	Best:29.37
2024-12-27 21:53:23,629: Snapshot:3	Epoch:28	Loss:2.241	translation_Loss:0.708	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.533                                                   	MRR:29.49	Hits@10:47.06	Best:29.49
2024-12-27 21:53:27,398: Snapshot:3	Epoch:29	Loss:2.189	translation_Loss:0.677	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.512                                                   	MRR:29.42	Hits@10:46.88	Best:29.49
2024-12-27 21:53:31,687: Snapshot:3	Epoch:30	Loss:2.154	translation_Loss:0.667	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.487                                                   	MRR:29.47	Hits@10:46.86	Best:29.49
2024-12-27 21:53:35,430: Snapshot:3	Epoch:31	Loss:2.109	translation_Loss:0.642	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.467                                                   	MRR:29.73	Hits@10:46.91	Best:29.73
2024-12-27 21:53:39,184: Snapshot:3	Epoch:32	Loss:2.076	translation_Loss:0.628	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.448                                                   	MRR:29.73	Hits@10:46.82	Best:29.73
2024-12-27 21:53:42,897: Snapshot:3	Epoch:33	Loss:2.047	translation_Loss:0.619	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.427                                                   	MRR:29.67	Hits@10:46.88	Best:29.73
2024-12-27 21:53:46,548: Snapshot:3	Epoch:34	Loss:2.007	translation_Loss:0.599	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.408                                                   	MRR:29.67	Hits@10:46.95	Best:29.73
2024-12-27 21:53:50,307: Snapshot:3	Epoch:35	Loss:1.975	translation_Loss:0.587	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.388                                                   	MRR:29.75	Hits@10:47.02	Best:29.75
2024-12-27 21:53:53,995: Snapshot:3	Epoch:36	Loss:1.947	translation_Loss:0.577	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.37                                                   	MRR:29.63	Hits@10:46.67	Best:29.75
2024-12-27 21:53:57,671: Snapshot:3	Epoch:37	Loss:1.921	translation_Loss:0.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.354                                                   	MRR:29.64	Hits@10:46.75	Best:29.75
2024-12-27 21:54:01,374: Snapshot:3	Epoch:38	Loss:1.906	translation_Loss:0.566	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.341                                                   	MRR:29.64	Hits@10:46.68	Best:29.75
2024-12-27 21:54:05,068: Snapshot:3	Epoch:39	Loss:1.878	translation_Loss:0.554	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.325                                                   	MRR:29.56	Hits@10:46.57	Best:29.75
2024-12-27 21:54:08,785: Early Stopping! Snapshot: 3 Epoch: 40 Best Results: 29.75
2024-12-27 21:54:08,785: Start to training tokens! Snapshot: 3 Epoch: 40 Loss:1.846 MRR:29.59 Best Results: 29.75
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:54:08,786: Snapshot:3	Epoch:40	Loss:1.846	translation_Loss:0.538	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.308                                                   	MRR:29.59	Hits@10:46.68	Best:29.75
2024-12-27 21:54:12,386: Snapshot:3	Epoch:41	Loss:14.163	translation_Loss:13.578	multi_layer_Loss:0.584	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:29.59	Hits@10:46.68	Best:29.75
2024-12-27 21:54:15,975: End of token training: 3 Epoch: 42 Loss:13.907 MRR:29.59 Best Results: 29.75
2024-12-27 21:54:15,975: Snapshot:3	Epoch:42	Loss:13.907	translation_Loss:13.569	multi_layer_Loss:0.338	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:29.59	Hits@10:46.68	Best:29.75
2024-12-27 21:54:16,286: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_10000/3model_best.tar'
2024-12-27 21:54:31,756: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.198  | 0.1014 | 0.2506 | 0.3125 |  0.378  |
|     1      | 0.1329 | 0.061  | 0.1581 | 0.2066 |  0.2735 |
|     2      | 0.1706 | 0.0894 | 0.1882 | 0.2412 |  0.3289 |
|     3      | 0.3001 | 0.2064 | 0.3422 | 0.3997 |  0.4735 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 21:54:44,149: Snapshot:4	Epoch:0	Loss:11.374	translation_Loss:11.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.056                                                   	MRR:5.41	Hits@10:15.58	Best:5.41
2024-12-27 21:54:46,822: Snapshot:4	Epoch:1	Loss:9.075	translation_Loss:8.907	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:7.51	Hits@10:20.47	Best:7.51
2024-12-27 21:54:49,503: Snapshot:4	Epoch:2	Loss:7.395	translation_Loss:7.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.277                                                   	MRR:9.54	Hits@10:23.74	Best:9.54
2024-12-27 21:54:52,179: Snapshot:4	Epoch:3	Loss:6.167	translation_Loss:5.784	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.383                                                   	MRR:11.27	Hits@10:27.21	Best:11.27
2024-12-27 21:54:54,868: Snapshot:4	Epoch:4	Loss:5.197	translation_Loss:4.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.483                                                   	MRR:13.42	Hits@10:31.64	Best:13.42
2024-12-27 21:54:57,524: Snapshot:4	Epoch:5	Loss:4.44	translation_Loss:3.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.577                                                   	MRR:15.59	Hits@10:35.59	Best:15.59
2024-12-27 21:55:00,206: Snapshot:4	Epoch:6	Loss:3.838	translation_Loss:3.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.662                                                   	MRR:17.47	Hits@10:38.97	Best:17.47
2024-12-27 21:55:02,889: Snapshot:4	Epoch:7	Loss:3.353	translation_Loss:2.616	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.737                                                   	MRR:19.11	Hits@10:41.47	Best:19.11
2024-12-27 21:55:05,575: Snapshot:4	Epoch:8	Loss:2.975	translation_Loss:2.175	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.8                                                   	MRR:20.51	Hits@10:44.0	Best:20.51
2024-12-27 21:55:08,270: Snapshot:4	Epoch:9	Loss:2.659	translation_Loss:1.81	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.849                                                   	MRR:21.27	Hits@10:45.52	Best:21.27
2024-12-27 21:55:10,985: Snapshot:4	Epoch:10	Loss:2.401	translation_Loss:1.514	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.887                                                   	MRR:22.2	Hits@10:46.8	Best:22.2
2024-12-27 21:55:13,644: Snapshot:4	Epoch:11	Loss:2.17	translation_Loss:1.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.916                                                   	MRR:23.51	Hits@10:47.53	Best:23.51
2024-12-27 21:55:16,322: Snapshot:4	Epoch:12	Loss:1.949	translation_Loss:1.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.938                                                   	MRR:24.52	Hits@10:48.59	Best:24.52
2024-12-27 21:55:19,032: Snapshot:4	Epoch:13	Loss:1.773	translation_Loss:0.824	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.949                                                   	MRR:25.36	Hits@10:49.44	Best:25.36
2024-12-27 21:55:21,717: Snapshot:4	Epoch:14	Loss:1.673	translation_Loss:0.718	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.955                                                   	MRR:25.71	Hits@10:49.25	Best:25.71
2024-12-27 21:55:24,408: Snapshot:4	Epoch:15	Loss:1.571	translation_Loss:0.615	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.956                                                   	MRR:25.8	Hits@10:49.42	Best:25.8
2024-12-27 21:55:27,090: Snapshot:4	Epoch:16	Loss:1.515	translation_Loss:0.561	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.953                                                   	MRR:26.37	Hits@10:49.93	Best:26.37
2024-12-27 21:55:29,760: Snapshot:4	Epoch:17	Loss:1.449	translation_Loss:0.501	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.948                                                   	MRR:26.6	Hits@10:50.25	Best:26.6
2024-12-27 21:55:32,478: Snapshot:4	Epoch:18	Loss:1.402	translation_Loss:0.462	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.94                                                   	MRR:26.71	Hits@10:50.63	Best:26.71
2024-12-27 21:55:35,151: Snapshot:4	Epoch:19	Loss:1.356	translation_Loss:0.425	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.931                                                   	MRR:27.0	Hits@10:50.68	Best:27.0
2024-12-27 21:55:37,850: Snapshot:4	Epoch:20	Loss:1.315	translation_Loss:0.396	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.919                                                   	MRR:27.12	Hits@10:50.59	Best:27.12
2024-12-27 21:55:40,553: Snapshot:4	Epoch:21	Loss:1.279	translation_Loss:0.371	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.908                                                   	MRR:27.17	Hits@10:50.44	Best:27.17
2024-12-27 21:55:43,246: Snapshot:4	Epoch:22	Loss:1.24	translation_Loss:0.345	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.895                                                   	MRR:27.37	Hits@10:50.75	Best:27.37
2024-12-27 21:55:46,437: Snapshot:4	Epoch:23	Loss:1.207	translation_Loss:0.325	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.882                                                   	MRR:27.62	Hits@10:50.86	Best:27.62
2024-12-27 21:55:49,110: Snapshot:4	Epoch:24	Loss:1.184	translation_Loss:0.316	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.868                                                   	MRR:27.63	Hits@10:51.1	Best:27.63
2024-12-27 21:55:51,789: Snapshot:4	Epoch:25	Loss:1.16	translation_Loss:0.304	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.856                                                   	MRR:27.61	Hits@10:51.52	Best:27.63
2024-12-27 21:55:54,390: Snapshot:4	Epoch:26	Loss:1.136	translation_Loss:0.292	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.844                                                   	MRR:27.54	Hits@10:51.92	Best:27.63
2024-12-27 21:55:57,054: Snapshot:4	Epoch:27	Loss:1.109	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.831                                                   	MRR:27.66	Hits@10:51.9	Best:27.66
2024-12-27 21:55:59,733: Snapshot:4	Epoch:28	Loss:1.091	translation_Loss:0.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.818                                                   	MRR:27.84	Hits@10:52.19	Best:27.84
2024-12-27 21:56:02,453: Snapshot:4	Epoch:29	Loss:1.061	translation_Loss:0.256	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.805                                                   	MRR:28.01	Hits@10:51.9	Best:28.01
2024-12-27 21:56:05,136: Snapshot:4	Epoch:30	Loss:1.038	translation_Loss:0.248	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.79                                                   	MRR:28.06	Hits@10:51.5	Best:28.06
2024-12-27 21:56:07,828: Snapshot:4	Epoch:31	Loss:1.017	translation_Loss:0.238	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.778                                                   	MRR:28.15	Hits@10:51.53	Best:28.15
2024-12-27 21:56:10,538: Snapshot:4	Epoch:32	Loss:1.001	translation_Loss:0.236	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.765                                                   	MRR:28.27	Hits@10:52.01	Best:28.27
2024-12-27 21:56:13,208: Snapshot:4	Epoch:33	Loss:0.981	translation_Loss:0.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.754                                                   	MRR:28.39	Hits@10:52.04	Best:28.39
2024-12-27 21:56:15,912: Snapshot:4	Epoch:34	Loss:0.966	translation_Loss:0.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.742                                                   	MRR:28.2	Hits@10:52.05	Best:28.39
2024-12-27 21:56:18,534: Snapshot:4	Epoch:35	Loss:0.945	translation_Loss:0.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.73                                                   	MRR:28.38	Hits@10:52.05	Best:28.39
2024-12-27 21:56:21,162: Snapshot:4	Epoch:36	Loss:0.928	translation_Loss:0.21	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.718                                                   	MRR:28.21	Hits@10:52.19	Best:28.39
2024-12-27 21:56:23,781: Snapshot:4	Epoch:37	Loss:0.917	translation_Loss:0.209	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.708                                                   	MRR:28.24	Hits@10:51.96	Best:28.39
2024-12-27 21:56:26,374: Early Stopping! Snapshot: 4 Epoch: 38 Best Results: 28.39
2024-12-27 21:56:26,374: Start to training tokens! Snapshot: 4 Epoch: 38 Loss:0.903 MRR:28.29 Best Results: 28.39
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 21:56:26,375: Snapshot:4	Epoch:38	Loss:0.903	translation_Loss:0.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.696                                                   	MRR:28.29	Hits@10:51.94	Best:28.39
2024-12-27 21:56:28,930: Snapshot:4	Epoch:39	Loss:8.004	translation_Loss:7.536	multi_layer_Loss:0.468	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.29	Hits@10:51.94	Best:28.39
2024-12-27 21:56:31,463: End of token training: 4 Epoch: 40 Loss:7.849 MRR:28.29 Best Results: 28.39
2024-12-27 21:56:31,463: Snapshot:4	Epoch:40	Loss:7.849	translation_Loss:7.508	multi_layer_Loss:0.341	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:28.29	Hits@10:51.94	Best:28.39
2024-12-27 21:56:31,802: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_1024_10000/4model_best.tar'
2024-12-27 21:56:48,837: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1867 | 0.0967 | 0.2345 | 0.2931 |  0.3502 |
|     1      | 0.1289 | 0.0578 | 0.1531 | 0.2019 |  0.2703 |
|     2      | 0.1604 | 0.0838 | 0.1791 | 0.2265 |  0.3059 |
|     3      |  0.26  | 0.1779 | 0.2906 | 0.3357 |  0.4064 |
|     4      | 0.2773 | 0.1607 | 0.3138 | 0.3959 |  0.5208 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 21:56:48,839: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2764 | 0.1642 | 0.3434 | 0.4134 |  0.4841 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2414 | 0.1307 | 0.3046 | 0.3736 |  0.4477 |
|     1      | 0.1633 | 0.0818 | 0.1929 | 0.2493 |  0.3207 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2014 | 0.1031 | 0.2554 | 0.3186 |  0.3849 |
|     1      | 0.1358 | 0.0633 | 0.1623 | 0.2119 |  0.2763 |
|     2      | 0.2242 | 0.1351 | 0.2503 | 0.3107 |  0.4031 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.198  | 0.1014 | 0.2506 | 0.3125 |  0.378  |
|     1      | 0.1329 | 0.061  | 0.1581 | 0.2066 |  0.2735 |
|     2      | 0.1706 | 0.0894 | 0.1882 | 0.2412 |  0.3289 |
|     3      | 0.3001 | 0.2064 | 0.3422 | 0.3997 |  0.4735 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1867 | 0.0967 | 0.2345 | 0.2931 |  0.3502 |
|     1      | 0.1289 | 0.0578 | 0.1531 | 0.2019 |  0.2703 |
|     2      | 0.1604 | 0.0838 | 0.1791 | 0.2265 |  0.3059 |
|     3      |  0.26  | 0.1779 | 0.2906 | 0.3357 |  0.4064 |
|     4      | 0.2773 | 0.1607 | 0.3138 | 0.3959 |  0.5208 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 21:56:48,840: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 537.3646812438965  |   0.276   |    0.164     |    0.343     |     0.484     |
|    1     |  237.506511926651  |   0.203   |    0.107     |     0.25     |     0.386     |
|    2     | 169.40101647377014 |   0.183   |    0.097     |     0.22     |      0.35     |
|    3     | 171.17659306526184 |   0.181   |    0.096     |    0.216     |     0.343     |
|    4     | 118.19482374191284 |   0.177   |    0.095     |    0.209     |     0.334     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 21:56:48,840: Sum_Training_Time:1233.6436264514923
2024-12-27 21:56:48,840: Every_Training_Time:[537.3646812438965, 237.506511926651, 169.40101647377014, 171.17659306526184, 118.19482374191284]
2024-12-27 21:56:48,840: Forward transfer: 0.018299999999999997 Backward transfer: -0.056999999999999995
2024-12-27 21:57:26,675: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.0001, lifelong_name='double_tokened', log_path='./logs/20241227215652/RELATIONrelation_0.0001_2048_1000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.0001_2048_1000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.0001_2048_1000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 21:57:42,384: Snapshot:0	Epoch:0	Loss:40.585	translation_Loss:40.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:2.21	Hits@10:2.85	Best:2.21
2024-12-27 21:57:54,073: Snapshot:0	Epoch:1	Loss:37.517	translation_Loss:37.517	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:5.51	Hits@10:11.63	Best:5.51
2024-12-27 21:58:05,377: Snapshot:0	Epoch:2	Loss:34.762	translation_Loss:34.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.21	Hits@10:18.12	Best:8.21
2024-12-27 21:58:16,842: Snapshot:0	Epoch:3	Loss:32.213	translation_Loss:32.213	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.19	Hits@10:21.03	Best:9.19
2024-12-27 21:58:28,125: Snapshot:0	Epoch:4	Loss:29.837	translation_Loss:29.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.93	Hits@10:23.3	Best:9.93
2024-12-27 21:58:39,979: Snapshot:0	Epoch:5	Loss:27.584	translation_Loss:27.584	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.78	Hits@10:25.96	Best:10.78
2024-12-27 21:58:51,290: Snapshot:0	Epoch:6	Loss:25.373	translation_Loss:25.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.97	Hits@10:28.93	Best:11.97
2024-12-27 21:59:02,669: Snapshot:0	Epoch:7	Loss:23.17	translation_Loss:23.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.38	Hits@10:32.2	Best:13.38
2024-12-27 21:59:14,619: Snapshot:0	Epoch:8	Loss:20.989	translation_Loss:20.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.9	Hits@10:35.24	Best:14.9
2024-12-27 21:59:25,977: Snapshot:0	Epoch:9	Loss:18.808	translation_Loss:18.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.39	Hits@10:37.6	Best:16.39
2024-12-27 21:59:37,284: Snapshot:0	Epoch:10	Loss:16.738	translation_Loss:16.738	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.86	Hits@10:39.49	Best:17.86
2024-12-27 21:59:48,643: Snapshot:0	Epoch:11	Loss:14.83	translation_Loss:14.83	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.06	Hits@10:40.8	Best:19.06
2024-12-27 22:00:00,537: Snapshot:0	Epoch:12	Loss:13.095	translation_Loss:13.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.2	Hits@10:41.95	Best:20.2
2024-12-27 22:00:12,009: Snapshot:0	Epoch:13	Loss:11.585	translation_Loss:11.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.17	Hits@10:42.98	Best:21.17
2024-12-27 22:00:23,350: Snapshot:0	Epoch:14	Loss:10.208	translation_Loss:10.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.92	Hits@10:43.61	Best:21.92
2024-12-27 22:00:35,191: Snapshot:0	Epoch:15	Loss:9.021	translation_Loss:9.021	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.55	Hits@10:44.31	Best:22.55
2024-12-27 22:00:46,485: Snapshot:0	Epoch:16	Loss:7.921	translation_Loss:7.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.16	Hits@10:44.94	Best:23.16
2024-12-27 22:00:57,800: Snapshot:0	Epoch:17	Loss:6.974	translation_Loss:6.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.65	Hits@10:45.49	Best:23.65
2024-12-27 22:01:09,672: Snapshot:0	Epoch:18	Loss:6.18	translation_Loss:6.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.15	Hits@10:45.88	Best:24.15
2024-12-27 22:01:20,965: Snapshot:0	Epoch:19	Loss:5.478	translation_Loss:5.478	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.51	Hits@10:46.29	Best:24.51
2024-12-27 22:01:32,363: Snapshot:0	Epoch:20	Loss:4.882	translation_Loss:4.882	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.9	Hits@10:46.59	Best:24.9
2024-12-27 22:01:43,674: Snapshot:0	Epoch:21	Loss:4.335	translation_Loss:4.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.19	Hits@10:46.75	Best:25.19
2024-12-27 22:01:55,485: Snapshot:0	Epoch:22	Loss:3.901	translation_Loss:3.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.48	Hits@10:46.94	Best:25.48
2024-12-27 22:02:06,807: Snapshot:0	Epoch:23	Loss:3.518	translation_Loss:3.518	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.68	Hits@10:47.16	Best:25.68
2024-12-27 22:02:18,159: Snapshot:0	Epoch:24	Loss:3.184	translation_Loss:3.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.86	Hits@10:47.3	Best:25.86
2024-12-27 22:02:30,073: Snapshot:0	Epoch:25	Loss:2.909	translation_Loss:2.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.99	Hits@10:47.49	Best:25.99
2024-12-27 22:02:41,498: Snapshot:0	Epoch:26	Loss:2.65	translation_Loss:2.65	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.19	Hits@10:47.64	Best:26.19
2024-12-27 22:02:52,902: Snapshot:0	Epoch:27	Loss:2.446	translation_Loss:2.446	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.3	Hits@10:47.77	Best:26.3
2024-12-27 22:03:04,703: Snapshot:0	Epoch:28	Loss:2.258	translation_Loss:2.258	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.36	Hits@10:47.62	Best:26.36
2024-12-27 22:03:16,112: Snapshot:0	Epoch:29	Loss:2.104	translation_Loss:2.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.44	Hits@10:47.8	Best:26.44
2024-12-27 22:03:27,467: Snapshot:0	Epoch:30	Loss:1.951	translation_Loss:1.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.52	Hits@10:47.84	Best:26.52
2024-12-27 22:03:39,313: Snapshot:0	Epoch:31	Loss:1.837	translation_Loss:1.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.6	Hits@10:47.89	Best:26.6
2024-12-27 22:03:50,609: Snapshot:0	Epoch:32	Loss:1.725	translation_Loss:1.725	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.74	Hits@10:48.04	Best:26.74
2024-12-27 22:04:02,034: Snapshot:0	Epoch:33	Loss:1.648	translation_Loss:1.648	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.78	Hits@10:47.98	Best:26.78
2024-12-27 22:04:13,406: Snapshot:0	Epoch:34	Loss:1.535	translation_Loss:1.535	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.89	Hits@10:48.11	Best:26.89
2024-12-27 22:04:25,155: Snapshot:0	Epoch:35	Loss:1.469	translation_Loss:1.469	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.91	Hits@10:48.16	Best:26.91
2024-12-27 22:04:36,529: Snapshot:0	Epoch:36	Loss:1.405	translation_Loss:1.405	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.99	Hits@10:48.13	Best:26.99
2024-12-27 22:04:47,850: Snapshot:0	Epoch:37	Loss:1.332	translation_Loss:1.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.02	Hits@10:48.09	Best:27.02
2024-12-27 22:04:59,708: Snapshot:0	Epoch:38	Loss:1.273	translation_Loss:1.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.0	Hits@10:48.25	Best:27.02
2024-12-27 22:05:11,102: Snapshot:0	Epoch:39	Loss:1.23	translation_Loss:1.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.03	Hits@10:48.12	Best:27.03
2024-12-27 22:05:22,532: Snapshot:0	Epoch:40	Loss:1.17	translation_Loss:1.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.11	Hits@10:48.21	Best:27.11
2024-12-27 22:05:34,439: Snapshot:0	Epoch:41	Loss:1.134	translation_Loss:1.134	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.16	Hits@10:48.1	Best:27.16
2024-12-27 22:05:45,874: Snapshot:0	Epoch:42	Loss:1.107	translation_Loss:1.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.14	Hits@10:48.04	Best:27.16
2024-12-27 22:05:57,211: Snapshot:0	Epoch:43	Loss:1.065	translation_Loss:1.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.2	Hits@10:48.13	Best:27.2
2024-12-27 22:06:08,577: Snapshot:0	Epoch:44	Loss:1.039	translation_Loss:1.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.15	Hits@10:48.19	Best:27.2
2024-12-27 22:06:20,377: Snapshot:0	Epoch:45	Loss:1.004	translation_Loss:1.004	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.17	Hits@10:48.06	Best:27.2
2024-12-27 22:06:31,700: Snapshot:0	Epoch:46	Loss:0.972	translation_Loss:0.972	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.16	Hits@10:48.05	Best:27.2
2024-12-27 22:06:42,967: Snapshot:0	Epoch:47	Loss:0.941	translation_Loss:0.941	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.13	Hits@10:48.03	Best:27.2
2024-12-27 22:06:54,748: Early Stopping! Snapshot: 0 Epoch: 48 Best Results: 27.2
2024-12-27 22:06:54,748: Start to training tokens! Snapshot: 0 Epoch: 48 Loss:0.918 MRR:27.11 Best Results: 27.2
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 22:06:54,748: Snapshot:0	Epoch:48	Loss:0.918	translation_Loss:0.918	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.11	Hits@10:48.09	Best:27.2
2024-12-27 22:07:06,614: Snapshot:0	Epoch:49	Loss:25.73	translation_Loss:24.862	multi_layer_Loss:0.868	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.11	Hits@10:48.09	Best:27.2
2024-12-27 22:07:17,944: End of token training: 0 Epoch: 50 Loss:25.179 MRR:27.11 Best Results: 27.2
2024-12-27 22:07:17,944: Snapshot:0	Epoch:50	Loss:25.179	translation_Loss:24.852	multi_layer_Loss:0.327	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.11	Hits@10:48.09	Best:27.2
2024-12-27 22:07:18,303: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_1000/0model_best.tar'
2024-12-27 22:07:23,684: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2754 | 0.1616 | 0.3438 | 0.4119 |  0.4834 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 22:07:59,180: Snapshot:1	Epoch:0	Loss:37.119	translation_Loss:37.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.03                                                   	MRR:2.65	Hits@10:7.5	Best:2.65
2024-12-27 22:08:09,667: Snapshot:1	Epoch:1	Loss:31.782	translation_Loss:31.66	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.121                                                   	MRR:4.01	Hits@10:11.14	Best:4.01
2024-12-27 22:08:20,517: Snapshot:1	Epoch:2	Loss:26.944	translation_Loss:26.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.267                                                   	MRR:6.19	Hits@10:16.73	Best:6.19
2024-12-27 22:08:31,218: Snapshot:1	Epoch:3	Loss:22.552	translation_Loss:22.103	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.449                                                   	MRR:8.46	Hits@10:21.1	Best:8.46
2024-12-27 22:08:41,731: Snapshot:1	Epoch:4	Loss:18.72	translation_Loss:18.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.654                                                   	MRR:10.56	Hits@10:24.79	Best:10.56
2024-12-27 22:08:52,288: Snapshot:1	Epoch:5	Loss:15.395	translation_Loss:14.524	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.87                                                   	MRR:12.32	Hits@10:28.11	Best:12.32
2024-12-27 22:09:03,349: Snapshot:1	Epoch:6	Loss:12.581	translation_Loss:11.494	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.087                                                   	MRR:13.88	Hits@10:30.4	Best:13.88
2024-12-27 22:09:13,896: Snapshot:1	Epoch:7	Loss:10.219	translation_Loss:8.927	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.292                                                   	MRR:15.16	Hits@10:32.12	Best:15.16
2024-12-27 22:09:24,433: Snapshot:1	Epoch:8	Loss:8.36	translation_Loss:6.883	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.476                                                   	MRR:16.28	Hits@10:33.52	Best:16.28
2024-12-27 22:09:35,377: Snapshot:1	Epoch:9	Loss:6.929	translation_Loss:5.298	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.631                                                   	MRR:17.03	Hits@10:34.49	Best:17.03
2024-12-27 22:09:45,927: Snapshot:1	Epoch:10	Loss:5.852	translation_Loss:4.102	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.75                                                   	MRR:17.56	Hits@10:35.15	Best:17.56
2024-12-27 22:09:56,506: Snapshot:1	Epoch:11	Loss:5.067	translation_Loss:3.232	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.835                                                   	MRR:17.97	Hits@10:35.57	Best:17.97
2024-12-27 22:10:07,075: Snapshot:1	Epoch:12	Loss:4.472	translation_Loss:2.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.887                                                   	MRR:18.35	Hits@10:36.06	Best:18.35
2024-12-27 22:10:18,172: Snapshot:1	Epoch:13	Loss:4.031	translation_Loss:2.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.913                                                   	MRR:18.56	Hits@10:36.45	Best:18.56
2024-12-27 22:10:28,600: Snapshot:1	Epoch:14	Loss:3.715	translation_Loss:1.798	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.918                                                   	MRR:18.71	Hits@10:36.62	Best:18.71
2024-12-27 22:10:39,044: Snapshot:1	Epoch:15	Loss:3.444	translation_Loss:1.534	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.91                                                   	MRR:18.85	Hits@10:37.0	Best:18.85
2024-12-27 22:10:49,941: Snapshot:1	Epoch:16	Loss:3.239	translation_Loss:1.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.893                                                   	MRR:18.84	Hits@10:37.05	Best:18.85
2024-12-27 22:11:00,598: Snapshot:1	Epoch:17	Loss:3.069	translation_Loss:1.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.871                                                   	MRR:18.87	Hits@10:37.13	Best:18.87
2024-12-27 22:11:11,032: Snapshot:1	Epoch:18	Loss:2.923	translation_Loss:1.077	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.846                                                   	MRR:19.17	Hits@10:37.32	Best:19.17
2024-12-27 22:11:21,543: Snapshot:1	Epoch:19	Loss:2.813	translation_Loss:0.993	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.819                                                   	MRR:19.2	Hits@10:37.47	Best:19.2
2024-12-27 22:11:32,622: Snapshot:1	Epoch:20	Loss:2.696	translation_Loss:0.905	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.79                                                   	MRR:19.37	Hits@10:37.51	Best:19.37
2024-12-27 22:11:43,062: Snapshot:1	Epoch:21	Loss:2.605	translation_Loss:0.845	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.76                                                   	MRR:19.35	Hits@10:37.48	Best:19.37
2024-12-27 22:11:53,536: Snapshot:1	Epoch:22	Loss:2.516	translation_Loss:0.785	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.731                                                   	MRR:19.38	Hits@10:37.64	Best:19.38
2024-12-27 22:12:04,753: Snapshot:1	Epoch:23	Loss:2.446	translation_Loss:0.744	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.702                                                   	MRR:19.35	Hits@10:37.67	Best:19.38
2024-12-27 22:12:15,263: Snapshot:1	Epoch:24	Loss:2.376	translation_Loss:0.704	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.672                                                   	MRR:19.52	Hits@10:37.76	Best:19.52
2024-12-27 22:12:25,736: Snapshot:1	Epoch:25	Loss:2.32	translation_Loss:0.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.644                                                   	MRR:19.52	Hits@10:37.75	Best:19.52
2024-12-27 22:12:36,205: Snapshot:1	Epoch:26	Loss:2.264	translation_Loss:0.647	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.617                                                   	MRR:19.6	Hits@10:37.89	Best:19.6
2024-12-27 22:12:47,119: Snapshot:1	Epoch:27	Loss:2.214	translation_Loss:0.623	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.591                                                   	MRR:19.75	Hits@10:37.96	Best:19.75
2024-12-27 22:12:57,549: Snapshot:1	Epoch:28	Loss:2.166	translation_Loss:0.601	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.565                                                   	MRR:19.81	Hits@10:37.91	Best:19.81
2024-12-27 22:13:07,972: Snapshot:1	Epoch:29	Loss:2.131	translation_Loss:0.588	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.542                                                   	MRR:19.81	Hits@10:38.06	Best:19.81
2024-12-27 22:13:18,479: Snapshot:1	Epoch:30	Loss:2.094	translation_Loss:0.575	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.519                                                   	MRR:19.73	Hits@10:38.07	Best:19.81
2024-12-27 22:13:29,568: Snapshot:1	Epoch:31	Loss:2.051	translation_Loss:0.553	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.498                                                   	MRR:19.61	Hits@10:37.99	Best:19.81
2024-12-27 22:13:39,986: Snapshot:1	Epoch:32	Loss:2.029	translation_Loss:0.554	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.476                                                   	MRR:19.6	Hits@10:38.06	Best:19.81
2024-12-27 22:13:50,409: Early Stopping! Snapshot: 1 Epoch: 33 Best Results: 19.81
2024-12-27 22:13:50,410: Start to training tokens! Snapshot: 1 Epoch: 33 Loss:1.995 MRR:19.68 Best Results: 19.81
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 22:13:50,410: Snapshot:1	Epoch:33	Loss:1.995	translation_Loss:0.539	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.456                                                   	MRR:19.68	Hits@10:38.14	Best:19.81
2024-12-27 22:14:01,139: Snapshot:1	Epoch:34	Loss:24.748	translation_Loss:23.906	multi_layer_Loss:0.842	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.68	Hits@10:38.14	Best:19.81
2024-12-27 22:14:11,538: End of token training: 1 Epoch: 35 Loss:24.209 MRR:19.68 Best Results: 19.81
2024-12-27 22:14:11,538: Snapshot:1	Epoch:35	Loss:24.209	translation_Loss:23.867	multi_layer_Loss:0.342	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.68	Hits@10:38.14	Best:19.81
2024-12-27 22:14:11,871: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_1000/1model_best.tar'
2024-12-27 22:14:21,740: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1873 | 0.0882 | 0.2408 | 0.3008 |  0.3708 |
|     1      | 0.1996 | 0.1054 | 0.2392 | 0.3002 |  0.3775 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 22:14:49,296: Snapshot:2	Epoch:0	Loss:24.618	translation_Loss:24.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.019                                                   	MRR:0.61	Hits@10:1.44	Best:0.61
2024-12-27 22:14:57,097: Snapshot:2	Epoch:1	Loss:17.888	translation_Loss:17.801	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:2.71	Hits@10:6.82	Best:2.71
2024-12-27 22:15:04,981: Snapshot:2	Epoch:2	Loss:12.172	translation_Loss:11.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.193                                                   	MRR:8.08	Hits@10:20.27	Best:8.08
2024-12-27 22:15:12,731: Snapshot:2	Epoch:3	Loss:8.368	translation_Loss:8.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.305                                                   	MRR:11.98	Hits@10:27.56	Best:11.98
2024-12-27 22:15:20,494: Snapshot:2	Epoch:4	Loss:6.209	translation_Loss:5.818	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.391                                                   	MRR:14.63	Hits@10:31.63	Best:14.63
2024-12-27 22:15:28,382: Snapshot:2	Epoch:5	Loss:4.83	translation_Loss:4.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.458                                                   	MRR:16.81	Hits@10:35.02	Best:16.81
2024-12-27 22:15:36,137: Snapshot:2	Epoch:6	Loss:3.894	translation_Loss:3.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.512                                                   	MRR:18.23	Hits@10:37.15	Best:18.23
2024-12-27 22:15:43,940: Snapshot:2	Epoch:7	Loss:3.253	translation_Loss:2.697	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.556                                                   	MRR:19.15	Hits@10:38.08	Best:19.15
2024-12-27 22:15:51,856: Snapshot:2	Epoch:8	Loss:2.755	translation_Loss:2.163	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.592                                                   	MRR:19.67	Hits@10:38.75	Best:19.67
2024-12-27 22:16:00,309: Snapshot:2	Epoch:9	Loss:2.43	translation_Loss:1.809	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.621                                                   	MRR:19.88	Hits@10:39.29	Best:19.88
2024-12-27 22:16:08,166: Snapshot:2	Epoch:10	Loss:2.162	translation_Loss:1.518	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.644                                                   	MRR:20.0	Hits@10:39.16	Best:20.0
2024-12-27 22:16:16,091: Snapshot:2	Epoch:11	Loss:1.965	translation_Loss:1.304	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.661                                                   	MRR:20.2	Hits@10:39.5	Best:20.2
2024-12-27 22:16:23,875: Snapshot:2	Epoch:12	Loss:1.808	translation_Loss:1.134	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.674                                                   	MRR:20.44	Hits@10:39.77	Best:20.44
2024-12-27 22:16:31,687: Snapshot:2	Epoch:13	Loss:1.688	translation_Loss:1.004	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.684                                                   	MRR:20.41	Hits@10:39.78	Best:20.44
2024-12-27 22:16:39,902: Snapshot:2	Epoch:14	Loss:1.567	translation_Loss:0.877	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.69                                                   	MRR:20.26	Hits@10:40.01	Best:20.44
2024-12-27 22:16:47,625: Snapshot:2	Epoch:15	Loss:1.473	translation_Loss:0.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.694                                                   	MRR:20.74	Hits@10:40.25	Best:20.74
2024-12-27 22:16:55,490: Snapshot:2	Epoch:16	Loss:1.386	translation_Loss:0.692	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.695                                                   	MRR:20.75	Hits@10:40.37	Best:20.75
2024-12-27 22:17:03,332: Snapshot:2	Epoch:17	Loss:1.319	translation_Loss:0.625	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.694                                                   	MRR:20.88	Hits@10:40.6	Best:20.88
2024-12-27 22:17:11,159: Snapshot:2	Epoch:18	Loss:1.265	translation_Loss:0.574	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.691                                                   	MRR:20.98	Hits@10:40.55	Best:20.98
2024-12-27 22:17:19,415: Snapshot:2	Epoch:19	Loss:1.212	translation_Loss:0.524	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.688                                                   	MRR:21.32	Hits@10:40.81	Best:21.32
2024-12-27 22:17:27,345: Snapshot:2	Epoch:20	Loss:1.154	translation_Loss:0.47	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.684                                                   	MRR:21.44	Hits@10:40.44	Best:21.44
2024-12-27 22:17:35,216: Snapshot:2	Epoch:21	Loss:1.118	translation_Loss:0.439	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.678                                                   	MRR:21.51	Hits@10:40.43	Best:21.51
2024-12-27 22:17:43,123: Snapshot:2	Epoch:22	Loss:1.078	translation_Loss:0.406	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.672                                                   	MRR:21.59	Hits@10:40.57	Best:21.59
2024-12-27 22:17:50,869: Snapshot:2	Epoch:23	Loss:1.043	translation_Loss:0.377	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.666                                                   	MRR:21.59	Hits@10:40.99	Best:21.59
2024-12-27 22:17:59,218: Snapshot:2	Epoch:24	Loss:1.021	translation_Loss:0.361	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.66                                                   	MRR:21.72	Hits@10:40.93	Best:21.72
2024-12-27 22:18:07,064: Snapshot:2	Epoch:25	Loss:0.99	translation_Loss:0.337	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.653                                                   	MRR:21.98	Hits@10:41.29	Best:21.98
2024-12-27 22:18:14,850: Snapshot:2	Epoch:26	Loss:0.97	translation_Loss:0.324	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.646                                                   	MRR:21.99	Hits@10:41.02	Best:21.99
2024-12-27 22:18:22,803: Snapshot:2	Epoch:27	Loss:0.943	translation_Loss:0.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.639                                                   	MRR:22.25	Hits@10:41.14	Best:22.25
2024-12-27 22:18:30,578: Snapshot:2	Epoch:28	Loss:0.92	translation_Loss:0.288	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.632                                                   	MRR:22.23	Hits@10:41.06	Best:22.25
2024-12-27 22:18:38,893: Snapshot:2	Epoch:29	Loss:0.897	translation_Loss:0.272	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.626                                                   	MRR:22.3	Hits@10:41.42	Best:22.3
2024-12-27 22:18:46,771: Snapshot:2	Epoch:30	Loss:0.882	translation_Loss:0.263	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.618                                                   	MRR:22.38	Hits@10:41.54	Best:22.38
2024-12-27 22:18:54,495: Snapshot:2	Epoch:31	Loss:0.867	translation_Loss:0.256	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.611                                                   	MRR:22.29	Hits@10:41.3	Best:22.38
2024-12-27 22:19:02,253: Snapshot:2	Epoch:32	Loss:0.846	translation_Loss:0.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.604                                                   	MRR:22.34	Hits@10:41.25	Best:22.38
2024-12-27 22:19:10,014: Snapshot:2	Epoch:33	Loss:0.831	translation_Loss:0.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.597                                                   	MRR:22.27	Hits@10:41.78	Best:22.38
2024-12-27 22:19:18,296: Snapshot:2	Epoch:34	Loss:0.82	translation_Loss:0.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.59                                                   	MRR:22.21	Hits@10:41.8	Best:22.38
2024-12-27 22:19:26,144: Early Stopping! Snapshot: 2 Epoch: 35 Best Results: 22.38
2024-12-27 22:19:26,144: Start to training tokens! Snapshot: 2 Epoch: 35 Loss:0.804 MRR:22.34 Best Results: 22.38
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 22:19:26,144: Snapshot:2	Epoch:35	Loss:0.804	translation_Loss:0.221	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.583                                                   	MRR:22.34	Hits@10:41.93	Best:22.38
2024-12-27 22:19:33,714: Snapshot:2	Epoch:36	Loss:14.166	translation_Loss:13.494	multi_layer_Loss:0.672	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.34	Hits@10:41.93	Best:22.38
2024-12-27 22:19:41,310: End of token training: 2 Epoch: 37 Loss:13.891 MRR:22.34 Best Results: 22.38
2024-12-27 22:19:41,310: Snapshot:2	Epoch:37	Loss:13.891	translation_Loss:13.491	multi_layer_Loss:0.399	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.34	Hits@10:41.93	Best:22.38
2024-12-27 22:19:41,612: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_1000/2model_best.tar'
2024-12-27 22:19:54,716: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1519 | 0.074  | 0.1906 | 0.238  |  0.294  |
|     1      | 0.1337 | 0.0617 | 0.1592 | 0.2081 |  0.2732 |
|     2      | 0.2208 | 0.1254 | 0.2494 | 0.3136 |  0.4092 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 22:20:10,121: Snapshot:3	Epoch:0	Loss:9.693	translation_Loss:9.69	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.003                                                   	MRR:1.15	Hits@10:2.63	Best:1.15
2024-12-27 22:20:13,740: Snapshot:3	Epoch:1	Loss:8.235	translation_Loss:8.224	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.011                                                   	MRR:3.2	Hits@10:8.02	Best:3.2
2024-12-27 22:20:17,809: Snapshot:3	Epoch:2	Loss:7.03	translation_Loss:7.007	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.023                                                   	MRR:5.78	Hits@10:13.16	Best:5.78
2024-12-27 22:20:21,451: Snapshot:3	Epoch:3	Loss:5.997	translation_Loss:5.96	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.038                                                   	MRR:8.02	Hits@10:17.43	Best:8.02
2024-12-27 22:20:25,265: Snapshot:3	Epoch:4	Loss:5.111	translation_Loss:5.057	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.054                                                   	MRR:9.78	Hits@10:21.04	Best:9.78
2024-12-27 22:20:28,957: Snapshot:3	Epoch:5	Loss:4.298	translation_Loss:4.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.071                                                   	MRR:11.89	Hits@10:25.5	Best:11.89
2024-12-27 22:20:32,607: Snapshot:3	Epoch:6	Loss:3.59	translation_Loss:3.5	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:14.38	Hits@10:31.14	Best:14.38
2024-12-27 22:20:36,266: Snapshot:3	Epoch:7	Loss:2.937	translation_Loss:2.828	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.109                                                   	MRR:16.97	Hits@10:35.97	Best:16.97
2024-12-27 22:20:39,980: Snapshot:3	Epoch:8	Loss:2.388	translation_Loss:2.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.127                                                   	MRR:19.26	Hits@10:39.51	Best:19.26
2024-12-27 22:20:43,686: Snapshot:3	Epoch:9	Loss:1.959	translation_Loss:1.814	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.145                                                   	MRR:21.11	Hits@10:41.47	Best:21.11
2024-12-27 22:20:47,383: Snapshot:3	Epoch:10	Loss:1.603	translation_Loss:1.442	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:22.49	Hits@10:43.11	Best:22.49
2024-12-27 22:20:50,975: Snapshot:3	Epoch:11	Loss:1.313	translation_Loss:1.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.175                                                   	MRR:23.29	Hits@10:44.11	Best:23.29
2024-12-27 22:20:54,627: Snapshot:3	Epoch:12	Loss:1.072	translation_Loss:0.884	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:24.0	Hits@10:44.86	Best:24.0
2024-12-27 22:20:58,817: Snapshot:3	Epoch:13	Loss:0.882	translation_Loss:0.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:24.69	Hits@10:45.19	Best:24.69
2024-12-27 22:21:02,519: Snapshot:3	Epoch:14	Loss:0.739	translation_Loss:0.533	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.207                                                   	MRR:25.37	Hits@10:45.46	Best:25.37
2024-12-27 22:21:06,173: Snapshot:3	Epoch:15	Loss:0.625	translation_Loss:0.412	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:25.94	Hits@10:45.82	Best:25.94
2024-12-27 22:21:09,883: Snapshot:3	Epoch:16	Loss:0.547	translation_Loss:0.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.217                                                   	MRR:26.45	Hits@10:46.01	Best:26.45
2024-12-27 22:21:13,559: Snapshot:3	Epoch:17	Loss:0.483	translation_Loss:0.263	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:26.74	Hits@10:46.54	Best:26.74
2024-12-27 22:21:17,280: Snapshot:3	Epoch:18	Loss:0.448	translation_Loss:0.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:27.03	Hits@10:46.81	Best:27.03
2024-12-27 22:21:20,894: Snapshot:3	Epoch:19	Loss:0.411	translation_Loss:0.19	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:27.38	Hits@10:46.88	Best:27.38
2024-12-27 22:21:24,591: Snapshot:3	Epoch:20	Loss:0.382	translation_Loss:0.161	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.22                                                   	MRR:27.75	Hits@10:47.16	Best:27.75
2024-12-27 22:21:28,211: Snapshot:3	Epoch:21	Loss:0.36	translation_Loss:0.141	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.219                                                   	MRR:27.96	Hits@10:47.21	Best:27.96
2024-12-27 22:21:31,879: Snapshot:3	Epoch:22	Loss:0.345	translation_Loss:0.128	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.217                                                   	MRR:28.26	Hits@10:47.48	Best:28.26
2024-12-27 22:21:35,629: Snapshot:3	Epoch:23	Loss:0.324	translation_Loss:0.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.215                                                   	MRR:28.58	Hits@10:47.61	Best:28.58
2024-12-27 22:21:39,730: Snapshot:3	Epoch:24	Loss:0.317	translation_Loss:0.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:28.81	Hits@10:47.54	Best:28.81
2024-12-27 22:21:43,474: Snapshot:3	Epoch:25	Loss:0.304	translation_Loss:0.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.211                                                   	MRR:28.93	Hits@10:47.63	Best:28.93
2024-12-27 22:21:47,218: Snapshot:3	Epoch:26	Loss:0.293	translation_Loss:0.084	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:28.97	Hits@10:47.71	Best:28.97
2024-12-27 22:21:50,876: Snapshot:3	Epoch:27	Loss:0.286	translation_Loss:0.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.206                                                   	MRR:29.16	Hits@10:47.91	Best:29.16
2024-12-27 22:21:54,520: Snapshot:3	Epoch:28	Loss:0.28	translation_Loss:0.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.204                                                   	MRR:29.29	Hits@10:47.97	Best:29.29
2024-12-27 22:21:58,162: Snapshot:3	Epoch:29	Loss:0.271	translation_Loss:0.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:29.46	Hits@10:47.95	Best:29.46
2024-12-27 22:22:01,840: Snapshot:3	Epoch:30	Loss:0.266	translation_Loss:0.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.2                                                   	MRR:29.5	Hits@10:48.3	Best:29.5
2024-12-27 22:22:05,487: Snapshot:3	Epoch:31	Loss:0.261	translation_Loss:0.063	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.198                                                   	MRR:29.65	Hits@10:48.28	Best:29.65
2024-12-27 22:22:09,182: Snapshot:3	Epoch:32	Loss:0.256	translation_Loss:0.06	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.196                                                   	MRR:29.77	Hits@10:48.46	Best:29.77
2024-12-27 22:22:12,842: Snapshot:3	Epoch:33	Loss:0.253	translation_Loss:0.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.194                                                   	MRR:29.82	Hits@10:48.27	Best:29.82
2024-12-27 22:22:16,499: Snapshot:3	Epoch:34	Loss:0.25	translation_Loss:0.058	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.192                                                   	MRR:30.1	Hits@10:48.24	Best:30.1
2024-12-27 22:22:20,630: Snapshot:3	Epoch:35	Loss:0.243	translation_Loss:0.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.19                                                   	MRR:30.0	Hits@10:48.38	Best:30.1
2024-12-27 22:22:24,281: Snapshot:3	Epoch:36	Loss:0.241	translation_Loss:0.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:30.11	Hits@10:48.23	Best:30.11
2024-12-27 22:22:27,919: Snapshot:3	Epoch:37	Loss:0.236	translation_Loss:0.049	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.186                                                   	MRR:30.1	Hits@10:48.27	Best:30.11
2024-12-27 22:22:31,577: Snapshot:3	Epoch:38	Loss:0.233	translation_Loss:0.048	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.185                                                   	MRR:30.12	Hits@10:48.29	Best:30.12
2024-12-27 22:22:35,288: Snapshot:3	Epoch:39	Loss:0.231	translation_Loss:0.048	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.183                                                   	MRR:30.31	Hits@10:48.54	Best:30.31
2024-12-27 22:22:38,989: Snapshot:3	Epoch:40	Loss:0.228	translation_Loss:0.046	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.182                                                   	MRR:30.41	Hits@10:48.61	Best:30.41
2024-12-27 22:22:42,524: Snapshot:3	Epoch:41	Loss:0.224	translation_Loss:0.044	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.18                                                   	MRR:30.34	Hits@10:48.51	Best:30.41
2024-12-27 22:22:46,187: Snapshot:3	Epoch:42	Loss:0.22	translation_Loss:0.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.179                                                   	MRR:30.5	Hits@10:48.58	Best:30.5
2024-12-27 22:22:49,826: Snapshot:3	Epoch:43	Loss:0.219	translation_Loss:0.042	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.177                                                   	MRR:30.54	Hits@10:48.58	Best:30.54
2024-12-27 22:22:53,429: Snapshot:3	Epoch:44	Loss:0.217	translation_Loss:0.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.176                                                   	MRR:30.54	Hits@10:48.61	Best:30.54
2024-12-27 22:22:57,043: Snapshot:3	Epoch:45	Loss:0.216	translation_Loss:0.042	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.174                                                   	MRR:30.63	Hits@10:48.68	Best:30.63
2024-12-27 22:23:00,710: Snapshot:3	Epoch:46	Loss:0.214	translation_Loss:0.041	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:30.8	Hits@10:48.74	Best:30.8
2024-12-27 22:23:04,802: Snapshot:3	Epoch:47	Loss:0.211	translation_Loss:0.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:30.81	Hits@10:48.84	Best:30.81
2024-12-27 22:23:08,419: Snapshot:3	Epoch:48	Loss:0.21	translation_Loss:0.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:30.62	Hits@10:48.98	Best:30.81
2024-12-27 22:23:12,005: Snapshot:3	Epoch:49	Loss:0.207	translation_Loss:0.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:30.7	Hits@10:49.03	Best:30.81
2024-12-27 22:23:15,654: Snapshot:3	Epoch:50	Loss:0.204	translation_Loss:0.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.168                                                   	MRR:30.82	Hits@10:48.93	Best:30.82
2024-12-27 22:23:19,351: Snapshot:3	Epoch:51	Loss:0.205	translation_Loss:0.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.167                                                   	MRR:30.84	Hits@10:48.84	Best:30.84
2024-12-27 22:23:23,057: Snapshot:3	Epoch:52	Loss:0.201	translation_Loss:0.035	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.166                                                   	MRR:30.85	Hits@10:48.9	Best:30.85
2024-12-27 22:23:26,879: Snapshot:3	Epoch:53	Loss:0.2	translation_Loss:0.035	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:30.88	Hits@10:48.99	Best:30.88
2024-12-27 22:23:30,462: Snapshot:3	Epoch:54	Loss:0.199	translation_Loss:0.035	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.164                                                   	MRR:30.84	Hits@10:48.88	Best:30.88
2024-12-27 22:23:34,065: Snapshot:3	Epoch:55	Loss:0.196	translation_Loss:0.033	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.162                                                   	MRR:30.71	Hits@10:49.06	Best:30.88
2024-12-27 22:23:37,666: Snapshot:3	Epoch:56	Loss:0.196	translation_Loss:0.035	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:30.79	Hits@10:49.08	Best:30.88
2024-12-27 22:23:41,737: Snapshot:3	Epoch:57	Loss:0.194	translation_Loss:0.034	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.16                                                   	MRR:30.76	Hits@10:49.13	Best:30.88
2024-12-27 22:23:45,398: Early Stopping! Snapshot: 3 Epoch: 58 Best Results: 30.88
2024-12-27 22:23:45,398: Start to training tokens! Snapshot: 3 Epoch: 58 Loss:0.191 MRR:30.83 Best Results: 30.88
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 22:23:45,399: Snapshot:3	Epoch:58	Loss:0.191	translation_Loss:0.032	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.159                                                   	MRR:30.83	Hits@10:49.24	Best:30.88
2024-12-27 22:23:48,959: Snapshot:3	Epoch:59	Loss:4.78	translation_Loss:4.456	multi_layer_Loss:0.323	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.83	Hits@10:49.24	Best:30.88
2024-12-27 22:23:52,486: End of token training: 3 Epoch: 60 Loss:4.747 MRR:30.83 Best Results: 30.88
2024-12-27 22:23:52,487: Snapshot:3	Epoch:60	Loss:4.747	translation_Loss:4.486	multi_layer_Loss:0.261	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.83	Hits@10:49.24	Best:30.88
2024-12-27 22:23:52,792: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_1000/3model_best.tar'
2024-12-27 22:24:07,912: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1458 | 0.0716 | 0.1805 | 0.2276 |  0.2856 |
|     1      | 0.117  | 0.0485 | 0.1384 | 0.1856 |  0.2524 |
|     2      | 0.1484 | 0.0708 | 0.1654 | 0.2119 |  0.2956 |
|     3      | 0.3112 | 0.2082 | 0.3625 | 0.4199 |  0.4958 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 22:24:20,332: Snapshot:4	Epoch:0	Loss:4.91	translation_Loss:4.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.002                                                   	MRR:5.25	Hits@10:15.02	Best:5.25
2024-12-27 22:24:22,958: Snapshot:4	Epoch:1	Loss:4.104	translation_Loss:4.097	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.007                                                   	MRR:7.02	Hits@10:18.64	Best:7.02
2024-12-27 22:24:25,544: Snapshot:4	Epoch:2	Loss:3.452	translation_Loss:3.438	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.014                                                   	MRR:8.48	Hits@10:21.45	Best:8.48
2024-12-27 22:24:28,171: Snapshot:4	Epoch:3	Loss:2.937	translation_Loss:2.915	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.022                                                   	MRR:10.1	Hits@10:24.62	Best:10.1
2024-12-27 22:24:30,788: Snapshot:4	Epoch:4	Loss:2.51	translation_Loss:2.481	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.03                                                   	MRR:11.47	Hits@10:27.85	Best:11.47
2024-12-27 22:24:33,373: Snapshot:4	Epoch:5	Loss:2.159	translation_Loss:2.122	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.038                                                   	MRR:12.8	Hits@10:30.24	Best:12.8
2024-12-27 22:24:36,045: Snapshot:4	Epoch:6	Loss:1.85	translation_Loss:1.805	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.045                                                   	MRR:14.08	Hits@10:32.73	Best:14.08
2024-12-27 22:24:38,611: Snapshot:4	Epoch:7	Loss:1.578	translation_Loss:1.526	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.052                                                   	MRR:15.44	Hits@10:35.1	Best:15.44
2024-12-27 22:24:41,206: Snapshot:4	Epoch:8	Loss:1.355	translation_Loss:1.298	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.058                                                   	MRR:16.73	Hits@10:37.44	Best:16.73
2024-12-27 22:24:43,809: Snapshot:4	Epoch:9	Loss:1.162	translation_Loss:1.099	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.063                                                   	MRR:17.88	Hits@10:39.81	Best:17.88
2024-12-27 22:24:46,440: Snapshot:4	Epoch:10	Loss:0.993	translation_Loss:0.924	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.068                                                   	MRR:19.08	Hits@10:42.07	Best:19.08
2024-12-27 22:24:49,514: Snapshot:4	Epoch:11	Loss:0.856	translation_Loss:0.783	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.073                                                   	MRR:20.08	Hits@10:43.98	Best:20.08
2024-12-27 22:24:52,084: Snapshot:4	Epoch:12	Loss:0.745	translation_Loss:0.668	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.077                                                   	MRR:20.95	Hits@10:45.45	Best:20.95
2024-12-27 22:24:54,669: Snapshot:4	Epoch:13	Loss:0.647	translation_Loss:0.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.081                                                   	MRR:21.8	Hits@10:46.31	Best:21.8
2024-12-27 22:24:57,272: Snapshot:4	Epoch:14	Loss:0.56	translation_Loss:0.476	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.084                                                   	MRR:22.33	Hits@10:46.87	Best:22.33
2024-12-27 22:24:59,904: Snapshot:4	Epoch:15	Loss:0.486	translation_Loss:0.4	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:22.79	Hits@10:47.72	Best:22.79
2024-12-27 22:25:02,547: Snapshot:4	Epoch:16	Loss:0.419	translation_Loss:0.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:23.29	Hits@10:48.0	Best:23.29
2024-12-27 22:25:05,144: Snapshot:4	Epoch:17	Loss:0.357	translation_Loss:0.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:24.14	Hits@10:48.38	Best:24.14
2024-12-27 22:25:07,820: Snapshot:4	Epoch:18	Loss:0.302	translation_Loss:0.21	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:24.88	Hits@10:49.07	Best:24.88
2024-12-27 22:25:10,367: Snapshot:4	Epoch:19	Loss:0.255	translation_Loss:0.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:25.17	Hits@10:49.35	Best:25.17
2024-12-27 22:25:12,954: Snapshot:4	Epoch:20	Loss:0.221	translation_Loss:0.128	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:25.36	Hits@10:49.39	Best:25.36
2024-12-27 22:25:15,547: Snapshot:4	Epoch:21	Loss:0.198	translation_Loss:0.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:25.51	Hits@10:49.5	Best:25.51
2024-12-27 22:25:18,224: Snapshot:4	Epoch:22	Loss:0.184	translation_Loss:0.09	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:25.68	Hits@10:49.43	Best:25.68
2024-12-27 22:25:20,867: Snapshot:4	Epoch:23	Loss:0.17	translation_Loss:0.077	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.094                                                   	MRR:25.84	Hits@10:49.51	Best:25.84
2024-12-27 22:25:23,500: Snapshot:4	Epoch:24	Loss:0.162	translation_Loss:0.068	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:25.92	Hits@10:49.56	Best:25.92
2024-12-27 22:25:26,071: Snapshot:4	Epoch:25	Loss:0.151	translation_Loss:0.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.093                                                   	MRR:25.86	Hits@10:49.77	Best:25.92
2024-12-27 22:25:29,107: Snapshot:4	Epoch:26	Loss:0.146	translation_Loss:0.054	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:25.98	Hits@10:49.86	Best:25.98
2024-12-27 22:25:31,694: Snapshot:4	Epoch:27	Loss:0.141	translation_Loss:0.049	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:26.05	Hits@10:50.15	Best:26.05
2024-12-27 22:25:34,291: Snapshot:4	Epoch:28	Loss:0.138	translation_Loss:0.047	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.091                                                   	MRR:26.11	Hits@10:50.35	Best:26.11
2024-12-27 22:25:36,886: Snapshot:4	Epoch:29	Loss:0.13	translation_Loss:0.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:26.13	Hits@10:50.64	Best:26.13
2024-12-27 22:25:39,432: Snapshot:4	Epoch:30	Loss:0.129	translation_Loss:0.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:26.07	Hits@10:50.44	Best:26.13
2024-12-27 22:25:41,969: Snapshot:4	Epoch:31	Loss:0.126	translation_Loss:0.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.07	Hits@10:50.6	Best:26.13
2024-12-27 22:25:44,508: Snapshot:4	Epoch:32	Loss:0.124	translation_Loss:0.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.088                                                   	MRR:26.03	Hits@10:50.56	Best:26.13
2024-12-27 22:25:47,043: Snapshot:4	Epoch:33	Loss:0.119	translation_Loss:0.032	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.087                                                   	MRR:26.06	Hits@10:50.93	Best:26.13
2024-12-27 22:25:49,633: Snapshot:4	Epoch:34	Loss:0.116	translation_Loss:0.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:26.2	Hits@10:50.74	Best:26.2
2024-12-27 22:25:52,222: Snapshot:4	Epoch:35	Loss:0.116	translation_Loss:0.03	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:26.24	Hits@10:50.71	Best:26.24
2024-12-27 22:25:54,962: Snapshot:4	Epoch:36	Loss:0.113	translation_Loss:0.028	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:26.36	Hits@10:50.83	Best:26.36
2024-12-27 22:25:57,572: Snapshot:4	Epoch:37	Loss:0.113	translation_Loss:0.029	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.084                                                   	MRR:26.43	Hits@10:50.95	Best:26.43
2024-12-27 22:26:00,197: Snapshot:4	Epoch:38	Loss:0.109	translation_Loss:0.026	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.083                                                   	MRR:26.54	Hits@10:51.04	Best:26.54
2024-12-27 22:26:02,824: Snapshot:4	Epoch:39	Loss:0.11	translation_Loss:0.027	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.083                                                   	MRR:26.59	Hits@10:50.96	Best:26.59
2024-12-27 22:26:05,416: Snapshot:4	Epoch:40	Loss:0.106	translation_Loss:0.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.082                                                   	MRR:26.62	Hits@10:51.05	Best:26.62
2024-12-27 22:26:08,004: Snapshot:4	Epoch:41	Loss:0.104	translation_Loss:0.022	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.081                                                   	MRR:26.8	Hits@10:51.04	Best:26.8
2024-12-27 22:26:11,124: Snapshot:4	Epoch:42	Loss:0.103	translation_Loss:0.023	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.081                                                   	MRR:26.91	Hits@10:50.98	Best:26.91
2024-12-27 22:26:13,713: Snapshot:4	Epoch:43	Loss:0.104	translation_Loss:0.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.08                                                   	MRR:26.98	Hits@10:50.75	Best:26.98
2024-12-27 22:26:16,383: Snapshot:4	Epoch:44	Loss:0.102	translation_Loss:0.022	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.079                                                   	MRR:26.99	Hits@10:50.79	Best:26.99
2024-12-27 22:26:18,980: Snapshot:4	Epoch:45	Loss:0.099	translation_Loss:0.021	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.079                                                   	MRR:27.03	Hits@10:50.95	Best:27.03
2024-12-27 22:26:21,572: Snapshot:4	Epoch:46	Loss:0.1	translation_Loss:0.021	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.078                                                   	MRR:27.04	Hits@10:50.81	Best:27.04
2024-12-27 22:26:24,116: Snapshot:4	Epoch:47	Loss:0.098	translation_Loss:0.02	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.078                                                   	MRR:27.0	Hits@10:51.2	Best:27.04
2024-12-27 22:26:26,653: Snapshot:4	Epoch:48	Loss:0.096	translation_Loss:0.019	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.077                                                   	MRR:27.01	Hits@10:51.22	Best:27.04
2024-12-27 22:26:29,209: Snapshot:4	Epoch:49	Loss:0.096	translation_Loss:0.019	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.077                                                   	MRR:27.13	Hits@10:51.16	Best:27.13
2024-12-27 22:26:31,810: Snapshot:4	Epoch:50	Loss:0.096	translation_Loss:0.019	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.076                                                   	MRR:27.2	Hits@10:51.17	Best:27.2
2024-12-27 22:26:34,445: Snapshot:4	Epoch:51	Loss:0.095	translation_Loss:0.019	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.076                                                   	MRR:27.25	Hits@10:51.2	Best:27.25
2024-12-27 22:26:37,007: Snapshot:4	Epoch:52	Loss:0.093	translation_Loss:0.018	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.075                                                   	MRR:27.12	Hits@10:51.38	Best:27.25
2024-12-27 22:26:39,521: Snapshot:4	Epoch:53	Loss:0.093	translation_Loss:0.018	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.075                                                   	MRR:27.2	Hits@10:51.02	Best:27.25
2024-12-27 22:26:42,070: Snapshot:4	Epoch:54	Loss:0.093	translation_Loss:0.018	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.075                                                   	MRR:27.31	Hits@10:51.08	Best:27.31
2024-12-27 22:26:44,665: Snapshot:4	Epoch:55	Loss:0.091	translation_Loss:0.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.074                                                   	MRR:27.29	Hits@10:51.12	Best:27.31
2024-12-27 22:26:47,210: Snapshot:4	Epoch:56	Loss:0.091	translation_Loss:0.017	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.074                                                   	MRR:27.27	Hits@10:51.35	Best:27.31
2024-12-27 22:26:49,828: Snapshot:4	Epoch:57	Loss:0.09	translation_Loss:0.017	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.073                                                   	MRR:27.33	Hits@10:51.5	Best:27.33
2024-12-27 22:26:53,007: Snapshot:4	Epoch:58	Loss:0.089	translation_Loss:0.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.073                                                   	MRR:27.37	Hits@10:51.19	Best:27.37
2024-12-27 22:26:55,546: Snapshot:4	Epoch:59	Loss:0.088	translation_Loss:0.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.073                                                   	MRR:27.32	Hits@10:51.24	Best:27.37
2024-12-27 22:26:58,160: Snapshot:4	Epoch:60	Loss:0.09	translation_Loss:0.017	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.072                                                   	MRR:27.34	Hits@10:51.52	Best:27.37
2024-12-27 22:27:00,710: Snapshot:4	Epoch:61	Loss:0.087	translation_Loss:0.015	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.072                                                   	MRR:27.29	Hits@10:51.64	Best:27.37
2024-12-27 22:27:03,309: Snapshot:4	Epoch:62	Loss:0.086	translation_Loss:0.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.072                                                   	MRR:27.52	Hits@10:51.63	Best:27.52
2024-12-27 22:27:05,984: Snapshot:4	Epoch:63	Loss:0.086	translation_Loss:0.015	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.071                                                   	MRR:27.54	Hits@10:51.68	Best:27.54
2024-12-27 22:27:08,571: Snapshot:4	Epoch:64	Loss:0.087	translation_Loss:0.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.071                                                   	MRR:27.62	Hits@10:51.24	Best:27.62
2024-12-27 22:27:11,126: Snapshot:4	Epoch:65	Loss:0.086	translation_Loss:0.015	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.071                                                   	MRR:27.5	Hits@10:51.09	Best:27.62
2024-12-27 22:27:13,621: Snapshot:4	Epoch:66	Loss:0.084	translation_Loss:0.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.07                                                   	MRR:27.46	Hits@10:51.3	Best:27.62
2024-12-27 22:27:16,187: Snapshot:4	Epoch:67	Loss:0.085	translation_Loss:0.015	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.07                                                   	MRR:27.57	Hits@10:51.37	Best:27.62
2024-12-27 22:27:18,717: Snapshot:4	Epoch:68	Loss:0.083	translation_Loss:0.013	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.07                                                   	MRR:27.53	Hits@10:51.27	Best:27.62
2024-12-27 22:27:21,264: Snapshot:4	Epoch:69	Loss:0.084	translation_Loss:0.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.069                                                   	MRR:27.7	Hits@10:51.68	Best:27.7
2024-12-27 22:27:23,879: Snapshot:4	Epoch:70	Loss:0.082	translation_Loss:0.013	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.069                                                   	MRR:27.76	Hits@10:51.94	Best:27.76
2024-12-27 22:27:26,475: Snapshot:4	Epoch:71	Loss:0.082	translation_Loss:0.013	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.069                                                   	MRR:27.8	Hits@10:51.85	Best:27.8
2024-12-27 22:27:29,039: Snapshot:4	Epoch:72	Loss:0.081	translation_Loss:0.013	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.068                                                   	MRR:27.86	Hits@10:51.99	Best:27.86
2024-12-27 22:27:31,639: Snapshot:4	Epoch:73	Loss:0.081	translation_Loss:0.013	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.068                                                   	MRR:27.88	Hits@10:52.19	Best:27.88
2024-12-27 22:27:34,618: Snapshot:4	Epoch:74	Loss:0.08	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.068                                                   	MRR:27.9	Hits@10:52.5	Best:27.9
2024-12-27 22:27:37,181: Snapshot:4	Epoch:75	Loss:0.081	translation_Loss:0.013	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.067                                                   	MRR:28.03	Hits@10:52.34	Best:28.03
2024-12-27 22:27:39,818: Snapshot:4	Epoch:76	Loss:0.079	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.067                                                   	MRR:28.08	Hits@10:52.49	Best:28.08
2024-12-27 22:27:42,363: Snapshot:4	Epoch:77	Loss:0.079	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.067                                                   	MRR:28.07	Hits@10:52.56	Best:28.08
2024-12-27 22:27:44,873: Snapshot:4	Epoch:78	Loss:0.08	translation_Loss:0.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.066                                                   	MRR:28.07	Hits@10:52.51	Best:28.08
2024-12-27 22:27:47,464: Snapshot:4	Epoch:79	Loss:0.079	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.066                                                   	MRR:28.1	Hits@10:52.52	Best:28.1
2024-12-27 22:27:49,967: Snapshot:4	Epoch:80	Loss:0.078	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.066                                                   	MRR:28.02	Hits@10:52.7	Best:28.1
2024-12-27 22:27:52,514: Snapshot:4	Epoch:81	Loss:0.077	translation_Loss:0.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.065                                                   	MRR:28.15	Hits@10:52.54	Best:28.15
2024-12-27 22:27:55,110: Snapshot:4	Epoch:82	Loss:0.079	translation_Loss:0.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.065                                                   	MRR:28.31	Hits@10:52.64	Best:28.31
2024-12-27 22:27:57,714: Snapshot:4	Epoch:83	Loss:0.077	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.065                                                   	MRR:28.44	Hits@10:52.88	Best:28.44
2024-12-27 22:28:00,250: Snapshot:4	Epoch:84	Loss:0.076	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.065                                                   	MRR:28.36	Hits@10:52.86	Best:28.44
2024-12-27 22:28:02,848: Snapshot:4	Epoch:85	Loss:0.076	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.064                                                   	MRR:28.51	Hits@10:52.98	Best:28.51
2024-12-27 22:28:05,391: Snapshot:4	Epoch:86	Loss:0.076	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.064                                                   	MRR:28.51	Hits@10:53.02	Best:28.51
2024-12-27 22:28:07,927: Snapshot:4	Epoch:87	Loss:0.075	translation_Loss:0.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.064                                                   	MRR:28.46	Hits@10:52.94	Best:28.51
2024-12-27 22:28:10,439: Snapshot:4	Epoch:88	Loss:0.075	translation_Loss:0.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.064                                                   	MRR:28.46	Hits@10:52.63	Best:28.51
2024-12-27 22:28:13,027: Snapshot:4	Epoch:89	Loss:0.076	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.064                                                   	MRR:28.52	Hits@10:52.66	Best:28.52
2024-12-27 22:28:16,088: Snapshot:4	Epoch:90	Loss:0.074	translation_Loss:0.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.063                                                   	MRR:28.42	Hits@10:52.63	Best:28.52
2024-12-27 22:28:18,623: Snapshot:4	Epoch:91	Loss:0.075	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.063                                                   	MRR:28.38	Hits@10:52.25	Best:28.52
2024-12-27 22:28:21,162: Snapshot:4	Epoch:92	Loss:0.074	translation_Loss:0.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.063                                                   	MRR:28.48	Hits@10:52.41	Best:28.52
2024-12-27 22:28:23,696: Snapshot:4	Epoch:93	Loss:0.073	translation_Loss:0.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.062                                                   	MRR:28.45	Hits@10:52.57	Best:28.52
2024-12-27 22:28:26,275: Snapshot:4	Epoch:94	Loss:0.073	translation_Loss:0.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.062                                                   	MRR:28.56	Hits@10:52.45	Best:28.56
2024-12-27 22:28:28,871: Snapshot:4	Epoch:95	Loss:0.072	translation_Loss:0.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.062                                                   	MRR:28.57	Hits@10:52.38	Best:28.57
2024-12-27 22:28:31,393: Snapshot:4	Epoch:96	Loss:0.073	translation_Loss:0.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.062                                                   	MRR:28.46	Hits@10:52.32	Best:28.57
2024-12-27 22:28:33,929: Snapshot:4	Epoch:97	Loss:0.073	translation_Loss:0.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.061                                                   	MRR:28.56	Hits@10:52.12	Best:28.57
2024-12-27 22:28:36,421: Snapshot:4	Epoch:98	Loss:0.072	translation_Loss:0.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.061                                                   	MRR:28.4	Hits@10:52.01	Best:28.57
2024-12-27 22:28:38,965: Snapshot:4	Epoch:99	Loss:0.073	translation_Loss:0.012	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.061                                                   	MRR:28.53	Hits@10:52.14	Best:28.57
2024-12-27 22:28:41,499: Early Stopping! Snapshot: 4 Epoch: 100 Best Results: 28.57
2024-12-27 22:28:41,499: Start to training tokens! Snapshot: 4 Epoch: 100 Loss:0.071 MRR:28.5 Best Results: 28.57
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 22:28:41,499: Snapshot:4	Epoch:100	Loss:0.071	translation_Loss:0.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.061                                                   	MRR:28.5	Hits@10:52.45	Best:28.57
2024-12-27 22:28:43,990: Snapshot:4	Epoch:101	Loss:3.025	translation_Loss:2.776	multi_layer_Loss:0.249	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.5	Hits@10:52.45	Best:28.57
2024-12-27 22:28:46,464: End of token training: 4 Epoch: 102 Loss:3.006 MRR:28.5 Best Results: 28.57
2024-12-27 22:28:46,464: Snapshot:4	Epoch:102	Loss:3.006	translation_Loss:2.787	multi_layer_Loss:0.219	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:28.5	Hits@10:52.45	Best:28.57
2024-12-27 22:28:46,770: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_1000/4model_best.tar'
2024-12-27 22:29:03,722: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1363 | 0.0671 | 0.1693 | 0.2124 |  0.2631 |
|     1      | 0.1107 | 0.044  | 0.1299 | 0.1775 |  0.243  |
|     2      | 0.1402 | 0.0705 | 0.1547 | 0.1975 |  0.2717 |
|     3      | 0.2496 | 0.1657 | 0.2799 | 0.3271 |  0.4017 |
|     4      |  0.28  | 0.1618 | 0.3213 | 0.4066 |  0.5208 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 22:29:03,724: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2754 | 0.1616 | 0.3438 | 0.4119 |  0.4834 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1873 | 0.0882 | 0.2408 | 0.3008 |  0.3708 |
|     1      | 0.1996 | 0.1054 | 0.2392 | 0.3002 |  0.3775 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1519 | 0.074  | 0.1906 | 0.238  |  0.294  |
|     1      | 0.1337 | 0.0617 | 0.1592 | 0.2081 |  0.2732 |
|     2      | 0.2208 | 0.1254 | 0.2494 | 0.3136 |  0.4092 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1458 | 0.0716 | 0.1805 | 0.2276 |  0.2856 |
|     1      | 0.117  | 0.0485 | 0.1384 | 0.1856 |  0.2524 |
|     2      | 0.1484 | 0.0708 | 0.1654 | 0.2119 |  0.2956 |
|     3      | 0.3112 | 0.2082 | 0.3625 | 0.4199 |  0.4958 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1363 | 0.0671 | 0.1693 | 0.2124 |  0.2631 |
|     1      | 0.1107 | 0.044  | 0.1299 | 0.1775 |  0.243  |
|     2      | 0.1402 | 0.0705 | 0.1547 | 0.1975 |  0.2717 |
|     3      | 0.2496 | 0.1657 | 0.2799 | 0.3271 |  0.4017 |
|     4      |  0.28  | 0.1618 | 0.3213 | 0.4066 |  0.5208 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 22:29:03,725: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 591.2688913345337  |   0.275   |    0.162     |    0.344     |     0.483     |
|    1     | 403.2075822353363  |   0.193   |    0.097     |     0.24     |     0.374     |
|    2     | 315.99510049819946 |   0.163   |    0.083     |    0.194     |     0.316     |
|    3     | 235.52364897727966 |   0.154   |    0.078     |    0.182     |     0.299     |
|    4     | 277.03398394584656 |    0.15   |    0.077     |    0.176     |      0.29     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 22:29:03,725: Sum_Training_Time:1823.0292069911957
2024-12-27 22:29:03,725: Every_Training_Time:[591.2688913345337, 403.2075822353363, 315.99510049819946, 235.52364897727966, 277.03398394584656]
2024-12-27 22:29:03,725: Forward transfer: 0.0184 Backward transfer: -0.09255
2024-12-27 22:29:44,283: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.0001, lifelong_name='double_tokened', log_path='./logs/20241227222909/RELATIONrelation_0.0001_2048_5000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.0001_2048_5000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.0001_2048_5000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 22:29:59,979: Snapshot:0	Epoch:0	Loss:40.585	translation_Loss:40.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:2.21	Hits@10:2.85	Best:2.21
2024-12-27 22:30:11,814: Snapshot:0	Epoch:1	Loss:37.517	translation_Loss:37.517	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:5.51	Hits@10:11.63	Best:5.51
2024-12-27 22:30:23,143: Snapshot:0	Epoch:2	Loss:34.762	translation_Loss:34.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.21	Hits@10:18.12	Best:8.21
2024-12-27 22:30:34,456: Snapshot:0	Epoch:3	Loss:32.213	translation_Loss:32.213	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.19	Hits@10:21.03	Best:9.19
2024-12-27 22:30:45,781: Snapshot:0	Epoch:4	Loss:29.837	translation_Loss:29.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.93	Hits@10:23.3	Best:9.93
2024-12-27 22:30:57,749: Snapshot:0	Epoch:5	Loss:27.584	translation_Loss:27.584	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.78	Hits@10:25.96	Best:10.78
2024-12-27 22:31:09,146: Snapshot:0	Epoch:6	Loss:25.373	translation_Loss:25.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.98	Hits@10:28.93	Best:11.98
2024-12-27 22:31:20,498: Snapshot:0	Epoch:7	Loss:23.17	translation_Loss:23.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.39	Hits@10:32.19	Best:13.39
2024-12-27 22:31:32,429: Snapshot:0	Epoch:8	Loss:20.989	translation_Loss:20.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.9	Hits@10:35.23	Best:14.9
2024-12-27 22:31:43,670: Snapshot:0	Epoch:9	Loss:18.808	translation_Loss:18.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.39	Hits@10:37.59	Best:16.39
2024-12-27 22:31:54,947: Snapshot:0	Epoch:10	Loss:16.738	translation_Loss:16.738	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.84	Hits@10:39.45	Best:17.84
2024-12-27 22:32:06,261: Snapshot:0	Epoch:11	Loss:14.83	translation_Loss:14.83	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.07	Hits@10:40.8	Best:19.07
2024-12-27 22:32:17,985: Snapshot:0	Epoch:12	Loss:13.095	translation_Loss:13.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.21	Hits@10:41.97	Best:20.21
2024-12-27 22:32:29,275: Snapshot:0	Epoch:13	Loss:11.585	translation_Loss:11.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.2	Hits@10:42.94	Best:21.2
2024-12-27 22:32:40,648: Snapshot:0	Epoch:14	Loss:10.208	translation_Loss:10.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.92	Hits@10:43.67	Best:21.92
2024-12-27 22:32:52,499: Snapshot:0	Epoch:15	Loss:9.022	translation_Loss:9.022	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.55	Hits@10:44.36	Best:22.55
2024-12-27 22:33:03,930: Snapshot:0	Epoch:16	Loss:7.921	translation_Loss:7.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.15	Hits@10:44.98	Best:23.15
2024-12-27 22:33:15,391: Snapshot:0	Epoch:17	Loss:6.974	translation_Loss:6.974	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.68	Hits@10:45.5	Best:23.68
2024-12-27 22:33:27,198: Snapshot:0	Epoch:18	Loss:6.18	translation_Loss:6.18	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.12	Hits@10:45.88	Best:24.12
2024-12-27 22:33:38,590: Snapshot:0	Epoch:19	Loss:5.479	translation_Loss:5.479	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.52	Hits@10:46.25	Best:24.52
2024-12-27 22:33:50,001: Snapshot:0	Epoch:20	Loss:4.883	translation_Loss:4.883	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.9	Hits@10:46.56	Best:24.9
2024-12-27 22:34:01,345: Snapshot:0	Epoch:21	Loss:4.335	translation_Loss:4.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.18	Hits@10:46.76	Best:25.18
2024-12-27 22:34:13,188: Snapshot:0	Epoch:22	Loss:3.901	translation_Loss:3.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.48	Hits@10:46.94	Best:25.48
2024-12-27 22:34:24,483: Snapshot:0	Epoch:23	Loss:3.519	translation_Loss:3.519	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.67	Hits@10:47.1	Best:25.67
2024-12-27 22:34:35,822: Snapshot:0	Epoch:24	Loss:3.184	translation_Loss:3.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.9	Hits@10:47.26	Best:25.9
2024-12-27 22:34:47,597: Snapshot:0	Epoch:25	Loss:2.91	translation_Loss:2.91	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.96	Hits@10:47.48	Best:25.96
2024-12-27 22:34:58,919: Snapshot:0	Epoch:26	Loss:2.65	translation_Loss:2.65	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.19	Hits@10:47.65	Best:26.19
2024-12-27 22:35:10,322: Snapshot:0	Epoch:27	Loss:2.446	translation_Loss:2.446	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.27	Hits@10:47.66	Best:26.27
2024-12-27 22:35:22,278: Snapshot:0	Epoch:28	Loss:2.258	translation_Loss:2.258	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.33	Hits@10:47.63	Best:26.33
2024-12-27 22:35:33,619: Snapshot:0	Epoch:29	Loss:2.104	translation_Loss:2.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.43	Hits@10:47.74	Best:26.43
2024-12-27 22:35:45,009: Snapshot:0	Epoch:30	Loss:1.951	translation_Loss:1.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.48	Hits@10:47.78	Best:26.48
2024-12-27 22:35:56,913: Snapshot:0	Epoch:31	Loss:1.837	translation_Loss:1.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.59	Hits@10:47.8	Best:26.59
2024-12-27 22:36:08,267: Snapshot:0	Epoch:32	Loss:1.725	translation_Loss:1.725	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.74	Hits@10:47.93	Best:26.74
2024-12-27 22:36:19,752: Snapshot:0	Epoch:33	Loss:1.648	translation_Loss:1.648	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.8	Hits@10:47.95	Best:26.8
2024-12-27 22:36:31,206: Snapshot:0	Epoch:34	Loss:1.535	translation_Loss:1.535	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.86	Hits@10:48.02	Best:26.86
2024-12-27 22:36:42,942: Snapshot:0	Epoch:35	Loss:1.468	translation_Loss:1.468	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.91	Hits@10:48.06	Best:26.91
2024-12-27 22:36:54,269: Snapshot:0	Epoch:36	Loss:1.406	translation_Loss:1.406	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.99	Hits@10:48.11	Best:26.99
2024-12-27 22:37:05,679: Snapshot:0	Epoch:37	Loss:1.332	translation_Loss:1.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.98	Hits@10:48.11	Best:26.99
2024-12-27 22:37:17,567: Snapshot:0	Epoch:38	Loss:1.273	translation_Loss:1.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.02	Hits@10:48.24	Best:27.02
2024-12-27 22:37:28,900: Snapshot:0	Epoch:39	Loss:1.23	translation_Loss:1.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.03	Hits@10:48.14	Best:27.03
2024-12-27 22:37:40,351: Snapshot:0	Epoch:40	Loss:1.17	translation_Loss:1.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.12	Hits@10:48.22	Best:27.12
2024-12-27 22:37:52,223: Snapshot:0	Epoch:41	Loss:1.133	translation_Loss:1.133	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.15	Hits@10:48.17	Best:27.15
2024-12-27 22:38:03,583: Snapshot:0	Epoch:42	Loss:1.108	translation_Loss:1.108	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.14	Hits@10:48.04	Best:27.15
2024-12-27 22:38:15,018: Snapshot:0	Epoch:43	Loss:1.065	translation_Loss:1.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.21	Hits@10:48.18	Best:27.21
2024-12-27 22:38:26,296: Snapshot:0	Epoch:44	Loss:1.039	translation_Loss:1.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.17	Hits@10:48.22	Best:27.21
2024-12-27 22:38:38,392: Snapshot:0	Epoch:45	Loss:1.004	translation_Loss:1.004	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.18	Hits@10:48.03	Best:27.21
2024-12-27 22:38:49,819: Snapshot:0	Epoch:46	Loss:0.972	translation_Loss:0.972	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.18	Hits@10:48.09	Best:27.21
2024-12-27 22:39:01,154: Snapshot:0	Epoch:47	Loss:0.941	translation_Loss:0.941	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.15	Hits@10:48.02	Best:27.21
2024-12-27 22:39:13,111: Early Stopping! Snapshot: 0 Epoch: 48 Best Results: 27.21
2024-12-27 22:39:13,111: Start to training tokens! Snapshot: 0 Epoch: 48 Loss:0.918 MRR:27.13 Best Results: 27.21
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 22:39:13,111: Snapshot:0	Epoch:48	Loss:0.918	translation_Loss:0.918	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.13	Hits@10:48.07	Best:27.21
2024-12-27 22:39:25,090: Snapshot:0	Epoch:49	Loss:25.758	translation_Loss:24.89	multi_layer_Loss:0.868	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.13	Hits@10:48.07	Best:27.21
2024-12-27 22:39:36,425: End of token training: 0 Epoch: 50 Loss:25.207 MRR:27.13 Best Results: 27.21
2024-12-27 22:39:36,425: Snapshot:0	Epoch:50	Loss:25.207	translation_Loss:24.88	multi_layer_Loss:0.327	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.13	Hits@10:48.07	Best:27.21
2024-12-27 22:39:36,767: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_5000/0model_best.tar'
2024-12-27 22:39:42,041: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2753 | 0.1622 | 0.3431 | 0.4117 |  0.4835 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 22:40:17,963: Snapshot:1	Epoch:0	Loss:37.223	translation_Loss:37.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.119                                                   	MRR:2.64	Hits@10:7.49	Best:2.64
2024-12-27 22:40:28,464: Snapshot:1	Epoch:1	Loss:32.316	translation_Loss:31.91	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.406                                                   	MRR:3.97	Hits@10:11.01	Best:3.97
2024-12-27 22:40:39,425: Snapshot:1	Epoch:2	Loss:28.111	translation_Loss:27.321	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.79                                                   	MRR:6.12	Hits@10:16.48	Best:6.12
2024-12-27 22:40:49,928: Snapshot:1	Epoch:3	Loss:24.405	translation_Loss:23.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.194                                                   	MRR:8.28	Hits@10:20.57	Best:8.28
2024-12-27 22:41:00,396: Snapshot:1	Epoch:4	Loss:21.244	translation_Loss:19.66	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.584                                                   	MRR:10.25	Hits@10:23.78	Best:10.25
2024-12-27 22:41:10,924: Snapshot:1	Epoch:5	Loss:18.533	translation_Loss:16.592	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.941                                                   	MRR:11.81	Hits@10:26.78	Best:11.81
2024-12-27 22:41:21,988: Snapshot:1	Epoch:6	Loss:16.246	translation_Loss:13.992	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.254                                                   	MRR:13.24	Hits@10:29.03	Best:13.24
2024-12-27 22:41:32,505: Snapshot:1	Epoch:7	Loss:14.287	translation_Loss:11.768	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.52                                                   	MRR:14.28	Hits@10:30.52	Best:14.28
2024-12-27 22:41:42,944: Snapshot:1	Epoch:8	Loss:12.689	translation_Loss:9.952	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.737                                                   	MRR:15.38	Hits@10:31.81	Best:15.38
2024-12-27 22:41:53,789: Snapshot:1	Epoch:9	Loss:11.381	translation_Loss:8.473	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.907                                                   	MRR:16.14	Hits@10:32.69	Best:16.14
2024-12-27 22:42:04,292: Snapshot:1	Epoch:10	Loss:10.295	translation_Loss:7.262	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.033                                                   	MRR:16.62	Hits@10:33.3	Best:16.62
2024-12-27 22:42:14,892: Snapshot:1	Epoch:11	Loss:9.42	translation_Loss:6.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.123                                                   	MRR:16.76	Hits@10:33.76	Best:16.76
2024-12-27 22:42:25,364: Snapshot:1	Epoch:12	Loss:8.666	translation_Loss:5.488	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.178                                                   	MRR:17.07	Hits@10:34.15	Best:17.07
2024-12-27 22:42:36,439: Snapshot:1	Epoch:13	Loss:8.036	translation_Loss:4.83	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.206                                                   	MRR:17.33	Hits@10:34.42	Best:17.33
2024-12-27 22:42:46,893: Snapshot:1	Epoch:14	Loss:7.525	translation_Loss:4.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.207                                                   	MRR:17.59	Hits@10:34.61	Best:17.59
2024-12-27 22:42:57,347: Snapshot:1	Epoch:15	Loss:7.075	translation_Loss:3.89	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.186                                                   	MRR:17.66	Hits@10:34.65	Best:17.66
2024-12-27 22:43:08,340: Snapshot:1	Epoch:16	Loss:6.704	translation_Loss:3.554	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.15                                                   	MRR:17.56	Hits@10:34.69	Best:17.66
2024-12-27 22:43:18,736: Snapshot:1	Epoch:17	Loss:6.405	translation_Loss:3.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.108                                                   	MRR:17.56	Hits@10:34.78	Best:17.66
2024-12-27 22:43:29,301: Snapshot:1	Epoch:18	Loss:6.13	translation_Loss:3.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.059                                                   	MRR:17.74	Hits@10:34.82	Best:17.74
2024-12-27 22:43:39,752: Snapshot:1	Epoch:19	Loss:5.918	translation_Loss:2.911	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.007                                                   	MRR:17.82	Hits@10:34.81	Best:17.82
2024-12-27 22:43:50,753: Snapshot:1	Epoch:20	Loss:5.707	translation_Loss:2.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.949                                                   	MRR:17.89	Hits@10:34.77	Best:17.89
2024-12-27 22:44:01,337: Snapshot:1	Epoch:21	Loss:5.54	translation_Loss:2.643	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.896                                                   	MRR:17.79	Hits@10:34.73	Best:17.89
2024-12-27 22:44:11,770: Snapshot:1	Epoch:22	Loss:5.387	translation_Loss:2.539	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.848                                                   	MRR:17.78	Hits@10:34.93	Best:17.89
2024-12-27 22:44:22,840: Snapshot:1	Epoch:23	Loss:5.254	translation_Loss:2.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.801                                                   	MRR:17.84	Hits@10:34.89	Best:17.89
2024-12-27 22:44:33,451: Snapshot:1	Epoch:24	Loss:5.13	translation_Loss:2.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.753                                                   	MRR:17.92	Hits@10:34.82	Best:17.92
2024-12-27 22:44:44,003: Snapshot:1	Epoch:25	Loss:5.034	translation_Loss:2.324	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.711                                                   	MRR:17.94	Hits@10:34.73	Best:17.94
2024-12-27 22:44:54,640: Snapshot:1	Epoch:26	Loss:4.94	translation_Loss:2.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.673                                                   	MRR:17.83	Hits@10:34.83	Best:17.94
2024-12-27 22:45:05,597: Snapshot:1	Epoch:27	Loss:4.87	translation_Loss:2.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.64                                                   	MRR:17.7	Hits@10:34.8	Best:17.94
2024-12-27 22:45:16,091: Snapshot:1	Epoch:28	Loss:4.79	translation_Loss:2.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.608                                                   	MRR:17.73	Hits@10:34.81	Best:17.94
2024-12-27 22:45:26,596: Snapshot:1	Epoch:29	Loss:4.735	translation_Loss:2.159	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.576                                                   	MRR:17.76	Hits@10:34.88	Best:17.94
2024-12-27 22:45:37,055: Early Stopping! Snapshot: 1 Epoch: 30 Best Results: 17.94
2024-12-27 22:45:37,055: Start to training tokens! Snapshot: 1 Epoch: 30 Loss:4.686 MRR:17.71 Best Results: 17.94
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 22:45:37,055: Snapshot:1	Epoch:30	Loss:4.686	translation_Loss:2.136	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.551                                                   	MRR:17.71	Hits@10:34.8	Best:17.94
2024-12-27 22:45:47,826: Snapshot:1	Epoch:31	Loss:28.129	translation_Loss:27.287	multi_layer_Loss:0.842	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.71	Hits@10:34.8	Best:17.94
2024-12-27 22:45:58,053: End of token training: 1 Epoch: 32 Loss:27.609 MRR:17.71 Best Results: 17.94
2024-12-27 22:45:58,053: Snapshot:1	Epoch:32	Loss:27.609	translation_Loss:27.267	multi_layer_Loss:0.342	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:17.71	Hits@10:34.8	Best:17.94
2024-12-27 22:45:58,353: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_5000/1model_best.tar'
2024-12-27 22:46:08,431: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.225  | 0.1156 | 0.2856 | 0.3526 |  0.428  |
|     1      | 0.1808 | 0.0931 | 0.2158 | 0.2757 |  0.3494 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 22:46:35,597: Snapshot:2	Epoch:0	Loss:25.447	translation_Loss:25.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.083                                                   	MRR:0.58	Hits@10:1.36	Best:0.58
2024-12-27 22:46:43,560: Snapshot:2	Epoch:1	Loss:19.33	translation_Loss:18.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.331                                                   	MRR:2.61	Hits@10:6.3	Best:2.61
2024-12-27 22:46:51,864: Snapshot:2	Epoch:2	Loss:14.229	translation_Loss:13.547	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.682                                                   	MRR:7.13	Hits@10:18.14	Best:7.13
2024-12-27 22:46:59,769: Snapshot:2	Epoch:3	Loss:10.563	translation_Loss:9.538	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.025                                                   	MRR:11.14	Hits@10:25.8	Best:11.14
2024-12-27 22:47:07,703: Snapshot:2	Epoch:4	Loss:8.422	translation_Loss:7.16	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.262                                                   	MRR:14.21	Hits@10:31.19	Best:14.21
2024-12-27 22:47:15,508: Snapshot:2	Epoch:5	Loss:7.078	translation_Loss:5.662	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.417                                                   	MRR:16.92	Hits@10:34.98	Best:16.92
2024-12-27 22:47:23,526: Snapshot:2	Epoch:6	Loss:6.168	translation_Loss:4.637	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.531                                                   	MRR:18.46	Hits@10:37.04	Best:18.46
2024-12-27 22:47:31,897: Snapshot:2	Epoch:7	Loss:5.525	translation_Loss:3.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.617                                                   	MRR:19.43	Hits@10:37.92	Best:19.43
2024-12-27 22:47:39,720: Snapshot:2	Epoch:8	Loss:5.017	translation_Loss:3.337	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.68                                                   	MRR:20.2	Hits@10:39.13	Best:20.2
2024-12-27 22:47:47,622: Snapshot:2	Epoch:9	Loss:4.665	translation_Loss:2.94	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.725                                                   	MRR:20.92	Hits@10:39.77	Best:20.92
2024-12-27 22:47:55,525: Snapshot:2	Epoch:10	Loss:4.359	translation_Loss:2.606	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.753                                                   	MRR:20.88	Hits@10:39.95	Best:20.92
2024-12-27 22:48:03,304: Snapshot:2	Epoch:11	Loss:4.112	translation_Loss:2.345	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.767                                                   	MRR:21.41	Hits@10:40.24	Best:21.41
2024-12-27 22:48:11,667: Snapshot:2	Epoch:12	Loss:3.906	translation_Loss:2.136	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.77                                                   	MRR:21.82	Hits@10:40.76	Best:21.82
2024-12-27 22:48:19,637: Snapshot:2	Epoch:13	Loss:3.72	translation_Loss:1.954	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.765                                                   	MRR:22.07	Hits@10:40.97	Best:22.07
2024-12-27 22:48:27,415: Snapshot:2	Epoch:14	Loss:3.549	translation_Loss:1.795	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.754                                                   	MRR:21.95	Hits@10:41.12	Best:22.07
2024-12-27 22:48:35,308: Snapshot:2	Epoch:15	Loss:3.407	translation_Loss:1.67	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.737                                                   	MRR:22.16	Hits@10:41.11	Best:22.16
2024-12-27 22:48:43,201: Snapshot:2	Epoch:16	Loss:3.28	translation_Loss:1.562	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.718                                                   	MRR:22.61	Hits@10:41.45	Best:22.61
2024-12-27 22:48:51,641: Snapshot:2	Epoch:17	Loss:3.152	translation_Loss:1.456	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.695                                                   	MRR:22.77	Hits@10:41.78	Best:22.77
2024-12-27 22:48:59,586: Snapshot:2	Epoch:18	Loss:3.048	translation_Loss:1.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.675                                                   	MRR:22.82	Hits@10:41.7	Best:22.82
2024-12-27 22:49:07,329: Snapshot:2	Epoch:19	Loss:2.942	translation_Loss:1.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.649                                                   	MRR:22.72	Hits@10:41.87	Best:22.82
2024-12-27 22:49:15,075: Snapshot:2	Epoch:20	Loss:2.846	translation_Loss:1.223	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.623                                                   	MRR:22.59	Hits@10:41.85	Best:22.82
2024-12-27 22:49:22,936: Snapshot:2	Epoch:21	Loss:2.772	translation_Loss:1.174	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.598                                                   	MRR:22.72	Hits@10:42.07	Best:22.82
2024-12-27 22:49:31,254: Snapshot:2	Epoch:22	Loss:2.68	translation_Loss:1.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.571                                                   	MRR:22.89	Hits@10:41.8	Best:22.89
2024-12-27 22:49:39,068: Snapshot:2	Epoch:23	Loss:2.603	translation_Loss:1.058	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.545                                                   	MRR:22.9	Hits@10:41.78	Best:22.9
2024-12-27 22:49:46,976: Snapshot:2	Epoch:24	Loss:2.538	translation_Loss:1.021	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.518                                                   	MRR:22.8	Hits@10:41.78	Best:22.9
2024-12-27 22:49:54,809: Snapshot:2	Epoch:25	Loss:2.469	translation_Loss:0.976	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.493                                                   	MRR:23.0	Hits@10:41.84	Best:23.0
2024-12-27 22:50:02,617: Snapshot:2	Epoch:26	Loss:2.412	translation_Loss:0.944	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.468                                                   	MRR:23.03	Hits@10:42.1	Best:23.03
2024-12-27 22:50:11,081: Snapshot:2	Epoch:27	Loss:2.352	translation_Loss:0.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.443                                                   	MRR:23.33	Hits@10:42.19	Best:23.33
2024-12-27 22:50:18,890: Snapshot:2	Epoch:28	Loss:2.304	translation_Loss:0.884	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.42                                                   	MRR:23.34	Hits@10:42.27	Best:23.34
2024-12-27 22:50:26,686: Snapshot:2	Epoch:29	Loss:2.25	translation_Loss:0.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.397                                                   	MRR:23.51	Hits@10:42.38	Best:23.51
2024-12-27 22:50:34,456: Snapshot:2	Epoch:30	Loss:2.213	translation_Loss:0.838	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.375                                                   	MRR:23.5	Hits@10:42.41	Best:23.51
2024-12-27 22:50:42,234: Snapshot:2	Epoch:31	Loss:2.159	translation_Loss:0.805	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.354                                                   	MRR:23.57	Hits@10:42.4	Best:23.57
2024-12-27 22:50:50,570: Snapshot:2	Epoch:32	Loss:2.126	translation_Loss:0.796	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.33                                                   	MRR:23.62	Hits@10:42.33	Best:23.62
2024-12-27 22:50:58,342: Snapshot:2	Epoch:33	Loss:2.08	translation_Loss:0.77	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.31                                                   	MRR:23.48	Hits@10:42.32	Best:23.62
2024-12-27 22:51:06,159: Snapshot:2	Epoch:34	Loss:2.04	translation_Loss:0.75	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.29                                                   	MRR:23.5	Hits@10:42.32	Best:23.62
2024-12-27 22:51:14,080: Snapshot:2	Epoch:35	Loss:2.007	translation_Loss:0.737	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.27                                                   	MRR:23.67	Hits@10:42.44	Best:23.67
2024-12-27 22:51:21,971: Snapshot:2	Epoch:36	Loss:1.969	translation_Loss:0.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.25                                                   	MRR:23.58	Hits@10:42.32	Best:23.67
2024-12-27 22:51:30,303: Snapshot:2	Epoch:37	Loss:1.944	translation_Loss:0.712	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.232                                                   	MRR:23.59	Hits@10:42.17	Best:23.67
2024-12-27 22:51:38,084: Snapshot:2	Epoch:38	Loss:1.922	translation_Loss:0.706	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.216                                                   	MRR:23.55	Hits@10:42.28	Best:23.67
2024-12-27 22:51:45,862: Snapshot:2	Epoch:39	Loss:1.892	translation_Loss:0.693	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.199                                                   	MRR:23.61	Hits@10:42.37	Best:23.67
2024-12-27 22:51:53,645: Snapshot:2	Epoch:40	Loss:1.872	translation_Loss:0.688	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.184                                                   	MRR:23.69	Hits@10:42.34	Best:23.69
2024-12-27 22:52:01,552: Snapshot:2	Epoch:41	Loss:1.843	translation_Loss:0.671	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.171                                                   	MRR:23.65	Hits@10:42.04	Best:23.69
2024-12-27 22:52:09,803: Snapshot:2	Epoch:42	Loss:1.811	translation_Loss:0.656	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.155                                                   	MRR:23.56	Hits@10:42.29	Best:23.69
2024-12-27 22:52:17,518: Snapshot:2	Epoch:43	Loss:1.795	translation_Loss:0.655	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.14                                                   	MRR:23.57	Hits@10:42.43	Best:23.69
2024-12-27 22:52:25,282: Snapshot:2	Epoch:44	Loss:1.78	translation_Loss:0.653	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.127                                                   	MRR:23.62	Hits@10:42.29	Best:23.69
2024-12-27 22:52:33,034: Early Stopping! Snapshot: 2 Epoch: 45 Best Results: 23.69
2024-12-27 22:52:33,034: Start to training tokens! Snapshot: 2 Epoch: 45 Loss:1.765 MRR:23.48 Best Results: 23.69
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 22:52:33,035: Snapshot:2	Epoch:45	Loss:1.765	translation_Loss:0.649	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.116                                                   	MRR:23.48	Hits@10:42.1	Best:23.69
2024-12-27 22:52:40,653: Snapshot:2	Epoch:46	Loss:19.042	translation_Loss:18.37	multi_layer_Loss:0.672	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.48	Hits@10:42.1	Best:23.69
2024-12-27 22:52:48,831: End of token training: 2 Epoch: 47 Loss:18.737 MRR:23.48 Best Results: 23.69
2024-12-27 22:52:48,831: Snapshot:2	Epoch:47	Loss:18.737	translation_Loss:18.338	multi_layer_Loss:0.399	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.48	Hits@10:42.1	Best:23.69
2024-12-27 22:52:49,134: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_5000/2model_best.tar'
2024-12-27 22:53:02,406: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1919 | 0.0972 | 0.2424 | 0.3029 |   0.37  |
|     1      | 0.1501 | 0.0731 | 0.1793 | 0.2315 |  0.2979 |
|     2      | 0.2322 | 0.1395 | 0.2607 | 0.3265 |  0.4171 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 22:53:17,341: Snapshot:3	Epoch:0	Loss:10.397	translation_Loss:10.383	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.014                                                   	MRR:1.17	Hits@10:2.73	Best:1.17
2024-12-27 22:53:21,002: Snapshot:3	Epoch:1	Loss:9.002	translation_Loss:8.953	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.049                                                   	MRR:3.21	Hits@10:8.22	Best:3.21
2024-12-27 22:53:24,675: Snapshot:3	Epoch:2	Loss:7.83	translation_Loss:7.736	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:5.1	Hits@10:12.35	Best:5.1
2024-12-27 22:53:28,805: Snapshot:3	Epoch:3	Loss:6.834	translation_Loss:6.685	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:6.98	Hits@10:16.13	Best:6.98
2024-12-27 22:53:32,390: Snapshot:3	Epoch:4	Loss:5.989	translation_Loss:5.783	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.206                                                   	MRR:8.99	Hits@10:19.88	Best:8.99
2024-12-27 22:53:35,985: Snapshot:3	Epoch:5	Loss:5.233	translation_Loss:4.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.265                                                   	MRR:11.09	Hits@10:24.4	Best:11.09
2024-12-27 22:53:39,651: Snapshot:3	Epoch:6	Loss:4.556	translation_Loss:4.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.324                                                   	MRR:13.52	Hits@10:29.55	Best:13.52
2024-12-27 22:53:43,326: Snapshot:3	Epoch:7	Loss:3.939	translation_Loss:3.555	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.383                                                   	MRR:16.33	Hits@10:34.66	Best:16.33
2024-12-27 22:53:47,033: Snapshot:3	Epoch:8	Loss:3.407	translation_Loss:2.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.439                                                   	MRR:18.78	Hits@10:39.02	Best:18.78
2024-12-27 22:53:50,667: Snapshot:3	Epoch:9	Loss:2.957	translation_Loss:2.467	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.49                                                   	MRR:21.01	Hits@10:41.54	Best:21.01
2024-12-27 22:53:54,329: Snapshot:3	Epoch:10	Loss:2.587	translation_Loss:2.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.534                                                   	MRR:22.58	Hits@10:43.19	Best:22.58
2024-12-27 22:53:58,017: Snapshot:3	Epoch:11	Loss:2.264	translation_Loss:1.693	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.57                                                   	MRR:23.59	Hits@10:44.24	Best:23.59
2024-12-27 22:54:01,727: Snapshot:3	Epoch:12	Loss:2.0	translation_Loss:1.4	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.6                                                   	MRR:24.57	Hits@10:45.08	Best:24.57
2024-12-27 22:54:05,350: Snapshot:3	Epoch:13	Loss:1.788	translation_Loss:1.164	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.624                                                   	MRR:25.29	Hits@10:45.54	Best:25.29
2024-12-27 22:54:09,427: Snapshot:3	Epoch:14	Loss:1.606	translation_Loss:0.964	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.642                                                   	MRR:25.9	Hits@10:46.0	Best:25.9
2024-12-27 22:54:13,103: Snapshot:3	Epoch:15	Loss:1.469	translation_Loss:0.814	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.655                                                   	MRR:26.45	Hits@10:46.18	Best:26.45
2024-12-27 22:54:16,756: Snapshot:3	Epoch:16	Loss:1.356	translation_Loss:0.692	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.664                                                   	MRR:27.06	Hits@10:46.66	Best:27.06
2024-12-27 22:54:20,356: Snapshot:3	Epoch:17	Loss:1.268	translation_Loss:0.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.67                                                   	MRR:27.59	Hits@10:46.87	Best:27.59
2024-12-27 22:54:24,069: Snapshot:3	Epoch:18	Loss:1.193	translation_Loss:0.52	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.673                                                   	MRR:27.97	Hits@10:47.09	Best:27.97
2024-12-27 22:54:27,747: Snapshot:3	Epoch:19	Loss:1.134	translation_Loss:0.46	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.674                                                   	MRR:28.39	Hits@10:47.43	Best:28.39
2024-12-27 22:54:31,378: Snapshot:3	Epoch:20	Loss:1.081	translation_Loss:0.408	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.673                                                   	MRR:28.61	Hits@10:47.41	Best:28.61
2024-12-27 22:54:35,025: Snapshot:3	Epoch:21	Loss:1.035	translation_Loss:0.364	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.671                                                   	MRR:28.78	Hits@10:47.77	Best:28.78
2024-12-27 22:54:38,686: Snapshot:3	Epoch:22	Loss:1.003	translation_Loss:0.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.668                                                   	MRR:28.96	Hits@10:47.99	Best:28.96
2024-12-27 22:54:42,278: Snapshot:3	Epoch:23	Loss:0.974	translation_Loss:0.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.664                                                   	MRR:29.25	Hits@10:47.91	Best:29.25
2024-12-27 22:54:45,982: Snapshot:3	Epoch:24	Loss:0.943	translation_Loss:0.284	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.659                                                   	MRR:29.48	Hits@10:48.14	Best:29.48
2024-12-27 22:54:50,178: Snapshot:3	Epoch:25	Loss:0.918	translation_Loss:0.265	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.654                                                   	MRR:29.78	Hits@10:48.11	Best:29.78
2024-12-27 22:54:53,775: Snapshot:3	Epoch:26	Loss:0.902	translation_Loss:0.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.648                                                   	MRR:29.81	Hits@10:48.07	Best:29.81
2024-12-27 22:54:57,422: Snapshot:3	Epoch:27	Loss:0.881	translation_Loss:0.239	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.642                                                   	MRR:29.87	Hits@10:48.19	Best:29.87
2024-12-27 22:55:01,114: Snapshot:3	Epoch:28	Loss:0.86	translation_Loss:0.225	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.635                                                   	MRR:29.9	Hits@10:48.23	Best:29.9
2024-12-27 22:55:04,776: Snapshot:3	Epoch:29	Loss:0.842	translation_Loss:0.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.628                                                   	MRR:30.1	Hits@10:48.29	Best:30.1
2024-12-27 22:55:08,352: Snapshot:3	Epoch:30	Loss:0.826	translation_Loss:0.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.621                                                   	MRR:30.07	Hits@10:48.38	Best:30.1
2024-12-27 22:55:11,938: Snapshot:3	Epoch:31	Loss:0.816	translation_Loss:0.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.614                                                   	MRR:30.04	Hits@10:48.63	Best:30.1
2024-12-27 22:55:15,509: Snapshot:3	Epoch:32	Loss:0.796	translation_Loss:0.189	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.607                                                   	MRR:30.0	Hits@10:48.6	Best:30.1
2024-12-27 22:55:19,074: Snapshot:3	Epoch:33	Loss:0.783	translation_Loss:0.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.601                                                   	MRR:30.07	Hits@10:48.37	Best:30.1
2024-12-27 22:55:22,733: Snapshot:3	Epoch:34	Loss:0.769	translation_Loss:0.175	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.594                                                   	MRR:30.14	Hits@10:48.29	Best:30.14
2024-12-27 22:55:26,393: Snapshot:3	Epoch:35	Loss:0.758	translation_Loss:0.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.586                                                   	MRR:30.19	Hits@10:48.49	Best:30.19
2024-12-27 22:55:30,456: Snapshot:3	Epoch:36	Loss:0.745	translation_Loss:0.166	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.579                                                   	MRR:30.2	Hits@10:48.61	Best:30.2
2024-12-27 22:55:33,991: Snapshot:3	Epoch:37	Loss:0.735	translation_Loss:0.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.573                                                   	MRR:30.18	Hits@10:48.53	Best:30.2
2024-12-27 22:55:37,599: Snapshot:3	Epoch:38	Loss:0.725	translation_Loss:0.159	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.566                                                   	MRR:30.38	Hits@10:48.66	Best:30.38
2024-12-27 22:55:41,158: Snapshot:3	Epoch:39	Loss:0.715	translation_Loss:0.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.559                                                   	MRR:30.37	Hits@10:48.64	Best:30.38
2024-12-27 22:55:44,707: Snapshot:3	Epoch:40	Loss:0.704	translation_Loss:0.151	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.552                                                   	MRR:30.32	Hits@10:48.75	Best:30.38
2024-12-27 22:55:48,298: Snapshot:3	Epoch:41	Loss:0.695	translation_Loss:0.149	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.546                                                   	MRR:30.26	Hits@10:48.76	Best:30.38
2024-12-27 22:55:51,900: Snapshot:3	Epoch:42	Loss:0.687	translation_Loss:0.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.54                                                   	MRR:30.2	Hits@10:48.8	Best:30.38
2024-12-27 22:55:55,445: Early Stopping! Snapshot: 3 Epoch: 43 Best Results: 30.38
2024-12-27 22:55:55,445: Start to training tokens! Snapshot: 3 Epoch: 43 Loss:0.673 MRR:30.18 Best Results: 30.38
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 22:55:55,446: Snapshot:3	Epoch:43	Loss:0.673	translation_Loss:0.139	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.534                                                   	MRR:30.18	Hits@10:48.59	Best:30.38
2024-12-27 22:55:58,967: Snapshot:3	Epoch:44	Loss:5.746	translation_Loss:5.422	multi_layer_Loss:0.323	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.18	Hits@10:48.59	Best:30.38
2024-12-27 22:56:02,448: End of token training: 3 Epoch: 45 Loss:5.688 MRR:30.18 Best Results: 30.38
2024-12-27 22:56:02,449: Snapshot:3	Epoch:45	Loss:5.688	translation_Loss:5.427	multi_layer_Loss:0.261	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.18	Hits@10:48.59	Best:30.38
2024-12-27 22:56:02,818: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_5000/3model_best.tar'
2024-12-27 22:56:18,213: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1858 | 0.094  | 0.2329 | 0.2932 |  0.358  |
|     1      | 0.1406 | 0.0656 | 0.1661 | 0.2175 |  0.2833 |
|     2      | 0.1641 | 0.0861 | 0.1818 | 0.2334 |  0.3116 |
|     3      | 0.3055 | 0.2068 | 0.3505 | 0.411  |  0.4863 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 22:56:30,514: Snapshot:4	Epoch:0	Loss:5.384	translation_Loss:5.376	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.008                                                   	MRR:5.17	Hits@10:14.76	Best:5.17
2024-12-27 22:56:33,109: Snapshot:4	Epoch:1	Loss:4.561	translation_Loss:4.531	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.03                                                   	MRR:6.8	Hits@10:18.75	Best:6.8
2024-12-27 22:56:35,700: Snapshot:4	Epoch:2	Loss:3.906	translation_Loss:3.848	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.057                                                   	MRR:8.07	Hits@10:21.23	Best:8.07
2024-12-27 22:56:38,295: Snapshot:4	Epoch:3	Loss:3.379	translation_Loss:3.293	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.086                                                   	MRR:9.33	Hits@10:24.21	Best:9.33
2024-12-27 22:56:40,868: Snapshot:4	Epoch:4	Loss:2.948	translation_Loss:2.834	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.113                                                   	MRR:10.57	Hits@10:26.59	Best:10.57
2024-12-27 22:56:43,475: Snapshot:4	Epoch:5	Loss:2.575	translation_Loss:2.437	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.138                                                   	MRR:11.88	Hits@10:28.88	Best:11.88
2024-12-27 22:56:46,041: Snapshot:4	Epoch:6	Loss:2.271	translation_Loss:2.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.16                                                   	MRR:13.35	Hits@10:31.51	Best:13.35
2024-12-27 22:56:48,669: Snapshot:4	Epoch:7	Loss:2.014	translation_Loss:1.835	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.179                                                   	MRR:14.6	Hits@10:34.42	Best:14.6
2024-12-27 22:56:51,267: Snapshot:4	Epoch:8	Loss:1.786	translation_Loss:1.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:15.83	Hits@10:37.0	Best:15.83
2024-12-27 22:56:53,856: Snapshot:4	Epoch:9	Loss:1.584	translation_Loss:1.371	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.213                                                   	MRR:17.06	Hits@10:39.47	Best:17.06
2024-12-27 22:56:56,450: Snapshot:4	Epoch:10	Loss:1.413	translation_Loss:1.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.229                                                   	MRR:18.31	Hits@10:41.46	Best:18.31
2024-12-27 22:56:59,055: Snapshot:4	Epoch:11	Loss:1.266	translation_Loss:1.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.243                                                   	MRR:19.45	Hits@10:43.18	Best:19.45
2024-12-27 22:57:01,641: Snapshot:4	Epoch:12	Loss:1.137	translation_Loss:0.882	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.256                                                   	MRR:20.48	Hits@10:45.24	Best:20.48
2024-12-27 22:57:04,217: Snapshot:4	Epoch:13	Loss:1.024	translation_Loss:0.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.267                                                   	MRR:21.16	Hits@10:46.41	Best:21.16
2024-12-27 22:57:06,767: Snapshot:4	Epoch:14	Loss:0.93	translation_Loss:0.654	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.276                                                   	MRR:21.9	Hits@10:47.73	Best:21.9
2024-12-27 22:57:09,353: Snapshot:4	Epoch:15	Loss:0.849	translation_Loss:0.566	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.284                                                   	MRR:22.37	Hits@10:48.37	Best:22.37
2024-12-27 22:57:11,916: Snapshot:4	Epoch:16	Loss:0.77	translation_Loss:0.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.29                                                   	MRR:22.89	Hits@10:48.54	Best:22.89
2024-12-27 22:57:14,485: Snapshot:4	Epoch:17	Loss:0.698	translation_Loss:0.403	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.295                                                   	MRR:23.78	Hits@10:48.93	Best:23.78
2024-12-27 22:57:17,073: Snapshot:4	Epoch:18	Loss:0.636	translation_Loss:0.337	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.298                                                   	MRR:24.5	Hits@10:49.27	Best:24.5
2024-12-27 22:57:20,189: Snapshot:4	Epoch:19	Loss:0.583	translation_Loss:0.282	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.301                                                   	MRR:25.0	Hits@10:49.78	Best:25.0
2024-12-27 22:57:22,795: Snapshot:4	Epoch:20	Loss:0.54	translation_Loss:0.237	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.303                                                   	MRR:25.24	Hits@10:50.07	Best:25.24
2024-12-27 22:57:25,394: Snapshot:4	Epoch:21	Loss:0.507	translation_Loss:0.203	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.304                                                   	MRR:25.49	Hits@10:50.36	Best:25.49
2024-12-27 22:57:27,991: Snapshot:4	Epoch:22	Loss:0.482	translation_Loss:0.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.304                                                   	MRR:25.79	Hits@10:50.79	Best:25.79
2024-12-27 22:57:30,582: Snapshot:4	Epoch:23	Loss:0.468	translation_Loss:0.164	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.303                                                   	MRR:25.93	Hits@10:50.94	Best:25.93
2024-12-27 22:57:33,155: Snapshot:4	Epoch:24	Loss:0.452	translation_Loss:0.149	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.302                                                   	MRR:25.95	Hits@10:50.86	Best:25.95
2024-12-27 22:57:35,767: Snapshot:4	Epoch:25	Loss:0.435	translation_Loss:0.134	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.301                                                   	MRR:26.06	Hits@10:51.05	Best:26.06
2024-12-27 22:57:38,362: Snapshot:4	Epoch:26	Loss:0.425	translation_Loss:0.126	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.299                                                   	MRR:26.11	Hits@10:50.74	Best:26.11
2024-12-27 22:57:40,960: Snapshot:4	Epoch:27	Loss:0.414	translation_Loss:0.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.297                                                   	MRR:26.2	Hits@10:50.98	Best:26.2
2024-12-27 22:57:43,516: Snapshot:4	Epoch:28	Loss:0.408	translation_Loss:0.112	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.295                                                   	MRR:26.51	Hits@10:51.11	Best:26.51
2024-12-27 22:57:46,147: Snapshot:4	Epoch:29	Loss:0.4	translation_Loss:0.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.293                                                   	MRR:26.6	Hits@10:51.37	Best:26.6
2024-12-27 22:57:48,803: Snapshot:4	Epoch:30	Loss:0.389	translation_Loss:0.098	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.291                                                   	MRR:26.7	Hits@10:51.17	Best:26.7
2024-12-27 22:57:51,392: Snapshot:4	Epoch:31	Loss:0.385	translation_Loss:0.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.289                                                   	MRR:26.79	Hits@10:51.08	Best:26.79
2024-12-27 22:57:54,028: Snapshot:4	Epoch:32	Loss:0.375	translation_Loss:0.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.287                                                   	MRR:26.86	Hits@10:51.32	Best:26.86
2024-12-27 22:57:56,666: Snapshot:4	Epoch:33	Loss:0.37	translation_Loss:0.085	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.284                                                   	MRR:27.04	Hits@10:51.22	Best:27.04
2024-12-27 22:57:59,295: Snapshot:4	Epoch:34	Loss:0.365	translation_Loss:0.083	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.282                                                   	MRR:27.05	Hits@10:51.32	Best:27.05
2024-12-27 22:58:02,257: Snapshot:4	Epoch:35	Loss:0.363	translation_Loss:0.083	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.28                                                   	MRR:26.97	Hits@10:51.41	Best:27.05
2024-12-27 22:58:04,809: Snapshot:4	Epoch:36	Loss:0.355	translation_Loss:0.077	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.278                                                   	MRR:27.06	Hits@10:51.5	Best:27.06
2024-12-27 22:58:07,394: Snapshot:4	Epoch:37	Loss:0.351	translation_Loss:0.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.275                                                   	MRR:27.14	Hits@10:51.81	Best:27.14
2024-12-27 22:58:10,018: Snapshot:4	Epoch:38	Loss:0.346	translation_Loss:0.073	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.273                                                   	MRR:26.92	Hits@10:52.07	Best:27.14
2024-12-27 22:58:12,530: Snapshot:4	Epoch:39	Loss:0.346	translation_Loss:0.075	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.271                                                   	MRR:27.07	Hits@10:51.76	Best:27.14
2024-12-27 22:58:15,085: Snapshot:4	Epoch:40	Loss:0.338	translation_Loss:0.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.269                                                   	MRR:27.16	Hits@10:51.7	Best:27.16
2024-12-27 22:58:17,684: Snapshot:4	Epoch:41	Loss:0.333	translation_Loss:0.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.266                                                   	MRR:27.44	Hits@10:51.97	Best:27.44
2024-12-27 22:58:20,257: Snapshot:4	Epoch:42	Loss:0.332	translation_Loss:0.068	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.264                                                   	MRR:27.56	Hits@10:52.04	Best:27.56
2024-12-27 22:58:22,820: Snapshot:4	Epoch:43	Loss:0.326	translation_Loss:0.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.261                                                   	MRR:27.69	Hits@10:51.99	Best:27.69
2024-12-27 22:58:25,368: Snapshot:4	Epoch:44	Loss:0.323	translation_Loss:0.064	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.259                                                   	MRR:27.76	Hits@10:52.07	Best:27.76
2024-12-27 22:58:27,900: Snapshot:4	Epoch:45	Loss:0.319	translation_Loss:0.063	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.256                                                   	MRR:27.63	Hits@10:51.93	Best:27.76
2024-12-27 22:58:30,432: Snapshot:4	Epoch:46	Loss:0.314	translation_Loss:0.06	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.254                                                   	MRR:27.63	Hits@10:52.13	Best:27.76
2024-12-27 22:58:32,949: Snapshot:4	Epoch:47	Loss:0.31	translation_Loss:0.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.251                                                   	MRR:27.72	Hits@10:52.16	Best:27.76
2024-12-27 22:58:35,438: Snapshot:4	Epoch:48	Loss:0.305	translation_Loss:0.056	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.249                                                   	MRR:27.62	Hits@10:52.35	Best:27.76
2024-12-27 22:58:37,969: Early Stopping! Snapshot: 4 Epoch: 49 Best Results: 27.76
2024-12-27 22:58:37,969: Start to training tokens! Snapshot: 4 Epoch: 49 Loss:0.303 MRR:27.73 Best Results: 27.76
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 22:58:37,969: Snapshot:4	Epoch:49	Loss:0.303	translation_Loss:0.057	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.247                                                   	MRR:27.73	Hits@10:52.28	Best:27.76
2024-12-27 22:58:40,441: Snapshot:4	Epoch:50	Loss:3.312	translation_Loss:3.063	multi_layer_Loss:0.249	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.73	Hits@10:52.28	Best:27.76
2024-12-27 22:58:43,436: End of token training: 4 Epoch: 51 Loss:3.27 MRR:27.73 Best Results: 27.76
2024-12-27 22:58:43,436: Snapshot:4	Epoch:51	Loss:3.27	translation_Loss:3.051	multi_layer_Loss:0.219	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.73	Hits@10:52.28	Best:27.76
2024-12-27 22:58:43,742: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_5000/4model_best.tar'
2024-12-27 22:59:00,340: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1732 | 0.0881 | 0.2171 | 0.2716 |  0.3299 |
|     1      | 0.134  | 0.0613 | 0.1573 | 0.2072 |  0.274  |
|     2      | 0.1517 | 0.0791 | 0.1679 | 0.2149 |  0.2909 |
|     3      | 0.2535 | 0.1669 | 0.2896 | 0.3359 |  0.4049 |
|     4      | 0.2724 | 0.1488 | 0.3165 | 0.4011 |  0.5207 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 22:59:00,343: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2753 | 0.1622 | 0.3431 | 0.4117 |  0.4835 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.225  | 0.1156 | 0.2856 | 0.3526 |  0.428  |
|     1      | 0.1808 | 0.0931 | 0.2158 | 0.2757 |  0.3494 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1919 | 0.0972 | 0.2424 | 0.3029 |   0.37  |
|     1      | 0.1501 | 0.0731 | 0.1793 | 0.2315 |  0.2979 |
|     2      | 0.2322 | 0.1395 | 0.2607 | 0.3265 |  0.4171 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1858 | 0.094  | 0.2329 | 0.2932 |  0.358  |
|     1      | 0.1406 | 0.0656 | 0.1661 | 0.2175 |  0.2833 |
|     2      | 0.1641 | 0.0861 | 0.1818 | 0.2334 |  0.3116 |
|     3      | 0.3055 | 0.2068 | 0.3505 | 0.411  |  0.4863 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1732 | 0.0881 | 0.2171 | 0.2716 |  0.3299 |
|     1      | 0.134  | 0.0613 | 0.1573 | 0.2072 |  0.274  |
|     2      | 0.1517 | 0.0791 | 0.1679 | 0.2149 |  0.2909 |
|     3      | 0.2535 | 0.1669 | 0.2896 | 0.3359 |  0.4049 |
|     4      | 0.2724 | 0.1488 | 0.3165 | 0.4011 |  0.5207 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 22:59:00,343: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     |  592.141389131546  |   0.275   |    0.162     |    0.343     |     0.483     |
|    1     |  371.377632856369  |   0.204   |    0.105     |    0.252     |      0.39     |
|    2     | 396.8622031211853  |   0.187   |    0.099     |    0.224     |     0.356     |
|    3     | 178.09533739089966 |   0.179   |    0.095     |    0.212     |     0.337     |
|    4     | 143.71567177772522 |   0.171   |     0.09     |    0.203     |     0.325     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 22:59:00,343: Sum_Training_Time:1682.1922342777252
2024-12-27 22:59:00,344: Every_Training_Time:[592.141389131546, 371.377632856369, 396.8622031211853, 178.09533739089966, 143.71567177772522]
2024-12-27 22:59:00,344: Forward transfer: 0.018975 Backward transfer: -0.07035
2024-12-27 22:59:43,699: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='2048', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.0001, lifelong_name='double_tokened', log_path='./logs/20241227225905/RELATIONrelation_0.0001_2048_10000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.0001_2048_10000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.0001_2048_10000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 22:59:59,695: Snapshot:0	Epoch:0	Loss:40.585	translation_Loss:40.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:2.21	Hits@10:2.85	Best:2.21
2024-12-27 23:00:11,671: Snapshot:0	Epoch:1	Loss:37.517	translation_Loss:37.517	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:5.51	Hits@10:11.63	Best:5.51
2024-12-27 23:00:23,178: Snapshot:0	Epoch:2	Loss:34.762	translation_Loss:34.762	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.21	Hits@10:18.12	Best:8.21
2024-12-27 23:00:34,672: Snapshot:0	Epoch:3	Loss:32.213	translation_Loss:32.213	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.19	Hits@10:21.03	Best:9.19
2024-12-27 23:00:46,142: Snapshot:0	Epoch:4	Loss:29.837	translation_Loss:29.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.93	Hits@10:23.32	Best:9.93
2024-12-27 23:00:58,153: Snapshot:0	Epoch:5	Loss:27.584	translation_Loss:27.584	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.78	Hits@10:25.96	Best:10.78
2024-12-27 23:01:09,692: Snapshot:0	Epoch:6	Loss:25.373	translation_Loss:25.373	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.98	Hits@10:28.94	Best:11.98
2024-12-27 23:01:21,212: Snapshot:0	Epoch:7	Loss:23.17	translation_Loss:23.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.39	Hits@10:32.2	Best:13.39
2024-12-27 23:01:33,229: Snapshot:0	Epoch:8	Loss:20.989	translation_Loss:20.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.91	Hits@10:35.2	Best:14.91
2024-12-27 23:01:44,690: Snapshot:0	Epoch:9	Loss:18.807	translation_Loss:18.807	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.39	Hits@10:37.6	Best:16.39
2024-12-27 23:01:56,245: Snapshot:0	Epoch:10	Loss:16.738	translation_Loss:16.738	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.84	Hits@10:39.42	Best:17.84
2024-12-27 23:02:07,625: Snapshot:0	Epoch:11	Loss:14.83	translation_Loss:14.83	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.08	Hits@10:40.8	Best:19.08
2024-12-27 23:02:19,506: Snapshot:0	Epoch:12	Loss:13.095	translation_Loss:13.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.19	Hits@10:42.01	Best:20.19
2024-12-27 23:02:30,957: Snapshot:0	Epoch:13	Loss:11.585	translation_Loss:11.585	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.19	Hits@10:42.95	Best:21.19
2024-12-27 23:02:42,382: Snapshot:0	Epoch:14	Loss:10.208	translation_Loss:10.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.92	Hits@10:43.61	Best:21.92
2024-12-27 23:02:54,268: Snapshot:0	Epoch:15	Loss:9.021	translation_Loss:9.021	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.55	Hits@10:44.35	Best:22.55
2024-12-27 23:03:05,679: Snapshot:0	Epoch:16	Loss:7.921	translation_Loss:7.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.15	Hits@10:44.98	Best:23.15
2024-12-27 23:03:17,086: Snapshot:0	Epoch:17	Loss:6.975	translation_Loss:6.975	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.66	Hits@10:45.5	Best:23.66
2024-12-27 23:03:29,073: Snapshot:0	Epoch:18	Loss:6.181	translation_Loss:6.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.13	Hits@10:45.85	Best:24.13
2024-12-27 23:03:40,503: Snapshot:0	Epoch:19	Loss:5.479	translation_Loss:5.479	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.56	Hits@10:46.26	Best:24.56
2024-12-27 23:03:51,951: Snapshot:0	Epoch:20	Loss:4.883	translation_Loss:4.883	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.88	Hits@10:46.59	Best:24.88
2024-12-27 23:04:03,389: Snapshot:0	Epoch:21	Loss:4.335	translation_Loss:4.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.16	Hits@10:46.69	Best:25.16
2024-12-27 23:04:15,401: Snapshot:0	Epoch:22	Loss:3.901	translation_Loss:3.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.49	Hits@10:46.97	Best:25.49
2024-12-27 23:04:27,012: Snapshot:0	Epoch:23	Loss:3.519	translation_Loss:3.519	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.66	Hits@10:47.13	Best:25.66
2024-12-27 23:04:38,428: Snapshot:0	Epoch:24	Loss:3.184	translation_Loss:3.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.88	Hits@10:47.3	Best:25.88
2024-12-27 23:04:50,303: Snapshot:0	Epoch:25	Loss:2.911	translation_Loss:2.911	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.01	Hits@10:47.49	Best:26.01
2024-12-27 23:05:01,736: Snapshot:0	Epoch:26	Loss:2.65	translation_Loss:2.65	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.19	Hits@10:47.6	Best:26.19
2024-12-27 23:05:13,201: Snapshot:0	Epoch:27	Loss:2.446	translation_Loss:2.446	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.27	Hits@10:47.76	Best:26.27
2024-12-27 23:05:25,144: Snapshot:0	Epoch:28	Loss:2.258	translation_Loss:2.258	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.35	Hits@10:47.66	Best:26.35
2024-12-27 23:05:36,599: Snapshot:0	Epoch:29	Loss:2.105	translation_Loss:2.105	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.44	Hits@10:47.79	Best:26.44
2024-12-27 23:05:48,072: Snapshot:0	Epoch:30	Loss:1.95	translation_Loss:1.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.52	Hits@10:47.78	Best:26.52
2024-12-27 23:05:59,969: Snapshot:0	Epoch:31	Loss:1.837	translation_Loss:1.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.64	Hits@10:47.81	Best:26.64
2024-12-27 23:06:11,380: Snapshot:0	Epoch:32	Loss:1.725	translation_Loss:1.725	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.78	Hits@10:47.96	Best:26.78
2024-12-27 23:06:22,791: Snapshot:0	Epoch:33	Loss:1.648	translation_Loss:1.648	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.76	Hits@10:47.98	Best:26.78
2024-12-27 23:06:34,272: Snapshot:0	Epoch:34	Loss:1.536	translation_Loss:1.536	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.88	Hits@10:48.05	Best:26.88
2024-12-27 23:06:46,152: Snapshot:0	Epoch:35	Loss:1.47	translation_Loss:1.47	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.91	Hits@10:48.1	Best:26.91
2024-12-27 23:06:57,664: Snapshot:0	Epoch:36	Loss:1.406	translation_Loss:1.406	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.03	Hits@10:48.12	Best:27.03
2024-12-27 23:07:09,083: Snapshot:0	Epoch:37	Loss:1.332	translation_Loss:1.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.03	Hits@10:48.06	Best:27.03
2024-12-27 23:07:21,037: Snapshot:0	Epoch:38	Loss:1.273	translation_Loss:1.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.04	Hits@10:48.2	Best:27.04
2024-12-27 23:07:32,527: Snapshot:0	Epoch:39	Loss:1.23	translation_Loss:1.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.0	Hits@10:48.16	Best:27.04
2024-12-27 23:07:43,921: Snapshot:0	Epoch:40	Loss:1.17	translation_Loss:1.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.08	Hits@10:48.26	Best:27.08
2024-12-27 23:07:55,753: Snapshot:0	Epoch:41	Loss:1.134	translation_Loss:1.134	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.15	Hits@10:48.16	Best:27.15
2024-12-27 23:08:07,188: Snapshot:0	Epoch:42	Loss:1.106	translation_Loss:1.106	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.15	Hits@10:48.1	Best:27.15
2024-12-27 23:08:18,660: Snapshot:0	Epoch:43	Loss:1.065	translation_Loss:1.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.21	Hits@10:48.17	Best:27.21
2024-12-27 23:08:30,170: Snapshot:0	Epoch:44	Loss:1.038	translation_Loss:1.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.14	Hits@10:48.16	Best:27.21
2024-12-27 23:08:42,015: Snapshot:0	Epoch:45	Loss:1.004	translation_Loss:1.004	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.17	Hits@10:48.05	Best:27.21
2024-12-27 23:08:53,437: Snapshot:0	Epoch:46	Loss:0.973	translation_Loss:0.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.17	Hits@10:48.06	Best:27.21
2024-12-27 23:09:04,900: Snapshot:0	Epoch:47	Loss:0.941	translation_Loss:0.941	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.14	Hits@10:48.08	Best:27.21
2024-12-27 23:09:16,825: Early Stopping! Snapshot: 0 Epoch: 48 Best Results: 27.21
2024-12-27 23:09:16,828: Start to training tokens! Snapshot: 0 Epoch: 48 Loss:0.918 MRR:27.13 Best Results: 27.21
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 23:09:16,829: Snapshot:0	Epoch:48	Loss:0.918	translation_Loss:0.918	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.13	Hits@10:48.1	Best:27.21
2024-12-27 23:09:28,894: Snapshot:0	Epoch:49	Loss:25.767	translation_Loss:24.899	multi_layer_Loss:0.868	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.13	Hits@10:48.1	Best:27.21
2024-12-27 23:09:40,326: End of token training: 0 Epoch: 50 Loss:25.216 MRR:27.13 Best Results: 27.21
2024-12-27 23:09:40,326: Snapshot:0	Epoch:50	Loss:25.216	translation_Loss:24.889	multi_layer_Loss:0.327	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.13	Hits@10:48.1	Best:27.21
2024-12-27 23:09:40,555: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_10000/0model_best.tar'
2024-12-27 23:09:45,877: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2753 | 0.1615 | 0.3442 | 0.412  |  0.4836 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 23:10:22,020: Snapshot:1	Epoch:0	Loss:37.327	translation_Loss:37.137	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.189                                                   	MRR:2.63	Hits@10:7.45	Best:2.63
2024-12-27 23:10:32,577: Snapshot:1	Epoch:1	Loss:32.759	translation_Loss:32.179	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.58                                                   	MRR:3.91	Hits@10:10.86	Best:3.91
2024-12-27 23:10:43,515: Snapshot:1	Epoch:2	Loss:28.958	translation_Loss:27.924	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.034                                                   	MRR:6.03	Hits@10:16.24	Best:6.03
2024-12-27 23:10:54,167: Snapshot:1	Epoch:3	Loss:25.599	translation_Loss:24.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.447                                                   	MRR:8.04	Hits@10:20.05	Best:8.04
2024-12-27 23:11:04,757: Snapshot:1	Epoch:4	Loss:22.722	translation_Loss:20.922	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.8                                                   	MRR:9.91	Hits@10:22.85	Best:9.91
2024-12-27 23:11:15,553: Snapshot:1	Epoch:5	Loss:20.234	translation_Loss:18.147	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.087                                                   	MRR:11.34	Hits@10:25.46	Best:11.34
2024-12-27 23:11:26,861: Snapshot:1	Epoch:6	Loss:18.116	translation_Loss:15.804	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.312                                                   	MRR:12.57	Hits@10:27.51	Best:12.57
2024-12-27 23:11:37,492: Snapshot:1	Epoch:7	Loss:16.268	translation_Loss:13.785	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.482                                                   	MRR:13.6	Hits@10:29.07	Best:13.6
2024-12-27 23:11:48,345: Snapshot:1	Epoch:8	Loss:14.732	translation_Loss:12.126	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.606                                                   	MRR:14.47	Hits@10:30.16	Best:14.47
2024-12-27 23:11:59,448: Snapshot:1	Epoch:9	Loss:13.442	translation_Loss:10.75	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.691                                                   	MRR:15.18	Hits@10:30.94	Best:15.18
2024-12-27 23:12:10,107: Snapshot:1	Epoch:10	Loss:12.343	translation_Loss:9.596	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.746                                                   	MRR:15.52	Hits@10:31.43	Best:15.52
2024-12-27 23:12:20,815: Snapshot:1	Epoch:11	Loss:11.436	translation_Loss:8.657	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.779                                                   	MRR:15.55	Hits@10:31.74	Best:15.55
2024-12-27 23:12:31,459: Snapshot:1	Epoch:12	Loss:10.636	translation_Loss:7.844	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.791                                                   	MRR:15.77	Hits@10:32.07	Best:15.77
2024-12-27 23:12:42,517: Snapshot:1	Epoch:13	Loss:9.957	translation_Loss:7.167	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.79                                                   	MRR:16.04	Hits@10:32.26	Best:16.04
2024-12-27 23:12:53,216: Snapshot:1	Epoch:14	Loss:9.386	translation_Loss:6.604	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.782                                                   	MRR:16.19	Hits@10:32.33	Best:16.19
2024-12-27 23:13:03,983: Snapshot:1	Epoch:15	Loss:8.884	translation_Loss:6.117	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.766                                                   	MRR:16.26	Hits@10:32.51	Best:16.26
2024-12-27 23:13:15,246: Snapshot:1	Epoch:16	Loss:8.466	translation_Loss:5.717	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.749                                                   	MRR:16.37	Hits@10:32.4	Best:16.37
2024-12-27 23:13:26,008: Snapshot:1	Epoch:17	Loss:8.119	translation_Loss:5.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.729                                                   	MRR:16.38	Hits@10:32.41	Best:16.38
2024-12-27 23:13:36,832: Snapshot:1	Epoch:18	Loss:7.811	translation_Loss:5.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.707                                                   	MRR:16.41	Hits@10:32.44	Best:16.41
2024-12-27 23:13:47,468: Snapshot:1	Epoch:19	Loss:7.568	translation_Loss:4.882	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.685                                                   	MRR:16.38	Hits@10:32.51	Best:16.41
2024-12-27 23:13:58,502: Snapshot:1	Epoch:20	Loss:7.332	translation_Loss:4.671	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.661                                                   	MRR:16.44	Hits@10:32.46	Best:16.44
2024-12-27 23:14:09,125: Snapshot:1	Epoch:21	Loss:7.145	translation_Loss:4.507	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.638                                                   	MRR:16.37	Hits@10:32.51	Best:16.44
2024-12-27 23:14:19,857: Snapshot:1	Epoch:22	Loss:6.975	translation_Loss:4.361	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.614                                                   	MRR:16.46	Hits@10:32.73	Best:16.46
2024-12-27 23:14:31,038: Snapshot:1	Epoch:23	Loss:6.827	translation_Loss:4.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.593                                                   	MRR:16.49	Hits@10:32.66	Best:16.49
2024-12-27 23:14:41,730: Snapshot:1	Epoch:24	Loss:6.701	translation_Loss:4.128	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.573                                                   	MRR:16.59	Hits@10:32.76	Best:16.59
2024-12-27 23:14:52,477: Snapshot:1	Epoch:25	Loss:6.597	translation_Loss:4.043	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.554                                                   	MRR:16.53	Hits@10:32.64	Best:16.59
2024-12-27 23:15:03,051: Snapshot:1	Epoch:26	Loss:6.503	translation_Loss:3.967	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.536                                                   	MRR:16.43	Hits@10:32.6	Best:16.59
2024-12-27 23:15:14,147: Snapshot:1	Epoch:27	Loss:6.427	translation_Loss:3.91	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.518                                                   	MRR:16.39	Hits@10:32.63	Best:16.59
2024-12-27 23:15:24,717: Snapshot:1	Epoch:28	Loss:6.34	translation_Loss:3.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.503                                                   	MRR:16.47	Hits@10:32.68	Best:16.59
2024-12-27 23:15:35,257: Early Stopping! Snapshot: 1 Epoch: 29 Best Results: 16.59
2024-12-27 23:15:35,258: Start to training tokens! Snapshot: 1 Epoch: 29 Loss:6.284 MRR:16.41 Best Results: 16.59
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 23:15:35,258: Snapshot:1	Epoch:29	Loss:6.284	translation_Loss:3.798	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.486                                                   	MRR:16.41	Hits@10:32.65	Best:16.59
2024-12-27 23:15:45,688: Snapshot:1	Epoch:30	Loss:29.571	translation_Loss:28.729	multi_layer_Loss:0.842	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.41	Hits@10:32.65	Best:16.59
2024-12-27 23:15:56,528: End of token training: 1 Epoch: 31 Loss:29.086 MRR:16.41 Best Results: 16.59
2024-12-27 23:15:56,528: Snapshot:1	Epoch:31	Loss:29.086	translation_Loss:28.744	multi_layer_Loss:0.342	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:16.41	Hits@10:32.65	Best:16.59
2024-12-27 23:15:56,812: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_10000/1model_best.tar'
2024-12-27 23:16:06,619: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2379 | 0.1255 | 0.3022 | 0.372  |  0.4467 |
|     1      | 0.1664 | 0.0837 | 0.1982 | 0.2539 |  0.3255 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 23:16:34,148: Snapshot:2	Epoch:0	Loss:25.856	translation_Loss:25.717	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.14                                                   	MRR:0.56	Hits@10:1.37	Best:0.56
2024-12-27 23:16:41,989: Snapshot:2	Epoch:1	Loss:20.231	translation_Loss:19.718	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.514                                                   	MRR:2.73	Hits@10:6.47	Best:2.73
2024-12-27 23:16:49,842: Snapshot:2	Epoch:2	Loss:15.614	translation_Loss:14.595	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.019                                                   	MRR:6.7	Hits@10:16.28	Best:6.7
2024-12-27 23:16:57,830: Snapshot:2	Epoch:3	Loss:12.24	translation_Loss:10.737	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.503                                                   	MRR:10.47	Hits@10:24.02	Best:10.47
2024-12-27 23:17:05,859: Snapshot:2	Epoch:4	Loss:10.113	translation_Loss:8.275	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.837                                                   	MRR:14.02	Hits@10:30.36	Best:14.02
2024-12-27 23:17:13,820: Snapshot:2	Epoch:5	Loss:8.794	translation_Loss:6.76	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.034                                                   	MRR:16.43	Hits@10:34.09	Best:16.43
2024-12-27 23:17:21,838: Snapshot:2	Epoch:6	Loss:7.907	translation_Loss:5.752	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.155                                                   	MRR:17.81	Hits@10:35.93	Best:17.81
2024-12-27 23:17:29,794: Snapshot:2	Epoch:7	Loss:7.266	translation_Loss:5.036	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.23                                                   	MRR:19.15	Hits@10:37.67	Best:19.15
2024-12-27 23:17:37,867: Snapshot:2	Epoch:8	Loss:6.757	translation_Loss:4.484	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.273                                                   	MRR:20.04	Hits@10:38.24	Best:20.04
2024-12-27 23:17:45,924: Snapshot:2	Epoch:9	Loss:6.345	translation_Loss:4.054	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.291                                                   	MRR:20.44	Hits@10:39.08	Best:20.44
2024-12-27 23:17:53,947: Snapshot:2	Epoch:10	Loss:6.01	translation_Loss:3.717	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.293                                                   	MRR:20.77	Hits@10:39.33	Best:20.77
2024-12-27 23:18:01,909: Snapshot:2	Epoch:11	Loss:5.718	translation_Loss:3.434	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.283                                                   	MRR:21.02	Hits@10:39.74	Best:21.02
2024-12-27 23:18:09,893: Snapshot:2	Epoch:12	Loss:5.469	translation_Loss:3.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.264                                                   	MRR:21.37	Hits@10:39.96	Best:21.37
2024-12-27 23:18:18,216: Snapshot:2	Epoch:13	Loss:5.23	translation_Loss:2.993	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.238                                                   	MRR:21.8	Hits@10:40.33	Best:21.8
2024-12-27 23:18:26,080: Snapshot:2	Epoch:14	Loss:5.025	translation_Loss:2.816	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.209                                                   	MRR:21.77	Hits@10:40.35	Best:21.8
2024-12-27 23:18:33,953: Snapshot:2	Epoch:15	Loss:4.825	translation_Loss:2.648	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.176                                                   	MRR:22.06	Hits@10:40.66	Best:22.06
2024-12-27 23:18:41,882: Snapshot:2	Epoch:16	Loss:4.648	translation_Loss:2.509	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.139                                                   	MRR:21.8	Hits@10:40.49	Best:22.06
2024-12-27 23:18:49,756: Snapshot:2	Epoch:17	Loss:4.48	translation_Loss:2.38	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.1                                                   	MRR:22.03	Hits@10:40.53	Best:22.06
2024-12-27 23:18:58,191: Snapshot:2	Epoch:18	Loss:4.329	translation_Loss:2.266	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.062                                                   	MRR:22.28	Hits@10:40.71	Best:22.28
2024-12-27 23:19:06,166: Snapshot:2	Epoch:19	Loss:4.203	translation_Loss:2.179	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.023                                                   	MRR:22.59	Hits@10:40.94	Best:22.59
2024-12-27 23:19:14,096: Snapshot:2	Epoch:20	Loss:4.063	translation_Loss:2.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.984                                                   	MRR:22.41	Hits@10:41.03	Best:22.59
2024-12-27 23:19:21,918: Snapshot:2	Epoch:21	Loss:3.945	translation_Loss:2.001	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.944                                                   	MRR:22.44	Hits@10:40.8	Best:22.59
2024-12-27 23:19:29,764: Snapshot:2	Epoch:22	Loss:3.826	translation_Loss:1.921	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.905                                                   	MRR:22.43	Hits@10:40.86	Best:22.59
2024-12-27 23:19:37,981: Snapshot:2	Epoch:23	Loss:3.733	translation_Loss:1.868	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.865                                                   	MRR:22.45	Hits@10:41.01	Best:22.59
2024-12-27 23:19:45,788: Early Stopping! Snapshot: 2 Epoch: 24 Best Results: 22.59
2024-12-27 23:19:45,788: Start to training tokens! Snapshot: 2 Epoch: 24 Loss:3.637 MRR:22.48 Best Results: 22.59
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 23:19:45,789: Snapshot:2	Epoch:24	Loss:3.637	translation_Loss:1.809	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.828                                                   	MRR:22.48	Hits@10:41.2	Best:22.59
2024-12-27 23:19:53,466: Snapshot:2	Epoch:25	Loss:18.259	translation_Loss:17.587	multi_layer_Loss:0.672	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.48	Hits@10:41.2	Best:22.59
2024-12-27 23:20:01,250: End of token training: 2 Epoch: 26 Loss:17.982 MRR:22.48 Best Results: 22.59
2024-12-27 23:20:01,252: Snapshot:2	Epoch:26	Loss:17.982	translation_Loss:17.583	multi_layer_Loss:0.399	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:22.48	Hits@10:41.2	Best:22.59
2024-12-27 23:20:01,590: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_10000/2model_best.tar'
2024-12-27 23:20:15,019: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1986 | 0.0998 | 0.2528 | 0.3159 |  0.3853 |
|     1      | 0.1366 | 0.0652 | 0.1615 | 0.2116 |  0.2769 |
|     2      | 0.222  | 0.1322 | 0.2474 | 0.3134 |  0.4019 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 23:20:29,941: Snapshot:3	Epoch:0	Loss:10.543	translation_Loss:10.517	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.026                                                   	MRR:1.26	Hits@10:3.15	Best:1.26
2024-12-27 23:20:33,608: Snapshot:3	Epoch:1	Loss:9.267	translation_Loss:9.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.081                                                   	MRR:3.36	Hits@10:8.28	Best:3.36
2024-12-27 23:20:37,258: Snapshot:3	Epoch:2	Loss:8.209	translation_Loss:8.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.149                                                   	MRR:4.84	Hits@10:11.57	Best:4.84
2024-12-27 23:20:40,936: Snapshot:3	Epoch:3	Loss:7.321	translation_Loss:7.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.228                                                   	MRR:6.78	Hits@10:15.02	Best:6.78
2024-12-27 23:20:44,636: Snapshot:3	Epoch:4	Loss:6.578	translation_Loss:6.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.311                                                   	MRR:8.56	Hits@10:18.72	Best:8.56
2024-12-27 23:20:48,345: Snapshot:3	Epoch:5	Loss:5.898	translation_Loss:5.503	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.394                                                   	MRR:10.61	Hits@10:23.09	Best:10.61
2024-12-27 23:20:52,022: Snapshot:3	Epoch:6	Loss:5.266	translation_Loss:4.788	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.478                                                   	MRR:12.86	Hits@10:28.23	Best:12.86
2024-12-27 23:20:55,754: Snapshot:3	Epoch:7	Loss:4.699	translation_Loss:4.141	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.559                                                   	MRR:15.5	Hits@10:33.14	Best:15.5
2024-12-27 23:20:59,828: Snapshot:3	Epoch:8	Loss:4.205	translation_Loss:3.57	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.635                                                   	MRR:17.83	Hits@10:37.36	Best:17.83
2024-12-27 23:21:03,496: Snapshot:3	Epoch:9	Loss:3.772	translation_Loss:3.068	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.704                                                   	MRR:19.85	Hits@10:39.99	Best:19.85
2024-12-27 23:21:07,196: Snapshot:3	Epoch:10	Loss:3.396	translation_Loss:2.633	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.763                                                   	MRR:21.46	Hits@10:41.59	Best:21.46
2024-12-27 23:21:10,867: Snapshot:3	Epoch:11	Loss:3.066	translation_Loss:2.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.813                                                   	MRR:22.58	Hits@10:42.73	Best:22.58
2024-12-27 23:21:14,558: Snapshot:3	Epoch:12	Loss:2.789	translation_Loss:1.936	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.853                                                   	MRR:23.4	Hits@10:43.56	Best:23.4
2024-12-27 23:21:18,254: Snapshot:3	Epoch:13	Loss:2.563	translation_Loss:1.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.885                                                   	MRR:24.13	Hits@10:44.47	Best:24.13
2024-12-27 23:21:21,954: Snapshot:3	Epoch:14	Loss:2.365	translation_Loss:1.456	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.909                                                   	MRR:24.75	Hits@10:44.94	Best:24.75
2024-12-27 23:21:25,664: Snapshot:3	Epoch:15	Loss:2.203	translation_Loss:1.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.927                                                   	MRR:25.51	Hits@10:45.43	Best:25.51
2024-12-27 23:21:29,342: Snapshot:3	Epoch:16	Loss:2.074	translation_Loss:1.136	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.938                                                   	MRR:26.09	Hits@10:45.91	Best:26.09
2024-12-27 23:21:33,032: Snapshot:3	Epoch:17	Loss:1.964	translation_Loss:1.019	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.945                                                   	MRR:26.52	Hits@10:46.24	Best:26.52
2024-12-27 23:21:36,746: Snapshot:3	Epoch:18	Loss:1.876	translation_Loss:0.927	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.948                                                   	MRR:27.0	Hits@10:46.65	Best:27.0
2024-12-27 23:21:40,875: Snapshot:3	Epoch:19	Loss:1.799	translation_Loss:0.85	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.949                                                   	MRR:27.34	Hits@10:46.67	Best:27.34
2024-12-27 23:21:44,559: Snapshot:3	Epoch:20	Loss:1.736	translation_Loss:0.788	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.948                                                   	MRR:27.64	Hits@10:46.6	Best:27.64
2024-12-27 23:21:48,251: Snapshot:3	Epoch:21	Loss:1.673	translation_Loss:0.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.946                                                   	MRR:27.91	Hits@10:46.85	Best:27.91
2024-12-27 23:21:51,960: Snapshot:3	Epoch:22	Loss:1.625	translation_Loss:0.682	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.943                                                   	MRR:28.15	Hits@10:47.07	Best:28.15
2024-12-27 23:21:55,617: Snapshot:3	Epoch:23	Loss:1.581	translation_Loss:0.642	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.939                                                   	MRR:28.16	Hits@10:47.12	Best:28.16
2024-12-27 23:21:59,391: Snapshot:3	Epoch:24	Loss:1.539	translation_Loss:0.606	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.933                                                   	MRR:28.28	Hits@10:47.18	Best:28.28
2024-12-27 23:22:03,080: Snapshot:3	Epoch:25	Loss:1.495	translation_Loss:0.568	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.927                                                   	MRR:28.41	Hits@10:47.26	Best:28.41
2024-12-27 23:22:06,698: Snapshot:3	Epoch:26	Loss:1.458	translation_Loss:0.539	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.919                                                   	MRR:28.63	Hits@10:47.36	Best:28.63
2024-12-27 23:22:10,312: Snapshot:3	Epoch:27	Loss:1.429	translation_Loss:0.517	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.911                                                   	MRR:28.51	Hits@10:47.35	Best:28.63
2024-12-27 23:22:13,909: Snapshot:3	Epoch:28	Loss:1.405	translation_Loss:0.502	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.903                                                   	MRR:28.55	Hits@10:47.28	Best:28.63
2024-12-27 23:22:17,559: Snapshot:3	Epoch:29	Loss:1.375	translation_Loss:0.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.895                                                   	MRR:28.67	Hits@10:47.1	Best:28.67
2024-12-27 23:22:21,721: Snapshot:3	Epoch:30	Loss:1.347	translation_Loss:0.46	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.887                                                   	MRR:28.6	Hits@10:47.16	Best:28.67
2024-12-27 23:22:25,319: Snapshot:3	Epoch:31	Loss:1.32	translation_Loss:0.443	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.878                                                   	MRR:28.59	Hits@10:47.25	Best:28.67
2024-12-27 23:22:29,013: Snapshot:3	Epoch:32	Loss:1.298	translation_Loss:0.43	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.868                                                   	MRR:28.74	Hits@10:47.14	Best:28.74
2024-12-27 23:22:32,654: Snapshot:3	Epoch:33	Loss:1.273	translation_Loss:0.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.859                                                   	MRR:28.7	Hits@10:47.14	Best:28.74
2024-12-27 23:22:36,335: Snapshot:3	Epoch:34	Loss:1.245	translation_Loss:0.395	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.85                                                   	MRR:28.77	Hits@10:47.29	Best:28.77
2024-12-27 23:22:40,056: Snapshot:3	Epoch:35	Loss:1.232	translation_Loss:0.393	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.84                                                   	MRR:28.8	Hits@10:47.34	Best:28.8
2024-12-27 23:22:43,770: Snapshot:3	Epoch:36	Loss:1.212	translation_Loss:0.381	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.831                                                   	MRR:28.81	Hits@10:47.28	Best:28.81
2024-12-27 23:22:47,381: Snapshot:3	Epoch:37	Loss:1.191	translation_Loss:0.369	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.822                                                   	MRR:28.73	Hits@10:47.15	Best:28.81
2024-12-27 23:22:51,066: Snapshot:3	Epoch:38	Loss:1.166	translation_Loss:0.352	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.814                                                   	MRR:28.92	Hits@10:47.33	Best:28.92
2024-12-27 23:22:54,832: Snapshot:3	Epoch:39	Loss:1.154	translation_Loss:0.349	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.805                                                   	MRR:28.9	Hits@10:47.24	Best:28.92
2024-12-27 23:22:58,422: Snapshot:3	Epoch:40	Loss:1.139	translation_Loss:0.343	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.796                                                   	MRR:28.84	Hits@10:47.38	Best:28.92
2024-12-27 23:23:02,468: Snapshot:3	Epoch:41	Loss:1.115	translation_Loss:0.328	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.787                                                   	MRR:29.01	Hits@10:47.39	Best:29.01
2024-12-27 23:23:06,050: Snapshot:3	Epoch:42	Loss:1.099	translation_Loss:0.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.777                                                   	MRR:28.99	Hits@10:47.44	Best:29.01
2024-12-27 23:23:10,098: Snapshot:3	Epoch:43	Loss:1.09	translation_Loss:0.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.769                                                   	MRR:29.11	Hits@10:47.39	Best:29.11
2024-12-27 23:23:13,772: Snapshot:3	Epoch:44	Loss:1.071	translation_Loss:0.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.761                                                   	MRR:29.15	Hits@10:47.44	Best:29.15
2024-12-27 23:23:17,369: Snapshot:3	Epoch:45	Loss:1.058	translation_Loss:0.305	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.753                                                   	MRR:28.96	Hits@10:47.34	Best:29.15
2024-12-27 23:23:20,937: Snapshot:3	Epoch:46	Loss:1.045	translation_Loss:0.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.746                                                   	MRR:29.07	Hits@10:47.39	Best:29.15
2024-12-27 23:23:24,607: Snapshot:3	Epoch:47	Loss:1.033	translation_Loss:0.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.738                                                   	MRR:29.14	Hits@10:47.38	Best:29.15
2024-12-27 23:23:28,254: Snapshot:3	Epoch:48	Loss:1.019	translation_Loss:0.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.73                                                   	MRR:29.27	Hits@10:47.34	Best:29.27
2024-12-27 23:23:31,934: Snapshot:3	Epoch:49	Loss:1.006	translation_Loss:0.283	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.723                                                   	MRR:29.31	Hits@10:47.37	Best:29.31
2024-12-27 23:23:35,593: Snapshot:3	Epoch:50	Loss:0.992	translation_Loss:0.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.715                                                   	MRR:29.21	Hits@10:47.52	Best:29.31
2024-12-27 23:23:39,196: Snapshot:3	Epoch:51	Loss:0.979	translation_Loss:0.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.708                                                   	MRR:29.29	Hits@10:47.48	Best:29.31
2024-12-27 23:23:43,304: Snapshot:3	Epoch:52	Loss:0.972	translation_Loss:0.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.7                                                   	MRR:29.26	Hits@10:47.55	Best:29.31
2024-12-27 23:23:46,975: Snapshot:3	Epoch:53	Loss:0.959	translation_Loss:0.266	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.693                                                   	MRR:29.33	Hits@10:47.52	Best:29.33
2024-12-27 23:23:50,568: Snapshot:3	Epoch:54	Loss:0.946	translation_Loss:0.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.685                                                   	MRR:29.27	Hits@10:47.58	Best:29.33
2024-12-27 23:23:54,207: Snapshot:3	Epoch:55	Loss:0.94	translation_Loss:0.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.679                                                   	MRR:29.32	Hits@10:47.52	Best:29.33
2024-12-27 23:23:57,860: Snapshot:3	Epoch:56	Loss:0.931	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.673                                                   	MRR:29.52	Hits@10:47.5	Best:29.52
2024-12-27 23:24:01,483: Snapshot:3	Epoch:57	Loss:0.921	translation_Loss:0.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.667                                                   	MRR:29.52	Hits@10:47.55	Best:29.52
2024-12-27 23:24:05,106: Snapshot:3	Epoch:58	Loss:0.915	translation_Loss:0.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.661                                                   	MRR:29.47	Hits@10:47.4	Best:29.52
2024-12-27 23:24:08,734: Snapshot:3	Epoch:59	Loss:0.903	translation_Loss:0.248	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.655                                                   	MRR:29.5	Hits@10:47.5	Best:29.52
2024-12-27 23:24:12,325: Snapshot:3	Epoch:60	Loss:0.896	translation_Loss:0.247	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.649                                                   	MRR:29.39	Hits@10:47.49	Best:29.52
2024-12-27 23:24:15,911: Early Stopping! Snapshot: 3 Epoch: 61 Best Results: 29.52
2024-12-27 23:24:15,911: Start to training tokens! Snapshot: 3 Epoch: 61 Loss:0.885 MRR:29.4 Best Results: 29.52
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 23:24:15,912: Snapshot:3	Epoch:61	Loss:0.885	translation_Loss:0.241	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.643                                                   	MRR:29.4	Hits@10:47.51	Best:29.52
2024-12-27 23:24:19,417: Snapshot:3	Epoch:62	Loss:6.804	translation_Loss:6.481	multi_layer_Loss:0.323	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:29.4	Hits@10:47.51	Best:29.52
2024-12-27 23:24:23,364: End of token training: 3 Epoch: 63 Loss:6.723 MRR:29.4 Best Results: 29.52
2024-12-27 23:24:23,364: Snapshot:3	Epoch:63	Loss:6.723	translation_Loss:6.462	multi_layer_Loss:0.261	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:29.4	Hits@10:47.51	Best:29.52
2024-12-27 23:24:23,653: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_10000/3model_best.tar'
2024-12-27 23:24:38,578: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1956 | 0.099  | 0.2472 | 0.3111 |  0.378  |
|     1      | 0.1329 | 0.0618 | 0.1563 | 0.2066 |  0.275  |
|     2      | 0.1656 | 0.0855 | 0.1836 | 0.2357 |  0.3226 |
|     3      | 0.3004 | 0.2049 | 0.3427 | 0.4009 |  0.4759 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-27 23:24:50,747: Snapshot:4	Epoch:0	Loss:5.773	translation_Loss:5.759	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.014                                                   	MRR:4.66	Hits@10:13.43	Best:4.66
2024-12-27 23:24:53,367: Snapshot:4	Epoch:1	Loss:4.963	translation_Loss:4.911	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.052                                                   	MRR:6.06	Hits@10:17.08	Best:6.06
2024-12-27 23:24:56,042: Snapshot:4	Epoch:2	Loss:4.306	translation_Loss:4.214	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:7.39	Hits@10:19.7	Best:7.39
2024-12-27 23:24:58,651: Snapshot:4	Epoch:3	Loss:3.79	translation_Loss:3.658	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.133                                                   	MRR:8.56	Hits@10:22.1	Best:8.56
2024-12-27 23:25:01,296: Snapshot:4	Epoch:4	Loss:3.349	translation_Loss:3.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.172                                                   	MRR:9.84	Hits@10:24.25	Best:9.84
2024-12-27 23:25:03,934: Snapshot:4	Epoch:5	Loss:2.985	translation_Loss:2.775	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:11.05	Hits@10:26.52	Best:11.05
2024-12-27 23:25:06,550: Snapshot:4	Epoch:6	Loss:2.679	translation_Loss:2.435	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.244                                                   	MRR:12.07	Hits@10:28.48	Best:12.07
2024-12-27 23:25:09,181: Snapshot:4	Epoch:7	Loss:2.415	translation_Loss:2.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.278                                                   	MRR:13.31	Hits@10:30.96	Best:13.31
2024-12-27 23:25:11,819: Snapshot:4	Epoch:8	Loss:2.184	translation_Loss:1.875	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.309                                                   	MRR:14.59	Hits@10:34.13	Best:14.59
2024-12-27 23:25:14,528: Snapshot:4	Epoch:9	Loss:1.985	translation_Loss:1.646	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.338                                                   	MRR:15.98	Hits@10:37.09	Best:15.98
2024-12-27 23:25:17,108: Snapshot:4	Epoch:10	Loss:1.814	translation_Loss:1.448	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.365                                                   	MRR:17.39	Hits@10:39.88	Best:17.39
2024-12-27 23:25:19,735: Snapshot:4	Epoch:11	Loss:1.665	translation_Loss:1.275	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.39                                                   	MRR:18.48	Hits@10:41.76	Best:18.48
2024-12-27 23:25:22,363: Snapshot:4	Epoch:12	Loss:1.53	translation_Loss:1.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.412                                                   	MRR:19.52	Hits@10:43.47	Best:19.52
2024-12-27 23:25:24,959: Snapshot:4	Epoch:13	Loss:1.417	translation_Loss:0.987	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.431                                                   	MRR:20.5	Hits@10:44.99	Best:20.5
2024-12-27 23:25:27,560: Snapshot:4	Epoch:14	Loss:1.313	translation_Loss:0.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.446                                                   	MRR:21.17	Hits@10:45.49	Best:21.17
2024-12-27 23:25:30,626: Snapshot:4	Epoch:15	Loss:1.223	translation_Loss:0.765	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.459                                                   	MRR:21.53	Hits@10:46.4	Best:21.53
2024-12-27 23:25:33,248: Snapshot:4	Epoch:16	Loss:1.142	translation_Loss:0.673	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.469                                                   	MRR:22.14	Hits@10:46.85	Best:22.14
2024-12-27 23:25:35,871: Snapshot:4	Epoch:17	Loss:1.066	translation_Loss:0.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.477                                                   	MRR:23.05	Hits@10:47.27	Best:23.05
2024-12-27 23:25:38,482: Snapshot:4	Epoch:18	Loss:0.997	translation_Loss:0.513	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.484                                                   	MRR:24.03	Hits@10:48.08	Best:24.03
2024-12-27 23:25:41,100: Snapshot:4	Epoch:19	Loss:0.928	translation_Loss:0.44	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.488                                                   	MRR:24.74	Hits@10:48.55	Best:24.74
2024-12-27 23:25:43,715: Snapshot:4	Epoch:20	Loss:0.879	translation_Loss:0.388	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.491                                                   	MRR:24.96	Hits@10:48.77	Best:24.96
2024-12-27 23:25:46,371: Snapshot:4	Epoch:21	Loss:0.84	translation_Loss:0.348	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.492                                                   	MRR:25.09	Hits@10:48.93	Best:25.09
2024-12-27 23:25:49,035: Snapshot:4	Epoch:22	Loss:0.811	translation_Loss:0.319	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.493                                                   	MRR:25.16	Hits@10:49.25	Best:25.16
2024-12-27 23:25:51,764: Snapshot:4	Epoch:23	Loss:0.782	translation_Loss:0.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.492                                                   	MRR:25.54	Hits@10:49.78	Best:25.54
2024-12-27 23:25:54,411: Snapshot:4	Epoch:24	Loss:0.764	translation_Loss:0.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.491                                                   	MRR:25.66	Hits@10:49.85	Best:25.66
2024-12-27 23:25:57,013: Snapshot:4	Epoch:25	Loss:0.743	translation_Loss:0.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.489                                                   	MRR:25.95	Hits@10:50.19	Best:25.95
2024-12-27 23:25:59,586: Snapshot:4	Epoch:26	Loss:0.728	translation_Loss:0.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.486                                                   	MRR:25.88	Hits@10:50.13	Best:25.95
2024-12-27 23:26:02,138: Snapshot:4	Epoch:27	Loss:0.713	translation_Loss:0.229	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.484                                                   	MRR:25.95	Hits@10:50.14	Best:25.95
2024-12-27 23:26:04,758: Snapshot:4	Epoch:28	Loss:0.699	translation_Loss:0.218	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.481                                                   	MRR:26.09	Hits@10:50.27	Best:26.09
2024-12-27 23:26:07,403: Snapshot:4	Epoch:29	Loss:0.683	translation_Loss:0.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.478                                                   	MRR:26.22	Hits@10:50.49	Best:26.22
2024-12-27 23:26:10,019: Snapshot:4	Epoch:30	Loss:0.67	translation_Loss:0.196	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.474                                                   	MRR:26.48	Hits@10:50.59	Best:26.48
2024-12-27 23:26:13,056: Snapshot:4	Epoch:31	Loss:0.657	translation_Loss:0.187	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.47                                                   	MRR:26.54	Hits@10:51.25	Best:26.54
2024-12-27 23:26:15,694: Snapshot:4	Epoch:32	Loss:0.647	translation_Loss:0.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.466                                                   	MRR:26.57	Hits@10:51.4	Best:26.57
2024-12-27 23:26:18,246: Snapshot:4	Epoch:33	Loss:0.635	translation_Loss:0.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.462                                                   	MRR:26.49	Hits@10:51.42	Best:26.57
2024-12-27 23:26:20,836: Snapshot:4	Epoch:34	Loss:0.622	translation_Loss:0.164	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.458                                                   	MRR:26.64	Hits@10:51.05	Best:26.64
2024-12-27 23:26:23,454: Snapshot:4	Epoch:35	Loss:0.615	translation_Loss:0.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.453                                                   	MRR:26.88	Hits@10:51.29	Best:26.88
2024-12-27 23:26:26,077: Snapshot:4	Epoch:36	Loss:0.606	translation_Loss:0.157	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.449                                                   	MRR:26.87	Hits@10:51.19	Best:26.88
2024-12-27 23:26:28,673: Snapshot:4	Epoch:37	Loss:0.597	translation_Loss:0.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.444                                                   	MRR:26.93	Hits@10:50.97	Best:26.93
2024-12-27 23:26:31,305: Snapshot:4	Epoch:38	Loss:0.587	translation_Loss:0.147	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.44                                                   	MRR:27.0	Hits@10:51.29	Best:27.0
2024-12-27 23:26:34,034: Snapshot:4	Epoch:39	Loss:0.578	translation_Loss:0.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.436                                                   	MRR:27.12	Hits@10:51.11	Best:27.12
2024-12-27 23:26:36,630: Snapshot:4	Epoch:40	Loss:0.568	translation_Loss:0.137	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.431                                                   	MRR:27.31	Hits@10:51.22	Best:27.31
2024-12-27 23:26:39,240: Snapshot:4	Epoch:41	Loss:0.563	translation_Loss:0.137	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.426                                                   	MRR:27.34	Hits@10:51.53	Best:27.34
2024-12-27 23:26:41,906: Snapshot:4	Epoch:42	Loss:0.556	translation_Loss:0.133	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.422                                                   	MRR:27.44	Hits@10:51.61	Best:27.44
2024-12-27 23:26:44,483: Snapshot:4	Epoch:43	Loss:0.55	translation_Loss:0.131	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.419                                                   	MRR:27.44	Hits@10:51.52	Best:27.44
2024-12-27 23:26:47,048: Snapshot:4	Epoch:44	Loss:0.542	translation_Loss:0.127	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.415                                                   	MRR:27.38	Hits@10:51.91	Best:27.44
2024-12-27 23:26:49,659: Snapshot:4	Epoch:45	Loss:0.534	translation_Loss:0.124	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.41                                                   	MRR:27.48	Hits@10:51.84	Best:27.48
2024-12-27 23:26:52,272: Snapshot:4	Epoch:46	Loss:0.529	translation_Loss:0.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.406                                                   	MRR:27.51	Hits@10:51.84	Best:27.51
2024-12-27 23:26:55,282: Snapshot:4	Epoch:47	Loss:0.522	translation_Loss:0.12	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.402                                                   	MRR:27.47	Hits@10:52.07	Best:27.51
2024-12-27 23:26:57,899: Snapshot:4	Epoch:48	Loss:0.512	translation_Loss:0.115	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.398                                                   	MRR:27.57	Hits@10:51.99	Best:27.57
2024-12-27 23:27:00,489: Snapshot:4	Epoch:49	Loss:0.512	translation_Loss:0.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.394                                                   	MRR:27.61	Hits@10:52.21	Best:27.61
2024-12-27 23:27:03,113: Snapshot:4	Epoch:50	Loss:0.502	translation_Loss:0.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.39                                                   	MRR:27.65	Hits@10:52.08	Best:27.65
2024-12-27 23:27:05,739: Snapshot:4	Epoch:51	Loss:0.496	translation_Loss:0.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.386                                                   	MRR:27.69	Hits@10:51.85	Best:27.69
2024-12-27 23:27:08,385: Snapshot:4	Epoch:52	Loss:0.487	translation_Loss:0.105	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.381                                                   	MRR:27.7	Hits@10:51.86	Best:27.7
2024-12-27 23:27:11,037: Snapshot:4	Epoch:53	Loss:0.481	translation_Loss:0.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.377                                                   	MRR:27.76	Hits@10:51.9	Best:27.76
2024-12-27 23:27:13,756: Snapshot:4	Epoch:54	Loss:0.478	translation_Loss:0.105	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.373                                                   	MRR:27.81	Hits@10:52.01	Best:27.81
2024-12-27 23:27:16,386: Snapshot:4	Epoch:55	Loss:0.473	translation_Loss:0.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.369                                                   	MRR:27.9	Hits@10:52.13	Best:27.9
2024-12-27 23:27:18,991: Snapshot:4	Epoch:56	Loss:0.466	translation_Loss:0.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.365                                                   	MRR:27.77	Hits@10:52.32	Best:27.9
2024-12-27 23:27:21,542: Snapshot:4	Epoch:57	Loss:0.462	translation_Loss:0.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.362                                                   	MRR:27.84	Hits@10:52.32	Best:27.9
2024-12-27 23:27:24,117: Snapshot:4	Epoch:58	Loss:0.454	translation_Loss:0.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.358                                                   	MRR:27.76	Hits@10:52.2	Best:27.9
2024-12-27 23:27:26,677: Snapshot:4	Epoch:59	Loss:0.451	translation_Loss:0.097	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.354                                                   	MRR:27.88	Hits@10:52.34	Best:27.9
2024-12-27 23:27:29,308: Snapshot:4	Epoch:60	Loss:0.45	translation_Loss:0.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.35                                                   	MRR:28.02	Hits@10:52.37	Best:28.02
2024-12-27 23:27:31,938: Snapshot:4	Epoch:61	Loss:0.442	translation_Loss:0.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.347                                                   	MRR:28.01	Hits@10:52.5	Best:28.02
2024-12-27 23:27:34,502: Snapshot:4	Epoch:62	Loss:0.436	translation_Loss:0.092	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.344                                                   	MRR:27.96	Hits@10:52.55	Best:28.02
2024-12-27 23:27:37,449: Snapshot:4	Epoch:63	Loss:0.436	translation_Loss:0.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.341                                                   	MRR:27.89	Hits@10:52.55	Best:28.02
2024-12-27 23:27:40,015: Snapshot:4	Epoch:64	Loss:0.427	translation_Loss:0.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.338                                                   	MRR:28.05	Hits@10:52.6	Best:28.05
2024-12-27 23:27:42,653: Snapshot:4	Epoch:65	Loss:0.426	translation_Loss:0.091	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.334                                                   	MRR:28.13	Hits@10:52.62	Best:28.13
2024-12-27 23:27:45,306: Snapshot:4	Epoch:66	Loss:0.422	translation_Loss:0.091	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.331                                                   	MRR:28.15	Hits@10:52.85	Best:28.15
2024-12-27 23:27:47,906: Snapshot:4	Epoch:67	Loss:0.418	translation_Loss:0.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.328                                                   	MRR:28.28	Hits@10:52.65	Best:28.28
2024-12-27 23:27:50,535: Snapshot:4	Epoch:68	Loss:0.411	translation_Loss:0.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.325                                                   	MRR:28.39	Hits@10:52.45	Best:28.39
2024-12-27 23:27:53,120: Snapshot:4	Epoch:69	Loss:0.408	translation_Loss:0.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.322                                                   	MRR:28.36	Hits@10:52.57	Best:28.39
2024-12-27 23:27:55,688: Snapshot:4	Epoch:70	Loss:0.404	translation_Loss:0.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.318                                                   	MRR:28.25	Hits@10:52.4	Best:28.39
2024-12-27 23:27:58,264: Snapshot:4	Epoch:71	Loss:0.401	translation_Loss:0.086	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.315                                                   	MRR:28.1	Hits@10:52.58	Best:28.39
2024-12-27 23:28:00,829: Snapshot:4	Epoch:72	Loss:0.392	translation_Loss:0.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.312                                                   	MRR:28.17	Hits@10:52.56	Best:28.39
2024-12-27 23:28:03,397: Early Stopping! Snapshot: 4 Epoch: 73 Best Results: 28.39
2024-12-27 23:28:03,397: Start to training tokens! Snapshot: 4 Epoch: 73 Loss:0.388 MRR:28.21 Best Results: 28.39
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 23:28:03,397: Snapshot:4	Epoch:73	Loss:0.388	translation_Loss:0.079	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.309                                                   	MRR:28.21	Hits@10:52.62	Best:28.39
2024-12-27 23:28:05,918: Snapshot:4	Epoch:74	Loss:3.981	translation_Loss:3.731	multi_layer_Loss:0.249	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.21	Hits@10:52.62	Best:28.39
2024-12-27 23:28:08,416: End of token training: 4 Epoch: 75 Loss:3.948 MRR:28.21 Best Results: 28.39
2024-12-27 23:28:08,416: Snapshot:4	Epoch:75	Loss:3.948	translation_Loss:3.729	multi_layer_Loss:0.219	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:28.21	Hits@10:52.62	Best:28.39
2024-12-27 23:28:08,756: => loading checkpoint './checkpoint/RELATIONrelation_0.0001_2048_10000/4model_best.tar'
2024-12-27 23:28:25,495: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1847 | 0.0942 | 0.2322 | 0.2919 |  0.3516 |
|     1      | 0.1297 | 0.059  | 0.1526 | 0.2021 |  0.2713 |
|     2      | 0.1599 | 0.0856 | 0.1754 | 0.2229 |  0.3031 |
|     3      | 0.2614 | 0.1771 | 0.2948 | 0.3425 |  0.4129 |
|     4      | 0.2792 | 0.1601 | 0.3169 | 0.4025 |  0.5278 |
+------------+--------+--------+--------+--------+---------+
2024-12-27 23:28:25,497: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2753 | 0.1615 | 0.3442 | 0.412  |  0.4836 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2379 | 0.1255 | 0.3022 | 0.372  |  0.4467 |
|     1      | 0.1664 | 0.0837 | 0.1982 | 0.2539 |  0.3255 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1986 | 0.0998 | 0.2528 | 0.3159 |  0.3853 |
|     1      | 0.1366 | 0.0652 | 0.1615 | 0.2116 |  0.2769 |
|     2      | 0.222  | 0.1322 | 0.2474 | 0.3134 |  0.4019 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1956 | 0.099  | 0.2472 | 0.3111 |  0.378  |
|     1      | 0.1329 | 0.0618 | 0.1563 | 0.2066 |  0.275  |
|     2      | 0.1656 | 0.0855 | 0.1836 | 0.2357 |  0.3226 |
|     3      | 0.3004 | 0.2049 | 0.3427 | 0.4009 |  0.4759 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1847 | 0.0942 | 0.2322 | 0.2919 |  0.3516 |
|     1      | 0.1297 | 0.059  | 0.1526 | 0.2021 |  0.2713 |
|     2      | 0.1599 | 0.0856 | 0.1754 | 0.2229 |  0.3031 |
|     3      | 0.2614 | 0.1771 | 0.2948 | 0.3425 |  0.4129 |
|     4      | 0.2792 | 0.1601 | 0.3169 | 0.4025 |  0.5278 |
+------------+--------+--------+--------+--------+---------+]
2024-12-27 23:28:25,498: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 596.6268167495728  |   0.275   |    0.162     |    0.344     |     0.484     |
|    1     | 366.0637171268463  |   0.203   |    0.105     |    0.252     |     0.388     |
|    2     | 231.07412838935852 |   0.182   |    0.096     |    0.218     |      0.35     |
|    3     | 246.40802264213562 |   0.179   |    0.095     |    0.213     |     0.342     |
|    4     | 208.3505597114563  |   0.177   |    0.094     |    0.208     |     0.335     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-27 23:28:25,498: Sum_Training_Time:1648.5232446193695
2024-12-27 23:28:25,498: Every_Training_Time:[596.6268167495728, 366.0637171268463, 231.07412838935852, 246.40802264213562, 208.3505597114563]
2024-12-27 23:28:25,498: Forward transfer: 0.018349999999999998 Backward transfer: -0.05709999999999999
2024-12-27 23:29:02,757: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=1e-05, lifelong_name='double_tokened', log_path='./logs/20241227232829/RELATIONrelation_0.00001_512_1000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.00001_512_1000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.00001_512_1000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=1000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-27 23:29:18,749: Snapshot:0	Epoch:0	Loss:165.062	translation_Loss:165.062	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:1.83	Hits@10:1.85	Best:1.83
2024-12-27 23:29:30,426: Snapshot:0	Epoch:1	Loss:162.089	translation_Loss:162.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:1.89	Hits@10:1.99	Best:1.89
2024-12-27 23:29:42,142: Snapshot:0	Epoch:2	Loss:159.039	translation_Loss:159.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:2.08	Hits@10:2.48	Best:2.08
2024-12-27 23:29:53,657: Snapshot:0	Epoch:3	Loss:156.025	translation_Loss:156.025	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:2.65	Hits@10:4.15	Best:2.65
2024-12-27 23:30:05,330: Snapshot:0	Epoch:4	Loss:153.079	translation_Loss:153.079	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:3.63	Hits@10:6.75	Best:3.63
2024-12-27 23:30:16,972: Snapshot:0	Epoch:5	Loss:150.267	translation_Loss:150.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.8	Hits@10:9.61	Best:4.8
2024-12-27 23:30:28,713: Snapshot:0	Epoch:6	Loss:147.532	translation_Loss:147.532	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:5.9	Hits@10:12.07	Best:5.9
2024-12-27 23:30:40,895: Snapshot:0	Epoch:7	Loss:144.844	translation_Loss:144.844	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:6.8	Hits@10:14.01	Best:6.8
2024-12-27 23:30:52,489: Snapshot:0	Epoch:8	Loss:142.33	translation_Loss:142.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.41	Hits@10:15.28	Best:7.41
2024-12-27 23:31:04,060: Snapshot:0	Epoch:9	Loss:139.836	translation_Loss:139.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.84	Hits@10:16.31	Best:7.84
2024-12-27 23:31:15,640: Snapshot:0	Epoch:10	Loss:137.505	translation_Loss:137.505	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.15	Hits@10:17.17	Best:8.15
2024-12-27 23:31:27,355: Snapshot:0	Epoch:11	Loss:135.246	translation_Loss:135.246	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.39	Hits@10:17.93	Best:8.39
2024-12-27 23:31:39,079: Snapshot:0	Epoch:12	Loss:132.99	translation_Loss:132.99	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.6	Hits@10:18.62	Best:8.6
2024-12-27 23:31:50,718: Snapshot:0	Epoch:13	Loss:130.929	translation_Loss:130.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.8	Hits@10:19.27	Best:8.8
2024-12-27 23:32:02,420: Snapshot:0	Epoch:14	Loss:128.817	translation_Loss:128.817	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.97	Hits@10:19.81	Best:8.97
2024-12-27 23:32:14,069: Snapshot:0	Epoch:15	Loss:126.902	translation_Loss:126.902	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.12	Hits@10:20.3	Best:9.12
2024-12-27 23:32:25,604: Snapshot:0	Epoch:16	Loss:124.769	translation_Loss:124.769	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.27	Hits@10:20.79	Best:9.27
2024-12-27 23:32:37,258: Snapshot:0	Epoch:17	Loss:122.834	translation_Loss:122.834	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.4	Hits@10:21.26	Best:9.4
2024-12-27 23:32:48,999: Snapshot:0	Epoch:18	Loss:120.914	translation_Loss:120.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.54	Hits@10:21.68	Best:9.54
2024-12-27 23:33:01,111: Snapshot:0	Epoch:19	Loss:118.966	translation_Loss:118.966	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.67	Hits@10:22.11	Best:9.67
2024-12-27 23:33:12,790: Snapshot:0	Epoch:20	Loss:117.16	translation_Loss:117.16	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.8	Hits@10:22.5	Best:9.8
2024-12-27 23:33:24,419: Snapshot:0	Epoch:21	Loss:115.205	translation_Loss:115.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.92	Hits@10:22.9	Best:9.92
2024-12-27 23:33:36,099: Snapshot:0	Epoch:22	Loss:113.455	translation_Loss:113.455	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.05	Hits@10:23.3	Best:10.05
2024-12-27 23:33:47,733: Snapshot:0	Epoch:23	Loss:111.59	translation_Loss:111.59	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.2	Hits@10:23.77	Best:10.2
2024-12-27 23:33:59,339: Snapshot:0	Epoch:24	Loss:109.708	translation_Loss:109.708	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.36	Hits@10:24.18	Best:10.36
2024-12-27 23:34:11,137: Snapshot:0	Epoch:25	Loss:108.053	translation_Loss:108.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.54	Hits@10:24.65	Best:10.54
2024-12-27 23:34:22,753: Snapshot:0	Epoch:26	Loss:106.172	translation_Loss:106.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.75	Hits@10:25.22	Best:10.75
2024-12-27 23:34:34,375: Snapshot:0	Epoch:27	Loss:104.393	translation_Loss:104.393	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.97	Hits@10:25.72	Best:10.97
2024-12-27 23:34:46,019: Snapshot:0	Epoch:28	Loss:102.674	translation_Loss:102.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.24	Hits@10:26.22	Best:11.24
2024-12-27 23:34:57,645: Snapshot:0	Epoch:29	Loss:100.893	translation_Loss:100.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.51	Hits@10:26.74	Best:11.51
2024-12-27 23:35:09,402: Snapshot:0	Epoch:30	Loss:99.101	translation_Loss:99.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.81	Hits@10:27.37	Best:11.81
2024-12-27 23:35:21,048: Snapshot:0	Epoch:31	Loss:97.402	translation_Loss:97.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.09	Hits@10:27.94	Best:12.09
2024-12-27 23:35:33,189: Snapshot:0	Epoch:32	Loss:95.6	translation_Loss:95.6	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.43	Hits@10:28.47	Best:12.43
2024-12-27 23:35:44,844: Snapshot:0	Epoch:33	Loss:93.962	translation_Loss:93.962	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.76	Hits@10:29.16	Best:12.76
2024-12-27 23:35:56,471: Snapshot:0	Epoch:34	Loss:92.111	translation_Loss:92.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.1	Hits@10:29.76	Best:13.1
2024-12-27 23:36:08,033: Snapshot:0	Epoch:35	Loss:90.548	translation_Loss:90.548	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.47	Hits@10:30.33	Best:13.47
2024-12-27 23:36:19,631: Snapshot:0	Epoch:36	Loss:88.741	translation_Loss:88.741	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.84	Hits@10:31.0	Best:13.84
2024-12-27 23:36:31,421: Snapshot:0	Epoch:37	Loss:87.076	translation_Loss:87.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.21	Hits@10:31.6	Best:14.21
2024-12-27 23:36:43,034: Snapshot:0	Epoch:38	Loss:85.453	translation_Loss:85.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.58	Hits@10:32.29	Best:14.58
2024-12-27 23:36:54,604: Snapshot:0	Epoch:39	Loss:83.863	translation_Loss:83.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.92	Hits@10:32.94	Best:14.92
2024-12-27 23:37:06,336: Snapshot:0	Epoch:40	Loss:82.025	translation_Loss:82.025	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.3	Hits@10:33.48	Best:15.3
2024-12-27 23:37:18,007: Snapshot:0	Epoch:41	Loss:80.438	translation_Loss:80.438	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.66	Hits@10:33.98	Best:15.66
2024-12-27 23:37:29,712: Snapshot:0	Epoch:42	Loss:78.854	translation_Loss:78.854	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.05	Hits@10:34.48	Best:16.05
2024-12-27 23:37:41,415: Snapshot:0	Epoch:43	Loss:77.206	translation_Loss:77.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.4	Hits@10:34.98	Best:16.4
2024-12-27 23:37:53,493: Snapshot:0	Epoch:44	Loss:75.556	translation_Loss:75.556	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.73	Hits@10:35.57	Best:16.73
2024-12-27 23:38:05,187: Snapshot:0	Epoch:45	Loss:73.95	translation_Loss:73.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.03	Hits@10:36.0	Best:17.03
2024-12-27 23:38:16,927: Snapshot:0	Epoch:46	Loss:72.368	translation_Loss:72.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.35	Hits@10:36.54	Best:17.35
2024-12-27 23:38:28,532: Snapshot:0	Epoch:47	Loss:70.792	translation_Loss:70.792	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.63	Hits@10:36.91	Best:17.63
2024-12-27 23:38:40,304: Snapshot:0	Epoch:48	Loss:69.198	translation_Loss:69.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.9	Hits@10:37.37	Best:17.9
2024-12-27 23:38:52,061: Snapshot:0	Epoch:49	Loss:67.67	translation_Loss:67.67	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.18	Hits@10:37.8	Best:18.18
2024-12-27 23:39:03,730: Snapshot:0	Epoch:50	Loss:66.104	translation_Loss:66.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.44	Hits@10:38.19	Best:18.44
2024-12-27 23:39:15,361: Snapshot:0	Epoch:51	Loss:64.635	translation_Loss:64.635	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.68	Hits@10:38.58	Best:18.68
2024-12-27 23:39:27,096: Snapshot:0	Epoch:52	Loss:63.251	translation_Loss:63.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.92	Hits@10:38.92	Best:18.92
2024-12-27 23:39:38,685: Snapshot:0	Epoch:53	Loss:61.702	translation_Loss:61.702	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.17	Hits@10:39.22	Best:19.17
2024-12-27 23:39:50,305: Snapshot:0	Epoch:54	Loss:60.29	translation_Loss:60.29	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.38	Hits@10:39.56	Best:19.38
2024-12-27 23:40:01,958: Snapshot:0	Epoch:55	Loss:58.969	translation_Loss:58.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.57	Hits@10:39.87	Best:19.57
2024-12-27 23:40:13,714: Snapshot:0	Epoch:56	Loss:57.662	translation_Loss:57.662	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.73	Hits@10:40.19	Best:19.73
2024-12-27 23:40:25,686: Snapshot:0	Epoch:57	Loss:56.231	translation_Loss:56.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.95	Hits@10:40.42	Best:19.95
2024-12-27 23:40:37,410: Snapshot:0	Epoch:58	Loss:55.009	translation_Loss:55.009	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.15	Hits@10:40.67	Best:20.15
2024-12-27 23:40:48,941: Snapshot:0	Epoch:59	Loss:53.637	translation_Loss:53.637	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.35	Hits@10:40.93	Best:20.35
2024-12-27 23:41:00,534: Snapshot:0	Epoch:60	Loss:52.48	translation_Loss:52.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.52	Hits@10:41.16	Best:20.52
2024-12-27 23:41:12,270: Snapshot:0	Epoch:61	Loss:51.322	translation_Loss:51.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.71	Hits@10:41.39	Best:20.71
2024-12-27 23:41:24,024: Snapshot:0	Epoch:62	Loss:50.026	translation_Loss:50.026	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.87	Hits@10:41.57	Best:20.87
2024-12-27 23:41:35,588: Snapshot:0	Epoch:63	Loss:48.908	translation_Loss:48.908	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.02	Hits@10:41.76	Best:21.02
2024-12-27 23:41:47,202: Snapshot:0	Epoch:64	Loss:47.669	translation_Loss:47.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.19	Hits@10:41.98	Best:21.19
2024-12-27 23:41:58,826: Snapshot:0	Epoch:65	Loss:46.651	translation_Loss:46.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.35	Hits@10:42.12	Best:21.35
2024-12-27 23:42:10,522: Snapshot:0	Epoch:66	Loss:45.62	translation_Loss:45.62	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.53	Hits@10:42.33	Best:21.53
2024-12-27 23:42:22,124: Snapshot:0	Epoch:67	Loss:44.525	translation_Loss:44.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.68	Hits@10:42.55	Best:21.68
2024-12-27 23:42:33,870: Snapshot:0	Epoch:68	Loss:43.562	translation_Loss:43.562	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.82	Hits@10:42.66	Best:21.82
2024-12-27 23:42:46,046: Snapshot:0	Epoch:69	Loss:42.385	translation_Loss:42.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.98	Hits@10:42.81	Best:21.98
2024-12-27 23:42:57,800: Snapshot:0	Epoch:70	Loss:41.44	translation_Loss:41.44	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.14	Hits@10:42.99	Best:22.14
2024-12-27 23:43:09,570: Snapshot:0	Epoch:71	Loss:40.482	translation_Loss:40.482	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.26	Hits@10:43.19	Best:22.26
2024-12-27 23:43:21,169: Snapshot:0	Epoch:72	Loss:39.485	translation_Loss:39.485	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.38	Hits@10:43.34	Best:22.38
2024-12-27 23:43:32,818: Snapshot:0	Epoch:73	Loss:38.576	translation_Loss:38.576	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.53	Hits@10:43.54	Best:22.53
2024-12-27 23:43:44,383: Snapshot:0	Epoch:74	Loss:37.63	translation_Loss:37.63	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.65	Hits@10:43.64	Best:22.65
2024-12-27 23:43:55,971: Snapshot:0	Epoch:75	Loss:36.797	translation_Loss:36.797	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.76	Hits@10:43.82	Best:22.76
2024-12-27 23:44:07,570: Snapshot:0	Epoch:76	Loss:35.861	translation_Loss:35.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.86	Hits@10:43.95	Best:22.86
2024-12-27 23:44:19,160: Snapshot:0	Epoch:77	Loss:35.0	translation_Loss:35.0	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.02	Hits@10:44.06	Best:23.02
2024-12-27 23:44:30,746: Snapshot:0	Epoch:78	Loss:34.067	translation_Loss:34.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.15	Hits@10:44.18	Best:23.15
2024-12-27 23:44:42,365: Snapshot:0	Epoch:79	Loss:33.245	translation_Loss:33.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.27	Hits@10:44.3	Best:23.27
2024-12-27 23:44:54,001: Snapshot:0	Epoch:80	Loss:32.45	translation_Loss:32.45	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.36	Hits@10:44.44	Best:23.36
2024-12-27 23:45:05,629: Snapshot:0	Epoch:81	Loss:31.716	translation_Loss:31.716	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.47	Hits@10:44.55	Best:23.47
2024-12-27 23:45:17,633: Snapshot:0	Epoch:82	Loss:30.843	translation_Loss:30.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.56	Hits@10:44.72	Best:23.56
2024-12-27 23:45:29,290: Snapshot:0	Epoch:83	Loss:30.105	translation_Loss:30.105	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.68	Hits@10:44.85	Best:23.68
2024-12-27 23:45:40,889: Snapshot:0	Epoch:84	Loss:29.319	translation_Loss:29.319	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.77	Hits@10:44.96	Best:23.77
2024-12-27 23:45:52,453: Snapshot:0	Epoch:85	Loss:28.676	translation_Loss:28.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.85	Hits@10:45.08	Best:23.85
2024-12-27 23:46:04,057: Snapshot:0	Epoch:86	Loss:27.986	translation_Loss:27.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.94	Hits@10:45.2	Best:23.94
2024-12-27 23:46:15,678: Snapshot:0	Epoch:87	Loss:27.273	translation_Loss:27.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.03	Hits@10:45.35	Best:24.03
2024-12-27 23:46:27,311: Snapshot:0	Epoch:88	Loss:26.559	translation_Loss:26.559	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.14	Hits@10:45.42	Best:24.14
2024-12-27 23:46:38,846: Snapshot:0	Epoch:89	Loss:25.956	translation_Loss:25.956	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.22	Hits@10:45.52	Best:24.22
2024-12-27 23:46:50,348: Snapshot:0	Epoch:90	Loss:25.335	translation_Loss:25.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.29	Hits@10:45.66	Best:24.29
2024-12-27 23:47:01,994: Snapshot:0	Epoch:91	Loss:24.688	translation_Loss:24.688	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.42	Hits@10:45.7	Best:24.42
2024-12-27 23:47:13,603: Snapshot:0	Epoch:92	Loss:24.05	translation_Loss:24.05	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.49	Hits@10:45.8	Best:24.49
2024-12-27 23:47:25,319: Snapshot:0	Epoch:93	Loss:23.389	translation_Loss:23.389	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.6	Hits@10:45.88	Best:24.6
2024-12-27 23:47:37,258: Snapshot:0	Epoch:94	Loss:22.879	translation_Loss:22.879	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:45.97	Best:24.66
2024-12-27 23:47:48,904: Snapshot:0	Epoch:95	Loss:22.349	translation_Loss:22.349	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.72	Hits@10:46.06	Best:24.72
2024-12-27 23:48:00,603: Snapshot:0	Epoch:96	Loss:21.736	translation_Loss:21.736	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.82	Hits@10:46.14	Best:24.82
2024-12-27 23:48:12,192: Snapshot:0	Epoch:97	Loss:21.254	translation_Loss:21.254	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.9	Hits@10:46.24	Best:24.9
2024-12-27 23:48:23,724: Snapshot:0	Epoch:98	Loss:20.698	translation_Loss:20.698	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.96	Hits@10:46.28	Best:24.96
2024-12-27 23:48:35,329: Snapshot:0	Epoch:99	Loss:20.276	translation_Loss:20.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.02	Hits@10:46.35	Best:25.02
2024-12-27 23:48:46,894: Snapshot:0	Epoch:100	Loss:19.687	translation_Loss:19.687	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.09	Hits@10:46.44	Best:25.09
2024-12-27 23:48:58,468: Snapshot:0	Epoch:101	Loss:19.204	translation_Loss:19.204	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.16	Hits@10:46.47	Best:25.16
2024-12-27 23:49:10,082: Snapshot:0	Epoch:102	Loss:18.708	translation_Loss:18.708	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.22	Hits@10:46.57	Best:25.22
2024-12-27 23:49:21,677: Snapshot:0	Epoch:103	Loss:18.314	translation_Loss:18.314	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.27	Hits@10:46.61	Best:25.27
2024-12-27 23:49:33,320: Snapshot:0	Epoch:104	Loss:17.887	translation_Loss:17.887	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.33	Hits@10:46.69	Best:25.33
2024-12-27 23:49:44,916: Snapshot:0	Epoch:105	Loss:17.435	translation_Loss:17.435	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.41	Hits@10:46.74	Best:25.41
2024-12-27 23:49:56,506: Snapshot:0	Epoch:106	Loss:16.99	translation_Loss:16.99	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.49	Hits@10:46.88	Best:25.49
2024-12-27 23:50:08,600: Snapshot:0	Epoch:107	Loss:16.563	translation_Loss:16.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.55	Hits@10:46.92	Best:25.55
2024-12-27 23:50:20,238: Snapshot:0	Epoch:108	Loss:16.162	translation_Loss:16.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.59	Hits@10:47.0	Best:25.59
2024-12-27 23:50:31,809: Snapshot:0	Epoch:109	Loss:15.852	translation_Loss:15.852	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.64	Hits@10:47.04	Best:25.64
2024-12-27 23:50:43,474: Snapshot:0	Epoch:110	Loss:15.454	translation_Loss:15.454	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.68	Hits@10:47.07	Best:25.68
2024-12-27 23:50:55,065: Snapshot:0	Epoch:111	Loss:15.094	translation_Loss:15.094	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.76	Hits@10:47.15	Best:25.76
2024-12-27 23:51:06,693: Snapshot:0	Epoch:112	Loss:14.784	translation_Loss:14.784	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.79	Hits@10:47.22	Best:25.79
2024-12-27 23:51:18,284: Snapshot:0	Epoch:113	Loss:14.451	translation_Loss:14.451	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.86	Hits@10:47.24	Best:25.86
2024-12-27 23:51:29,940: Snapshot:0	Epoch:114	Loss:14.155	translation_Loss:14.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.92	Hits@10:47.3	Best:25.92
2024-12-27 23:51:41,591: Snapshot:0	Epoch:115	Loss:13.733	translation_Loss:13.733	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.97	Hits@10:47.38	Best:25.97
2024-12-27 23:51:53,166: Snapshot:0	Epoch:116	Loss:13.434	translation_Loss:13.434	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.02	Hits@10:47.46	Best:26.02
2024-12-27 23:52:04,818: Snapshot:0	Epoch:117	Loss:13.181	translation_Loss:13.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.05	Hits@10:47.51	Best:26.05
2024-12-27 23:52:16,398: Snapshot:0	Epoch:118	Loss:12.815	translation_Loss:12.815	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.13	Hits@10:47.45	Best:26.13
2024-12-27 23:52:28,394: Snapshot:0	Epoch:119	Loss:12.552	translation_Loss:12.552	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.15	Hits@10:47.53	Best:26.15
2024-12-27 23:52:39,942: Snapshot:0	Epoch:120	Loss:12.297	translation_Loss:12.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.18	Hits@10:47.5	Best:26.18
2024-12-27 23:52:51,554: Snapshot:0	Epoch:121	Loss:12.0	translation_Loss:12.0	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.21	Hits@10:47.57	Best:26.21
2024-12-27 23:53:03,251: Snapshot:0	Epoch:122	Loss:11.766	translation_Loss:11.766	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.3	Hits@10:47.63	Best:26.3
2024-12-27 23:53:14,839: Snapshot:0	Epoch:123	Loss:11.545	translation_Loss:11.545	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.32	Hits@10:47.62	Best:26.32
2024-12-27 23:53:26,402: Snapshot:0	Epoch:124	Loss:11.267	translation_Loss:11.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.38	Hits@10:47.66	Best:26.38
2024-12-27 23:53:37,973: Snapshot:0	Epoch:125	Loss:11.087	translation_Loss:11.087	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.43	Hits@10:47.69	Best:26.43
2024-12-27 23:53:49,671: Snapshot:0	Epoch:126	Loss:10.828	translation_Loss:10.828	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.5	Hits@10:47.76	Best:26.5
2024-12-27 23:54:01,262: Snapshot:0	Epoch:127	Loss:10.608	translation_Loss:10.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.53	Hits@10:47.78	Best:26.53
2024-12-27 23:54:12,874: Snapshot:0	Epoch:128	Loss:10.382	translation_Loss:10.382	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.57	Hits@10:47.75	Best:26.57
2024-12-27 23:54:24,418: Snapshot:0	Epoch:129	Loss:10.177	translation_Loss:10.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.61	Hits@10:47.78	Best:26.61
2024-12-27 23:54:35,967: Snapshot:0	Epoch:130	Loss:9.998	translation_Loss:9.998	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.61	Hits@10:47.79	Best:26.61
2024-12-27 23:54:47,904: Snapshot:0	Epoch:131	Loss:9.787	translation_Loss:9.787	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.63	Hits@10:47.8	Best:26.63
2024-12-27 23:54:59,607: Snapshot:0	Epoch:132	Loss:9.556	translation_Loss:9.556	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.68	Hits@10:47.87	Best:26.68
2024-12-27 23:55:11,344: Snapshot:0	Epoch:133	Loss:9.346	translation_Loss:9.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.68	Hits@10:47.86	Best:26.68
2024-12-27 23:55:22,903: Snapshot:0	Epoch:134	Loss:9.207	translation_Loss:9.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.71	Hits@10:47.88	Best:26.71
2024-12-27 23:55:34,430: Snapshot:0	Epoch:135	Loss:9.024	translation_Loss:9.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.74	Hits@10:47.89	Best:26.74
2024-12-27 23:55:45,971: Snapshot:0	Epoch:136	Loss:8.909	translation_Loss:8.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.73	Hits@10:47.91	Best:26.74
2024-12-27 23:55:57,522: Snapshot:0	Epoch:137	Loss:8.695	translation_Loss:8.695	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.77	Hits@10:47.94	Best:26.77
2024-12-27 23:56:09,131: Snapshot:0	Epoch:138	Loss:8.507	translation_Loss:8.507	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.79	Hits@10:47.95	Best:26.79
2024-12-27 23:56:20,757: Snapshot:0	Epoch:139	Loss:8.394	translation_Loss:8.394	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.78	Hits@10:47.95	Best:26.79
2024-12-27 23:56:32,335: Snapshot:0	Epoch:140	Loss:8.24	translation_Loss:8.24	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.87	Hits@10:47.97	Best:26.87
2024-12-27 23:56:44,000: Snapshot:0	Epoch:141	Loss:8.059	translation_Loss:8.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.86	Hits@10:48.0	Best:26.87
2024-12-27 23:56:55,603: Snapshot:0	Epoch:142	Loss:7.968	translation_Loss:7.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.85	Hits@10:47.96	Best:26.87
2024-12-27 23:57:07,138: Snapshot:0	Epoch:143	Loss:7.837	translation_Loss:7.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.89	Hits@10:48.0	Best:26.89
2024-12-27 23:57:19,165: Snapshot:0	Epoch:144	Loss:7.644	translation_Loss:7.644	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.89	Hits@10:48.03	Best:26.89
2024-12-27 23:57:30,784: Snapshot:0	Epoch:145	Loss:7.522	translation_Loss:7.522	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.92	Hits@10:47.99	Best:26.92
2024-12-27 23:57:42,360: Snapshot:0	Epoch:146	Loss:7.425	translation_Loss:7.425	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.94	Hits@10:48.04	Best:26.94
2024-12-27 23:57:53,924: Snapshot:0	Epoch:147	Loss:7.296	translation_Loss:7.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.97	Hits@10:48.01	Best:26.97
2024-12-27 23:58:05,444: Snapshot:0	Epoch:148	Loss:7.171	translation_Loss:7.171	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.97	Hits@10:48.05	Best:26.97
2024-12-27 23:58:17,041: Snapshot:0	Epoch:149	Loss:7.044	translation_Loss:7.044	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.01	Hits@10:48.03	Best:27.01
2024-12-27 23:58:28,584: Snapshot:0	Epoch:150	Loss:6.984	translation_Loss:6.984	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.01	Hits@10:48.08	Best:27.01
2024-12-27 23:58:40,115: Snapshot:0	Epoch:151	Loss:6.872	translation_Loss:6.872	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.04	Hits@10:48.08	Best:27.04
2024-12-27 23:58:51,616: Snapshot:0	Epoch:152	Loss:6.707	translation_Loss:6.707	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.03	Hits@10:48.1	Best:27.04
2024-12-27 23:59:03,236: Snapshot:0	Epoch:153	Loss:6.624	translation_Loss:6.624	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.98	Hits@10:48.06	Best:27.04
2024-12-27 23:59:14,922: Snapshot:0	Epoch:154	Loss:6.537	translation_Loss:6.537	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.01	Hits@10:48.06	Best:27.04
2024-12-27 23:59:26,548: Snapshot:0	Epoch:155	Loss:6.481	translation_Loss:6.481	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.02	Hits@10:48.17	Best:27.04
2024-12-27 23:59:38,473: Early Stopping! Snapshot: 0 Epoch: 156 Best Results: 27.04
2024-12-27 23:59:38,473: Start to training tokens! Snapshot: 0 Epoch: 156 Loss:6.356 MRR:27.02 Best Results: 27.04
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-27 23:59:38,474: Snapshot:0	Epoch:156	Loss:6.356	translation_Loss:6.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.02	Hits@10:48.2	Best:27.04
2024-12-27 23:59:51,107: Snapshot:0	Epoch:157	Loss:108.066	translation_Loss:103.874	multi_layer_Loss:4.192	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.02	Hits@10:48.2	Best:27.04
2024-12-28 00:00:02,964: End of token training: 0 Epoch: 158 Loss:106.862 MRR:27.02 Best Results: 27.04
2024-12-28 00:00:02,964: Snapshot:0	Epoch:158	Loss:106.862	translation_Loss:103.732	multi_layer_Loss:3.13	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.02	Hits@10:48.2	Best:27.04
2024-12-28 00:00:03,189: => loading checkpoint './checkpoint/RELATIONrelation_0.00001_512_1000/0model_best.tar'
2024-12-28 00:00:08,544: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2734 | 0.158  | 0.3455 | 0.4134 |  0.4843 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 00:00:45,677: Snapshot:1	Epoch:0	Loss:154.129	translation_Loss:154.124	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.005                                                   	MRR:2.43	Hits@10:7.07	Best:2.43
2024-12-28 00:00:56,797: Snapshot:1	Epoch:1	Loss:149.018	translation_Loss:148.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.023                                                   	MRR:2.5	Hits@10:7.21	Best:2.5
2024-12-28 00:01:08,023: Snapshot:1	Epoch:2	Loss:143.89	translation_Loss:143.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.055                                                   	MRR:2.58	Hits@10:7.38	Best:2.58
2024-12-28 00:01:19,326: Snapshot:1	Epoch:3	Loss:138.791	translation_Loss:138.69	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:2.77	Hits@10:7.9	Best:2.77
2024-12-28 00:01:30,644: Snapshot:1	Epoch:4	Loss:133.956	translation_Loss:133.797	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.159                                                   	MRR:3.13	Hits@10:8.69	Best:3.13
2024-12-28 00:01:41,917: Snapshot:1	Epoch:5	Loss:129.086	translation_Loss:128.857	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.229                                                   	MRR:3.62	Hits@10:10.09	Best:3.62
2024-12-28 00:01:53,161: Snapshot:1	Epoch:6	Loss:124.412	translation_Loss:124.102	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.31                                                   	MRR:4.13	Hits@10:11.37	Best:4.13
2024-12-28 00:02:04,530: Snapshot:1	Epoch:7	Loss:119.931	translation_Loss:119.532	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.399                                                   	MRR:4.59	Hits@10:12.36	Best:4.59
2024-12-28 00:02:15,828: Snapshot:1	Epoch:8	Loss:115.581	translation_Loss:115.084	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.497                                                   	MRR:5.08	Hits@10:13.52	Best:5.08
2024-12-28 00:02:27,014: Snapshot:1	Epoch:9	Loss:111.375	translation_Loss:110.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.602                                                   	MRR:5.6	Hits@10:14.63	Best:5.6
2024-12-28 00:02:38,357: Snapshot:1	Epoch:10	Loss:107.347	translation_Loss:106.633	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.713                                                   	MRR:6.15	Hits@10:15.69	Best:6.15
2024-12-28 00:02:49,612: Snapshot:1	Epoch:11	Loss:103.516	translation_Loss:102.686	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.831                                                   	MRR:6.64	Hits@10:16.74	Best:6.64
2024-12-28 00:03:00,958: Snapshot:1	Epoch:12	Loss:99.789	translation_Loss:98.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.953                                                   	MRR:7.09	Hits@10:17.73	Best:7.09
2024-12-28 00:03:12,219: Snapshot:1	Epoch:13	Loss:96.205	translation_Loss:95.126	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.079                                                   	MRR:7.54	Hits@10:18.6	Best:7.54
2024-12-28 00:03:23,887: Snapshot:1	Epoch:14	Loss:92.739	translation_Loss:91.529	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.21                                                   	MRR:7.91	Hits@10:19.47	Best:7.91
2024-12-28 00:03:35,107: Snapshot:1	Epoch:15	Loss:89.298	translation_Loss:87.953	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.345                                                   	MRR:8.36	Hits@10:20.37	Best:8.36
2024-12-28 00:03:46,344: Snapshot:1	Epoch:16	Loss:86.031	translation_Loss:84.548	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.483                                                   	MRR:8.82	Hits@10:21.23	Best:8.82
2024-12-28 00:03:57,519: Snapshot:1	Epoch:17	Loss:82.827	translation_Loss:81.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.625                                                   	MRR:9.26	Hits@10:22.07	Best:9.26
2024-12-28 00:04:08,706: Snapshot:1	Epoch:18	Loss:79.723	translation_Loss:77.953	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.77                                                   	MRR:9.7	Hits@10:22.94	Best:9.7
2024-12-28 00:04:19,938: Snapshot:1	Epoch:19	Loss:76.646	translation_Loss:74.73	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.917                                                   	MRR:10.16	Hits@10:23.79	Best:10.16
2024-12-28 00:04:31,234: Snapshot:1	Epoch:20	Loss:73.698	translation_Loss:71.631	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.066                                                   	MRR:10.61	Hits@10:24.55	Best:10.61
2024-12-28 00:04:42,557: Snapshot:1	Epoch:21	Loss:70.8	translation_Loss:68.582	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.218                                                   	MRR:11.03	Hits@10:25.33	Best:11.03
2024-12-28 00:04:53,783: Snapshot:1	Epoch:22	Loss:67.895	translation_Loss:65.523	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.372                                                   	MRR:11.48	Hits@10:26.08	Best:11.48
2024-12-28 00:05:05,114: Snapshot:1	Epoch:23	Loss:65.15	translation_Loss:62.622	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.527                                                   	MRR:11.86	Hits@10:26.77	Best:11.86
2024-12-28 00:05:16,325: Snapshot:1	Epoch:24	Loss:62.493	translation_Loss:59.81	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.684                                                   	MRR:12.22	Hits@10:27.44	Best:12.22
2024-12-28 00:05:27,580: Snapshot:1	Epoch:25	Loss:59.821	translation_Loss:56.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.842                                                   	MRR:12.54	Hits@10:28.03	Best:12.54
2024-12-28 00:05:38,779: Snapshot:1	Epoch:26	Loss:57.259	translation_Loss:54.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.002                                                   	MRR:12.93	Hits@10:28.65	Best:12.93
2024-12-28 00:05:50,036: Snapshot:1	Epoch:27	Loss:54.788	translation_Loss:51.626	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.162                                                   	MRR:13.25	Hits@10:29.21	Best:13.25
2024-12-28 00:06:01,745: Snapshot:1	Epoch:28	Loss:52.398	translation_Loss:49.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.322                                                   	MRR:13.61	Hits@10:29.76	Best:13.61
2024-12-28 00:06:12,960: Snapshot:1	Epoch:29	Loss:49.977	translation_Loss:46.495	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.482                                                   	MRR:13.94	Hits@10:30.33	Best:13.94
2024-12-28 00:06:24,202: Snapshot:1	Epoch:30	Loss:47.755	translation_Loss:44.114	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.641                                                   	MRR:14.28	Hits@10:30.79	Best:14.28
2024-12-28 00:06:35,429: Snapshot:1	Epoch:31	Loss:45.477	translation_Loss:41.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.799                                                   	MRR:14.6	Hits@10:31.21	Best:14.6
2024-12-28 00:06:46,657: Snapshot:1	Epoch:32	Loss:43.311	translation_Loss:39.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.956                                                   	MRR:14.92	Hits@10:31.59	Best:14.92
2024-12-28 00:06:57,835: Snapshot:1	Epoch:33	Loss:41.243	translation_Loss:37.133	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.11                                                   	MRR:15.24	Hits@10:31.98	Best:15.24
2024-12-28 00:07:09,005: Snapshot:1	Epoch:34	Loss:39.331	translation_Loss:35.069	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.262                                                   	MRR:15.5	Hits@10:32.36	Best:15.5
2024-12-28 00:07:20,238: Snapshot:1	Epoch:35	Loss:37.445	translation_Loss:33.035	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.41                                                   	MRR:15.81	Hits@10:32.72	Best:15.81
2024-12-28 00:07:31,554: Snapshot:1	Epoch:36	Loss:35.729	translation_Loss:31.175	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.555                                                   	MRR:16.03	Hits@10:32.98	Best:16.03
2024-12-28 00:07:43,011: Snapshot:1	Epoch:37	Loss:33.938	translation_Loss:29.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.695                                                   	MRR:16.3	Hits@10:33.24	Best:16.3
2024-12-28 00:07:54,424: Snapshot:1	Epoch:38	Loss:32.401	translation_Loss:27.569	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.831                                                   	MRR:16.56	Hits@10:33.55	Best:16.56
2024-12-28 00:08:05,747: Snapshot:1	Epoch:39	Loss:30.771	translation_Loss:25.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.963                                                   	MRR:16.78	Hits@10:33.91	Best:16.78
2024-12-28 00:08:17,209: Snapshot:1	Epoch:40	Loss:29.386	translation_Loss:24.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.089                                                   	MRR:17.05	Hits@10:34.19	Best:17.05
2024-12-28 00:08:28,985: Snapshot:1	Epoch:41	Loss:28.091	translation_Loss:22.881	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.21                                                   	MRR:17.28	Hits@10:34.45	Best:17.28
2024-12-28 00:08:40,224: Snapshot:1	Epoch:42	Loss:26.814	translation_Loss:21.49	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.324                                                   	MRR:17.53	Hits@10:34.64	Best:17.53
2024-12-28 00:08:51,476: Snapshot:1	Epoch:43	Loss:25.649	translation_Loss:20.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.431                                                   	MRR:17.71	Hits@10:34.89	Best:17.71
2024-12-28 00:09:02,678: Snapshot:1	Epoch:44	Loss:24.532	translation_Loss:18.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.533                                                   	MRR:17.88	Hits@10:35.08	Best:17.88
2024-12-28 00:09:13,987: Snapshot:1	Epoch:45	Loss:23.515	translation_Loss:17.887	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.627                                                   	MRR:18.0	Hits@10:35.25	Best:18.0
2024-12-28 00:09:25,295: Snapshot:1	Epoch:46	Loss:22.592	translation_Loss:16.876	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.716                                                   	MRR:18.18	Hits@10:35.46	Best:18.18
2024-12-28 00:09:36,668: Snapshot:1	Epoch:47	Loss:21.61	translation_Loss:15.811	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.799                                                   	MRR:18.3	Hits@10:35.66	Best:18.3
2024-12-28 00:09:47,888: Snapshot:1	Epoch:48	Loss:20.806	translation_Loss:14.932	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.874                                                   	MRR:18.44	Hits@10:35.79	Best:18.44
2024-12-28 00:09:59,178: Snapshot:1	Epoch:49	Loss:20.067	translation_Loss:14.124	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.943                                                   	MRR:18.49	Hits@10:35.92	Best:18.49
2024-12-28 00:10:10,652: Snapshot:1	Epoch:50	Loss:19.403	translation_Loss:13.396	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.007                                                   	MRR:18.65	Hits@10:36.04	Best:18.65
2024-12-28 00:10:21,973: Snapshot:1	Epoch:51	Loss:18.651	translation_Loss:12.586	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.065                                                   	MRR:18.75	Hits@10:36.13	Best:18.75
2024-12-28 00:10:33,335: Snapshot:1	Epoch:52	Loss:18.08	translation_Loss:11.964	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.116                                                   	MRR:18.89	Hits@10:36.25	Best:18.89
2024-12-28 00:10:44,682: Snapshot:1	Epoch:53	Loss:17.472	translation_Loss:11.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.162                                                   	MRR:18.89	Hits@10:36.42	Best:18.89
2024-12-28 00:10:56,560: Snapshot:1	Epoch:54	Loss:16.944	translation_Loss:10.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.204                                                   	MRR:19.02	Hits@10:36.42	Best:19.02
2024-12-28 00:11:07,789: Snapshot:1	Epoch:55	Loss:16.401	translation_Loss:10.161	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.24                                                   	MRR:19.05	Hits@10:36.49	Best:19.05
2024-12-28 00:11:19,071: Snapshot:1	Epoch:56	Loss:15.87	translation_Loss:9.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.272                                                   	MRR:19.18	Hits@10:36.58	Best:19.18
2024-12-28 00:11:30,421: Snapshot:1	Epoch:57	Loss:15.492	translation_Loss:9.192	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.3                                                   	MRR:19.24	Hits@10:36.66	Best:19.24
2024-12-28 00:11:41,762: Snapshot:1	Epoch:58	Loss:15.042	translation_Loss:8.717	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.324                                                   	MRR:19.28	Hits@10:36.77	Best:19.28
2024-12-28 00:11:52,981: Snapshot:1	Epoch:59	Loss:14.69	translation_Loss:8.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.344                                                   	MRR:19.43	Hits@10:36.81	Best:19.43
2024-12-28 00:12:04,195: Snapshot:1	Epoch:60	Loss:14.31	translation_Loss:7.949	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.36                                                   	MRR:19.53	Hits@10:36.97	Best:19.53
2024-12-28 00:12:15,622: Snapshot:1	Epoch:61	Loss:13.939	translation_Loss:7.564	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.375                                                   	MRR:19.61	Hits@10:37.0	Best:19.61
2024-12-28 00:12:26,853: Snapshot:1	Epoch:62	Loss:13.593	translation_Loss:7.209	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.384                                                   	MRR:19.67	Hits@10:37.04	Best:19.67
2024-12-28 00:12:38,229: Snapshot:1	Epoch:63	Loss:13.305	translation_Loss:6.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.39                                                   	MRR:19.71	Hits@10:37.18	Best:19.71
2024-12-28 00:12:49,576: Snapshot:1	Epoch:64	Loss:13.074	translation_Loss:6.679	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.394                                                   	MRR:19.78	Hits@10:37.14	Best:19.78
2024-12-28 00:13:00,791: Snapshot:1	Epoch:65	Loss:12.786	translation_Loss:6.389	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.397                                                   	MRR:19.78	Hits@10:37.2	Best:19.78
2024-12-28 00:13:11,965: Snapshot:1	Epoch:66	Loss:12.54	translation_Loss:6.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.398                                                   	MRR:19.76	Hits@10:37.3	Best:19.78
2024-12-28 00:13:23,651: Snapshot:1	Epoch:67	Loss:12.268	translation_Loss:5.873	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.395                                                   	MRR:19.8	Hits@10:37.34	Best:19.8
2024-12-28 00:13:34,995: Snapshot:1	Epoch:68	Loss:12.032	translation_Loss:5.639	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.392                                                   	MRR:19.82	Hits@10:37.38	Best:19.82
2024-12-28 00:13:46,187: Snapshot:1	Epoch:69	Loss:11.854	translation_Loss:5.468	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.386                                                   	MRR:19.81	Hits@10:37.39	Best:19.82
2024-12-28 00:13:57,579: Snapshot:1	Epoch:70	Loss:11.629	translation_Loss:5.25	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.379                                                   	MRR:19.94	Hits@10:37.51	Best:19.94
2024-12-28 00:14:08,909: Snapshot:1	Epoch:71	Loss:11.452	translation_Loss:5.081	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.371                                                   	MRR:19.91	Hits@10:37.52	Best:19.94
2024-12-28 00:14:20,175: Snapshot:1	Epoch:72	Loss:11.284	translation_Loss:4.923	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.361                                                   	MRR:19.99	Hits@10:37.61	Best:19.99
2024-12-28 00:14:31,402: Snapshot:1	Epoch:73	Loss:11.095	translation_Loss:4.746	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.349                                                   	MRR:19.97	Hits@10:37.56	Best:19.99
2024-12-28 00:14:42,606: Snapshot:1	Epoch:74	Loss:10.878	translation_Loss:4.543	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.335                                                   	MRR:19.97	Hits@10:37.61	Best:19.99
2024-12-28 00:14:53,701: Snapshot:1	Epoch:75	Loss:10.78	translation_Loss:4.46	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.32                                                   	MRR:19.95	Hits@10:37.68	Best:19.99
2024-12-28 00:15:04,918: Snapshot:1	Epoch:76	Loss:10.634	translation_Loss:4.328	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.306                                                   	MRR:19.96	Hits@10:37.79	Best:19.99
2024-12-28 00:15:16,227: Early Stopping! Snapshot: 1 Epoch: 77 Best Results: 19.99
2024-12-28 00:15:16,228: Start to training tokens! Snapshot: 1 Epoch: 77 Loss:10.463 MRR:19.99 Best Results: 19.99
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 00:15:16,228: Snapshot:1	Epoch:77	Loss:10.463	translation_Loss:4.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.291                                                   	MRR:19.99	Hits@10:37.74	Best:19.99
2024-12-28 00:15:27,128: Snapshot:1	Epoch:78	Loss:102.777	translation_Loss:98.772	multi_layer_Loss:4.006	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.99	Hits@10:37.74	Best:19.99
2024-12-28 00:15:38,019: End of token training: 1 Epoch: 79 Loss:101.859 MRR:19.99 Best Results: 19.99
2024-12-28 00:15:38,019: Snapshot:1	Epoch:79	Loss:101.859	translation_Loss:98.792	multi_layer_Loss:3.068	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:19.99	Hits@10:37.74	Best:19.99
2024-12-28 00:15:38,366: => loading checkpoint './checkpoint/RELATIONrelation_0.00001_512_1000/1model_best.tar'
2024-12-28 00:15:48,496: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1848 | 0.0868 | 0.2376 | 0.2947 |  0.3666 |
|     1      |  0.2   | 0.1071 | 0.2406 | 0.3001 |  0.3755 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 00:16:16,826: Snapshot:2	Epoch:0	Loss:107.395	translation_Loss:107.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.003                                                   	MRR:0.32	Hits@10:0.65	Best:0.32
2024-12-28 00:16:25,128: Snapshot:2	Epoch:1	Loss:100.238	translation_Loss:100.221	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.017                                                   	MRR:0.39	Hits@10:0.79	Best:0.39
2024-12-28 00:16:33,518: Snapshot:2	Epoch:2	Loss:92.821	translation_Loss:92.779	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.042                                                   	MRR:0.54	Hits@10:1.24	Best:0.54
2024-12-28 00:16:41,928: Snapshot:2	Epoch:3	Loss:85.374	translation_Loss:85.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.078                                                   	MRR:0.84	Hits@10:2.0	Best:0.84
2024-12-28 00:16:50,328: Snapshot:2	Epoch:4	Loss:77.899	translation_Loss:77.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.126                                                   	MRR:1.48	Hits@10:3.59	Best:1.48
2024-12-28 00:16:58,834: Snapshot:2	Epoch:5	Loss:70.543	translation_Loss:70.359	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.184                                                   	MRR:2.43	Hits@10:6.06	Best:2.43
2024-12-28 00:17:07,169: Snapshot:2	Epoch:6	Loss:63.625	translation_Loss:63.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.251                                                   	MRR:3.54	Hits@10:8.81	Best:3.54
2024-12-28 00:17:15,618: Snapshot:2	Epoch:7	Loss:57.12	translation_Loss:56.795	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.325                                                   	MRR:5.01	Hits@10:12.38	Best:5.01
2024-12-28 00:17:24,309: Snapshot:2	Epoch:8	Loss:51.142	translation_Loss:50.739	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.404                                                   	MRR:6.88	Hits@10:16.85	Best:6.88
2024-12-28 00:17:32,671: Snapshot:2	Epoch:9	Loss:45.936	translation_Loss:45.451	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.485                                                   	MRR:8.72	Hits@10:20.48	Best:8.72
2024-12-28 00:17:41,083: Snapshot:2	Epoch:10	Loss:41.468	translation_Loss:40.902	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.567                                                   	MRR:10.05	Hits@10:23.19	Best:10.05
2024-12-28 00:17:49,493: Snapshot:2	Epoch:11	Loss:37.922	translation_Loss:37.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.645                                                   	MRR:11.19	Hits@10:25.26	Best:11.19
2024-12-28 00:17:57,866: Snapshot:2	Epoch:12	Loss:35.006	translation_Loss:34.288	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.718                                                   	MRR:12.32	Hits@10:27.43	Best:12.32
2024-12-28 00:18:06,230: Snapshot:2	Epoch:13	Loss:32.579	translation_Loss:31.792	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.787                                                   	MRR:13.33	Hits@10:29.14	Best:13.33
2024-12-28 00:18:14,625: Snapshot:2	Epoch:14	Loss:30.484	translation_Loss:29.631	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.853                                                   	MRR:14.22	Hits@10:30.62	Best:14.22
2024-12-28 00:18:23,529: Snapshot:2	Epoch:15	Loss:28.567	translation_Loss:27.652	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.915                                                   	MRR:14.95	Hits@10:31.68	Best:14.95
2024-12-28 00:18:31,974: Snapshot:2	Epoch:16	Loss:26.889	translation_Loss:25.915	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.974                                                   	MRR:15.55	Hits@10:32.68	Best:15.55
2024-12-28 00:18:40,339: Snapshot:2	Epoch:17	Loss:25.375	translation_Loss:24.344	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.03                                                   	MRR:16.07	Hits@10:33.53	Best:16.07
2024-12-28 00:18:48,800: Snapshot:2	Epoch:18	Loss:24.011	translation_Loss:22.926	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.085                                                   	MRR:16.63	Hits@10:34.24	Best:16.63
2024-12-28 00:18:57,247: Snapshot:2	Epoch:19	Loss:22.78	translation_Loss:21.643	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.137                                                   	MRR:16.98	Hits@10:34.83	Best:16.98
2024-12-28 00:19:05,632: Snapshot:2	Epoch:20	Loss:21.648	translation_Loss:20.461	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.187                                                   	MRR:17.37	Hits@10:35.29	Best:17.37
2024-12-28 00:19:14,044: Snapshot:2	Epoch:21	Loss:20.565	translation_Loss:19.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.236                                                   	MRR:17.78	Hits@10:35.88	Best:17.78
2024-12-28 00:19:22,407: Snapshot:2	Epoch:22	Loss:19.484	translation_Loss:18.201	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.283                                                   	MRR:18.06	Hits@10:36.37	Best:18.06
2024-12-28 00:19:30,824: Snapshot:2	Epoch:23	Loss:18.573	translation_Loss:17.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.328                                                   	MRR:18.3	Hits@10:36.88	Best:18.3
2024-12-28 00:19:39,282: Snapshot:2	Epoch:24	Loss:17.67	translation_Loss:16.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.371                                                   	MRR:18.58	Hits@10:37.2	Best:18.58
2024-12-28 00:19:47,793: Snapshot:2	Epoch:25	Loss:16.882	translation_Loss:15.468	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.414                                                   	MRR:18.87	Hits@10:37.6	Best:18.87
2024-12-28 00:19:56,181: Snapshot:2	Epoch:26	Loss:16.106	translation_Loss:14.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.455                                                   	MRR:19.03	Hits@10:37.92	Best:19.03
2024-12-28 00:20:04,544: Snapshot:2	Epoch:27	Loss:15.381	translation_Loss:13.886	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.494                                                   	MRR:19.3	Hits@10:38.23	Best:19.3
2024-12-28 00:20:13,012: Snapshot:2	Epoch:28	Loss:14.732	translation_Loss:13.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.533                                                   	MRR:19.54	Hits@10:38.51	Best:19.54
2024-12-28 00:20:21,317: Snapshot:2	Epoch:29	Loss:14.078	translation_Loss:12.508	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.57                                                   	MRR:19.74	Hits@10:38.96	Best:19.74
2024-12-28 00:20:29,849: Snapshot:2	Epoch:30	Loss:13.473	translation_Loss:11.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.606                                                   	MRR:19.86	Hits@10:39.03	Best:19.86
2024-12-28 00:20:38,273: Snapshot:2	Epoch:31	Loss:12.928	translation_Loss:11.288	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.64                                                   	MRR:20.08	Hits@10:39.36	Best:20.08
2024-12-28 00:20:46,701: Snapshot:2	Epoch:32	Loss:12.409	translation_Loss:10.735	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.674                                                   	MRR:20.23	Hits@10:39.52	Best:20.23
2024-12-28 00:20:55,585: Snapshot:2	Epoch:33	Loss:11.892	translation_Loss:10.187	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.706                                                   	MRR:20.31	Hits@10:39.73	Best:20.31
2024-12-28 00:21:03,895: Snapshot:2	Epoch:34	Loss:11.44	translation_Loss:9.704	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.736                                                   	MRR:20.34	Hits@10:39.85	Best:20.34
2024-12-28 00:21:12,309: Snapshot:2	Epoch:35	Loss:10.944	translation_Loss:9.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.766                                                   	MRR:20.59	Hits@10:39.98	Best:20.59
2024-12-28 00:21:20,787: Snapshot:2	Epoch:36	Loss:10.561	translation_Loss:8.766	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.795                                                   	MRR:20.72	Hits@10:40.14	Best:20.72
2024-12-28 00:21:29,160: Snapshot:2	Epoch:37	Loss:10.13	translation_Loss:8.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.823                                                   	MRR:20.72	Hits@10:40.28	Best:20.72
2024-12-28 00:21:37,515: Snapshot:2	Epoch:38	Loss:9.796	translation_Loss:7.947	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.849                                                   	MRR:21.0	Hits@10:40.34	Best:21.0
2024-12-28 00:21:45,930: Snapshot:2	Epoch:39	Loss:9.435	translation_Loss:7.561	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.875                                                   	MRR:21.05	Hits@10:40.55	Best:21.05
2024-12-28 00:21:54,346: Snapshot:2	Epoch:40	Loss:9.1	translation_Loss:7.201	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.899                                                   	MRR:21.07	Hits@10:40.53	Best:21.07
2024-12-28 00:22:02,694: Snapshot:2	Epoch:41	Loss:8.797	translation_Loss:6.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.922                                                   	MRR:21.07	Hits@10:40.57	Best:21.07
2024-12-28 00:22:11,048: Snapshot:2	Epoch:42	Loss:8.547	translation_Loss:6.602	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.944                                                   	MRR:21.11	Hits@10:40.69	Best:21.11
2024-12-28 00:22:19,559: Snapshot:2	Epoch:43	Loss:8.219	translation_Loss:6.253	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.966                                                   	MRR:21.19	Hits@10:40.8	Best:21.19
2024-12-28 00:22:28,001: Snapshot:2	Epoch:44	Loss:7.981	translation_Loss:5.996	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.985                                                   	MRR:21.31	Hits@10:40.61	Best:21.31
2024-12-28 00:22:36,404: Snapshot:2	Epoch:45	Loss:7.747	translation_Loss:5.743	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.004                                                   	MRR:21.37	Hits@10:40.89	Best:21.37
2024-12-28 00:22:44,745: Snapshot:2	Epoch:46	Loss:7.482	translation_Loss:5.46	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.022                                                   	MRR:21.38	Hits@10:40.88	Best:21.38
2024-12-28 00:22:53,113: Snapshot:2	Epoch:47	Loss:7.283	translation_Loss:5.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.038                                                   	MRR:21.36	Hits@10:40.86	Best:21.38
2024-12-28 00:23:01,433: Snapshot:2	Epoch:48	Loss:7.115	translation_Loss:5.061	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.054                                                   	MRR:21.53	Hits@10:40.91	Best:21.53
2024-12-28 00:23:09,903: Snapshot:2	Epoch:49	Loss:6.953	translation_Loss:4.884	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.069                                                   	MRR:21.54	Hits@10:40.99	Best:21.54
2024-12-28 00:23:18,329: Snapshot:2	Epoch:50	Loss:6.766	translation_Loss:4.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.083                                                   	MRR:21.52	Hits@10:41.11	Best:21.54
2024-12-28 00:23:26,693: Snapshot:2	Epoch:51	Loss:6.593	translation_Loss:4.497	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.096                                                   	MRR:21.5	Hits@10:41.03	Best:21.54
2024-12-28 00:23:35,432: Snapshot:2	Epoch:52	Loss:6.417	translation_Loss:4.309	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.108                                                   	MRR:21.46	Hits@10:40.93	Best:21.54
2024-12-28 00:23:43,748: Snapshot:2	Epoch:53	Loss:6.27	translation_Loss:4.15	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.12                                                   	MRR:21.49	Hits@10:40.91	Best:21.54
2024-12-28 00:23:52,086: Snapshot:2	Epoch:54	Loss:6.152	translation_Loss:4.022	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.13                                                   	MRR:21.64	Hits@10:41.06	Best:21.64
2024-12-28 00:24:00,569: Snapshot:2	Epoch:55	Loss:5.969	translation_Loss:3.83	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.139                                                   	MRR:21.71	Hits@10:41.01	Best:21.71
2024-12-28 00:24:08,975: Snapshot:2	Epoch:56	Loss:5.851	translation_Loss:3.702	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.148                                                   	MRR:21.73	Hits@10:41.23	Best:21.73
2024-12-28 00:24:17,368: Snapshot:2	Epoch:57	Loss:5.724	translation_Loss:3.568	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.157                                                   	MRR:21.77	Hits@10:41.27	Best:21.77
2024-12-28 00:24:25,811: Snapshot:2	Epoch:58	Loss:5.622	translation_Loss:3.458	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.164                                                   	MRR:21.83	Hits@10:41.15	Best:21.83
2024-12-28 00:24:34,165: Snapshot:2	Epoch:59	Loss:5.517	translation_Loss:3.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.172                                                   	MRR:21.89	Hits@10:41.19	Best:21.89
2024-12-28 00:24:42,534: Snapshot:2	Epoch:60	Loss:5.371	translation_Loss:3.194	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.178                                                   	MRR:21.93	Hits@10:41.09	Best:21.93
2024-12-28 00:24:50,864: Snapshot:2	Epoch:61	Loss:5.254	translation_Loss:3.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.183                                                   	MRR:21.9	Hits@10:41.33	Best:21.93
2024-12-28 00:24:59,201: Snapshot:2	Epoch:62	Loss:5.179	translation_Loss:2.991	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.188                                                   	MRR:21.95	Hits@10:41.43	Best:21.95
2024-12-28 00:25:07,706: Snapshot:2	Epoch:63	Loss:5.075	translation_Loss:2.883	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.191                                                   	MRR:22.01	Hits@10:41.47	Best:22.01
2024-12-28 00:25:16,085: Snapshot:2	Epoch:64	Loss:4.976	translation_Loss:2.782	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.195                                                   	MRR:22.05	Hits@10:41.45	Best:22.05
2024-12-28 00:25:24,416: Snapshot:2	Epoch:65	Loss:4.917	translation_Loss:2.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.197                                                   	MRR:21.98	Hits@10:41.39	Best:22.05
2024-12-28 00:25:32,786: Snapshot:2	Epoch:66	Loss:4.821	translation_Loss:2.621	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.2                                                   	MRR:22.04	Hits@10:41.33	Best:22.05
2024-12-28 00:25:41,233: Snapshot:2	Epoch:67	Loss:4.752	translation_Loss:2.55	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.202                                                   	MRR:22.14	Hits@10:41.35	Best:22.14
2024-12-28 00:25:49,581: Snapshot:2	Epoch:68	Loss:4.662	translation_Loss:2.46	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.202                                                   	MRR:22.19	Hits@10:41.35	Best:22.19
2024-12-28 00:25:57,905: Snapshot:2	Epoch:69	Loss:4.591	translation_Loss:2.388	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.203                                                   	MRR:22.12	Hits@10:41.47	Best:22.19
2024-12-28 00:26:06,689: Snapshot:2	Epoch:70	Loss:4.476	translation_Loss:2.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.203                                                   	MRR:22.17	Hits@10:41.48	Best:22.19
2024-12-28 00:26:15,033: Snapshot:2	Epoch:71	Loss:4.467	translation_Loss:2.265	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.202                                                   	MRR:22.2	Hits@10:41.62	Best:22.2
2024-12-28 00:26:23,472: Snapshot:2	Epoch:72	Loss:4.383	translation_Loss:2.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.202                                                   	MRR:22.29	Hits@10:41.63	Best:22.29
2024-12-28 00:26:31,943: Snapshot:2	Epoch:73	Loss:4.318	translation_Loss:2.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.2                                                   	MRR:22.34	Hits@10:41.71	Best:22.34
2024-12-28 00:26:40,309: Snapshot:2	Epoch:74	Loss:4.233	translation_Loss:2.034	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.199                                                   	MRR:22.32	Hits@10:41.76	Best:22.34
2024-12-28 00:26:48,651: Snapshot:2	Epoch:75	Loss:4.187	translation_Loss:1.99	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.197                                                   	MRR:22.32	Hits@10:41.82	Best:22.34
2024-12-28 00:26:56,932: Snapshot:2	Epoch:76	Loss:4.154	translation_Loss:1.959	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.196                                                   	MRR:22.25	Hits@10:41.67	Best:22.34
2024-12-28 00:27:05,234: Snapshot:2	Epoch:77	Loss:4.092	translation_Loss:1.899	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.194                                                   	MRR:22.34	Hits@10:41.7	Best:22.34
2024-12-28 00:27:13,612: Snapshot:2	Epoch:78	Loss:4.034	translation_Loss:1.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.191                                                   	MRR:22.39	Hits@10:41.78	Best:22.39
2024-12-28 00:27:22,044: Snapshot:2	Epoch:79	Loss:3.956	translation_Loss:1.768	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.189                                                   	MRR:22.42	Hits@10:41.79	Best:22.42
2024-12-28 00:27:30,413: Snapshot:2	Epoch:80	Loss:3.934	translation_Loss:1.749	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.185                                                   	MRR:22.42	Hits@10:41.79	Best:22.42
2024-12-28 00:27:38,879: Snapshot:2	Epoch:81	Loss:3.9	translation_Loss:1.719	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.182                                                   	MRR:22.53	Hits@10:41.76	Best:22.53
2024-12-28 00:27:47,243: Snapshot:2	Epoch:82	Loss:3.854	translation_Loss:1.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.178                                                   	MRR:22.56	Hits@10:41.66	Best:22.56
2024-12-28 00:27:55,713: Snapshot:2	Epoch:83	Loss:3.785	translation_Loss:1.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.175                                                   	MRR:22.61	Hits@10:41.7	Best:22.61
2024-12-28 00:28:04,036: Snapshot:2	Epoch:84	Loss:3.749	translation_Loss:1.578	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.171                                                   	MRR:22.58	Hits@10:41.79	Best:22.61
2024-12-28 00:28:12,409: Snapshot:2	Epoch:85	Loss:3.717	translation_Loss:1.551	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.167                                                   	MRR:22.69	Hits@10:41.88	Best:22.69
2024-12-28 00:28:20,722: Snapshot:2	Epoch:86	Loss:3.671	translation_Loss:1.509	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.162                                                   	MRR:22.8	Hits@10:42.04	Best:22.8
2024-12-28 00:28:29,193: Snapshot:2	Epoch:87	Loss:3.647	translation_Loss:1.489	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.158                                                   	MRR:22.84	Hits@10:41.92	Best:22.84
2024-12-28 00:28:37,496: Snapshot:2	Epoch:88	Loss:3.617	translation_Loss:1.463	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.154                                                   	MRR:22.77	Hits@10:42.01	Best:22.84
2024-12-28 00:28:46,244: Snapshot:2	Epoch:89	Loss:3.55	translation_Loss:1.4	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.15                                                   	MRR:22.83	Hits@10:41.98	Best:22.84
2024-12-28 00:28:54,531: Snapshot:2	Epoch:90	Loss:3.526	translation_Loss:1.381	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.145                                                   	MRR:22.87	Hits@10:41.95	Best:22.87
2024-12-28 00:29:02,931: Snapshot:2	Epoch:91	Loss:3.482	translation_Loss:1.343	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.139                                                   	MRR:23.0	Hits@10:41.99	Best:23.0
2024-12-28 00:29:11,365: Snapshot:2	Epoch:92	Loss:3.479	translation_Loss:1.345	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.134                                                   	MRR:23.07	Hits@10:42.1	Best:23.07
2024-12-28 00:29:19,853: Snapshot:2	Epoch:93	Loss:3.419	translation_Loss:1.291	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.128                                                   	MRR:23.09	Hits@10:42.11	Best:23.09
2024-12-28 00:29:28,203: Snapshot:2	Epoch:94	Loss:3.406	translation_Loss:1.282	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.123                                                   	MRR:23.04	Hits@10:42.06	Best:23.09
2024-12-28 00:29:36,614: Snapshot:2	Epoch:95	Loss:3.379	translation_Loss:1.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.118                                                   	MRR:23.04	Hits@10:42.15	Best:23.09
2024-12-28 00:29:44,943: Snapshot:2	Epoch:96	Loss:3.325	translation_Loss:1.213	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.112                                                   	MRR:23.04	Hits@10:42.09	Best:23.09
2024-12-28 00:29:53,250: Snapshot:2	Epoch:97	Loss:3.294	translation_Loss:1.188	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.106                                                   	MRR:23.08	Hits@10:42.08	Best:23.09
2024-12-28 00:30:01,579: Early Stopping! Snapshot: 2 Epoch: 98 Best Results: 23.09
2024-12-28 00:30:01,579: Start to training tokens! Snapshot: 2 Epoch: 98 Loss:3.27 MRR:23.01 Best Results: 23.09
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 00:30:01,580: Snapshot:2	Epoch:98	Loss:3.27	translation_Loss:1.169	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.1                                                   	MRR:23.01	Hits@10:42.01	Best:23.09
2024-12-28 00:30:09,716: Snapshot:2	Epoch:99	Loss:61.801	translation_Loss:58.83	multi_layer_Loss:2.971	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.01	Hits@10:42.01	Best:23.09
2024-12-28 00:30:17,736: End of token training: 2 Epoch: 100 Loss:61.407 MRR:23.01 Best Results: 23.09
2024-12-28 00:30:17,737: Snapshot:2	Epoch:100	Loss:61.407	translation_Loss:58.873	multi_layer_Loss:2.534	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.01	Hits@10:42.01	Best:23.09
2024-12-28 00:30:18,081: => loading checkpoint './checkpoint/RELATIONrelation_0.00001_512_1000/2model_best.tar'
2024-12-28 00:30:31,467: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1525 | 0.0739 | 0.1919 | 0.2393 |  0.2969 |
|     1      | 0.1502 | 0.0759 | 0.1791 | 0.227  |  0.2872 |
|     2      | 0.2293 | 0.1353 | 0.2567 | 0.3214 |   0.42  |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 00:30:46,971: Snapshot:3	Epoch:0	Loss:40.856	translation_Loss:40.856	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:0.86	Hits@10:2.1	Best:0.86
2024-12-28 00:30:50,870: Snapshot:3	Epoch:1	Loss:39.42	translation_Loss:39.418	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.002                                                   	MRR:0.94	Hits@10:2.27	Best:0.94
2024-12-28 00:30:54,796: Snapshot:3	Epoch:2	Loss:37.966	translation_Loss:37.962	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.004                                                   	MRR:1.16	Hits@10:2.78	Best:1.16
2024-12-28 00:30:58,708: Snapshot:3	Epoch:3	Loss:36.546	translation_Loss:36.539	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.007                                                   	MRR:1.79	Hits@10:4.84	Best:1.79
2024-12-28 00:31:02,685: Snapshot:3	Epoch:4	Loss:35.228	translation_Loss:35.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.011                                                   	MRR:2.59	Hits@10:6.11	Best:2.59
2024-12-28 00:31:06,591: Snapshot:3	Epoch:5	Loss:33.942	translation_Loss:33.926	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.016                                                   	MRR:3.15	Hits@10:7.01	Best:3.15
2024-12-28 00:31:10,471: Snapshot:3	Epoch:6	Loss:32.66	translation_Loss:32.638	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.022                                                   	MRR:3.65	Hits@10:8.01	Best:3.65
2024-12-28 00:31:14,410: Snapshot:3	Epoch:7	Loss:31.452	translation_Loss:31.423	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.028                                                   	MRR:4.22	Hits@10:9.23	Best:4.22
2024-12-28 00:31:18,433: Snapshot:3	Epoch:8	Loss:30.361	translation_Loss:30.326	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.035                                                   	MRR:4.85	Hits@10:10.62	Best:4.85
2024-12-28 00:31:22,431: Snapshot:3	Epoch:9	Loss:29.234	translation_Loss:29.19	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.043                                                   	MRR:5.54	Hits@10:11.83	Best:5.54
2024-12-28 00:31:26,346: Snapshot:3	Epoch:10	Loss:28.189	translation_Loss:28.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.051                                                   	MRR:6.13	Hits@10:12.89	Best:6.13
2024-12-28 00:31:30,211: Snapshot:3	Epoch:11	Loss:27.18	translation_Loss:27.12	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.06                                                   	MRR:6.72	Hits@10:14.06	Best:6.72
2024-12-28 00:31:34,125: Snapshot:3	Epoch:12	Loss:26.217	translation_Loss:26.147	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.069                                                   	MRR:7.28	Hits@10:15.23	Best:7.28
2024-12-28 00:31:38,028: Snapshot:3	Epoch:13	Loss:25.251	translation_Loss:25.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.079                                                   	MRR:7.79	Hits@10:16.23	Best:7.79
2024-12-28 00:31:41,906: Snapshot:3	Epoch:14	Loss:24.334	translation_Loss:24.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.089                                                   	MRR:8.34	Hits@10:17.62	Best:8.34
2024-12-28 00:31:45,817: Snapshot:3	Epoch:15	Loss:23.413	translation_Loss:23.314	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:9.0	Hits@10:18.94	Best:9.0
2024-12-28 00:31:49,740: Snapshot:3	Epoch:16	Loss:22.59	translation_Loss:22.479	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.111                                                   	MRR:9.67	Hits@10:20.31	Best:9.67
2024-12-28 00:31:53,643: Snapshot:3	Epoch:17	Loss:21.738	translation_Loss:21.616	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.122                                                   	MRR:10.31	Hits@10:21.88	Best:10.31
2024-12-28 00:31:57,566: Snapshot:3	Epoch:18	Loss:20.934	translation_Loss:20.8	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.134                                                   	MRR:11.04	Hits@10:23.56	Best:11.04
2024-12-28 00:32:01,459: Snapshot:3	Epoch:19	Loss:20.144	translation_Loss:19.998	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.146                                                   	MRR:11.72	Hits@10:25.05	Best:11.72
2024-12-28 00:32:05,355: Snapshot:3	Epoch:20	Loss:19.379	translation_Loss:19.221	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.158                                                   	MRR:12.4	Hits@10:26.64	Best:12.4
2024-12-28 00:32:09,338: Snapshot:3	Epoch:21	Loss:18.601	translation_Loss:18.431	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.171                                                   	MRR:13.1	Hits@10:28.44	Best:13.1
2024-12-28 00:32:13,228: Snapshot:3	Epoch:22	Loss:17.886	translation_Loss:17.703	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.183                                                   	MRR:13.85	Hits@10:30.01	Best:13.85
2024-12-28 00:32:17,245: Snapshot:3	Epoch:23	Loss:17.191	translation_Loss:16.994	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.197                                                   	MRR:14.6	Hits@10:31.47	Best:14.6
2024-12-28 00:32:21,150: Snapshot:3	Epoch:24	Loss:16.508	translation_Loss:16.298	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.21                                                   	MRR:15.23	Hits@10:32.74	Best:15.23
2024-12-28 00:32:25,145: Snapshot:3	Epoch:25	Loss:15.814	translation_Loss:15.591	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.224                                                   	MRR:15.82	Hits@10:33.94	Best:15.82
2024-12-28 00:32:29,088: Snapshot:3	Epoch:26	Loss:15.174	translation_Loss:14.936	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.237                                                   	MRR:16.42	Hits@10:35.01	Best:16.42
2024-12-28 00:32:33,014: Snapshot:3	Epoch:27	Loss:14.528	translation_Loss:14.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.252                                                   	MRR:16.96	Hits@10:35.97	Best:16.96
2024-12-28 00:32:36,924: Snapshot:3	Epoch:28	Loss:13.945	translation_Loss:13.679	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.266                                                   	MRR:17.43	Hits@10:36.72	Best:17.43
2024-12-28 00:32:40,873: Snapshot:3	Epoch:29	Loss:13.376	translation_Loss:13.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.28                                                   	MRR:17.92	Hits@10:37.41	Best:17.92
2024-12-28 00:32:44,770: Snapshot:3	Epoch:30	Loss:12.779	translation_Loss:12.485	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.295                                                   	MRR:18.4	Hits@10:38.03	Best:18.4
2024-12-28 00:32:48,707: Snapshot:3	Epoch:31	Loss:12.245	translation_Loss:11.936	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.309                                                   	MRR:18.89	Hits@10:38.76	Best:18.89
2024-12-28 00:32:52,656: Snapshot:3	Epoch:32	Loss:11.727	translation_Loss:11.403	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.324                                                   	MRR:19.31	Hits@10:39.35	Best:19.31
2024-12-28 00:32:57,044: Snapshot:3	Epoch:33	Loss:11.227	translation_Loss:10.888	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.339                                                   	MRR:19.76	Hits@10:39.9	Best:19.76
2024-12-28 00:33:01,020: Snapshot:3	Epoch:34	Loss:10.772	translation_Loss:10.419	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.353                                                   	MRR:20.18	Hits@10:40.4	Best:20.18
2024-12-28 00:33:04,923: Snapshot:3	Epoch:35	Loss:10.263	translation_Loss:9.894	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.368                                                   	MRR:20.55	Hits@10:40.77	Best:20.55
2024-12-28 00:33:08,814: Snapshot:3	Epoch:36	Loss:9.83	translation_Loss:9.447	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.383                                                   	MRR:20.91	Hits@10:41.11	Best:20.91
2024-12-28 00:33:12,714: Snapshot:3	Epoch:37	Loss:9.425	translation_Loss:9.027	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.397                                                   	MRR:21.33	Hits@10:41.46	Best:21.33
2024-12-28 00:33:16,618: Snapshot:3	Epoch:38	Loss:9.015	translation_Loss:8.603	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.412                                                   	MRR:21.65	Hits@10:41.86	Best:21.65
2024-12-28 00:33:20,519: Snapshot:3	Epoch:39	Loss:8.619	translation_Loss:8.193	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.426                                                   	MRR:22.0	Hits@10:42.18	Best:22.0
2024-12-28 00:33:24,466: Snapshot:3	Epoch:40	Loss:8.265	translation_Loss:7.824	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.44                                                   	MRR:22.32	Hits@10:42.58	Best:22.32
2024-12-28 00:33:28,401: Snapshot:3	Epoch:41	Loss:7.902	translation_Loss:7.448	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.454                                                   	MRR:22.58	Hits@10:42.83	Best:22.58
2024-12-28 00:33:32,343: Snapshot:3	Epoch:42	Loss:7.604	translation_Loss:7.136	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.468                                                   	MRR:22.91	Hits@10:43.12	Best:22.91
2024-12-28 00:33:36,267: Snapshot:3	Epoch:43	Loss:7.283	translation_Loss:6.801	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.482                                                   	MRR:23.18	Hits@10:43.36	Best:23.18
2024-12-28 00:33:40,204: Snapshot:3	Epoch:44	Loss:6.975	translation_Loss:6.479	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.495                                                   	MRR:23.43	Hits@10:43.6	Best:23.43
2024-12-28 00:33:44,100: Snapshot:3	Epoch:45	Loss:6.664	translation_Loss:6.156	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.509                                                   	MRR:23.6	Hits@10:43.87	Best:23.6
2024-12-28 00:33:48,051: Snapshot:3	Epoch:46	Loss:6.385	translation_Loss:5.864	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.522                                                   	MRR:23.86	Hits@10:44.07	Best:23.86
2024-12-28 00:33:51,993: Snapshot:3	Epoch:47	Loss:6.125	translation_Loss:5.591	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.534                                                   	MRR:24.01	Hits@10:44.22	Best:24.01
2024-12-28 00:33:55,857: Snapshot:3	Epoch:48	Loss:5.866	translation_Loss:5.319	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.547                                                   	MRR:24.18	Hits@10:44.41	Best:24.18
2024-12-28 00:33:59,852: Snapshot:3	Epoch:49	Loss:5.625	translation_Loss:5.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.559                                                   	MRR:24.35	Hits@10:44.67	Best:24.35
2024-12-28 00:34:03,836: Snapshot:3	Epoch:50	Loss:5.39	translation_Loss:4.818	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.571                                                   	MRR:24.52	Hits@10:44.84	Best:24.52
2024-12-28 00:34:07,749: Snapshot:3	Epoch:51	Loss:5.166	translation_Loss:4.583	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.583                                                   	MRR:24.76	Hits@10:45.07	Best:24.76
2024-12-28 00:34:11,683: Snapshot:3	Epoch:52	Loss:4.935	translation_Loss:4.341	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.594                                                   	MRR:24.95	Hits@10:45.27	Best:24.95
2024-12-28 00:34:15,558: Snapshot:3	Epoch:53	Loss:4.74	translation_Loss:4.134	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.606                                                   	MRR:25.1	Hits@10:45.4	Best:25.1
2024-12-28 00:34:19,552: Snapshot:3	Epoch:54	Loss:4.532	translation_Loss:3.916	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.617                                                   	MRR:25.2	Hits@10:45.61	Best:25.2
2024-12-28 00:34:23,459: Snapshot:3	Epoch:55	Loss:4.359	translation_Loss:3.732	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.627                                                   	MRR:25.4	Hits@10:45.75	Best:25.4
2024-12-28 00:34:27,432: Snapshot:3	Epoch:56	Loss:4.131	translation_Loss:3.494	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.637                                                   	MRR:25.52	Hits@10:45.84	Best:25.52
2024-12-28 00:34:31,321: Snapshot:3	Epoch:57	Loss:3.986	translation_Loss:3.339	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.647                                                   	MRR:25.67	Hits@10:46.13	Best:25.67
2024-12-28 00:34:35,232: Snapshot:3	Epoch:58	Loss:3.859	translation_Loss:3.202	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.657                                                   	MRR:25.79	Hits@10:46.17	Best:25.79
2024-12-28 00:34:39,248: Snapshot:3	Epoch:59	Loss:3.69	translation_Loss:3.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.666                                                   	MRR:26.0	Hits@10:46.22	Best:26.0
2024-12-28 00:34:43,115: Snapshot:3	Epoch:60	Loss:3.529	translation_Loss:2.854	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.675                                                   	MRR:26.12	Hits@10:46.33	Best:26.12
2024-12-28 00:34:47,025: Snapshot:3	Epoch:61	Loss:3.384	translation_Loss:2.701	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.683                                                   	MRR:26.27	Hits@10:46.37	Best:26.27
2024-12-28 00:34:50,939: Snapshot:3	Epoch:62	Loss:3.259	translation_Loss:2.567	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.691                                                   	MRR:26.37	Hits@10:46.5	Best:26.37
2024-12-28 00:34:54,883: Snapshot:3	Epoch:63	Loss:3.147	translation_Loss:2.448	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.699                                                   	MRR:26.55	Hits@10:46.64	Best:26.55
2024-12-28 00:34:58,794: Snapshot:3	Epoch:64	Loss:3.042	translation_Loss:2.336	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.707                                                   	MRR:26.62	Hits@10:46.68	Best:26.62
2024-12-28 00:35:02,669: Snapshot:3	Epoch:65	Loss:2.921	translation_Loss:2.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.714                                                   	MRR:26.73	Hits@10:46.76	Best:26.73
2024-12-28 00:35:06,600: Snapshot:3	Epoch:66	Loss:2.791	translation_Loss:2.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.72                                                   	MRR:26.86	Hits@10:46.76	Best:26.86
2024-12-28 00:35:10,490: Snapshot:3	Epoch:67	Loss:2.713	translation_Loss:1.987	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.726                                                   	MRR:26.93	Hits@10:46.83	Best:26.93
2024-12-28 00:35:14,370: Snapshot:3	Epoch:68	Loss:2.639	translation_Loss:1.907	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.732                                                   	MRR:27.1	Hits@10:46.87	Best:27.1
2024-12-28 00:35:18,333: Snapshot:3	Epoch:69	Loss:2.517	translation_Loss:1.779	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.738                                                   	MRR:27.24	Hits@10:47.0	Best:27.24
2024-12-28 00:35:22,222: Snapshot:3	Epoch:70	Loss:2.435	translation_Loss:1.692	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.743                                                   	MRR:27.35	Hits@10:47.05	Best:27.35
2024-12-28 00:35:26,130: Snapshot:3	Epoch:71	Loss:2.363	translation_Loss:1.615	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.748                                                   	MRR:27.49	Hits@10:47.18	Best:27.49
2024-12-28 00:35:30,096: Snapshot:3	Epoch:72	Loss:2.292	translation_Loss:1.54	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.752                                                   	MRR:27.61	Hits@10:47.25	Best:27.61
2024-12-28 00:35:34,035: Snapshot:3	Epoch:73	Loss:2.227	translation_Loss:1.471	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.756                                                   	MRR:27.71	Hits@10:47.2	Best:27.71
2024-12-28 00:35:38,470: Snapshot:3	Epoch:74	Loss:2.134	translation_Loss:1.375	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.76                                                   	MRR:27.81	Hits@10:47.27	Best:27.81
2024-12-28 00:35:42,355: Snapshot:3	Epoch:75	Loss:2.094	translation_Loss:1.331	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.763                                                   	MRR:27.91	Hits@10:47.29	Best:27.91
2024-12-28 00:35:46,263: Snapshot:3	Epoch:76	Loss:2.024	translation_Loss:1.258	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.766                                                   	MRR:27.92	Hits@10:47.39	Best:27.92
2024-12-28 00:35:50,255: Snapshot:3	Epoch:77	Loss:1.945	translation_Loss:1.176	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.769                                                   	MRR:28.07	Hits@10:47.43	Best:28.07
2024-12-28 00:35:54,162: Snapshot:3	Epoch:78	Loss:1.914	translation_Loss:1.143	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.771                                                   	MRR:28.19	Hits@10:47.42	Best:28.19
2024-12-28 00:35:58,118: Snapshot:3	Epoch:79	Loss:1.869	translation_Loss:1.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.773                                                   	MRR:28.27	Hits@10:47.37	Best:28.27
2024-12-28 00:36:02,040: Snapshot:3	Epoch:80	Loss:1.813	translation_Loss:1.038	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.775                                                   	MRR:28.32	Hits@10:47.45	Best:28.32
2024-12-28 00:36:05,877: Snapshot:3	Epoch:81	Loss:1.759	translation_Loss:0.982	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.777                                                   	MRR:28.41	Hits@10:47.49	Best:28.41
2024-12-28 00:36:09,816: Snapshot:3	Epoch:82	Loss:1.734	translation_Loss:0.956	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.778                                                   	MRR:28.55	Hits@10:47.54	Best:28.55
2024-12-28 00:36:13,705: Snapshot:3	Epoch:83	Loss:1.685	translation_Loss:0.907	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.779                                                   	MRR:28.63	Hits@10:47.74	Best:28.63
2024-12-28 00:36:17,624: Snapshot:3	Epoch:84	Loss:1.65	translation_Loss:0.871	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.78                                                   	MRR:28.76	Hits@10:47.79	Best:28.76
2024-12-28 00:36:21,721: Snapshot:3	Epoch:85	Loss:1.606	translation_Loss:0.826	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.78                                                   	MRR:28.81	Hits@10:47.85	Best:28.81
2024-12-28 00:36:25,618: Snapshot:3	Epoch:86	Loss:1.565	translation_Loss:0.785	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.78                                                   	MRR:28.95	Hits@10:47.77	Best:28.95
2024-12-28 00:36:29,528: Snapshot:3	Epoch:87	Loss:1.533	translation_Loss:0.753	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.78                                                   	MRR:29.01	Hits@10:47.84	Best:29.01
2024-12-28 00:36:33,389: Snapshot:3	Epoch:88	Loss:1.502	translation_Loss:0.722	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.78                                                   	MRR:29.1	Hits@10:48.01	Best:29.1
2024-12-28 00:36:37,315: Snapshot:3	Epoch:89	Loss:1.481	translation_Loss:0.701	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.78                                                   	MRR:29.18	Hits@10:47.96	Best:29.18
2024-12-28 00:36:41,235: Snapshot:3	Epoch:90	Loss:1.433	translation_Loss:0.654	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.779                                                   	MRR:29.23	Hits@10:47.89	Best:29.23
2024-12-28 00:36:45,115: Snapshot:3	Epoch:91	Loss:1.43	translation_Loss:0.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.778                                                   	MRR:29.35	Hits@10:47.94	Best:29.35
2024-12-28 00:36:49,027: Snapshot:3	Epoch:92	Loss:1.404	translation_Loss:0.627	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.777                                                   	MRR:29.39	Hits@10:47.99	Best:29.39
2024-12-28 00:36:52,850: Snapshot:3	Epoch:93	Loss:1.364	translation_Loss:0.588	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.776                                                   	MRR:29.35	Hits@10:48.07	Best:29.39
2024-12-28 00:36:56,712: Snapshot:3	Epoch:94	Loss:1.363	translation_Loss:0.588	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.775                                                   	MRR:29.43	Hits@10:48.05	Best:29.43
2024-12-28 00:37:00,624: Snapshot:3	Epoch:95	Loss:1.333	translation_Loss:0.559	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.774                                                   	MRR:29.5	Hits@10:48.09	Best:29.5
2024-12-28 00:37:04,534: Snapshot:3	Epoch:96	Loss:1.296	translation_Loss:0.524	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.772                                                   	MRR:29.56	Hits@10:48.08	Best:29.56
2024-12-28 00:37:08,389: Snapshot:3	Epoch:97	Loss:1.276	translation_Loss:0.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.77                                                   	MRR:29.57	Hits@10:48.17	Best:29.57
2024-12-28 00:37:12,224: Snapshot:3	Epoch:98	Loss:1.264	translation_Loss:0.495	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.768                                                   	MRR:29.56	Hits@10:48.21	Best:29.57
2024-12-28 00:37:16,115: Snapshot:3	Epoch:99	Loss:1.226	translation_Loss:0.459	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.766                                                   	MRR:29.63	Hits@10:48.16	Best:29.63
2024-12-28 00:37:20,136: Snapshot:3	Epoch:100	Loss:1.218	translation_Loss:0.454	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.764                                                   	MRR:29.7	Hits@10:48.24	Best:29.7
2024-12-28 00:37:24,089: Snapshot:3	Epoch:101	Loss:1.212	translation_Loss:0.449	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.762                                                   	MRR:29.74	Hits@10:48.12	Best:29.74
2024-12-28 00:37:28,024: Snapshot:3	Epoch:102	Loss:1.196	translation_Loss:0.436	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.76                                                   	MRR:29.8	Hits@10:48.18	Best:29.8
2024-12-28 00:37:31,905: Snapshot:3	Epoch:103	Loss:1.181	translation_Loss:0.423	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.758                                                   	MRR:29.84	Hits@10:48.25	Best:29.84
2024-12-28 00:37:35,774: Snapshot:3	Epoch:104	Loss:1.169	translation_Loss:0.413	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.756                                                   	MRR:29.88	Hits@10:48.25	Best:29.88
2024-12-28 00:37:39,666: Snapshot:3	Epoch:105	Loss:1.149	translation_Loss:0.395	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.753                                                   	MRR:29.99	Hits@10:48.4	Best:29.99
2024-12-28 00:37:43,632: Snapshot:3	Epoch:106	Loss:1.138	translation_Loss:0.387	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.751                                                   	MRR:30.02	Hits@10:48.46	Best:30.02
2024-12-28 00:37:47,570: Snapshot:3	Epoch:107	Loss:1.117	translation_Loss:0.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.748                                                   	MRR:30.07	Hits@10:48.53	Best:30.07
2024-12-28 00:37:51,418: Snapshot:3	Epoch:108	Loss:1.102	translation_Loss:0.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.746                                                   	MRR:30.14	Hits@10:48.51	Best:30.14
2024-12-28 00:37:55,437: Snapshot:3	Epoch:109	Loss:1.104	translation_Loss:0.36	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.743                                                   	MRR:30.2	Hits@10:48.48	Best:30.2
2024-12-28 00:37:59,301: Snapshot:3	Epoch:110	Loss:1.087	translation_Loss:0.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.741                                                   	MRR:30.24	Hits@10:48.69	Best:30.24
2024-12-28 00:38:03,172: Snapshot:3	Epoch:111	Loss:1.072	translation_Loss:0.333	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.738                                                   	MRR:30.32	Hits@10:48.58	Best:30.32
2024-12-28 00:38:07,126: Snapshot:3	Epoch:112	Loss:1.055	translation_Loss:0.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.736                                                   	MRR:30.43	Hits@10:48.61	Best:30.43
2024-12-28 00:38:11,009: Snapshot:3	Epoch:113	Loss:1.046	translation_Loss:0.313	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.733                                                   	MRR:30.41	Hits@10:48.58	Best:30.43
2024-12-28 00:38:14,824: Snapshot:3	Epoch:114	Loss:1.039	translation_Loss:0.309	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.731                                                   	MRR:30.42	Hits@10:48.66	Best:30.43
2024-12-28 00:38:19,141: Snapshot:3	Epoch:115	Loss:1.023	translation_Loss:0.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.728                                                   	MRR:30.46	Hits@10:48.81	Best:30.46
2024-12-28 00:38:23,096: Snapshot:3	Epoch:116	Loss:1.014	translation_Loss:0.289	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.725                                                   	MRR:30.51	Hits@10:48.84	Best:30.51
2024-12-28 00:38:27,031: Snapshot:3	Epoch:117	Loss:1.006	translation_Loss:0.284	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.722                                                   	MRR:30.53	Hits@10:48.87	Best:30.53
2024-12-28 00:38:30,985: Snapshot:3	Epoch:118	Loss:0.999	translation_Loss:0.28	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.719                                                   	MRR:30.54	Hits@10:48.84	Best:30.54
2024-12-28 00:38:34,819: Snapshot:3	Epoch:119	Loss:0.978	translation_Loss:0.262	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.716                                                   	MRR:30.57	Hits@10:48.74	Best:30.57
2024-12-28 00:38:38,762: Snapshot:3	Epoch:120	Loss:0.982	translation_Loss:0.268	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.714                                                   	MRR:30.6	Hits@10:48.93	Best:30.6
2024-12-28 00:38:42,649: Snapshot:3	Epoch:121	Loss:0.968	translation_Loss:0.257	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.711                                                   	MRR:30.53	Hits@10:48.92	Best:30.6
2024-12-28 00:38:46,497: Snapshot:3	Epoch:122	Loss:0.966	translation_Loss:0.258	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.708                                                   	MRR:30.58	Hits@10:48.93	Best:30.6
2024-12-28 00:38:50,369: Snapshot:3	Epoch:123	Loss:0.95	translation_Loss:0.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.705                                                   	MRR:30.61	Hits@10:48.96	Best:30.61
2024-12-28 00:38:54,237: Snapshot:3	Epoch:124	Loss:0.946	translation_Loss:0.243	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.703                                                   	MRR:30.63	Hits@10:48.9	Best:30.63
2024-12-28 00:38:58,154: Snapshot:3	Epoch:125	Loss:0.945	translation_Loss:0.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.7                                                   	MRR:30.71	Hits@10:49.01	Best:30.71
2024-12-28 00:39:02,085: Snapshot:3	Epoch:126	Loss:0.926	translation_Loss:0.229	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.698                                                   	MRR:30.74	Hits@10:49.09	Best:30.74
2024-12-28 00:39:05,927: Snapshot:3	Epoch:127	Loss:0.926	translation_Loss:0.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.695                                                   	MRR:30.77	Hits@10:49.1	Best:30.77
2024-12-28 00:39:09,770: Snapshot:3	Epoch:128	Loss:0.908	translation_Loss:0.216	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.692                                                   	MRR:30.74	Hits@10:49.13	Best:30.77
2024-12-28 00:39:13,568: Snapshot:3	Epoch:129	Loss:0.912	translation_Loss:0.222	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.69                                                   	MRR:30.75	Hits@10:49.3	Best:30.77
2024-12-28 00:39:17,396: Snapshot:3	Epoch:130	Loss:0.905	translation_Loss:0.218	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.687                                                   	MRR:30.72	Hits@10:49.26	Best:30.77
2024-12-28 00:39:21,238: Snapshot:3	Epoch:131	Loss:0.897	translation_Loss:0.212	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.685                                                   	MRR:30.72	Hits@10:49.32	Best:30.77
2024-12-28 00:39:25,180: Snapshot:3	Epoch:132	Loss:0.897	translation_Loss:0.215	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.682                                                   	MRR:30.78	Hits@10:49.35	Best:30.78
2024-12-28 00:39:29,126: Snapshot:3	Epoch:133	Loss:0.886	translation_Loss:0.206	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.68                                                   	MRR:30.88	Hits@10:49.19	Best:30.88
2024-12-28 00:39:33,004: Snapshot:3	Epoch:134	Loss:0.877	translation_Loss:0.2	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.678                                                   	MRR:30.86	Hits@10:49.25	Best:30.88
2024-12-28 00:39:36,789: Snapshot:3	Epoch:135	Loss:0.877	translation_Loss:0.201	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.675                                                   	MRR:30.88	Hits@10:49.29	Best:30.88
2024-12-28 00:39:40,598: Snapshot:3	Epoch:136	Loss:0.864	translation_Loss:0.192	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.673                                                   	MRR:30.86	Hits@10:49.44	Best:30.88
2024-12-28 00:39:44,441: Snapshot:3	Epoch:137	Loss:0.86	translation_Loss:0.19	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.67                                                   	MRR:30.95	Hits@10:49.49	Best:30.95
2024-12-28 00:39:48,409: Snapshot:3	Epoch:138	Loss:0.86	translation_Loss:0.192	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.668                                                   	MRR:30.98	Hits@10:49.46	Best:30.98
2024-12-28 00:39:52,286: Snapshot:3	Epoch:139	Loss:0.859	translation_Loss:0.193	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.666                                                   	MRR:31.01	Hits@10:49.46	Best:31.01
2024-12-28 00:39:56,217: Snapshot:3	Epoch:140	Loss:0.848	translation_Loss:0.184	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.664                                                   	MRR:31.05	Hits@10:49.57	Best:31.05
2024-12-28 00:40:00,081: Snapshot:3	Epoch:141	Loss:0.844	translation_Loss:0.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.662                                                   	MRR:31.0	Hits@10:49.52	Best:31.05
2024-12-28 00:40:03,934: Snapshot:3	Epoch:142	Loss:0.836	translation_Loss:0.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.659                                                   	MRR:31.03	Hits@10:49.6	Best:31.05
2024-12-28 00:40:07,826: Snapshot:3	Epoch:143	Loss:0.829	translation_Loss:0.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.657                                                   	MRR:31.04	Hits@10:49.51	Best:31.05
2024-12-28 00:40:11,731: Snapshot:3	Epoch:144	Loss:0.825	translation_Loss:0.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.655                                                   	MRR:31.11	Hits@10:49.5	Best:31.11
2024-12-28 00:40:15,621: Snapshot:3	Epoch:145	Loss:0.818	translation_Loss:0.166	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.652                                                   	MRR:31.19	Hits@10:49.54	Best:31.19
2024-12-28 00:40:19,596: Snapshot:3	Epoch:146	Loss:0.811	translation_Loss:0.161	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.65                                                   	MRR:31.21	Hits@10:49.65	Best:31.21
2024-12-28 00:40:23,569: Snapshot:3	Epoch:147	Loss:0.816	translation_Loss:0.168	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.648                                                   	MRR:31.25	Hits@10:49.6	Best:31.25
2024-12-28 00:40:27,507: Snapshot:3	Epoch:148	Loss:0.811	translation_Loss:0.165	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.646                                                   	MRR:31.19	Hits@10:49.55	Best:31.25
2024-12-28 00:40:31,389: Snapshot:3	Epoch:149	Loss:0.806	translation_Loss:0.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.644                                                   	MRR:31.28	Hits@10:49.68	Best:31.28
2024-12-28 00:40:35,289: Snapshot:3	Epoch:150	Loss:0.799	translation_Loss:0.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.642                                                   	MRR:31.2	Hits@10:49.64	Best:31.28
2024-12-28 00:40:39,136: Snapshot:3	Epoch:151	Loss:0.793	translation_Loss:0.153	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.639                                                   	MRR:31.19	Hits@10:49.77	Best:31.28
2024-12-28 00:40:42,964: Snapshot:3	Epoch:152	Loss:0.794	translation_Loss:0.157	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.637                                                   	MRR:31.23	Hits@10:49.7	Best:31.28
2024-12-28 00:40:46,747: Snapshot:3	Epoch:153	Loss:0.79	translation_Loss:0.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.635                                                   	MRR:31.22	Hits@10:49.74	Best:31.28
2024-12-28 00:40:50,588: Snapshot:3	Epoch:154	Loss:0.778	translation_Loss:0.145	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.633                                                   	MRR:31.3	Hits@10:49.73	Best:31.3
2024-12-28 00:40:54,394: Snapshot:3	Epoch:155	Loss:0.785	translation_Loss:0.153	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.632                                                   	MRR:31.27	Hits@10:49.7	Best:31.3
2024-12-28 00:40:58,740: Snapshot:3	Epoch:156	Loss:0.782	translation_Loss:0.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.63                                                   	MRR:31.2	Hits@10:49.83	Best:31.3
2024-12-28 00:41:02,595: Snapshot:3	Epoch:157	Loss:0.777	translation_Loss:0.149	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.628                                                   	MRR:31.25	Hits@10:49.72	Best:31.3
2024-12-28 00:41:06,473: Snapshot:3	Epoch:158	Loss:0.778	translation_Loss:0.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.626                                                   	MRR:31.37	Hits@10:49.78	Best:31.37
2024-12-28 00:41:10,371: Snapshot:3	Epoch:159	Loss:0.766	translation_Loss:0.142	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.624                                                   	MRR:31.31	Hits@10:49.71	Best:31.37
2024-12-28 00:41:14,173: Snapshot:3	Epoch:160	Loss:0.765	translation_Loss:0.143	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.622                                                   	MRR:31.3	Hits@10:49.75	Best:31.37
2024-12-28 00:41:18,026: Snapshot:3	Epoch:161	Loss:0.767	translation_Loss:0.147	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.62                                                   	MRR:31.35	Hits@10:49.72	Best:31.37
2024-12-28 00:41:21,848: Snapshot:3	Epoch:162	Loss:0.757	translation_Loss:0.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.618                                                   	MRR:31.33	Hits@10:49.67	Best:31.37
2024-12-28 00:41:25,729: Early Stopping! Snapshot: 3 Epoch: 163 Best Results: 31.37
2024-12-28 00:41:25,729: Start to training tokens! Snapshot: 3 Epoch: 163 Loss:0.756 MRR:31.28 Best Results: 31.37
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 00:41:25,730: Snapshot:3	Epoch:163	Loss:0.756	translation_Loss:0.139	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.617                                                   	MRR:31.28	Hits@10:49.68	Best:31.37
2024-12-28 00:41:29,419: Snapshot:3	Epoch:164	Loss:21.234	translation_Loss:19.894	multi_layer_Loss:1.34	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:31.28	Hits@10:49.68	Best:31.37
2024-12-28 00:41:33,140: End of token training: 3 Epoch: 165 Loss:21.17 MRR:31.28 Best Results: 31.37
2024-12-28 00:41:33,140: Snapshot:3	Epoch:165	Loss:21.17	translation_Loss:19.923	multi_layer_Loss:1.247	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:31.28	Hits@10:49.68	Best:31.37
2024-12-28 00:41:33,485: => loading checkpoint './checkpoint/RELATIONrelation_0.00001_512_1000/3model_best.tar'
2024-12-28 00:41:48,575: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1479 | 0.0725 | 0.1849 | 0.2305 |  0.2866 |
|     1      | 0.1352 | 0.0637 | 0.1614 | 0.2078 |  0.2705 |
|     2      | 0.1552 | 0.0757 | 0.1726 | 0.2245 |  0.3033 |
|     3      | 0.3134 | 0.2091 | 0.3669 | 0.4269 |  0.4977 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 00:42:01,330: Snapshot:4	Epoch:0	Loss:21.524	translation_Loss:21.524	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.11	Hits@10:12.31	Best:4.11
2024-12-28 00:42:04,103: Snapshot:4	Epoch:1	Loss:20.652	translation_Loss:20.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.001                                                   	MRR:4.5	Hits@10:13.36	Best:4.5
2024-12-28 00:42:06,889: Snapshot:4	Epoch:2	Loss:19.776	translation_Loss:19.774	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.003                                                   	MRR:4.9	Hits@10:14.63	Best:4.9
2024-12-28 00:42:09,682: Snapshot:4	Epoch:3	Loss:18.964	translation_Loss:18.959	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.004                                                   	MRR:5.37	Hits@10:15.79	Best:5.37
2024-12-28 00:42:12,458: Snapshot:4	Epoch:4	Loss:18.098	translation_Loss:18.091	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.007                                                   	MRR:5.84	Hits@10:16.66	Best:5.84
2024-12-28 00:42:15,263: Snapshot:4	Epoch:5	Loss:17.334	translation_Loss:17.324	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.01                                                   	MRR:6.24	Hits@10:17.63	Best:6.24
2024-12-28 00:42:18,152: Snapshot:4	Epoch:6	Loss:16.641	translation_Loss:16.628	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.013                                                   	MRR:6.72	Hits@10:18.7	Best:6.72
2024-12-28 00:42:20,977: Snapshot:4	Epoch:7	Loss:15.917	translation_Loss:15.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.017                                                   	MRR:7.19	Hits@10:19.55	Best:7.19
2024-12-28 00:42:23,764: Snapshot:4	Epoch:8	Loss:15.232	translation_Loss:15.211	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.021                                                   	MRR:7.62	Hits@10:20.2	Best:7.62
2024-12-28 00:42:26,597: Snapshot:4	Epoch:9	Loss:14.596	translation_Loss:14.571	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.025                                                   	MRR:7.97	Hits@10:21.08	Best:7.97
2024-12-28 00:42:29,401: Snapshot:4	Epoch:10	Loss:14.008	translation_Loss:13.979	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.029                                                   	MRR:8.4	Hits@10:21.88	Best:8.4
2024-12-28 00:42:32,186: Snapshot:4	Epoch:11	Loss:13.402	translation_Loss:13.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.034                                                   	MRR:8.81	Hits@10:22.48	Best:8.81
2024-12-28 00:42:35,008: Snapshot:4	Epoch:12	Loss:12.854	translation_Loss:12.815	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.039                                                   	MRR:9.09	Hits@10:23.15	Best:9.09
2024-12-28 00:42:37,744: Snapshot:4	Epoch:13	Loss:12.315	translation_Loss:12.271	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.044                                                   	MRR:9.45	Hits@10:24.11	Best:9.45
2024-12-28 00:42:40,556: Snapshot:4	Epoch:14	Loss:11.866	translation_Loss:11.817	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.049                                                   	MRR:9.9	Hits@10:24.72	Best:9.9
2024-12-28 00:42:43,481: Snapshot:4	Epoch:15	Loss:11.358	translation_Loss:11.304	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.054                                                   	MRR:10.22	Hits@10:25.46	Best:10.22
2024-12-28 00:42:46,307: Snapshot:4	Epoch:16	Loss:10.917	translation_Loss:10.858	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.059                                                   	MRR:10.58	Hits@10:26.58	Best:10.58
2024-12-28 00:42:49,235: Snapshot:4	Epoch:17	Loss:10.45	translation_Loss:10.386	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.064                                                   	MRR:10.96	Hits@10:27.38	Best:10.96
2024-12-28 00:42:52,080: Snapshot:4	Epoch:18	Loss:10.065	translation_Loss:9.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.07                                                   	MRR:11.35	Hits@10:28.06	Best:11.35
2024-12-28 00:42:54,894: Snapshot:4	Epoch:19	Loss:9.673	translation_Loss:9.598	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.075                                                   	MRR:11.79	Hits@10:29.1	Best:11.79
2024-12-28 00:42:57,694: Snapshot:4	Epoch:20	Loss:9.271	translation_Loss:9.191	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.08                                                   	MRR:12.19	Hits@10:29.9	Best:12.19
2024-12-28 00:43:00,482: Snapshot:4	Epoch:21	Loss:8.933	translation_Loss:8.848	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.085                                                   	MRR:12.59	Hits@10:30.76	Best:12.59
2024-12-28 00:43:03,316: Snapshot:4	Epoch:22	Loss:8.554	translation_Loss:8.464	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.09                                                   	MRR:12.98	Hits@10:31.47	Best:12.98
2024-12-28 00:43:06,115: Snapshot:4	Epoch:23	Loss:8.226	translation_Loss:8.131	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.095                                                   	MRR:13.35	Hits@10:32.44	Best:13.35
2024-12-28 00:43:08,989: Snapshot:4	Epoch:24	Loss:7.903	translation_Loss:7.802	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.101                                                   	MRR:13.67	Hits@10:33.48	Best:13.67
2024-12-28 00:43:11,773: Snapshot:4	Epoch:25	Loss:7.612	translation_Loss:7.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.106                                                   	MRR:14.05	Hits@10:34.12	Best:14.05
2024-12-28 00:43:14,611: Snapshot:4	Epoch:26	Loss:7.326	translation_Loss:7.216	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.11                                                   	MRR:14.43	Hits@10:34.72	Best:14.43
2024-12-28 00:43:17,418: Snapshot:4	Epoch:27	Loss:7.049	translation_Loss:6.934	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.115                                                   	MRR:14.77	Hits@10:35.59	Best:14.77
2024-12-28 00:43:20,281: Snapshot:4	Epoch:28	Loss:6.792	translation_Loss:6.671	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.12                                                   	MRR:15.1	Hits@10:36.14	Best:15.1
2024-12-28 00:43:23,090: Snapshot:4	Epoch:29	Loss:6.552	translation_Loss:6.427	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.125                                                   	MRR:15.5	Hits@10:36.66	Best:15.5
2024-12-28 00:43:25,891: Snapshot:4	Epoch:30	Loss:6.302	translation_Loss:6.173	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.13                                                   	MRR:15.85	Hits@10:37.21	Best:15.85
2024-12-28 00:43:28,691: Snapshot:4	Epoch:31	Loss:6.085	translation_Loss:5.951	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.134                                                   	MRR:16.15	Hits@10:37.88	Best:16.15
2024-12-28 00:43:31,477: Snapshot:4	Epoch:32	Loss:5.875	translation_Loss:5.736	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.139                                                   	MRR:16.46	Hits@10:38.33	Best:16.46
2024-12-28 00:43:34,249: Snapshot:4	Epoch:33	Loss:5.614	translation_Loss:5.471	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.143                                                   	MRR:16.71	Hits@10:39.2	Best:16.71
2024-12-28 00:43:37,030: Snapshot:4	Epoch:34	Loss:5.439	translation_Loss:5.291	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.148                                                   	MRR:17.05	Hits@10:39.73	Best:17.05
2024-12-28 00:43:39,867: Snapshot:4	Epoch:35	Loss:5.249	translation_Loss:5.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.152                                                   	MRR:17.33	Hits@10:40.1	Best:17.33
2024-12-28 00:43:42,638: Snapshot:4	Epoch:36	Loss:5.068	translation_Loss:4.912	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.156                                                   	MRR:17.64	Hits@10:40.52	Best:17.64
2024-12-28 00:43:45,464: Snapshot:4	Epoch:37	Loss:4.859	translation_Loss:4.698	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:17.96	Hits@10:40.83	Best:17.96
2024-12-28 00:43:48,241: Snapshot:4	Epoch:38	Loss:4.699	translation_Loss:4.534	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.165                                                   	MRR:18.25	Hits@10:41.48	Best:18.25
2024-12-28 00:43:51,011: Snapshot:4	Epoch:39	Loss:4.553	translation_Loss:4.384	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.169                                                   	MRR:18.53	Hits@10:41.99	Best:18.53
2024-12-28 00:43:53,784: Snapshot:4	Epoch:40	Loss:4.393	translation_Loss:4.22	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.173                                                   	MRR:18.87	Hits@10:42.29	Best:18.87
2024-12-28 00:43:56,580: Snapshot:4	Epoch:41	Loss:4.264	translation_Loss:4.087	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.177                                                   	MRR:19.09	Hits@10:42.64	Best:19.09
2024-12-28 00:43:59,349: Snapshot:4	Epoch:42	Loss:4.107	translation_Loss:3.926	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.181                                                   	MRR:19.36	Hits@10:43.24	Best:19.36
2024-12-28 00:44:02,153: Snapshot:4	Epoch:43	Loss:3.964	translation_Loss:3.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.184                                                   	MRR:19.68	Hits@10:43.78	Best:19.68
2024-12-28 00:44:04,916: Snapshot:4	Epoch:44	Loss:3.828	translation_Loss:3.64	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.188                                                   	MRR:20.04	Hits@10:44.14	Best:20.04
2024-12-28 00:44:07,738: Snapshot:4	Epoch:45	Loss:3.711	translation_Loss:3.519	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.192                                                   	MRR:20.39	Hits@10:44.57	Best:20.39
2024-12-28 00:44:10,523: Snapshot:4	Epoch:46	Loss:3.615	translation_Loss:3.42	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.195                                                   	MRR:20.67	Hits@10:44.7	Best:20.67
2024-12-28 00:44:13,277: Snapshot:4	Epoch:47	Loss:3.478	translation_Loss:3.28	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.199                                                   	MRR:20.95	Hits@10:45.03	Best:20.95
2024-12-28 00:44:16,060: Snapshot:4	Epoch:48	Loss:3.392	translation_Loss:3.19	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.202                                                   	MRR:21.2	Hits@10:45.53	Best:21.2
2024-12-28 00:44:18,849: Snapshot:4	Epoch:49	Loss:3.272	translation_Loss:3.066	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.205                                                   	MRR:21.42	Hits@10:45.72	Best:21.42
2024-12-28 00:44:21,634: Snapshot:4	Epoch:50	Loss:3.193	translation_Loss:2.985	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.209                                                   	MRR:21.66	Hits@10:46.28	Best:21.66
2024-12-28 00:44:24,464: Snapshot:4	Epoch:51	Loss:3.085	translation_Loss:2.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.212                                                   	MRR:21.81	Hits@10:46.74	Best:21.81
2024-12-28 00:44:27,257: Snapshot:4	Epoch:52	Loss:2.997	translation_Loss:2.782	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.215                                                   	MRR:22.0	Hits@10:46.98	Best:22.0
2024-12-28 00:44:30,056: Snapshot:4	Epoch:53	Loss:2.902	translation_Loss:2.684	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.218                                                   	MRR:22.18	Hits@10:47.21	Best:22.18
2024-12-28 00:44:32,849: Snapshot:4	Epoch:54	Loss:2.814	translation_Loss:2.593	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.221                                                   	MRR:22.38	Hits@10:47.64	Best:22.38
2024-12-28 00:44:35,629: Snapshot:4	Epoch:55	Loss:2.742	translation_Loss:2.518	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.224                                                   	MRR:22.58	Hits@10:47.81	Best:22.58
2024-12-28 00:44:38,906: Snapshot:4	Epoch:56	Loss:2.656	translation_Loss:2.429	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.227                                                   	MRR:22.68	Hits@10:48.03	Best:22.68
2024-12-28 00:44:41,694: Snapshot:4	Epoch:57	Loss:2.575	translation_Loss:2.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.229                                                   	MRR:22.89	Hits@10:48.34	Best:22.89
2024-12-28 00:44:44,491: Snapshot:4	Epoch:58	Loss:2.5	translation_Loss:2.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.232                                                   	MRR:23.0	Hits@10:48.76	Best:23.0
2024-12-28 00:44:47,277: Snapshot:4	Epoch:59	Loss:2.417	translation_Loss:2.182	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.235                                                   	MRR:23.15	Hits@10:48.78	Best:23.15
2024-12-28 00:44:50,071: Snapshot:4	Epoch:60	Loss:2.349	translation_Loss:2.112	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.237                                                   	MRR:23.25	Hits@10:48.98	Best:23.25
2024-12-28 00:44:52,924: Snapshot:4	Epoch:61	Loss:2.272	translation_Loss:2.032	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.24                                                   	MRR:23.4	Hits@10:49.24	Best:23.4
2024-12-28 00:44:55,709: Snapshot:4	Epoch:62	Loss:2.212	translation_Loss:1.97	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.242                                                   	MRR:23.47	Hits@10:49.58	Best:23.47
2024-12-28 00:44:58,505: Snapshot:4	Epoch:63	Loss:2.158	translation_Loss:1.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.244                                                   	MRR:23.57	Hits@10:49.83	Best:23.57
2024-12-28 00:45:01,254: Snapshot:4	Epoch:64	Loss:2.084	translation_Loss:1.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.247                                                   	MRR:23.73	Hits@10:50.01	Best:23.73
2024-12-28 00:45:04,052: Snapshot:4	Epoch:65	Loss:2.034	translation_Loss:1.785	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.249                                                   	MRR:23.81	Hits@10:50.25	Best:23.81
2024-12-28 00:45:06,843: Snapshot:4	Epoch:66	Loss:1.96	translation_Loss:1.709	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.251                                                   	MRR:23.9	Hits@10:50.41	Best:23.9
2024-12-28 00:45:09,613: Snapshot:4	Epoch:67	Loss:1.894	translation_Loss:1.641	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.253                                                   	MRR:23.98	Hits@10:50.73	Best:23.98
2024-12-28 00:45:12,386: Snapshot:4	Epoch:68	Loss:1.833	translation_Loss:1.578	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.255                                                   	MRR:24.12	Hits@10:50.82	Best:24.12
2024-12-28 00:45:15,171: Snapshot:4	Epoch:69	Loss:1.771	translation_Loss:1.514	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.257                                                   	MRR:24.22	Hits@10:50.98	Best:24.22
2024-12-28 00:45:18,007: Snapshot:4	Epoch:70	Loss:1.716	translation_Loss:1.457	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.259                                                   	MRR:24.32	Hits@10:51.04	Best:24.32
2024-12-28 00:45:20,796: Snapshot:4	Epoch:71	Loss:1.651	translation_Loss:1.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.261                                                   	MRR:24.43	Hits@10:51.12	Best:24.43
2024-12-28 00:45:23,619: Snapshot:4	Epoch:72	Loss:1.611	translation_Loss:1.348	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.263                                                   	MRR:24.52	Hits@10:51.09	Best:24.52
2024-12-28 00:45:26,425: Snapshot:4	Epoch:73	Loss:1.55	translation_Loss:1.285	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.265                                                   	MRR:24.59	Hits@10:51.1	Best:24.59
2024-12-28 00:45:29,263: Snapshot:4	Epoch:74	Loss:1.496	translation_Loss:1.23	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.266                                                   	MRR:24.67	Hits@10:51.17	Best:24.67
2024-12-28 00:45:32,051: Snapshot:4	Epoch:75	Loss:1.438	translation_Loss:1.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.268                                                   	MRR:24.79	Hits@10:51.41	Best:24.79
2024-12-28 00:45:34,810: Snapshot:4	Epoch:76	Loss:1.402	translation_Loss:1.132	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.27                                                   	MRR:24.98	Hits@10:51.46	Best:24.98
2024-12-28 00:45:37,561: Snapshot:4	Epoch:77	Loss:1.33	translation_Loss:1.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.271                                                   	MRR:25.1	Hits@10:51.57	Best:25.1
2024-12-28 00:45:40,359: Snapshot:4	Epoch:78	Loss:1.292	translation_Loss:1.019	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.273                                                   	MRR:25.27	Hits@10:51.48	Best:25.27
2024-12-28 00:45:43,108: Snapshot:4	Epoch:79	Loss:1.243	translation_Loss:0.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.274                                                   	MRR:25.51	Hits@10:51.63	Best:25.51
2024-12-28 00:45:45,894: Snapshot:4	Epoch:80	Loss:1.189	translation_Loss:0.913	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.276                                                   	MRR:25.69	Hits@10:51.61	Best:25.69
2024-12-28 00:45:48,716: Snapshot:4	Epoch:81	Loss:1.149	translation_Loss:0.872	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.277                                                   	MRR:25.99	Hits@10:51.79	Best:25.99
2024-12-28 00:45:51,528: Snapshot:4	Epoch:82	Loss:1.1	translation_Loss:0.821	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.279                                                   	MRR:26.09	Hits@10:51.85	Best:26.09
2024-12-28 00:45:54,290: Snapshot:4	Epoch:83	Loss:1.053	translation_Loss:0.773	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.28                                                   	MRR:26.24	Hits@10:51.85	Best:26.24
2024-12-28 00:45:57,088: Snapshot:4	Epoch:84	Loss:1.015	translation_Loss:0.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.281                                                   	MRR:26.39	Hits@10:51.94	Best:26.39
2024-12-28 00:45:59,905: Snapshot:4	Epoch:85	Loss:0.963	translation_Loss:0.681	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.282                                                   	MRR:26.5	Hits@10:51.9	Best:26.5
2024-12-28 00:46:02,759: Snapshot:4	Epoch:86	Loss:0.94	translation_Loss:0.657	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.283                                                   	MRR:26.57	Hits@10:51.97	Best:26.57
2024-12-28 00:46:05,557: Snapshot:4	Epoch:87	Loss:0.9	translation_Loss:0.616	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.284                                                   	MRR:26.67	Hits@10:52.14	Best:26.67
2024-12-28 00:46:08,328: Snapshot:4	Epoch:88	Loss:0.872	translation_Loss:0.587	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.285                                                   	MRR:26.74	Hits@10:52.16	Best:26.74
2024-12-28 00:46:11,143: Snapshot:4	Epoch:89	Loss:0.837	translation_Loss:0.551	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.286                                                   	MRR:26.75	Hits@10:52.29	Best:26.75
2024-12-28 00:46:13,935: Snapshot:4	Epoch:90	Loss:0.812	translation_Loss:0.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.287                                                   	MRR:26.87	Hits@10:52.26	Best:26.87
2024-12-28 00:46:16,771: Snapshot:4	Epoch:91	Loss:0.785	translation_Loss:0.497	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.288                                                   	MRR:26.93	Hits@10:52.36	Best:26.93
2024-12-28 00:46:19,569: Snapshot:4	Epoch:92	Loss:0.754	translation_Loss:0.465	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.288                                                   	MRR:27.0	Hits@10:52.4	Best:27.0
2024-12-28 00:46:22,366: Snapshot:4	Epoch:93	Loss:0.738	translation_Loss:0.449	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.289                                                   	MRR:27.12	Hits@10:52.36	Best:27.12
2024-12-28 00:46:25,098: Snapshot:4	Epoch:94	Loss:0.723	translation_Loss:0.434	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.289                                                   	MRR:27.08	Hits@10:52.27	Best:27.12
2024-12-28 00:46:27,785: Snapshot:4	Epoch:95	Loss:0.705	translation_Loss:0.415	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.29                                                   	MRR:27.09	Hits@10:52.43	Best:27.12
2024-12-28 00:46:30,548: Snapshot:4	Epoch:96	Loss:0.677	translation_Loss:0.387	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.29                                                   	MRR:27.14	Hits@10:52.45	Best:27.14
2024-12-28 00:46:33,233: Snapshot:4	Epoch:97	Loss:0.68	translation_Loss:0.389	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.291                                                   	MRR:27.14	Hits@10:52.41	Best:27.14
2024-12-28 00:46:35,979: Snapshot:4	Epoch:98	Loss:0.653	translation_Loss:0.362	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.291                                                   	MRR:27.15	Hits@10:52.42	Best:27.15
2024-12-28 00:46:38,745: Snapshot:4	Epoch:99	Loss:0.63	translation_Loss:0.339	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.291                                                   	MRR:27.14	Hits@10:52.5	Best:27.15
2024-12-28 00:46:41,445: Snapshot:4	Epoch:100	Loss:0.622	translation_Loss:0.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.292                                                   	MRR:27.11	Hits@10:52.67	Best:27.15
2024-12-28 00:46:44,131: Snapshot:4	Epoch:101	Loss:0.599	translation_Loss:0.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.292                                                   	MRR:27.13	Hits@10:52.69	Best:27.15
2024-12-28 00:46:46,866: Snapshot:4	Epoch:102	Loss:0.595	translation_Loss:0.303	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.292                                                   	MRR:27.22	Hits@10:52.77	Best:27.22
2024-12-28 00:46:49,603: Snapshot:4	Epoch:103	Loss:0.58	translation_Loss:0.288	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.292                                                   	MRR:27.19	Hits@10:52.76	Best:27.22
2024-12-28 00:46:52,330: Snapshot:4	Epoch:104	Loss:0.57	translation_Loss:0.278	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.292                                                   	MRR:27.25	Hits@10:52.7	Best:27.25
2024-12-28 00:46:55,102: Snapshot:4	Epoch:105	Loss:0.564	translation_Loss:0.272	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.292                                                   	MRR:27.28	Hits@10:52.94	Best:27.28
2024-12-28 00:46:57,906: Snapshot:4	Epoch:106	Loss:0.556	translation_Loss:0.265	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.292                                                   	MRR:27.34	Hits@10:52.94	Best:27.34
2024-12-28 00:47:00,674: Snapshot:4	Epoch:107	Loss:0.539	translation_Loss:0.247	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.291                                                   	MRR:27.3	Hits@10:53.14	Best:27.34
2024-12-28 00:47:03,386: Snapshot:4	Epoch:108	Loss:0.538	translation_Loss:0.247	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.291                                                   	MRR:27.31	Hits@10:52.99	Best:27.34
2024-12-28 00:47:06,116: Snapshot:4	Epoch:109	Loss:0.52	translation_Loss:0.229	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.291                                                   	MRR:27.26	Hits@10:53.0	Best:27.34
2024-12-28 00:47:08,899: Snapshot:4	Epoch:110	Loss:0.513	translation_Loss:0.223	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.291                                                   	MRR:27.26	Hits@10:52.89	Best:27.34
2024-12-28 00:47:11,669: Snapshot:4	Epoch:111	Loss:0.517	translation_Loss:0.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.29                                                   	MRR:27.35	Hits@10:52.94	Best:27.35
2024-12-28 00:47:14,412: Snapshot:4	Epoch:112	Loss:0.51	translation_Loss:0.22	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.29                                                   	MRR:27.35	Hits@10:52.89	Best:27.35
2024-12-28 00:47:17,684: Snapshot:4	Epoch:113	Loss:0.498	translation_Loss:0.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.29                                                   	MRR:27.49	Hits@10:52.85	Best:27.49
2024-12-28 00:47:20,478: Snapshot:4	Epoch:114	Loss:0.492	translation_Loss:0.203	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.289                                                   	MRR:27.5	Hits@10:52.77	Best:27.5
2024-12-28 00:47:23,342: Snapshot:4	Epoch:115	Loss:0.483	translation_Loss:0.194	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.289                                                   	MRR:27.54	Hits@10:52.71	Best:27.54
2024-12-28 00:47:26,104: Snapshot:4	Epoch:116	Loss:0.475	translation_Loss:0.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.289                                                   	MRR:27.5	Hits@10:52.82	Best:27.54
2024-12-28 00:47:28,891: Snapshot:4	Epoch:117	Loss:0.475	translation_Loss:0.186	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.288                                                   	MRR:27.61	Hits@10:52.93	Best:27.61
2024-12-28 00:47:31,673: Snapshot:4	Epoch:118	Loss:0.466	translation_Loss:0.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.288                                                   	MRR:27.62	Hits@10:52.99	Best:27.62
2024-12-28 00:47:34,442: Snapshot:4	Epoch:119	Loss:0.458	translation_Loss:0.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.287                                                   	MRR:27.68	Hits@10:53.35	Best:27.68
2024-12-28 00:47:37,125: Snapshot:4	Epoch:120	Loss:0.455	translation_Loss:0.168	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.287                                                   	MRR:27.63	Hits@10:53.22	Best:27.68
2024-12-28 00:47:39,842: Snapshot:4	Epoch:121	Loss:0.441	translation_Loss:0.154	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.286                                                   	MRR:27.65	Hits@10:53.0	Best:27.68
2024-12-28 00:47:42,594: Snapshot:4	Epoch:122	Loss:0.447	translation_Loss:0.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.286                                                   	MRR:27.67	Hits@10:53.13	Best:27.68
2024-12-28 00:47:45,359: Snapshot:4	Epoch:123	Loss:0.444	translation_Loss:0.159	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.285                                                   	MRR:27.72	Hits@10:53.16	Best:27.72
2024-12-28 00:47:48,097: Snapshot:4	Epoch:124	Loss:0.435	translation_Loss:0.151	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.285                                                   	MRR:27.72	Hits@10:53.33	Best:27.72
2024-12-28 00:47:50,778: Snapshot:4	Epoch:125	Loss:0.423	translation_Loss:0.139	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.284                                                   	MRR:27.69	Hits@10:53.16	Best:27.72
2024-12-28 00:47:53,496: Snapshot:4	Epoch:126	Loss:0.429	translation_Loss:0.145	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.283                                                   	MRR:27.58	Hits@10:53.11	Best:27.72
2024-12-28 00:47:56,283: Snapshot:4	Epoch:127	Loss:0.419	translation_Loss:0.136	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.283                                                   	MRR:27.73	Hits@10:52.99	Best:27.73
2024-12-28 00:47:59,039: Snapshot:4	Epoch:128	Loss:0.414	translation_Loss:0.132	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.282                                                   	MRR:27.69	Hits@10:53.09	Best:27.73
2024-12-28 00:48:01,770: Snapshot:4	Epoch:129	Loss:0.416	translation_Loss:0.135	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.282                                                   	MRR:27.69	Hits@10:53.22	Best:27.73
2024-12-28 00:48:04,614: Snapshot:4	Epoch:130	Loss:0.41	translation_Loss:0.13	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.281                                                   	MRR:27.74	Hits@10:53.4	Best:27.74
2024-12-28 00:48:07,415: Snapshot:4	Epoch:131	Loss:0.412	translation_Loss:0.132	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.28                                                   	MRR:27.8	Hits@10:53.53	Best:27.8
2024-12-28 00:48:10,222: Snapshot:4	Epoch:132	Loss:0.402	translation_Loss:0.122	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.28                                                   	MRR:27.72	Hits@10:53.57	Best:27.8
2024-12-28 00:48:12,952: Snapshot:4	Epoch:133	Loss:0.393	translation_Loss:0.114	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.279                                                   	MRR:27.72	Hits@10:53.48	Best:27.8
2024-12-28 00:48:15,716: Snapshot:4	Epoch:134	Loss:0.399	translation_Loss:0.12	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.278                                                   	MRR:27.84	Hits@10:53.52	Best:27.84
2024-12-28 00:48:18,544: Snapshot:4	Epoch:135	Loss:0.393	translation_Loss:0.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.278                                                   	MRR:27.84	Hits@10:53.52	Best:27.84
2024-12-28 00:48:21,361: Snapshot:4	Epoch:136	Loss:0.388	translation_Loss:0.112	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.277                                                   	MRR:27.9	Hits@10:53.36	Best:27.9
2024-12-28 00:48:24,208: Snapshot:4	Epoch:137	Loss:0.39	translation_Loss:0.114	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.276                                                   	MRR:27.91	Hits@10:53.23	Best:27.91
2024-12-28 00:48:27,004: Snapshot:4	Epoch:138	Loss:0.385	translation_Loss:0.11	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.276                                                   	MRR:27.94	Hits@10:53.24	Best:27.94
2024-12-28 00:48:29,782: Snapshot:4	Epoch:139	Loss:0.384	translation_Loss:0.109	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.275                                                   	MRR:28.04	Hits@10:53.21	Best:28.04
2024-12-28 00:48:32,583: Snapshot:4	Epoch:140	Loss:0.382	translation_Loss:0.107	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.274                                                   	MRR:28.07	Hits@10:53.18	Best:28.07
2024-12-28 00:48:35,370: Snapshot:4	Epoch:141	Loss:0.38	translation_Loss:0.106	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.274                                                   	MRR:28.13	Hits@10:53.22	Best:28.13
2024-12-28 00:48:38,187: Snapshot:4	Epoch:142	Loss:0.368	translation_Loss:0.095	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.273                                                   	MRR:28.07	Hits@10:53.39	Best:28.13
2024-12-28 00:48:40,923: Snapshot:4	Epoch:143	Loss:0.374	translation_Loss:0.102	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.272                                                   	MRR:28.1	Hits@10:53.66	Best:28.13
2024-12-28 00:48:43,666: Snapshot:4	Epoch:144	Loss:0.366	translation_Loss:0.094	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.272                                                   	MRR:28.06	Hits@10:53.67	Best:28.13
2024-12-28 00:48:46,394: Snapshot:4	Epoch:145	Loss:0.368	translation_Loss:0.098	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.271                                                   	MRR:28.05	Hits@10:53.69	Best:28.13
2024-12-28 00:48:49,078: Early Stopping! Snapshot: 4 Epoch: 146 Best Results: 28.13
2024-12-28 00:48:49,078: Start to training tokens! Snapshot: 4 Epoch: 146 Loss:0.361 MRR:28.04 Best Results: 28.13
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 00:48:49,078: Snapshot:4	Epoch:146	Loss:0.361	translation_Loss:0.091	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.27                                                   	MRR:28.04	Hits@10:53.76	Best:28.13
2024-12-28 00:48:51,711: Snapshot:4	Epoch:147	Loss:12.133	translation_Loss:11.125	multi_layer_Loss:1.008	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:28.04	Hits@10:53.76	Best:28.13
2024-12-28 00:48:54,317: End of token training: 4 Epoch: 148 Loss:12.02 MRR:28.04 Best Results: 28.13
2024-12-28 00:48:54,318: Snapshot:4	Epoch:148	Loss:12.02	translation_Loss:11.056	multi_layer_Loss:0.964	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:28.04	Hits@10:53.76	Best:28.13
2024-12-28 00:48:54,662: => loading checkpoint './checkpoint/RELATIONrelation_0.00001_512_1000/4model_best.tar'
2024-12-28 00:49:11,362: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1383 | 0.0703 | 0.1721 | 0.2119 |  0.2583 |
|     1      | 0.1282 | 0.0592 | 0.1518 | 0.1964 |  0.2578 |
|     2      | 0.1443 | 0.0699 | 0.1632 | 0.2074 |  0.2796 |
|     3      | 0.2574 | 0.1721 | 0.289  | 0.3332 |  0.4104 |
|     4      | 0.2763 | 0.1499 | 0.324  | 0.4087 |  0.5298 |
+------------+--------+--------+--------+--------+---------+
2024-12-28 00:49:11,364: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2734 | 0.158  | 0.3455 | 0.4134 |  0.4843 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1848 | 0.0868 | 0.2376 | 0.2947 |  0.3666 |
|     1      |  0.2   | 0.1071 | 0.2406 | 0.3001 |  0.3755 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1525 | 0.0739 | 0.1919 | 0.2393 |  0.2969 |
|     1      | 0.1502 | 0.0759 | 0.1791 | 0.227  |  0.2872 |
|     2      | 0.2293 | 0.1353 | 0.2567 | 0.3214 |   0.42  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1479 | 0.0725 | 0.1849 | 0.2305 |  0.2866 |
|     1      | 0.1352 | 0.0637 | 0.1614 | 0.2078 |  0.2705 |
|     2      | 0.1552 | 0.0757 | 0.1726 | 0.2245 |  0.3033 |
|     3      | 0.3134 | 0.2091 | 0.3669 | 0.4269 |  0.4977 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1383 | 0.0703 | 0.1721 | 0.2119 |  0.2583 |
|     1      | 0.1282 | 0.0592 | 0.1518 | 0.1964 |  0.2578 |
|     2      | 0.1443 | 0.0699 | 0.1632 | 0.2074 |  0.2796 |
|     3      | 0.2574 | 0.1721 | 0.289  | 0.3332 |  0.4104 |
|     4      | 0.2763 | 0.1499 | 0.324  | 0.4087 |  0.5298 |
+------------+--------+--------+--------+--------+---------+]
2024-12-28 00:49:11,365: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 1860.206127166748  |   0.273   |    0.158     |    0.345     |     0.484     |
|    1     | 925.1544694900513  |   0.192   |    0.097     |    0.239     |     0.371     |
|    2     | 865.6860256195068  |   0.171   |     0.09     |    0.204     |     0.325     |
|    3     | 659.7423141002655  |   0.163   |    0.085     |    0.193     |     0.307     |
|    4     | 424.26224422454834 |   0.158   |    0.082     |    0.186     |     0.296     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-28 00:49:11,365: Sum_Training_Time:4735.05118060112
2024-12-28 00:49:11,365: Every_Training_Time:[1860.206127166748, 925.1544694900513, 865.6860256195068, 659.7423141002655, 424.26224422454834]
2024-12-28 00:49:11,365: Forward transfer: 0.018675 Backward transfer: -0.08697499999999998
2024-12-28 00:49:48,885: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=1e-05, lifelong_name='double_tokened', log_path='./logs/20241228004915/RELATIONrelation_0.00001_512_5000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.00001_512_5000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.00001_512_5000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=5000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-28 00:50:05,005: Snapshot:0	Epoch:0	Loss:165.062	translation_Loss:165.062	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:1.83	Hits@10:1.85	Best:1.83
2024-12-28 00:50:16,655: Snapshot:0	Epoch:1	Loss:162.089	translation_Loss:162.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:1.89	Hits@10:1.99	Best:1.89
2024-12-28 00:50:28,270: Snapshot:0	Epoch:2	Loss:159.039	translation_Loss:159.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:2.08	Hits@10:2.48	Best:2.08
2024-12-28 00:50:39,888: Snapshot:0	Epoch:3	Loss:156.025	translation_Loss:156.025	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:2.65	Hits@10:4.15	Best:2.65
2024-12-28 00:50:51,498: Snapshot:0	Epoch:4	Loss:153.079	translation_Loss:153.079	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:3.63	Hits@10:6.75	Best:3.63
2024-12-28 00:51:03,221: Snapshot:0	Epoch:5	Loss:150.267	translation_Loss:150.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.8	Hits@10:9.61	Best:4.8
2024-12-28 00:51:14,958: Snapshot:0	Epoch:6	Loss:147.532	translation_Loss:147.532	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:5.9	Hits@10:12.07	Best:5.9
2024-12-28 00:51:27,136: Snapshot:0	Epoch:7	Loss:144.844	translation_Loss:144.844	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:6.8	Hits@10:14.01	Best:6.8
2024-12-28 00:51:38,774: Snapshot:0	Epoch:8	Loss:142.33	translation_Loss:142.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.41	Hits@10:15.28	Best:7.41
2024-12-28 00:51:50,422: Snapshot:0	Epoch:9	Loss:139.836	translation_Loss:139.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.84	Hits@10:16.31	Best:7.84
2024-12-28 00:52:02,043: Snapshot:0	Epoch:10	Loss:137.505	translation_Loss:137.505	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.15	Hits@10:17.17	Best:8.15
2024-12-28 00:52:13,701: Snapshot:0	Epoch:11	Loss:135.246	translation_Loss:135.246	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.39	Hits@10:17.93	Best:8.39
2024-12-28 00:52:25,452: Snapshot:0	Epoch:12	Loss:132.99	translation_Loss:132.99	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.6	Hits@10:18.62	Best:8.6
2024-12-28 00:52:37,221: Snapshot:0	Epoch:13	Loss:130.929	translation_Loss:130.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.8	Hits@10:19.27	Best:8.8
2024-12-28 00:52:48,847: Snapshot:0	Epoch:14	Loss:128.817	translation_Loss:128.817	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.97	Hits@10:19.81	Best:8.97
2024-12-28 00:53:00,551: Snapshot:0	Epoch:15	Loss:126.902	translation_Loss:126.902	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.12	Hits@10:20.3	Best:9.12
2024-12-28 00:53:12,358: Snapshot:0	Epoch:16	Loss:124.769	translation_Loss:124.769	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.27	Hits@10:20.79	Best:9.27
2024-12-28 00:53:23,984: Snapshot:0	Epoch:17	Loss:122.834	translation_Loss:122.834	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.4	Hits@10:21.26	Best:9.4
2024-12-28 00:53:35,792: Snapshot:0	Epoch:18	Loss:120.914	translation_Loss:120.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.54	Hits@10:21.68	Best:9.54
2024-12-28 00:53:48,107: Snapshot:0	Epoch:19	Loss:118.966	translation_Loss:118.966	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.67	Hits@10:22.1	Best:9.67
2024-12-28 00:53:59,753: Snapshot:0	Epoch:20	Loss:117.16	translation_Loss:117.16	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.8	Hits@10:22.5	Best:9.8
2024-12-28 00:54:11,467: Snapshot:0	Epoch:21	Loss:115.205	translation_Loss:115.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.92	Hits@10:22.89	Best:9.92
2024-12-28 00:54:23,248: Snapshot:0	Epoch:22	Loss:113.455	translation_Loss:113.455	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.05	Hits@10:23.31	Best:10.05
2024-12-28 00:54:34,933: Snapshot:0	Epoch:23	Loss:111.589	translation_Loss:111.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.2	Hits@10:23.77	Best:10.2
2024-12-28 00:54:46,731: Snapshot:0	Epoch:24	Loss:109.708	translation_Loss:109.708	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.36	Hits@10:24.19	Best:10.36
2024-12-28 00:54:58,564: Snapshot:0	Epoch:25	Loss:108.053	translation_Loss:108.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.54	Hits@10:24.65	Best:10.54
2024-12-28 00:55:10,401: Snapshot:0	Epoch:26	Loss:106.172	translation_Loss:106.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.75	Hits@10:25.22	Best:10.75
2024-12-28 00:55:22,020: Snapshot:0	Epoch:27	Loss:104.393	translation_Loss:104.393	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.97	Hits@10:25.72	Best:10.97
2024-12-28 00:55:33,626: Snapshot:0	Epoch:28	Loss:102.674	translation_Loss:102.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.25	Hits@10:26.23	Best:11.25
2024-12-28 00:55:45,404: Snapshot:0	Epoch:29	Loss:100.893	translation_Loss:100.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.51	Hits@10:26.74	Best:11.51
2024-12-28 00:55:57,179: Snapshot:0	Epoch:30	Loss:99.101	translation_Loss:99.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.81	Hits@10:27.38	Best:11.81
2024-12-28 00:56:08,918: Snapshot:0	Epoch:31	Loss:97.402	translation_Loss:97.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.09	Hits@10:27.94	Best:12.09
2024-12-28 00:56:21,126: Snapshot:0	Epoch:32	Loss:95.6	translation_Loss:95.6	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.43	Hits@10:28.47	Best:12.43
2024-12-28 00:56:32,857: Snapshot:0	Epoch:33	Loss:93.962	translation_Loss:93.962	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.77	Hits@10:29.15	Best:12.77
2024-12-28 00:56:44,535: Snapshot:0	Epoch:34	Loss:92.111	translation_Loss:92.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.1	Hits@10:29.75	Best:13.1
2024-12-28 00:56:56,155: Snapshot:0	Epoch:35	Loss:90.548	translation_Loss:90.548	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.47	Hits@10:30.34	Best:13.47
2024-12-28 00:57:07,877: Snapshot:0	Epoch:36	Loss:88.741	translation_Loss:88.741	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.84	Hits@10:31.0	Best:13.84
2024-12-28 00:57:19,628: Snapshot:0	Epoch:37	Loss:87.077	translation_Loss:87.077	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.21	Hits@10:31.59	Best:14.21
2024-12-28 00:57:31,296: Snapshot:0	Epoch:38	Loss:85.453	translation_Loss:85.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.58	Hits@10:32.3	Best:14.58
2024-12-28 00:57:43,046: Snapshot:0	Epoch:39	Loss:83.863	translation_Loss:83.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.92	Hits@10:32.93	Best:14.92
2024-12-28 00:57:54,649: Snapshot:0	Epoch:40	Loss:82.026	translation_Loss:82.026	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.29	Hits@10:33.48	Best:15.29
2024-12-28 00:58:06,292: Snapshot:0	Epoch:41	Loss:80.438	translation_Loss:80.438	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.67	Hits@10:33.98	Best:15.67
2024-12-28 00:58:18,033: Snapshot:0	Epoch:42	Loss:78.854	translation_Loss:78.854	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.05	Hits@10:34.47	Best:16.05
2024-12-28 00:58:29,656: Snapshot:0	Epoch:43	Loss:77.207	translation_Loss:77.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.4	Hits@10:34.98	Best:16.4
2024-12-28 00:58:41,888: Snapshot:0	Epoch:44	Loss:75.557	translation_Loss:75.557	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.73	Hits@10:35.57	Best:16.73
2024-12-28 00:58:53,553: Snapshot:0	Epoch:45	Loss:73.95	translation_Loss:73.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.02	Hits@10:36.0	Best:17.02
2024-12-28 00:59:05,234: Snapshot:0	Epoch:46	Loss:72.368	translation_Loss:72.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.34	Hits@10:36.53	Best:17.34
2024-12-28 00:59:16,941: Snapshot:0	Epoch:47	Loss:70.792	translation_Loss:70.792	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.63	Hits@10:36.91	Best:17.63
2024-12-28 00:59:28,617: Snapshot:0	Epoch:48	Loss:69.198	translation_Loss:69.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.89	Hits@10:37.35	Best:17.89
2024-12-28 00:59:40,292: Snapshot:0	Epoch:49	Loss:67.67	translation_Loss:67.67	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.18	Hits@10:37.81	Best:18.18
2024-12-28 00:59:52,058: Snapshot:0	Epoch:50	Loss:66.104	translation_Loss:66.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.43	Hits@10:38.19	Best:18.43
2024-12-28 01:00:03,792: Snapshot:0	Epoch:51	Loss:64.635	translation_Loss:64.635	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.69	Hits@10:38.57	Best:18.69
2024-12-28 01:00:15,551: Snapshot:0	Epoch:52	Loss:63.251	translation_Loss:63.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.93	Hits@10:38.91	Best:18.93
2024-12-28 01:00:27,308: Snapshot:0	Epoch:53	Loss:61.703	translation_Loss:61.703	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.17	Hits@10:39.22	Best:19.17
2024-12-28 01:00:38,956: Snapshot:0	Epoch:54	Loss:60.29	translation_Loss:60.29	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.38	Hits@10:39.56	Best:19.38
2024-12-28 01:00:50,647: Snapshot:0	Epoch:55	Loss:58.969	translation_Loss:58.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.57	Hits@10:39.88	Best:19.57
2024-12-28 01:01:02,308: Snapshot:0	Epoch:56	Loss:57.661	translation_Loss:57.661	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.73	Hits@10:40.2	Best:19.73
2024-12-28 01:01:14,610: Snapshot:0	Epoch:57	Loss:56.231	translation_Loss:56.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.94	Hits@10:40.43	Best:19.94
2024-12-28 01:01:26,247: Snapshot:0	Epoch:58	Loss:55.009	translation_Loss:55.009	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.15	Hits@10:40.66	Best:20.15
2024-12-28 01:01:37,865: Snapshot:0	Epoch:59	Loss:53.637	translation_Loss:53.637	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.35	Hits@10:40.92	Best:20.35
2024-12-28 01:01:49,536: Snapshot:0	Epoch:60	Loss:52.48	translation_Loss:52.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.51	Hits@10:41.14	Best:20.51
2024-12-28 01:02:01,287: Snapshot:0	Epoch:61	Loss:51.322	translation_Loss:51.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.71	Hits@10:41.4	Best:20.71
2024-12-28 01:02:12,999: Snapshot:0	Epoch:62	Loss:50.026	translation_Loss:50.026	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.87	Hits@10:41.59	Best:20.87
2024-12-28 01:02:24,634: Snapshot:0	Epoch:63	Loss:48.907	translation_Loss:48.907	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.02	Hits@10:41.78	Best:21.02
2024-12-28 01:02:36,257: Snapshot:0	Epoch:64	Loss:47.669	translation_Loss:47.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.2	Hits@10:41.96	Best:21.2
2024-12-28 01:02:48,029: Snapshot:0	Epoch:65	Loss:46.651	translation_Loss:46.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.34	Hits@10:42.13	Best:21.34
2024-12-28 01:02:59,741: Snapshot:0	Epoch:66	Loss:45.62	translation_Loss:45.62	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.53	Hits@10:42.31	Best:21.53
2024-12-28 01:03:11,485: Snapshot:0	Epoch:67	Loss:44.525	translation_Loss:44.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.67	Hits@10:42.53	Best:21.67
2024-12-28 01:03:23,218: Snapshot:0	Epoch:68	Loss:43.562	translation_Loss:43.562	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.82	Hits@10:42.66	Best:21.82
2024-12-28 01:03:35,409: Snapshot:0	Epoch:69	Loss:42.385	translation_Loss:42.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.99	Hits@10:42.79	Best:21.99
2024-12-28 01:03:47,064: Snapshot:0	Epoch:70	Loss:41.44	translation_Loss:41.44	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.13	Hits@10:42.99	Best:22.13
2024-12-28 01:03:58,737: Snapshot:0	Epoch:71	Loss:40.483	translation_Loss:40.483	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.27	Hits@10:43.18	Best:22.27
2024-12-28 01:04:10,374: Snapshot:0	Epoch:72	Loss:39.485	translation_Loss:39.485	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.39	Hits@10:43.35	Best:22.39
2024-12-28 01:04:22,045: Snapshot:0	Epoch:73	Loss:38.576	translation_Loss:38.576	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.52	Hits@10:43.5	Best:22.52
2024-12-28 01:04:33,817: Snapshot:0	Epoch:74	Loss:37.63	translation_Loss:37.63	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.65	Hits@10:43.62	Best:22.65
2024-12-28 01:04:45,534: Snapshot:0	Epoch:75	Loss:36.798	translation_Loss:36.798	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.77	Hits@10:43.81	Best:22.77
2024-12-28 01:04:57,123: Snapshot:0	Epoch:76	Loss:35.861	translation_Loss:35.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.86	Hits@10:43.93	Best:22.86
2024-12-28 01:05:08,858: Snapshot:0	Epoch:77	Loss:35.001	translation_Loss:35.001	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.02	Hits@10:44.08	Best:23.02
2024-12-28 01:05:20,648: Snapshot:0	Epoch:78	Loss:34.067	translation_Loss:34.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.13	Hits@10:44.18	Best:23.13
2024-12-28 01:05:32,375: Snapshot:0	Epoch:79	Loss:33.245	translation_Loss:33.245	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.27	Hits@10:44.27	Best:23.27
2024-12-28 01:05:44,094: Snapshot:0	Epoch:80	Loss:32.45	translation_Loss:32.45	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.36	Hits@10:44.43	Best:23.36
2024-12-28 01:05:55,733: Snapshot:0	Epoch:81	Loss:31.716	translation_Loss:31.716	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.47	Hits@10:44.56	Best:23.47
2024-12-28 01:06:07,959: Snapshot:0	Epoch:82	Loss:30.843	translation_Loss:30.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.56	Hits@10:44.72	Best:23.56
2024-12-28 01:06:19,687: Snapshot:0	Epoch:83	Loss:30.105	translation_Loss:30.105	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.68	Hits@10:44.82	Best:23.68
2024-12-28 01:06:31,350: Snapshot:0	Epoch:84	Loss:29.318	translation_Loss:29.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.78	Hits@10:44.94	Best:23.78
2024-12-28 01:06:43,043: Snapshot:0	Epoch:85	Loss:28.676	translation_Loss:28.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.85	Hits@10:45.1	Best:23.85
2024-12-28 01:06:54,626: Snapshot:0	Epoch:86	Loss:27.986	translation_Loss:27.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.93	Hits@10:45.21	Best:23.93
2024-12-28 01:07:06,220: Snapshot:0	Epoch:87	Loss:27.274	translation_Loss:27.274	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.04	Hits@10:45.35	Best:24.04
2024-12-28 01:07:17,960: Snapshot:0	Epoch:88	Loss:26.56	translation_Loss:26.56	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.14	Hits@10:45.43	Best:24.14
2024-12-28 01:07:29,824: Snapshot:0	Epoch:89	Loss:25.956	translation_Loss:25.956	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.21	Hits@10:45.52	Best:24.21
2024-12-28 01:07:41,519: Snapshot:0	Epoch:90	Loss:25.335	translation_Loss:25.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.29	Hits@10:45.63	Best:24.29
2024-12-28 01:07:53,256: Snapshot:0	Epoch:91	Loss:24.688	translation_Loss:24.688	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.41	Hits@10:45.7	Best:24.41
2024-12-28 01:08:04,911: Snapshot:0	Epoch:92	Loss:24.051	translation_Loss:24.051	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.49	Hits@10:45.79	Best:24.49
2024-12-28 01:08:16,650: Snapshot:0	Epoch:93	Loss:23.39	translation_Loss:23.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.6	Hits@10:45.85	Best:24.6
2024-12-28 01:08:28,851: Snapshot:0	Epoch:94	Loss:22.88	translation_Loss:22.88	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.67	Hits@10:45.97	Best:24.67
2024-12-28 01:08:40,493: Snapshot:0	Epoch:95	Loss:22.35	translation_Loss:22.35	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.74	Hits@10:46.04	Best:24.74
2024-12-28 01:08:52,226: Snapshot:0	Epoch:96	Loss:21.737	translation_Loss:21.737	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.83	Hits@10:46.13	Best:24.83
2024-12-28 01:09:03,877: Snapshot:0	Epoch:97	Loss:21.255	translation_Loss:21.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.89	Hits@10:46.24	Best:24.89
2024-12-28 01:09:15,679: Snapshot:0	Epoch:98	Loss:20.699	translation_Loss:20.699	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.96	Hits@10:46.27	Best:24.96
2024-12-28 01:09:27,404: Snapshot:0	Epoch:99	Loss:20.277	translation_Loss:20.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.03	Hits@10:46.36	Best:25.03
2024-12-28 01:09:39,062: Snapshot:0	Epoch:100	Loss:19.687	translation_Loss:19.687	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.1	Hits@10:46.45	Best:25.1
2024-12-28 01:09:50,747: Snapshot:0	Epoch:101	Loss:19.205	translation_Loss:19.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.15	Hits@10:46.51	Best:25.15
2024-12-28 01:10:02,377: Snapshot:0	Epoch:102	Loss:18.709	translation_Loss:18.709	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.23	Hits@10:46.57	Best:25.23
2024-12-28 01:10:14,141: Snapshot:0	Epoch:103	Loss:18.314	translation_Loss:18.314	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.27	Hits@10:46.6	Best:25.27
2024-12-28 01:10:25,921: Snapshot:0	Epoch:104	Loss:17.887	translation_Loss:17.887	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.34	Hits@10:46.7	Best:25.34
2024-12-28 01:10:37,608: Snapshot:0	Epoch:105	Loss:17.435	translation_Loss:17.435	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.4	Hits@10:46.74	Best:25.4
2024-12-28 01:10:49,331: Snapshot:0	Epoch:106	Loss:16.99	translation_Loss:16.99	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.49	Hits@10:46.85	Best:25.49
2024-12-28 01:11:01,527: Snapshot:0	Epoch:107	Loss:16.564	translation_Loss:16.564	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.54	Hits@10:46.91	Best:25.54
2024-12-28 01:11:13,193: Snapshot:0	Epoch:108	Loss:16.162	translation_Loss:16.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.59	Hits@10:47.0	Best:25.59
2024-12-28 01:11:24,934: Snapshot:0	Epoch:109	Loss:15.853	translation_Loss:15.853	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.65	Hits@10:47.01	Best:25.65
2024-12-28 01:11:36,552: Snapshot:0	Epoch:110	Loss:15.453	translation_Loss:15.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.68	Hits@10:47.09	Best:25.68
2024-12-28 01:11:48,350: Snapshot:0	Epoch:111	Loss:15.094	translation_Loss:15.094	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.76	Hits@10:47.17	Best:25.76
2024-12-28 01:11:59,971: Snapshot:0	Epoch:112	Loss:14.784	translation_Loss:14.784	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.79	Hits@10:47.19	Best:25.79
2024-12-28 01:12:11,652: Snapshot:0	Epoch:113	Loss:14.451	translation_Loss:14.451	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.86	Hits@10:47.23	Best:25.86
2024-12-28 01:12:23,280: Snapshot:0	Epoch:114	Loss:14.155	translation_Loss:14.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.92	Hits@10:47.31	Best:25.92
2024-12-28 01:12:34,919: Snapshot:0	Epoch:115	Loss:13.733	translation_Loss:13.733	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.97	Hits@10:47.34	Best:25.97
2024-12-28 01:12:46,695: Snapshot:0	Epoch:116	Loss:13.434	translation_Loss:13.434	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.02	Hits@10:47.43	Best:26.02
2024-12-28 01:12:58,386: Snapshot:0	Epoch:117	Loss:13.181	translation_Loss:13.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.06	Hits@10:47.49	Best:26.06
2024-12-28 01:13:10,043: Snapshot:0	Epoch:118	Loss:12.815	translation_Loss:12.815	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.14	Hits@10:47.46	Best:26.14
2024-12-28 01:13:22,244: Snapshot:0	Epoch:119	Loss:12.552	translation_Loss:12.552	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.17	Hits@10:47.54	Best:26.17
2024-12-28 01:13:33,825: Snapshot:0	Epoch:120	Loss:12.297	translation_Loss:12.297	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.2	Hits@10:47.5	Best:26.2
2024-12-28 01:13:45,457: Snapshot:0	Epoch:121	Loss:12.0	translation_Loss:12.0	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.22	Hits@10:47.61	Best:26.22
2024-12-28 01:13:57,138: Snapshot:0	Epoch:122	Loss:11.766	translation_Loss:11.766	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.3	Hits@10:47.67	Best:26.3
2024-12-28 01:14:08,794: Snapshot:0	Epoch:123	Loss:11.546	translation_Loss:11.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.33	Hits@10:47.64	Best:26.33
2024-12-28 01:14:20,503: Snapshot:0	Epoch:124	Loss:11.267	translation_Loss:11.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.38	Hits@10:47.61	Best:26.38
2024-12-28 01:14:32,168: Snapshot:0	Epoch:125	Loss:11.087	translation_Loss:11.087	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.44	Hits@10:47.68	Best:26.44
2024-12-28 01:14:43,878: Snapshot:0	Epoch:126	Loss:10.828	translation_Loss:10.828	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.5	Hits@10:47.76	Best:26.5
2024-12-28 01:14:55,480: Snapshot:0	Epoch:127	Loss:10.608	translation_Loss:10.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.52	Hits@10:47.76	Best:26.52
2024-12-28 01:15:07,216: Snapshot:0	Epoch:128	Loss:10.383	translation_Loss:10.383	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.57	Hits@10:47.78	Best:26.57
2024-12-28 01:15:18,978: Snapshot:0	Epoch:129	Loss:10.178	translation_Loss:10.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.58	Hits@10:47.78	Best:26.58
2024-12-28 01:15:30,671: Snapshot:0	Epoch:130	Loss:9.997	translation_Loss:9.997	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.61	Hits@10:47.8	Best:26.61
2024-12-28 01:15:43,020: Snapshot:0	Epoch:131	Loss:9.786	translation_Loss:9.786	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.65	Hits@10:47.83	Best:26.65
2024-12-28 01:15:54,610: Snapshot:0	Epoch:132	Loss:9.556	translation_Loss:9.556	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.68	Hits@10:47.86	Best:26.68
2024-12-28 01:16:06,286: Snapshot:0	Epoch:133	Loss:9.346	translation_Loss:9.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.69	Hits@10:47.86	Best:26.69
2024-12-28 01:16:17,940: Snapshot:0	Epoch:134	Loss:9.207	translation_Loss:9.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.69	Hits@10:47.89	Best:26.69
2024-12-28 01:16:29,767: Snapshot:0	Epoch:135	Loss:9.024	translation_Loss:9.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.7	Hits@10:47.91	Best:26.7
2024-12-28 01:16:41,575: Snapshot:0	Epoch:136	Loss:8.909	translation_Loss:8.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.73	Hits@10:47.95	Best:26.73
2024-12-28 01:16:53,411: Snapshot:0	Epoch:137	Loss:8.695	translation_Loss:8.695	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.77	Hits@10:47.95	Best:26.77
2024-12-28 01:17:05,124: Snapshot:0	Epoch:138	Loss:8.507	translation_Loss:8.507	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.78	Hits@10:47.94	Best:26.78
2024-12-28 01:17:16,854: Snapshot:0	Epoch:139	Loss:8.393	translation_Loss:8.393	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.76	Hits@10:47.93	Best:26.78
2024-12-28 01:17:28,634: Snapshot:0	Epoch:140	Loss:8.239	translation_Loss:8.239	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.84	Hits@10:47.97	Best:26.84
2024-12-28 01:17:40,245: Snapshot:0	Epoch:141	Loss:8.059	translation_Loss:8.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.85	Hits@10:48.01	Best:26.85
2024-12-28 01:17:51,971: Snapshot:0	Epoch:142	Loss:7.967	translation_Loss:7.967	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.86	Hits@10:47.97	Best:26.86
2024-12-28 01:18:03,691: Snapshot:0	Epoch:143	Loss:7.837	translation_Loss:7.837	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.88	Hits@10:48.0	Best:26.88
2024-12-28 01:18:15,924: Snapshot:0	Epoch:144	Loss:7.644	translation_Loss:7.644	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.88	Hits@10:47.99	Best:26.88
2024-12-28 01:18:27,595: Snapshot:0	Epoch:145	Loss:7.522	translation_Loss:7.522	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.93	Hits@10:48.0	Best:26.93
2024-12-28 01:18:39,262: Snapshot:0	Epoch:146	Loss:7.425	translation_Loss:7.425	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.95	Hits@10:48.04	Best:26.95
2024-12-28 01:18:50,941: Snapshot:0	Epoch:147	Loss:7.296	translation_Loss:7.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.96	Hits@10:48.01	Best:26.96
2024-12-28 01:19:02,588: Snapshot:0	Epoch:148	Loss:7.17	translation_Loss:7.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.97	Hits@10:48.01	Best:26.97
2024-12-28 01:19:14,362: Snapshot:0	Epoch:149	Loss:7.044	translation_Loss:7.044	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.0	Hits@10:48.02	Best:27.0
2024-12-28 01:19:26,070: Snapshot:0	Epoch:150	Loss:6.984	translation_Loss:6.984	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.01	Hits@10:48.08	Best:27.01
2024-12-28 01:19:37,679: Snapshot:0	Epoch:151	Loss:6.872	translation_Loss:6.872	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.03	Hits@10:48.07	Best:27.03
2024-12-28 01:19:49,373: Snapshot:0	Epoch:152	Loss:6.707	translation_Loss:6.707	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.01	Hits@10:48.04	Best:27.03
2024-12-28 01:20:01,262: Snapshot:0	Epoch:153	Loss:6.623	translation_Loss:6.623	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.98	Hits@10:48.05	Best:27.03
2024-12-28 01:20:13,129: Snapshot:0	Epoch:154	Loss:6.537	translation_Loss:6.537	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.98	Hits@10:48.09	Best:27.03
2024-12-28 01:20:24,722: Snapshot:0	Epoch:155	Loss:6.482	translation_Loss:6.482	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.99	Hits@10:48.16	Best:27.03
2024-12-28 01:20:36,960: Early Stopping! Snapshot: 0 Epoch: 156 Best Results: 27.03
2024-12-28 01:20:36,960: Start to training tokens! Snapshot: 0 Epoch: 156 Loss:6.356 MRR:27.02 Best Results: 27.03
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 01:20:36,961: Snapshot:0	Epoch:156	Loss:6.356	translation_Loss:6.356	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.02	Hits@10:48.18	Best:27.03
2024-12-28 01:20:49,517: Snapshot:0	Epoch:157	Loss:108.017	translation_Loss:103.825	multi_layer_Loss:4.192	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.02	Hits@10:48.18	Best:27.03
2024-12-28 01:21:01,442: End of token training: 0 Epoch: 158 Loss:106.814 MRR:27.02 Best Results: 27.03
2024-12-28 01:21:01,442: Snapshot:0	Epoch:158	Loss:106.814	translation_Loss:103.684	multi_layer_Loss:3.13	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.02	Hits@10:48.18	Best:27.03
2024-12-28 01:21:01,743: => loading checkpoint './checkpoint/RELATIONrelation_0.00001_512_5000/0model_best.tar'
2024-12-28 01:21:06,978: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2733 | 0.1579 | 0.3449 | 0.413  |  0.4843 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 01:21:44,610: Snapshot:1	Epoch:0	Loss:154.153	translation_Loss:154.13	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.023                                                   	MRR:2.43	Hits@10:7.08	Best:2.43
2024-12-28 01:21:55,728: Snapshot:1	Epoch:1	Loss:149.158	translation_Loss:149.058	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.1                                                   	MRR:2.51	Hits@10:7.21	Best:2.51
2024-12-28 01:22:06,971: Snapshot:1	Epoch:2	Loss:144.241	translation_Loss:144.009	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.231                                                   	MRR:2.58	Hits@10:7.38	Best:2.58
2024-12-28 01:22:18,327: Snapshot:1	Epoch:3	Loss:139.431	translation_Loss:139.023	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.408                                                   	MRR:2.76	Hits@10:7.86	Best:2.76
2024-12-28 01:22:29,699: Snapshot:1	Epoch:4	Loss:134.947	translation_Loss:134.326	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.62                                                   	MRR:3.1	Hits@10:8.68	Best:3.1
2024-12-28 01:22:41,058: Snapshot:1	Epoch:5	Loss:130.479	translation_Loss:129.618	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.861                                                   	MRR:3.59	Hits@10:10.03	Best:3.59
2024-12-28 01:22:52,240: Snapshot:1	Epoch:6	Loss:126.243	translation_Loss:125.12	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.123                                                   	MRR:4.1	Hits@10:11.27	Best:4.1
2024-12-28 01:23:03,550: Snapshot:1	Epoch:7	Loss:122.23	translation_Loss:120.829	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.401                                                   	MRR:4.55	Hits@10:12.27	Best:4.55
2024-12-28 01:23:14,865: Snapshot:1	Epoch:8	Loss:118.364	translation_Loss:116.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.69                                                   	MRR:5.03	Hits@10:13.4	Best:5.03
2024-12-28 01:23:26,291: Snapshot:1	Epoch:9	Loss:114.655	translation_Loss:112.668	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.987                                                   	MRR:5.53	Hits@10:14.39	Best:5.53
2024-12-28 01:23:37,680: Snapshot:1	Epoch:10	Loss:111.135	translation_Loss:108.847	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.288                                                   	MRR:6.06	Hits@10:15.52	Best:6.06
2024-12-28 01:23:49,008: Snapshot:1	Epoch:11	Loss:107.819	translation_Loss:105.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.592                                                   	MRR:6.56	Hits@10:16.48	Best:6.56
2024-12-28 01:24:00,364: Snapshot:1	Epoch:12	Loss:104.605	translation_Loss:101.707	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.898                                                   	MRR:7.0	Hits@10:17.45	Best:7.0
2024-12-28 01:24:11,716: Snapshot:1	Epoch:13	Loss:101.542	translation_Loss:98.34	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.201                                                   	MRR:7.41	Hits@10:18.32	Best:7.41
2024-12-28 01:24:23,592: Snapshot:1	Epoch:14	Loss:98.605	translation_Loss:95.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.505                                                   	MRR:7.77	Hits@10:19.12	Best:7.77
2024-12-28 01:24:34,919: Snapshot:1	Epoch:15	Loss:95.682	translation_Loss:91.874	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.808                                                   	MRR:8.18	Hits@10:19.93	Best:8.18
2024-12-28 01:24:46,295: Snapshot:1	Epoch:16	Loss:92.944	translation_Loss:88.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.108                                                   	MRR:8.61	Hits@10:20.71	Best:8.61
2024-12-28 01:24:57,670: Snapshot:1	Epoch:17	Loss:90.255	translation_Loss:85.848	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.407                                                   	MRR:8.99	Hits@10:21.42	Best:8.99
2024-12-28 01:25:08,959: Snapshot:1	Epoch:18	Loss:87.66	translation_Loss:82.957	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.703                                                   	MRR:9.41	Hits@10:22.17	Best:9.41
2024-12-28 01:25:20,272: Snapshot:1	Epoch:19	Loss:85.084	translation_Loss:80.09	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.993                                                   	MRR:9.8	Hits@10:22.94	Best:9.8
2024-12-28 01:25:31,592: Snapshot:1	Epoch:20	Loss:82.641	translation_Loss:77.361	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.28                                                   	MRR:10.21	Hits@10:23.75	Best:10.21
2024-12-28 01:25:42,930: Snapshot:1	Epoch:21	Loss:80.233	translation_Loss:74.672	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.561                                                   	MRR:10.65	Hits@10:24.39	Best:10.65
2024-12-28 01:25:54,233: Snapshot:1	Epoch:22	Loss:77.829	translation_Loss:71.991	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.838                                                   	MRR:11.07	Hits@10:25.11	Best:11.07
2024-12-28 01:26:05,475: Snapshot:1	Epoch:23	Loss:75.562	translation_Loss:69.452	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.111                                                   	MRR:11.45	Hits@10:25.72	Best:11.45
2024-12-28 01:26:16,697: Snapshot:1	Epoch:24	Loss:73.387	translation_Loss:67.01	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.377                                                   	MRR:11.79	Hits@10:26.34	Best:11.79
2024-12-28 01:26:27,876: Snapshot:1	Epoch:25	Loss:71.2	translation_Loss:64.56	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.639                                                   	MRR:12.11	Hits@10:26.96	Best:12.11
2024-12-28 01:26:39,294: Snapshot:1	Epoch:26	Loss:69.105	translation_Loss:62.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.898                                                   	MRR:12.42	Hits@10:27.47	Best:12.42
2024-12-28 01:26:50,618: Snapshot:1	Epoch:27	Loss:67.079	translation_Loss:59.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.15                                                   	MRR:12.71	Hits@10:28.03	Best:12.71
2024-12-28 01:27:02,473: Snapshot:1	Epoch:28	Loss:65.122	translation_Loss:57.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.396                                                   	MRR:13.0	Hits@10:28.47	Best:13.0
2024-12-28 01:27:13,789: Snapshot:1	Epoch:29	Loss:63.112	translation_Loss:55.476	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.636                                                   	MRR:13.34	Hits@10:28.96	Best:13.34
2024-12-28 01:27:25,111: Snapshot:1	Epoch:30	Loss:61.285	translation_Loss:53.415	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.87                                                   	MRR:13.62	Hits@10:29.34	Best:13.62
2024-12-28 01:27:36,314: Snapshot:1	Epoch:31	Loss:59.413	translation_Loss:51.315	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.098                                                   	MRR:13.87	Hits@10:29.74	Best:13.87
2024-12-28 01:27:47,604: Snapshot:1	Epoch:32	Loss:57.581	translation_Loss:49.259	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.322                                                   	MRR:14.18	Hits@10:30.11	Best:14.18
2024-12-28 01:27:58,844: Snapshot:1	Epoch:33	Loss:55.851	translation_Loss:47.314	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.537                                                   	MRR:14.45	Hits@10:30.49	Best:14.45
2024-12-28 01:28:10,023: Snapshot:1	Epoch:34	Loss:54.221	translation_Loss:45.476	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.745                                                   	MRR:14.72	Hits@10:30.76	Best:14.72
2024-12-28 01:28:21,337: Snapshot:1	Epoch:35	Loss:52.62	translation_Loss:43.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.946                                                   	MRR:15.01	Hits@10:31.11	Best:15.01
2024-12-28 01:28:32,554: Snapshot:1	Epoch:36	Loss:51.154	translation_Loss:42.014	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.14                                                   	MRR:15.21	Hits@10:31.4	Best:15.21
2024-12-28 01:28:43,962: Snapshot:1	Epoch:37	Loss:49.561	translation_Loss:40.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.326                                                   	MRR:15.45	Hits@10:31.7	Best:15.45
2024-12-28 01:28:55,449: Snapshot:1	Epoch:38	Loss:48.239	translation_Loss:38.734	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.505                                                   	MRR:15.69	Hits@10:31.98	Best:15.69
2024-12-28 01:29:06,691: Snapshot:1	Epoch:39	Loss:46.766	translation_Loss:37.088	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.678                                                   	MRR:15.87	Hits@10:32.23	Best:15.87
2024-12-28 01:29:18,007: Snapshot:1	Epoch:40	Loss:45.513	translation_Loss:35.671	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.841                                                   	MRR:16.03	Hits@10:32.43	Best:16.03
2024-12-28 01:29:29,909: Snapshot:1	Epoch:41	Loss:44.312	translation_Loss:34.313	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.999                                                   	MRR:16.28	Hits@10:32.65	Best:16.28
2024-12-28 01:29:41,244: Snapshot:1	Epoch:42	Loss:43.114	translation_Loss:32.967	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.148                                                   	MRR:16.45	Hits@10:32.87	Best:16.45
2024-12-28 01:29:52,455: Snapshot:1	Epoch:43	Loss:41.992	translation_Loss:31.704	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.288                                                   	MRR:16.69	Hits@10:33.11	Best:16.69
2024-12-28 01:30:04,081: Snapshot:1	Epoch:44	Loss:40.874	translation_Loss:30.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.421                                                   	MRR:16.82	Hits@10:33.33	Best:16.82
2024-12-28 01:30:15,623: Snapshot:1	Epoch:45	Loss:39.879	translation_Loss:29.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.545                                                   	MRR:16.92	Hits@10:33.46	Best:16.92
2024-12-28 01:30:26,914: Snapshot:1	Epoch:46	Loss:38.964	translation_Loss:28.301	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.663                                                   	MRR:17.13	Hits@10:33.64	Best:17.13
2024-12-28 01:30:38,139: Snapshot:1	Epoch:47	Loss:37.934	translation_Loss:27.16	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.774                                                   	MRR:17.21	Hits@10:33.75	Best:17.21
2024-12-28 01:30:49,558: Snapshot:1	Epoch:48	Loss:37.053	translation_Loss:26.179	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.874                                                   	MRR:17.26	Hits@10:33.88	Best:17.26
2024-12-28 01:31:00,875: Snapshot:1	Epoch:49	Loss:36.263	translation_Loss:25.295	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.969                                                   	MRR:17.33	Hits@10:34.02	Best:17.33
2024-12-28 01:31:12,258: Snapshot:1	Epoch:50	Loss:35.544	translation_Loss:24.49	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.055                                                   	MRR:17.45	Hits@10:34.12	Best:17.45
2024-12-28 01:31:23,701: Snapshot:1	Epoch:51	Loss:34.686	translation_Loss:23.551	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.135                                                   	MRR:17.51	Hits@10:34.21	Best:17.51
2024-12-28 01:31:34,940: Snapshot:1	Epoch:52	Loss:34.015	translation_Loss:22.809	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.206                                                   	MRR:17.62	Hits@10:34.31	Best:17.62
2024-12-28 01:31:46,317: Snapshot:1	Epoch:53	Loss:33.316	translation_Loss:22.046	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.27                                                   	MRR:17.64	Hits@10:34.42	Best:17.64
2024-12-28 01:31:58,304: Snapshot:1	Epoch:54	Loss:32.691	translation_Loss:21.363	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.328                                                   	MRR:17.7	Hits@10:34.54	Best:17.7
2024-12-28 01:32:09,553: Snapshot:1	Epoch:55	Loss:32.057	translation_Loss:20.677	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.38                                                   	MRR:17.76	Hits@10:34.62	Best:17.76
2024-12-28 01:32:20,960: Snapshot:1	Epoch:56	Loss:31.43	translation_Loss:20.002	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.427                                                   	MRR:17.85	Hits@10:34.63	Best:17.85
2024-12-28 01:32:32,190: Snapshot:1	Epoch:57	Loss:30.937	translation_Loss:19.468	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.469                                                   	MRR:17.88	Hits@10:34.71	Best:17.88
2024-12-28 01:32:43,412: Snapshot:1	Epoch:58	Loss:30.38	translation_Loss:18.873	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.506                                                   	MRR:17.87	Hits@10:34.77	Best:17.88
2024-12-28 01:32:54,672: Snapshot:1	Epoch:59	Loss:29.895	translation_Loss:18.359	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.536                                                   	MRR:17.91	Hits@10:34.76	Best:17.91
2024-12-28 01:33:05,905: Snapshot:1	Epoch:60	Loss:29.428	translation_Loss:17.867	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.561                                                   	MRR:17.98	Hits@10:34.8	Best:17.98
2024-12-28 01:33:17,169: Snapshot:1	Epoch:61	Loss:28.945	translation_Loss:17.361	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.584                                                   	MRR:17.96	Hits@10:34.82	Best:17.98
2024-12-28 01:33:28,526: Snapshot:1	Epoch:62	Loss:28.471	translation_Loss:16.869	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.602                                                   	MRR:18.02	Hits@10:34.84	Best:18.02
2024-12-28 01:33:39,993: Snapshot:1	Epoch:63	Loss:28.052	translation_Loss:16.438	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.614                                                   	MRR:18.07	Hits@10:34.92	Best:18.07
2024-12-28 01:33:51,402: Snapshot:1	Epoch:64	Loss:27.739	translation_Loss:16.116	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.623                                                   	MRR:18.09	Hits@10:34.95	Best:18.09
2024-12-28 01:34:02,785: Snapshot:1	Epoch:65	Loss:27.364	translation_Loss:15.733	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.631                                                   	MRR:18.11	Hits@10:34.89	Best:18.11
2024-12-28 01:34:14,180: Snapshot:1	Epoch:66	Loss:26.986	translation_Loss:15.353	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.632                                                   	MRR:18.16	Hits@10:35.01	Best:18.16
2024-12-28 01:34:26,087: Snapshot:1	Epoch:67	Loss:26.597	translation_Loss:14.966	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.631                                                   	MRR:18.17	Hits@10:35.03	Best:18.17
2024-12-28 01:34:37,253: Snapshot:1	Epoch:68	Loss:26.24	translation_Loss:14.615	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.625                                                   	MRR:18.17	Hits@10:35.01	Best:18.17
2024-12-28 01:34:48,521: Snapshot:1	Epoch:69	Loss:25.957	translation_Loss:14.343	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.614                                                   	MRR:18.13	Hits@10:35.06	Best:18.17
2024-12-28 01:34:59,710: Snapshot:1	Epoch:70	Loss:25.653	translation_Loss:14.051	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.602                                                   	MRR:18.17	Hits@10:35.11	Best:18.17
2024-12-28 01:35:10,987: Snapshot:1	Epoch:71	Loss:25.362	translation_Loss:13.772	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.59                                                   	MRR:18.16	Hits@10:35.03	Best:18.17
2024-12-28 01:35:22,232: Snapshot:1	Epoch:72	Loss:25.079	translation_Loss:13.505	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.574                                                   	MRR:18.19	Hits@10:35.07	Best:18.19
2024-12-28 01:35:33,453: Snapshot:1	Epoch:73	Loss:24.761	translation_Loss:13.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.554                                                   	MRR:18.15	Hits@10:35.01	Best:18.19
2024-12-28 01:35:44,652: Snapshot:1	Epoch:74	Loss:24.482	translation_Loss:12.946	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.535                                                   	MRR:18.19	Hits@10:35.02	Best:18.19
2024-12-28 01:35:55,827: Snapshot:1	Epoch:75	Loss:24.298	translation_Loss:12.785	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.513                                                   	MRR:18.14	Hits@10:35.07	Best:18.19
2024-12-28 01:36:06,950: Snapshot:1	Epoch:76	Loss:24.041	translation_Loss:12.55	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.491                                                   	MRR:18.15	Hits@10:35.03	Best:18.19
2024-12-28 01:36:18,092: Early Stopping! Snapshot: 1 Epoch: 77 Best Results: 18.19
2024-12-28 01:36:18,093: Start to training tokens! Snapshot: 1 Epoch: 77 Loss:23.806 MRR:18.13 Best Results: 18.19
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 01:36:18,093: Snapshot:1	Epoch:77	Loss:23.806	translation_Loss:12.338	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:11.468                                                   	MRR:18.13	Hits@10:35.08	Best:18.19
2024-12-28 01:36:28,879: Snapshot:1	Epoch:78	Loss:115.149	translation_Loss:111.143	multi_layer_Loss:4.006	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.13	Hits@10:35.08	Best:18.19
2024-12-28 01:36:39,685: End of token training: 1 Epoch: 79 Loss:114.226 MRR:18.13 Best Results: 18.19
2024-12-28 01:36:39,685: Snapshot:1	Epoch:79	Loss:114.226	translation_Loss:111.158	multi_layer_Loss:3.068	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:18.13	Hits@10:35.08	Best:18.19
2024-12-28 01:36:40,070: => loading checkpoint './checkpoint/RELATIONrelation_0.00001_512_5000/1model_best.tar'
2024-12-28 01:36:50,081: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2164 | 0.1081 | 0.2765 | 0.3428 |  0.4182 |
|     1      | 0.1831 | 0.0957 | 0.219  | 0.2782 |  0.3494 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 01:37:18,583: Snapshot:2	Epoch:0	Loss:109.795	translation_Loss:109.779	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.016                                                   	MRR:0.3	Hits@10:0.65	Best:0.3
2024-12-28 01:37:27,061: Snapshot:2	Epoch:1	Loss:103.054	translation_Loss:102.977	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.077                                                   	MRR:0.37	Hits@10:0.78	Best:0.37
2024-12-28 01:37:35,401: Snapshot:2	Epoch:2	Loss:96.167	translation_Loss:95.981	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.186                                                   	MRR:0.53	Hits@10:1.2	Best:0.53
2024-12-28 01:37:43,902: Snapshot:2	Epoch:3	Loss:89.326	translation_Loss:88.985	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.341                                                   	MRR:0.96	Hits@10:2.4	Best:0.96
2024-12-28 01:37:52,285: Snapshot:2	Epoch:4	Loss:82.534	translation_Loss:82.0	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.534                                                   	MRR:1.69	Hits@10:4.04	Best:1.69
2024-12-28 01:38:00,722: Snapshot:2	Epoch:5	Loss:75.888	translation_Loss:75.127	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.761                                                   	MRR:2.49	Hits@10:6.0	Best:2.49
2024-12-28 01:38:09,116: Snapshot:2	Epoch:6	Loss:69.674	translation_Loss:68.659	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.016                                                   	MRR:3.35	Hits@10:8.13	Best:3.35
2024-12-28 01:38:17,532: Snapshot:2	Epoch:7	Loss:63.844	translation_Loss:62.554	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.29                                                   	MRR:4.52	Hits@10:10.97	Best:4.52
2024-12-28 01:38:25,985: Snapshot:2	Epoch:8	Loss:58.478	translation_Loss:56.901	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.577                                                   	MRR:6.02	Hits@10:15.06	Best:6.02
2024-12-28 01:38:34,461: Snapshot:2	Epoch:9	Loss:53.644	translation_Loss:51.775	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.869                                                   	MRR:7.65	Hits@10:19.11	Best:7.65
2024-12-28 01:38:42,979: Snapshot:2	Epoch:10	Loss:49.319	translation_Loss:47.161	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.158                                                   	MRR:9.1	Hits@10:21.71	Best:9.1
2024-12-28 01:38:51,387: Snapshot:2	Epoch:11	Loss:45.747	translation_Loss:43.314	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.433                                                   	MRR:10.39	Hits@10:24.17	Best:10.39
2024-12-28 01:38:59,797: Snapshot:2	Epoch:12	Loss:42.753	translation_Loss:40.068	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.685                                                   	MRR:11.68	Hits@10:26.44	Best:11.68
2024-12-28 01:39:08,263: Snapshot:2	Epoch:13	Loss:40.259	translation_Loss:37.344	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.915                                                   	MRR:12.68	Hits@10:28.23	Best:12.68
2024-12-28 01:39:16,772: Snapshot:2	Epoch:14	Loss:38.151	translation_Loss:35.029	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.122                                                   	MRR:13.54	Hits@10:29.65	Best:13.54
2024-12-28 01:39:25,775: Snapshot:2	Epoch:15	Loss:36.225	translation_Loss:32.915	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.31                                                   	MRR:14.22	Hits@10:30.78	Best:14.22
2024-12-28 01:39:34,195: Snapshot:2	Epoch:16	Loss:34.572	translation_Loss:31.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.483                                                   	MRR:14.8	Hits@10:31.78	Best:14.8
2024-12-28 01:39:42,576: Snapshot:2	Epoch:17	Loss:33.076	translation_Loss:29.433	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.643                                                   	MRR:15.5	Hits@10:32.76	Best:15.5
2024-12-28 01:39:50,940: Snapshot:2	Epoch:18	Loss:31.744	translation_Loss:27.953	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.791                                                   	MRR:16.11	Hits@10:33.53	Best:16.11
2024-12-28 01:39:59,429: Snapshot:2	Epoch:19	Loss:30.558	translation_Loss:26.628	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.93                                                   	MRR:16.55	Hits@10:34.25	Best:16.55
2024-12-28 01:40:08,201: Snapshot:2	Epoch:20	Loss:29.441	translation_Loss:25.381	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.06                                                   	MRR:16.98	Hits@10:34.72	Best:16.98
2024-12-28 01:40:16,637: Snapshot:2	Epoch:21	Loss:28.4	translation_Loss:24.215	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.185                                                   	MRR:17.46	Hits@10:35.34	Best:17.46
2024-12-28 01:40:24,971: Snapshot:2	Epoch:22	Loss:27.385	translation_Loss:23.082	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.303                                                   	MRR:17.85	Hits@10:35.89	Best:17.85
2024-12-28 01:40:33,455: Snapshot:2	Epoch:23	Loss:26.499	translation_Loss:22.084	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.415                                                   	MRR:18.14	Hits@10:36.31	Best:18.14
2024-12-28 01:40:41,899: Snapshot:2	Epoch:24	Loss:25.619	translation_Loss:21.099	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.52                                                   	MRR:18.47	Hits@10:36.76	Best:18.47
2024-12-28 01:40:50,296: Snapshot:2	Epoch:25	Loss:24.847	translation_Loss:20.227	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.621                                                   	MRR:18.82	Hits@10:37.16	Best:18.82
2024-12-28 01:40:58,759: Snapshot:2	Epoch:26	Loss:24.114	translation_Loss:19.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.716                                                   	MRR:19.12	Hits@10:37.53	Best:19.12
2024-12-28 01:41:07,113: Snapshot:2	Epoch:27	Loss:23.441	translation_Loss:18.634	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.807                                                   	MRR:19.41	Hits@10:37.72	Best:19.41
2024-12-28 01:41:15,516: Snapshot:2	Epoch:28	Loss:22.806	translation_Loss:17.911	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.895                                                   	MRR:19.73	Hits@10:38.12	Best:19.73
2024-12-28 01:41:24,000: Snapshot:2	Epoch:29	Loss:22.168	translation_Loss:17.191	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.978                                                   	MRR:19.96	Hits@10:38.48	Best:19.96
2024-12-28 01:41:32,461: Snapshot:2	Epoch:30	Loss:21.583	translation_Loss:16.526	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.057                                                   	MRR:20.13	Hits@10:38.6	Best:20.13
2024-12-28 01:41:40,772: Snapshot:2	Epoch:31	Loss:21.038	translation_Loss:15.907	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.13                                                   	MRR:20.4	Hits@10:38.83	Best:20.4
2024-12-28 01:41:49,234: Snapshot:2	Epoch:32	Loss:20.552	translation_Loss:15.35	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.201                                                   	MRR:20.6	Hits@10:39.23	Best:20.6
2024-12-28 01:41:58,147: Snapshot:2	Epoch:33	Loss:20.007	translation_Loss:14.739	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.267                                                   	MRR:20.71	Hits@10:39.42	Best:20.71
2024-12-28 01:42:06,551: Snapshot:2	Epoch:34	Loss:19.56	translation_Loss:14.232	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.328                                                   	MRR:20.84	Hits@10:39.68	Best:20.84
2024-12-28 01:42:14,959: Snapshot:2	Epoch:35	Loss:19.07	translation_Loss:13.686	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.384                                                   	MRR:21.13	Hits@10:39.89	Best:21.13
2024-12-28 01:42:23,336: Snapshot:2	Epoch:36	Loss:18.658	translation_Loss:13.221	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.437                                                   	MRR:21.26	Hits@10:40.13	Best:21.26
2024-12-28 01:42:31,752: Snapshot:2	Epoch:37	Loss:18.245	translation_Loss:12.758	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.488                                                   	MRR:21.28	Hits@10:40.31	Best:21.28
2024-12-28 01:42:40,273: Snapshot:2	Epoch:38	Loss:17.867	translation_Loss:12.332	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.535                                                   	MRR:21.54	Hits@10:40.46	Best:21.54
2024-12-28 01:42:48,715: Snapshot:2	Epoch:39	Loss:17.492	translation_Loss:11.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.578                                                   	MRR:21.63	Hits@10:40.69	Best:21.63
2024-12-28 01:42:57,196: Snapshot:2	Epoch:40	Loss:17.144	translation_Loss:11.526	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.618                                                   	MRR:21.71	Hits@10:40.83	Best:21.71
2024-12-28 01:43:05,549: Snapshot:2	Epoch:41	Loss:16.792	translation_Loss:11.138	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.653                                                   	MRR:21.76	Hits@10:40.86	Best:21.76
2024-12-28 01:43:13,927: Snapshot:2	Epoch:42	Loss:16.514	translation_Loss:10.831	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.683                                                   	MRR:21.81	Hits@10:41.02	Best:21.81
2024-12-28 01:43:22,400: Snapshot:2	Epoch:43	Loss:16.183	translation_Loss:10.471	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.712                                                   	MRR:21.91	Hits@10:40.95	Best:21.91
2024-12-28 01:43:30,803: Snapshot:2	Epoch:44	Loss:15.892	translation_Loss:10.155	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.737                                                   	MRR:22.02	Hits@10:41.23	Best:22.02
2024-12-28 01:43:39,210: Snapshot:2	Epoch:45	Loss:15.64	translation_Loss:9.88	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.76                                                   	MRR:22.05	Hits@10:41.25	Best:22.05
2024-12-28 01:43:47,682: Snapshot:2	Epoch:46	Loss:15.331	translation_Loss:9.55	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.781                                                   	MRR:22.12	Hits@10:41.33	Best:22.12
2024-12-28 01:43:56,153: Snapshot:2	Epoch:47	Loss:15.114	translation_Loss:9.316	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.798                                                   	MRR:22.23	Hits@10:41.47	Best:22.23
2024-12-28 01:44:04,503: Snapshot:2	Epoch:48	Loss:14.885	translation_Loss:9.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.813                                                   	MRR:22.39	Hits@10:41.64	Best:22.39
2024-12-28 01:44:12,939: Snapshot:2	Epoch:49	Loss:14.676	translation_Loss:8.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.825                                                   	MRR:22.44	Hits@10:41.6	Best:22.44
2024-12-28 01:44:21,370: Snapshot:2	Epoch:50	Loss:14.475	translation_Loss:8.64	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.835                                                   	MRR:22.55	Hits@10:41.57	Best:22.55
2024-12-28 01:44:29,786: Snapshot:2	Epoch:51	Loss:14.254	translation_Loss:8.412	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.842                                                   	MRR:22.5	Hits@10:41.76	Best:22.55
2024-12-28 01:44:38,749: Snapshot:2	Epoch:52	Loss:14.051	translation_Loss:8.204	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.847                                                   	MRR:22.64	Hits@10:41.78	Best:22.64
2024-12-28 01:44:47,259: Snapshot:2	Epoch:53	Loss:13.843	translation_Loss:7.993	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.85                                                   	MRR:22.68	Hits@10:41.83	Best:22.68
2024-12-28 01:44:55,781: Snapshot:2	Epoch:54	Loss:13.687	translation_Loss:7.835	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.852                                                   	MRR:22.71	Hits@10:41.88	Best:22.71
2024-12-28 01:45:04,272: Snapshot:2	Epoch:55	Loss:13.443	translation_Loss:7.592	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.851                                                   	MRR:22.78	Hits@10:41.99	Best:22.78
2024-12-28 01:45:12,735: Snapshot:2	Epoch:56	Loss:13.315	translation_Loss:7.467	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.847                                                   	MRR:22.84	Hits@10:42.11	Best:22.84
2024-12-28 01:45:21,152: Snapshot:2	Epoch:57	Loss:13.166	translation_Loss:7.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.844                                                   	MRR:22.85	Hits@10:42.04	Best:22.85
2024-12-28 01:45:29,629: Snapshot:2	Epoch:58	Loss:13.005	translation_Loss:7.164	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.842                                                   	MRR:22.91	Hits@10:42.0	Best:22.91
2024-12-28 01:45:38,005: Snapshot:2	Epoch:59	Loss:12.854	translation_Loss:7.016	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.838                                                   	MRR:22.96	Hits@10:42.15	Best:22.96
2024-12-28 01:45:46,442: Snapshot:2	Epoch:60	Loss:12.683	translation_Loss:6.85	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.833                                                   	MRR:22.91	Hits@10:42.16	Best:22.96
2024-12-28 01:45:54,865: Snapshot:2	Epoch:61	Loss:12.491	translation_Loss:6.666	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.825                                                   	MRR:22.86	Hits@10:42.13	Best:22.96
2024-12-28 01:46:03,143: Snapshot:2	Epoch:62	Loss:12.389	translation_Loss:6.574	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.814                                                   	MRR:22.89	Hits@10:42.02	Best:22.96
2024-12-28 01:46:11,446: Snapshot:2	Epoch:63	Loss:12.238	translation_Loss:6.434	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.805                                                   	MRR:22.95	Hits@10:42.17	Best:22.96
2024-12-28 01:46:19,883: Snapshot:2	Epoch:64	Loss:12.07	translation_Loss:6.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.794                                                   	MRR:23.01	Hits@10:42.17	Best:23.01
2024-12-28 01:46:28,402: Snapshot:2	Epoch:65	Loss:11.984	translation_Loss:6.204	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.78                                                   	MRR:23.09	Hits@10:42.24	Best:23.09
2024-12-28 01:46:36,803: Snapshot:2	Epoch:66	Loss:11.851	translation_Loss:6.082	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.768                                                   	MRR:23.0	Hits@10:42.28	Best:23.09
2024-12-28 01:46:45,220: Snapshot:2	Epoch:67	Loss:11.742	translation_Loss:5.985	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.757                                                   	MRR:23.03	Hits@10:42.23	Best:23.09
2024-12-28 01:46:53,732: Snapshot:2	Epoch:68	Loss:11.605	translation_Loss:5.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.742                                                   	MRR:22.98	Hits@10:42.36	Best:23.09
2024-12-28 01:47:02,101: Snapshot:2	Epoch:69	Loss:11.47	translation_Loss:5.742	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.727                                                   	MRR:22.98	Hits@10:42.29	Best:23.09
2024-12-28 01:47:10,958: Early Stopping! Snapshot: 2 Epoch: 70 Best Results: 23.09
2024-12-28 01:47:10,958: Start to training tokens! Snapshot: 2 Epoch: 70 Loss:11.318 MRR:23.09 Best Results: 23.09
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 01:47:10,958: Snapshot:2	Epoch:70	Loss:11.318	translation_Loss:5.605	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.713                                                   	MRR:23.09	Hits@10:42.39	Best:23.09
2024-12-28 01:47:19,062: Snapshot:2	Epoch:71	Loss:69.147	translation_Loss:66.176	multi_layer_Loss:2.971	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.09	Hits@10:42.39	Best:23.09
2024-12-28 01:47:27,215: End of token training: 2 Epoch: 72 Loss:68.796 MRR:23.09 Best Results: 23.09
2024-12-28 01:47:27,216: Snapshot:2	Epoch:72	Loss:68.796	translation_Loss:66.261	multi_layer_Loss:2.534	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:23.09	Hits@10:42.39	Best:23.09
2024-12-28 01:47:27,530: => loading checkpoint './checkpoint/RELATIONrelation_0.00001_512_5000/2model_best.tar'
2024-12-28 01:47:40,776: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1836 | 0.0911 | 0.2324 | 0.2902 |  0.3576 |
|     1      | 0.1502 | 0.0748 | 0.1795 |  0.23  |  0.2931 |
|     2      | 0.2289 | 0.1358 | 0.2605 | 0.324  |  0.4153 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 01:47:56,441: Snapshot:3	Epoch:0	Loss:42.415	translation_Loss:42.412	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.002                                                   	MRR:0.88	Hits@10:2.13	Best:0.88
2024-12-28 01:48:00,333: Snapshot:3	Epoch:1	Loss:41.042	translation_Loss:41.033	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.009                                                   	MRR:0.99	Hits@10:2.34	Best:0.99
2024-12-28 01:48:04,357: Snapshot:3	Epoch:2	Loss:39.742	translation_Loss:39.722	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.02                                                   	MRR:1.31	Hits@10:3.41	Best:1.31
2024-12-28 01:48:08,274: Snapshot:3	Epoch:3	Loss:38.394	translation_Loss:38.359	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.035                                                   	MRR:2.09	Hits@10:5.64	Best:2.09
2024-12-28 01:48:12,234: Snapshot:3	Epoch:4	Loss:37.13	translation_Loss:37.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.054                                                   	MRR:2.8	Hits@10:6.72	Best:2.8
2024-12-28 01:48:16,162: Snapshot:3	Epoch:5	Loss:35.916	translation_Loss:35.84	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.076                                                   	MRR:3.26	Hits@10:7.49	Best:3.26
2024-12-28 01:48:20,059: Snapshot:3	Epoch:6	Loss:34.734	translation_Loss:34.632	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.102                                                   	MRR:3.71	Hits@10:8.42	Best:3.71
2024-12-28 01:48:23,987: Snapshot:3	Epoch:7	Loss:33.605	translation_Loss:33.475	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.13                                                   	MRR:4.18	Hits@10:9.41	Best:4.18
2024-12-28 01:48:27,965: Snapshot:3	Epoch:8	Loss:32.587	translation_Loss:32.427	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.161                                                   	MRR:4.65	Hits@10:10.62	Best:4.65
2024-12-28 01:48:31,892: Snapshot:3	Epoch:9	Loss:31.578	translation_Loss:31.384	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.193                                                   	MRR:5.2	Hits@10:11.68	Best:5.2
2024-12-28 01:48:35,767: Snapshot:3	Epoch:10	Loss:30.626	translation_Loss:30.398	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.228                                                   	MRR:5.81	Hits@10:12.66	Best:5.81
2024-12-28 01:48:40,262: Snapshot:3	Epoch:11	Loss:29.668	translation_Loss:29.404	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.264                                                   	MRR:6.38	Hits@10:13.66	Best:6.38
2024-12-28 01:48:44,197: Snapshot:3	Epoch:12	Loss:28.817	translation_Loss:28.516	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.301                                                   	MRR:6.88	Hits@10:14.82	Best:6.88
2024-12-28 01:48:48,080: Snapshot:3	Epoch:13	Loss:27.949	translation_Loss:27.61	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.339                                                   	MRR:7.42	Hits@10:15.79	Best:7.42
2024-12-28 01:48:52,014: Snapshot:3	Epoch:14	Loss:27.094	translation_Loss:26.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.379                                                   	MRR:7.96	Hits@10:16.97	Best:7.96
2024-12-28 01:48:55,989: Snapshot:3	Epoch:15	Loss:26.271	translation_Loss:25.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.42                                                   	MRR:8.53	Hits@10:18.18	Best:8.53
2024-12-28 01:48:59,954: Snapshot:3	Epoch:16	Loss:25.508	translation_Loss:25.047	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.461                                                   	MRR:9.1	Hits@10:19.73	Best:9.1
2024-12-28 01:49:03,924: Snapshot:3	Epoch:17	Loss:24.748	translation_Loss:24.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.504                                                   	MRR:9.74	Hits@10:21.35	Best:9.74
2024-12-28 01:49:07,903: Snapshot:3	Epoch:18	Loss:23.981	translation_Loss:23.433	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.547                                                   	MRR:10.34	Hits@10:22.77	Best:10.34
2024-12-28 01:49:11,840: Snapshot:3	Epoch:19	Loss:23.245	translation_Loss:22.654	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.591                                                   	MRR:10.99	Hits@10:24.12	Best:10.99
2024-12-28 01:49:15,849: Snapshot:3	Epoch:20	Loss:22.567	translation_Loss:21.931	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.636                                                   	MRR:11.65	Hits@10:25.84	Best:11.65
2024-12-28 01:49:19,822: Snapshot:3	Epoch:21	Loss:21.849	translation_Loss:21.168	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.681                                                   	MRR:12.36	Hits@10:27.39	Best:12.36
2024-12-28 01:49:23,770: Snapshot:3	Epoch:22	Loss:21.179	translation_Loss:20.452	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.727                                                   	MRR:13.03	Hits@10:28.85	Best:13.03
2024-12-28 01:49:27,795: Snapshot:3	Epoch:23	Loss:20.522	translation_Loss:19.749	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.773                                                   	MRR:13.67	Hits@10:30.2	Best:13.67
2024-12-28 01:49:31,705: Snapshot:3	Epoch:24	Loss:19.859	translation_Loss:19.04	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.82                                                   	MRR:14.3	Hits@10:31.33	Best:14.3
2024-12-28 01:49:35,643: Snapshot:3	Epoch:25	Loss:19.259	translation_Loss:18.392	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.867                                                   	MRR:14.92	Hits@10:32.41	Best:14.92
2024-12-28 01:49:39,561: Snapshot:3	Epoch:26	Loss:18.725	translation_Loss:17.81	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.914                                                   	MRR:15.48	Hits@10:33.41	Best:15.48
2024-12-28 01:49:43,489: Snapshot:3	Epoch:27	Loss:18.079	translation_Loss:17.118	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.962                                                   	MRR:16.0	Hits@10:34.47	Best:16.0
2024-12-28 01:49:47,387: Snapshot:3	Epoch:28	Loss:17.537	translation_Loss:16.528	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.009                                                   	MRR:16.51	Hits@10:35.18	Best:16.51
2024-12-28 01:49:51,248: Snapshot:3	Epoch:29	Loss:16.959	translation_Loss:15.903	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.057                                                   	MRR:16.92	Hits@10:35.94	Best:16.92
2024-12-28 01:49:55,204: Snapshot:3	Epoch:30	Loss:16.441	translation_Loss:15.337	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.104                                                   	MRR:17.39	Hits@10:36.6	Best:17.39
2024-12-28 01:49:59,123: Snapshot:3	Epoch:31	Loss:15.921	translation_Loss:14.77	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.151                                                   	MRR:17.77	Hits@10:37.17	Best:17.77
2024-12-28 01:50:03,059: Snapshot:3	Epoch:32	Loss:15.407	translation_Loss:14.208	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.198                                                   	MRR:18.15	Hits@10:37.71	Best:18.15
2024-12-28 01:50:07,007: Snapshot:3	Epoch:33	Loss:14.925	translation_Loss:13.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.245                                                   	MRR:18.51	Hits@10:38.34	Best:18.51
2024-12-28 01:50:10,990: Snapshot:3	Epoch:34	Loss:14.469	translation_Loss:13.178	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.291                                                   	MRR:18.95	Hits@10:38.92	Best:18.95
2024-12-28 01:50:14,905: Snapshot:3	Epoch:35	Loss:14.021	translation_Loss:12.685	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.337                                                   	MRR:19.32	Hits@10:39.43	Best:19.32
2024-12-28 01:50:18,818: Snapshot:3	Epoch:36	Loss:13.58	translation_Loss:12.199	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.381                                                   	MRR:19.68	Hits@10:39.84	Best:19.68
2024-12-28 01:50:22,716: Snapshot:3	Epoch:37	Loss:13.206	translation_Loss:11.78	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.425                                                   	MRR:20.1	Hits@10:40.34	Best:20.1
2024-12-28 01:50:26,667: Snapshot:3	Epoch:38	Loss:12.777	translation_Loss:11.308	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.469                                                   	MRR:20.49	Hits@10:40.88	Best:20.49
2024-12-28 01:50:30,601: Snapshot:3	Epoch:39	Loss:12.401	translation_Loss:10.89	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.511                                                   	MRR:20.79	Hits@10:41.26	Best:20.79
2024-12-28 01:50:34,535: Snapshot:3	Epoch:40	Loss:12.041	translation_Loss:10.488	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.553                                                   	MRR:21.12	Hits@10:41.7	Best:21.12
2024-12-28 01:50:38,452: Snapshot:3	Epoch:41	Loss:11.674	translation_Loss:10.08	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.594                                                   	MRR:21.4	Hits@10:41.98	Best:21.4
2024-12-28 01:50:42,375: Snapshot:3	Epoch:42	Loss:11.334	translation_Loss:9.7	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.634                                                   	MRR:21.75	Hits@10:42.33	Best:21.75
2024-12-28 01:50:46,288: Snapshot:3	Epoch:43	Loss:10.99	translation_Loss:9.317	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.673                                                   	MRR:22.03	Hits@10:42.74	Best:22.03
2024-12-28 01:50:50,243: Snapshot:3	Epoch:44	Loss:10.683	translation_Loss:8.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.71                                                   	MRR:22.31	Hits@10:43.02	Best:22.31
2024-12-28 01:50:54,135: Snapshot:3	Epoch:45	Loss:10.399	translation_Loss:8.652	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.747                                                   	MRR:22.56	Hits@10:43.37	Best:22.56
2024-12-28 01:50:58,075: Snapshot:3	Epoch:46	Loss:10.044	translation_Loss:8.261	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.782                                                   	MRR:22.78	Hits@10:43.57	Best:22.78
2024-12-28 01:51:02,005: Snapshot:3	Epoch:47	Loss:9.79	translation_Loss:7.973	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.817                                                   	MRR:23.05	Hits@10:43.9	Best:23.05
2024-12-28 01:51:05,906: Snapshot:3	Epoch:48	Loss:9.528	translation_Loss:7.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.85                                                   	MRR:23.31	Hits@10:44.1	Best:23.31
2024-12-28 01:51:09,828: Snapshot:3	Epoch:49	Loss:9.261	translation_Loss:7.378	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.883                                                   	MRR:23.6	Hits@10:44.22	Best:23.6
2024-12-28 01:51:13,738: Snapshot:3	Epoch:50	Loss:9.025	translation_Loss:7.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.914                                                   	MRR:23.83	Hits@10:44.51	Best:23.83
2024-12-28 01:51:17,625: Snapshot:3	Epoch:51	Loss:8.784	translation_Loss:6.84	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.944                                                   	MRR:24.04	Hits@10:44.76	Best:24.04
2024-12-28 01:51:22,134: Snapshot:3	Epoch:52	Loss:8.526	translation_Loss:6.553	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.973                                                   	MRR:24.21	Hits@10:44.9	Best:24.21
2024-12-28 01:51:26,049: Snapshot:3	Epoch:53	Loss:8.307	translation_Loss:6.306	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.001                                                   	MRR:24.43	Hits@10:45.05	Best:24.43
2024-12-28 01:51:29,943: Snapshot:3	Epoch:54	Loss:8.098	translation_Loss:6.07	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.028                                                   	MRR:24.6	Hits@10:45.16	Best:24.6
2024-12-28 01:51:33,886: Snapshot:3	Epoch:55	Loss:7.873	translation_Loss:5.82	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.053                                                   	MRR:24.81	Hits@10:45.27	Best:24.81
2024-12-28 01:51:37,814: Snapshot:3	Epoch:56	Loss:7.703	translation_Loss:5.625	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.078                                                   	MRR:24.87	Hits@10:45.37	Best:24.87
2024-12-28 01:51:41,767: Snapshot:3	Epoch:57	Loss:7.5	translation_Loss:5.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.101                                                   	MRR:24.98	Hits@10:45.46	Best:24.98
2024-12-28 01:51:45,667: Snapshot:3	Epoch:58	Loss:7.34	translation_Loss:5.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.123                                                   	MRR:25.21	Hits@10:45.56	Best:25.21
2024-12-28 01:51:49,566: Snapshot:3	Epoch:59	Loss:7.15	translation_Loss:5.005	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.145                                                   	MRR:25.36	Hits@10:45.66	Best:25.36
2024-12-28 01:51:53,505: Snapshot:3	Epoch:60	Loss:7.001	translation_Loss:4.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.165                                                   	MRR:25.54	Hits@10:45.8	Best:25.54
2024-12-28 01:51:57,451: Snapshot:3	Epoch:61	Loss:6.864	translation_Loss:4.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.185                                                   	MRR:25.72	Hits@10:45.9	Best:25.72
2024-12-28 01:52:01,300: Snapshot:3	Epoch:62	Loss:6.7	translation_Loss:4.496	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.204                                                   	MRR:25.81	Hits@10:46.11	Best:25.81
2024-12-28 01:52:05,212: Snapshot:3	Epoch:63	Loss:6.507	translation_Loss:4.286	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.221                                                   	MRR:25.96	Hits@10:46.25	Best:25.96
2024-12-28 01:52:09,107: Snapshot:3	Epoch:64	Loss:6.375	translation_Loss:4.137	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.238                                                   	MRR:26.05	Hits@10:46.4	Best:26.05
2024-12-28 01:52:13,031: Snapshot:3	Epoch:65	Loss:6.242	translation_Loss:3.988	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.253                                                   	MRR:26.21	Hits@10:46.48	Best:26.21
2024-12-28 01:52:16,881: Snapshot:3	Epoch:66	Loss:6.134	translation_Loss:3.866	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.268                                                   	MRR:26.33	Hits@10:46.55	Best:26.33
2024-12-28 01:52:20,807: Snapshot:3	Epoch:67	Loss:6.004	translation_Loss:3.722	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.282                                                   	MRR:26.54	Hits@10:46.6	Best:26.54
2024-12-28 01:52:24,772: Snapshot:3	Epoch:68	Loss:5.892	translation_Loss:3.597	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.295                                                   	MRR:26.68	Hits@10:46.71	Best:26.68
2024-12-28 01:52:28,714: Snapshot:3	Epoch:69	Loss:5.756	translation_Loss:3.448	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.308                                                   	MRR:26.84	Hits@10:46.82	Best:26.84
2024-12-28 01:52:32,649: Snapshot:3	Epoch:70	Loss:5.642	translation_Loss:3.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.319                                                   	MRR:26.98	Hits@10:46.92	Best:26.98
2024-12-28 01:52:36,541: Snapshot:3	Epoch:71	Loss:5.535	translation_Loss:3.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.33                                                   	MRR:27.15	Hits@10:46.96	Best:27.15
2024-12-28 01:52:40,445: Snapshot:3	Epoch:72	Loss:5.436	translation_Loss:3.096	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.34                                                   	MRR:27.25	Hits@10:47.0	Best:27.25
2024-12-28 01:52:44,363: Snapshot:3	Epoch:73	Loss:5.346	translation_Loss:2.997	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.349                                                   	MRR:27.4	Hits@10:47.05	Best:27.4
2024-12-28 01:52:48,230: Snapshot:3	Epoch:74	Loss:5.264	translation_Loss:2.906	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.358                                                   	MRR:27.5	Hits@10:47.21	Best:27.5
2024-12-28 01:52:52,163: Snapshot:3	Epoch:75	Loss:5.167	translation_Loss:2.801	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.366                                                   	MRR:27.64	Hits@10:47.26	Best:27.64
2024-12-28 01:52:56,092: Snapshot:3	Epoch:76	Loss:5.083	translation_Loss:2.71	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.373                                                   	MRR:27.78	Hits@10:47.26	Best:27.78
2024-12-28 01:53:00,036: Snapshot:3	Epoch:77	Loss:5.01	translation_Loss:2.631	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.379                                                   	MRR:27.88	Hits@10:47.34	Best:27.88
2024-12-28 01:53:03,964: Snapshot:3	Epoch:78	Loss:4.907	translation_Loss:2.521	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.386                                                   	MRR:27.98	Hits@10:47.39	Best:27.98
2024-12-28 01:53:07,841: Snapshot:3	Epoch:79	Loss:4.829	translation_Loss:2.438	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.391                                                   	MRR:28.09	Hits@10:47.51	Best:28.09
2024-12-28 01:53:11,709: Snapshot:3	Epoch:80	Loss:4.766	translation_Loss:2.37	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.396                                                   	MRR:28.19	Hits@10:47.52	Best:28.19
2024-12-28 01:53:15,643: Snapshot:3	Epoch:81	Loss:4.71	translation_Loss:2.309	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.401                                                   	MRR:28.28	Hits@10:47.59	Best:28.28
2024-12-28 01:53:19,634: Snapshot:3	Epoch:82	Loss:4.641	translation_Loss:2.235	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.406                                                   	MRR:28.39	Hits@10:47.63	Best:28.39
2024-12-28 01:53:23,576: Snapshot:3	Epoch:83	Loss:4.562	translation_Loss:2.152	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.41                                                   	MRR:28.43	Hits@10:47.59	Best:28.43
2024-12-28 01:53:27,482: Snapshot:3	Epoch:84	Loss:4.519	translation_Loss:2.105	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.413                                                   	MRR:28.58	Hits@10:47.64	Best:28.58
2024-12-28 01:53:31,398: Snapshot:3	Epoch:85	Loss:4.451	translation_Loss:2.034	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.417                                                   	MRR:28.71	Hits@10:47.76	Best:28.71
2024-12-28 01:53:35,319: Snapshot:3	Epoch:86	Loss:4.388	translation_Loss:1.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.42                                                   	MRR:28.73	Hits@10:47.77	Best:28.73
2024-12-28 01:53:39,247: Snapshot:3	Epoch:87	Loss:4.332	translation_Loss:1.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.423                                                   	MRR:28.85	Hits@10:47.85	Best:28.85
2024-12-28 01:53:43,199: Snapshot:3	Epoch:88	Loss:4.286	translation_Loss:1.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.425                                                   	MRR:28.9	Hits@10:47.93	Best:28.9
2024-12-28 01:53:47,158: Snapshot:3	Epoch:89	Loss:4.223	translation_Loss:1.796	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.426                                                   	MRR:28.92	Hits@10:47.94	Best:28.92
2024-12-28 01:53:51,045: Snapshot:3	Epoch:90	Loss:4.168	translation_Loss:1.74	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.428                                                   	MRR:28.99	Hits@10:47.97	Best:28.99
2024-12-28 01:53:54,976: Snapshot:3	Epoch:91	Loss:4.139	translation_Loss:1.711	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.429                                                   	MRR:29.08	Hits@10:47.99	Best:29.08
2024-12-28 01:53:58,907: Snapshot:3	Epoch:92	Loss:4.071	translation_Loss:1.641	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.43                                                   	MRR:29.14	Hits@10:48.17	Best:29.14
2024-12-28 01:54:03,308: Snapshot:3	Epoch:93	Loss:4.032	translation_Loss:1.602	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.43                                                   	MRR:29.22	Hits@10:48.09	Best:29.22
2024-12-28 01:54:07,216: Snapshot:3	Epoch:94	Loss:4.002	translation_Loss:1.572	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.431                                                   	MRR:29.26	Hits@10:48.06	Best:29.26
2024-12-28 01:54:11,116: Snapshot:3	Epoch:95	Loss:3.937	translation_Loss:1.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.431                                                   	MRR:29.35	Hits@10:48.17	Best:29.35
2024-12-28 01:54:15,060: Snapshot:3	Epoch:96	Loss:3.91	translation_Loss:1.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.43                                                   	MRR:29.39	Hits@10:48.11	Best:29.39
2024-12-28 01:54:18,981: Snapshot:3	Epoch:97	Loss:3.878	translation_Loss:1.449	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.429                                                   	MRR:29.53	Hits@10:48.09	Best:29.53
2024-12-28 01:54:22,919: Snapshot:3	Epoch:98	Loss:3.827	translation_Loss:1.399	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.428                                                   	MRR:29.54	Hits@10:48.1	Best:29.54
2024-12-28 01:54:26,767: Snapshot:3	Epoch:99	Loss:3.784	translation_Loss:1.358	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.427                                                   	MRR:29.67	Hits@10:48.09	Best:29.67
2024-12-28 01:54:30,616: Snapshot:3	Epoch:100	Loss:3.761	translation_Loss:1.336	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.425                                                   	MRR:29.71	Hits@10:48.14	Best:29.71
2024-12-28 01:54:34,479: Snapshot:3	Epoch:101	Loss:3.73	translation_Loss:1.307	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.423                                                   	MRR:29.68	Hits@10:48.24	Best:29.71
2024-12-28 01:54:38,392: Snapshot:3	Epoch:102	Loss:3.7	translation_Loss:1.279	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.421                                                   	MRR:29.79	Hits@10:48.24	Best:29.79
2024-12-28 01:54:42,350: Snapshot:3	Epoch:103	Loss:3.661	translation_Loss:1.242	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.419                                                   	MRR:29.84	Hits@10:48.33	Best:29.84
2024-12-28 01:54:46,207: Snapshot:3	Epoch:104	Loss:3.636	translation_Loss:1.22	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.416                                                   	MRR:29.89	Hits@10:48.5	Best:29.89
2024-12-28 01:54:50,023: Snapshot:3	Epoch:105	Loss:3.626	translation_Loss:1.212	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.414                                                   	MRR:29.87	Hits@10:48.55	Best:29.89
2024-12-28 01:54:53,873: Snapshot:3	Epoch:106	Loss:3.569	translation_Loss:1.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.412                                                   	MRR:29.9	Hits@10:48.49	Best:29.9
2024-12-28 01:54:57,711: Snapshot:3	Epoch:107	Loss:3.524	translation_Loss:1.115	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.409                                                   	MRR:29.82	Hits@10:48.47	Best:29.9
2024-12-28 01:55:01,517: Snapshot:3	Epoch:108	Loss:3.496	translation_Loss:1.092	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.405                                                   	MRR:29.86	Hits@10:48.44	Best:29.9
2024-12-28 01:55:05,368: Snapshot:3	Epoch:109	Loss:3.482	translation_Loss:1.082	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.401                                                   	MRR:29.89	Hits@10:48.43	Best:29.9
2024-12-28 01:55:09,285: Snapshot:3	Epoch:110	Loss:3.462	translation_Loss:1.065	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.398                                                   	MRR:29.93	Hits@10:48.49	Best:29.93
2024-12-28 01:55:13,219: Snapshot:3	Epoch:111	Loss:3.418	translation_Loss:1.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.394                                                   	MRR:29.96	Hits@10:48.54	Best:29.96
2024-12-28 01:55:17,139: Snapshot:3	Epoch:112	Loss:3.416	translation_Loss:1.027	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.389                                                   	MRR:30.0	Hits@10:48.44	Best:30.0
2024-12-28 01:55:21,030: Snapshot:3	Epoch:113	Loss:3.388	translation_Loss:1.002	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.385                                                   	MRR:29.98	Hits@10:48.49	Best:30.0
2024-12-28 01:55:24,973: Snapshot:3	Epoch:114	Loss:3.368	translation_Loss:0.987	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.381                                                   	MRR:30.05	Hits@10:48.44	Best:30.05
2024-12-28 01:55:28,819: Snapshot:3	Epoch:115	Loss:3.342	translation_Loss:0.966	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.376                                                   	MRR:30.17	Hits@10:48.45	Best:30.17
2024-12-28 01:55:32,647: Snapshot:3	Epoch:116	Loss:3.319	translation_Loss:0.948	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.372                                                   	MRR:30.13	Hits@10:48.54	Best:30.17
2024-12-28 01:55:36,520: Snapshot:3	Epoch:117	Loss:3.296	translation_Loss:0.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.367                                                   	MRR:30.09	Hits@10:48.61	Best:30.17
2024-12-28 01:55:40,372: Snapshot:3	Epoch:118	Loss:3.279	translation_Loss:0.917	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.362                                                   	MRR:30.26	Hits@10:48.59	Best:30.26
2024-12-28 01:55:44,285: Snapshot:3	Epoch:119	Loss:3.262	translation_Loss:0.904	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.358                                                   	MRR:30.27	Hits@10:48.63	Best:30.27
2024-12-28 01:55:48,182: Snapshot:3	Epoch:120	Loss:3.237	translation_Loss:0.883	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.354                                                   	MRR:30.32	Hits@10:48.7	Best:30.32
2024-12-28 01:55:51,998: Snapshot:3	Epoch:121	Loss:3.225	translation_Loss:0.877	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.349                                                   	MRR:30.31	Hits@10:48.73	Best:30.32
2024-12-28 01:55:55,875: Snapshot:3	Epoch:122	Loss:3.221	translation_Loss:0.876	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.344                                                   	MRR:30.41	Hits@10:48.62	Best:30.41
2024-12-28 01:55:59,808: Snapshot:3	Epoch:123	Loss:3.191	translation_Loss:0.851	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.34                                                   	MRR:30.45	Hits@10:48.64	Best:30.45
2024-12-28 01:56:03,770: Snapshot:3	Epoch:124	Loss:3.16	translation_Loss:0.826	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.335                                                   	MRR:30.38	Hits@10:48.66	Best:30.45
2024-12-28 01:56:07,572: Snapshot:3	Epoch:125	Loss:3.143	translation_Loss:0.813	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.329                                                   	MRR:30.38	Hits@10:48.63	Best:30.45
2024-12-28 01:56:11,457: Snapshot:3	Epoch:126	Loss:3.128	translation_Loss:0.805	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.323                                                   	MRR:30.36	Hits@10:48.63	Best:30.45
2024-12-28 01:56:15,314: Snapshot:3	Epoch:127	Loss:3.119	translation_Loss:0.803	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.317                                                   	MRR:30.38	Hits@10:48.8	Best:30.45
2024-12-28 01:56:19,157: Early Stopping! Snapshot: 3 Epoch: 128 Best Results: 30.45
2024-12-28 01:56:19,157: Start to training tokens! Snapshot: 3 Epoch: 128 Loss:3.119 MRR:30.44 Best Results: 30.45
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 01:56:19,158: Snapshot:3	Epoch:128	Loss:3.119	translation_Loss:0.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.311                                                   	MRR:30.44	Hits@10:48.57	Best:30.45
2024-12-28 01:56:22,859: Snapshot:3	Epoch:129	Loss:23.947	translation_Loss:22.607	multi_layer_Loss:1.34	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:30.44	Hits@10:48.57	Best:30.45
2024-12-28 01:56:26,574: End of token training: 3 Epoch: 130 Loss:23.818 MRR:30.44 Best Results: 30.45
2024-12-28 01:56:26,574: Snapshot:3	Epoch:130	Loss:23.818	translation_Loss:22.571	multi_layer_Loss:1.247	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:30.44	Hits@10:48.57	Best:30.45
2024-12-28 01:56:26,950: => loading checkpoint './checkpoint/RELATIONrelation_0.00001_512_5000/3model_best.tar'
2024-12-28 01:56:42,303: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1782 | 0.0884 | 0.2244 | 0.2798 |  0.3472 |
|     1      | 0.1401 | 0.0664 | 0.1662 | 0.2161 |  0.2801 |
|     2      | 0.1618 | 0.0809 | 0.1807 | 0.2347 |  0.3155 |
|     3      | 0.303  | 0.1984 | 0.3588 | 0.4129 |  0.488  |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 01:56:55,416: Snapshot:4	Epoch:0	Loss:23.324	translation_Loss:23.323	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.001                                                   	MRR:4.26	Hits@10:12.77	Best:4.26
2024-12-28 01:56:58,158: Snapshot:4	Epoch:1	Loss:22.477	translation_Loss:22.471	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.006                                                   	MRR:4.59	Hits@10:13.74	Best:4.59
2024-12-28 01:57:00,953: Snapshot:4	Epoch:2	Loss:21.617	translation_Loss:21.605	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.012                                                   	MRR:4.99	Hits@10:15.08	Best:4.99
2024-12-28 01:57:03,729: Snapshot:4	Epoch:3	Loss:20.791	translation_Loss:20.77	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.021                                                   	MRR:5.38	Hits@10:15.89	Best:5.38
2024-12-28 01:57:06,512: Snapshot:4	Epoch:4	Loss:20.027	translation_Loss:19.995	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.032                                                   	MRR:5.7	Hits@10:16.83	Best:5.7
2024-12-28 01:57:09,315: Snapshot:4	Epoch:5	Loss:19.26	translation_Loss:19.215	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.045                                                   	MRR:6.07	Hits@10:17.79	Best:6.07
2024-12-28 01:57:12,103: Snapshot:4	Epoch:6	Loss:18.493	translation_Loss:18.434	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.059                                                   	MRR:6.57	Hits@10:18.57	Best:6.57
2024-12-28 01:57:14,899: Snapshot:4	Epoch:7	Loss:17.774	translation_Loss:17.698	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.075                                                   	MRR:6.96	Hits@10:19.17	Best:6.96
2024-12-28 01:57:17,675: Snapshot:4	Epoch:8	Loss:17.095	translation_Loss:17.003	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.092                                                   	MRR:7.33	Hits@10:19.99	Best:7.33
2024-12-28 01:57:20,498: Snapshot:4	Epoch:9	Loss:16.46	translation_Loss:16.349	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.111                                                   	MRR:7.67	Hits@10:20.77	Best:7.67
2024-12-28 01:57:23,302: Snapshot:4	Epoch:10	Loss:15.844	translation_Loss:15.714	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.13                                                   	MRR:8.01	Hits@10:21.37	Best:8.01
2024-12-28 01:57:26,176: Snapshot:4	Epoch:11	Loss:15.281	translation_Loss:15.131	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.15                                                   	MRR:8.32	Hits@10:21.98	Best:8.32
2024-12-28 01:57:28,927: Snapshot:4	Epoch:12	Loss:14.702	translation_Loss:14.532	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.17                                                   	MRR:8.62	Hits@10:22.69	Best:8.62
2024-12-28 01:57:31,714: Snapshot:4	Epoch:13	Loss:14.174	translation_Loss:13.983	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.191                                                   	MRR:8.97	Hits@10:23.33	Best:8.97
2024-12-28 01:57:34,576: Snapshot:4	Epoch:14	Loss:13.663	translation_Loss:13.451	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.211                                                   	MRR:9.27	Hits@10:24.08	Best:9.27
2024-12-28 01:57:37,374: Snapshot:4	Epoch:15	Loss:13.167	translation_Loss:12.934	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.232                                                   	MRR:9.55	Hits@10:24.86	Best:9.55
2024-12-28 01:57:40,159: Snapshot:4	Epoch:16	Loss:12.759	translation_Loss:12.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.253                                                   	MRR:9.92	Hits@10:25.65	Best:9.92
2024-12-28 01:57:42,950: Snapshot:4	Epoch:17	Loss:12.285	translation_Loss:12.011	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.274                                                   	MRR:10.3	Hits@10:26.34	Best:10.3
2024-12-28 01:57:45,720: Snapshot:4	Epoch:18	Loss:11.857	translation_Loss:11.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.295                                                   	MRR:10.64	Hits@10:27.14	Best:10.64
2024-12-28 01:57:48,530: Snapshot:4	Epoch:19	Loss:11.473	translation_Loss:11.158	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.315                                                   	MRR:11.0	Hits@10:27.75	Best:11.0
2024-12-28 01:57:51,369: Snapshot:4	Epoch:20	Loss:11.069	translation_Loss:10.733	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.335                                                   	MRR:11.3	Hits@10:28.47	Best:11.3
2024-12-28 01:57:54,153: Snapshot:4	Epoch:21	Loss:10.702	translation_Loss:10.347	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.355                                                   	MRR:11.58	Hits@10:29.08	Best:11.58
2024-12-28 01:57:56,959: Snapshot:4	Epoch:22	Loss:10.373	translation_Loss:9.998	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.375                                                   	MRR:11.9	Hits@10:30.0	Best:11.9
2024-12-28 01:57:59,736: Snapshot:4	Epoch:23	Loss:10.032	translation_Loss:9.637	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.394                                                   	MRR:12.2	Hits@10:30.67	Best:12.2
2024-12-28 01:58:02,518: Snapshot:4	Epoch:24	Loss:9.711	translation_Loss:9.298	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.413                                                   	MRR:12.6	Hits@10:31.5	Best:12.6
2024-12-28 01:58:05,262: Snapshot:4	Epoch:25	Loss:9.4	translation_Loss:8.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.432                                                   	MRR:12.98	Hits@10:32.14	Best:12.98
2024-12-28 01:58:08,073: Snapshot:4	Epoch:26	Loss:9.086	translation_Loss:8.635	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.451                                                   	MRR:13.33	Hits@10:32.76	Best:13.33
2024-12-28 01:58:10,868: Snapshot:4	Epoch:27	Loss:8.811	translation_Loss:8.343	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.468                                                   	MRR:13.67	Hits@10:33.5	Best:13.67
2024-12-28 01:58:13,663: Snapshot:4	Epoch:28	Loss:8.564	translation_Loss:8.078	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.486                                                   	MRR:13.96	Hits@10:34.07	Best:13.96
2024-12-28 01:58:16,431: Snapshot:4	Epoch:29	Loss:8.29	translation_Loss:7.786	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.503                                                   	MRR:14.25	Hits@10:34.74	Best:14.25
2024-12-28 01:58:19,262: Snapshot:4	Epoch:30	Loss:8.052	translation_Loss:7.532	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.52                                                   	MRR:14.6	Hits@10:35.42	Best:14.6
2024-12-28 01:58:22,037: Snapshot:4	Epoch:31	Loss:7.801	translation_Loss:7.265	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.537                                                   	MRR:14.96	Hits@10:36.12	Best:14.96
2024-12-28 01:58:24,823: Snapshot:4	Epoch:32	Loss:7.57	translation_Loss:7.017	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.553                                                   	MRR:15.22	Hits@10:36.73	Best:15.22
2024-12-28 01:58:27,582: Snapshot:4	Epoch:33	Loss:7.343	translation_Loss:6.774	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.569                                                   	MRR:15.55	Hits@10:37.31	Best:15.55
2024-12-28 01:58:30,396: Snapshot:4	Epoch:34	Loss:7.136	translation_Loss:6.552	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.584                                                   	MRR:15.87	Hits@10:38.03	Best:15.87
2024-12-28 01:58:33,203: Snapshot:4	Epoch:35	Loss:6.939	translation_Loss:6.34	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.6                                                   	MRR:16.18	Hits@10:38.5	Best:16.18
2024-12-28 01:58:35,976: Snapshot:4	Epoch:36	Loss:6.762	translation_Loss:6.147	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.615                                                   	MRR:16.46	Hits@10:38.89	Best:16.46
2024-12-28 01:58:38,780: Snapshot:4	Epoch:37	Loss:6.57	translation_Loss:5.94	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.629                                                   	MRR:16.73	Hits@10:39.35	Best:16.73
2024-12-28 01:58:41,570: Snapshot:4	Epoch:38	Loss:6.359	translation_Loss:5.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.644                                                   	MRR:17.02	Hits@10:39.97	Best:17.02
2024-12-28 01:58:44,350: Snapshot:4	Epoch:39	Loss:6.185	translation_Loss:5.527	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.658                                                   	MRR:17.24	Hits@10:40.52	Best:17.24
2024-12-28 01:58:47,084: Snapshot:4	Epoch:40	Loss:6.04	translation_Loss:5.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.672                                                   	MRR:17.57	Hits@10:41.02	Best:17.57
2024-12-28 01:58:49,859: Snapshot:4	Epoch:41	Loss:5.88	translation_Loss:5.195	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.685                                                   	MRR:17.9	Hits@10:41.56	Best:17.9
2024-12-28 01:58:52,651: Snapshot:4	Epoch:42	Loss:5.706	translation_Loss:5.007	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.699                                                   	MRR:18.16	Hits@10:41.99	Best:18.16
2024-12-28 01:58:55,445: Snapshot:4	Epoch:43	Loss:5.58	translation_Loss:4.868	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.712                                                   	MRR:18.54	Hits@10:42.44	Best:18.54
2024-12-28 01:58:58,214: Snapshot:4	Epoch:44	Loss:5.422	translation_Loss:4.698	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.725                                                   	MRR:18.79	Hits@10:42.73	Best:18.79
2024-12-28 01:59:00,994: Snapshot:4	Epoch:45	Loss:5.279	translation_Loss:4.542	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.737                                                   	MRR:19.06	Hits@10:43.25	Best:19.06
2024-12-28 01:59:03,776: Snapshot:4	Epoch:46	Loss:5.156	translation_Loss:4.407	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.749                                                   	MRR:19.26	Hits@10:43.63	Best:19.26
2024-12-28 01:59:06,538: Snapshot:4	Epoch:47	Loss:5.025	translation_Loss:4.265	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.761                                                   	MRR:19.48	Hits@10:43.81	Best:19.48
2024-12-28 01:59:09,346: Snapshot:4	Epoch:48	Loss:4.895	translation_Loss:4.123	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.772                                                   	MRR:19.72	Hits@10:44.51	Best:19.72
2024-12-28 01:59:12,138: Snapshot:4	Epoch:49	Loss:4.773	translation_Loss:3.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.783                                                   	MRR:19.95	Hits@10:44.87	Best:19.95
2024-12-28 01:59:14,922: Snapshot:4	Epoch:50	Loss:4.673	translation_Loss:3.879	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.794                                                   	MRR:20.24	Hits@10:45.14	Best:20.24
2024-12-28 01:59:17,719: Snapshot:4	Epoch:51	Loss:4.555	translation_Loss:3.75	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.805                                                   	MRR:20.5	Hits@10:45.52	Best:20.5
2024-12-28 01:59:20,507: Snapshot:4	Epoch:52	Loss:4.461	translation_Loss:3.646	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.816                                                   	MRR:20.69	Hits@10:45.86	Best:20.69
2024-12-28 01:59:23,325: Snapshot:4	Epoch:53	Loss:4.368	translation_Loss:3.542	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.826                                                   	MRR:20.97	Hits@10:46.32	Best:20.97
2024-12-28 01:59:26,109: Snapshot:4	Epoch:54	Loss:4.25	translation_Loss:3.414	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.836                                                   	MRR:21.15	Hits@10:46.56	Best:21.15
2024-12-28 01:59:28,896: Snapshot:4	Epoch:55	Loss:4.159	translation_Loss:3.314	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.845                                                   	MRR:21.32	Hits@10:46.89	Best:21.32
2024-12-28 01:59:31,690: Snapshot:4	Epoch:56	Loss:4.089	translation_Loss:3.234	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.855                                                   	MRR:21.5	Hits@10:47.3	Best:21.5
2024-12-28 01:59:34,472: Snapshot:4	Epoch:57	Loss:3.964	translation_Loss:3.1	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.864                                                   	MRR:21.72	Hits@10:47.58	Best:21.72
2024-12-28 01:59:37,259: Snapshot:4	Epoch:58	Loss:3.882	translation_Loss:3.009	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.873                                                   	MRR:21.89	Hits@10:47.84	Best:21.89
2024-12-28 01:59:40,050: Snapshot:4	Epoch:59	Loss:3.822	translation_Loss:2.941	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.881                                                   	MRR:22.03	Hits@10:48.28	Best:22.03
2024-12-28 01:59:42,837: Snapshot:4	Epoch:60	Loss:3.723	translation_Loss:2.833	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.89                                                   	MRR:22.27	Hits@10:48.47	Best:22.27
2024-12-28 01:59:45,600: Snapshot:4	Epoch:61	Loss:3.662	translation_Loss:2.764	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.898                                                   	MRR:22.5	Hits@10:48.84	Best:22.5
2024-12-28 01:59:48,429: Snapshot:4	Epoch:62	Loss:3.582	translation_Loss:2.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.906                                                   	MRR:22.7	Hits@10:49.11	Best:22.7
2024-12-28 01:59:51,244: Snapshot:4	Epoch:63	Loss:3.513	translation_Loss:2.6	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.913                                                   	MRR:22.85	Hits@10:49.35	Best:22.85
2024-12-28 01:59:54,593: Snapshot:4	Epoch:64	Loss:3.441	translation_Loss:2.521	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.92                                                   	MRR:22.96	Hits@10:49.7	Best:22.96
2024-12-28 01:59:57,376: Snapshot:4	Epoch:65	Loss:3.374	translation_Loss:2.447	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.927                                                   	MRR:23.07	Hits@10:49.99	Best:23.07
2024-12-28 02:00:00,186: Snapshot:4	Epoch:66	Loss:3.288	translation_Loss:2.354	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.934                                                   	MRR:23.1	Hits@10:50.21	Best:23.1
2024-12-28 02:00:02,995: Snapshot:4	Epoch:67	Loss:3.216	translation_Loss:2.275	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.941                                                   	MRR:23.2	Hits@10:50.34	Best:23.2
2024-12-28 02:00:05,800: Snapshot:4	Epoch:68	Loss:3.163	translation_Loss:2.216	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.947                                                   	MRR:23.46	Hits@10:50.43	Best:23.46
2024-12-28 02:00:08,691: Snapshot:4	Epoch:69	Loss:3.104	translation_Loss:2.15	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.953                                                   	MRR:23.5	Hits@10:50.6	Best:23.5
2024-12-28 02:00:11,507: Snapshot:4	Epoch:70	Loss:3.031	translation_Loss:2.072	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.959                                                   	MRR:23.61	Hits@10:50.73	Best:23.61
2024-12-28 02:00:14,283: Snapshot:4	Epoch:71	Loss:2.963	translation_Loss:1.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.965                                                   	MRR:23.73	Hits@10:50.83	Best:23.73
2024-12-28 02:00:17,078: Snapshot:4	Epoch:72	Loss:2.914	translation_Loss:1.944	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.97                                                   	MRR:23.82	Hits@10:51.02	Best:23.82
2024-12-28 02:00:19,859: Snapshot:4	Epoch:73	Loss:2.84	translation_Loss:1.865	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.976                                                   	MRR:23.89	Hits@10:51.03	Best:23.89
2024-12-28 02:00:22,673: Snapshot:4	Epoch:74	Loss:2.775	translation_Loss:1.795	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.981                                                   	MRR:23.94	Hits@10:51.02	Best:23.94
2024-12-28 02:00:25,470: Snapshot:4	Epoch:75	Loss:2.714	translation_Loss:1.729	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.985                                                   	MRR:24.02	Hits@10:51.35	Best:24.02
2024-12-28 02:00:28,268: Snapshot:4	Epoch:76	Loss:2.667	translation_Loss:1.678	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.99                                                   	MRR:24.23	Hits@10:51.4	Best:24.23
2024-12-28 02:00:31,060: Snapshot:4	Epoch:77	Loss:2.613	translation_Loss:1.619	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.994                                                   	MRR:24.4	Hits@10:51.34	Best:24.4
2024-12-28 02:00:33,839: Snapshot:4	Epoch:78	Loss:2.543	translation_Loss:1.545	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.998                                                   	MRR:24.56	Hits@10:51.64	Best:24.56
2024-12-28 02:00:36,615: Snapshot:4	Epoch:79	Loss:2.504	translation_Loss:1.502	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.002                                                   	MRR:24.8	Hits@10:51.74	Best:24.8
2024-12-28 02:00:39,424: Snapshot:4	Epoch:80	Loss:2.436	translation_Loss:1.43	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.006                                                   	MRR:25.0	Hits@10:51.84	Best:25.0
2024-12-28 02:00:42,202: Snapshot:4	Epoch:81	Loss:2.385	translation_Loss:1.376	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.009                                                   	MRR:25.18	Hits@10:51.86	Best:25.18
2024-12-28 02:00:44,961: Snapshot:4	Epoch:82	Loss:2.332	translation_Loss:1.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.012                                                   	MRR:25.27	Hits@10:52.06	Best:25.27
2024-12-28 02:00:47,731: Snapshot:4	Epoch:83	Loss:2.292	translation_Loss:1.277	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.015                                                   	MRR:25.53	Hits@10:52.18	Best:25.53
2024-12-28 02:00:50,478: Snapshot:4	Epoch:84	Loss:2.235	translation_Loss:1.217	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.018                                                   	MRR:25.66	Hits@10:52.13	Best:25.66
2024-12-28 02:00:53,255: Snapshot:4	Epoch:85	Loss:2.195	translation_Loss:1.174	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.021                                                   	MRR:25.73	Hits@10:52.18	Best:25.73
2024-12-28 02:00:56,029: Snapshot:4	Epoch:86	Loss:2.15	translation_Loss:1.127	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.024                                                   	MRR:25.84	Hits@10:52.2	Best:25.84
2024-12-28 02:00:58,948: Snapshot:4	Epoch:87	Loss:2.108	translation_Loss:1.083	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.026                                                   	MRR:26.0	Hits@10:52.27	Best:26.0
2024-12-28 02:01:01,732: Snapshot:4	Epoch:88	Loss:2.062	translation_Loss:1.034	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.028                                                   	MRR:26.11	Hits@10:52.35	Best:26.11
2024-12-28 02:01:04,534: Snapshot:4	Epoch:89	Loss:2.022	translation_Loss:0.992	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.03                                                   	MRR:26.22	Hits@10:52.45	Best:26.22
2024-12-28 02:01:07,319: Snapshot:4	Epoch:90	Loss:1.992	translation_Loss:0.959	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.032                                                   	MRR:26.34	Hits@10:52.43	Best:26.34
2024-12-28 02:01:10,106: Snapshot:4	Epoch:91	Loss:1.948	translation_Loss:0.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.034                                                   	MRR:26.46	Hits@10:52.43	Best:26.46
2024-12-28 02:01:12,952: Snapshot:4	Epoch:92	Loss:1.912	translation_Loss:0.877	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.035                                                   	MRR:26.47	Hits@10:52.38	Best:26.47
2024-12-28 02:01:15,735: Snapshot:4	Epoch:93	Loss:1.902	translation_Loss:0.865	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.037                                                   	MRR:26.51	Hits@10:52.51	Best:26.51
2024-12-28 02:01:18,510: Snapshot:4	Epoch:94	Loss:1.846	translation_Loss:0.808	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.038                                                   	MRR:26.6	Hits@10:52.49	Best:26.6
2024-12-28 02:01:21,292: Snapshot:4	Epoch:95	Loss:1.856	translation_Loss:0.818	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.039                                                   	MRR:26.64	Hits@10:52.48	Best:26.64
2024-12-28 02:01:24,105: Snapshot:4	Epoch:96	Loss:1.815	translation_Loss:0.775	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.04                                                   	MRR:26.67	Hits@10:52.55	Best:26.67
2024-12-28 02:01:26,891: Snapshot:4	Epoch:97	Loss:1.788	translation_Loss:0.747	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.041                                                   	MRR:26.71	Hits@10:52.69	Best:26.71
2024-12-28 02:01:29,649: Snapshot:4	Epoch:98	Loss:1.761	translation_Loss:0.72	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.041                                                   	MRR:26.76	Hits@10:52.71	Best:26.76
2024-12-28 02:01:32,443: Snapshot:4	Epoch:99	Loss:1.748	translation_Loss:0.706	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.042                                                   	MRR:26.82	Hits@10:52.76	Best:26.82
2024-12-28 02:01:35,227: Snapshot:4	Epoch:100	Loss:1.725	translation_Loss:0.683	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.042                                                   	MRR:26.91	Hits@10:52.84	Best:26.91
2024-12-28 02:01:38,016: Snapshot:4	Epoch:101	Loss:1.715	translation_Loss:0.673	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.042                                                   	MRR:26.93	Hits@10:52.71	Best:26.93
2024-12-28 02:01:40,868: Snapshot:4	Epoch:102	Loss:1.676	translation_Loss:0.634	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.042                                                   	MRR:27.0	Hits@10:52.7	Best:27.0
2024-12-28 02:01:43,596: Snapshot:4	Epoch:103	Loss:1.657	translation_Loss:0.615	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.042                                                   	MRR:27.0	Hits@10:52.77	Best:27.0
2024-12-28 02:01:46,332: Snapshot:4	Epoch:104	Loss:1.658	translation_Loss:0.616	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.042                                                   	MRR:26.96	Hits@10:52.84	Best:27.0
2024-12-28 02:01:49,018: Snapshot:4	Epoch:105	Loss:1.65	translation_Loss:0.609	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.042                                                   	MRR:26.97	Hits@10:52.91	Best:27.0
2024-12-28 02:01:51,768: Snapshot:4	Epoch:106	Loss:1.617	translation_Loss:0.576	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.041                                                   	MRR:27.03	Hits@10:52.84	Best:27.03
2024-12-28 02:01:54,561: Snapshot:4	Epoch:107	Loss:1.595	translation_Loss:0.555	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.04                                                   	MRR:27.11	Hits@10:52.88	Best:27.11
2024-12-28 02:01:57,307: Snapshot:4	Epoch:108	Loss:1.572	translation_Loss:0.532	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.039                                                   	MRR:27.06	Hits@10:52.92	Best:27.11
2024-12-28 02:02:00,036: Snapshot:4	Epoch:109	Loss:1.585	translation_Loss:0.546	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.038                                                   	MRR:27.03	Hits@10:52.79	Best:27.11
2024-12-28 02:02:02,736: Snapshot:4	Epoch:110	Loss:1.572	translation_Loss:0.535	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.037                                                   	MRR:27.07	Hits@10:52.76	Best:27.11
2024-12-28 02:02:05,523: Snapshot:4	Epoch:111	Loss:1.548	translation_Loss:0.511	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.037                                                   	MRR:27.15	Hits@10:52.98	Best:27.15
2024-12-28 02:02:08,301: Snapshot:4	Epoch:112	Loss:1.551	translation_Loss:0.515	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.035                                                   	MRR:27.2	Hits@10:53.02	Best:27.2
2024-12-28 02:02:11,103: Snapshot:4	Epoch:113	Loss:1.529	translation_Loss:0.495	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.034                                                   	MRR:27.25	Hits@10:53.07	Best:27.25
2024-12-28 02:02:13,861: Snapshot:4	Epoch:114	Loss:1.523	translation_Loss:0.49	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.033                                                   	MRR:27.28	Hits@10:53.04	Best:27.28
2024-12-28 02:02:16,631: Snapshot:4	Epoch:115	Loss:1.512	translation_Loss:0.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.032                                                   	MRR:27.33	Hits@10:53.13	Best:27.33
2024-12-28 02:02:19,380: Snapshot:4	Epoch:116	Loss:1.505	translation_Loss:0.474	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.032                                                   	MRR:27.31	Hits@10:53.17	Best:27.33
2024-12-28 02:02:22,086: Snapshot:4	Epoch:117	Loss:1.488	translation_Loss:0.457	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.031                                                   	MRR:27.26	Hits@10:53.16	Best:27.33
2024-12-28 02:02:24,785: Snapshot:4	Epoch:118	Loss:1.475	translation_Loss:0.445	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.03                                                   	MRR:27.3	Hits@10:53.16	Best:27.33
2024-12-28 02:02:27,480: Snapshot:4	Epoch:119	Loss:1.478	translation_Loss:0.449	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.029                                                   	MRR:27.31	Hits@10:53.14	Best:27.33
2024-12-28 02:02:30,230: Snapshot:4	Epoch:120	Loss:1.457	translation_Loss:0.429	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.028                                                   	MRR:27.37	Hits@10:53.23	Best:27.37
2024-12-28 02:02:33,035: Snapshot:4	Epoch:121	Loss:1.451	translation_Loss:0.425	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.026                                                   	MRR:27.39	Hits@10:53.44	Best:27.39
2024-12-28 02:02:36,361: Snapshot:4	Epoch:122	Loss:1.449	translation_Loss:0.424	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.025                                                   	MRR:27.4	Hits@10:53.37	Best:27.4
2024-12-28 02:02:39,159: Snapshot:4	Epoch:123	Loss:1.426	translation_Loss:0.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.024                                                   	MRR:27.52	Hits@10:53.31	Best:27.52
2024-12-28 02:02:41,944: Snapshot:4	Epoch:124	Loss:1.424	translation_Loss:0.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.022                                                   	MRR:27.54	Hits@10:53.4	Best:27.54
2024-12-28 02:02:44,723: Snapshot:4	Epoch:125	Loss:1.415	translation_Loss:0.395	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.021                                                   	MRR:27.56	Hits@10:53.4	Best:27.56
2024-12-28 02:02:47,523: Snapshot:4	Epoch:126	Loss:1.405	translation_Loss:0.386	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.019                                                   	MRR:27.57	Hits@10:53.43	Best:27.57
2024-12-28 02:02:50,283: Snapshot:4	Epoch:127	Loss:1.402	translation_Loss:0.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.017                                                   	MRR:27.64	Hits@10:53.37	Best:27.64
2024-12-28 02:02:52,970: Snapshot:4	Epoch:128	Loss:1.39	translation_Loss:0.374	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.016                                                   	MRR:27.62	Hits@10:53.46	Best:27.64
2024-12-28 02:02:55,767: Snapshot:4	Epoch:129	Loss:1.386	translation_Loss:0.372	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.014                                                   	MRR:27.7	Hits@10:53.57	Best:27.7
2024-12-28 02:02:58,525: Snapshot:4	Epoch:130	Loss:1.385	translation_Loss:0.372	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.013                                                   	MRR:27.64	Hits@10:53.68	Best:27.7
2024-12-28 02:03:01,280: Snapshot:4	Epoch:131	Loss:1.371	translation_Loss:0.36	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.011                                                   	MRR:27.72	Hits@10:53.65	Best:27.72
2024-12-28 02:03:04,055: Snapshot:4	Epoch:132	Loss:1.363	translation_Loss:0.354	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.01                                                   	MRR:27.71	Hits@10:53.6	Best:27.72
2024-12-28 02:03:06,753: Snapshot:4	Epoch:133	Loss:1.359	translation_Loss:0.351	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.008                                                   	MRR:27.65	Hits@10:53.64	Best:27.72
2024-12-28 02:03:09,468: Snapshot:4	Epoch:134	Loss:1.353	translation_Loss:0.347	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.006                                                   	MRR:27.67	Hits@10:53.52	Best:27.72
2024-12-28 02:03:12,182: Snapshot:4	Epoch:135	Loss:1.348	translation_Loss:0.344	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.004                                                   	MRR:27.72	Hits@10:53.55	Best:27.72
2024-12-28 02:03:14,963: Snapshot:4	Epoch:136	Loss:1.33	translation_Loss:0.328	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.003                                                   	MRR:27.78	Hits@10:53.53	Best:27.78
2024-12-28 02:03:17,694: Snapshot:4	Epoch:137	Loss:1.325	translation_Loss:0.324	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.001                                                   	MRR:27.73	Hits@10:53.5	Best:27.78
2024-12-28 02:03:20,429: Snapshot:4	Epoch:138	Loss:1.316	translation_Loss:0.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.999                                                   	MRR:27.72	Hits@10:53.64	Best:27.78
2024-12-28 02:03:23,165: Snapshot:4	Epoch:139	Loss:1.317	translation_Loss:0.32	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.997                                                   	MRR:27.76	Hits@10:53.58	Best:27.78
2024-12-28 02:03:25,884: Snapshot:4	Epoch:140	Loss:1.305	translation_Loss:0.31	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.995                                                   	MRR:27.76	Hits@10:53.73	Best:27.78
2024-12-28 02:03:28,573: Early Stopping! Snapshot: 4 Epoch: 141 Best Results: 27.78
2024-12-28 02:03:28,573: Start to training tokens! Snapshot: 4 Epoch: 141 Loss:1.309 MRR:27.77 Best Results: 27.78
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 02:03:28,573: Snapshot:4	Epoch:141	Loss:1.309	translation_Loss:0.315	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.994                                                   	MRR:27.77	Hits@10:53.84	Best:27.78
2024-12-28 02:03:31,167: Snapshot:4	Epoch:142	Loss:13.322	translation_Loss:12.314	multi_layer_Loss:1.008	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.77	Hits@10:53.84	Best:27.78
2024-12-28 02:03:33,773: End of token training: 4 Epoch: 143 Loss:13.319 MRR:27.77 Best Results: 27.78
2024-12-28 02:03:33,773: Snapshot:4	Epoch:143	Loss:13.319	translation_Loss:12.355	multi_layer_Loss:0.964	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:27.77	Hits@10:53.84	Best:27.78
2024-12-28 02:03:34,150: => loading checkpoint './checkpoint/RELATIONrelation_0.00001_512_5000/4model_best.tar'
2024-12-28 02:03:50,955: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1661 | 0.0835 | 0.2083 | 0.2567 |  0.3172 |
|     1      | 0.1334 | 0.0623 | 0.157  | 0.2053 |  0.2716 |
|     2      | 0.1511 | 0.0751 | 0.1692 | 0.2169 |  0.2945 |
|     3      | 0.2582 | 0.1669 | 0.2996 | 0.3453 |  0.4219 |
|     4      | 0.2742 | 0.1462 | 0.318  | 0.414  |  0.5379 |
+------------+--------+--------+--------+--------+---------+
2024-12-28 02:03:50,958: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2733 | 0.1579 | 0.3449 | 0.413  |  0.4843 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2164 | 0.1081 | 0.2765 | 0.3428 |  0.4182 |
|     1      | 0.1831 | 0.0957 | 0.219  | 0.2782 |  0.3494 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1836 | 0.0911 | 0.2324 | 0.2902 |  0.3576 |
|     1      | 0.1502 | 0.0748 | 0.1795 |  0.23  |  0.2931 |
|     2      | 0.2289 | 0.1358 | 0.2605 | 0.324  |  0.4153 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1782 | 0.0884 | 0.2244 | 0.2798 |  0.3472 |
|     1      | 0.1401 | 0.0664 | 0.1662 | 0.2161 |  0.2801 |
|     2      | 0.1618 | 0.0809 | 0.1807 | 0.2347 |  0.3155 |
|     3      | 0.303  | 0.1984 | 0.3588 | 0.4129 |  0.488  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.1661 | 0.0835 | 0.2083 | 0.2567 |  0.3172 |
|     1      | 0.1334 | 0.0623 | 0.157  | 0.2053 |  0.2716 |
|     2      | 0.1511 | 0.0751 | 0.1692 | 0.2169 |  0.2945 |
|     3      | 0.2582 | 0.1669 | 0.2996 | 0.3453 |  0.4219 |
|     4      | 0.2742 | 0.1462 | 0.318  | 0.414  |  0.5379 |
+------------+--------+--------+--------+--------+---------+]
2024-12-28 02:03:50,958: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 1872.5563390254974 |   0.273   |    0.158     |    0.345     |     0.484     |
|    1     |  928.379921913147  |    0.2    |    0.102     |    0.249     |     0.385     |
|    2     |  633.531031370163  |   0.183   |    0.097     |     0.22     |     0.349     |
|    3     | 524.1527149677277  |   0.175   |    0.091     |     0.21     |     0.333     |
|    4     | 409.65138721466064 |   0.169   |    0.088     |    0.201     |     0.324     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2024-12-28 02:03:50,958: Sum_Training_Time:4368.271394491196
2024-12-28 02:03:50,959: Every_Training_Time:[1872.5563390254974, 928.379921913147, 633.531031370163, 524.1527149677277, 409.65138721466064]
2024-12-28 02:03:50,959: Forward transfer: 0.018875 Backward transfer: -0.06987499999999999
2024-12-28 02:04:28,145: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='512', contrast_loss_weight=0.1, data_path='./data/RELATION/', dataset='RELATION', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=1e-05, lifelong_name='double_tokened', log_path='./logs/20241228020354/RELATIONrelation_0.00001_512_10000', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=0.01, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='relation_0.00001_512_10000', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/RELATIONrelation_0.00001_512_10000', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=10000.0, token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2024-12-28 02:04:44,170: Snapshot:0	Epoch:0	Loss:165.062	translation_Loss:165.062	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:1.83	Hits@10:1.85	Best:1.83
2024-12-28 02:04:55,933: Snapshot:0	Epoch:1	Loss:162.089	translation_Loss:162.089	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:1.89	Hits@10:1.99	Best:1.89
2024-12-28 02:05:07,579: Snapshot:0	Epoch:2	Loss:159.039	translation_Loss:159.039	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:2.08	Hits@10:2.48	Best:2.08
2024-12-28 02:05:19,240: Snapshot:0	Epoch:3	Loss:156.025	translation_Loss:156.025	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:2.65	Hits@10:4.15	Best:2.65
2024-12-28 02:05:31,010: Snapshot:0	Epoch:4	Loss:153.079	translation_Loss:153.079	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:3.63	Hits@10:6.75	Best:3.63
2024-12-28 02:05:42,691: Snapshot:0	Epoch:5	Loss:150.267	translation_Loss:150.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:4.8	Hits@10:9.61	Best:4.8
2024-12-28 02:05:54,401: Snapshot:0	Epoch:6	Loss:147.532	translation_Loss:147.532	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:5.9	Hits@10:12.07	Best:5.9
2024-12-28 02:06:06,542: Snapshot:0	Epoch:7	Loss:144.844	translation_Loss:144.844	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:6.8	Hits@10:14.01	Best:6.8
2024-12-28 02:06:18,244: Snapshot:0	Epoch:8	Loss:142.33	translation_Loss:142.33	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.41	Hits@10:15.28	Best:7.41
2024-12-28 02:06:29,867: Snapshot:0	Epoch:9	Loss:139.836	translation_Loss:139.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:7.84	Hits@10:16.31	Best:7.84
2024-12-28 02:06:41,678: Snapshot:0	Epoch:10	Loss:137.505	translation_Loss:137.505	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.15	Hits@10:17.17	Best:8.15
2024-12-28 02:06:53,324: Snapshot:0	Epoch:11	Loss:135.246	translation_Loss:135.246	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.39	Hits@10:17.93	Best:8.39
2024-12-28 02:07:04,937: Snapshot:0	Epoch:12	Loss:132.99	translation_Loss:132.99	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.6	Hits@10:18.62	Best:8.6
2024-12-28 02:07:16,696: Snapshot:0	Epoch:13	Loss:130.929	translation_Loss:130.929	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.8	Hits@10:19.27	Best:8.8
2024-12-28 02:07:28,426: Snapshot:0	Epoch:14	Loss:128.817	translation_Loss:128.817	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:8.97	Hits@10:19.81	Best:8.97
2024-12-28 02:07:40,090: Snapshot:0	Epoch:15	Loss:126.902	translation_Loss:126.902	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.12	Hits@10:20.3	Best:9.12
2024-12-28 02:07:51,729: Snapshot:0	Epoch:16	Loss:124.769	translation_Loss:124.769	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.27	Hits@10:20.79	Best:9.27
2024-12-28 02:08:03,426: Snapshot:0	Epoch:17	Loss:122.834	translation_Loss:122.834	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.4	Hits@10:21.26	Best:9.4
2024-12-28 02:08:15,213: Snapshot:0	Epoch:18	Loss:120.914	translation_Loss:120.914	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.54	Hits@10:21.69	Best:9.54
2024-12-28 02:08:27,415: Snapshot:0	Epoch:19	Loss:118.966	translation_Loss:118.966	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.67	Hits@10:22.11	Best:9.67
2024-12-28 02:08:39,045: Snapshot:0	Epoch:20	Loss:117.16	translation_Loss:117.16	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.8	Hits@10:22.5	Best:9.8
2024-12-28 02:08:50,729: Snapshot:0	Epoch:21	Loss:115.205	translation_Loss:115.205	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:9.92	Hits@10:22.89	Best:9.92
2024-12-28 02:09:02,424: Snapshot:0	Epoch:22	Loss:113.455	translation_Loss:113.455	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.05	Hits@10:23.3	Best:10.05
2024-12-28 02:09:14,185: Snapshot:0	Epoch:23	Loss:111.589	translation_Loss:111.589	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.2	Hits@10:23.77	Best:10.2
2024-12-28 02:09:25,905: Snapshot:0	Epoch:24	Loss:109.708	translation_Loss:109.708	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.36	Hits@10:24.19	Best:10.36
2024-12-28 02:09:37,746: Snapshot:0	Epoch:25	Loss:108.053	translation_Loss:108.053	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.54	Hits@10:24.66	Best:10.54
2024-12-28 02:09:49,563: Snapshot:0	Epoch:26	Loss:106.172	translation_Loss:106.172	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.75	Hits@10:25.22	Best:10.75
2024-12-28 02:10:01,212: Snapshot:0	Epoch:27	Loss:104.393	translation_Loss:104.393	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:10.97	Hits@10:25.72	Best:10.97
2024-12-28 02:10:13,029: Snapshot:0	Epoch:28	Loss:102.674	translation_Loss:102.674	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.25	Hits@10:26.22	Best:11.25
2024-12-28 02:10:24,616: Snapshot:0	Epoch:29	Loss:100.893	translation_Loss:100.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.51	Hits@10:26.73	Best:11.51
2024-12-28 02:10:36,287: Snapshot:0	Epoch:30	Loss:99.101	translation_Loss:99.101	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:11.81	Hits@10:27.37	Best:11.81
2024-12-28 02:10:47,958: Snapshot:0	Epoch:31	Loss:97.402	translation_Loss:97.402	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.09	Hits@10:27.94	Best:12.09
2024-12-28 02:11:00,045: Snapshot:0	Epoch:32	Loss:95.6	translation_Loss:95.6	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.43	Hits@10:28.47	Best:12.43
2024-12-28 02:11:11,727: Snapshot:0	Epoch:33	Loss:93.962	translation_Loss:93.962	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:12.77	Hits@10:29.16	Best:12.77
2024-12-28 02:11:23,503: Snapshot:0	Epoch:34	Loss:92.111	translation_Loss:92.111	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.1	Hits@10:29.75	Best:13.1
2024-12-28 02:11:35,133: Snapshot:0	Epoch:35	Loss:90.548	translation_Loss:90.548	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.47	Hits@10:30.34	Best:13.47
2024-12-28 02:11:46,842: Snapshot:0	Epoch:36	Loss:88.741	translation_Loss:88.741	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:13.84	Hits@10:31.0	Best:13.84
2024-12-28 02:11:58,521: Snapshot:0	Epoch:37	Loss:87.076	translation_Loss:87.076	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.21	Hits@10:31.6	Best:14.21
2024-12-28 02:12:10,149: Snapshot:0	Epoch:38	Loss:85.453	translation_Loss:85.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.57	Hits@10:32.29	Best:14.57
2024-12-28 02:12:21,839: Snapshot:0	Epoch:39	Loss:83.863	translation_Loss:83.863	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:14.93	Hits@10:32.93	Best:14.93
2024-12-28 02:12:33,460: Snapshot:0	Epoch:40	Loss:82.025	translation_Loss:82.025	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.3	Hits@10:33.48	Best:15.3
2024-12-28 02:12:45,258: Snapshot:0	Epoch:41	Loss:80.438	translation_Loss:80.438	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:15.66	Hits@10:33.98	Best:15.66
2024-12-28 02:12:56,973: Snapshot:0	Epoch:42	Loss:78.854	translation_Loss:78.854	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.06	Hits@10:34.48	Best:16.06
2024-12-28 02:13:08,672: Snapshot:0	Epoch:43	Loss:77.207	translation_Loss:77.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.4	Hits@10:34.98	Best:16.4
2024-12-28 02:13:20,832: Snapshot:0	Epoch:44	Loss:75.557	translation_Loss:75.557	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:16.72	Hits@10:35.57	Best:16.72
2024-12-28 02:13:32,613: Snapshot:0	Epoch:45	Loss:73.95	translation_Loss:73.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.02	Hits@10:36.01	Best:17.02
2024-12-28 02:13:44,272: Snapshot:0	Epoch:46	Loss:72.368	translation_Loss:72.368	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.35	Hits@10:36.53	Best:17.35
2024-12-28 02:13:55,927: Snapshot:0	Epoch:47	Loss:70.792	translation_Loss:70.792	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.63	Hits@10:36.91	Best:17.63
2024-12-28 02:14:07,705: Snapshot:0	Epoch:48	Loss:69.198	translation_Loss:69.198	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:17.9	Hits@10:37.36	Best:17.9
2024-12-28 02:14:19,401: Snapshot:0	Epoch:49	Loss:67.67	translation_Loss:67.67	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.18	Hits@10:37.8	Best:18.18
2024-12-28 02:14:31,139: Snapshot:0	Epoch:50	Loss:66.104	translation_Loss:66.104	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.43	Hits@10:38.18	Best:18.43
2024-12-28 02:14:42,826: Snapshot:0	Epoch:51	Loss:64.635	translation_Loss:64.635	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.68	Hits@10:38.57	Best:18.68
2024-12-28 02:14:54,462: Snapshot:0	Epoch:52	Loss:63.251	translation_Loss:63.251	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:18.92	Hits@10:38.91	Best:18.92
2024-12-28 02:15:06,156: Snapshot:0	Epoch:53	Loss:61.702	translation_Loss:61.702	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.16	Hits@10:39.21	Best:19.16
2024-12-28 02:15:17,922: Snapshot:0	Epoch:54	Loss:60.29	translation_Loss:60.29	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.38	Hits@10:39.58	Best:19.38
2024-12-28 02:15:29,662: Snapshot:0	Epoch:55	Loss:58.969	translation_Loss:58.969	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.57	Hits@10:39.87	Best:19.57
2024-12-28 02:15:41,315: Snapshot:0	Epoch:56	Loss:57.662	translation_Loss:57.662	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.73	Hits@10:40.19	Best:19.73
2024-12-28 02:15:53,386: Snapshot:0	Epoch:57	Loss:56.231	translation_Loss:56.231	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:19.94	Hits@10:40.42	Best:19.94
2024-12-28 02:16:05,168: Snapshot:0	Epoch:58	Loss:55.009	translation_Loss:55.009	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.14	Hits@10:40.67	Best:20.14
2024-12-28 02:16:16,864: Snapshot:0	Epoch:59	Loss:53.637	translation_Loss:53.637	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.34	Hits@10:40.92	Best:20.34
2024-12-28 02:16:28,495: Snapshot:0	Epoch:60	Loss:52.48	translation_Loss:52.48	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.51	Hits@10:41.14	Best:20.51
2024-12-28 02:16:40,290: Snapshot:0	Epoch:61	Loss:51.322	translation_Loss:51.322	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.71	Hits@10:41.39	Best:20.71
2024-12-28 02:16:51,942: Snapshot:0	Epoch:62	Loss:50.025	translation_Loss:50.025	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:20.87	Hits@10:41.56	Best:20.87
2024-12-28 02:17:03,584: Snapshot:0	Epoch:63	Loss:48.907	translation_Loss:48.907	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.02	Hits@10:41.77	Best:21.02
2024-12-28 02:17:15,209: Snapshot:0	Epoch:64	Loss:47.669	translation_Loss:47.669	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.2	Hits@10:41.99	Best:21.2
2024-12-28 02:17:26,959: Snapshot:0	Epoch:65	Loss:46.651	translation_Loss:46.651	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.36	Hits@10:42.14	Best:21.36
2024-12-28 02:17:38,658: Snapshot:0	Epoch:66	Loss:45.62	translation_Loss:45.62	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.52	Hits@10:42.34	Best:21.52
2024-12-28 02:17:50,426: Snapshot:0	Epoch:67	Loss:44.525	translation_Loss:44.525	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.69	Hits@10:42.54	Best:21.69
2024-12-28 02:18:02,100: Snapshot:0	Epoch:68	Loss:43.563	translation_Loss:43.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.82	Hits@10:42.66	Best:21.82
2024-12-28 02:18:14,264: Snapshot:0	Epoch:69	Loss:42.385	translation_Loss:42.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:21.98	Hits@10:42.81	Best:21.98
2024-12-28 02:18:25,955: Snapshot:0	Epoch:70	Loss:41.44	translation_Loss:41.44	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.14	Hits@10:42.99	Best:22.14
2024-12-28 02:18:37,668: Snapshot:0	Epoch:71	Loss:40.483	translation_Loss:40.483	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.27	Hits@10:43.16	Best:22.27
2024-12-28 02:18:49,278: Snapshot:0	Epoch:72	Loss:39.485	translation_Loss:39.485	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.39	Hits@10:43.35	Best:22.39
2024-12-28 02:19:00,918: Snapshot:0	Epoch:73	Loss:38.576	translation_Loss:38.576	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.51	Hits@10:43.53	Best:22.51
2024-12-28 02:19:12,636: Snapshot:0	Epoch:74	Loss:37.63	translation_Loss:37.63	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.65	Hits@10:43.64	Best:22.65
2024-12-28 02:19:24,275: Snapshot:0	Epoch:75	Loss:36.798	translation_Loss:36.798	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.76	Hits@10:43.81	Best:22.76
2024-12-28 02:19:35,909: Snapshot:0	Epoch:76	Loss:35.861	translation_Loss:35.861	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:22.85	Hits@10:43.91	Best:22.85
2024-12-28 02:19:47,551: Snapshot:0	Epoch:77	Loss:35.0	translation_Loss:35.0	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.02	Hits@10:44.06	Best:23.02
2024-12-28 02:19:59,190: Snapshot:0	Epoch:78	Loss:34.067	translation_Loss:34.067	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.14	Hits@10:44.18	Best:23.14
2024-12-28 02:20:10,994: Snapshot:0	Epoch:79	Loss:33.244	translation_Loss:33.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.26	Hits@10:44.28	Best:23.26
2024-12-28 02:20:22,649: Snapshot:0	Epoch:80	Loss:32.449	translation_Loss:32.449	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.36	Hits@10:44.44	Best:23.36
2024-12-28 02:20:34,252: Snapshot:0	Epoch:81	Loss:31.715	translation_Loss:31.715	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.48	Hits@10:44.57	Best:23.48
2024-12-28 02:20:46,429: Snapshot:0	Epoch:82	Loss:30.843	translation_Loss:30.843	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.57	Hits@10:44.71	Best:23.57
2024-12-28 02:20:58,039: Snapshot:0	Epoch:83	Loss:30.105	translation_Loss:30.105	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.69	Hits@10:44.84	Best:23.69
2024-12-28 02:21:09,783: Snapshot:0	Epoch:84	Loss:29.318	translation_Loss:29.318	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.77	Hits@10:44.96	Best:23.77
2024-12-28 02:21:21,370: Snapshot:0	Epoch:85	Loss:28.676	translation_Loss:28.676	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.87	Hits@10:45.11	Best:23.87
2024-12-28 02:21:33,035: Snapshot:0	Epoch:86	Loss:27.986	translation_Loss:27.986	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:23.92	Hits@10:45.2	Best:23.92
2024-12-28 02:21:44,673: Snapshot:0	Epoch:87	Loss:27.273	translation_Loss:27.273	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.03	Hits@10:45.33	Best:24.03
2024-12-28 02:21:56,248: Snapshot:0	Epoch:88	Loss:26.559	translation_Loss:26.559	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.14	Hits@10:45.41	Best:24.14
2024-12-28 02:22:07,919: Snapshot:0	Epoch:89	Loss:25.956	translation_Loss:25.956	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.21	Hits@10:45.52	Best:24.21
2024-12-28 02:22:19,531: Snapshot:0	Epoch:90	Loss:25.335	translation_Loss:25.335	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.29	Hits@10:45.64	Best:24.29
2024-12-28 02:22:31,167: Snapshot:0	Epoch:91	Loss:24.688	translation_Loss:24.688	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.41	Hits@10:45.72	Best:24.41
2024-12-28 02:22:42,930: Snapshot:0	Epoch:92	Loss:24.05	translation_Loss:24.05	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.49	Hits@10:45.78	Best:24.49
2024-12-28 02:22:54,497: Snapshot:0	Epoch:93	Loss:23.39	translation_Loss:23.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.6	Hits@10:45.87	Best:24.6
2024-12-28 02:23:06,497: Snapshot:0	Epoch:94	Loss:22.879	translation_Loss:22.879	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.66	Hits@10:46.0	Best:24.66
2024-12-28 02:23:18,157: Snapshot:0	Epoch:95	Loss:22.348	translation_Loss:22.348	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.72	Hits@10:46.05	Best:24.72
2024-12-28 02:23:29,897: Snapshot:0	Epoch:96	Loss:21.736	translation_Loss:21.736	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.83	Hits@10:46.15	Best:24.83
2024-12-28 02:23:41,558: Snapshot:0	Epoch:97	Loss:21.255	translation_Loss:21.255	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.89	Hits@10:46.23	Best:24.89
2024-12-28 02:23:53,237: Snapshot:0	Epoch:98	Loss:20.698	translation_Loss:20.698	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:24.97	Hits@10:46.29	Best:24.97
2024-12-28 02:24:04,866: Snapshot:0	Epoch:99	Loss:20.276	translation_Loss:20.276	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.03	Hits@10:46.33	Best:25.03
2024-12-28 02:24:16,479: Snapshot:0	Epoch:100	Loss:19.687	translation_Loss:19.687	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.1	Hits@10:46.47	Best:25.1
2024-12-28 02:24:28,137: Snapshot:0	Epoch:101	Loss:19.204	translation_Loss:19.204	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.14	Hits@10:46.49	Best:25.14
2024-12-28 02:24:39,744: Snapshot:0	Epoch:102	Loss:18.709	translation_Loss:18.709	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.22	Hits@10:46.58	Best:25.22
2024-12-28 02:24:51,326: Snapshot:0	Epoch:103	Loss:18.313	translation_Loss:18.313	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.27	Hits@10:46.62	Best:25.27
2024-12-28 02:25:02,971: Snapshot:0	Epoch:104	Loss:17.887	translation_Loss:17.887	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.34	Hits@10:46.68	Best:25.34
2024-12-28 02:25:14,634: Snapshot:0	Epoch:105	Loss:17.435	translation_Loss:17.435	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.41	Hits@10:46.72	Best:25.41
2024-12-28 02:25:26,291: Snapshot:0	Epoch:106	Loss:16.989	translation_Loss:16.989	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.5	Hits@10:46.87	Best:25.5
2024-12-28 02:25:38,305: Snapshot:0	Epoch:107	Loss:16.563	translation_Loss:16.563	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.55	Hits@10:46.93	Best:25.55
2024-12-28 02:25:49,951: Snapshot:0	Epoch:108	Loss:16.162	translation_Loss:16.162	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.61	Hits@10:47.0	Best:25.61
2024-12-28 02:26:01,678: Snapshot:0	Epoch:109	Loss:15.852	translation_Loss:15.852	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.64	Hits@10:47.03	Best:25.64
2024-12-28 02:26:13,310: Snapshot:0	Epoch:110	Loss:15.453	translation_Loss:15.453	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.68	Hits@10:47.09	Best:25.68
2024-12-28 02:26:25,057: Snapshot:0	Epoch:111	Loss:15.093	translation_Loss:15.093	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.75	Hits@10:47.15	Best:25.75
2024-12-28 02:26:36,654: Snapshot:0	Epoch:112	Loss:14.783	translation_Loss:14.783	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.78	Hits@10:47.19	Best:25.78
2024-12-28 02:26:48,404: Snapshot:0	Epoch:113	Loss:14.45	translation_Loss:14.45	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.86	Hits@10:47.23	Best:25.86
2024-12-28 02:27:00,090: Snapshot:0	Epoch:114	Loss:14.154	translation_Loss:14.154	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.92	Hits@10:47.3	Best:25.92
2024-12-28 02:27:11,753: Snapshot:0	Epoch:115	Loss:13.732	translation_Loss:13.732	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:25.97	Hits@10:47.35	Best:25.97
2024-12-28 02:27:23,446: Snapshot:0	Epoch:116	Loss:13.433	translation_Loss:13.433	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.01	Hits@10:47.44	Best:26.01
2024-12-28 02:27:35,064: Snapshot:0	Epoch:117	Loss:13.181	translation_Loss:13.181	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.04	Hits@10:47.5	Best:26.04
2024-12-28 02:27:46,671: Snapshot:0	Epoch:118	Loss:12.814	translation_Loss:12.814	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.11	Hits@10:47.47	Best:26.11
2024-12-28 02:27:58,726: Snapshot:0	Epoch:119	Loss:12.552	translation_Loss:12.552	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.16	Hits@10:47.54	Best:26.16
2024-12-28 02:28:10,334: Snapshot:0	Epoch:120	Loss:12.296	translation_Loss:12.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.19	Hits@10:47.53	Best:26.19
2024-12-28 02:28:22,003: Snapshot:0	Epoch:121	Loss:11.999	translation_Loss:11.999	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.22	Hits@10:47.63	Best:26.22
2024-12-28 02:28:33,572: Snapshot:0	Epoch:122	Loss:11.765	translation_Loss:11.765	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.29	Hits@10:47.66	Best:26.29
2024-12-28 02:28:45,311: Snapshot:0	Epoch:123	Loss:11.545	translation_Loss:11.545	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.34	Hits@10:47.63	Best:26.34
2024-12-28 02:28:56,953: Snapshot:0	Epoch:124	Loss:11.267	translation_Loss:11.267	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.37	Hits@10:47.66	Best:26.37
2024-12-28 02:29:08,524: Snapshot:0	Epoch:125	Loss:11.087	translation_Loss:11.087	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.44	Hits@10:47.69	Best:26.44
2024-12-28 02:29:20,147: Snapshot:0	Epoch:126	Loss:10.828	translation_Loss:10.828	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.5	Hits@10:47.78	Best:26.5
2024-12-28 02:29:31,785: Snapshot:0	Epoch:127	Loss:10.608	translation_Loss:10.608	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.52	Hits@10:47.77	Best:26.52
2024-12-28 02:29:43,443: Snapshot:0	Epoch:128	Loss:10.383	translation_Loss:10.383	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.56	Hits@10:47.77	Best:26.56
2024-12-28 02:29:55,046: Snapshot:0	Epoch:129	Loss:10.177	translation_Loss:10.177	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.58	Hits@10:47.78	Best:26.58
2024-12-28 02:30:06,726: Snapshot:0	Epoch:130	Loss:9.997	translation_Loss:9.997	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.6	Hits@10:47.8	Best:26.6
2024-12-28 02:30:18,813: Snapshot:0	Epoch:131	Loss:9.787	translation_Loss:9.787	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.64	Hits@10:47.81	Best:26.64
2024-12-28 02:30:30,433: Snapshot:0	Epoch:132	Loss:9.556	translation_Loss:9.556	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.66	Hits@10:47.89	Best:26.66
2024-12-28 02:30:42,013: Snapshot:0	Epoch:133	Loss:9.345	translation_Loss:9.345	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.68	Hits@10:47.86	Best:26.68
2024-12-28 02:30:53,764: Snapshot:0	Epoch:134	Loss:9.207	translation_Loss:9.207	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.7	Hits@10:47.9	Best:26.7
2024-12-28 02:31:05,362: Snapshot:0	Epoch:135	Loss:9.024	translation_Loss:9.024	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.71	Hits@10:47.91	Best:26.71
2024-12-28 02:31:17,163: Snapshot:0	Epoch:136	Loss:8.909	translation_Loss:8.909	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.73	Hits@10:47.93	Best:26.73
2024-12-28 02:31:28,877: Snapshot:0	Epoch:137	Loss:8.695	translation_Loss:8.695	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.78	Hits@10:47.93	Best:26.78
2024-12-28 02:31:40,442: Snapshot:0	Epoch:138	Loss:8.507	translation_Loss:8.507	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.78	Hits@10:47.91	Best:26.78
2024-12-28 02:31:52,052: Snapshot:0	Epoch:139	Loss:8.394	translation_Loss:8.394	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.76	Hits@10:47.94	Best:26.78
2024-12-28 02:32:03,620: Snapshot:0	Epoch:140	Loss:8.239	translation_Loss:8.239	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.86	Hits@10:47.98	Best:26.86
2024-12-28 02:32:15,353: Snapshot:0	Epoch:141	Loss:8.059	translation_Loss:8.059	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.85	Hits@10:47.95	Best:26.86
2024-12-28 02:32:27,092: Snapshot:0	Epoch:142	Loss:7.968	translation_Loss:7.968	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.86	Hits@10:47.93	Best:26.86
2024-12-28 02:32:38,665: Snapshot:0	Epoch:143	Loss:7.836	translation_Loss:7.836	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.88	Hits@10:47.99	Best:26.88
2024-12-28 02:32:50,747: Snapshot:0	Epoch:144	Loss:7.644	translation_Loss:7.644	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.88	Hits@10:47.99	Best:26.88
2024-12-28 02:33:02,334: Snapshot:0	Epoch:145	Loss:7.522	translation_Loss:7.522	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.91	Hits@10:48.01	Best:26.91
2024-12-28 02:33:14,068: Snapshot:0	Epoch:146	Loss:7.425	translation_Loss:7.425	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.93	Hits@10:48.0	Best:26.93
2024-12-28 02:33:25,664: Snapshot:0	Epoch:147	Loss:7.296	translation_Loss:7.296	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.95	Hits@10:48.02	Best:26.95
2024-12-28 02:33:37,198: Snapshot:0	Epoch:148	Loss:7.17	translation_Loss:7.17	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.95	Hits@10:48.03	Best:26.95
2024-12-28 02:33:48,771: Snapshot:0	Epoch:149	Loss:7.044	translation_Loss:7.044	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.99	Hits@10:48.06	Best:26.99
2024-12-28 02:34:00,326: Snapshot:0	Epoch:150	Loss:6.985	translation_Loss:6.985	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.01	Hits@10:48.08	Best:27.01
2024-12-28 02:34:11,948: Snapshot:0	Epoch:151	Loss:6.872	translation_Loss:6.872	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.05	Hits@10:48.11	Best:27.05
2024-12-28 02:34:23,541: Snapshot:0	Epoch:152	Loss:6.706	translation_Loss:6.706	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.01	Hits@10:48.07	Best:27.05
2024-12-28 02:34:35,050: Snapshot:0	Epoch:153	Loss:6.624	translation_Loss:6.624	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.99	Hits@10:48.03	Best:27.05
2024-12-28 02:34:46,708: Snapshot:0	Epoch:154	Loss:6.537	translation_Loss:6.537	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.01	Hits@10:48.07	Best:27.05
2024-12-28 02:34:58,268: Snapshot:0	Epoch:155	Loss:6.481	translation_Loss:6.481	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:27.01	Hits@10:48.17	Best:27.05
2024-12-28 02:35:10,387: Early Stopping! Snapshot: 0 Epoch: 156 Best Results: 27.05
2024-12-28 02:35:10,387: Start to training tokens! Snapshot: 0 Epoch: 156 Loss:6.357 MRR:26.99 Best Results: 27.05
Token added to optimizer, embeddings excluded successfully.
Optimizer parameter groups:
Group 0:
 - torch.Size([5, 200]), requires_grad: True
 - torch.Size([5, 200]), requires_grad: True
2024-12-28 02:35:10,387: Snapshot:0	Epoch:156	Loss:6.357	translation_Loss:6.357	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.99	Hits@10:48.15	Best:27.05
2024-12-28 02:35:22,879: Snapshot:0	Epoch:157	Loss:108.047	translation_Loss:103.855	multi_layer_Loss:4.192	MAE_Loss:0.0	decompose_Loss:0.0                                                   	MRR:26.99	Hits@10:48.15	Best:27.05
2024-12-28 02:35:34,673: End of token training: 0 Epoch: 158 Loss:106.843 MRR:26.99 Best Results: 27.05
2024-12-28 02:35:34,674: Snapshot:0	Epoch:158	Loss:106.843	translation_Loss:103.713	multi_layer_Loss:3.13	MAE_Loss:0.0	decompose_Loss:0.0                                                           	MRR:26.99	Hits@10:48.15	Best:27.05
2024-12-28 02:35:34,899: => loading checkpoint './checkpoint/RELATIONrelation_0.00001_512_10000/0model_best.tar'
2024-12-28 02:35:40,116: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2731 | 0.1578 | 0.3451 | 0.413  |  0.4839 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2024-12-28 02:36:17,411: Snapshot:1	Epoch:0	Loss:154.189	translation_Loss:154.146	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.043                                                   	MRR:2.42	Hits@10:7.07	Best:2.42
2024-12-28 02:36:28,651: Snapshot:1	Epoch:1	Loss:149.316	translation_Loss:149.139	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.176                                                   	MRR:2.5	Hits@10:7.2	Best:2.5
2024-12-28 02:36:39,899: Snapshot:1	Epoch:2	Loss:144.604	translation_Loss:144.212	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.392                                                   	MRR:2.58	Hits@10:7.37	Best:2.58
2024-12-28 02:36:51,127: Snapshot:1	Epoch:3	Loss:140.058	translation_Loss:139.39	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.668                                                   	MRR:2.74	Hits@10:7.82	Best:2.74
2024-12-28 02:37:02,349: Snapshot:1	Epoch:4	Loss:135.876	translation_Loss:134.891	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:0.985                                                   	MRR:3.08	Hits@10:8.64	Best:3.08
2024-12-28 02:37:13,613: Snapshot:1	Epoch:5	Loss:131.733	translation_Loss:130.405	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.329                                                   	MRR:3.56	Hits@10:9.89	Best:3.56
2024-12-28 02:37:25,028: Snapshot:1	Epoch:6	Loss:127.83	translation_Loss:126.141	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:1.689                                                   	MRR:4.05	Hits@10:11.11	Best:4.05
2024-12-28 02:37:36,223: Snapshot:1	Epoch:7	Loss:124.154	translation_Loss:122.097	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.057                                                   	MRR:4.49	Hits@10:12.17	Best:4.49
2024-12-28 02:37:47,418: Snapshot:1	Epoch:8	Loss:120.619	translation_Loss:118.192	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.427                                                   	MRR:4.94	Hits@10:13.23	Best:4.94
2024-12-28 02:37:58,735: Snapshot:1	Epoch:9	Loss:117.229	translation_Loss:114.436	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:2.793                                                   	MRR:5.44	Hits@10:14.21	Best:5.44
2024-12-28 02:38:10,000: Snapshot:1	Epoch:10	Loss:114.024	translation_Loss:110.871	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.153                                                   	MRR:5.95	Hits@10:15.28	Best:5.95
2024-12-28 02:38:21,340: Snapshot:1	Epoch:11	Loss:111.011	translation_Loss:107.506	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.505                                                   	MRR:6.44	Hits@10:16.25	Best:6.44
2024-12-28 02:38:32,831: Snapshot:1	Epoch:12	Loss:108.088	translation_Loss:104.24	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:3.847                                                   	MRR:6.87	Hits@10:17.12	Best:6.87
2024-12-28 02:38:44,246: Snapshot:1	Epoch:13	Loss:105.307	translation_Loss:101.129	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.178                                                   	MRR:7.26	Hits@10:17.95	Best:7.26
2024-12-28 02:38:55,983: Snapshot:1	Epoch:14	Loss:102.646	translation_Loss:98.145	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.5                                                   	MRR:7.63	Hits@10:18.75	Best:7.63
2024-12-28 02:39:07,210: Snapshot:1	Epoch:15	Loss:99.979	translation_Loss:95.166	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:4.812                                                   	MRR:7.99	Hits@10:19.5	Best:7.99
2024-12-28 02:39:18,470: Snapshot:1	Epoch:16	Loss:97.499	translation_Loss:92.385	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.114                                                   	MRR:8.37	Hits@10:20.21	Best:8.37
2024-12-28 02:39:29,843: Snapshot:1	Epoch:17	Loss:95.053	translation_Loss:89.647	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.407                                                   	MRR:8.71	Hits@10:20.91	Best:8.71
2024-12-28 02:39:41,263: Snapshot:1	Epoch:18	Loss:92.687	translation_Loss:86.997	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.69                                                   	MRR:9.09	Hits@10:21.55	Best:9.09
2024-12-28 02:39:52,569: Snapshot:1	Epoch:19	Loss:90.326	translation_Loss:84.365	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:5.962                                                   	MRR:9.45	Hits@10:22.24	Best:9.45
2024-12-28 02:40:03,872: Snapshot:1	Epoch:20	Loss:88.089	translation_Loss:81.866	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.223                                                   	MRR:9.81	Hits@10:22.86	Best:9.81
2024-12-28 02:40:15,273: Snapshot:1	Epoch:21	Loss:85.879	translation_Loss:79.404	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.475                                                   	MRR:10.21	Hits@10:23.52	Best:10.21
2024-12-28 02:40:26,636: Snapshot:1	Epoch:22	Loss:83.667	translation_Loss:76.95	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.717                                                   	MRR:10.61	Hits@10:24.12	Best:10.61
2024-12-28 02:40:38,112: Snapshot:1	Epoch:23	Loss:81.577	translation_Loss:74.627	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:6.95                                                   	MRR:10.97	Hits@10:24.74	Best:10.97
2024-12-28 02:40:49,406: Snapshot:1	Epoch:24	Loss:79.579	translation_Loss:72.409	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.171                                                   	MRR:11.32	Hits@10:25.33	Best:11.32
2024-12-28 02:41:00,700: Snapshot:1	Epoch:25	Loss:77.57	translation_Loss:70.185	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.385                                                   	MRR:11.59	Hits@10:25.84	Best:11.59
2024-12-28 02:41:12,158: Snapshot:1	Epoch:26	Loss:75.644	translation_Loss:68.051	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.592                                                   	MRR:11.89	Hits@10:26.32	Best:11.89
2024-12-28 02:41:23,466: Snapshot:1	Epoch:27	Loss:73.767	translation_Loss:65.977	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.789                                                   	MRR:12.15	Hits@10:26.83	Best:12.15
2024-12-28 02:41:35,301: Snapshot:1	Epoch:28	Loss:71.964	translation_Loss:63.985	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:7.979                                                   	MRR:12.44	Hits@10:27.25	Best:12.44
2024-12-28 02:41:46,596: Snapshot:1	Epoch:29	Loss:70.095	translation_Loss:61.936	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.159                                                   	MRR:12.7	Hits@10:27.64	Best:12.7
2024-12-28 02:41:57,878: Snapshot:1	Epoch:30	Loss:68.404	translation_Loss:60.071	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.333                                                   	MRR:12.91	Hits@10:28.06	Best:12.91
2024-12-28 02:42:09,168: Snapshot:1	Epoch:31	Loss:66.666	translation_Loss:58.166	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.5                                                   	MRR:13.13	Hits@10:28.37	Best:13.13
2024-12-28 02:42:20,546: Snapshot:1	Epoch:32	Loss:64.946	translation_Loss:56.285	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.66                                                   	MRR:13.38	Hits@10:28.73	Best:13.38
2024-12-28 02:42:31,804: Snapshot:1	Epoch:33	Loss:63.335	translation_Loss:54.523	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.812                                                   	MRR:13.64	Hits@10:29.01	Best:13.64
2024-12-28 02:42:43,064: Snapshot:1	Epoch:34	Loss:61.79	translation_Loss:52.833	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:8.957                                                   	MRR:13.89	Hits@10:29.27	Best:13.89
2024-12-28 02:42:54,340: Snapshot:1	Epoch:35	Loss:60.291	translation_Loss:51.196	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.095                                                   	MRR:14.12	Hits@10:29.55	Best:14.12
2024-12-28 02:43:05,539: Snapshot:1	Epoch:36	Loss:58.908	translation_Loss:49.68	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.228                                                   	MRR:14.33	Hits@10:29.86	Best:14.33
2024-12-28 02:43:16,907: Snapshot:1	Epoch:37	Loss:57.388	translation_Loss:48.033	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.355                                                   	MRR:14.56	Hits@10:30.11	Best:14.56
2024-12-28 02:43:28,241: Snapshot:1	Epoch:38	Loss:56.142	translation_Loss:46.668	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.474                                                   	MRR:14.76	Hits@10:30.27	Best:14.76
2024-12-28 02:43:39,455: Snapshot:1	Epoch:39	Loss:54.724	translation_Loss:45.135	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.589                                                   	MRR:14.93	Hits@10:30.5	Best:14.93
2024-12-28 02:43:50,871: Snapshot:1	Epoch:40	Loss:53.518	translation_Loss:43.819	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.699                                                   	MRR:15.14	Hits@10:30.65	Best:15.14
2024-12-28 02:44:02,703: Snapshot:1	Epoch:41	Loss:52.357	translation_Loss:42.557	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.8                                                   	MRR:15.31	Hits@10:30.86	Best:15.31
2024-12-28 02:44:14,075: Snapshot:1	Epoch:42	Loss:51.196	translation_Loss:41.299	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.897                                                   	MRR:15.46	Hits@10:31.08	Best:15.46
2024-12-28 02:44:25,285: Snapshot:1	Epoch:43	Loss:50.106	translation_Loss:40.122	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:9.985                                                   	MRR:15.59	Hits@10:31.27	Best:15.59
2024-12-28 02:44:36,504: Snapshot:1	Epoch:44	Loss:48.996	translation_Loss:38.926	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.069                                                   	MRR:15.75	Hits@10:31.42	Best:15.75
2024-12-28 02:44:47,765: Snapshot:1	Epoch:45	Loss:48.013	translation_Loss:37.865	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.147                                                   	MRR:15.83	Hits@10:31.58	Best:15.83
2024-12-28 02:44:58,958: Snapshot:1	Epoch:46	Loss:47.115	translation_Loss:36.893	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.222                                                   	MRR:15.98	Hits@10:31.75	Best:15.98
2024-12-28 02:45:10,361: Snapshot:1	Epoch:47	Loss:46.077	translation_Loss:35.784	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.293                                                   	MRR:16.06	Hits@10:31.91	Best:16.06
2024-12-28 02:45:21,641: Snapshot:1	Epoch:48	Loss:45.188	translation_Loss:34.833	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.355                                                   	MRR:16.12	Hits@10:32.07	Best:16.12
2024-12-28 02:45:33,032: Snapshot:1	Epoch:49	Loss:44.38	translation_Loss:33.964	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.415                                                   	MRR:16.12	Hits@10:32.13	Best:16.12
2024-12-28 02:45:44,247: Snapshot:1	Epoch:50	Loss:43.642	translation_Loss:33.171	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.471                                                   	MRR:16.2	Hits@10:32.31	Best:16.2
2024-12-28 02:45:55,561: Snapshot:1	Epoch:51	Loss:42.764	translation_Loss:32.244	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.52                                                   	MRR:16.25	Hits@10:32.34	Best:16.25
2024-12-28 02:46:06,780: Snapshot:1	Epoch:52	Loss:42.059	translation_Loss:31.495	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.563                                                   	MRR:16.35	Hits@10:32.43	Best:16.35
2024-12-28 02:46:18,024: Snapshot:1	Epoch:53	Loss:41.328	translation_Loss:30.726	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.603                                                   	MRR:16.32	Hits@10:32.49	Best:16.35
2024-12-28 02:46:29,699: Snapshot:1	Epoch:54	Loss:40.676	translation_Loss:30.037	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.639                                                   	MRR:16.43	Hits@10:32.55	Best:16.43
2024-12-28 02:46:41,142: Snapshot:1	Epoch:55	Loss:40.019	translation_Loss:29.346	multi_layer_Loss:0.0	MAE_Loss:0.0	decompose_Loss:10.673                                                   	MRR:16.43	Hits@10:32.61	Best:16.43
