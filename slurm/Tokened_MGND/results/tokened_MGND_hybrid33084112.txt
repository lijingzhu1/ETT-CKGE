2025-01-06 18:16:35,182: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106181619/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=11, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 3000.0, 800.0, 200000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:16:45,294: Snapshot:0	Epoch:0	Loss:15.447	translation_Loss:15.447	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.03	Hits@10:17.26	Best:7.03
2025-01-06 18:16:52,269: Snapshot:0	Epoch:1	Loss:10.835	translation_Loss:10.835	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.26	Hits@10:30.12	Best:12.26
2025-01-06 18:16:59,075: Snapshot:0	Epoch:2	Loss:7.175	translation_Loss:7.175	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.22	Hits@10:38.85	Best:18.22
2025-01-06 18:17:05,753: Snapshot:0	Epoch:3	Loss:4.244	translation_Loss:4.244	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.34	Hits@10:43.14	Best:22.34
2025-01-06 18:17:12,801: Snapshot:0	Epoch:4	Loss:2.539	translation_Loss:2.539	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.05	Hits@10:44.94	Best:24.05
2025-01-06 18:17:19,484: Snapshot:0	Epoch:5	Loss:1.617	translation_Loss:1.617	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.97	Hits@10:45.66	Best:24.97
2025-01-06 18:17:26,502: Snapshot:0	Epoch:6	Loss:1.102	translation_Loss:1.102	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.53	Hits@10:46.05	Best:25.53
2025-01-06 18:17:33,220: Snapshot:0	Epoch:7	Loss:0.815	translation_Loss:0.815	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.64	Hits@10:46.21	Best:25.64
2025-01-06 18:17:40,218: Snapshot:0	Epoch:8	Loss:0.643	translation_Loss:0.643	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.75	Hits@10:46.5	Best:25.75
2025-01-06 18:17:46,874: Snapshot:0	Epoch:9	Loss:0.539	translation_Loss:0.539	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.89	Hits@10:46.26	Best:25.89
2025-01-06 18:17:53,883: Snapshot:0	Epoch:10	Loss:0.46	translation_Loss:0.46	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.85	Hits@10:46.23	Best:25.89
2025-01-06 18:18:00,542: Snapshot:0	Epoch:11	Loss:0.403	translation_Loss:0.403	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.87	Hits@10:46.39	Best:25.89
2025-01-06 18:18:07,623: Snapshot:0	Epoch:12	Loss:0.357	translation_Loss:0.357	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.7	Hits@10:46.36	Best:25.89
2025-01-06 18:18:14,217: Snapshot:0	Epoch:13	Loss:0.321	translation_Loss:0.321	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.69	Hits@10:46.21	Best:25.89
2025-01-06 18:18:20,809: Early Stopping! Snapshot: 0 Epoch: 14 Best Results: 25.89
2025-01-06 18:18:20,809: Start to training tokens! Snapshot: 0 Epoch: 14 Loss:0.289 MRR:25.79 Best Results: 25.89
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:18:20,810: Snapshot:0	Epoch:14	Loss:0.289	translation_Loss:0.289	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:46.33	Best:25.89
2025-01-06 18:18:28,358: Snapshot:0	Epoch:15	Loss:26.64	translation_Loss:11.827	token_training_loss:14.813	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:46.33	Best:25.89
2025-01-06 18:18:35,065: End of token training: 0 Epoch: 16 Loss:12.164 MRR:25.79 Best Results: 25.89
2025-01-06 18:18:35,065: Snapshot:0	Epoch:16	Loss:12.164	translation_Loss:11.811	token_training_loss:0.353	distillation_Loss:0.0                                                           	MRR:25.79	Hits@10:46.33	Best:25.89
2025-01-06 18:18:35,314: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2025-01-06 18:18:38,348: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2582 | 0.1499 | 0.3162 | 0.3814 |  0.4526 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:18:45,884: Snapshot:1	Epoch:0	Loss:4.996	translation_Loss:4.775	token_training_loss:0.0	distillation_Loss:0.221                                                   	MRR:10.13	Hits@10:18.54	Best:10.13
2025-01-06 18:18:48,474: Snapshot:1	Epoch:1	Loss:3.154	translation_Loss:2.745	token_training_loss:0.0	distillation_Loss:0.408                                                   	MRR:16.7	Hits@10:30.79	Best:16.7
2025-01-06 18:18:51,025: Snapshot:1	Epoch:2	Loss:2.097	translation_Loss:1.633	token_training_loss:0.0	distillation_Loss:0.464                                                   	MRR:20.78	Hits@10:36.86	Best:20.78
2025-01-06 18:18:53,589: Snapshot:1	Epoch:3	Loss:1.528	translation_Loss:1.099	token_training_loss:0.0	distillation_Loss:0.429                                                   	MRR:23.15	Hits@10:41.32	Best:23.15
2025-01-06 18:18:56,218: Snapshot:1	Epoch:4	Loss:1.195	translation_Loss:0.829	token_training_loss:0.0	distillation_Loss:0.367                                                   	MRR:24.85	Hits@10:44.97	Best:24.85
2025-01-06 18:18:58,889: Snapshot:1	Epoch:5	Loss:1.011	translation_Loss:0.694	token_training_loss:0.0	distillation_Loss:0.317                                                   	MRR:26.43	Hits@10:47.94	Best:26.43
2025-01-06 18:19:01,478: Snapshot:1	Epoch:6	Loss:0.894	translation_Loss:0.609	token_training_loss:0.0	distillation_Loss:0.285                                                   	MRR:27.49	Hits@10:48.97	Best:27.49
2025-01-06 18:19:04,401: Snapshot:1	Epoch:7	Loss:0.814	translation_Loss:0.549	token_training_loss:0.0	distillation_Loss:0.265                                                   	MRR:28.42	Hits@10:49.71	Best:28.42
2025-01-06 18:19:06,990: Snapshot:1	Epoch:8	Loss:0.762	translation_Loss:0.51	token_training_loss:0.0	distillation_Loss:0.252                                                   	MRR:28.75	Hits@10:50.19	Best:28.75
2025-01-06 18:19:09,557: Snapshot:1	Epoch:9	Loss:0.72	translation_Loss:0.478	token_training_loss:0.0	distillation_Loss:0.242                                                   	MRR:29.0	Hits@10:50.83	Best:29.0
2025-01-06 18:19:12,148: Snapshot:1	Epoch:10	Loss:0.687	translation_Loss:0.453	token_training_loss:0.0	distillation_Loss:0.234                                                   	MRR:29.36	Hits@10:50.72	Best:29.36
2025-01-06 18:19:14,809: Snapshot:1	Epoch:11	Loss:0.662	translation_Loss:0.435	token_training_loss:0.0	distillation_Loss:0.227                                                   	MRR:29.61	Hits@10:50.87	Best:29.61
2025-01-06 18:19:17,421: Snapshot:1	Epoch:12	Loss:0.639	translation_Loss:0.418	token_training_loss:0.0	distillation_Loss:0.221                                                   	MRR:29.81	Hits@10:51.21	Best:29.81
2025-01-06 18:19:20,327: Snapshot:1	Epoch:13	Loss:0.626	translation_Loss:0.409	token_training_loss:0.0	distillation_Loss:0.217                                                   	MRR:29.82	Hits@10:51.43	Best:29.82
2025-01-06 18:19:22,941: Snapshot:1	Epoch:14	Loss:0.605	translation_Loss:0.391	token_training_loss:0.0	distillation_Loss:0.214                                                   	MRR:29.93	Hits@10:51.43	Best:29.93
2025-01-06 18:19:25,575: Snapshot:1	Epoch:15	Loss:0.584	translation_Loss:0.377	token_training_loss:0.0	distillation_Loss:0.207                                                   	MRR:30.04	Hits@10:51.44	Best:30.04
2025-01-06 18:19:28,158: Snapshot:1	Epoch:16	Loss:0.577	translation_Loss:0.373	token_training_loss:0.0	distillation_Loss:0.203                                                   	MRR:30.06	Hits@10:51.44	Best:30.06
2025-01-06 18:19:30,850: Snapshot:1	Epoch:17	Loss:0.567	translation_Loss:0.365	token_training_loss:0.0	distillation_Loss:0.202                                                   	MRR:30.13	Hits@10:51.56	Best:30.13
2025-01-06 18:19:33,460: Snapshot:1	Epoch:18	Loss:0.552	translation_Loss:0.351	token_training_loss:0.0	distillation_Loss:0.201                                                   	MRR:30.17	Hits@10:51.69	Best:30.17
2025-01-06 18:19:36,403: Snapshot:1	Epoch:19	Loss:0.55	translation_Loss:0.351	token_training_loss:0.0	distillation_Loss:0.198                                                   	MRR:30.24	Hits@10:51.72	Best:30.24
2025-01-06 18:19:38,981: Snapshot:1	Epoch:20	Loss:0.544	translation_Loss:0.348	token_training_loss:0.0	distillation_Loss:0.196                                                   	MRR:30.33	Hits@10:51.72	Best:30.33
2025-01-06 18:19:41,559: Snapshot:1	Epoch:21	Loss:0.535	translation_Loss:0.341	token_training_loss:0.0	distillation_Loss:0.194                                                   	MRR:30.26	Hits@10:51.69	Best:30.33
2025-01-06 18:19:44,105: Snapshot:1	Epoch:22	Loss:0.529	translation_Loss:0.337	token_training_loss:0.0	distillation_Loss:0.192                                                   	MRR:30.49	Hits@10:51.68	Best:30.49
2025-01-06 18:19:46,613: Snapshot:1	Epoch:23	Loss:0.524	translation_Loss:0.332	token_training_loss:0.0	distillation_Loss:0.192                                                   	MRR:30.41	Hits@10:51.94	Best:30.49
2025-01-06 18:19:49,153: Snapshot:1	Epoch:24	Loss:0.525	translation_Loss:0.337	token_training_loss:0.0	distillation_Loss:0.188                                                   	MRR:30.39	Hits@10:52.11	Best:30.49
2025-01-06 18:19:52,072: Snapshot:1	Epoch:25	Loss:0.512	translation_Loss:0.323	token_training_loss:0.0	distillation_Loss:0.189                                                   	MRR:30.48	Hits@10:52.07	Best:30.49
2025-01-06 18:19:54,572: Snapshot:1	Epoch:26	Loss:0.519	translation_Loss:0.331	token_training_loss:0.0	distillation_Loss:0.187                                                   	MRR:30.43	Hits@10:52.24	Best:30.49
2025-01-06 18:19:57,149: Snapshot:1	Epoch:27	Loss:0.512	translation_Loss:0.324	token_training_loss:0.0	distillation_Loss:0.188                                                   	MRR:30.54	Hits@10:52.01	Best:30.54
2025-01-06 18:19:59,739: Snapshot:1	Epoch:28	Loss:0.508	translation_Loss:0.32	token_training_loss:0.0	distillation_Loss:0.188                                                   	MRR:30.48	Hits@10:51.83	Best:30.54
2025-01-06 18:20:02,356: Snapshot:1	Epoch:29	Loss:0.504	translation_Loss:0.318	token_training_loss:0.0	distillation_Loss:0.186                                                   	MRR:30.62	Hits@10:51.69	Best:30.62
2025-01-06 18:20:05,004: Snapshot:1	Epoch:30	Loss:0.501	translation_Loss:0.317	token_training_loss:0.0	distillation_Loss:0.185                                                   	MRR:30.64	Hits@10:51.74	Best:30.64
2025-01-06 18:20:07,902: Snapshot:1	Epoch:31	Loss:0.496	translation_Loss:0.313	token_training_loss:0.0	distillation_Loss:0.183                                                   	MRR:30.68	Hits@10:51.93	Best:30.68
2025-01-06 18:20:10,488: Snapshot:1	Epoch:32	Loss:0.494	translation_Loss:0.312	token_training_loss:0.0	distillation_Loss:0.182                                                   	MRR:30.38	Hits@10:51.84	Best:30.68
2025-01-06 18:20:13,002: Snapshot:1	Epoch:33	Loss:0.494	translation_Loss:0.311	token_training_loss:0.0	distillation_Loss:0.183                                                   	MRR:30.37	Hits@10:51.99	Best:30.68
2025-01-06 18:20:15,580: Snapshot:1	Epoch:34	Loss:0.492	translation_Loss:0.309	token_training_loss:0.0	distillation_Loss:0.183                                                   	MRR:30.5	Hits@10:52.16	Best:30.68
2025-01-06 18:20:18,154: Snapshot:1	Epoch:35	Loss:0.493	translation_Loss:0.311	token_training_loss:0.0	distillation_Loss:0.182                                                   	MRR:30.6	Hits@10:52.42	Best:30.68
2025-01-06 18:20:20,743: Early Stopping! Snapshot: 1 Epoch: 36 Best Results: 30.68
2025-01-06 18:20:20,743: Start to training tokens! Snapshot: 1 Epoch: 36 Loss:0.492 MRR:30.6 Best Results: 30.68
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:20:20,743: Snapshot:1	Epoch:36	Loss:0.492	translation_Loss:0.311	token_training_loss:0.0	distillation_Loss:0.181                                                   	MRR:30.6	Hits@10:52.08	Best:30.68
2025-01-06 18:20:23,291: Snapshot:1	Epoch:37	Loss:16.529	translation_Loss:4.543	token_training_loss:11.986	distillation_Loss:0.0                                                   	MRR:30.6	Hits@10:52.08	Best:30.68
2025-01-06 18:20:26,106: End of token training: 1 Epoch: 38 Loss:7.32 MRR:30.6 Best Results: 30.68
2025-01-06 18:20:26,106: Snapshot:1	Epoch:38	Loss:7.32	translation_Loss:4.536	token_training_loss:2.784	distillation_Loss:0.0                                                           	MRR:30.6	Hits@10:52.08	Best:30.68
2025-01-06 18:20:26,360: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2025-01-06 18:20:30,375: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2591 | 0.1503 | 0.3179 | 0.3834 |  0.4562 |
|     1      | 0.299  | 0.1907 | 0.351  | 0.419  |  0.5113 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:20:49,781: Snapshot:2	Epoch:0	Loss:16.236	translation_Loss:15.191	token_training_loss:0.0	distillation_Loss:1.045                                                   	MRR:14.2	Hits@10:29.51	Best:14.2
2025-01-06 18:21:00,923: Snapshot:2	Epoch:1	Loss:7.568	translation_Loss:6.067	token_training_loss:0.0	distillation_Loss:1.501                                                   	MRR:19.2	Hits@10:36.9	Best:19.2
2025-01-06 18:21:12,413: Snapshot:2	Epoch:2	Loss:5.063	translation_Loss:3.702	token_training_loss:0.0	distillation_Loss:1.361                                                   	MRR:21.02	Hits@10:38.19	Best:21.02
2025-01-06 18:21:23,859: Snapshot:2	Epoch:3	Loss:4.144	translation_Loss:2.914	token_training_loss:0.0	distillation_Loss:1.23                                                   	MRR:21.49	Hits@10:38.76	Best:21.49
2025-01-06 18:21:35,054: Snapshot:2	Epoch:4	Loss:3.755	translation_Loss:2.6	token_training_loss:0.0	distillation_Loss:1.155                                                   	MRR:21.88	Hits@10:38.98	Best:21.88
2025-01-06 18:21:46,511: Snapshot:2	Epoch:5	Loss:3.571	translation_Loss:2.455	token_training_loss:0.0	distillation_Loss:1.117                                                   	MRR:21.91	Hits@10:39.03	Best:21.91
2025-01-06 18:21:58,012: Snapshot:2	Epoch:6	Loss:3.45	translation_Loss:2.354	token_training_loss:0.0	distillation_Loss:1.095                                                   	MRR:21.81	Hits@10:39.03	Best:21.91
2025-01-06 18:22:09,488: Snapshot:2	Epoch:7	Loss:3.39	translation_Loss:2.303	token_training_loss:0.0	distillation_Loss:1.086                                                   	MRR:21.86	Hits@10:38.97	Best:21.91
2025-01-06 18:22:20,595: Snapshot:2	Epoch:8	Loss:3.354	translation_Loss:2.269	token_training_loss:0.0	distillation_Loss:1.085                                                   	MRR:22.08	Hits@10:39.16	Best:22.08
2025-01-06 18:22:32,053: Snapshot:2	Epoch:9	Loss:3.31	translation_Loss:2.235	token_training_loss:0.0	distillation_Loss:1.075                                                   	MRR:22.1	Hits@10:39.2	Best:22.1
2025-01-06 18:22:43,421: Snapshot:2	Epoch:10	Loss:3.296	translation_Loss:2.222	token_training_loss:0.0	distillation_Loss:1.074                                                   	MRR:21.99	Hits@10:39.14	Best:22.1
2025-01-06 18:22:54,444: Snapshot:2	Epoch:11	Loss:3.273	translation_Loss:2.201	token_training_loss:0.0	distillation_Loss:1.072                                                   	MRR:21.93	Hits@10:39.18	Best:22.1
2025-01-06 18:23:06,012: Snapshot:2	Epoch:12	Loss:3.259	translation_Loss:2.186	token_training_loss:0.0	distillation_Loss:1.073                                                   	MRR:21.94	Hits@10:39.32	Best:22.1
2025-01-06 18:23:17,315: Snapshot:2	Epoch:13	Loss:3.244	translation_Loss:2.172	token_training_loss:0.0	distillation_Loss:1.072                                                   	MRR:22.02	Hits@10:39.22	Best:22.1
2025-01-06 18:23:28,409: Early Stopping! Snapshot: 2 Epoch: 14 Best Results: 22.1
2025-01-06 18:23:28,409: Start to training tokens! Snapshot: 2 Epoch: 14 Loss:3.221 MRR:22.04 Best Results: 22.1
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:23:28,410: Snapshot:2	Epoch:14	Loss:3.221	translation_Loss:2.155	token_training_loss:0.0	distillation_Loss:1.066                                                   	MRR:22.04	Hits@10:39.29	Best:22.1
2025-01-06 18:23:39,678: Snapshot:2	Epoch:15	Loss:32.812	translation_Loss:18.098	token_training_loss:14.713	distillation_Loss:0.0                                                   	MRR:22.04	Hits@10:39.29	Best:22.1
2025-01-06 18:23:50,847: End of token training: 2 Epoch: 16 Loss:18.215 MRR:22.04 Best Results: 22.1
2025-01-06 18:23:50,847: Snapshot:2	Epoch:16	Loss:18.215	translation_Loss:18.092	token_training_loss:0.123	distillation_Loss:0.0                                                           	MRR:22.04	Hits@10:39.29	Best:22.1
2025-01-06 18:23:51,096: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2025-01-06 18:23:59,794: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2571 | 0.1444 | 0.3153 | 0.3826 |  0.4625 |
|     1      | 0.2797 | 0.1705 | 0.3293 | 0.3958 |  0.4875 |
|     2      | 0.2194 | 0.132  | 0.2514 | 0.3094 |  0.3882 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:24:22,467: Snapshot:3	Epoch:0	Loss:14.685	translation_Loss:13.906	token_training_loss:0.0	distillation_Loss:0.779                                                   	MRR:16.31	Hits@10:32.92	Best:16.31
2025-01-06 18:24:36,286: Snapshot:3	Epoch:1	Loss:5.421	translation_Loss:4.026	token_training_loss:0.0	distillation_Loss:1.395                                                   	MRR:20.61	Hits@10:38.62	Best:20.61
2025-01-06 18:24:49,770: Snapshot:3	Epoch:2	Loss:3.562	translation_Loss:2.137	token_training_loss:0.0	distillation_Loss:1.425                                                   	MRR:21.38	Hits@10:39.74	Best:21.38
2025-01-06 18:25:03,634: Snapshot:3	Epoch:3	Loss:3.0	translation_Loss:1.63	token_training_loss:0.0	distillation_Loss:1.37                                                   	MRR:21.62	Hits@10:40.39	Best:21.62
2025-01-06 18:25:17,626: Snapshot:3	Epoch:4	Loss:2.784	translation_Loss:1.444	token_training_loss:0.0	distillation_Loss:1.34                                                   	MRR:21.85	Hits@10:40.4	Best:21.85
2025-01-06 18:25:31,464: Snapshot:3	Epoch:5	Loss:2.655	translation_Loss:1.331	token_training_loss:0.0	distillation_Loss:1.324                                                   	MRR:22.03	Hits@10:40.93	Best:22.03
2025-01-06 18:25:45,234: Snapshot:3	Epoch:6	Loss:2.59	translation_Loss:1.279	token_training_loss:0.0	distillation_Loss:1.31                                                   	MRR:22.15	Hits@10:40.67	Best:22.15
2025-01-06 18:25:58,654: Snapshot:3	Epoch:7	Loss:2.524	translation_Loss:1.23	token_training_loss:0.0	distillation_Loss:1.293                                                   	MRR:22.25	Hits@10:40.97	Best:22.25
2025-01-06 18:26:12,535: Snapshot:3	Epoch:8	Loss:2.501	translation_Loss:1.214	token_training_loss:0.0	distillation_Loss:1.287                                                   	MRR:22.16	Hits@10:41.03	Best:22.25
2025-01-06 18:26:26,395: Snapshot:3	Epoch:9	Loss:2.48	translation_Loss:1.19	token_training_loss:0.0	distillation_Loss:1.289                                                   	MRR:22.36	Hits@10:41.08	Best:22.36
2025-01-06 18:26:40,207: Snapshot:3	Epoch:10	Loss:2.46	translation_Loss:1.176	token_training_loss:0.0	distillation_Loss:1.284                                                   	MRR:22.15	Hits@10:40.8	Best:22.36
2025-01-06 18:26:53,881: Snapshot:3	Epoch:11	Loss:2.454	translation_Loss:1.171	token_training_loss:0.0	distillation_Loss:1.283                                                   	MRR:22.1	Hits@10:40.89	Best:22.36
2025-01-06 18:27:07,272: Snapshot:3	Epoch:12	Loss:2.429	translation_Loss:1.149	token_training_loss:0.0	distillation_Loss:1.28                                                   	MRR:22.2	Hits@10:40.76	Best:22.36
2025-01-06 18:27:21,026: Snapshot:3	Epoch:13	Loss:2.427	translation_Loss:1.15	token_training_loss:0.0	distillation_Loss:1.277                                                   	MRR:22.18	Hits@10:40.76	Best:22.36
2025-01-06 18:27:34,961: Early Stopping! Snapshot: 3 Epoch: 14 Best Results: 22.36
2025-01-06 18:27:34,961: Start to training tokens! Snapshot: 3 Epoch: 14 Loss:2.421 MRR:22.21 Best Results: 22.36
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:27:34,961: Snapshot:3	Epoch:14	Loss:2.421	translation_Loss:1.145	token_training_loss:0.0	distillation_Loss:1.275                                                   	MRR:22.21	Hits@10:40.87	Best:22.36
2025-01-06 18:27:48,431: Snapshot:3	Epoch:15	Loss:32.675	translation_Loss:18.069	token_training_loss:14.606	distillation_Loss:0.0                                                   	MRR:22.21	Hits@10:40.87	Best:22.36
2025-01-06 18:28:01,993: End of token training: 3 Epoch: 16 Loss:18.14 MRR:22.21 Best Results: 22.36
2025-01-06 18:28:01,994: Snapshot:3	Epoch:16	Loss:18.14	translation_Loss:18.071	token_training_loss:0.069	distillation_Loss:0.0                                                           	MRR:22.21	Hits@10:40.87	Best:22.36
2025-01-06 18:28:02,239: => loading checkpoint './checkpoint/HYBRID/3model_best.tar'
2025-01-06 18:28:16,619: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2545 | 0.1504 | 0.3035 | 0.3691 |  0.451  |
|     1      | 0.2743 | 0.1725 | 0.3131 | 0.3784 |  0.4756 |
|     2      | 0.2107 | 0.1231 | 0.2392 | 0.2996 |  0.3819 |
|     3      | 0.2224 | 0.1243 | 0.2631 | 0.3272 |  0.4092 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:28:28,387: Snapshot:4	Epoch:0	Loss:7.599	translation_Loss:6.182	token_training_loss:0.0	distillation_Loss:1.417                                                   	MRR:9.89	Hits@10:20.49	Best:9.89
2025-01-06 18:28:33,975: Snapshot:4	Epoch:1	Loss:5.497	translation_Loss:4.631	token_training_loss:0.0	distillation_Loss:0.866                                                   	MRR:15.44	Hits@10:28.7	Best:15.44
2025-01-06 18:28:39,442: Snapshot:4	Epoch:2	Loss:4.512	translation_Loss:3.716	token_training_loss:0.0	distillation_Loss:0.796                                                   	MRR:18.59	Hits@10:32.24	Best:18.59
2025-01-06 18:28:44,933: Snapshot:4	Epoch:3	Loss:3.808	translation_Loss:3.092	token_training_loss:0.0	distillation_Loss:0.716                                                   	MRR:20.61	Hits@10:34.63	Best:20.61
2025-01-06 18:28:50,808: Snapshot:4	Epoch:4	Loss:3.315	translation_Loss:2.662	token_training_loss:0.0	distillation_Loss:0.653                                                   	MRR:21.64	Hits@10:35.23	Best:21.64
2025-01-06 18:28:56,271: Snapshot:4	Epoch:5	Loss:2.999	translation_Loss:2.381	token_training_loss:0.0	distillation_Loss:0.618                                                   	MRR:22.04	Hits@10:35.53	Best:22.04
2025-01-06 18:29:01,886: Snapshot:4	Epoch:6	Loss:2.82	translation_Loss:2.228	token_training_loss:0.0	distillation_Loss:0.593                                                   	MRR:22.19	Hits@10:35.56	Best:22.19
2025-01-06 18:29:07,772: Snapshot:4	Epoch:7	Loss:2.733	translation_Loss:2.155	token_training_loss:0.0	distillation_Loss:0.578                                                   	MRR:22.27	Hits@10:35.65	Best:22.27
2025-01-06 18:29:13,280: Snapshot:4	Epoch:8	Loss:2.666	translation_Loss:2.102	token_training_loss:0.0	distillation_Loss:0.564                                                   	MRR:22.33	Hits@10:35.6	Best:22.33
2025-01-06 18:29:18,729: Snapshot:4	Epoch:9	Loss:2.639	translation_Loss:2.086	token_training_loss:0.0	distillation_Loss:0.552                                                   	MRR:22.32	Hits@10:35.4	Best:22.33
2025-01-06 18:29:24,534: Snapshot:4	Epoch:10	Loss:2.621	translation_Loss:2.077	token_training_loss:0.0	distillation_Loss:0.544                                                   	MRR:22.42	Hits@10:35.61	Best:22.42
2025-01-06 18:29:29,998: Snapshot:4	Epoch:11	Loss:2.597	translation_Loss:2.062	token_training_loss:0.0	distillation_Loss:0.534                                                   	MRR:22.39	Hits@10:35.41	Best:22.42
2025-01-06 18:29:35,656: Snapshot:4	Epoch:12	Loss:2.591	translation_Loss:2.064	token_training_loss:0.0	distillation_Loss:0.527                                                   	MRR:22.47	Hits@10:35.58	Best:22.47
2025-01-06 18:29:41,413: Snapshot:4	Epoch:13	Loss:2.583	translation_Loss:2.059	token_training_loss:0.0	distillation_Loss:0.525                                                   	MRR:22.42	Hits@10:35.56	Best:22.47
2025-01-06 18:29:46,826: Snapshot:4	Epoch:14	Loss:2.591	translation_Loss:2.068	token_training_loss:0.0	distillation_Loss:0.523                                                   	MRR:22.37	Hits@10:35.48	Best:22.47
2025-01-06 18:29:52,241: Snapshot:4	Epoch:15	Loss:2.577	translation_Loss:2.059	token_training_loss:0.0	distillation_Loss:0.518                                                   	MRR:22.33	Hits@10:35.38	Best:22.47
2025-01-06 18:29:58,054: Snapshot:4	Epoch:16	Loss:2.576	translation_Loss:2.057	token_training_loss:0.0	distillation_Loss:0.518                                                   	MRR:22.23	Hits@10:35.47	Best:22.47
2025-01-06 18:30:03,586: Early Stopping! Snapshot: 4 Epoch: 17 Best Results: 22.47
2025-01-06 18:30:03,586: Start to training tokens! Snapshot: 4 Epoch: 17 Loss:2.573 MRR:22.35 Best Results: 22.47
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:30:03,586: Snapshot:4	Epoch:17	Loss:2.573	translation_Loss:2.058	token_training_loss:0.0	distillation_Loss:0.515                                                   	MRR:22.35	Hits@10:35.37	Best:22.47
2025-01-06 18:30:09,103: Snapshot:4	Epoch:18	Loss:23.308	translation_Loss:9.711	token_training_loss:13.597	distillation_Loss:0.0                                                   	MRR:22.35	Hits@10:35.37	Best:22.47
2025-01-06 18:30:14,804: End of token training: 4 Epoch: 19 Loss:10.46 MRR:22.35 Best Results: 22.47
2025-01-06 18:30:14,804: Snapshot:4	Epoch:19	Loss:10.46	translation_Loss:9.708	token_training_loss:0.752	distillation_Loss:0.0                                                           	MRR:22.35	Hits@10:35.37	Best:22.47
2025-01-06 18:30:15,051: => loading checkpoint './checkpoint/HYBRID/4model_best.tar'
2025-01-06 18:30:32,017: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2437 | 0.1361 | 0.2954 | 0.3647 |  0.4487 |
|     1      | 0.271  | 0.1678 | 0.3099 | 0.3788 |  0.4751 |
|     2      | 0.2087 | 0.1204 | 0.2376 | 0.2979 |  0.3819 |
|     3      | 0.2192 | 0.1201 | 0.2612 | 0.3268 |  0.4079 |
|     4      | 0.2222 | 0.1528 | 0.2494 | 0.2934 |  0.3551 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 18:30:32,020: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2582 | 0.1499 | 0.3162 | 0.3814 |  0.4526 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2591 | 0.1503 | 0.3179 | 0.3834 |  0.4562 |
|     1      | 0.299  | 0.1907 | 0.351  | 0.419  |  0.5113 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2571 | 0.1444 | 0.3153 | 0.3826 |  0.4625 |
|     1      | 0.2797 | 0.1705 | 0.3293 | 0.3958 |  0.4875 |
|     2      | 0.2194 | 0.132  | 0.2514 | 0.3094 |  0.3882 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2545 | 0.1504 | 0.3035 | 0.3691 |  0.451  |
|     1      | 0.2743 | 0.1725 | 0.3131 | 0.3784 |  0.4756 |
|     2      | 0.2107 | 0.1231 | 0.2392 | 0.2996 |  0.3819 |
|     3      | 0.2224 | 0.1243 | 0.2631 | 0.3272 |  0.4092 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2437 | 0.1361 | 0.2954 | 0.3647 |  0.4487 |
|     1      | 0.271  | 0.1678 | 0.3099 | 0.3788 |  0.4751 |
|     2      | 0.2087 | 0.1204 | 0.2376 | 0.2979 |  0.3819 |
|     3      | 0.2192 | 0.1201 | 0.2612 | 0.3268 |  0.4079 |
|     4      | 0.2222 | 0.1528 | 0.2494 | 0.2934 |  0.3551 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 18:30:32,020: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 119.88230466842651 |   0.258   |     0.15     |    0.316     |     0.453     |
|    1     | 106.44827938079834 |    0.27   |    0.161     |    0.327     |     0.471     |
|    2     | 196.04136967658997 |    0.24   |    0.141     |    0.283     |     0.426     |
|    3     | 236.64031672477722 |   0.229   |    0.133     |    0.268     |     0.414     |
|    4     |  115.567307472229  |   0.225   |    0.131     |    0.263     |     0.406     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 18:30:32,020: Sum_Training_Time:774.579577922821
2025-01-06 18:30:32,020: Every_Training_Time:[119.88230466842651, 106.44827938079834, 196.04136967658997, 236.64031672477722, 115.567307472229]
2025-01-06 18:30:32,021: Forward transfer: 0.045375 Backward transfer: -0.014099999999999988
2025-01-06 18:30:51,610: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106183037/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=22, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 3000.0, 800.0, 200000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:31:01,879: Snapshot:0	Epoch:0	Loss:15.391	translation_Loss:15.391	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.24	Hits@10:17.71	Best:7.24
2025-01-06 18:31:08,940: Snapshot:0	Epoch:1	Loss:10.766	translation_Loss:10.766	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.57	Hits@10:31.22	Best:12.57
2025-01-06 18:31:15,775: Snapshot:0	Epoch:2	Loss:7.102	translation_Loss:7.102	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.7	Hits@10:39.29	Best:18.7
2025-01-06 18:31:22,500: Snapshot:0	Epoch:3	Loss:4.213	translation_Loss:4.213	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.7	Hits@10:43.31	Best:22.7
2025-01-06 18:31:29,600: Snapshot:0	Epoch:4	Loss:2.536	translation_Loss:2.536	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.34	Hits@10:44.93	Best:24.34
2025-01-06 18:31:36,282: Snapshot:0	Epoch:5	Loss:1.611	translation_Loss:1.611	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.05	Hits@10:45.55	Best:25.05
2025-01-06 18:31:43,332: Snapshot:0	Epoch:6	Loss:1.098	translation_Loss:1.098	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.48	Hits@10:45.89	Best:25.48
2025-01-06 18:31:49,996: Snapshot:0	Epoch:7	Loss:0.819	translation_Loss:0.819	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.8	Hits@10:46.23	Best:25.8
2025-01-06 18:31:57,026: Snapshot:0	Epoch:8	Loss:0.64	translation_Loss:0.64	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.97	Hits@10:46.26	Best:25.97
2025-01-06 18:32:03,773: Snapshot:0	Epoch:9	Loss:0.525	translation_Loss:0.525	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.05	Hits@10:46.25	Best:26.05
2025-01-06 18:32:10,859: Snapshot:0	Epoch:10	Loss:0.45	translation_Loss:0.45	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.96	Hits@10:46.18	Best:26.05
2025-01-06 18:32:17,515: Snapshot:0	Epoch:11	Loss:0.39	translation_Loss:0.39	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.07	Hits@10:46.08	Best:26.07
2025-01-06 18:32:24,606: Snapshot:0	Epoch:12	Loss:0.344	translation_Loss:0.344	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.09	Hits@10:46.01	Best:26.09
2025-01-06 18:32:31,304: Snapshot:0	Epoch:13	Loss:0.309	translation_Loss:0.309	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:26.0	Hits@10:45.99	Best:26.09
2025-01-06 18:32:37,944: Snapshot:0	Epoch:14	Loss:0.28	translation_Loss:0.28	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.93	Hits@10:46.03	Best:26.09
2025-01-06 18:32:44,932: Snapshot:0	Epoch:15	Loss:0.265	translation_Loss:0.265	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.83	Hits@10:45.63	Best:26.09
2025-01-06 18:32:51,566: Snapshot:0	Epoch:16	Loss:0.24	translation_Loss:0.24	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.9	Hits@10:45.97	Best:26.09
2025-01-06 18:32:58,573: Early Stopping! Snapshot: 0 Epoch: 17 Best Results: 26.09
2025-01-06 18:32:58,573: Start to training tokens! Snapshot: 0 Epoch: 17 Loss:0.225 MRR:25.96 Best Results: 26.09
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:32:58,574: Snapshot:0	Epoch:17	Loss:0.225	translation_Loss:0.225	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.96	Hits@10:46.08	Best:26.09
2025-01-06 18:33:05,852: Snapshot:0	Epoch:18	Loss:26.716	translation_Loss:11.673	token_training_loss:15.043	distillation_Loss:0.0                                                   	MRR:25.96	Hits@10:46.08	Best:26.09
2025-01-06 18:33:12,887: End of token training: 0 Epoch: 19 Loss:12.063 MRR:25.96 Best Results: 26.09
2025-01-06 18:33:12,887: Snapshot:0	Epoch:19	Loss:12.063	translation_Loss:11.68	token_training_loss:0.383	distillation_Loss:0.0                                                           	MRR:25.96	Hits@10:46.08	Best:26.09
2025-01-06 18:33:13,132: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2025-01-06 18:33:15,920: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2585 | 0.1514 | 0.3151 | 0.3783 |  0.4537 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:33:23,464: Snapshot:1	Epoch:0	Loss:4.926	translation_Loss:4.707	token_training_loss:0.0	distillation_Loss:0.219                                                   	MRR:10.32	Hits@10:18.93	Best:10.32
2025-01-06 18:33:26,145: Snapshot:1	Epoch:1	Loss:3.052	translation_Loss:2.65	token_training_loss:0.0	distillation_Loss:0.402                                                   	MRR:17.05	Hits@10:30.92	Best:17.05
2025-01-06 18:33:28,731: Snapshot:1	Epoch:2	Loss:2.001	translation_Loss:1.552	token_training_loss:0.0	distillation_Loss:0.449                                                   	MRR:20.99	Hits@10:36.96	Best:20.99
2025-01-06 18:33:31,382: Snapshot:1	Epoch:3	Loss:1.417	translation_Loss:1.008	token_training_loss:0.0	distillation_Loss:0.409                                                   	MRR:23.38	Hits@10:40.92	Best:23.38
2025-01-06 18:33:33,992: Snapshot:1	Epoch:4	Loss:1.098	translation_Loss:0.753	token_training_loss:0.0	distillation_Loss:0.345                                                   	MRR:25.06	Hits@10:43.84	Best:25.06
2025-01-06 18:33:36,689: Snapshot:1	Epoch:5	Loss:0.914	translation_Loss:0.621	token_training_loss:0.0	distillation_Loss:0.293                                                   	MRR:25.92	Hits@10:46.16	Best:25.92
2025-01-06 18:33:39,730: Snapshot:1	Epoch:6	Loss:0.804	translation_Loss:0.543	token_training_loss:0.0	distillation_Loss:0.26                                                   	MRR:26.59	Hits@10:47.54	Best:26.59
2025-01-06 18:33:42,357: Snapshot:1	Epoch:7	Loss:0.733	translation_Loss:0.493	token_training_loss:0.0	distillation_Loss:0.24                                                   	MRR:27.23	Hits@10:48.18	Best:27.23
2025-01-06 18:33:45,002: Snapshot:1	Epoch:8	Loss:0.687	translation_Loss:0.459	token_training_loss:0.0	distillation_Loss:0.228                                                   	MRR:27.72	Hits@10:49.02	Best:27.72
2025-01-06 18:33:47,637: Snapshot:1	Epoch:9	Loss:0.647	translation_Loss:0.427	token_training_loss:0.0	distillation_Loss:0.22                                                   	MRR:27.86	Hits@10:49.44	Best:27.86
2025-01-06 18:33:50,296: Snapshot:1	Epoch:10	Loss:0.618	translation_Loss:0.407	token_training_loss:0.0	distillation_Loss:0.211                                                   	MRR:28.3	Hits@10:49.64	Best:28.3
2025-01-06 18:33:52,885: Snapshot:1	Epoch:11	Loss:0.588	translation_Loss:0.381	token_training_loss:0.0	distillation_Loss:0.206                                                   	MRR:28.57	Hits@10:50.02	Best:28.57
2025-01-06 18:33:55,797: Snapshot:1	Epoch:12	Loss:0.571	translation_Loss:0.371	token_training_loss:0.0	distillation_Loss:0.2                                                   	MRR:28.87	Hits@10:50.0	Best:28.87
2025-01-06 18:33:58,410: Snapshot:1	Epoch:13	Loss:0.553	translation_Loss:0.355	token_training_loss:0.0	distillation_Loss:0.197                                                   	MRR:29.2	Hits@10:50.37	Best:29.2
2025-01-06 18:34:20,232: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106183406/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=33, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 3000.0, 800.0, 200000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:34:48,948: Namespace(batch_size='3072', contrast_loss_weight=0.1, data_path='./data/HYBRID/', dataset='HYBRID', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250106183434/HYBRID', logger=<RootLogger root (INFO)>, margin=8.0, multi_distill_num=3, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=5, predict_result=False, random_seed=44, record=False, reply_loss_weight=0.1, save_path='./checkpoint/HYBRID', score_distill_weight=1, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[10000.0, 3000.0, 800.0, 200000.0], token_num=5, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-06 18:34:59,031: Snapshot:0	Epoch:0	Loss:15.438	translation_Loss:15.438	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:7.07	Hits@10:17.42	Best:7.07
2025-01-06 18:35:06,207: Snapshot:0	Epoch:1	Loss:10.885	translation_Loss:10.885	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.38	Hits@10:31.2	Best:12.38
2025-01-06 18:35:12,850: Snapshot:0	Epoch:2	Loss:7.189	translation_Loss:7.189	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.76	Hits@10:39.36	Best:18.76
2025-01-06 18:35:19,590: Snapshot:0	Epoch:3	Loss:4.27	translation_Loss:4.27	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.8	Hits@10:43.09	Best:22.8
2025-01-06 18:35:26,722: Snapshot:0	Epoch:4	Loss:2.564	translation_Loss:2.564	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.49	Hits@10:44.46	Best:24.49
2025-01-06 18:35:33,475: Snapshot:0	Epoch:5	Loss:1.615	translation_Loss:1.615	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.23	Hits@10:45.54	Best:25.23
2025-01-06 18:35:40,515: Snapshot:0	Epoch:6	Loss:1.106	translation_Loss:1.106	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.62	Hits@10:46.0	Best:25.62
2025-01-06 18:35:47,198: Snapshot:0	Epoch:7	Loss:0.819	translation_Loss:0.819	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.85	Hits@10:46.07	Best:25.85
2025-01-06 18:35:54,183: Snapshot:0	Epoch:8	Loss:0.65	translation_Loss:0.65	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.87	Hits@10:45.99	Best:25.87
2025-01-06 18:36:00,922: Snapshot:0	Epoch:9	Loss:0.532	translation_Loss:0.532	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.92	Hits@10:45.95	Best:25.92
2025-01-06 18:36:07,999: Snapshot:0	Epoch:10	Loss:0.459	translation_Loss:0.459	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.96	Hits@10:46.09	Best:25.96
2025-01-06 18:36:14,660: Snapshot:0	Epoch:11	Loss:0.402	translation_Loss:0.402	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.87	Hits@10:45.93	Best:25.96
2025-01-06 18:36:21,670: Snapshot:0	Epoch:12	Loss:0.363	translation_Loss:0.363	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.83	Hits@10:45.87	Best:25.96
2025-01-06 18:36:28,320: Snapshot:0	Epoch:13	Loss:0.323	translation_Loss:0.323	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.83	Hits@10:46.17	Best:25.96
2025-01-06 18:36:35,000: Snapshot:0	Epoch:14	Loss:0.294	translation_Loss:0.294	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.69	Hits@10:45.98	Best:25.96
2025-01-06 18:36:41,954: Early Stopping! Snapshot: 0 Epoch: 15 Best Results: 25.96
2025-01-06 18:36:41,954: Start to training tokens! Snapshot: 0 Epoch: 15 Loss:0.27 MRR:25.79 Best Results: 25.96
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:36:41,955: Snapshot:0	Epoch:15	Loss:0.27	translation_Loss:0.27	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:45.94	Best:25.96
2025-01-06 18:36:49,116: Snapshot:0	Epoch:16	Loss:26.379	translation_Loss:11.687	token_training_loss:14.692	distillation_Loss:0.0                                                   	MRR:25.79	Hits@10:45.94	Best:25.96
2025-01-06 18:36:56,088: End of token training: 0 Epoch: 17 Loss:12.065 MRR:25.79 Best Results: 25.96
2025-01-06 18:36:56,088: Snapshot:0	Epoch:17	Loss:12.065	translation_Loss:11.681	token_training_loss:0.384	distillation_Loss:0.0                                                           	MRR:25.79	Hits@10:45.94	Best:25.96
2025-01-06 18:36:56,336: => loading checkpoint './checkpoint/HYBRID/0model_best.tar'
2025-01-06 18:36:59,012: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2583 | 0.1505 | 0.3147 | 0.3779 |  0.453  |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:37:06,541: Snapshot:1	Epoch:0	Loss:4.987	translation_Loss:4.767	token_training_loss:0.0	distillation_Loss:0.22                                                   	MRR:9.96	Hits@10:17.74	Best:9.96
2025-01-06 18:37:09,130: Snapshot:1	Epoch:1	Loss:3.13	translation_Loss:2.726	token_training_loss:0.0	distillation_Loss:0.405                                                   	MRR:16.78	Hits@10:30.44	Best:16.78
2025-01-06 18:37:11,766: Snapshot:1	Epoch:2	Loss:2.078	translation_Loss:1.623	token_training_loss:0.0	distillation_Loss:0.455                                                   	MRR:21.04	Hits@10:36.57	Best:21.04
2025-01-06 18:37:14,335: Snapshot:1	Epoch:3	Loss:1.503	translation_Loss:1.086	token_training_loss:0.0	distillation_Loss:0.417                                                   	MRR:23.09	Hits@10:40.49	Best:23.09
2025-01-06 18:37:17,238: Snapshot:1	Epoch:4	Loss:1.183	translation_Loss:0.828	token_training_loss:0.0	distillation_Loss:0.355                                                   	MRR:24.66	Hits@10:43.84	Best:24.66
2025-01-06 18:37:19,883: Snapshot:1	Epoch:5	Loss:0.987	translation_Loss:0.682	token_training_loss:0.0	distillation_Loss:0.306                                                   	MRR:26.03	Hits@10:46.72	Best:26.03
2025-01-06 18:37:22,439: Snapshot:1	Epoch:6	Loss:0.873	translation_Loss:0.598	token_training_loss:0.0	distillation_Loss:0.275                                                   	MRR:27.04	Hits@10:47.84	Best:27.04
2025-01-06 18:37:25,056: Snapshot:1	Epoch:7	Loss:0.799	translation_Loss:0.544	token_training_loss:0.0	distillation_Loss:0.254                                                   	MRR:27.76	Hits@10:48.8	Best:27.76
2025-01-06 18:37:27,678: Snapshot:1	Epoch:8	Loss:0.74	translation_Loss:0.497	token_training_loss:0.0	distillation_Loss:0.243                                                   	MRR:28.39	Hits@10:49.59	Best:28.39
2025-01-06 18:37:30,315: Snapshot:1	Epoch:9	Loss:0.704	translation_Loss:0.472	token_training_loss:0.0	distillation_Loss:0.232                                                   	MRR:28.74	Hits@10:50.06	Best:28.74
2025-01-06 18:37:33,251: Snapshot:1	Epoch:10	Loss:0.674	translation_Loss:0.449	token_training_loss:0.0	distillation_Loss:0.224                                                   	MRR:28.99	Hits@10:50.24	Best:28.99
2025-01-06 18:37:35,870: Snapshot:1	Epoch:11	Loss:0.644	translation_Loss:0.425	token_training_loss:0.0	distillation_Loss:0.218                                                   	MRR:29.24	Hits@10:50.49	Best:29.24
2025-01-06 18:37:38,455: Snapshot:1	Epoch:12	Loss:0.626	translation_Loss:0.413	token_training_loss:0.0	distillation_Loss:0.213                                                   	MRR:29.43	Hits@10:50.63	Best:29.43
2025-01-06 18:37:41,037: Snapshot:1	Epoch:13	Loss:0.605	translation_Loss:0.397	token_training_loss:0.0	distillation_Loss:0.208                                                   	MRR:29.71	Hits@10:50.46	Best:29.71
2025-01-06 18:37:43,636: Snapshot:1	Epoch:14	Loss:0.59	translation_Loss:0.386	token_training_loss:0.0	distillation_Loss:0.204                                                   	MRR:29.95	Hits@10:50.66	Best:29.95
2025-01-06 18:37:46,164: Snapshot:1	Epoch:15	Loss:0.581	translation_Loss:0.381	token_training_loss:0.0	distillation_Loss:0.2                                                   	MRR:29.89	Hits@10:50.79	Best:29.95
2025-01-06 18:37:49,146: Snapshot:1	Epoch:16	Loss:0.559	translation_Loss:0.363	token_training_loss:0.0	distillation_Loss:0.195                                                   	MRR:30.08	Hits@10:50.78	Best:30.08
2025-01-06 18:37:51,687: Snapshot:1	Epoch:17	Loss:0.547	translation_Loss:0.355	token_training_loss:0.0	distillation_Loss:0.192                                                   	MRR:30.01	Hits@10:50.59	Best:30.08
2025-01-06 18:37:54,238: Snapshot:1	Epoch:18	Loss:0.542	translation_Loss:0.351	token_training_loss:0.0	distillation_Loss:0.191                                                   	MRR:29.83	Hits@10:50.63	Best:30.08
2025-01-06 18:37:56,856: Snapshot:1	Epoch:19	Loss:0.535	translation_Loss:0.344	token_training_loss:0.0	distillation_Loss:0.191                                                   	MRR:30.09	Hits@10:50.48	Best:30.09
2025-01-06 18:37:59,517: Snapshot:1	Epoch:20	Loss:0.523	translation_Loss:0.336	token_training_loss:0.0	distillation_Loss:0.187                                                   	MRR:30.27	Hits@10:50.93	Best:30.27
2025-01-06 18:38:02,064: Snapshot:1	Epoch:21	Loss:0.52	translation_Loss:0.333	token_training_loss:0.0	distillation_Loss:0.186                                                   	MRR:30.24	Hits@10:50.96	Best:30.27
2025-01-06 18:38:04,915: Snapshot:1	Epoch:22	Loss:0.508	translation_Loss:0.324	token_training_loss:0.0	distillation_Loss:0.184                                                   	MRR:30.05	Hits@10:50.75	Best:30.27
2025-01-06 18:38:07,466: Snapshot:1	Epoch:23	Loss:0.506	translation_Loss:0.325	token_training_loss:0.0	distillation_Loss:0.181                                                   	MRR:30.23	Hits@10:50.97	Best:30.27
2025-01-06 18:38:10,044: Snapshot:1	Epoch:24	Loss:0.502	translation_Loss:0.321	token_training_loss:0.0	distillation_Loss:0.181                                                   	MRR:30.33	Hits@10:51.11	Best:30.33
2025-01-06 18:38:12,632: Snapshot:1	Epoch:25	Loss:0.497	translation_Loss:0.317	token_training_loss:0.0	distillation_Loss:0.18                                                   	MRR:30.38	Hits@10:51.19	Best:30.38
2025-01-06 18:38:15,216: Snapshot:1	Epoch:26	Loss:0.495	translation_Loss:0.314	token_training_loss:0.0	distillation_Loss:0.18                                                   	MRR:30.41	Hits@10:51.27	Best:30.41
2025-01-06 18:38:17,741: Snapshot:1	Epoch:27	Loss:0.491	translation_Loss:0.311	token_training_loss:0.0	distillation_Loss:0.18                                                   	MRR:30.33	Hits@10:51.5	Best:30.41
2025-01-06 18:38:20,318: Snapshot:1	Epoch:28	Loss:0.49	translation_Loss:0.313	token_training_loss:0.0	distillation_Loss:0.177                                                   	MRR:30.5	Hits@10:51.32	Best:30.5
2025-01-06 18:38:23,153: Snapshot:1	Epoch:29	Loss:0.488	translation_Loss:0.313	token_training_loss:0.0	distillation_Loss:0.176                                                   	MRR:30.46	Hits@10:51.35	Best:30.5
2025-01-06 18:38:25,674: Snapshot:1	Epoch:30	Loss:0.485	translation_Loss:0.308	token_training_loss:0.0	distillation_Loss:0.177                                                   	MRR:30.41	Hits@10:51.16	Best:30.5
2025-01-06 18:38:28,188: Snapshot:1	Epoch:31	Loss:0.482	translation_Loss:0.307	token_training_loss:0.0	distillation_Loss:0.175                                                   	MRR:30.33	Hits@10:50.93	Best:30.5
2025-01-06 18:38:30,750: Snapshot:1	Epoch:32	Loss:0.48	translation_Loss:0.307	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:30.25	Hits@10:51.32	Best:30.5
2025-01-06 18:38:33,266: Early Stopping! Snapshot: 1 Epoch: 33 Best Results: 30.5
2025-01-06 18:38:33,266: Start to training tokens! Snapshot: 1 Epoch: 33 Loss:0.477 MRR:30.27 Best Results: 30.5
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:38:33,266: Snapshot:1	Epoch:33	Loss:0.477	translation_Loss:0.303	token_training_loss:0.0	distillation_Loss:0.173                                                   	MRR:30.27	Hits@10:51.27	Best:30.5
2025-01-06 18:38:35,748: Snapshot:1	Epoch:34	Loss:16.497	translation_Loss:4.516	token_training_loss:11.981	distillation_Loss:0.0                                                   	MRR:30.27	Hits@10:51.27	Best:30.5
2025-01-06 18:38:38,545: End of token training: 1 Epoch: 35 Loss:7.109 MRR:30.27 Best Results: 30.5
2025-01-06 18:38:38,545: Snapshot:1	Epoch:35	Loss:7.109	translation_Loss:4.525	token_training_loss:2.584	distillation_Loss:0.0                                                           	MRR:30.27	Hits@10:51.27	Best:30.5
2025-01-06 18:38:38,793: => loading checkpoint './checkpoint/HYBRID/1model_best.tar'
2025-01-06 18:38:42,778: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2598 | 0.1521 | 0.3164 | 0.3811 |  0.4551 |
|     1      | 0.2975 | 0.1928 | 0.343  | 0.4128 |  0.5073 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:39:02,318: Snapshot:2	Epoch:0	Loss:16.211	translation_Loss:15.172	token_training_loss:0.0	distillation_Loss:1.04                                                   	MRR:14.05	Hits@10:29.09	Best:14.05
2025-01-06 18:39:13,481: Snapshot:2	Epoch:1	Loss:7.4	translation_Loss:5.903	token_training_loss:0.0	distillation_Loss:1.497                                                   	MRR:19.69	Hits@10:37.01	Best:19.69
2025-01-06 18:39:24,914: Snapshot:2	Epoch:2	Loss:4.883	translation_Loss:3.551	token_training_loss:0.0	distillation_Loss:1.332                                                   	MRR:21.0	Hits@10:38.18	Best:21.0
2025-01-06 18:39:36,399: Snapshot:2	Epoch:3	Loss:3.972	translation_Loss:2.774	token_training_loss:0.0	distillation_Loss:1.198                                                   	MRR:21.7	Hits@10:38.71	Best:21.7
2025-01-06 18:39:47,834: Snapshot:2	Epoch:4	Loss:3.605	translation_Loss:2.476	token_training_loss:0.0	distillation_Loss:1.129                                                   	MRR:21.69	Hits@10:38.74	Best:21.7
2025-01-06 18:39:58,987: Snapshot:2	Epoch:5	Loss:3.442	translation_Loss:2.351	token_training_loss:0.0	distillation_Loss:1.091                                                   	MRR:22.03	Hits@10:38.72	Best:22.03
2025-01-06 18:40:10,807: Snapshot:2	Epoch:6	Loss:3.359	translation_Loss:2.286	token_training_loss:0.0	distillation_Loss:1.073                                                   	MRR:21.82	Hits@10:38.87	Best:22.03
2025-01-06 18:40:22,192: Snapshot:2	Epoch:7	Loss:3.286	translation_Loss:2.226	token_training_loss:0.0	distillation_Loss:1.06                                                   	MRR:21.84	Hits@10:38.7	Best:22.03
2025-01-06 18:40:33,305: Snapshot:2	Epoch:8	Loss:3.245	translation_Loss:2.186	token_training_loss:0.0	distillation_Loss:1.059                                                   	MRR:21.78	Hits@10:38.81	Best:22.03
2025-01-06 18:40:44,706: Snapshot:2	Epoch:9	Loss:3.206	translation_Loss:2.156	token_training_loss:0.0	distillation_Loss:1.049                                                   	MRR:21.82	Hits@10:38.6	Best:22.03
2025-01-06 18:40:56,155: Early Stopping! Snapshot: 2 Epoch: 10 Best Results: 22.03
2025-01-06 18:40:56,155: Start to training tokens! Snapshot: 2 Epoch: 10 Loss:3.177 MRR:21.86 Best Results: 22.03
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:40:56,155: Snapshot:2	Epoch:10	Loss:3.177	translation_Loss:2.129	token_training_loss:0.0	distillation_Loss:1.048                                                   	MRR:21.86	Hits@10:38.84	Best:22.03
2025-01-06 18:41:07,278: Snapshot:2	Epoch:11	Loss:32.808	translation_Loss:18.133	token_training_loss:14.675	distillation_Loss:0.0                                                   	MRR:21.86	Hits@10:38.84	Best:22.03
2025-01-06 18:41:18,619: End of token training: 2 Epoch: 12 Loss:18.261 MRR:21.86 Best Results: 22.03
2025-01-06 18:41:18,619: Snapshot:2	Epoch:12	Loss:18.261	translation_Loss:18.136	token_training_loss:0.126	distillation_Loss:0.0                                                           	MRR:21.86	Hits@10:38.84	Best:22.03
2025-01-06 18:41:18,875: => loading checkpoint './checkpoint/HYBRID/2model_best.tar'
2025-01-06 18:41:27,885: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2574 | 0.1476 | 0.3127 | 0.3773 |  0.4585 |
|     1      | 0.2786 | 0.1751 | 0.3204 | 0.3881 |  0.4734 |
|     2      | 0.2179 | 0.1301 | 0.2496 | 0.3088 |  0.3872 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:41:50,851: Snapshot:3	Epoch:0	Loss:14.667	translation_Loss:13.887	token_training_loss:0.0	distillation_Loss:0.779                                                   	MRR:15.96	Hits@10:32.64	Best:15.96
2025-01-06 18:42:04,693: Snapshot:3	Epoch:1	Loss:5.335	translation_Loss:3.941	token_training_loss:0.0	distillation_Loss:1.394                                                   	MRR:20.49	Hits@10:38.53	Best:20.49
2025-01-06 18:42:18,163: Snapshot:3	Epoch:2	Loss:3.484	translation_Loss:2.07	token_training_loss:0.0	distillation_Loss:1.414                                                   	MRR:21.23	Hits@10:39.35	Best:21.23
2025-01-06 18:42:32,069: Snapshot:3	Epoch:3	Loss:2.935	translation_Loss:1.583	token_training_loss:0.0	distillation_Loss:1.351                                                   	MRR:21.62	Hits@10:40.22	Best:21.62
2025-01-06 18:42:45,862: Snapshot:3	Epoch:4	Loss:2.7	translation_Loss:1.385	token_training_loss:0.0	distillation_Loss:1.315                                                   	MRR:21.78	Hits@10:40.25	Best:21.78
2025-01-06 18:42:59,717: Snapshot:3	Epoch:5	Loss:2.584	translation_Loss:1.296	token_training_loss:0.0	distillation_Loss:1.287                                                   	MRR:21.83	Hits@10:40.11	Best:21.83
2025-01-06 18:43:13,556: Snapshot:3	Epoch:6	Loss:2.511	translation_Loss:1.236	token_training_loss:0.0	distillation_Loss:1.275                                                   	MRR:21.91	Hits@10:40.46	Best:21.91
2025-01-06 18:43:27,017: Snapshot:3	Epoch:7	Loss:2.466	translation_Loss:1.203	token_training_loss:0.0	distillation_Loss:1.264                                                   	MRR:22.1	Hits@10:40.35	Best:22.1
2025-01-06 18:43:40,931: Snapshot:3	Epoch:8	Loss:2.442	translation_Loss:1.179	token_training_loss:0.0	distillation_Loss:1.263                                                   	MRR:22.14	Hits@10:40.79	Best:22.14
2025-01-06 18:43:54,704: Snapshot:3	Epoch:9	Loss:2.416	translation_Loss:1.157	token_training_loss:0.0	distillation_Loss:1.258                                                   	MRR:22.03	Hits@10:40.75	Best:22.14
2025-01-06 18:44:08,479: Snapshot:3	Epoch:10	Loss:2.417	translation_Loss:1.158	token_training_loss:0.0	distillation_Loss:1.258                                                   	MRR:22.14	Hits@10:40.58	Best:22.14
2025-01-06 18:44:22,250: Snapshot:3	Epoch:11	Loss:2.4	translation_Loss:1.141	token_training_loss:0.0	distillation_Loss:1.259                                                   	MRR:22.15	Hits@10:40.37	Best:22.15
2025-01-06 18:44:36,123: Snapshot:3	Epoch:12	Loss:2.385	translation_Loss:1.132	token_training_loss:0.0	distillation_Loss:1.253                                                   	MRR:22.15	Hits@10:40.81	Best:22.15
2025-01-06 18:44:49,517: Snapshot:3	Epoch:13	Loss:2.388	translation_Loss:1.128	token_training_loss:0.0	distillation_Loss:1.26                                                   	MRR:22.11	Hits@10:40.42	Best:22.15
2025-01-06 18:45:03,370: Snapshot:3	Epoch:14	Loss:2.383	translation_Loss:1.123	token_training_loss:0.0	distillation_Loss:1.26                                                   	MRR:22.36	Hits@10:40.86	Best:22.36
2025-01-06 18:45:17,199: Snapshot:3	Epoch:15	Loss:2.375	translation_Loss:1.119	token_training_loss:0.0	distillation_Loss:1.256                                                   	MRR:22.1	Hits@10:40.71	Best:22.36
2025-01-06 18:45:30,911: Snapshot:3	Epoch:16	Loss:2.377	translation_Loss:1.117	token_training_loss:0.0	distillation_Loss:1.26                                                   	MRR:22.17	Hits@10:40.53	Best:22.36
2025-01-06 18:45:44,667: Snapshot:3	Epoch:17	Loss:2.375	translation_Loss:1.114	token_training_loss:0.0	distillation_Loss:1.261                                                   	MRR:22.25	Hits@10:40.84	Best:22.36
2025-01-06 18:45:58,113: Snapshot:3	Epoch:18	Loss:2.362	translation_Loss:1.101	token_training_loss:0.0	distillation_Loss:1.261                                                   	MRR:22.15	Hits@10:40.23	Best:22.36
2025-01-06 18:46:12,218: Early Stopping! Snapshot: 3 Epoch: 19 Best Results: 22.36
2025-01-06 18:46:12,219: Start to training tokens! Snapshot: 3 Epoch: 19 Loss:2.364 MRR:22.13 Best Results: 22.36
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:46:12,219: Snapshot:3	Epoch:19	Loss:2.364	translation_Loss:1.105	token_training_loss:0.0	distillation_Loss:1.259                                                   	MRR:22.13	Hits@10:40.51	Best:22.36
2025-01-06 18:46:25,825: Snapshot:3	Epoch:20	Loss:32.754	translation_Loss:18.033	token_training_loss:14.72	distillation_Loss:0.0                                                   	MRR:22.13	Hits@10:40.51	Best:22.36
2025-01-06 18:46:39,418: End of token training: 3 Epoch: 21 Loss:18.125 MRR:22.13 Best Results: 22.36
2025-01-06 18:46:39,419: Snapshot:3	Epoch:21	Loss:18.125	translation_Loss:18.057	token_training_loss:0.068	distillation_Loss:0.0                                                           	MRR:22.13	Hits@10:40.51	Best:22.36
2025-01-06 18:46:39,679: => loading checkpoint './checkpoint/HYBRID/3model_best.tar'
2025-01-06 18:46:54,484: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2549 | 0.1507 | 0.3033 | 0.3675 |  0.4498 |
|     1      | 0.2745 | 0.1741 | 0.312  | 0.3807 |  0.4646 |
|     2      | 0.2052 | 0.1189 | 0.2328 | 0.2931 |  0.3753 |
|     3      | 0.2214 | 0.1244 | 0.2605 | 0.3248 |  0.4066 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-06 18:47:06,299: Snapshot:4	Epoch:0	Loss:7.636	translation_Loss:6.203	token_training_loss:0.0	distillation_Loss:1.433                                                   	MRR:9.25	Hits@10:19.73	Best:9.25
2025-01-06 18:47:11,790: Snapshot:4	Epoch:1	Loss:5.482	translation_Loss:4.597	token_training_loss:0.0	distillation_Loss:0.884                                                   	MRR:16.04	Hits@10:28.66	Best:16.04
2025-01-06 18:47:17,630: Snapshot:4	Epoch:2	Loss:4.477	translation_Loss:3.653	token_training_loss:0.0	distillation_Loss:0.824                                                   	MRR:18.94	Hits@10:32.93	Best:18.94
2025-01-06 18:47:23,182: Snapshot:4	Epoch:3	Loss:3.775	translation_Loss:3.043	token_training_loss:0.0	distillation_Loss:0.732                                                   	MRR:20.89	Hits@10:34.91	Best:20.89
2025-01-06 18:47:28,735: Snapshot:4	Epoch:4	Loss:3.31	translation_Loss:2.646	token_training_loss:0.0	distillation_Loss:0.665                                                   	MRR:21.94	Hits@10:35.28	Best:21.94
2025-01-06 18:47:34,578: Snapshot:4	Epoch:5	Loss:3.012	translation_Loss:2.387	token_training_loss:0.0	distillation_Loss:0.625                                                   	MRR:22.16	Hits@10:35.3	Best:22.16
2025-01-06 18:47:40,076: Snapshot:4	Epoch:6	Loss:2.85	translation_Loss:2.249	token_training_loss:0.0	distillation_Loss:0.601                                                   	MRR:22.26	Hits@10:35.18	Best:22.26
2025-01-06 18:47:45,530: Snapshot:4	Epoch:7	Loss:2.752	translation_Loss:2.173	token_training_loss:0.0	distillation_Loss:0.579                                                   	MRR:22.26	Hits@10:35.3	Best:22.26
2025-01-06 18:47:51,336: Snapshot:4	Epoch:8	Loss:2.707	translation_Loss:2.143	token_training_loss:0.0	distillation_Loss:0.564                                                   	MRR:22.3	Hits@10:35.23	Best:22.3
2025-01-06 18:47:56,784: Snapshot:4	Epoch:9	Loss:2.676	translation_Loss:2.119	token_training_loss:0.0	distillation_Loss:0.557                                                   	MRR:22.26	Hits@10:35.33	Best:22.3
2025-01-06 18:48:02,253: Snapshot:4	Epoch:10	Loss:2.664	translation_Loss:2.115	token_training_loss:0.0	distillation_Loss:0.549                                                   	MRR:22.26	Hits@10:35.3	Best:22.3
2025-01-06 18:48:08,095: Snapshot:4	Epoch:11	Loss:2.645	translation_Loss:2.104	token_training_loss:0.0	distillation_Loss:0.541                                                   	MRR:22.21	Hits@10:35.32	Best:22.3
2025-01-06 18:48:13,500: Snapshot:4	Epoch:12	Loss:2.63	translation_Loss:2.094	token_training_loss:0.0	distillation_Loss:0.536                                                   	MRR:22.28	Hits@10:35.33	Best:22.3
2025-01-06 18:48:18,942: Early Stopping! Snapshot: 4 Epoch: 13 Best Results: 22.3
2025-01-06 18:48:18,942: Start to training tokens! Snapshot: 4 Epoch: 13 Loss:2.631 MRR:22.26 Best Results: 22.3
Token added to optimizer, embeddings excluded successfully.
2025-01-06 18:48:18,942: Snapshot:4	Epoch:13	Loss:2.631	translation_Loss:2.098	token_training_loss:0.0	distillation_Loss:0.533                                                   	MRR:22.26	Hits@10:35.21	Best:22.3
2025-01-06 18:48:24,673: Snapshot:4	Epoch:14	Loss:24.808	translation_Loss:10.006	token_training_loss:14.801	distillation_Loss:0.0                                                   	MRR:22.26	Hits@10:35.21	Best:22.3
2025-01-06 18:48:30,126: End of token training: 4 Epoch: 15 Loss:10.886 MRR:22.26 Best Results: 22.3
2025-01-06 18:48:30,126: Snapshot:4	Epoch:15	Loss:10.886	translation_Loss:10.001	token_training_loss:0.884	distillation_Loss:0.0                                                           	MRR:22.26	Hits@10:35.21	Best:22.3
2025-01-06 18:48:30,377: => loading checkpoint './checkpoint/HYBRID/4model_best.tar'
2025-01-06 18:48:47,777: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2426 | 0.136  | 0.2915 | 0.3575 |  0.4439 |
|     1      | 0.2725 | 0.1717 | 0.3103 | 0.3784 |  0.4656 |
|     2      | 0.2028 | 0.1155 | 0.2311 | 0.2915 |  0.3744 |
|     3      | 0.2183 | 0.1207 | 0.2577 | 0.3226 |  0.4054 |
|     4      | 0.2222 | 0.1561 | 0.2445 | 0.2894 |  0.3526 |
+------------+--------+--------+--------+--------+---------+
2025-01-06 18:48:47,780: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2583 | 0.1505 | 0.3147 | 0.3779 |  0.453  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2598 | 0.1521 | 0.3164 | 0.3811 |  0.4551 |
|     1      | 0.2975 | 0.1928 | 0.343  | 0.4128 |  0.5073 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2574 | 0.1476 | 0.3127 | 0.3773 |  0.4585 |
|     1      | 0.2786 | 0.1751 | 0.3204 | 0.3881 |  0.4734 |
|     2      | 0.2179 | 0.1301 | 0.2496 | 0.3088 |  0.3872 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2549 | 0.1507 | 0.3033 | 0.3675 |  0.4498 |
|     1      | 0.2745 | 0.1741 | 0.312  | 0.3807 |  0.4646 |
|     2      | 0.2052 | 0.1189 | 0.2328 | 0.2931 |  0.3753 |
|     3      | 0.2214 | 0.1244 | 0.2605 | 0.3248 |  0.4066 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2426 | 0.136  | 0.2915 | 0.3575 |  0.4439 |
|     1      | 0.2725 | 0.1717 | 0.3103 | 0.3784 |  0.4656 |
|     2      | 0.2028 | 0.1155 | 0.2311 | 0.2915 |  0.3744 |
|     3      | 0.2183 | 0.1207 | 0.2577 | 0.3226 |  0.4054 |
|     4      | 0.2222 | 0.1561 | 0.2445 | 0.2894 |  0.3526 |
+------------+--------+--------+--------+--------+---------+]
2025-01-06 18:48:47,780: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 127.13973355293274 |   0.258   |     0.15     |    0.315     |     0.453     |
|    1     | 98.21103882789612  |    0.27   |    0.163     |    0.323     |     0.469     |
|    2     | 151.36598825454712 |   0.239   |    0.142     |     0.28     |     0.423     |
|    3     | 305.71523880958557 |   0.227   |    0.132     |    0.265     |      0.41     |
|    4     | 92.99267792701721  |   0.223   |     0.13     |    0.258     |     0.401     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-06 18:48:47,780: Sum_Training_Time:775.4246773719788
2025-01-06 18:48:47,780: Every_Training_Time:[127.13973355293274, 98.21103882789612, 151.36598825454712, 305.71523880958557, 92.99267792701721]
2025-01-06 18:48:47,780: Forward transfer: 0.0453 Backward transfer: -0.014724999999999988
