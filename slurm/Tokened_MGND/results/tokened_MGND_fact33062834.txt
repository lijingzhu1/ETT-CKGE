2025-01-04 19:06:08,532: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250104190532/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[500.0, 10000.0, 8000.0, 15000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-04 19:06:17,794: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.23	Hits@10:13.26	Best:6.23
2025-01-04 19:06:24,339: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:9.68	Hits@10:22.61	Best:9.68
2025-01-04 19:06:30,235: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.91	Hits@10:28.87	Best:12.91
2025-01-04 19:06:36,539: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.77	Hits@10:33.1	Best:15.77
2025-01-04 19:06:42,348: Snapshot:0	Epoch:4	Loss:4.364	translation_Loss:4.364	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.34	Hits@10:36.01	Best:18.34
2025-01-04 19:06:48,164: Snapshot:0	Epoch:5	Loss:3.085	translation_Loss:3.085	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:20.45	Hits@10:37.75	Best:20.45
2025-01-04 19:06:54,509: Snapshot:0	Epoch:6	Loss:2.175	translation_Loss:2.175	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:21.94	Hits@10:38.69	Best:21.94
2025-01-04 19:07:00,439: Snapshot:0	Epoch:7	Loss:1.541	translation_Loss:1.541	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.01	Hits@10:39.41	Best:23.01
2025-01-04 19:07:06,759: Snapshot:0	Epoch:8	Loss:1.096	translation_Loss:1.096	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.68	Hits@10:39.86	Best:23.68
2025-01-04 19:07:12,609: Snapshot:0	Epoch:9	Loss:0.814	translation_Loss:0.814	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.08	Hits@10:40.18	Best:24.08
2025-01-04 19:07:18,488: Snapshot:0	Epoch:10	Loss:0.626	translation_Loss:0.626	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.34	Hits@10:40.26	Best:24.34
2025-01-04 19:07:24,721: Snapshot:0	Epoch:11	Loss:0.494	translation_Loss:0.494	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.4	Hits@10:40.27	Best:24.4
2025-01-04 19:07:30,528: Snapshot:0	Epoch:12	Loss:0.41	translation_Loss:0.41	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.52	Hits@10:40.38	Best:24.52
2025-01-04 19:07:36,794: Snapshot:0	Epoch:13	Loss:0.351	translation_Loss:0.351	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.71	Hits@10:40.38	Best:24.71
2025-01-04 19:07:42,621: Snapshot:0	Epoch:14	Loss:0.311	translation_Loss:0.311	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.78	Hits@10:40.4	Best:24.78
2025-01-04 19:07:48,513: Snapshot:0	Epoch:15	Loss:0.272	translation_Loss:0.272	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.71	Hits@10:40.3	Best:24.78
2025-01-04 19:07:54,774: Snapshot:0	Epoch:16	Loss:0.243	translation_Loss:0.243	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.79	Hits@10:40.43	Best:24.79
2025-01-04 19:08:00,639: Snapshot:0	Epoch:17	Loss:0.224	translation_Loss:0.224	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.77	Hits@10:40.37	Best:24.79
2025-01-04 19:08:06,860: Snapshot:0	Epoch:18	Loss:0.208	translation_Loss:0.208	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.75	Hits@10:40.23	Best:24.79
2025-01-04 19:08:12,776: Snapshot:0	Epoch:19	Loss:0.192	translation_Loss:0.192	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.8	Hits@10:40.22	Best:24.8
2025-01-04 19:08:19,015: Snapshot:0	Epoch:20	Loss:0.18	translation_Loss:0.18	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.78	Hits@10:40.27	Best:24.8
2025-01-04 19:08:24,803: Snapshot:0	Epoch:21	Loss:0.167	translation_Loss:0.167	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.67	Hits@10:40.44	Best:24.8
2025-01-04 19:08:30,698: Early Stopping! Snapshot: 0 Epoch: 22 Best Results: 24.8
2025-01-04 19:08:30,698: Start to training tokens! Snapshot: 0 Epoch: 22 Loss:0.156 MRR:24.67 Best Results: 24.8
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:08:30,699: Snapshot:0	Epoch:22	Loss:0.156	translation_Loss:0.156	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.67	Hits@10:40.13	Best:24.8
2025-01-04 19:08:37,421: Snapshot:0	Epoch:23	Loss:28.268	translation_Loss:12.314	token_training_loss:15.955	distillation_Loss:0.0                                                   	MRR:24.67	Hits@10:40.13	Best:24.8
2025-01-04 19:08:43,334: End of token training: 0 Epoch: 24 Loss:12.646 MRR:24.67 Best Results: 24.8
2025-01-04 19:08:43,334: Snapshot:0	Epoch:24	Loss:12.646	translation_Loss:12.3	token_training_loss:0.346	distillation_Loss:0.0                                                           	MRR:24.67	Hits@10:40.13	Best:24.8
2025-01-04 19:08:43,590: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2025-01-04 19:08:46,044: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2398 | 0.1553 | 0.2796 | 0.3304 |  0.3922 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:08:58,588: Snapshot:1	Epoch:0	Loss:7.307	translation_Loss:6.949	token_training_loss:0.0	distillation_Loss:0.357                                                   	MRR:20.7	Hits@10:34.6	Best:20.7
2025-01-04 19:09:05,234: Snapshot:1	Epoch:1	Loss:3.815	translation_Loss:3.016	token_training_loss:0.0	distillation_Loss:0.8                                                   	MRR:22.44	Hits@10:37.14	Best:22.44
2025-01-04 19:09:11,515: Snapshot:1	Epoch:2	Loss:2.602	translation_Loss:1.563	token_training_loss:0.0	distillation_Loss:1.039                                                   	MRR:23.23	Hits@10:38.21	Best:23.23
2025-01-04 19:09:18,350: Snapshot:1	Epoch:3	Loss:2.199	translation_Loss:1.084	token_training_loss:0.0	distillation_Loss:1.115                                                   	MRR:23.31	Hits@10:38.61	Best:23.31
2025-01-04 19:09:24,583: Snapshot:1	Epoch:4	Loss:2.064	translation_Loss:0.912	token_training_loss:0.0	distillation_Loss:1.152                                                   	MRR:23.39	Hits@10:38.57	Best:23.39
2025-01-04 19:09:30,826: Snapshot:1	Epoch:5	Loss:2.012	translation_Loss:0.843	token_training_loss:0.0	distillation_Loss:1.169                                                   	MRR:23.52	Hits@10:38.84	Best:23.52
2025-01-04 19:09:37,501: Snapshot:1	Epoch:6	Loss:1.978	translation_Loss:0.797	token_training_loss:0.0	distillation_Loss:1.182                                                   	MRR:23.41	Hits@10:38.65	Best:23.52
2025-01-04 19:09:43,711: Snapshot:1	Epoch:7	Loss:1.961	translation_Loss:0.768	token_training_loss:0.0	distillation_Loss:1.193                                                   	MRR:23.28	Hits@10:38.61	Best:23.52
2025-01-04 19:09:50,328: Early Stopping! Snapshot: 1 Epoch: 8 Best Results: 23.52
2025-01-04 19:09:50,328: Start to training tokens! Snapshot: 1 Epoch: 8 Loss:1.961 MRR:23.36 Best Results: 23.52
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:09:50,328: Snapshot:1	Epoch:8	Loss:1.961	translation_Loss:0.758	token_training_loss:0.0	distillation_Loss:1.203                                                   	MRR:23.36	Hits@10:38.58	Best:23.52
2025-01-04 19:09:56,585: Snapshot:1	Epoch:9	Loss:28.845	translation_Loss:13.27	token_training_loss:15.576	distillation_Loss:0.0                                                   	MRR:23.36	Hits@10:38.58	Best:23.52
2025-01-04 19:10:02,960: End of token training: 1 Epoch: 10 Loss:13.616 MRR:23.36 Best Results: 23.52
2025-01-04 19:10:02,960: Snapshot:1	Epoch:10	Loss:13.616	translation_Loss:13.273	token_training_loss:0.342	distillation_Loss:0.0                                                           	MRR:23.36	Hits@10:38.58	Best:23.52
2025-01-04 19:10:03,220: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2025-01-04 19:10:08,905: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2496 | 0.1614 | 0.2888 | 0.3444 |  0.4175 |
|     1      | 0.2355 | 0.1534 | 0.2731 | 0.3245 |  0.3851 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:10:21,592: Snapshot:2	Epoch:0	Loss:5.065	translation_Loss:3.886	token_training_loss:0.0	distillation_Loss:1.18                                                   	MRR:21.43	Hits@10:36.94	Best:21.43
2025-01-04 19:10:28,398: Snapshot:2	Epoch:1	Loss:4.143	translation_Loss:3.045	token_training_loss:0.0	distillation_Loss:1.098                                                   	MRR:21.86	Hits@10:37.3	Best:21.86
2025-01-04 19:10:34,914: Snapshot:2	Epoch:2	Loss:3.748	translation_Loss:2.784	token_training_loss:0.0	distillation_Loss:0.964                                                   	MRR:22.01	Hits@10:37.56	Best:22.01
2025-01-04 19:10:41,773: Snapshot:2	Epoch:3	Loss:3.663	translation_Loss:2.687	token_training_loss:0.0	distillation_Loss:0.976                                                   	MRR:22.01	Hits@10:37.62	Best:22.01
2025-01-04 19:10:48,208: Snapshot:2	Epoch:4	Loss:3.632	translation_Loss:2.675	token_training_loss:0.0	distillation_Loss:0.956                                                   	MRR:22.04	Hits@10:37.51	Best:22.04
2025-01-04 19:10:54,592: Snapshot:2	Epoch:5	Loss:3.623	translation_Loss:2.652	token_training_loss:0.0	distillation_Loss:0.972                                                   	MRR:22.03	Hits@10:37.56	Best:22.04
2025-01-04 19:11:01,410: Snapshot:2	Epoch:6	Loss:3.618	translation_Loss:2.652	token_training_loss:0.0	distillation_Loss:0.966                                                   	MRR:21.93	Hits@10:37.55	Best:22.04
2025-01-04 19:11:07,760: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 22.04
2025-01-04 19:11:07,764: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:3.627 MRR:21.92 Best Results: 22.04
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:11:07,764: Snapshot:2	Epoch:7	Loss:3.627	translation_Loss:2.653	token_training_loss:0.0	distillation_Loss:0.973                                                   	MRR:21.92	Hits@10:37.43	Best:22.04
2025-01-04 19:11:14,444: Snapshot:2	Epoch:8	Loss:30.857	translation_Loss:14.425	token_training_loss:16.432	distillation_Loss:0.0                                                   	MRR:21.92	Hits@10:37.43	Best:22.04
2025-01-04 19:11:20,915: End of token training: 2 Epoch: 9 Loss:14.782 MRR:21.92 Best Results: 22.04
2025-01-04 19:11:20,916: Snapshot:2	Epoch:9	Loss:14.782	translation_Loss:14.421	token_training_loss:0.361	distillation_Loss:0.0                                                           	MRR:21.92	Hits@10:37.43	Best:22.04
2025-01-04 19:11:21,196: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2025-01-04 19:11:29,411: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2494 | 0.1605 | 0.2887 | 0.3452 |  0.418  |
|     1      | 0.2391 | 0.156  | 0.2759 | 0.3296 |  0.3953 |
|     2      | 0.2207 | 0.1382 | 0.256  | 0.3082 |  0.3768 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:11:42,375: Snapshot:3	Epoch:0	Loss:3.49	translation_Loss:2.471	token_training_loss:0.0	distillation_Loss:1.019                                                   	MRR:19.56	Hits@10:37.21	Best:19.56
2025-01-04 19:11:49,192: Snapshot:3	Epoch:1	Loss:2.722	translation_Loss:1.691	token_training_loss:0.0	distillation_Loss:1.031                                                   	MRR:19.64	Hits@10:36.93	Best:19.64
2025-01-04 19:11:55,769: Snapshot:3	Epoch:2	Loss:2.608	translation_Loss:1.679	token_training_loss:0.0	distillation_Loss:0.929                                                   	MRR:19.79	Hits@10:37.32	Best:19.79
2025-01-04 19:12:02,620: Snapshot:3	Epoch:3	Loss:2.57	translation_Loss:1.625	token_training_loss:0.0	distillation_Loss:0.945                                                   	MRR:19.78	Hits@10:37.13	Best:19.79
2025-01-04 19:12:09,043: Snapshot:3	Epoch:4	Loss:2.573	translation_Loss:1.639	token_training_loss:0.0	distillation_Loss:0.934                                                   	MRR:19.74	Hits@10:37.15	Best:19.79
2025-01-04 19:12:15,536: Early Stopping! Snapshot: 3 Epoch: 5 Best Results: 19.79
2025-01-04 19:12:15,536: Start to training tokens! Snapshot: 3 Epoch: 5 Loss:2.57 MRR:19.79 Best Results: 19.79
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:12:15,536: Snapshot:3	Epoch:5	Loss:2.57	translation_Loss:1.625	token_training_loss:0.0	distillation_Loss:0.946                                                   	MRR:19.79	Hits@10:37.14	Best:19.79
2025-01-04 19:12:22,371: Snapshot:3	Epoch:6	Loss:30.498	translation_Loss:13.766	token_training_loss:16.733	distillation_Loss:0.0                                                   	MRR:19.79	Hits@10:37.14	Best:19.79
2025-01-04 19:12:28,784: End of token training: 3 Epoch: 7 Loss:14.128 MRR:19.79 Best Results: 19.79
2025-01-04 19:12:28,784: Snapshot:3	Epoch:7	Loss:14.128	translation_Loss:13.78	token_training_loss:0.347	distillation_Loss:0.0                                                           	MRR:19.79	Hits@10:37.14	Best:19.79
2025-01-04 19:12:29,009: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2025-01-04 19:12:40,484: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.243  | 0.1553 | 0.2786 | 0.3363 |  0.4125 |
|     1      | 0.2352 | 0.1524 | 0.2699 | 0.3246 |  0.3926 |
|     2      | 0.2195 | 0.1351 | 0.2532 | 0.3093 |  0.3853 |
|     3      | 0.2009 | 0.1119 | 0.2343 | 0.2943 |  0.375  |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:12:53,256: Snapshot:4	Epoch:0	Loss:2.295	translation_Loss:1.496	token_training_loss:0.0	distillation_Loss:0.799                                                   	MRR:19.23	Hits@10:41.7	Best:19.23
2025-01-04 19:13:00,196: Snapshot:4	Epoch:1	Loss:1.558	translation_Loss:0.905	token_training_loss:0.0	distillation_Loss:0.653                                                   	MRR:20.05	Hits@10:42.08	Best:20.05
2025-01-04 19:13:06,636: Snapshot:4	Epoch:2	Loss:1.351	translation_Loss:0.762	token_training_loss:0.0	distillation_Loss:0.589                                                   	MRR:20.14	Hits@10:42.05	Best:20.14
2025-01-04 19:13:13,625: Snapshot:4	Epoch:3	Loss:1.325	translation_Loss:0.734	token_training_loss:0.0	distillation_Loss:0.591                                                   	MRR:20.3	Hits@10:42.63	Best:20.3
2025-01-04 19:13:20,059: Snapshot:4	Epoch:4	Loss:1.316	translation_Loss:0.731	token_training_loss:0.0	distillation_Loss:0.584                                                   	MRR:20.2	Hits@10:42.06	Best:20.3
2025-01-04 19:13:26,456: Snapshot:4	Epoch:5	Loss:1.313	translation_Loss:0.722	token_training_loss:0.0	distillation_Loss:0.591                                                   	MRR:20.08	Hits@10:42.23	Best:20.3
2025-01-04 19:13:33,242: Early Stopping! Snapshot: 4 Epoch: 6 Best Results: 20.3
2025-01-04 19:13:33,243: Start to training tokens! Snapshot: 4 Epoch: 6 Loss:1.312 MRR:20.29 Best Results: 20.3
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:13:33,243: Snapshot:4	Epoch:6	Loss:1.312	translation_Loss:0.724	token_training_loss:0.0	distillation_Loss:0.588                                                   	MRR:20.29	Hits@10:42.1	Best:20.3
2025-01-04 19:13:39,772: Snapshot:4	Epoch:7	Loss:27.681	translation_Loss:11.706	token_training_loss:15.975	distillation_Loss:0.0                                                   	MRR:20.29	Hits@10:42.1	Best:20.3
2025-01-04 19:13:46,594: End of token training: 4 Epoch: 8 Loss:12.069 MRR:20.29 Best Results: 20.3
2025-01-04 19:13:46,594: Snapshot:4	Epoch:8	Loss:12.069	translation_Loss:11.718	token_training_loss:0.351	distillation_Loss:0.0                                                           	MRR:20.29	Hits@10:42.1	Best:20.3
2025-01-04 19:13:46,862: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2025-01-04 19:14:01,040: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2396 | 0.1538 | 0.2742 | 0.3303 |  0.4067 |
|     1      | 0.2306 | 0.148  | 0.2653 | 0.3183 |  0.3886 |
|     2      | 0.2161 | 0.1329 | 0.2461 | 0.3025 |  0.3814 |
|     3      | 0.2001 | 0.1109 | 0.2293 | 0.2928 |  0.3794 |
|     4      | 0.2034 | 0.0969 | 0.2336 | 0.3155 |  0.4272 |
+------------+--------+--------+--------+--------+---------+
2025-01-04 19:14:01,042: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2398 | 0.1553 | 0.2796 | 0.3304 |  0.3922 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2496 | 0.1614 | 0.2888 | 0.3444 |  0.4175 |
|     1      | 0.2355 | 0.1534 | 0.2731 | 0.3245 |  0.3851 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2494 | 0.1605 | 0.2887 | 0.3452 |  0.418  |
|     1      | 0.2391 | 0.156  | 0.2759 | 0.3296 |  0.3953 |
|     2      | 0.2207 | 0.1382 | 0.256  | 0.3082 |  0.3768 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.243  | 0.1553 | 0.2786 | 0.3363 |  0.4125 |
|     1      | 0.2352 | 0.1524 | 0.2699 | 0.3246 |  0.3926 |
|     2      | 0.2195 | 0.1351 | 0.2532 | 0.3093 |  0.3853 |
|     3      | 0.2009 | 0.1119 | 0.2343 | 0.2943 |  0.375  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2396 | 0.1538 | 0.2742 | 0.3303 |  0.4067 |
|     1      | 0.2306 | 0.148  | 0.2653 | 0.3183 |  0.3886 |
|     2      | 0.2161 | 0.1329 | 0.2461 | 0.3025 |  0.3814 |
|     3      | 0.2001 | 0.1109 | 0.2293 | 0.2928 |  0.3794 |
|     4      | 0.2034 | 0.0969 | 0.2336 | 0.3155 |  0.4272 |
+------------+--------+--------+--------+--------+---------+]
2025-01-04 19:14:01,043: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 154.80146169662476 |    0.24   |    0.155     |     0.28     |     0.392     |
|    1     | 74.13615012168884  |   0.243   |    0.157     |    0.281     |     0.401     |
|    2     | 68.97984957695007  |   0.236   |    0.152     |    0.274     |     0.397     |
|    3     | 56.11144685745239  |   0.225   |    0.139     |    0.259     |     0.391     |
|    4     | 63.08298659324646  |   0.218   |    0.129     |     0.25     |     0.397     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-04 19:14:01,043: Sum_Training_Time:417.1118948459625
2025-01-04 19:14:01,043: Every_Training_Time:[154.80146169662476, 74.13615012168884, 68.97984957695007, 56.11144685745239, 63.08298659324646]
2025-01-04 19:14:01,043: Forward transfer: 0.175275 Backward transfer: -0.0026250000000000023
2025-01-04 19:14:37,512: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250104191405/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[500.0, 10000.0, 10000.0, 20000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-04 19:14:46,849: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.23	Hits@10:13.25	Best:6.23
2025-01-04 19:14:53,142: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:9.69	Hits@10:22.6	Best:9.69
2025-01-04 19:14:59,127: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.9	Hits@10:28.89	Best:12.9
2025-01-04 19:15:05,550: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.76	Hits@10:33.18	Best:15.76
2025-01-04 19:15:11,522: Snapshot:0	Epoch:4	Loss:4.365	translation_Loss:4.365	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.34	Hits@10:35.97	Best:18.34
2025-01-04 19:15:17,572: Snapshot:0	Epoch:5	Loss:3.085	translation_Loss:3.085	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:20.48	Hits@10:37.67	Best:20.48
2025-01-04 19:15:23,968: Snapshot:0	Epoch:6	Loss:2.174	translation_Loss:2.174	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:21.97	Hits@10:38.76	Best:21.97
2025-01-04 19:15:30,004: Snapshot:0	Epoch:7	Loss:1.542	translation_Loss:1.542	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.96	Hits@10:39.57	Best:22.96
2025-01-04 19:15:36,504: Snapshot:0	Epoch:8	Loss:1.096	translation_Loss:1.096	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.7	Hits@10:39.85	Best:23.7
2025-01-04 19:15:42,520: Snapshot:0	Epoch:9	Loss:0.816	translation_Loss:0.816	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.07	Hits@10:39.98	Best:24.07
2025-01-04 19:15:48,483: Snapshot:0	Epoch:10	Loss:0.628	translation_Loss:0.628	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.31	Hits@10:40.09	Best:24.31
2025-01-04 19:15:54,929: Snapshot:0	Epoch:11	Loss:0.496	translation_Loss:0.496	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.42	Hits@10:40.23	Best:24.42
2025-01-04 19:16:01,012: Snapshot:0	Epoch:12	Loss:0.411	translation_Loss:0.411	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.53	Hits@10:40.27	Best:24.53
2025-01-04 19:16:07,374: Snapshot:0	Epoch:13	Loss:0.349	translation_Loss:0.349	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.66	Hits@10:40.32	Best:24.66
2025-01-04 19:16:13,474: Snapshot:0	Epoch:14	Loss:0.31	translation_Loss:0.31	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.7	Hits@10:40.48	Best:24.7
2025-01-04 19:16:19,524: Snapshot:0	Epoch:15	Loss:0.273	translation_Loss:0.273	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.58	Hits@10:40.42	Best:24.7
2025-01-04 19:16:25,842: Snapshot:0	Epoch:16	Loss:0.245	translation_Loss:0.245	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.63	Hits@10:40.37	Best:24.7
2025-01-04 19:16:31,835: Snapshot:0	Epoch:17	Loss:0.224	translation_Loss:0.224	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.76	Hits@10:40.46	Best:24.76
2025-01-04 19:16:38,224: Snapshot:0	Epoch:18	Loss:0.209	translation_Loss:0.209	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.67	Hits@10:40.33	Best:24.76
2025-01-04 19:16:44,135: Snapshot:0	Epoch:19	Loss:0.191	translation_Loss:0.191	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.7	Hits@10:40.19	Best:24.76
2025-01-04 19:16:50,556: Early Stopping! Snapshot: 0 Epoch: 20 Best Results: 24.76
2025-01-04 19:16:50,556: Start to training tokens! Snapshot: 0 Epoch: 20 Loss:0.18 MRR:24.72 Best Results: 24.76
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:16:50,556: Snapshot:0	Epoch:20	Loss:0.18	translation_Loss:0.18	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.72	Hits@10:40.31	Best:24.76
2025-01-04 19:16:57,037: Snapshot:0	Epoch:21	Loss:28.281	translation_Loss:12.327	token_training_loss:15.955	distillation_Loss:0.0                                                   	MRR:24.72	Hits@10:40.31	Best:24.76
2025-01-04 19:17:03,007: End of token training: 0 Epoch: 22 Loss:12.661 MRR:24.72 Best Results: 24.76
2025-01-04 19:17:03,007: Snapshot:0	Epoch:22	Loss:12.661	translation_Loss:12.316	token_training_loss:0.346	distillation_Loss:0.0                                                           	MRR:24.72	Hits@10:40.31	Best:24.76
2025-01-04 19:17:03,304: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2025-01-04 19:17:05,779: 
+------------+------+--------+--------+--------+---------+
| Snapshot:0 | MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+------+--------+--------+--------+---------+
|     0      | 0.24 | 0.1541 | 0.2814 | 0.3328 |  0.3933 |
+------------+------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:17:18,556: Snapshot:1	Epoch:0	Loss:7.431	translation_Loss:7.071	token_training_loss:0.0	distillation_Loss:0.359                                                   	MRR:20.71	Hits@10:34.57	Best:20.71
2025-01-04 19:17:25,233: Snapshot:1	Epoch:1	Loss:3.901	translation_Loss:3.093	token_training_loss:0.0	distillation_Loss:0.808                                                   	MRR:22.44	Hits@10:37.07	Best:22.44
2025-01-04 19:17:31,586: Snapshot:1	Epoch:2	Loss:2.657	translation_Loss:1.603	token_training_loss:0.0	distillation_Loss:1.055                                                   	MRR:23.16	Hits@10:38.23	Best:23.16
2025-01-04 19:17:38,474: Snapshot:1	Epoch:3	Loss:2.25	translation_Loss:1.113	token_training_loss:0.0	distillation_Loss:1.137                                                   	MRR:23.27	Hits@10:38.5	Best:23.27
2025-01-04 19:17:44,889: Snapshot:1	Epoch:4	Loss:2.103	translation_Loss:0.931	token_training_loss:0.0	distillation_Loss:1.173                                                   	MRR:23.41	Hits@10:38.51	Best:23.41
2025-01-04 19:17:51,211: Snapshot:1	Epoch:5	Loss:2.041	translation_Loss:0.848	token_training_loss:0.0	distillation_Loss:1.192                                                   	MRR:23.33	Hits@10:38.63	Best:23.41
2025-01-04 19:17:58,050: Snapshot:1	Epoch:6	Loss:2.01	translation_Loss:0.803	token_training_loss:0.0	distillation_Loss:1.207                                                   	MRR:23.27	Hits@10:38.54	Best:23.41
2025-01-04 19:18:04,390: Early Stopping! Snapshot: 1 Epoch: 7 Best Results: 23.41
2025-01-04 19:18:04,390: Start to training tokens! Snapshot: 1 Epoch: 7 Loss:2.002 MRR:23.35 Best Results: 23.41
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:18:04,391: Snapshot:1	Epoch:7	Loss:2.002	translation_Loss:0.782	token_training_loss:0.0	distillation_Loss:1.22                                                   	MRR:23.35	Hits@10:38.63	Best:23.41
2025-01-04 19:18:11,117: Snapshot:1	Epoch:8	Loss:28.849	translation_Loss:13.274	token_training_loss:15.576	distillation_Loss:0.0                                                   	MRR:23.35	Hits@10:38.63	Best:23.41
2025-01-04 19:18:17,384: End of token training: 1 Epoch: 9 Loss:13.624 MRR:23.35 Best Results: 23.41
2025-01-04 19:18:17,384: Snapshot:1	Epoch:9	Loss:13.624	translation_Loss:13.282	token_training_loss:0.342	distillation_Loss:0.0                                                           	MRR:23.35	Hits@10:38.63	Best:23.41
2025-01-04 19:18:17,639: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2025-01-04 19:18:23,153: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2501 | 0.1606 | 0.2917 | 0.3468 |  0.4181 |
|     1      | 0.2355 | 0.1524 | 0.2737 | 0.325  |  0.3867 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:18:36,168: Snapshot:2	Epoch:0	Loss:5.228	translation_Loss:4.019	token_training_loss:0.0	distillation_Loss:1.209                                                   	MRR:21.48	Hits@10:37.22	Best:21.48
2025-01-04 19:18:43,103: Snapshot:2	Epoch:1	Loss:4.294	translation_Loss:3.159	token_training_loss:0.0	distillation_Loss:1.134                                                   	MRR:21.87	Hits@10:37.46	Best:21.87
2025-01-04 19:18:49,595: Snapshot:2	Epoch:2	Loss:3.898	translation_Loss:2.901	token_training_loss:0.0	distillation_Loss:0.997                                                   	MRR:21.98	Hits@10:37.67	Best:21.98
2025-01-04 19:18:56,049: Snapshot:2	Epoch:3	Loss:3.801	translation_Loss:2.792	token_training_loss:0.0	distillation_Loss:1.009                                                   	MRR:22.03	Hits@10:37.72	Best:22.03
2025-01-04 19:19:03,020: Snapshot:2	Epoch:4	Loss:3.771	translation_Loss:2.782	token_training_loss:0.0	distillation_Loss:0.989                                                   	MRR:22.05	Hits@10:37.85	Best:22.05
2025-01-04 19:19:09,460: Snapshot:2	Epoch:5	Loss:3.767	translation_Loss:2.768	token_training_loss:0.0	distillation_Loss:0.999                                                   	MRR:22.05	Hits@10:37.61	Best:22.05
2025-01-04 19:19:16,300: Snapshot:2	Epoch:6	Loss:3.761	translation_Loss:2.757	token_training_loss:0.0	distillation_Loss:1.005                                                   	MRR:22.0	Hits@10:37.73	Best:22.05
2025-01-04 19:19:22,809: Early Stopping! Snapshot: 2 Epoch: 7 Best Results: 22.05
2025-01-04 19:19:22,809: Start to training tokens! Snapshot: 2 Epoch: 7 Loss:3.77 MRR:21.97 Best Results: 22.05
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:19:22,810: Snapshot:2	Epoch:7	Loss:3.77	translation_Loss:2.764	token_training_loss:0.0	distillation_Loss:1.005                                                   	MRR:21.97	Hits@10:37.65	Best:22.05
2025-01-04 19:19:29,173: Snapshot:2	Epoch:8	Loss:30.933	translation_Loss:14.501	token_training_loss:16.432	distillation_Loss:0.0                                                   	MRR:21.97	Hits@10:37.65	Best:22.05
2025-01-04 19:19:36,011: End of token training: 2 Epoch: 9 Loss:14.86 MRR:21.97 Best Results: 22.05
2025-01-04 19:19:36,012: Snapshot:2	Epoch:9	Loss:14.86	translation_Loss:14.499	token_training_loss:0.361	distillation_Loss:0.0                                                           	MRR:21.97	Hits@10:37.65	Best:22.05
2025-01-04 19:19:36,283: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2025-01-04 19:19:44,838: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2501 | 0.1603 | 0.2907 | 0.3473 |  0.4194 |
|     1      | 0.2392 | 0.1552 | 0.276  | 0.3297 |  0.3949 |
|     2      |  0.22  | 0.1361 | 0.2568 | 0.3094 |  0.3781 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:19:57,966: Snapshot:3	Epoch:0	Loss:3.692	translation_Loss:2.594	token_training_loss:0.0	distillation_Loss:1.098                                                   	MRR:19.38	Hits@10:36.82	Best:19.38
2025-01-04 19:20:04,754: Snapshot:3	Epoch:1	Loss:3.023	translation_Loss:1.979	token_training_loss:0.0	distillation_Loss:1.044                                                   	MRR:19.44	Hits@10:36.85	Best:19.44
2025-01-04 19:20:12,083: Snapshot:3	Epoch:2	Loss:2.854	translation_Loss:1.922	token_training_loss:0.0	distillation_Loss:0.932                                                   	MRR:19.55	Hits@10:36.89	Best:19.55
2025-01-04 19:20:18,668: Snapshot:3	Epoch:3	Loss:2.838	translation_Loss:1.887	token_training_loss:0.0	distillation_Loss:0.952                                                   	MRR:19.56	Hits@10:37.04	Best:19.56
2025-01-04 19:20:25,665: Snapshot:3	Epoch:4	Loss:2.831	translation_Loss:1.892	token_training_loss:0.0	distillation_Loss:0.939                                                   	MRR:19.61	Hits@10:36.8	Best:19.61
2025-01-04 19:20:32,148: Snapshot:3	Epoch:5	Loss:2.844	translation_Loss:1.883	token_training_loss:0.0	distillation_Loss:0.96                                                   	MRR:19.5	Hits@10:37.02	Best:19.61
2025-01-04 19:20:38,727: Snapshot:3	Epoch:6	Loss:2.83	translation_Loss:1.883	token_training_loss:0.0	distillation_Loss:0.947                                                   	MRR:19.56	Hits@10:37.04	Best:19.61
2025-01-04 19:20:45,679: Snapshot:3	Epoch:7	Loss:2.834	translation_Loss:1.877	token_training_loss:0.0	distillation_Loss:0.957                                                   	MRR:19.73	Hits@10:36.95	Best:19.73
2025-01-04 19:20:52,212: Snapshot:3	Epoch:8	Loss:2.829	translation_Loss:1.882	token_training_loss:0.0	distillation_Loss:0.947                                                   	MRR:19.7	Hits@10:37.15	Best:19.73
2025-01-04 19:20:59,187: Snapshot:3	Epoch:9	Loss:2.835	translation_Loss:1.871	token_training_loss:0.0	distillation_Loss:0.965                                                   	MRR:19.64	Hits@10:37.1	Best:19.73
2025-01-04 19:21:05,636: Early Stopping! Snapshot: 3 Epoch: 10 Best Results: 19.73
2025-01-04 19:21:05,637: Start to training tokens! Snapshot: 3 Epoch: 10 Loss:2.836 MRR:19.7 Best Results: 19.73
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:21:05,637: Snapshot:3	Epoch:10	Loss:2.836	translation_Loss:1.879	token_training_loss:0.0	distillation_Loss:0.957                                                   	MRR:19.7	Hits@10:36.82	Best:19.73
2025-01-04 19:21:12,193: Snapshot:3	Epoch:11	Loss:30.674	translation_Loss:13.942	token_training_loss:16.733	distillation_Loss:0.0                                                   	MRR:19.7	Hits@10:36.82	Best:19.73
2025-01-04 19:21:19,051: End of token training: 3 Epoch: 12 Loss:14.318 MRR:19.7 Best Results: 19.73
2025-01-04 19:21:19,051: Snapshot:3	Epoch:12	Loss:14.318	translation_Loss:13.971	token_training_loss:0.347	distillation_Loss:0.0                                                           	MRR:19.7	Hits@10:36.82	Best:19.73
2025-01-04 19:21:19,324: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2025-01-04 19:21:30,752: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2435 | 0.1549 | 0.2816 | 0.3384 |  0.4139 |
|     1      | 0.2354 | 0.1521 | 0.2705 | 0.3256 |  0.3949 |
|     2      | 0.2191 | 0.1341 | 0.2527 | 0.3103 |  0.3858 |
|     3      | 0.1985 | 0.1103 | 0.2312 | 0.2908 |  0.3703 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:21:43,880: Snapshot:4	Epoch:0	Loss:2.525	translation_Loss:1.624	token_training_loss:0.0	distillation_Loss:0.901                                                   	MRR:18.63	Hits@10:40.73	Best:18.63
2025-01-04 19:21:50,548: Snapshot:4	Epoch:1	Loss:1.807	translation_Loss:1.086	token_training_loss:0.0	distillation_Loss:0.721                                                   	MRR:19.43	Hits@10:41.46	Best:19.43
2025-01-04 19:21:57,103: Snapshot:4	Epoch:2	Loss:1.586	translation_Loss:0.927	token_training_loss:0.0	distillation_Loss:0.659                                                   	MRR:19.53	Hits@10:41.3	Best:19.53
2025-01-04 19:22:04,137: Snapshot:4	Epoch:3	Loss:1.558	translation_Loss:0.9	token_training_loss:0.0	distillation_Loss:0.658                                                   	MRR:19.64	Hits@10:41.54	Best:19.64
2025-01-04 19:22:10,815: Snapshot:4	Epoch:4	Loss:1.541	translation_Loss:0.896	token_training_loss:0.0	distillation_Loss:0.645                                                   	MRR:19.65	Hits@10:41.52	Best:19.65
2025-01-04 19:22:17,785: Snapshot:4	Epoch:5	Loss:1.541	translation_Loss:0.89	token_training_loss:0.0	distillation_Loss:0.651                                                   	MRR:19.69	Hits@10:41.69	Best:19.69
2025-01-04 19:22:24,518: Snapshot:4	Epoch:6	Loss:1.544	translation_Loss:0.897	token_training_loss:0.0	distillation_Loss:0.647                                                   	MRR:19.7	Hits@10:41.54	Best:19.7
2025-01-04 19:22:31,058: Snapshot:4	Epoch:7	Loss:1.539	translation_Loss:0.885	token_training_loss:0.0	distillation_Loss:0.654                                                   	MRR:19.69	Hits@10:41.54	Best:19.7
2025-01-04 19:22:38,038: Snapshot:4	Epoch:8	Loss:1.534	translation_Loss:0.888	token_training_loss:0.0	distillation_Loss:0.647                                                   	MRR:19.56	Hits@10:41.33	Best:19.7
2025-01-04 19:22:44,557: Early Stopping! Snapshot: 4 Epoch: 9 Best Results: 19.7
2025-01-04 19:22:44,558: Start to training tokens! Snapshot: 4 Epoch: 9 Loss:1.538 MRR:19.66 Best Results: 19.7
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:22:44,558: Snapshot:4	Epoch:9	Loss:1.538	translation_Loss:0.878	token_training_loss:0.0	distillation_Loss:0.66                                                   	MRR:19.66	Hits@10:41.33	Best:19.7
2025-01-04 19:22:51,372: Snapshot:4	Epoch:10	Loss:27.91	translation_Loss:11.935	token_training_loss:15.975	distillation_Loss:0.0                                                   	MRR:19.66	Hits@10:41.33	Best:19.7
2025-01-04 19:22:57,859: End of token training: 4 Epoch: 11 Loss:12.273 MRR:19.66 Best Results: 19.7
2025-01-04 19:22:57,859: Snapshot:4	Epoch:11	Loss:12.273	translation_Loss:11.922	token_training_loss:0.351	distillation_Loss:0.0                                                           	MRR:19.66	Hits@10:41.33	Best:19.7
2025-01-04 19:22:58,117: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2025-01-04 19:23:12,245: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2397 | 0.1524 | 0.2769 | 0.3328 |  0.406  |
|     1      | 0.2307 | 0.1478 | 0.264  | 0.3195 |  0.3897 |
|     2      | 0.2148 | 0.1299 | 0.2473 | 0.3047 |  0.3844 |
|     3      | 0.1982 | 0.1094 | 0.2266 | 0.2892 |  0.3767 |
|     4      | 0.1993 | 0.0955 | 0.2288 | 0.3066 |  0.4162 |
+------------+--------+--------+--------+--------+---------+
2025-01-04 19:23:12,248: Final Result:
[+------------+------+--------+--------+--------+---------+
| Snapshot:0 | MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+------+--------+--------+--------+---------+
|     0      | 0.24 | 0.1541 | 0.2814 | 0.3328 |  0.3933 |
+------------+------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2501 | 0.1606 | 0.2917 | 0.3468 |  0.4181 |
|     1      | 0.2355 | 0.1524 | 0.2737 | 0.325  |  0.3867 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2501 | 0.1603 | 0.2907 | 0.3473 |  0.4194 |
|     1      | 0.2392 | 0.1552 | 0.276  | 0.3297 |  0.3949 |
|     2      |  0.22  | 0.1361 | 0.2568 | 0.3094 |  0.3781 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2435 | 0.1549 | 0.2816 | 0.3384 |  0.4139 |
|     1      | 0.2354 | 0.1521 | 0.2705 | 0.3256 |  0.3949 |
|     2      | 0.2191 | 0.1341 | 0.2527 | 0.3103 |  0.3858 |
|     3      | 0.1985 | 0.1103 | 0.2312 | 0.2908 |  0.3703 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2397 | 0.1524 | 0.2769 | 0.3328 |  0.406  |
|     1      | 0.2307 | 0.1478 | 0.264  | 0.3195 |  0.3897 |
|     2      | 0.2148 | 0.1299 | 0.2473 | 0.3047 |  0.3844 |
|     3      | 0.1982 | 0.1094 | 0.2266 | 0.2892 |  0.3767 |
|     4      | 0.1993 | 0.0955 | 0.2288 | 0.3066 |  0.4162 |
+------------+--------+--------+--------+--------+---------+]
2025-01-04 19:23:12,248: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 145.49470782279968 |    0.24   |    0.154     |    0.281     |     0.393     |
|    1     | 68.51886630058289  |   0.243   |    0.157     |    0.283     |     0.402     |
|    2     | 69.94204950332642  |   0.236   |    0.151     |    0.275     |     0.397     |
|    3     | 91.23839092254639  |   0.224   |    0.138     |    0.259     |     0.391     |
|    4     |  84.3771162033081  |   0.217   |    0.127     |    0.249     |     0.395     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-04 19:23:12,248: Sum_Training_Time:459.5711307525635
2025-01-04 19:23:12,248: Every_Training_Time:[145.49470782279968, 68.51886630058289, 69.94204950332642, 91.23839092254639, 84.3771162033081]
2025-01-04 19:23:12,248: Forward transfer: 0.173625 Backward transfer: -0.0026500000000000065
2025-01-04 19:23:48,875: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250104192316/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[1000.0, 10000.0, 10000.0, 20000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-04 19:23:58,026: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.23	Hits@10:13.26	Best:6.23
2025-01-04 19:24:04,287: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:9.69	Hits@10:22.6	Best:9.69
2025-01-04 19:24:10,105: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.9	Hits@10:28.88	Best:12.9
2025-01-04 19:24:16,373: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.75	Hits@10:33.14	Best:15.75
2025-01-04 19:24:22,269: Snapshot:0	Epoch:4	Loss:4.364	translation_Loss:4.364	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.35	Hits@10:35.99	Best:18.35
2025-01-04 19:24:28,162: Snapshot:0	Epoch:5	Loss:3.084	translation_Loss:3.084	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:20.41	Hits@10:37.68	Best:20.41
2025-01-04 19:24:34,429: Snapshot:0	Epoch:6	Loss:2.175	translation_Loss:2.175	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:21.97	Hits@10:38.8	Best:21.97
2025-01-04 19:24:40,297: Snapshot:0	Epoch:7	Loss:1.54	translation_Loss:1.54	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.99	Hits@10:39.4	Best:22.99
2025-01-04 19:24:46,499: Snapshot:0	Epoch:8	Loss:1.094	translation_Loss:1.094	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.76	Hits@10:39.79	Best:23.76
2025-01-04 19:24:52,372: Snapshot:0	Epoch:9	Loss:0.817	translation_Loss:0.817	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.07	Hits@10:39.99	Best:24.07
2025-01-04 19:24:58,315: Snapshot:0	Epoch:10	Loss:0.627	translation_Loss:0.627	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.36	Hits@10:40.16	Best:24.36
2025-01-04 19:25:04,516: Snapshot:0	Epoch:11	Loss:0.497	translation_Loss:0.497	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.4	Hits@10:40.36	Best:24.4
2025-01-04 19:25:10,336: Snapshot:0	Epoch:12	Loss:0.41	translation_Loss:0.41	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.43	Hits@10:40.34	Best:24.43
2025-01-04 19:25:16,569: Snapshot:0	Epoch:13	Loss:0.351	translation_Loss:0.351	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.62	Hits@10:40.28	Best:24.62
2025-01-04 19:25:22,374: Snapshot:0	Epoch:14	Loss:0.31	translation_Loss:0.31	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.63	Hits@10:40.29	Best:24.63
2025-01-04 19:25:28,222: Snapshot:0	Epoch:15	Loss:0.273	translation_Loss:0.273	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.57	Hits@10:40.29	Best:24.63
2025-01-04 19:25:34,584: Snapshot:0	Epoch:16	Loss:0.245	translation_Loss:0.245	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.69	Hits@10:40.27	Best:24.69
2025-01-04 19:25:40,491: Snapshot:0	Epoch:17	Loss:0.224	translation_Loss:0.224	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.73	Hits@10:40.4	Best:24.73
2025-01-04 19:25:46,714: Snapshot:0	Epoch:18	Loss:0.209	translation_Loss:0.209	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.8	Hits@10:40.3	Best:24.8
2025-01-04 19:25:52,623: Snapshot:0	Epoch:19	Loss:0.192	translation_Loss:0.192	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.68	Hits@10:40.19	Best:24.8
2025-01-04 19:25:58,874: Snapshot:0	Epoch:20	Loss:0.181	translation_Loss:0.181	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.69	Hits@10:40.36	Best:24.8
2025-01-04 19:26:04,601: Early Stopping! Snapshot: 0 Epoch: 21 Best Results: 24.8
2025-01-04 19:26:04,601: Start to training tokens! Snapshot: 0 Epoch: 21 Loss:0.167 MRR:24.63 Best Results: 24.8
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:26:04,601: Snapshot:0	Epoch:21	Loss:0.167	translation_Loss:0.167	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.63	Hits@10:40.35	Best:24.8
2025-01-04 19:26:10,991: Snapshot:0	Epoch:22	Loss:28.248	translation_Loss:12.293	token_training_loss:15.955	distillation_Loss:0.0                                                   	MRR:24.63	Hits@10:40.35	Best:24.8
2025-01-04 19:26:17,293: End of token training: 0 Epoch: 23 Loss:12.652 MRR:24.63 Best Results: 24.8
2025-01-04 19:26:17,293: Snapshot:0	Epoch:23	Loss:12.652	translation_Loss:12.306	token_training_loss:0.346	distillation_Loss:0.0                                                           	MRR:24.63	Hits@10:40.35	Best:24.8
2025-01-04 19:26:17,561: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2025-01-04 19:26:20,060: 
+------------+------+--------+--------+--------+---------+
| Snapshot:0 | MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+------+--------+--------+--------+---------+
|     0      | 0.24 | 0.1545 | 0.2823 | 0.3301 |  0.3922 |
+------------+------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:26:32,404: Snapshot:1	Epoch:0	Loss:7.577	translation_Loss:7.039	token_training_loss:0.0	distillation_Loss:0.538                                                   	MRR:20.6	Hits@10:34.61	Best:20.6
2025-01-04 19:26:39,102: Snapshot:1	Epoch:1	Loss:4.432	translation_Loss:3.275	token_training_loss:0.0	distillation_Loss:1.157                                                   	MRR:22.12	Hits@10:36.87	Best:22.12
2025-01-04 19:26:45,389: Snapshot:1	Epoch:2	Loss:3.432	translation_Loss:2.04	token_training_loss:0.0	distillation_Loss:1.392                                                   	MRR:22.73	Hits@10:37.72	Best:22.73
2025-01-04 19:26:52,033: Snapshot:1	Epoch:3	Loss:3.087	translation_Loss:1.613	token_training_loss:0.0	distillation_Loss:1.474                                                   	MRR:23.03	Hits@10:38.2	Best:23.03
2025-01-04 19:26:58,397: Snapshot:1	Epoch:4	Loss:2.958	translation_Loss:1.453	token_training_loss:0.0	distillation_Loss:1.505                                                   	MRR:23.04	Hits@10:38.34	Best:23.04
2025-01-04 19:27:04,694: Snapshot:1	Epoch:5	Loss:2.922	translation_Loss:1.392	token_training_loss:0.0	distillation_Loss:1.53                                                   	MRR:23.1	Hits@10:38.3	Best:23.1
2025-01-04 19:27:11,420: Snapshot:1	Epoch:6	Loss:2.889	translation_Loss:1.34	token_training_loss:0.0	distillation_Loss:1.549                                                   	MRR:22.92	Hits@10:38.34	Best:23.1
2025-01-04 19:27:17,661: Snapshot:1	Epoch:7	Loss:2.878	translation_Loss:1.318	token_training_loss:0.0	distillation_Loss:1.561                                                   	MRR:23.13	Hits@10:38.42	Best:23.13
2025-01-04 19:27:24,293: Snapshot:1	Epoch:8	Loss:2.871	translation_Loss:1.304	token_training_loss:0.0	distillation_Loss:1.566                                                   	MRR:22.99	Hits@10:38.48	Best:23.13
2025-01-04 19:27:30,600: Snapshot:1	Epoch:9	Loss:2.862	translation_Loss:1.282	token_training_loss:0.0	distillation_Loss:1.581                                                   	MRR:23.17	Hits@10:38.4	Best:23.17
2025-01-04 19:27:37,377: Snapshot:1	Epoch:10	Loss:2.857	translation_Loss:1.274	token_training_loss:0.0	distillation_Loss:1.583                                                   	MRR:23.03	Hits@10:38.38	Best:23.17
2025-01-04 19:27:43,724: Snapshot:1	Epoch:11	Loss:2.86	translation_Loss:1.269	token_training_loss:0.0	distillation_Loss:1.59                                                   	MRR:23.01	Hits@10:38.31	Best:23.17
2025-01-04 19:27:49,973: Early Stopping! Snapshot: 1 Epoch: 12 Best Results: 23.17
2025-01-04 19:27:49,974: Start to training tokens! Snapshot: 1 Epoch: 12 Loss:2.855 MRR:22.94 Best Results: 23.17
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:27:49,974: Snapshot:1	Epoch:12	Loss:2.855	translation_Loss:1.267	token_training_loss:0.0	distillation_Loss:1.588                                                   	MRR:22.94	Hits@10:38.3	Best:23.17
2025-01-04 19:27:56,514: Snapshot:1	Epoch:13	Loss:29.102	translation_Loss:13.526	token_training_loss:15.576	distillation_Loss:0.0                                                   	MRR:22.94	Hits@10:38.3	Best:23.17
2025-01-04 19:28:02,701: End of token training: 1 Epoch: 14 Loss:13.876 MRR:22.94 Best Results: 23.17
2025-01-04 19:28:02,702: Snapshot:1	Epoch:14	Loss:13.876	translation_Loss:13.534	token_training_loss:0.342	distillation_Loss:0.0                                                           	MRR:22.94	Hits@10:38.3	Best:23.17
2025-01-04 19:28:02,954: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2025-01-04 19:28:08,204: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.254  | 0.164  | 0.2948 | 0.3519 |  0.4209 |
|     1      | 0.2311 | 0.1476 | 0.2701 | 0.3198 |  0.3856 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:28:21,013: Snapshot:2	Epoch:0	Loss:5.345	translation_Loss:4.147	token_training_loss:0.0	distillation_Loss:1.197                                                   	MRR:21.12	Hits@10:36.84	Best:21.12
2025-01-04 19:28:27,797: Snapshot:2	Epoch:1	Loss:4.409	translation_Loss:3.298	token_training_loss:0.0	distillation_Loss:1.111                                                   	MRR:21.47	Hits@10:37.21	Best:21.47
2025-01-04 19:28:34,222: Snapshot:2	Epoch:2	Loss:4.003	translation_Loss:3.03	token_training_loss:0.0	distillation_Loss:0.973                                                   	MRR:21.63	Hits@10:37.33	Best:21.63
2025-01-04 19:28:41,138: Snapshot:2	Epoch:3	Loss:3.925	translation_Loss:2.941	token_training_loss:0.0	distillation_Loss:0.984                                                   	MRR:21.7	Hits@10:37.44	Best:21.7
2025-01-04 19:28:47,575: Snapshot:2	Epoch:4	Loss:3.91	translation_Loss:2.939	token_training_loss:0.0	distillation_Loss:0.971                                                   	MRR:21.62	Hits@10:37.42	Best:21.7
2025-01-04 19:28:54,356: Snapshot:2	Epoch:5	Loss:3.895	translation_Loss:2.909	token_training_loss:0.0	distillation_Loss:0.986                                                   	MRR:21.76	Hits@10:37.3	Best:21.76
2025-01-04 19:29:00,677: Snapshot:2	Epoch:6	Loss:3.867	translation_Loss:2.896	token_training_loss:0.0	distillation_Loss:0.971                                                   	MRR:21.68	Hits@10:37.42	Best:21.76
2025-01-04 19:29:06,990: Snapshot:2	Epoch:7	Loss:3.885	translation_Loss:2.905	token_training_loss:0.0	distillation_Loss:0.981                                                   	MRR:21.71	Hits@10:37.31	Best:21.76
2025-01-04 19:29:13,778: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 21.76
2025-01-04 19:29:13,778: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:3.878 MRR:21.68 Best Results: 21.76
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:29:13,778: Snapshot:2	Epoch:8	Loss:3.878	translation_Loss:2.902	token_training_loss:0.0	distillation_Loss:0.976                                                   	MRR:21.68	Hits@10:37.46	Best:21.76
2025-01-04 19:29:20,224: Snapshot:2	Epoch:9	Loss:30.898	translation_Loss:14.466	token_training_loss:16.432	distillation_Loss:0.0                                                   	MRR:21.68	Hits@10:37.46	Best:21.76
2025-01-04 19:29:26,966: End of token training: 2 Epoch: 10 Loss:14.841 MRR:21.68 Best Results: 21.76
2025-01-04 19:29:26,966: Snapshot:2	Epoch:10	Loss:14.841	translation_Loss:14.48	token_training_loss:0.361	distillation_Loss:0.0                                                           	MRR:21.68	Hits@10:37.46	Best:21.76
2025-01-04 19:29:27,233: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2025-01-04 19:29:35,366: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2535 | 0.1638 | 0.2937 | 0.3503 |  0.4207 |
|     1      | 0.2344 | 0.1503 | 0.2734 | 0.3243 |  0.391  |
|     2      | 0.2156 | 0.1333 | 0.2505 | 0.304  |  0.3724 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:29:48,433: Snapshot:3	Epoch:0	Loss:3.849	translation_Loss:2.747	token_training_loss:0.0	distillation_Loss:1.102                                                   	MRR:19.27	Hits@10:36.61	Best:19.27
2025-01-04 19:29:54,921: Snapshot:3	Epoch:1	Loss:3.169	translation_Loss:2.12	token_training_loss:0.0	distillation_Loss:1.049                                                   	MRR:19.41	Hits@10:36.49	Best:19.41
2025-01-04 19:30:01,465: Snapshot:3	Epoch:2	Loss:2.992	translation_Loss:2.052	token_training_loss:0.0	distillation_Loss:0.94                                                   	MRR:19.49	Hits@10:36.74	Best:19.49
2025-01-04 19:30:08,740: Snapshot:3	Epoch:3	Loss:2.978	translation_Loss:2.022	token_training_loss:0.0	distillation_Loss:0.957                                                   	MRR:19.63	Hits@10:36.77	Best:19.63
2025-01-04 19:30:15,226: Snapshot:3	Epoch:4	Loss:2.973	translation_Loss:2.027	token_training_loss:0.0	distillation_Loss:0.946                                                   	MRR:19.47	Hits@10:36.74	Best:19.63
2025-01-04 19:30:21,645: Snapshot:3	Epoch:5	Loss:2.968	translation_Loss:2.011	token_training_loss:0.0	distillation_Loss:0.957                                                   	MRR:19.54	Hits@10:36.68	Best:19.63
2025-01-04 19:30:28,337: Early Stopping! Snapshot: 3 Epoch: 6 Best Results: 19.63
2025-01-04 19:30:28,338: Start to training tokens! Snapshot: 3 Epoch: 6 Loss:2.961 MRR:19.52 Best Results: 19.63
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:30:28,338: Snapshot:3	Epoch:6	Loss:2.961	translation_Loss:2.011	token_training_loss:0.0	distillation_Loss:0.949                                                   	MRR:19.52	Hits@10:36.9	Best:19.63
2025-01-04 19:30:34,664: Snapshot:3	Epoch:7	Loss:30.706	translation_Loss:13.973	token_training_loss:16.733	distillation_Loss:0.0                                                   	MRR:19.52	Hits@10:36.9	Best:19.63
2025-01-04 19:30:41,555: End of token training: 3 Epoch: 8 Loss:14.321 MRR:19.52 Best Results: 19.63
2025-01-04 19:30:41,555: Snapshot:3	Epoch:8	Loss:14.321	translation_Loss:13.974	token_training_loss:0.347	distillation_Loss:0.0                                                           	MRR:19.52	Hits@10:36.9	Best:19.63
2025-01-04 19:30:41,810: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2025-01-04 19:30:53,013: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2486 |  0.16  | 0.2861 | 0.3425 |  0.4154 |
|     1      | 0.2317 | 0.1475 | 0.2699 | 0.3223 |  0.389  |
|     2      | 0.2155 | 0.1308 | 0.2494 | 0.3056 |  0.3802 |
|     3      | 0.1973 | 0.1106 | 0.2281 | 0.2884 |  0.369  |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:31:05,730: Snapshot:4	Epoch:0	Loss:2.654	translation_Loss:1.73	token_training_loss:0.0	distillation_Loss:0.925                                                   	MRR:18.61	Hits@10:40.39	Best:18.61
2025-01-04 19:31:12,683: Snapshot:4	Epoch:1	Loss:1.944	translation_Loss:1.196	token_training_loss:0.0	distillation_Loss:0.748                                                   	MRR:19.46	Hits@10:41.06	Best:19.46
2025-01-04 19:31:19,203: Snapshot:4	Epoch:2	Loss:1.704	translation_Loss:1.021	token_training_loss:0.0	distillation_Loss:0.683                                                   	MRR:19.46	Hits@10:41.24	Best:19.46
2025-01-04 19:31:26,104: Snapshot:4	Epoch:3	Loss:1.677	translation_Loss:1.001	token_training_loss:0.0	distillation_Loss:0.676                                                   	MRR:19.6	Hits@10:41.32	Best:19.6
2025-01-04 19:31:32,540: Snapshot:4	Epoch:4	Loss:1.666	translation_Loss:0.993	token_training_loss:0.0	distillation_Loss:0.673                                                   	MRR:19.62	Hits@10:40.94	Best:19.62
2025-01-04 19:31:39,003: Snapshot:4	Epoch:5	Loss:1.661	translation_Loss:0.983	token_training_loss:0.0	distillation_Loss:0.679                                                   	MRR:19.65	Hits@10:41.46	Best:19.65
2025-01-04 19:31:45,940: Snapshot:4	Epoch:6	Loss:1.658	translation_Loss:0.979	token_training_loss:0.0	distillation_Loss:0.679                                                   	MRR:19.69	Hits@10:41.23	Best:19.69
2025-01-04 19:31:52,422: Snapshot:4	Epoch:7	Loss:1.656	translation_Loss:0.974	token_training_loss:0.0	distillation_Loss:0.683                                                   	MRR:19.68	Hits@10:41.42	Best:19.69
2025-01-04 19:31:59,187: Snapshot:4	Epoch:8	Loss:1.66	translation_Loss:0.982	token_training_loss:0.0	distillation_Loss:0.678                                                   	MRR:19.69	Hits@10:41.43	Best:19.69
2025-01-04 19:32:05,600: Snapshot:4	Epoch:9	Loss:1.663	translation_Loss:0.983	token_training_loss:0.0	distillation_Loss:0.68                                                   	MRR:19.82	Hits@10:41.41	Best:19.82
2025-01-04 19:32:12,049: Snapshot:4	Epoch:10	Loss:1.657	translation_Loss:0.975	token_training_loss:0.0	distillation_Loss:0.682                                                   	MRR:19.72	Hits@10:41.5	Best:19.82
2025-01-04 19:32:18,893: Snapshot:4	Epoch:11	Loss:1.658	translation_Loss:0.972	token_training_loss:0.0	distillation_Loss:0.686                                                   	MRR:19.77	Hits@10:41.41	Best:19.82
2025-01-04 19:32:25,387: Early Stopping! Snapshot: 4 Epoch: 12 Best Results: 19.82
2025-01-04 19:32:25,388: Start to training tokens! Snapshot: 4 Epoch: 12 Loss:1.661 MRR:19.63 Best Results: 19.82
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:32:25,388: Snapshot:4	Epoch:12	Loss:1.661	translation_Loss:0.981	token_training_loss:0.0	distillation_Loss:0.68                                                   	MRR:19.63	Hits@10:41.19	Best:19.82
2025-01-04 19:32:32,229: Snapshot:4	Epoch:13	Loss:27.924	translation_Loss:11.949	token_training_loss:15.975	distillation_Loss:0.0                                                   	MRR:19.63	Hits@10:41.19	Best:19.82
2025-01-04 19:32:38,579: End of token training: 4 Epoch: 14 Loss:12.303 MRR:19.63 Best Results: 19.82
2025-01-04 19:32:38,579: Snapshot:4	Epoch:14	Loss:12.303	translation_Loss:11.952	token_training_loss:0.351	distillation_Loss:0.0                                                           	MRR:19.63	Hits@10:41.19	Best:19.82
2025-01-04 19:32:38,896: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2025-01-04 19:32:52,974: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2432 | 0.1554 | 0.2805 | 0.3355 |  0.409  |
|     1      | 0.2278 | 0.1455 | 0.2622 | 0.3152 |  0.3839 |
|     2      | 0.2123 | 0.1285 | 0.245  | 0.3002 |  0.3776 |
|     3      | 0.1974 | 0.1104 | 0.226  | 0.2873 |  0.373  |
|     4      | 0.2005 | 0.0968 | 0.231  | 0.3099 |  0.4137 |
+------------+--------+--------+--------+--------+---------+
2025-01-04 19:32:52,976: Final Result:
[+------------+------+--------+--------+--------+---------+
| Snapshot:0 | MRR  | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+------+--------+--------+--------+---------+
|     0      | 0.24 | 0.1545 | 0.2823 | 0.3301 |  0.3922 |
+------------+------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.254  | 0.164  | 0.2948 | 0.3519 |  0.4209 |
|     1      | 0.2311 | 0.1476 | 0.2701 | 0.3198 |  0.3856 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2535 | 0.1638 | 0.2937 | 0.3503 |  0.4207 |
|     1      | 0.2344 | 0.1503 | 0.2734 | 0.3243 |  0.391  |
|     2      | 0.2156 | 0.1333 | 0.2505 | 0.304  |  0.3724 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2486 |  0.16  | 0.2861 | 0.3425 |  0.4154 |
|     1      | 0.2317 | 0.1475 | 0.2699 | 0.3223 |  0.389  |
|     2      | 0.2155 | 0.1308 | 0.2494 | 0.3056 |  0.3802 |
|     3      | 0.1973 | 0.1106 | 0.2281 | 0.2884 |  0.369  |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2432 | 0.1554 | 0.2805 | 0.3355 |  0.409  |
|     1      | 0.2278 | 0.1455 | 0.2622 | 0.3152 |  0.3839 |
|     2      | 0.2123 | 0.1285 | 0.245  | 0.3002 |  0.3776 |
|     3      | 0.1974 | 0.1104 | 0.226  | 0.2873 |  0.373  |
|     4      | 0.2005 | 0.0968 | 0.231  | 0.3099 |  0.4137 |
+------------+--------+--------+--------+--------+---------+]
2025-01-04 19:32:52,976: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 148.4172797203064  |    0.24   |    0.154     |    0.282     |     0.392     |
|    1     | 99.84419870376587  |   0.243   |    0.156     |    0.282     |     0.403     |
|    2     | 75.54380440711975  |   0.234   |    0.149     |    0.273     |     0.395     |
|    3     | 63.17613363265991  |   0.223   |    0.137     |    0.258     |     0.388     |
|    4     | 102.53152179718018 |   0.216   |    0.127     |    0.249     |     0.391     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-04 19:32:52,976: Sum_Training_Time:489.5129382610321
2025-01-04 19:32:52,976: Every_Training_Time:[148.4172797203064, 99.84419870376587, 75.54380440711975, 63.17613363265991, 102.53152179718018]
2025-01-04 19:32:52,976: Forward transfer: 0.172775 Backward transfer: -0.0008250000000000063
2025-01-04 19:33:29,011: Namespace(MAE_loss_weights=[1e-05, 1e-05, 1e-05, 1e-05], batch_size='3072', contrast_loss_weight=0.1, data_path='./data/FACT/', dataset='FACT', device=device(type='cuda', index=0), emb_dim=200, embedding_distill_weight=0.1, epoch_num=200, first_layer_epoch_num=10, first_training=True, gpu=0, l2=0.0, learning_rate=0.001, lifelong_name='double_tokened', log_path='./logs/20250104193257/FACT', logger=<RootLogger root (INFO)>, margin=8.0, mask_ratio=0.2, multi_distill_num=3, multi_layer_distance_weight=40, multi_layer_weight=1.0, multi_layers_path='train_sorted_by_edges_betweenness.txt', muti_embedding_distill_weight=1, neg_ratio=10, note='', num_layer=1, num_old_triples=20000, patience=3, predict_result=False, random_seed=3407, record=False, reply_loss_weight=0.1, save_path='./checkpoint/FACT', score_distill_weight=1, second_layer_epoch_num=20, skip_previous='False', snapshot_num=5, structure_distill_weight=0.1, token_distillation_weight=[200.0, 10000.0, 15000.0, 20000.0], token_num=7, train_new=True, two_stage_epoch_num=20, use_multi_layers='False', use_two_stage='False', using_MAE_loss=False, using_all_data=False, using_contrast_distill=False, using_different_weights=True, using_embedding_distill=True, using_mask_weight=True, using_multi_embedding_distill=False, using_multi_layer_distance_loss=False, using_relation_distill=False, using_reply=False, using_score_distill=False, using_structure_distill=False, using_test=False, using_token_distillation_loss=True, valid_metrics='mrr', without_hier_distill=False, without_multi_layers='True', without_two_stage=False)
Snapshot 0: No changes made to optimizer or model parameters.
Start training =============================
2025-01-04 19:33:38,241: Snapshot:0	Epoch:0	Loss:17.024	translation_Loss:17.024	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:6.23	Hits@10:13.26	Best:6.23
2025-01-04 19:33:44,652: Snapshot:0	Epoch:1	Loss:11.963	translation_Loss:11.963	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:9.69	Hits@10:22.6	Best:9.69
2025-01-04 19:33:50,507: Snapshot:0	Epoch:2	Loss:8.603	translation_Loss:8.603	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:12.9	Hits@10:28.88	Best:12.9
2025-01-04 19:33:56,772: Snapshot:0	Epoch:3	Loss:6.158	translation_Loss:6.158	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:15.74	Hits@10:33.13	Best:15.74
2025-01-04 19:34:02,748: Snapshot:0	Epoch:4	Loss:4.364	translation_Loss:4.364	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:18.35	Hits@10:36.01	Best:18.35
2025-01-04 19:34:08,718: Snapshot:0	Epoch:5	Loss:3.084	translation_Loss:3.084	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:20.42	Hits@10:37.69	Best:20.42
2025-01-04 19:34:15,131: Snapshot:0	Epoch:6	Loss:2.175	translation_Loss:2.175	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:21.98	Hits@10:38.79	Best:21.98
2025-01-04 19:34:21,105: Snapshot:0	Epoch:7	Loss:1.541	translation_Loss:1.541	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:22.96	Hits@10:39.49	Best:22.96
2025-01-04 19:34:27,348: Snapshot:0	Epoch:8	Loss:1.095	translation_Loss:1.095	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:23.75	Hits@10:39.71	Best:23.75
2025-01-04 19:34:33,288: Snapshot:0	Epoch:9	Loss:0.816	translation_Loss:0.816	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.19	Hits@10:40.12	Best:24.19
2025-01-04 19:34:39,240: Snapshot:0	Epoch:10	Loss:0.628	translation_Loss:0.628	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.38	Hits@10:40.29	Best:24.38
2025-01-04 19:34:45,666: Snapshot:0	Epoch:11	Loss:0.496	translation_Loss:0.496	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.49	Hits@10:40.31	Best:24.49
2025-01-04 19:34:51,614: Snapshot:0	Epoch:12	Loss:0.412	translation_Loss:0.412	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.52	Hits@10:40.29	Best:24.52
2025-01-04 19:34:57,863: Snapshot:0	Epoch:13	Loss:0.35	translation_Loss:0.35	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.67	Hits@10:40.34	Best:24.67
2025-01-04 19:35:03,891: Snapshot:0	Epoch:14	Loss:0.31	translation_Loss:0.31	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.6	Hits@10:40.25	Best:24.67
2025-01-04 19:35:09,883: Snapshot:0	Epoch:15	Loss:0.272	translation_Loss:0.272	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.72	Hits@10:40.32	Best:24.72
2025-01-04 19:35:16,068: Snapshot:0	Epoch:16	Loss:0.243	translation_Loss:0.243	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.7	Hits@10:40.3	Best:24.72
2025-01-04 19:35:22,007: Snapshot:0	Epoch:17	Loss:0.222	translation_Loss:0.222	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.79	Hits@10:40.48	Best:24.79
2025-01-04 19:35:28,356: Snapshot:0	Epoch:18	Loss:0.207	translation_Loss:0.207	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.79	Hits@10:40.39	Best:24.79
2025-01-04 19:35:34,186: Snapshot:0	Epoch:19	Loss:0.193	translation_Loss:0.193	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.74	Hits@10:40.28	Best:24.79
2025-01-04 19:35:40,452: Early Stopping! Snapshot: 0 Epoch: 20 Best Results: 24.79
2025-01-04 19:35:40,453: Start to training tokens! Snapshot: 0 Epoch: 20 Loss:0.18 MRR:24.7 Best Results: 24.79
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:35:40,453: Snapshot:0	Epoch:20	Loss:0.18	translation_Loss:0.18	token_training_loss:0.0	distillation_Loss:0.0                                                   	MRR:24.7	Hits@10:40.37	Best:24.79
2025-01-04 19:35:46,870: Snapshot:0	Epoch:21	Loss:28.277	translation_Loss:12.323	token_training_loss:15.955	distillation_Loss:0.0                                                   	MRR:24.7	Hits@10:40.37	Best:24.79
2025-01-04 19:35:52,672: End of token training: 0 Epoch: 22 Loss:12.657 MRR:24.7 Best Results: 24.79
2025-01-04 19:35:52,672: Snapshot:0	Epoch:22	Loss:12.657	translation_Loss:12.311	token_training_loss:0.346	distillation_Loss:0.0                                                           	MRR:24.7	Hits@10:40.37	Best:24.79
2025-01-04 19:35:52,950: => loading checkpoint './checkpoint/FACT/0model_best.tar'
2025-01-04 19:35:55,446: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2403 | 0.1555 | 0.2815 | 0.3301 |  0.3927 |
+------------+--------+--------+--------+--------+---------+
Snapshot 1: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:36:08,126: Snapshot:1	Epoch:0	Loss:7.259	translation_Loss:7.06	token_training_loss:0.0	distillation_Loss:0.199                                                   	MRR:20.84	Hits@10:34.74	Best:20.84
2025-01-04 19:36:14,769: Snapshot:1	Epoch:1	Loss:3.405	translation_Loss:2.954	token_training_loss:0.0	distillation_Loss:0.45                                                   	MRR:22.6	Hits@10:37.3	Best:22.6
2025-01-04 19:36:21,130: Snapshot:1	Epoch:2	Loss:1.963	translation_Loss:1.36	token_training_loss:0.0	distillation_Loss:0.603                                                   	MRR:23.37	Hits@10:38.23	Best:23.37
2025-01-04 19:36:27,793: Snapshot:1	Epoch:3	Loss:1.483	translation_Loss:0.811	token_training_loss:0.0	distillation_Loss:0.671                                                   	MRR:23.47	Hits@10:38.44	Best:23.47
2025-01-04 19:36:34,081: Snapshot:1	Epoch:4	Loss:1.317	translation_Loss:0.62	token_training_loss:0.0	distillation_Loss:0.696                                                   	MRR:23.33	Hits@10:38.44	Best:23.47
2025-01-04 19:36:40,290: Snapshot:1	Epoch:5	Loss:1.237	translation_Loss:0.53	token_training_loss:0.0	distillation_Loss:0.707                                                   	MRR:23.38	Hits@10:38.5	Best:23.47
2025-01-04 19:36:46,915: Early Stopping! Snapshot: 1 Epoch: 6 Best Results: 23.47
2025-01-04 19:36:46,916: Start to training tokens! Snapshot: 1 Epoch: 6 Loss:1.2 MRR:23.32 Best Results: 23.47
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:36:46,916: Snapshot:1	Epoch:6	Loss:1.2	translation_Loss:0.487	token_training_loss:0.0	distillation_Loss:0.713                                                   	MRR:23.32	Hits@10:38.41	Best:23.47
2025-01-04 19:36:53,121: Snapshot:1	Epoch:7	Loss:28.699	translation_Loss:13.124	token_training_loss:15.576	distillation_Loss:0.0                                                   	MRR:23.32	Hits@10:38.41	Best:23.47
2025-01-04 19:36:59,892: End of token training: 1 Epoch: 8 Loss:13.465 MRR:23.32 Best Results: 23.47
2025-01-04 19:36:59,893: Snapshot:1	Epoch:8	Loss:13.465	translation_Loss:13.122	token_training_loss:0.342	distillation_Loss:0.0                                                           	MRR:23.32	Hits@10:38.41	Best:23.47
2025-01-04 19:37:00,158: => loading checkpoint './checkpoint/FACT/1model_best.tar'
2025-01-04 19:37:05,220: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2432 | 0.1563 | 0.2811 | 0.3356 |  0.4094 |
|     1      | 0.2344 | 0.1517 | 0.2746 | 0.3221 |  0.3872 |
+------------+--------+--------+--------+--------+---------+
Snapshot 2: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:37:18,449: Snapshot:2	Epoch:0	Loss:5.112	translation_Loss:3.927	token_training_loss:0.0	distillation_Loss:1.185                                                   	MRR:21.46	Hits@10:37.11	Best:21.46
2025-01-04 19:37:25,028: Snapshot:2	Epoch:1	Loss:4.185	translation_Loss:3.069	token_training_loss:0.0	distillation_Loss:1.117                                                   	MRR:21.74	Hits@10:37.35	Best:21.74
2025-01-04 19:37:31,525: Snapshot:2	Epoch:2	Loss:3.784	translation_Loss:2.796	token_training_loss:0.0	distillation_Loss:0.988                                                   	MRR:21.94	Hits@10:37.66	Best:21.94
2025-01-04 19:37:38,428: Snapshot:2	Epoch:3	Loss:3.711	translation_Loss:2.719	token_training_loss:0.0	distillation_Loss:0.992                                                   	MRR:21.97	Hits@10:37.65	Best:21.97
2025-01-04 19:37:44,901: Snapshot:2	Epoch:4	Loss:3.682	translation_Loss:2.704	token_training_loss:0.0	distillation_Loss:0.978                                                   	MRR:21.92	Hits@10:37.66	Best:21.97
2025-01-04 19:37:51,854: Snapshot:2	Epoch:5	Loss:3.666	translation_Loss:2.68	token_training_loss:0.0	distillation_Loss:0.987                                                   	MRR:22.03	Hits@10:37.74	Best:22.03
2025-01-04 19:37:58,333: Snapshot:2	Epoch:6	Loss:3.667	translation_Loss:2.688	token_training_loss:0.0	distillation_Loss:0.979                                                   	MRR:21.96	Hits@10:37.64	Best:22.03
2025-01-04 19:38:04,798: Snapshot:2	Epoch:7	Loss:3.669	translation_Loss:2.671	token_training_loss:0.0	distillation_Loss:0.998                                                   	MRR:21.92	Hits@10:37.68	Best:22.03
2025-01-04 19:38:11,609: Early Stopping! Snapshot: 2 Epoch: 8 Best Results: 22.03
2025-01-04 19:38:11,609: Start to training tokens! Snapshot: 2 Epoch: 8 Loss:3.667 MRR:21.94 Best Results: 22.03
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:38:11,609: Snapshot:2	Epoch:8	Loss:3.667	translation_Loss:2.683	token_training_loss:0.0	distillation_Loss:0.984                                                   	MRR:21.94	Hits@10:37.69	Best:22.03
2025-01-04 19:38:17,942: Snapshot:2	Epoch:9	Loss:30.968	translation_Loss:14.536	token_training_loss:16.432	distillation_Loss:0.0                                                   	MRR:21.94	Hits@10:37.69	Best:22.03
2025-01-04 19:38:24,671: End of token training: 2 Epoch: 10 Loss:14.878 MRR:21.94 Best Results: 22.03
2025-01-04 19:38:24,671: Snapshot:2	Epoch:10	Loss:14.878	translation_Loss:14.517	token_training_loss:0.361	distillation_Loss:0.0                                                           	MRR:21.94	Hits@10:37.69	Best:22.03
2025-01-04 19:38:24,922: => loading checkpoint './checkpoint/FACT/2model_best.tar'
2025-01-04 19:38:33,177: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2437 | 0.1563 | 0.2802 | 0.3367 |  0.4113 |
|     1      | 0.2384 | 0.1543 | 0.2775 | 0.3273 |  0.3946 |
|     2      | 0.2204 | 0.138  | 0.2534 | 0.3075 |  0.3766 |
+------------+--------+--------+--------+--------+---------+
Snapshot 3: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:38:46,065: Snapshot:3	Epoch:0	Loss:3.728	translation_Loss:2.585	token_training_loss:0.0	distillation_Loss:1.143                                                   	MRR:19.04	Hits@10:35.92	Best:19.04
2025-01-04 19:38:52,973: Snapshot:3	Epoch:1	Loss:3.287	translation_Loss:2.312	token_training_loss:0.0	distillation_Loss:0.976                                                   	MRR:19.23	Hits@10:36.22	Best:19.23
2025-01-04 19:38:59,550: Snapshot:3	Epoch:2	Loss:3.007	translation_Loss:2.137	token_training_loss:0.0	distillation_Loss:0.87                                                   	MRR:19.41	Hits@10:36.26	Best:19.41
2025-01-04 19:39:06,537: Snapshot:3	Epoch:3	Loss:3.006	translation_Loss:2.132	token_training_loss:0.0	distillation_Loss:0.874                                                   	MRR:19.4	Hits@10:36.22	Best:19.41
2025-01-04 19:39:13,031: Snapshot:3	Epoch:4	Loss:2.993	translation_Loss:2.13	token_training_loss:0.0	distillation_Loss:0.863                                                   	MRR:19.35	Hits@10:36.36	Best:19.41
2025-01-04 19:39:19,654: Snapshot:3	Epoch:5	Loss:2.993	translation_Loss:2.118	token_training_loss:0.0	distillation_Loss:0.875                                                   	MRR:19.52	Hits@10:36.47	Best:19.52
2025-01-04 19:39:26,602: Snapshot:3	Epoch:6	Loss:2.984	translation_Loss:2.112	token_training_loss:0.0	distillation_Loss:0.872                                                   	MRR:19.46	Hits@10:36.43	Best:19.52
2025-01-04 19:39:33,003: Snapshot:3	Epoch:7	Loss:3.01	translation_Loss:2.139	token_training_loss:0.0	distillation_Loss:0.871                                                   	MRR:19.44	Hits@10:36.33	Best:19.52
2025-01-04 19:39:39,817: Early Stopping! Snapshot: 3 Epoch: 8 Best Results: 19.52
2025-01-04 19:39:39,817: Start to training tokens! Snapshot: 3 Epoch: 8 Loss:2.998 MRR:19.45 Best Results: 19.52
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:39:39,817: Snapshot:3	Epoch:8	Loss:2.998	translation_Loss:2.12	token_training_loss:0.0	distillation_Loss:0.878                                                   	MRR:19.45	Hits@10:36.42	Best:19.52
2025-01-04 19:39:46,274: Snapshot:3	Epoch:9	Loss:30.851	translation_Loss:14.118	token_training_loss:16.733	distillation_Loss:0.0                                                   	MRR:19.45	Hits@10:36.42	Best:19.52
2025-01-04 19:39:53,115: End of token training: 3 Epoch: 10 Loss:14.473 MRR:19.45 Best Results: 19.52
2025-01-04 19:39:53,115: Snapshot:3	Epoch:10	Loss:14.473	translation_Loss:14.126	token_training_loss:0.347	distillation_Loss:0.0                                                           	MRR:19.45	Hits@10:36.42	Best:19.52
2025-01-04 19:39:53,416: => loading checkpoint './checkpoint/FACT/3model_best.tar'
2025-01-04 19:40:04,735: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2397 | 0.1528 | 0.2744 | 0.3318 |  0.4087 |
|     1      | 0.2363 | 0.1526 | 0.2738 | 0.3258 |  0.3938 |
|     2      | 0.2204 | 0.1356 | 0.2543 | 0.3125 |  0.3858 |
|     3      | 0.1972 | 0.1102 | 0.2291 | 0.2889 |  0.3668 |
+------------+--------+--------+--------+--------+---------+
Snapshot 4: Resetting for new snapshot...
Token frozen for new snapshot.
Embeddings are now trainable.
Reinitializing token...
Optimizer reset: Training embeddings and reinitialized token.
Start training =============================
2025-01-04 19:40:17,788: Snapshot:4	Epoch:0	Loss:2.632	translation_Loss:1.695	token_training_loss:0.0	distillation_Loss:0.937                                                   	MRR:18.62	Hits@10:40.45	Best:18.62
2025-01-04 19:40:24,775: Snapshot:4	Epoch:1	Loss:1.901	translation_Loss:1.14	token_training_loss:0.0	distillation_Loss:0.761                                                   	MRR:19.32	Hits@10:40.72	Best:19.32
2025-01-04 19:40:31,420: Snapshot:4	Epoch:2	Loss:1.662	translation_Loss:0.973	token_training_loss:0.0	distillation_Loss:0.689                                                   	MRR:19.57	Hits@10:41.21	Best:19.57
2025-01-04 19:40:38,483: Snapshot:4	Epoch:3	Loss:1.636	translation_Loss:0.951	token_training_loss:0.0	distillation_Loss:0.685                                                   	MRR:19.61	Hits@10:40.98	Best:19.61
2025-01-04 19:40:44,965: Snapshot:4	Epoch:4	Loss:1.637	translation_Loss:0.953	token_training_loss:0.0	distillation_Loss:0.685                                                   	MRR:19.51	Hits@10:41.08	Best:19.61
2025-01-04 19:40:51,905: Snapshot:4	Epoch:5	Loss:1.628	translation_Loss:0.944	token_training_loss:0.0	distillation_Loss:0.685                                                   	MRR:19.53	Hits@10:41.03	Best:19.61
2025-01-04 19:40:58,379: Early Stopping! Snapshot: 4 Epoch: 6 Best Results: 19.61
2025-01-04 19:40:58,379: Start to training tokens! Snapshot: 4 Epoch: 6 Loss:1.625 MRR:19.56 Best Results: 19.61
Token added to optimizer, embeddings excluded successfully.
2025-01-04 19:40:58,379: Snapshot:4	Epoch:6	Loss:1.625	translation_Loss:0.938	token_training_loss:0.0	distillation_Loss:0.687                                                   	MRR:19.56	Hits@10:40.88	Best:19.61
2025-01-04 19:41:04,904: Snapshot:4	Epoch:7	Loss:27.956	translation_Loss:11.982	token_training_loss:15.975	distillation_Loss:0.0                                                   	MRR:19.56	Hits@10:40.88	Best:19.61
2025-01-04 19:41:11,709: End of token training: 4 Epoch: 8 Loss:12.337 MRR:19.56 Best Results: 19.61
2025-01-04 19:41:11,709: Snapshot:4	Epoch:8	Loss:12.337	translation_Loss:11.986	token_training_loss:0.351	distillation_Loss:0.0                                                           	MRR:19.56	Hits@10:40.88	Best:19.61
2025-01-04 19:41:11,968: => loading checkpoint './checkpoint/FACT/4model_best.tar'
2025-01-04 19:41:26,240: 
+------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2366 | 0.1507 | 0.2705 | 0.3258 |  0.4019 |
|     1      | 0.2314 | 0.1488 | 0.2666 | 0.3173 |  0.3888 |
|     2      | 0.2172 | 0.1334 | 0.2498 | 0.3076 |  0.3837 |
|     3      | 0.1967 | 0.1086 | 0.2277 | 0.2884 |  0.3751 |
|     4      | 0.1978 | 0.0949 | 0.2277 | 0.3065 |  0.4104 |
+------------+--------+--------+--------+--------+---------+
2025-01-04 19:41:26,243: Final Result:
[+------------+--------+--------+--------+--------+---------+
| Snapshot:0 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2403 | 0.1555 | 0.2815 | 0.3301 |  0.3927 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:1 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2432 | 0.1563 | 0.2811 | 0.3356 |  0.4094 |
|     1      | 0.2344 | 0.1517 | 0.2746 | 0.3221 |  0.3872 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:2 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2437 | 0.1563 | 0.2802 | 0.3367 |  0.4113 |
|     1      | 0.2384 | 0.1543 | 0.2775 | 0.3273 |  0.3946 |
|     2      | 0.2204 | 0.138  | 0.2534 | 0.3075 |  0.3766 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:3 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2397 | 0.1528 | 0.2744 | 0.3318 |  0.4087 |
|     1      | 0.2363 | 0.1526 | 0.2738 | 0.3258 |  0.3938 |
|     2      | 0.2204 | 0.1356 | 0.2543 | 0.3125 |  0.3858 |
|     3      | 0.1972 | 0.1102 | 0.2291 | 0.2889 |  0.3668 |
+------------+--------+--------+--------+--------+---------+, +------------+--------+--------+--------+--------+---------+
| Snapshot:4 |  MRR   | Hits@1 | Hits@3 | Hits@5 | Hits@10 |
+------------+--------+--------+--------+--------+---------+
|     0      | 0.2366 | 0.1507 | 0.2705 | 0.3258 |  0.4019 |
|     1      | 0.2314 | 0.1488 | 0.2666 | 0.3173 |  0.3888 |
|     2      | 0.2172 | 0.1334 | 0.2498 | 0.3076 |  0.3837 |
|     3      | 0.1967 | 0.1086 | 0.2277 | 0.2884 |  0.3751 |
|     4      | 0.1978 | 0.0949 | 0.2277 | 0.3065 |  0.4104 |
+------------+--------+--------+--------+--------+---------+]
2025-01-04 19:41:26,243: Report Result:
+----------+--------------------+-----------+--------------+--------------+---------------+
| Snapshot |        Time        | Whole_MRR | Whole_Hits@1 | Whole_Hits@3 | Whole_Hits@10 |
+----------+--------------------+-----------+--------------+--------------+---------------+
|    0     | 143.66005158424377 |    0.24   |    0.155     |    0.281     |     0.393     |
|    1     | 61.351799726486206 |   0.239   |    0.154     |    0.278     |     0.398     |
|    2     | 76.23631834983826  |   0.234   |     0.15     |     0.27     |     0.394     |
|    3     | 76.94054007530212  |   0.223   |    0.138     |    0.258     |     0.389     |
|    4     | 63.844831228256226 |   0.216   |    0.127     |    0.248     |     0.392     |
+----------+--------------------+-----------+--------------+--------------+---------------+
2025-01-04 19:41:26,243: Sum_Training_Time:422.0335409641266
2025-01-04 19:41:26,243: Every_Training_Time:[143.66005158424377, 61.351799726486206, 76.23631834983826, 76.94054007530212, 63.844831228256226]
2025-01-04 19:41:26,243: Forward transfer: 0.17367499999999997 Backward transfer: -0.002599999999999998
